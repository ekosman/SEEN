{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 64\n",
    "tree_depth = 12\n",
    "batch_size = 512\n",
    "device = 'cpu'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.531494617462158 | KNN Loss: 5.871538162231445 | CLS Loss: 1.6599565744400024\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 5.513195037841797 | KNN Loss: 4.814934253692627 | CLS Loss: 0.6982605457305908\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 5.213438987731934 | KNN Loss: 4.526139736175537 | CLS Loss: 0.6872991323471069\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 5.109689712524414 | KNN Loss: 4.477982997894287 | CLS Loss: 0.631706953048706\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 4.985007286071777 | KNN Loss: 4.419722557067871 | CLS Loss: 0.5652847290039062\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 5.026525974273682 | KNN Loss: 4.453143119812012 | CLS Loss: 0.5733826756477356\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 4.984081745147705 | KNN Loss: 4.435934066772461 | CLS Loss: 0.5481476187705994\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 4.842815399169922 | KNN Loss: 4.402174472808838 | CLS Loss: 0.440640926361084\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 4.837180137634277 | KNN Loss: 4.356228828430176 | CLS Loss: 0.48095110058784485\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 4.86761474609375 | KNN Loss: 4.356707572937012 | CLS Loss: 0.5109070539474487\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 4.844347953796387 | KNN Loss: 4.351109504699707 | CLS Loss: 0.49323850870132446\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 4.812997341156006 | KNN Loss: 4.344372749328613 | CLS Loss: 0.46862471103668213\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 4.772484302520752 | KNN Loss: 4.3443098068237305 | CLS Loss: 0.4281744956970215\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 4.795876502990723 | KNN Loss: 4.358642578125 | CLS Loss: 0.43723368644714355\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 4.7264933586120605 | KNN Loss: 4.37161922454834 | CLS Loss: 0.3548739552497864\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 4.684883117675781 | KNN Loss: 4.340778350830078 | CLS Loss: 0.3441050052642822\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 4.678932189941406 | KNN Loss: 4.360625743865967 | CLS Loss: 0.31830650568008423\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 4.739923477172852 | KNN Loss: 4.387346267700195 | CLS Loss: 0.35257723927497864\n",
      "Epoch: 001, Loss: 5.0142, Train: 0.8951, Valid: 0.8949, Best: 0.8949\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 4.665853500366211 | KNN Loss: 4.366030216217041 | CLS Loss: 0.29982319474220276\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 4.686320781707764 | KNN Loss: 4.345386981964111 | CLS Loss: 0.34093400835990906\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 4.678792953491211 | KNN Loss: 4.353337287902832 | CLS Loss: 0.32545560598373413\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 4.64133358001709 | KNN Loss: 4.341179370880127 | CLS Loss: 0.30015429854393005\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 4.615643501281738 | KNN Loss: 4.328779697418213 | CLS Loss: 0.2868639826774597\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 4.5952019691467285 | KNN Loss: 4.334383964538574 | CLS Loss: 0.26081785559654236\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 4.664651870727539 | KNN Loss: 4.319424629211426 | CLS Loss: 0.34522727131843567\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 4.595530033111572 | KNN Loss: 4.359244346618652 | CLS Loss: 0.23628561198711395\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 4.562207221984863 | KNN Loss: 4.365199565887451 | CLS Loss: 0.19700779020786285\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 4.581249713897705 | KNN Loss: 4.346012592315674 | CLS Loss: 0.23523730039596558\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 4.575910568237305 | KNN Loss: 4.33078145980835 | CLS Loss: 0.24512922763824463\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 4.566370010375977 | KNN Loss: 4.333819389343262 | CLS Loss: 0.2325504571199417\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 4.565351963043213 | KNN Loss: 4.362583160400391 | CLS Loss: 0.20276877284049988\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 4.484416484832764 | KNN Loss: 4.326459884643555 | CLS Loss: 0.1579568088054657\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 4.48662805557251 | KNN Loss: 4.322916030883789 | CLS Loss: 0.16371199488639832\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 4.555151462554932 | KNN Loss: 4.360466480255127 | CLS Loss: 0.19468514621257782\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 4.4955854415893555 | KNN Loss: 4.307567596435547 | CLS Loss: 0.18801778554916382\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 4.5074262619018555 | KNN Loss: 4.323485374450684 | CLS Loss: 0.183941051363945\n",
      "Epoch: 002, Loss: 4.5898, Train: 0.9445, Valid: 0.9437, Best: 0.9437\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 4.510640621185303 | KNN Loss: 4.332912445068359 | CLS Loss: 0.1777283102273941\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 4.495962142944336 | KNN Loss: 4.347454071044922 | CLS Loss: 0.14850787818431854\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 4.461782932281494 | KNN Loss: 4.310579776763916 | CLS Loss: 0.15120325982570648\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 4.507964611053467 | KNN Loss: 4.303603649139404 | CLS Loss: 0.20436115562915802\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 4.511752605438232 | KNN Loss: 4.314167499542236 | CLS Loss: 0.1975853145122528\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 4.500018119812012 | KNN Loss: 4.322235107421875 | CLS Loss: 0.17778320610523224\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 4.480422496795654 | KNN Loss: 4.32008171081543 | CLS Loss: 0.1603408008813858\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 4.472776412963867 | KNN Loss: 4.307987689971924 | CLS Loss: 0.16478891670703888\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 4.503215789794922 | KNN Loss: 4.2862324714660645 | CLS Loss: 0.21698316931724548\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 4.549815654754639 | KNN Loss: 4.3247175216674805 | CLS Loss: 0.22509829699993134\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 4.50234317779541 | KNN Loss: 4.337508201599121 | CLS Loss: 0.1648350954055786\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 4.453555107116699 | KNN Loss: 4.320334434509277 | CLS Loss: 0.13322046399116516\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 4.444880485534668 | KNN Loss: 4.312883377075195 | CLS Loss: 0.13199728727340698\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 4.464241981506348 | KNN Loss: 4.309895992279053 | CLS Loss: 0.1543458253145218\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 4.4711384773254395 | KNN Loss: 4.267195224761963 | CLS Loss: 0.203943133354187\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 4.400390625 | KNN Loss: 4.268805503845215 | CLS Loss: 0.13158535957336426\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 4.392827987670898 | KNN Loss: 4.279166221618652 | CLS Loss: 0.11366157233715057\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 4.44739294052124 | KNN Loss: 4.291868209838867 | CLS Loss: 0.15552476048469543\n",
      "Epoch: 003, Loss: 4.4789, Train: 0.9664, Valid: 0.9638, Best: 0.9638\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 4.5483222007751465 | KNN Loss: 4.355396747589111 | CLS Loss: 0.1929253339767456\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 4.4637064933776855 | KNN Loss: 4.335848331451416 | CLS Loss: 0.1278580278158188\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 4.458404064178467 | KNN Loss: 4.297366619110107 | CLS Loss: 0.16103747487068176\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 4.429920196533203 | KNN Loss: 4.301069259643555 | CLS Loss: 0.1288507878780365\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 4.38587760925293 | KNN Loss: 4.2714457511901855 | CLS Loss: 0.11443163454532623\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 4.347342014312744 | KNN Loss: 4.2280192375183105 | CLS Loss: 0.11932295560836792\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 4.454438209533691 | KNN Loss: 4.30618953704834 | CLS Loss: 0.14824844896793365\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 4.466045379638672 | KNN Loss: 4.271651268005371 | CLS Loss: 0.194394052028656\n",
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 4.390892028808594 | KNN Loss: 4.326221466064453 | CLS Loss: 0.06467077881097794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 4.3926873207092285 | KNN Loss: 4.253031253814697 | CLS Loss: 0.1396559327840805\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 4.483060359954834 | KNN Loss: 4.3383259773254395 | CLS Loss: 0.14473433792591095\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 4.440836429595947 | KNN Loss: 4.299612045288086 | CLS Loss: 0.14122438430786133\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 4.440685749053955 | KNN Loss: 4.326118469238281 | CLS Loss: 0.11456704884767532\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 4.37481164932251 | KNN Loss: 4.264281272888184 | CLS Loss: 0.11053016036748886\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 4.391666412353516 | KNN Loss: 4.29433012008667 | CLS Loss: 0.0973360538482666\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 4.4143781661987305 | KNN Loss: 4.301726341247559 | CLS Loss: 0.11265181005001068\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 4.412785053253174 | KNN Loss: 4.273590087890625 | CLS Loss: 0.1391947865486145\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 4.423834323883057 | KNN Loss: 4.28007173538208 | CLS Loss: 0.1437627375125885\n",
      "Epoch: 004, Loss: 4.4340, Train: 0.9648, Valid: 0.9615, Best: 0.9638\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 4.375726222991943 | KNN Loss: 4.302730560302734 | CLS Loss: 0.07299553602933884\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 4.390544891357422 | KNN Loss: 4.289870262145996 | CLS Loss: 0.10067478567361832\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 4.467219352722168 | KNN Loss: 4.278704643249512 | CLS Loss: 0.1885147988796234\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 4.4346723556518555 | KNN Loss: 4.259498119354248 | CLS Loss: 0.1751740425825119\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 4.454113483428955 | KNN Loss: 4.3097381591796875 | CLS Loss: 0.1443755179643631\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 4.407293796539307 | KNN Loss: 4.277963638305664 | CLS Loss: 0.1293303370475769\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 4.4065093994140625 | KNN Loss: 4.298153400421143 | CLS Loss: 0.10835620015859604\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 4.391480922698975 | KNN Loss: 4.283437252044678 | CLS Loss: 0.10804365575313568\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 4.347795009613037 | KNN Loss: 4.244888782501221 | CLS Loss: 0.10290607064962387\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 4.473507881164551 | KNN Loss: 4.347211837768555 | CLS Loss: 0.1262960135936737\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 4.4266839027404785 | KNN Loss: 4.290064334869385 | CLS Loss: 0.13661974668502808\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 4.390198707580566 | KNN Loss: 4.2863450050354 | CLS Loss: 0.10385365039110184\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 4.441283226013184 | KNN Loss: 4.3037872314453125 | CLS Loss: 0.13749606907367706\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 4.3718085289001465 | KNN Loss: 4.268657207489014 | CLS Loss: 0.10315118730068207\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 4.4042768478393555 | KNN Loss: 4.291000843048096 | CLS Loss: 0.11327596008777618\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 4.422295093536377 | KNN Loss: 4.271430969238281 | CLS Loss: 0.15086397528648376\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 4.398947238922119 | KNN Loss: 4.293615818023682 | CLS Loss: 0.10533126443624496\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 4.397848606109619 | KNN Loss: 4.262834548950195 | CLS Loss: 0.13501428067684174\n",
      "Epoch: 005, Loss: 4.4034, Train: 0.9695, Valid: 0.9670, Best: 0.9670\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 4.4235758781433105 | KNN Loss: 4.310730457305908 | CLS Loss: 0.1128452941775322\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 4.39417839050293 | KNN Loss: 4.312626838684082 | CLS Loss: 0.08155132830142975\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 4.364891529083252 | KNN Loss: 4.289061546325684 | CLS Loss: 0.07583017647266388\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 4.426804542541504 | KNN Loss: 4.327571392059326 | CLS Loss: 0.09923302382230759\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 4.446159362792969 | KNN Loss: 4.277613639831543 | CLS Loss: 0.16854578256607056\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 4.373056411743164 | KNN Loss: 4.293088436126709 | CLS Loss: 0.07996774464845657\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 4.426081657409668 | KNN Loss: 4.302976131439209 | CLS Loss: 0.12310570478439331\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 4.452378273010254 | KNN Loss: 4.298091411590576 | CLS Loss: 0.15428677201271057\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 4.41211462020874 | KNN Loss: 4.266013145446777 | CLS Loss: 0.14610154926776886\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 4.409678936004639 | KNN Loss: 4.308217525482178 | CLS Loss: 0.10146156698465347\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 4.341362953186035 | KNN Loss: 4.252481460571289 | CLS Loss: 0.08888141810894012\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 4.368595123291016 | KNN Loss: 4.243179798126221 | CLS Loss: 0.12541534006595612\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 4.46674108505249 | KNN Loss: 4.335638523101807 | CLS Loss: 0.13110266625881195\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 4.407722473144531 | KNN Loss: 4.298402309417725 | CLS Loss: 0.10931992530822754\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 4.3513312339782715 | KNN Loss: 4.264945983886719 | CLS Loss: 0.08638520538806915\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 4.441259860992432 | KNN Loss: 4.325175762176514 | CLS Loss: 0.11608432233333588\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 4.383543491363525 | KNN Loss: 4.27788782119751 | CLS Loss: 0.10565555840730667\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 4.351691722869873 | KNN Loss: 4.277735710144043 | CLS Loss: 0.07395584881305695\n",
      "Epoch: 006, Loss: 4.3851, Train: 0.9739, Valid: 0.9708, Best: 0.9708\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 4.357418537139893 | KNN Loss: 4.249086380004883 | CLS Loss: 0.10833221673965454\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 4.343996524810791 | KNN Loss: 4.252140998840332 | CLS Loss: 0.09185566753149033\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 4.4211626052856445 | KNN Loss: 4.298884868621826 | CLS Loss: 0.12227776646614075\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 4.321169376373291 | KNN Loss: 4.247689247131348 | CLS Loss: 0.07348015159368515\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 4.3417134284973145 | KNN Loss: 4.272793292999268 | CLS Loss: 0.06892016530036926\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 4.398430347442627 | KNN Loss: 4.276566505432129 | CLS Loss: 0.12186391651630402\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 4.328023433685303 | KNN Loss: 4.276104927062988 | CLS Loss: 0.05191860347986221\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 4.3349480628967285 | KNN Loss: 4.224846363067627 | CLS Loss: 0.11010191589593887\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 4.3759942054748535 | KNN Loss: 4.299134731292725 | CLS Loss: 0.07685945928096771\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 4.341864109039307 | KNN Loss: 4.225998401641846 | CLS Loss: 0.11586559563875198\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 4.333805084228516 | KNN Loss: 4.265697002410889 | CLS Loss: 0.0681082010269165\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 4.368422985076904 | KNN Loss: 4.276611804962158 | CLS Loss: 0.09181104600429535\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 4.324291706085205 | KNN Loss: 4.264031410217285 | CLS Loss: 0.060260239988565445\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 4.338636875152588 | KNN Loss: 4.250611305236816 | CLS Loss: 0.08802574127912521\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 4.386260986328125 | KNN Loss: 4.299702167510986 | CLS Loss: 0.08655904233455658\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 4.420206069946289 | KNN Loss: 4.33203649520874 | CLS Loss: 0.08816956728696823\n",
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 4.366316795349121 | KNN Loss: 4.251708030700684 | CLS Loss: 0.11460857838392258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 4.310531139373779 | KNN Loss: 4.249791622161865 | CLS Loss: 0.06073939800262451\n",
      "Epoch: 007, Loss: 4.3683, Train: 0.9783, Valid: 0.9751, Best: 0.9751\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 4.277074813842773 | KNN Loss: 4.203298568725586 | CLS Loss: 0.07377618551254272\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 4.31929874420166 | KNN Loss: 4.248308181762695 | CLS Loss: 0.07099057734012604\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 4.40557861328125 | KNN Loss: 4.308181285858154 | CLS Loss: 0.09739750623703003\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 4.342289924621582 | KNN Loss: 4.222406387329102 | CLS Loss: 0.11988357454538345\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 4.311273097991943 | KNN Loss: 4.241094589233398 | CLS Loss: 0.07017853856086731\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 4.384051322937012 | KNN Loss: 4.28169059753418 | CLS Loss: 0.10236073285341263\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 4.357473850250244 | KNN Loss: 4.279686450958252 | CLS Loss: 0.07778739929199219\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 4.335943698883057 | KNN Loss: 4.258141994476318 | CLS Loss: 0.0778018906712532\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 4.389273166656494 | KNN Loss: 4.301309108734131 | CLS Loss: 0.08796412497758865\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 4.369704246520996 | KNN Loss: 4.282916069030762 | CLS Loss: 0.08678832650184631\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 4.356576442718506 | KNN Loss: 4.282532215118408 | CLS Loss: 0.07404439151287079\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 4.3268866539001465 | KNN Loss: 4.256409645080566 | CLS Loss: 0.07047706097364426\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 4.386401653289795 | KNN Loss: 4.255176544189453 | CLS Loss: 0.1312253177165985\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 4.3245086669921875 | KNN Loss: 4.2397613525390625 | CLS Loss: 0.08474720269441605\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 4.374102592468262 | KNN Loss: 4.296687126159668 | CLS Loss: 0.07741531729698181\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 4.3340606689453125 | KNN Loss: 4.246105194091797 | CLS Loss: 0.0879555493593216\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 4.3925347328186035 | KNN Loss: 4.2823076248168945 | CLS Loss: 0.110227070748806\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 4.294737815856934 | KNN Loss: 4.235171794891357 | CLS Loss: 0.059566039592027664\n",
      "Epoch: 008, Loss: 4.3498, Train: 0.9807, Valid: 0.9776, Best: 0.9776\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 4.311003684997559 | KNN Loss: 4.251768112182617 | CLS Loss: 0.0592355951666832\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 4.333959102630615 | KNN Loss: 4.271722793579102 | CLS Loss: 0.06223630532622337\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 4.3092474937438965 | KNN Loss: 4.218405246734619 | CLS Loss: 0.09084231406450272\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 4.312718391418457 | KNN Loss: 4.252183437347412 | CLS Loss: 0.06053488329052925\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 4.3666181564331055 | KNN Loss: 4.281317710876465 | CLS Loss: 0.08530032634735107\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 4.347099304199219 | KNN Loss: 4.2528252601623535 | CLS Loss: 0.09427385032176971\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 4.416123867034912 | KNN Loss: 4.288578987121582 | CLS Loss: 0.12754492461681366\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 4.3213348388671875 | KNN Loss: 4.267243385314941 | CLS Loss: 0.054091550409793854\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 4.276268482208252 | KNN Loss: 4.241774082183838 | CLS Loss: 0.03449424356222153\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 4.327019214630127 | KNN Loss: 4.266530990600586 | CLS Loss: 0.060488346964120865\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 4.376027584075928 | KNN Loss: 4.298384666442871 | CLS Loss: 0.07764274626970291\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 4.415575981140137 | KNN Loss: 4.264496326446533 | CLS Loss: 0.15107986330986023\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 4.344814777374268 | KNN Loss: 4.254151821136475 | CLS Loss: 0.09066294133663177\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 4.365498065948486 | KNN Loss: 4.275001049041748 | CLS Loss: 0.0904969647526741\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 4.365352630615234 | KNN Loss: 4.275557518005371 | CLS Loss: 0.08979503810405731\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 4.331993579864502 | KNN Loss: 4.250126361846924 | CLS Loss: 0.08186732232570648\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 4.353581428527832 | KNN Loss: 4.249344348907471 | CLS Loss: 0.10423697531223297\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 4.308157920837402 | KNN Loss: 4.261821269989014 | CLS Loss: 0.046336524188518524\n",
      "Epoch: 009, Loss: 4.3400, Train: 0.9813, Valid: 0.9768, Best: 0.9776\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 4.284303665161133 | KNN Loss: 4.242923259735107 | CLS Loss: 0.04138048365712166\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 4.319874286651611 | KNN Loss: 4.2682342529296875 | CLS Loss: 0.05164021626114845\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 4.294203281402588 | KNN Loss: 4.242664813995361 | CLS Loss: 0.051538385450839996\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 4.345341682434082 | KNN Loss: 4.275518894195557 | CLS Loss: 0.06982254981994629\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 4.375880718231201 | KNN Loss: 4.246825695037842 | CLS Loss: 0.12905508279800415\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 4.303836822509766 | KNN Loss: 4.2523064613342285 | CLS Loss: 0.051530513912439346\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 4.3880510330200195 | KNN Loss: 4.246886253356934 | CLS Loss: 0.14116500318050385\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 4.327816009521484 | KNN Loss: 4.254071235656738 | CLS Loss: 0.07374455034732819\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 4.3387322425842285 | KNN Loss: 4.242752552032471 | CLS Loss: 0.09597980976104736\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 4.300419330596924 | KNN Loss: 4.2353081703186035 | CLS Loss: 0.06511100381612778\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 4.325949192047119 | KNN Loss: 4.25996208190918 | CLS Loss: 0.065987229347229\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 4.286390781402588 | KNN Loss: 4.23747444152832 | CLS Loss: 0.048916298896074295\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 4.303496837615967 | KNN Loss: 4.237241744995117 | CLS Loss: 0.06625500321388245\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 4.313688278198242 | KNN Loss: 4.243006706237793 | CLS Loss: 0.07068139314651489\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 4.313968658447266 | KNN Loss: 4.254425525665283 | CLS Loss: 0.05954302102327347\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 4.282809257507324 | KNN Loss: 4.240658760070801 | CLS Loss: 0.04215048998594284\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 4.364563465118408 | KNN Loss: 4.275115966796875 | CLS Loss: 0.08944768458604813\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 4.347898960113525 | KNN Loss: 4.266775608062744 | CLS Loss: 0.08112320303916931\n",
      "Epoch: 010, Loss: 4.3273, Train: 0.9784, Valid: 0.9747, Best: 0.9776\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 4.326720714569092 | KNN Loss: 4.247372150421143 | CLS Loss: 0.079348623752594\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 4.34274435043335 | KNN Loss: 4.245232582092285 | CLS Loss: 0.09751176834106445\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 4.338228702545166 | KNN Loss: 4.262054443359375 | CLS Loss: 0.07617426663637161\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 4.372700214385986 | KNN Loss: 4.259392261505127 | CLS Loss: 0.11330807954072952\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 4.295061111450195 | KNN Loss: 4.246380805969238 | CLS Loss: 0.048680439591407776\n",
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 4.322564601898193 | KNN Loss: 4.254627704620361 | CLS Loss: 0.06793666630983353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 4.304662704467773 | KNN Loss: 4.250932216644287 | CLS Loss: 0.05373039469122887\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 4.341189384460449 | KNN Loss: 4.271505832672119 | CLS Loss: 0.06968340277671814\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 4.320568084716797 | KNN Loss: 4.246573448181152 | CLS Loss: 0.07399451732635498\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 4.314630031585693 | KNN Loss: 4.247573375701904 | CLS Loss: 0.06705685704946518\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 4.307745456695557 | KNN Loss: 4.227632522583008 | CLS Loss: 0.08011271804571152\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 4.377388000488281 | KNN Loss: 4.2904052734375 | CLS Loss: 0.08698272705078125\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 4.331469535827637 | KNN Loss: 4.27426815032959 | CLS Loss: 0.05720130726695061\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 4.290808200836182 | KNN Loss: 4.200938701629639 | CLS Loss: 0.08986964821815491\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 4.30148983001709 | KNN Loss: 4.259342670440674 | CLS Loss: 0.04214721918106079\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 4.296808242797852 | KNN Loss: 4.2455244064331055 | CLS Loss: 0.051283951848745346\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 4.3217058181762695 | KNN Loss: 4.26304817199707 | CLS Loss: 0.05865779146552086\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 4.291942119598389 | KNN Loss: 4.242379188537598 | CLS Loss: 0.049562718719244\n",
      "Epoch: 011, Loss: 4.3198, Train: 0.9836, Valid: 0.9801, Best: 0.9801\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 4.333315849304199 | KNN Loss: 4.2712483406066895 | CLS Loss: 0.062067292630672455\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 4.300771236419678 | KNN Loss: 4.25631046295166 | CLS Loss: 0.04446058347821236\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 4.347617149353027 | KNN Loss: 4.232183456420898 | CLS Loss: 0.11543361842632294\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 4.302502632141113 | KNN Loss: 4.259362697601318 | CLS Loss: 0.043139804154634476\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 4.308712482452393 | KNN Loss: 4.23265266418457 | CLS Loss: 0.07605962455272675\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 4.362399578094482 | KNN Loss: 4.267119884490967 | CLS Loss: 0.09527980536222458\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 4.316226482391357 | KNN Loss: 4.269245624542236 | CLS Loss: 0.046980708837509155\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 4.275600910186768 | KNN Loss: 4.221692085266113 | CLS Loss: 0.05390891060233116\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 4.295536994934082 | KNN Loss: 4.2327775955200195 | CLS Loss: 0.06275950372219086\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 4.299810886383057 | KNN Loss: 4.24788761138916 | CLS Loss: 0.05192304402589798\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 4.2964701652526855 | KNN Loss: 4.255619049072266 | CLS Loss: 0.040851157158613205\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 4.306790351867676 | KNN Loss: 4.247520446777344 | CLS Loss: 0.05927001312375069\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 4.3561835289001465 | KNN Loss: 4.263298988342285 | CLS Loss: 0.09288443624973297\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 4.272515296936035 | KNN Loss: 4.193233489990234 | CLS Loss: 0.07928203046321869\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 4.346685886383057 | KNN Loss: 4.254687309265137 | CLS Loss: 0.09199845790863037\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 4.327144145965576 | KNN Loss: 4.248575687408447 | CLS Loss: 0.07856866717338562\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 4.28691291809082 | KNN Loss: 4.246322154998779 | CLS Loss: 0.04059096425771713\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 4.280723571777344 | KNN Loss: 4.2304606437683105 | CLS Loss: 0.0502629391849041\n",
      "Epoch: 012, Loss: 4.3075, Train: 0.9835, Valid: 0.9800, Best: 0.9801\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 4.287143230438232 | KNN Loss: 4.2429704666137695 | CLS Loss: 0.04417288675904274\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 4.318778991699219 | KNN Loss: 4.253535747528076 | CLS Loss: 0.06524302810430527\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 4.2571797370910645 | KNN Loss: 4.208815574645996 | CLS Loss: 0.04836399480700493\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 4.318114757537842 | KNN Loss: 4.237313270568848 | CLS Loss: 0.08080137521028519\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 4.306617259979248 | KNN Loss: 4.255190372467041 | CLS Loss: 0.05142689123749733\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 4.325312614440918 | KNN Loss: 4.241485595703125 | CLS Loss: 0.08382708579301834\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 4.314737319946289 | KNN Loss: 4.263371467590332 | CLS Loss: 0.051365990191698074\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 4.348291397094727 | KNN Loss: 4.2487473487854 | CLS Loss: 0.09954408556222916\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 4.369467735290527 | KNN Loss: 4.2703962326049805 | CLS Loss: 0.09907130897045135\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 4.306753635406494 | KNN Loss: 4.224469184875488 | CLS Loss: 0.08228462934494019\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 4.270948886871338 | KNN Loss: 4.247762203216553 | CLS Loss: 0.023186827078461647\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 4.32084846496582 | KNN Loss: 4.221211910247803 | CLS Loss: 0.09963662922382355\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 4.327007293701172 | KNN Loss: 4.223399639129639 | CLS Loss: 0.10360749810934067\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 4.305768966674805 | KNN Loss: 4.259313583374023 | CLS Loss: 0.04645546153187752\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 4.295657157897949 | KNN Loss: 4.201991558074951 | CLS Loss: 0.09366566687822342\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 4.276646614074707 | KNN Loss: 4.229412078857422 | CLS Loss: 0.047234728932380676\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 4.314171314239502 | KNN Loss: 4.252207279205322 | CLS Loss: 0.061963897198438644\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 4.276025772094727 | KNN Loss: 4.199026107788086 | CLS Loss: 0.07699944823980331\n",
      "Epoch: 013, Loss: 4.3053, Train: 0.9841, Valid: 0.9801, Best: 0.9801\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 4.305225372314453 | KNN Loss: 4.254064559936523 | CLS Loss: 0.05116089805960655\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 4.3335347175598145 | KNN Loss: 4.254332542419434 | CLS Loss: 0.07920203357934952\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 4.300693035125732 | KNN Loss: 4.239318370819092 | CLS Loss: 0.06137464568018913\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 4.301535129547119 | KNN Loss: 4.252825736999512 | CLS Loss: 0.048709411174058914\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 4.298044204711914 | KNN Loss: 4.246669292449951 | CLS Loss: 0.05137511342763901\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 4.296059608459473 | KNN Loss: 4.254912853240967 | CLS Loss: 0.041146621108055115\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 4.292279243469238 | KNN Loss: 4.234864711761475 | CLS Loss: 0.05741448700428009\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 4.310777187347412 | KNN Loss: 4.2231364250183105 | CLS Loss: 0.08764073252677917\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 4.314065456390381 | KNN Loss: 4.237899303436279 | CLS Loss: 0.07616632431745529\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 4.276959419250488 | KNN Loss: 4.233017921447754 | CLS Loss: 0.04394160211086273\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 4.262765884399414 | KNN Loss: 4.231427192687988 | CLS Loss: 0.031338565051555634\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 4.267741680145264 | KNN Loss: 4.245471000671387 | CLS Loss: 0.02227083407342434\n",
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 4.278167724609375 | KNN Loss: 4.237876892089844 | CLS Loss: 0.0402909517288208\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 4.299015522003174 | KNN Loss: 4.261236190795898 | CLS Loss: 0.03777945041656494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 4.30272912979126 | KNN Loss: 4.275683879852295 | CLS Loss: 0.027045099064707756\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 4.2770795822143555 | KNN Loss: 4.199060916900635 | CLS Loss: 0.07801886647939682\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 4.277829647064209 | KNN Loss: 4.22072172164917 | CLS Loss: 0.057107966393232346\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 4.290104389190674 | KNN Loss: 4.221899509429932 | CLS Loss: 0.06820482760667801\n",
      "Epoch: 014, Loss: 4.2912, Train: 0.9864, Valid: 0.9821, Best: 0.9821\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 4.274198055267334 | KNN Loss: 4.247531414031982 | CLS Loss: 0.026666713878512383\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 4.339036464691162 | KNN Loss: 4.263019561767578 | CLS Loss: 0.07601696252822876\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 4.276369571685791 | KNN Loss: 4.238150596618652 | CLS Loss: 0.038218822330236435\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 4.3070197105407715 | KNN Loss: 4.277245998382568 | CLS Loss: 0.029773876070976257\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 4.2316508293151855 | KNN Loss: 4.215925216674805 | CLS Loss: 0.015725627541542053\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 4.248851299285889 | KNN Loss: 4.198570728302002 | CLS Loss: 0.05028035119175911\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 4.253203868865967 | KNN Loss: 4.208137035369873 | CLS Loss: 0.04506690055131912\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 4.278779029846191 | KNN Loss: 4.209921836853027 | CLS Loss: 0.06885696947574615\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 4.27007532119751 | KNN Loss: 4.212102890014648 | CLS Loss: 0.05797259509563446\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 4.266281604766846 | KNN Loss: 4.192942142486572 | CLS Loss: 0.0733395665884018\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 4.336292743682861 | KNN Loss: 4.270726680755615 | CLS Loss: 0.06556587666273117\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 4.2750468254089355 | KNN Loss: 4.2264556884765625 | CLS Loss: 0.04859131574630737\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 4.327681064605713 | KNN Loss: 4.235762119293213 | CLS Loss: 0.09191873669624329\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 4.4233317375183105 | KNN Loss: 4.335535526275635 | CLS Loss: 0.08779630064964294\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 4.310153961181641 | KNN Loss: 4.254374980926514 | CLS Loss: 0.05577905476093292\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 4.290719985961914 | KNN Loss: 4.244722843170166 | CLS Loss: 0.04599737003445625\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 4.28035831451416 | KNN Loss: 4.237220764160156 | CLS Loss: 0.043137624859809875\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 4.264299392700195 | KNN Loss: 4.2264275550842285 | CLS Loss: 0.037872012704610825\n",
      "Epoch: 015, Loss: 4.2907, Train: 0.9862, Valid: 0.9821, Best: 0.9821\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 4.261938571929932 | KNN Loss: 4.198884010314941 | CLS Loss: 0.06305479258298874\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 4.241744041442871 | KNN Loss: 4.200092792510986 | CLS Loss: 0.04165143147110939\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 4.241454124450684 | KNN Loss: 4.184703826904297 | CLS Loss: 0.05675049126148224\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 4.280897617340088 | KNN Loss: 4.230919361114502 | CLS Loss: 0.049978189170360565\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 4.276447296142578 | KNN Loss: 4.228350639343262 | CLS Loss: 0.04809682071208954\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 4.286086082458496 | KNN Loss: 4.233914375305176 | CLS Loss: 0.05217151343822479\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 4.31500768661499 | KNN Loss: 4.243852615356445 | CLS Loss: 0.07115519046783447\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 4.349764823913574 | KNN Loss: 4.284903049468994 | CLS Loss: 0.06486182659864426\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 4.327719211578369 | KNN Loss: 4.234745025634766 | CLS Loss: 0.09297428280115128\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 4.250429153442383 | KNN Loss: 4.215277671813965 | CLS Loss: 0.03515142947435379\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 4.265319347381592 | KNN Loss: 4.203119277954102 | CLS Loss: 0.06219997629523277\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 4.367536544799805 | KNN Loss: 4.2921977043151855 | CLS Loss: 0.0753389224410057\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 4.288210868835449 | KNN Loss: 4.232959747314453 | CLS Loss: 0.0552513562142849\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 4.274726390838623 | KNN Loss: 4.239390850067139 | CLS Loss: 0.03533540293574333\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 4.316886901855469 | KNN Loss: 4.248169898986816 | CLS Loss: 0.06871677190065384\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 4.253297328948975 | KNN Loss: 4.218131065368652 | CLS Loss: 0.03516615554690361\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 4.2394232749938965 | KNN Loss: 4.2139973640441895 | CLS Loss: 0.025425713509321213\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 4.316304683685303 | KNN Loss: 4.258384704589844 | CLS Loss: 0.05792006105184555\n",
      "Epoch: 016, Loss: 4.2822, Train: 0.9878, Valid: 0.9831, Best: 0.9831\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 4.276673793792725 | KNN Loss: 4.238060474395752 | CLS Loss: 0.03861343488097191\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 4.300407886505127 | KNN Loss: 4.223570346832275 | CLS Loss: 0.07683775573968887\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 4.281848430633545 | KNN Loss: 4.231114864349365 | CLS Loss: 0.05073346570134163\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 4.311302661895752 | KNN Loss: 4.227317810058594 | CLS Loss: 0.08398488163948059\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 4.251880645751953 | KNN Loss: 4.213430881500244 | CLS Loss: 0.0384499691426754\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 4.286481857299805 | KNN Loss: 4.233911037445068 | CLS Loss: 0.052570659667253494\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 4.252690315246582 | KNN Loss: 4.224353313446045 | CLS Loss: 0.0283367820084095\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 4.292093753814697 | KNN Loss: 4.233161926269531 | CLS Loss: 0.05893167853355408\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 4.281916618347168 | KNN Loss: 4.230037689208984 | CLS Loss: 0.05187908560037613\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 4.279826641082764 | KNN Loss: 4.235952854156494 | CLS Loss: 0.043873757123947144\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 4.236300945281982 | KNN Loss: 4.199580192565918 | CLS Loss: 0.03672054782509804\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 4.254542827606201 | KNN Loss: 4.196095943450928 | CLS Loss: 0.058446746319532394\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 4.286788463592529 | KNN Loss: 4.22146463394165 | CLS Loss: 0.06532391160726547\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 4.289473056793213 | KNN Loss: 4.231907367706299 | CLS Loss: 0.057565778493881226\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 4.260624408721924 | KNN Loss: 4.195471286773682 | CLS Loss: 0.06515312194824219\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 4.236067771911621 | KNN Loss: 4.195040225982666 | CLS Loss: 0.04102746769785881\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 4.251677513122559 | KNN Loss: 4.215760231018066 | CLS Loss: 0.035917364060878754\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 4.283155918121338 | KNN Loss: 4.23769474029541 | CLS Loss: 0.045461270958185196\n",
      "Epoch: 017, Loss: 4.2755, Train: 0.9873, Valid: 0.9827, Best: 0.9831\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 4.299240589141846 | KNN Loss: 4.214163780212402 | CLS Loss: 0.08507683128118515\n",
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 4.282053470611572 | KNN Loss: 4.2422308921813965 | CLS Loss: 0.039822522550821304\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 4.272047519683838 | KNN Loss: 4.229465484619141 | CLS Loss: 0.04258213937282562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 4.300478458404541 | KNN Loss: 4.260936260223389 | CLS Loss: 0.03954201936721802\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 4.229725360870361 | KNN Loss: 4.186895370483398 | CLS Loss: 0.04282982274889946\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 4.31614351272583 | KNN Loss: 4.250302314758301 | CLS Loss: 0.06584139913320541\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 4.270289421081543 | KNN Loss: 4.2217583656311035 | CLS Loss: 0.04853105917572975\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 4.284079074859619 | KNN Loss: 4.241131782531738 | CLS Loss: 0.042947061359882355\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 4.313508033752441 | KNN Loss: 4.248310089111328 | CLS Loss: 0.06519799679517746\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 4.228884696960449 | KNN Loss: 4.191882133483887 | CLS Loss: 0.03700267896056175\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 4.2878546714782715 | KNN Loss: 4.227721214294434 | CLS Loss: 0.0601334385573864\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 4.275990962982178 | KNN Loss: 4.230684757232666 | CLS Loss: 0.045306380838155746\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 4.247855186462402 | KNN Loss: 4.206966876983643 | CLS Loss: 0.040888138115406036\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 4.275296211242676 | KNN Loss: 4.239689350128174 | CLS Loss: 0.03560684621334076\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 4.307961463928223 | KNN Loss: 4.256913185119629 | CLS Loss: 0.05104817450046539\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 4.295242786407471 | KNN Loss: 4.238590240478516 | CLS Loss: 0.05665278062224388\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 4.282105922698975 | KNN Loss: 4.220745086669922 | CLS Loss: 0.06136099621653557\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 4.262877464294434 | KNN Loss: 4.200016498565674 | CLS Loss: 0.06286095082759857\n",
      "Epoch: 018, Loss: 4.2710, Train: 0.9860, Valid: 0.9800, Best: 0.9831\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 4.255110263824463 | KNN Loss: 4.228693008422852 | CLS Loss: 0.026417311280965805\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 4.2612128257751465 | KNN Loss: 4.221155166625977 | CLS Loss: 0.04005756229162216\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 4.225743293762207 | KNN Loss: 4.186176776885986 | CLS Loss: 0.03956657275557518\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 4.268346309661865 | KNN Loss: 4.21113395690918 | CLS Loss: 0.057212140411138535\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 4.254316806793213 | KNN Loss: 4.194565773010254 | CLS Loss: 0.05975082516670227\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 4.258113384246826 | KNN Loss: 4.22055196762085 | CLS Loss: 0.03756130114197731\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 4.292077541351318 | KNN Loss: 4.216521739959717 | CLS Loss: 0.0755559578537941\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 4.28553581237793 | KNN Loss: 4.219974994659424 | CLS Loss: 0.06556059420108795\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 4.244348526000977 | KNN Loss: 4.203763961791992 | CLS Loss: 0.040584664791822433\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 4.234307765960693 | KNN Loss: 4.194136619567871 | CLS Loss: 0.040171071887016296\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 4.2658514976501465 | KNN Loss: 4.2242231369018555 | CLS Loss: 0.041628338396549225\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 4.2750349044799805 | KNN Loss: 4.245258331298828 | CLS Loss: 0.02977653779089451\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 4.239983558654785 | KNN Loss: 4.19501256942749 | CLS Loss: 0.04497120901942253\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 4.2469072341918945 | KNN Loss: 4.215463638305664 | CLS Loss: 0.03144364804029465\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 4.268245697021484 | KNN Loss: 4.207159042358398 | CLS Loss: 0.061086755245923996\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 4.237905502319336 | KNN Loss: 4.19456148147583 | CLS Loss: 0.04334399849176407\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 4.290033340454102 | KNN Loss: 4.239835262298584 | CLS Loss: 0.0501982644200325\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 4.283017635345459 | KNN Loss: 4.22041654586792 | CLS Loss: 0.06260115653276443\n",
      "Epoch: 019, Loss: 4.2606, Train: 0.9866, Valid: 0.9823, Best: 0.9831\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 4.264398097991943 | KNN Loss: 4.196169853210449 | CLS Loss: 0.0682283267378807\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 4.26140832901001 | KNN Loss: 4.191339492797852 | CLS Loss: 0.0700688436627388\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 4.315601348876953 | KNN Loss: 4.249368667602539 | CLS Loss: 0.0662325993180275\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 4.241291046142578 | KNN Loss: 4.200498580932617 | CLS Loss: 0.04079263657331467\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 4.233309745788574 | KNN Loss: 4.185309410095215 | CLS Loss: 0.04800046235322952\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 4.218205451965332 | KNN Loss: 4.172706604003906 | CLS Loss: 0.04549890011548996\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 4.262904644012451 | KNN Loss: 4.223309516906738 | CLS Loss: 0.03959519788622856\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 4.225302219390869 | KNN Loss: 4.207856178283691 | CLS Loss: 0.01744607836008072\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 4.258817195892334 | KNN Loss: 4.218954563140869 | CLS Loss: 0.03986278921365738\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 4.283994197845459 | KNN Loss: 4.222585201263428 | CLS Loss: 0.061409104615449905\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 4.22291898727417 | KNN Loss: 4.184706687927246 | CLS Loss: 0.03821229189634323\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 4.2194318771362305 | KNN Loss: 4.2059006690979 | CLS Loss: 0.013531233184039593\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 4.255224704742432 | KNN Loss: 4.191181182861328 | CLS Loss: 0.064043328166008\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 4.247721195220947 | KNN Loss: 4.224203586578369 | CLS Loss: 0.023517467081546783\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 4.243388652801514 | KNN Loss: 4.214087009429932 | CLS Loss: 0.029301438480615616\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 4.2620849609375 | KNN Loss: 4.218428611755371 | CLS Loss: 0.04365633800625801\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 4.279603481292725 | KNN Loss: 4.230100154876709 | CLS Loss: 0.04950321838259697\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 4.2665696144104 | KNN Loss: 4.220705032348633 | CLS Loss: 0.045864712446928024\n",
      "Epoch: 020, Loss: 4.2579, Train: 0.9888, Valid: 0.9837, Best: 0.9837\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 4.282561302185059 | KNN Loss: 4.216083526611328 | CLS Loss: 0.06647767871618271\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 4.252080917358398 | KNN Loss: 4.204895496368408 | CLS Loss: 0.0471852570772171\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 4.262913227081299 | KNN Loss: 4.210625648498535 | CLS Loss: 0.05228766053915024\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 4.240136623382568 | KNN Loss: 4.2110443115234375 | CLS Loss: 0.029092075303196907\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 4.245991230010986 | KNN Loss: 4.226739406585693 | CLS Loss: 0.01925164833664894\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 4.258514881134033 | KNN Loss: 4.214909553527832 | CLS Loss: 0.043605294078588486\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 4.247994422912598 | KNN Loss: 4.213252544403076 | CLS Loss: 0.03474174812436104\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 4.291901588439941 | KNN Loss: 4.219470024108887 | CLS Loss: 0.07243148982524872\n",
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 4.2845282554626465 | KNN Loss: 4.230785846710205 | CLS Loss: 0.0537424273788929\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 4.2487406730651855 | KNN Loss: 4.2173357009887695 | CLS Loss: 0.03140484169125557\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 4.24400520324707 | KNN Loss: 4.199164867401123 | CLS Loss: 0.04484039545059204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 4.242568492889404 | KNN Loss: 4.19084358215332 | CLS Loss: 0.05172489210963249\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 4.26951789855957 | KNN Loss: 4.204338073730469 | CLS Loss: 0.06517962366342545\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 4.252274513244629 | KNN Loss: 4.210559368133545 | CLS Loss: 0.041715025901794434\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 4.244344234466553 | KNN Loss: 4.211349010467529 | CLS Loss: 0.03299541398882866\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 4.223918914794922 | KNN Loss: 4.208064556121826 | CLS Loss: 0.01585458032786846\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 4.237831115722656 | KNN Loss: 4.218386650085449 | CLS Loss: 0.019444482401013374\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 4.250600337982178 | KNN Loss: 4.207740783691406 | CLS Loss: 0.04285946115851402\n",
      "Epoch: 021, Loss: 4.2551, Train: 0.9901, Valid: 0.9843, Best: 0.9843\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 4.26363468170166 | KNN Loss: 4.21523904800415 | CLS Loss: 0.0483957901597023\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 4.238028049468994 | KNN Loss: 4.2043280601501465 | CLS Loss: 0.033700212836265564\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 4.2621989250183105 | KNN Loss: 4.2276387214660645 | CLS Loss: 0.034560348838567734\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 4.233824729919434 | KNN Loss: 4.206545829772949 | CLS Loss: 0.027279125526547432\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 4.247460842132568 | KNN Loss: 4.221658706665039 | CLS Loss: 0.025802219286561012\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 4.238104343414307 | KNN Loss: 4.212119102478027 | CLS Loss: 0.025985194370150566\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 4.219166278839111 | KNN Loss: 4.194698810577393 | CLS Loss: 0.02446727454662323\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 4.264344692230225 | KNN Loss: 4.203697204589844 | CLS Loss: 0.06064740568399429\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 4.309886932373047 | KNN Loss: 4.244949817657471 | CLS Loss: 0.06493702530860901\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 4.280764102935791 | KNN Loss: 4.206567287445068 | CLS Loss: 0.07419688999652863\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 4.2218098640441895 | KNN Loss: 4.190967082977295 | CLS Loss: 0.030842557549476624\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 4.240954875946045 | KNN Loss: 4.192777156829834 | CLS Loss: 0.048177570104599\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 4.2377214431762695 | KNN Loss: 4.22178316116333 | CLS Loss: 0.015938397496938705\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 4.263994216918945 | KNN Loss: 4.2143754959106445 | CLS Loss: 0.049618590623140335\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 4.21458101272583 | KNN Loss: 4.201375961303711 | CLS Loss: 0.013205217197537422\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 4.254439830780029 | KNN Loss: 4.229713439941406 | CLS Loss: 0.02472654916346073\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 4.248920440673828 | KNN Loss: 4.2090959548950195 | CLS Loss: 0.039824534207582474\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 4.256414413452148 | KNN Loss: 4.220263957977295 | CLS Loss: 0.03615051135420799\n",
      "Epoch: 022, Loss: 4.2507, Train: 0.9893, Valid: 0.9840, Best: 0.9843\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 4.225429058074951 | KNN Loss: 4.205722332000732 | CLS Loss: 0.019706634804606438\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 4.241482257843018 | KNN Loss: 4.211812973022461 | CLS Loss: 0.02966950833797455\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 4.2223591804504395 | KNN Loss: 4.205831050872803 | CLS Loss: 0.016528047621250153\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 4.245630264282227 | KNN Loss: 4.209422588348389 | CLS Loss: 0.03620745986700058\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 4.237456798553467 | KNN Loss: 4.206690311431885 | CLS Loss: 0.030766675248742104\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 4.232883453369141 | KNN Loss: 4.213161945343018 | CLS Loss: 0.019721465185284615\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 4.293240070343018 | KNN Loss: 4.262021541595459 | CLS Loss: 0.031218502670526505\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 4.182837963104248 | KNN Loss: 4.162750244140625 | CLS Loss: 0.02008768916130066\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 4.27237606048584 | KNN Loss: 4.220275402069092 | CLS Loss: 0.052100587636232376\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 4.2944560050964355 | KNN Loss: 4.226013660430908 | CLS Loss: 0.06844212859869003\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 4.280012607574463 | KNN Loss: 4.24685001373291 | CLS Loss: 0.03316261246800423\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 4.222733497619629 | KNN Loss: 4.212090015411377 | CLS Loss: 0.010643656365573406\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 4.234246730804443 | KNN Loss: 4.200653553009033 | CLS Loss: 0.03359328210353851\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 4.240029811859131 | KNN Loss: 4.223904609680176 | CLS Loss: 0.016125230118632317\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 4.298585891723633 | KNN Loss: 4.25570011138916 | CLS Loss: 0.04288579523563385\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 4.243435382843018 | KNN Loss: 4.218135833740234 | CLS Loss: 0.02529965341091156\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 4.304502964019775 | KNN Loss: 4.20878267288208 | CLS Loss: 0.09572019428014755\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 4.23245906829834 | KNN Loss: 4.177985191345215 | CLS Loss: 0.05447401478886604\n",
      "Epoch: 023, Loss: 4.2466, Train: 0.9902, Valid: 0.9841, Best: 0.9843\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 4.224496841430664 | KNN Loss: 4.198901176452637 | CLS Loss: 0.02559582330286503\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 4.248991966247559 | KNN Loss: 4.223862648010254 | CLS Loss: 0.025129524990916252\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 4.241505146026611 | KNN Loss: 4.212324142456055 | CLS Loss: 0.029181096702814102\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 4.218474864959717 | KNN Loss: 4.204560279846191 | CLS Loss: 0.013914738781750202\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 4.212886333465576 | KNN Loss: 4.166659355163574 | CLS Loss: 0.04622684046626091\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 4.235716819763184 | KNN Loss: 4.2147674560546875 | CLS Loss: 0.0209493450820446\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 4.277256011962891 | KNN Loss: 4.247523784637451 | CLS Loss: 0.029732365161180496\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 4.250813007354736 | KNN Loss: 4.225243091583252 | CLS Loss: 0.025569895282387733\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 4.244571208953857 | KNN Loss: 4.214493274688721 | CLS Loss: 0.030077798292040825\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 4.242938041687012 | KNN Loss: 4.197516918182373 | CLS Loss: 0.04542119801044464\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 4.236166000366211 | KNN Loss: 4.200995445251465 | CLS Loss: 0.03517032787203789\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 4.261486530303955 | KNN Loss: 4.213858604431152 | CLS Loss: 0.047627899795770645\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 4.217586517333984 | KNN Loss: 4.194005489349365 | CLS Loss: 0.023580919951200485\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 4.218927383422852 | KNN Loss: 4.184655666351318 | CLS Loss: 0.03427153825759888\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 4.266479969024658 | KNN Loss: 4.234225749969482 | CLS Loss: 0.032254237681627274\n",
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 4.214378833770752 | KNN Loss: 4.1884284019470215 | CLS Loss: 0.025950338691473007\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 4.246735572814941 | KNN Loss: 4.203944683074951 | CLS Loss: 0.042790696024894714\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 4.226083278656006 | KNN Loss: 4.2110466957092285 | CLS Loss: 0.015036782249808311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Loss: 4.2406, Train: 0.9907, Valid: 0.9845, Best: 0.9845\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 4.207675933837891 | KNN Loss: 4.183061122894287 | CLS Loss: 0.024614786729216576\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 4.246267795562744 | KNN Loss: 4.224581718444824 | CLS Loss: 0.021685931831598282\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 4.279109477996826 | KNN Loss: 4.247529983520508 | CLS Loss: 0.03157961741089821\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 4.267364501953125 | KNN Loss: 4.233802318572998 | CLS Loss: 0.03356197103857994\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 4.251857280731201 | KNN Loss: 4.219854831695557 | CLS Loss: 0.03200257942080498\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 4.244296073913574 | KNN Loss: 4.202948093414307 | CLS Loss: 0.041347846388816833\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 4.264890193939209 | KNN Loss: 4.198514938354492 | CLS Loss: 0.06637528538703918\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 4.237987518310547 | KNN Loss: 4.210434913635254 | CLS Loss: 0.027552781626582146\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 4.293338298797607 | KNN Loss: 4.234116077423096 | CLS Loss: 0.05922209098935127\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 4.263910293579102 | KNN Loss: 4.21621561050415 | CLS Loss: 0.04769464209675789\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 4.2671918869018555 | KNN Loss: 4.246379852294922 | CLS Loss: 0.020812062546610832\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 4.229402542114258 | KNN Loss: 4.190834045410156 | CLS Loss: 0.038568396121263504\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 4.217265605926514 | KNN Loss: 4.198070049285889 | CLS Loss: 0.0191954392939806\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 4.206869602203369 | KNN Loss: 4.170062065124512 | CLS Loss: 0.03680753335356712\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 4.204840183258057 | KNN Loss: 4.176608562469482 | CLS Loss: 0.02823171578347683\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 4.244999408721924 | KNN Loss: 4.2344865798950195 | CLS Loss: 0.010512820445001125\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 4.305217742919922 | KNN Loss: 4.236262798309326 | CLS Loss: 0.0689549595117569\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 4.284779071807861 | KNN Loss: 4.2311601638793945 | CLS Loss: 0.05361903831362724\n",
      "Epoch: 025, Loss: 4.2414, Train: 0.9913, Valid: 0.9854, Best: 0.9854\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 4.2237372398376465 | KNN Loss: 4.199480056762695 | CLS Loss: 0.024257194250822067\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 4.249383926391602 | KNN Loss: 4.199251174926758 | CLS Loss: 0.05013285577297211\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 4.209959030151367 | KNN Loss: 4.184283256530762 | CLS Loss: 0.02567579224705696\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 4.246071815490723 | KNN Loss: 4.18885612487793 | CLS Loss: 0.057215817272663116\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 4.200114727020264 | KNN Loss: 4.171320915222168 | CLS Loss: 0.02879391610622406\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 4.244124889373779 | KNN Loss: 4.210236549377441 | CLS Loss: 0.03388817235827446\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 4.242410659790039 | KNN Loss: 4.216406345367432 | CLS Loss: 0.026004329323768616\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 4.231773853302002 | KNN Loss: 4.172779083251953 | CLS Loss: 0.05899471789598465\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 4.245260715484619 | KNN Loss: 4.187856197357178 | CLS Loss: 0.05740462243556976\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 4.1900482177734375 | KNN Loss: 4.159599304199219 | CLS Loss: 0.03044898435473442\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 4.22724723815918 | KNN Loss: 4.1944260597229 | CLS Loss: 0.03282126411795616\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 4.270864009857178 | KNN Loss: 4.219779014587402 | CLS Loss: 0.051085054874420166\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 4.25728702545166 | KNN Loss: 4.212704181671143 | CLS Loss: 0.044582631438970566\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 4.2800750732421875 | KNN Loss: 4.259171485900879 | CLS Loss: 0.020903512835502625\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 4.242274761199951 | KNN Loss: 4.211249351501465 | CLS Loss: 0.031025312840938568\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 4.2385663986206055 | KNN Loss: 4.211668014526367 | CLS Loss: 0.026898546144366264\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 4.220128059387207 | KNN Loss: 4.186482906341553 | CLS Loss: 0.03364504128694534\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 4.2302565574646 | KNN Loss: 4.190888404846191 | CLS Loss: 0.03936810791492462\n",
      "Epoch: 026, Loss: 4.2408, Train: 0.9903, Valid: 0.9836, Best: 0.9854\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 4.243315696716309 | KNN Loss: 4.220664978027344 | CLS Loss: 0.02265053242444992\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 4.219631195068359 | KNN Loss: 4.177741050720215 | CLS Loss: 0.04189002513885498\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 4.29232931137085 | KNN Loss: 4.246301651000977 | CLS Loss: 0.04602759703993797\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 4.267711162567139 | KNN Loss: 4.231900215148926 | CLS Loss: 0.035811156034469604\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 4.223302841186523 | KNN Loss: 4.191433906555176 | CLS Loss: 0.03186871483922005\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 4.2177934646606445 | KNN Loss: 4.189296722412109 | CLS Loss: 0.028496939688920975\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 4.2401957511901855 | KNN Loss: 4.2094221115112305 | CLS Loss: 0.030773799866437912\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 4.254327297210693 | KNN Loss: 4.227235317230225 | CLS Loss: 0.027092067524790764\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 4.257734298706055 | KNN Loss: 4.217812538146973 | CLS Loss: 0.039921704679727554\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 4.2464399337768555 | KNN Loss: 4.221536636352539 | CLS Loss: 0.024903444573283195\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 4.24393367767334 | KNN Loss: 4.222192287445068 | CLS Loss: 0.021741164848208427\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 4.216709136962891 | KNN Loss: 4.1726765632629395 | CLS Loss: 0.044032447040081024\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 4.2566704750061035 | KNN Loss: 4.2004241943359375 | CLS Loss: 0.05624638497829437\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 4.208313465118408 | KNN Loss: 4.196155071258545 | CLS Loss: 0.012158545665442944\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 4.215405464172363 | KNN Loss: 4.195765495300293 | CLS Loss: 0.019639991223812103\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 4.21016263961792 | KNN Loss: 4.194016933441162 | CLS Loss: 0.01614547148346901\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 4.254595756530762 | KNN Loss: 4.21661376953125 | CLS Loss: 0.03798210248351097\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 4.225044250488281 | KNN Loss: 4.208972454071045 | CLS Loss: 0.016071638092398643\n",
      "Epoch: 027, Loss: 4.2345, Train: 0.9903, Valid: 0.9848, Best: 0.9854\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 4.241350173950195 | KNN Loss: 4.209170341491699 | CLS Loss: 0.032179780304431915\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 4.195211887359619 | KNN Loss: 4.183465003967285 | CLS Loss: 0.011746860109269619\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 4.232937335968018 | KNN Loss: 4.199764728546143 | CLS Loss: 0.033172547817230225\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 4.2298150062561035 | KNN Loss: 4.1775922775268555 | CLS Loss: 0.05222267284989357\n",
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 4.222453594207764 | KNN Loss: 4.188598155975342 | CLS Loss: 0.03385539352893829\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 4.198068618774414 | KNN Loss: 4.176914691925049 | CLS Loss: 0.021154021844267845\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 4.214816570281982 | KNN Loss: 4.190162181854248 | CLS Loss: 0.024654319509863853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 4.2436323165893555 | KNN Loss: 4.2053399085998535 | CLS Loss: 0.03829244151711464\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 4.230072498321533 | KNN Loss: 4.197988986968994 | CLS Loss: 0.03208357095718384\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 4.234865665435791 | KNN Loss: 4.207112789154053 | CLS Loss: 0.02775268629193306\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 4.284020900726318 | KNN Loss: 4.208919525146484 | CLS Loss: 0.0751013234257698\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 4.203401565551758 | KNN Loss: 4.1948933601379395 | CLS Loss: 0.008508346974849701\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 4.279885292053223 | KNN Loss: 4.220667362213135 | CLS Loss: 0.05921813100576401\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 4.213982582092285 | KNN Loss: 4.182875633239746 | CLS Loss: 0.031106863170862198\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 4.274678707122803 | KNN Loss: 4.227445125579834 | CLS Loss: 0.047233760356903076\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 4.208677291870117 | KNN Loss: 4.182529926300049 | CLS Loss: 0.026147302240133286\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 4.260059833526611 | KNN Loss: 4.205142498016357 | CLS Loss: 0.05491745471954346\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 4.21222448348999 | KNN Loss: 4.163828372955322 | CLS Loss: 0.04839621111750603\n",
      "Epoch: 028, Loss: 4.2325, Train: 0.9915, Valid: 0.9852, Best: 0.9854\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 4.228460311889648 | KNN Loss: 4.179934024810791 | CLS Loss: 0.048526253551244736\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 4.2255859375 | KNN Loss: 4.179223537445068 | CLS Loss: 0.046362556517124176\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 4.189938068389893 | KNN Loss: 4.168251037597656 | CLS Loss: 0.02168719843029976\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 4.208189487457275 | KNN Loss: 4.198647975921631 | CLS Loss: 0.009541523642838001\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 4.2453694343566895 | KNN Loss: 4.218326568603516 | CLS Loss: 0.027042802423238754\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 4.211178779602051 | KNN Loss: 4.189082622528076 | CLS Loss: 0.02209634706377983\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 4.21149206161499 | KNN Loss: 4.187443733215332 | CLS Loss: 0.024048270657658577\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 4.1938018798828125 | KNN Loss: 4.1795196533203125 | CLS Loss: 0.014282319694757462\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 4.269479751586914 | KNN Loss: 4.231413841247559 | CLS Loss: 0.03806599974632263\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 4.215422630310059 | KNN Loss: 4.190418720245361 | CLS Loss: 0.025003889575600624\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 4.227081298828125 | KNN Loss: 4.205003261566162 | CLS Loss: 0.022078271955251694\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 4.2189249992370605 | KNN Loss: 4.187506198883057 | CLS Loss: 0.0314185693860054\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 4.207641124725342 | KNN Loss: 4.195699691772461 | CLS Loss: 0.011941308155655861\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 4.245633125305176 | KNN Loss: 4.203089237213135 | CLS Loss: 0.04254389554262161\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 4.201501369476318 | KNN Loss: 4.188706398010254 | CLS Loss: 0.012794747948646545\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 4.194442272186279 | KNN Loss: 4.166172504425049 | CLS Loss: 0.028269819915294647\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 4.26163387298584 | KNN Loss: 4.222728729248047 | CLS Loss: 0.03890491649508476\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 4.234468460083008 | KNN Loss: 4.201882362365723 | CLS Loss: 0.03258586674928665\n",
      "Epoch: 029, Loss: 4.2314, Train: 0.9906, Valid: 0.9849, Best: 0.9854\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 4.218545436859131 | KNN Loss: 4.196953773498535 | CLS Loss: 0.021591797471046448\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 4.208219051361084 | KNN Loss: 4.17555046081543 | CLS Loss: 0.03266877308487892\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 4.239309310913086 | KNN Loss: 4.207054615020752 | CLS Loss: 0.03225461021065712\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 4.193971633911133 | KNN Loss: 4.162802696228027 | CLS Loss: 0.031168783083558083\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 4.215887069702148 | KNN Loss: 4.179595947265625 | CLS Loss: 0.036291033029556274\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 4.228527545928955 | KNN Loss: 4.215514659881592 | CLS Loss: 0.013012787327170372\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 4.217362880706787 | KNN Loss: 4.168591022491455 | CLS Loss: 0.048771996051073074\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 4.2038116455078125 | KNN Loss: 4.164287090301514 | CLS Loss: 0.0395243801176548\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 4.225387096405029 | KNN Loss: 4.186980724334717 | CLS Loss: 0.03840633109211922\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 4.268812656402588 | KNN Loss: 4.230160236358643 | CLS Loss: 0.03865261748433113\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 4.207691669464111 | KNN Loss: 4.177730560302734 | CLS Loss: 0.029961325228214264\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 4.212769031524658 | KNN Loss: 4.195322036743164 | CLS Loss: 0.01744699664413929\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 4.197849273681641 | KNN Loss: 4.167163372039795 | CLS Loss: 0.03068597801029682\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 4.215353965759277 | KNN Loss: 4.200031757354736 | CLS Loss: 0.015322349034249783\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 4.220218181610107 | KNN Loss: 4.184662818908691 | CLS Loss: 0.03555537760257721\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 4.195065975189209 | KNN Loss: 4.155018329620361 | CLS Loss: 0.04004758223891258\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 4.209155559539795 | KNN Loss: 4.171545028686523 | CLS Loss: 0.037610672414302826\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 4.210373878479004 | KNN Loss: 4.1894755363464355 | CLS Loss: 0.020898373797535896\n",
      "Epoch: 030, Loss: 4.2208, Train: 0.9924, Valid: 0.9853, Best: 0.9854\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 4.259559631347656 | KNN Loss: 4.200908660888672 | CLS Loss: 0.05865076184272766\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 4.195594787597656 | KNN Loss: 4.186947345733643 | CLS Loss: 0.00864757876843214\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 4.166682243347168 | KNN Loss: 4.154289245605469 | CLS Loss: 0.012393025681376457\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 4.19606351852417 | KNN Loss: 4.177100658416748 | CLS Loss: 0.01896289922297001\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 4.234002113342285 | KNN Loss: 4.18347692489624 | CLS Loss: 0.05052537843585014\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 4.239284515380859 | KNN Loss: 4.191178798675537 | CLS Loss: 0.048105813562870026\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 4.2145490646362305 | KNN Loss: 4.1832051277160645 | CLS Loss: 0.03134411573410034\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 4.2424468994140625 | KNN Loss: 4.2246928215026855 | CLS Loss: 0.017754141241312027\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 4.238956451416016 | KNN Loss: 4.209726810455322 | CLS Loss: 0.02922956645488739\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 4.212356090545654 | KNN Loss: 4.199211120605469 | CLS Loss: 0.013145101256668568\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 4.175990581512451 | KNN Loss: 4.1609416007995605 | CLS Loss: 0.015049021691083908\n",
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 4.2060723304748535 | KNN Loss: 4.181670188903809 | CLS Loss: 0.02440210059285164\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 4.194844722747803 | KNN Loss: 4.177313804626465 | CLS Loss: 0.017530813813209534\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 4.194544315338135 | KNN Loss: 4.171716690063477 | CLS Loss: 0.022827602922916412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 4.243635177612305 | KNN Loss: 4.2295145988464355 | CLS Loss: 0.01412065140902996\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 4.250445365905762 | KNN Loss: 4.179553985595703 | CLS Loss: 0.0708916187286377\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 4.22918176651001 | KNN Loss: 4.187734127044678 | CLS Loss: 0.04144773259758949\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 4.221603870391846 | KNN Loss: 4.197984218597412 | CLS Loss: 0.023619798943400383\n",
      "Epoch: 031, Loss: 4.2214, Train: 0.9924, Valid: 0.9854, Best: 0.9854\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 4.279277801513672 | KNN Loss: 4.232723236083984 | CLS Loss: 0.046554360538721085\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 4.216104507446289 | KNN Loss: 4.1956634521484375 | CLS Loss: 0.02044091187417507\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 4.202889919281006 | KNN Loss: 4.1732988357543945 | CLS Loss: 0.029590968042612076\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 4.249967575073242 | KNN Loss: 4.212971210479736 | CLS Loss: 0.03699633851647377\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 4.19138765335083 | KNN Loss: 4.1721391677856445 | CLS Loss: 0.019248610362410545\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 4.182888031005859 | KNN Loss: 4.170245170593262 | CLS Loss: 0.012642745859920979\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 4.196641445159912 | KNN Loss: 4.179912090301514 | CLS Loss: 0.0167295653373003\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 4.214561462402344 | KNN Loss: 4.184105396270752 | CLS Loss: 0.0304560624063015\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 4.220438003540039 | KNN Loss: 4.189229488372803 | CLS Loss: 0.031208738684654236\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 4.222602844238281 | KNN Loss: 4.205143928527832 | CLS Loss: 0.017458908259868622\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 4.240377426147461 | KNN Loss: 4.201411247253418 | CLS Loss: 0.03896611928939819\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 4.231118679046631 | KNN Loss: 4.204967021942139 | CLS Loss: 0.026151763275265694\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 4.213812828063965 | KNN Loss: 4.196209907531738 | CLS Loss: 0.017603041604161263\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 4.256380081176758 | KNN Loss: 4.236844062805176 | CLS Loss: 0.019536202773451805\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 4.228821277618408 | KNN Loss: 4.206532955169678 | CLS Loss: 0.02228839322924614\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 4.257809638977051 | KNN Loss: 4.213223934173584 | CLS Loss: 0.04458564147353172\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 4.214405536651611 | KNN Loss: 4.182590961456299 | CLS Loss: 0.031814541667699814\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 4.245768070220947 | KNN Loss: 4.218050479888916 | CLS Loss: 0.02771751768887043\n",
      "Epoch: 032, Loss: 4.2211, Train: 0.9891, Valid: 0.9823, Best: 0.9854\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 4.20149564743042 | KNN Loss: 4.188134670257568 | CLS Loss: 0.013360769487917423\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 4.217787265777588 | KNN Loss: 4.176818370819092 | CLS Loss: 0.040969062596559525\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 4.20524263381958 | KNN Loss: 4.175887584686279 | CLS Loss: 0.029355036094784737\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 4.202444553375244 | KNN Loss: 4.164117336273193 | CLS Loss: 0.03832726180553436\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 4.206229209899902 | KNN Loss: 4.173544406890869 | CLS Loss: 0.03268458694219589\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 4.203685283660889 | KNN Loss: 4.169680595397949 | CLS Loss: 0.03400483354926109\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 4.231832504272461 | KNN Loss: 4.1893157958984375 | CLS Loss: 0.04251673445105553\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 4.216833591461182 | KNN Loss: 4.199520587921143 | CLS Loss: 0.01731298491358757\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 4.298383712768555 | KNN Loss: 4.23044490814209 | CLS Loss: 0.06793856620788574\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 4.21727180480957 | KNN Loss: 4.167850494384766 | CLS Loss: 0.04942111670970917\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 4.234102249145508 | KNN Loss: 4.207562446594238 | CLS Loss: 0.026539750397205353\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 4.264962673187256 | KNN Loss: 4.214600086212158 | CLS Loss: 0.05036237835884094\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 4.217982292175293 | KNN Loss: 4.199769973754883 | CLS Loss: 0.01821225695312023\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 4.179871559143066 | KNN Loss: 4.155340194702148 | CLS Loss: 0.024531129747629166\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 4.223017692565918 | KNN Loss: 4.2086687088012695 | CLS Loss: 0.014349061995744705\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 4.223447322845459 | KNN Loss: 4.162204742431641 | CLS Loss: 0.061242539435625076\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 4.21073055267334 | KNN Loss: 4.189791202545166 | CLS Loss: 0.020939350128173828\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 4.2204203605651855 | KNN Loss: 4.1884236335754395 | CLS Loss: 0.03199685737490654\n",
      "Epoch: 033, Loss: 4.2226, Train: 0.9927, Valid: 0.9858, Best: 0.9858\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 4.227759838104248 | KNN Loss: 4.221616744995117 | CLS Loss: 0.006143221165984869\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 4.228026390075684 | KNN Loss: 4.183427810668945 | CLS Loss: 0.044598598033189774\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 4.200754165649414 | KNN Loss: 4.167840480804443 | CLS Loss: 0.032913561910390854\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 4.238884925842285 | KNN Loss: 4.208106994628906 | CLS Loss: 0.030778080224990845\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 4.250917434692383 | KNN Loss: 4.212064743041992 | CLS Loss: 0.03885258361697197\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 4.263339519500732 | KNN Loss: 4.210039138793945 | CLS Loss: 0.053300585597753525\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 4.2160444259643555 | KNN Loss: 4.188493251800537 | CLS Loss: 0.027551209554076195\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 4.228070259094238 | KNN Loss: 4.210431098937988 | CLS Loss: 0.017638953402638435\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 4.19211483001709 | KNN Loss: 4.1599345207214355 | CLS Loss: 0.032180532813072205\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 4.268519878387451 | KNN Loss: 4.213946342468262 | CLS Loss: 0.0545734241604805\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 4.225214958190918 | KNN Loss: 4.15791130065918 | CLS Loss: 0.06730350852012634\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 4.2084550857543945 | KNN Loss: 4.185826301574707 | CLS Loss: 0.022628678008913994\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 4.21036958694458 | KNN Loss: 4.183884620666504 | CLS Loss: 0.02648504264652729\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 4.2074151039123535 | KNN Loss: 4.187851428985596 | CLS Loss: 0.019563736394047737\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 4.221588134765625 | KNN Loss: 4.195227146148682 | CLS Loss: 0.026360882446169853\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 4.232076644897461 | KNN Loss: 4.208430767059326 | CLS Loss: 0.023645645007491112\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 4.251437664031982 | KNN Loss: 4.227802753448486 | CLS Loss: 0.0236351378262043\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 4.214811325073242 | KNN Loss: 4.19640588760376 | CLS Loss: 0.01840519905090332\n",
      "Epoch: 034, Loss: 4.2231, Train: 0.9928, Valid: 0.9860, Best: 0.9860\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 4.268966197967529 | KNN Loss: 4.2158308029174805 | CLS Loss: 0.053135521709918976\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 4.313774108886719 | KNN Loss: 4.257004737854004 | CLS Loss: 0.056769244372844696\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 4.220889568328857 | KNN Loss: 4.183457851409912 | CLS Loss: 0.037431903183460236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 4.223684310913086 | KNN Loss: 4.208004474639893 | CLS Loss: 0.015679875388741493\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 4.1940083503723145 | KNN Loss: 4.175229549407959 | CLS Loss: 0.018778743222355843\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 4.2106170654296875 | KNN Loss: 4.187617778778076 | CLS Loss: 0.022999344393610954\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 4.218364238739014 | KNN Loss: 4.182963848114014 | CLS Loss: 0.0354003831744194\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 4.194406986236572 | KNN Loss: 4.168439865112305 | CLS Loss: 0.025967281311750412\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 4.277900218963623 | KNN Loss: 4.234869480133057 | CLS Loss: 0.04303088039159775\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 4.208922863006592 | KNN Loss: 4.195460796356201 | CLS Loss: 0.013462303206324577\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 4.239328384399414 | KNN Loss: 4.209620952606201 | CLS Loss: 0.029707282781600952\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 4.202705383300781 | KNN Loss: 4.178379535675049 | CLS Loss: 0.02432594820857048\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 4.275991439819336 | KNN Loss: 4.2541117668151855 | CLS Loss: 0.021879874169826508\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 4.242476463317871 | KNN Loss: 4.19730806350708 | CLS Loss: 0.04516821354627609\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 4.200331211090088 | KNN Loss: 4.172837734222412 | CLS Loss: 0.027493244037032127\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 4.233816623687744 | KNN Loss: 4.185647487640381 | CLS Loss: 0.04816891998052597\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 4.250768661499023 | KNN Loss: 4.217321395874023 | CLS Loss: 0.033447105437517166\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 4.223115921020508 | KNN Loss: 4.204308986663818 | CLS Loss: 0.018806790933012962\n",
      "Epoch: 035, Loss: 4.2363, Train: 0.9918, Valid: 0.9851, Best: 0.9860\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 4.270948886871338 | KNN Loss: 4.234485149383545 | CLS Loss: 0.036463771015405655\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 4.226230144500732 | KNN Loss: 4.206080436706543 | CLS Loss: 0.020149623975157738\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 4.255595684051514 | KNN Loss: 4.232728958129883 | CLS Loss: 0.02286692149937153\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 4.236919403076172 | KNN Loss: 4.203047275543213 | CLS Loss: 0.03387223184108734\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 4.283088207244873 | KNN Loss: 4.252564907073975 | CLS Loss: 0.030523253604769707\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 4.264194011688232 | KNN Loss: 4.212921142578125 | CLS Loss: 0.05127294734120369\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 4.236915588378906 | KNN Loss: 4.222531795501709 | CLS Loss: 0.014383859001100063\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 4.22376823425293 | KNN Loss: 4.18998908996582 | CLS Loss: 0.033779338002204895\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 4.277470111846924 | KNN Loss: 4.2606096267700195 | CLS Loss: 0.016860531643033028\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 4.234355449676514 | KNN Loss: 4.217248439788818 | CLS Loss: 0.017106814309954643\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 4.25463342666626 | KNN Loss: 4.242549419403076 | CLS Loss: 0.012084152549505234\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 4.270273685455322 | KNN Loss: 4.232734203338623 | CLS Loss: 0.037539251148700714\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 4.183304786682129 | KNN Loss: 4.154879570007324 | CLS Loss: 0.02842540293931961\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 4.226150035858154 | KNN Loss: 4.2013325691223145 | CLS Loss: 0.024817589670419693\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 4.2120184898376465 | KNN Loss: 4.190174102783203 | CLS Loss: 0.021844200789928436\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 4.234813690185547 | KNN Loss: 4.229188442230225 | CLS Loss: 0.0056252204813063145\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 4.217493057250977 | KNN Loss: 4.18796968460083 | CLS Loss: 0.029523320496082306\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 4.221793174743652 | KNN Loss: 4.180239677429199 | CLS Loss: 0.04155341535806656\n",
      "Epoch: 036, Loss: 4.2321, Train: 0.9926, Valid: 0.9861, Best: 0.9861\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 4.213284969329834 | KNN Loss: 4.190762519836426 | CLS Loss: 0.02252241037786007\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 4.209907054901123 | KNN Loss: 4.176758766174316 | CLS Loss: 0.03314836695790291\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 4.233612060546875 | KNN Loss: 4.194241523742676 | CLS Loss: 0.03937055915594101\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 4.223320484161377 | KNN Loss: 4.197206497192383 | CLS Loss: 0.026114191859960556\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 4.21807336807251 | KNN Loss: 4.176521301269531 | CLS Loss: 0.041552167385816574\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 4.249131679534912 | KNN Loss: 4.231781482696533 | CLS Loss: 0.01735028252005577\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 4.268265724182129 | KNN Loss: 4.245574474334717 | CLS Loss: 0.022691166028380394\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 4.2304816246032715 | KNN Loss: 4.187576770782471 | CLS Loss: 0.042904943227767944\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 4.264204502105713 | KNN Loss: 4.218634128570557 | CLS Loss: 0.04557047039270401\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 4.224334716796875 | KNN Loss: 4.196927070617676 | CLS Loss: 0.027407752349972725\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 4.289355754852295 | KNN Loss: 4.232734203338623 | CLS Loss: 0.05662170425057411\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 4.214915752410889 | KNN Loss: 4.194515228271484 | CLS Loss: 0.020400602370500565\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 4.212084770202637 | KNN Loss: 4.177839279174805 | CLS Loss: 0.03424554690718651\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 4.2140326499938965 | KNN Loss: 4.1962714195251465 | CLS Loss: 0.017761152237653732\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 4.224306106567383 | KNN Loss: 4.168944835662842 | CLS Loss: 0.05536149442195892\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 4.275346755981445 | KNN Loss: 4.239215850830078 | CLS Loss: 0.03613085299730301\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 4.210931777954102 | KNN Loss: 4.17904806137085 | CLS Loss: 0.031883712857961655\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 4.220278739929199 | KNN Loss: 4.201518535614014 | CLS Loss: 0.018760258331894875\n",
      "Epoch: 037, Loss: 4.2225, Train: 0.9932, Valid: 0.9854, Best: 0.9861\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 4.242093563079834 | KNN Loss: 4.217773914337158 | CLS Loss: 0.024319753050804138\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 4.192922592163086 | KNN Loss: 4.168537139892578 | CLS Loss: 0.024385614320635796\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 4.2348408699035645 | KNN Loss: 4.1994733810424805 | CLS Loss: 0.03536766394972801\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 4.251128196716309 | KNN Loss: 4.198737621307373 | CLS Loss: 0.05239043012261391\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 4.219976425170898 | KNN Loss: 4.205502510070801 | CLS Loss: 0.014473817311227322\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 4.22802209854126 | KNN Loss: 4.218861103057861 | CLS Loss: 0.009160803630948067\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 4.231265068054199 | KNN Loss: 4.199680805206299 | CLS Loss: 0.03158431872725487\n",
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 4.248819351196289 | KNN Loss: 4.220113277435303 | CLS Loss: 0.0287062618881464\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 4.22890567779541 | KNN Loss: 4.210209369659424 | CLS Loss: 0.01869651861488819\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 4.262963771820068 | KNN Loss: 4.218461990356445 | CLS Loss: 0.04450177028775215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 4.246324062347412 | KNN Loss: 4.219326019287109 | CLS Loss: 0.026997875422239304\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 4.198949813842773 | KNN Loss: 4.184017658233643 | CLS Loss: 0.014931933023035526\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 4.225663661956787 | KNN Loss: 4.193836212158203 | CLS Loss: 0.031827352941036224\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 4.20611047744751 | KNN Loss: 4.194192886352539 | CLS Loss: 0.01191764697432518\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 4.259815216064453 | KNN Loss: 4.221579074859619 | CLS Loss: 0.03823606297373772\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 4.221337795257568 | KNN Loss: 4.190531253814697 | CLS Loss: 0.03080640733242035\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 4.226406097412109 | KNN Loss: 4.202661991119385 | CLS Loss: 0.023743966594338417\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 4.256950378417969 | KNN Loss: 4.2392401695251465 | CLS Loss: 0.017710285261273384\n",
      "Epoch: 038, Loss: 4.2247, Train: 0.9936, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 4.238755226135254 | KNN Loss: 4.186317443847656 | CLS Loss: 0.052437927573919296\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 4.210507392883301 | KNN Loss: 4.1806440353393555 | CLS Loss: 0.029863297939300537\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 4.224991321563721 | KNN Loss: 4.1829447746276855 | CLS Loss: 0.04204640910029411\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 4.197319030761719 | KNN Loss: 4.188992500305176 | CLS Loss: 0.008326663635671139\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 4.256365776062012 | KNN Loss: 4.241360187530518 | CLS Loss: 0.015005582012236118\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 4.213697910308838 | KNN Loss: 4.1960039138793945 | CLS Loss: 0.01769392192363739\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 4.210077285766602 | KNN Loss: 4.182721138000488 | CLS Loss: 0.027356183156371117\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 4.253408432006836 | KNN Loss: 4.2065749168396 | CLS Loss: 0.046833328902721405\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 4.18289041519165 | KNN Loss: 4.168039321899414 | CLS Loss: 0.014851017855107784\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 4.201836109161377 | KNN Loss: 4.177954196929932 | CLS Loss: 0.02388187125325203\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 4.247099876403809 | KNN Loss: 4.222369194030762 | CLS Loss: 0.02473083883523941\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 4.23855447769165 | KNN Loss: 4.208370208740234 | CLS Loss: 0.030184395611286163\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 4.232840061187744 | KNN Loss: 4.215382099151611 | CLS Loss: 0.01745793968439102\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 4.242137908935547 | KNN Loss: 4.206649303436279 | CLS Loss: 0.035488445311784744\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 4.247096061706543 | KNN Loss: 4.194089412689209 | CLS Loss: 0.053006675094366074\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 4.205179214477539 | KNN Loss: 4.192689895629883 | CLS Loss: 0.012489302083849907\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 4.22340726852417 | KNN Loss: 4.1995720863342285 | CLS Loss: 0.02383529581129551\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 4.225578308105469 | KNN Loss: 4.200642108917236 | CLS Loss: 0.024936232715845108\n",
      "Epoch: 039, Loss: 4.2302, Train: 0.9933, Valid: 0.9860, Best: 0.9866\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 4.2244954109191895 | KNN Loss: 4.194321632385254 | CLS Loss: 0.03017379157245159\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 4.243697166442871 | KNN Loss: 4.227006912231445 | CLS Loss: 0.016690416261553764\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 4.23285436630249 | KNN Loss: 4.175861358642578 | CLS Loss: 0.05699288845062256\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 4.250513076782227 | KNN Loss: 4.218561172485352 | CLS Loss: 0.031952064484357834\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 4.219606399536133 | KNN Loss: 4.197984218597412 | CLS Loss: 0.021622370928525925\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 4.186829566955566 | KNN Loss: 4.169642448425293 | CLS Loss: 0.01718691922724247\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 4.213962078094482 | KNN Loss: 4.189242839813232 | CLS Loss: 0.024719320237636566\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 4.248053073883057 | KNN Loss: 4.2104597091674805 | CLS Loss: 0.0375933013856411\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 4.22231912612915 | KNN Loss: 4.190463066101074 | CLS Loss: 0.03185621649026871\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 4.250176906585693 | KNN Loss: 4.196500778198242 | CLS Loss: 0.053676024079322815\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 4.155498504638672 | KNN Loss: 4.149198532104492 | CLS Loss: 0.0062998076900839806\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 4.188114643096924 | KNN Loss: 4.179814338684082 | CLS Loss: 0.008300144225358963\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 4.248083591461182 | KNN Loss: 4.223315238952637 | CLS Loss: 0.02476837858557701\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 4.240222454071045 | KNN Loss: 4.173706531524658 | CLS Loss: 0.06651614606380463\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 4.210036754608154 | KNN Loss: 4.194655895233154 | CLS Loss: 0.01538075227290392\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 4.213318824768066 | KNN Loss: 4.200338363647461 | CLS Loss: 0.012980474159121513\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 4.200775146484375 | KNN Loss: 4.192844867706299 | CLS Loss: 0.007930325344204903\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 4.196145534515381 | KNN Loss: 4.180962562561035 | CLS Loss: 0.015182794071733952\n",
      "Epoch: 040, Loss: 4.2169, Train: 0.9928, Valid: 0.9854, Best: 0.9866\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 4.200985908508301 | KNN Loss: 4.191455364227295 | CLS Loss: 0.009530339390039444\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 4.253439903259277 | KNN Loss: 4.2181715965271 | CLS Loss: 0.03526811674237251\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 4.201481819152832 | KNN Loss: 4.171969890594482 | CLS Loss: 0.029511919245123863\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 4.182188034057617 | KNN Loss: 4.174124717712402 | CLS Loss: 0.008063094690442085\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 4.211480617523193 | KNN Loss: 4.186575412750244 | CLS Loss: 0.024905428290367126\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 4.264908790588379 | KNN Loss: 4.2206711769104 | CLS Loss: 0.04423748329281807\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 4.251957893371582 | KNN Loss: 4.222018241882324 | CLS Loss: 0.029939623549580574\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 4.194458484649658 | KNN Loss: 4.1731038093566895 | CLS Loss: 0.021354876458644867\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 4.259962558746338 | KNN Loss: 4.227798938751221 | CLS Loss: 0.032163526862859726\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 4.219488620758057 | KNN Loss: 4.188485145568848 | CLS Loss: 0.031003601849079132\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 4.192567825317383 | KNN Loss: 4.184676647186279 | CLS Loss: 0.007891234941780567\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 4.206348419189453 | KNN Loss: 4.191944122314453 | CLS Loss: 0.01440421398729086\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 4.229572296142578 | KNN Loss: 4.218780994415283 | CLS Loss: 0.010791433043777943\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 4.216599464416504 | KNN Loss: 4.19693660736084 | CLS Loss: 0.01966271921992302\n",
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 4.186849594116211 | KNN Loss: 4.164445877075195 | CLS Loss: 0.02240373194217682\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 4.208166599273682 | KNN Loss: 4.177216053009033 | CLS Loss: 0.030950557440519333\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 4.225836277008057 | KNN Loss: 4.2153778076171875 | CLS Loss: 0.0104586873203516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 4.2383131980896 | KNN Loss: 4.208118438720703 | CLS Loss: 0.030194832012057304\n",
      "Epoch: 041, Loss: 4.2181, Train: 0.9940, Valid: 0.9863, Best: 0.9866\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 4.219261646270752 | KNN Loss: 4.211283206939697 | CLS Loss: 0.007978660054504871\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 4.20481014251709 | KNN Loss: 4.200500011444092 | CLS Loss: 0.004310272168368101\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 4.217003345489502 | KNN Loss: 4.188265800476074 | CLS Loss: 0.028737446293234825\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 4.198896408081055 | KNN Loss: 4.182306289672852 | CLS Loss: 0.016590293496847153\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 4.225890636444092 | KNN Loss: 4.198854446411133 | CLS Loss: 0.027036169543862343\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 4.241453647613525 | KNN Loss: 4.208463668823242 | CLS Loss: 0.03299001604318619\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 4.228715419769287 | KNN Loss: 4.205084323883057 | CLS Loss: 0.023630915209650993\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 4.216965198516846 | KNN Loss: 4.202038288116455 | CLS Loss: 0.014926719479262829\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 4.226895332336426 | KNN Loss: 4.206131935119629 | CLS Loss: 0.020763160660862923\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 4.207304000854492 | KNN Loss: 4.197865962982178 | CLS Loss: 0.009437955915927887\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 4.181887149810791 | KNN Loss: 4.160001277923584 | CLS Loss: 0.021885864436626434\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 4.2545905113220215 | KNN Loss: 4.219748497009277 | CLS Loss: 0.03484193608164787\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 4.2228851318359375 | KNN Loss: 4.194380283355713 | CLS Loss: 0.028504634276032448\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 4.2434492111206055 | KNN Loss: 4.200212001800537 | CLS Loss: 0.043237000703811646\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 4.195584774017334 | KNN Loss: 4.172107696533203 | CLS Loss: 0.02347724698483944\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 4.204496383666992 | KNN Loss: 4.180890083312988 | CLS Loss: 0.023606279864907265\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 4.1900715827941895 | KNN Loss: 4.174272537231445 | CLS Loss: 0.015799278393387794\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 4.233290672302246 | KNN Loss: 4.1921467781066895 | CLS Loss: 0.04114401340484619\n",
      "Epoch: 042, Loss: 4.2242, Train: 0.9938, Valid: 0.9858, Best: 0.9866\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 4.220352649688721 | KNN Loss: 4.193437576293945 | CLS Loss: 0.02691519260406494\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 4.2017130851745605 | KNN Loss: 4.176826477050781 | CLS Loss: 0.0248867254704237\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 4.252951145172119 | KNN Loss: 4.197403430938721 | CLS Loss: 0.05554759129881859\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 4.188842296600342 | KNN Loss: 4.176894187927246 | CLS Loss: 0.011947892606258392\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 4.187206268310547 | KNN Loss: 4.170523643493652 | CLS Loss: 0.016682811081409454\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 4.224752426147461 | KNN Loss: 4.2073974609375 | CLS Loss: 0.0173550583422184\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 4.211635589599609 | KNN Loss: 4.17559289932251 | CLS Loss: 0.03604258596897125\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 4.212854862213135 | KNN Loss: 4.195584774017334 | CLS Loss: 0.017270099371671677\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 4.18223237991333 | KNN Loss: 4.160242557525635 | CLS Loss: 0.02198999933898449\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 4.218253135681152 | KNN Loss: 4.206408500671387 | CLS Loss: 0.011844629421830177\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 4.207736968994141 | KNN Loss: 4.170038223266602 | CLS Loss: 0.0376986488699913\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 4.174313068389893 | KNN Loss: 4.164514541625977 | CLS Loss: 0.009798608720302582\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 4.229349613189697 | KNN Loss: 4.224903583526611 | CLS Loss: 0.004445810802280903\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 4.23259973526001 | KNN Loss: 4.20529842376709 | CLS Loss: 0.027301300317049026\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 4.197196006774902 | KNN Loss: 4.187988758087158 | CLS Loss: 0.009207150898873806\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 4.176760673522949 | KNN Loss: 4.170515060424805 | CLS Loss: 0.006245654541999102\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 4.19437837600708 | KNN Loss: 4.187318325042725 | CLS Loss: 0.0070601110346615314\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 4.191983222961426 | KNN Loss: 4.16314697265625 | CLS Loss: 0.028836017474532127\n",
      "Epoch: 043, Loss: 4.2193, Train: 0.9942, Valid: 0.9857, Best: 0.9866\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 4.202454090118408 | KNN Loss: 4.181721210479736 | CLS Loss: 0.020732855424284935\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 4.160355091094971 | KNN Loss: 4.1519036293029785 | CLS Loss: 0.00845160149037838\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 4.1740403175354 | KNN Loss: 4.165558338165283 | CLS Loss: 0.00848178006708622\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 4.203347682952881 | KNN Loss: 4.185874938964844 | CLS Loss: 0.01747274398803711\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 4.193264484405518 | KNN Loss: 4.186610221862793 | CLS Loss: 0.0066544050350785255\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 4.235352039337158 | KNN Loss: 4.210716247558594 | CLS Loss: 0.02463558129966259\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 4.2217607498168945 | KNN Loss: 4.180044174194336 | CLS Loss: 0.04171677306294441\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 4.215535640716553 | KNN Loss: 4.204823017120361 | CLS Loss: 0.010712845250964165\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 4.205613613128662 | KNN Loss: 4.187925815582275 | CLS Loss: 0.01768779195845127\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 4.259138584136963 | KNN Loss: 4.219130516052246 | CLS Loss: 0.0400080531835556\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 4.2905144691467285 | KNN Loss: 4.277820110321045 | CLS Loss: 0.012694183737039566\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 4.214311122894287 | KNN Loss: 4.1928887367248535 | CLS Loss: 0.021422279998660088\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 4.244341850280762 | KNN Loss: 4.221149444580078 | CLS Loss: 0.023192180320620537\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 4.217735290527344 | KNN Loss: 4.206732273101807 | CLS Loss: 0.01100300345569849\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 4.1954121589660645 | KNN Loss: 4.169270992279053 | CLS Loss: 0.02614131011068821\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 4.222461700439453 | KNN Loss: 4.20343542098999 | CLS Loss: 0.019026335328817368\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 4.1812944412231445 | KNN Loss: 4.176788330078125 | CLS Loss: 0.004506166558712721\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 4.200724124908447 | KNN Loss: 4.189693450927734 | CLS Loss: 0.011030558496713638\n",
      "Epoch: 044, Loss: 4.2151, Train: 0.9923, Valid: 0.9832, Best: 0.9866\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 4.24108362197876 | KNN Loss: 4.211195945739746 | CLS Loss: 0.029887445271015167\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 4.206664085388184 | KNN Loss: 4.1811017990112305 | CLS Loss: 0.025562386959791183\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 4.230742931365967 | KNN Loss: 4.201186180114746 | CLS Loss: 0.02955666370689869\n",
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 4.217006683349609 | KNN Loss: 4.1952996253967285 | CLS Loss: 0.021707093343138695\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 4.240418910980225 | KNN Loss: 4.205870628356934 | CLS Loss: 0.034548379480838776\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 4.1929497718811035 | KNN Loss: 4.188098907470703 | CLS Loss: 0.004850998055189848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 4.225077152252197 | KNN Loss: 4.1896491050720215 | CLS Loss: 0.03542814403772354\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 4.214105606079102 | KNN Loss: 4.202685832977295 | CLS Loss: 0.011419560760259628\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 4.1733808517456055 | KNN Loss: 4.158309459686279 | CLS Loss: 0.015071537345647812\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 4.203010559082031 | KNN Loss: 4.181915283203125 | CLS Loss: 0.021095316857099533\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 4.207612037658691 | KNN Loss: 4.16044807434082 | CLS Loss: 0.04716384410858154\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 4.259705543518066 | KNN Loss: 4.214901924133301 | CLS Loss: 0.04480363428592682\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 4.184332370758057 | KNN Loss: 4.16845703125 | CLS Loss: 0.01587517559528351\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 4.227839946746826 | KNN Loss: 4.202188491821289 | CLS Loss: 0.025651533156633377\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 4.185074329376221 | KNN Loss: 4.158129692077637 | CLS Loss: 0.026944588869810104\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 4.190545082092285 | KNN Loss: 4.180526256561279 | CLS Loss: 0.010018968023359776\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 4.174064636230469 | KNN Loss: 4.157198905944824 | CLS Loss: 0.016865642741322517\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 4.210885524749756 | KNN Loss: 4.176383018493652 | CLS Loss: 0.03450272977352142\n",
      "Epoch: 045, Loss: 4.2129, Train: 0.9941, Valid: 0.9861, Best: 0.9866\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 4.198591709136963 | KNN Loss: 4.191805839538574 | CLS Loss: 0.00678565539419651\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 4.202183723449707 | KNN Loss: 4.185183048248291 | CLS Loss: 0.01700054667890072\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 4.201656341552734 | KNN Loss: 4.187806606292725 | CLS Loss: 0.013849889859557152\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 4.222723484039307 | KNN Loss: 4.21696138381958 | CLS Loss: 0.005761907901614904\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 4.215459823608398 | KNN Loss: 4.1913161277771 | CLS Loss: 0.024143556132912636\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 4.182106971740723 | KNN Loss: 4.170276641845703 | CLS Loss: 0.01183051336556673\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 4.225568771362305 | KNN Loss: 4.183621406555176 | CLS Loss: 0.04194742441177368\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 4.232501029968262 | KNN Loss: 4.212149620056152 | CLS Loss: 0.0203514713793993\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 4.17967414855957 | KNN Loss: 4.1686835289001465 | CLS Loss: 0.010990547016263008\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 4.2049150466918945 | KNN Loss: 4.188053131103516 | CLS Loss: 0.01686195842921734\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 4.237927436828613 | KNN Loss: 4.205207347869873 | CLS Loss: 0.03272009640932083\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 4.243720054626465 | KNN Loss: 4.2229719161987305 | CLS Loss: 0.020748374983668327\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 4.226124286651611 | KNN Loss: 4.177177429199219 | CLS Loss: 0.04894701763987541\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 4.221742153167725 | KNN Loss: 4.19488000869751 | CLS Loss: 0.026862192898988724\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 4.210257053375244 | KNN Loss: 4.200915336608887 | CLS Loss: 0.009341550059616566\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 4.206786632537842 | KNN Loss: 4.172357082366943 | CLS Loss: 0.03442947566509247\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 4.202057361602783 | KNN Loss: 4.184760570526123 | CLS Loss: 0.017296867445111275\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 4.213730812072754 | KNN Loss: 4.174402713775635 | CLS Loss: 0.03932826966047287\n",
      "Epoch: 046, Loss: 4.2112, Train: 0.9947, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 4.163883209228516 | KNN Loss: 4.134797096252441 | CLS Loss: 0.029086105525493622\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 4.204691410064697 | KNN Loss: 4.196269989013672 | CLS Loss: 0.008421649225056171\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 4.169710159301758 | KNN Loss: 4.157334327697754 | CLS Loss: 0.012375898659229279\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 4.207871913909912 | KNN Loss: 4.1992506980896 | CLS Loss: 0.00862132292240858\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 4.179137229919434 | KNN Loss: 4.1645402908325195 | CLS Loss: 0.014596748165786266\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 4.187913417816162 | KNN Loss: 4.173782825469971 | CLS Loss: 0.014130516909062862\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 4.154101848602295 | KNN Loss: 4.147006034851074 | CLS Loss: 0.007095667067915201\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 4.19074821472168 | KNN Loss: 4.178926944732666 | CLS Loss: 0.011821117252111435\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 4.193648815155029 | KNN Loss: 4.169755935668945 | CLS Loss: 0.023892998695373535\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 4.1838459968566895 | KNN Loss: 4.172661304473877 | CLS Loss: 0.011184616945683956\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 4.198381423950195 | KNN Loss: 4.174510955810547 | CLS Loss: 0.02387034147977829\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 4.278504848480225 | KNN Loss: 4.252630233764648 | CLS Loss: 0.025874584913253784\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 4.218481540679932 | KNN Loss: 4.189413547515869 | CLS Loss: 0.029067853465676308\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 4.184218406677246 | KNN Loss: 4.168333530426025 | CLS Loss: 0.015885004773736\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 4.2405009269714355 | KNN Loss: 4.225456237792969 | CLS Loss: 0.015044481493532658\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 4.190372467041016 | KNN Loss: 4.18019962310791 | CLS Loss: 0.010172927752137184\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 4.195671558380127 | KNN Loss: 4.180739402770996 | CLS Loss: 0.014931930229067802\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 4.197432994842529 | KNN Loss: 4.169139862060547 | CLS Loss: 0.028293104842305183\n",
      "Epoch: 047, Loss: 4.2049, Train: 0.9946, Valid: 0.9862, Best: 0.9866\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 4.224093437194824 | KNN Loss: 4.205868244171143 | CLS Loss: 0.018225284293293953\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 4.264572620391846 | KNN Loss: 4.215452671051025 | CLS Loss: 0.04911988601088524\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 4.200451374053955 | KNN Loss: 4.184793472290039 | CLS Loss: 0.015657776966691017\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 4.227719783782959 | KNN Loss: 4.206963539123535 | CLS Loss: 0.020756084471940994\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 4.206523895263672 | KNN Loss: 4.184031009674072 | CLS Loss: 0.02249288000166416\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 4.186136245727539 | KNN Loss: 4.178140163421631 | CLS Loss: 0.007995976135134697\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 4.204689025878906 | KNN Loss: 4.183684349060059 | CLS Loss: 0.021004440262913704\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 4.173661708831787 | KNN Loss: 4.142889976501465 | CLS Loss: 0.03077193908393383\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 4.200789451599121 | KNN Loss: 4.194991111755371 | CLS Loss: 0.005798173602670431\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 4.1710615158081055 | KNN Loss: 4.143170356750488 | CLS Loss: 0.027891220524907112\n",
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 4.207253932952881 | KNN Loss: 4.185125350952148 | CLS Loss: 0.022128742188215256\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 4.201847553253174 | KNN Loss: 4.195197105407715 | CLS Loss: 0.006650399416685104\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 4.2278008460998535 | KNN Loss: 4.192557334899902 | CLS Loss: 0.035243336111307144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 4.189859390258789 | KNN Loss: 4.166978359222412 | CLS Loss: 0.022881262004375458\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 4.185413837432861 | KNN Loss: 4.1628737449646 | CLS Loss: 0.022540142759680748\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 4.170398235321045 | KNN Loss: 4.161129951477051 | CLS Loss: 0.0092684431001544\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 4.205132484436035 | KNN Loss: 4.196259021759033 | CLS Loss: 0.008873231709003448\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 4.196340560913086 | KNN Loss: 4.182790756225586 | CLS Loss: 0.013549677096307278\n",
      "Epoch: 048, Loss: 4.2077, Train: 0.9942, Valid: 0.9852, Best: 0.9866\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 4.1939921379089355 | KNN Loss: 4.182600498199463 | CLS Loss: 0.011391740292310715\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 4.217296600341797 | KNN Loss: 4.188128471374512 | CLS Loss: 0.02916790172457695\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 4.193646430969238 | KNN Loss: 4.179772853851318 | CLS Loss: 0.013873688876628876\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 4.171011924743652 | KNN Loss: 4.152377128601074 | CLS Loss: 0.01863475888967514\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 4.1929121017456055 | KNN Loss: 4.179715156555176 | CLS Loss: 0.01319713145494461\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 4.204505443572998 | KNN Loss: 4.186474800109863 | CLS Loss: 0.018030762672424316\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 4.211314678192139 | KNN Loss: 4.195878028869629 | CLS Loss: 0.015436788089573383\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 4.181133270263672 | KNN Loss: 4.175395965576172 | CLS Loss: 0.005737284664064646\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 4.187863826751709 | KNN Loss: 4.176908016204834 | CLS Loss: 0.010955791920423508\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 4.1703996658325195 | KNN Loss: 4.156368732452393 | CLS Loss: 0.01403087005019188\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 4.230154514312744 | KNN Loss: 4.206461429595947 | CLS Loss: 0.02369300089776516\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 4.206637382507324 | KNN Loss: 4.1789960861206055 | CLS Loss: 0.027641328051686287\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 4.189930438995361 | KNN Loss: 4.179382801055908 | CLS Loss: 0.010547636076807976\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 4.231333255767822 | KNN Loss: 4.207545757293701 | CLS Loss: 0.023787721991539\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 4.18277645111084 | KNN Loss: 4.161043167114258 | CLS Loss: 0.021733419969677925\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 4.235466957092285 | KNN Loss: 4.211185932159424 | CLS Loss: 0.024281062185764313\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 4.2046918869018555 | KNN Loss: 4.177398681640625 | CLS Loss: 0.02729320153594017\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 4.231855392456055 | KNN Loss: 4.194480895996094 | CLS Loss: 0.037374719977378845\n",
      "Epoch: 049, Loss: 4.2047, Train: 0.9942, Valid: 0.9867, Best: 0.9867\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 4.196619033813477 | KNN Loss: 4.18585729598999 | CLS Loss: 0.010761511512100697\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 4.213454246520996 | KNN Loss: 4.178756237030029 | CLS Loss: 0.03469821810722351\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 4.217024326324463 | KNN Loss: 4.210661888122559 | CLS Loss: 0.0063626389019191265\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 4.223398208618164 | KNN Loss: 4.17385196685791 | CLS Loss: 0.04954603314399719\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 4.1975417137146 | KNN Loss: 4.189525127410889 | CLS Loss: 0.00801680888980627\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 4.184427738189697 | KNN Loss: 4.177657127380371 | CLS Loss: 0.006770801730453968\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 4.198660850524902 | KNN Loss: 4.180384635925293 | CLS Loss: 0.01827608421444893\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 4.231855392456055 | KNN Loss: 4.194158554077148 | CLS Loss: 0.03769677132368088\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 4.250217914581299 | KNN Loss: 4.2306036949157715 | CLS Loss: 0.019614433869719505\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 4.243480205535889 | KNN Loss: 4.219107151031494 | CLS Loss: 0.0243730116635561\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 4.202046871185303 | KNN Loss: 4.172593593597412 | CLS Loss: 0.029453108087182045\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 4.171889781951904 | KNN Loss: 4.160588264465332 | CLS Loss: 0.011301460675895214\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 4.180535316467285 | KNN Loss: 4.165257930755615 | CLS Loss: 0.015277257189154625\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 4.208583354949951 | KNN Loss: 4.1884050369262695 | CLS Loss: 0.02017819695174694\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 4.199354648590088 | KNN Loss: 4.180679798126221 | CLS Loss: 0.018674703314900398\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 4.163522720336914 | KNN Loss: 4.147541046142578 | CLS Loss: 0.015981459990143776\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 4.208374977111816 | KNN Loss: 4.184695243835449 | CLS Loss: 0.023679619655013084\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 4.234560012817383 | KNN Loss: 4.202713489532471 | CLS Loss: 0.031846728175878525\n",
      "Epoch: 050, Loss: 4.2024, Train: 0.9924, Valid: 0.9854, Best: 0.9867\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 4.199019908905029 | KNN Loss: 4.151477336883545 | CLS Loss: 0.04754254221916199\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 4.218230724334717 | KNN Loss: 4.2058186531066895 | CLS Loss: 0.012412202544510365\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 4.2070393562316895 | KNN Loss: 4.191653728485107 | CLS Loss: 0.015385747887194157\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 4.224429607391357 | KNN Loss: 4.2113213539123535 | CLS Loss: 0.013108289800584316\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 4.1869797706604 | KNN Loss: 4.178150653839111 | CLS Loss: 0.008828893303871155\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 4.253616809844971 | KNN Loss: 4.236894607543945 | CLS Loss: 0.016722146421670914\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 4.198062896728516 | KNN Loss: 4.177772045135498 | CLS Loss: 0.020291071385145187\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 4.184554100036621 | KNN Loss: 4.17203950881958 | CLS Loss: 0.01251472719013691\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 4.182314395904541 | KNN Loss: 4.164721488952637 | CLS Loss: 0.017592785879969597\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 4.226393222808838 | KNN Loss: 4.21732234954834 | CLS Loss: 0.009070849977433681\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 4.205795764923096 | KNN Loss: 4.186753273010254 | CLS Loss: 0.019042517989873886\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 4.184231281280518 | KNN Loss: 4.160373210906982 | CLS Loss: 0.023857930675148964\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 4.194999694824219 | KNN Loss: 4.1763176918029785 | CLS Loss: 0.0186819639056921\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 4.252880096435547 | KNN Loss: 4.212306976318359 | CLS Loss: 0.04057333618402481\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 4.17671537399292 | KNN Loss: 4.1691060066223145 | CLS Loss: 0.007609491236507893\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 4.182720184326172 | KNN Loss: 4.158029079437256 | CLS Loss: 0.024691328406333923\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 4.189098358154297 | KNN Loss: 4.1625165939331055 | CLS Loss: 0.02658185362815857\n",
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 4.184682846069336 | KNN Loss: 4.178899765014648 | CLS Loss: 0.005783258005976677\n",
      "Epoch: 051, Loss: 4.2054, Train: 0.9945, Valid: 0.9866, Best: 0.9867\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 4.229191303253174 | KNN Loss: 4.213734149932861 | CLS Loss: 0.015457370318472385\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 4.166078567504883 | KNN Loss: 4.155720233917236 | CLS Loss: 0.010358160361647606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 4.1702799797058105 | KNN Loss: 4.148709297180176 | CLS Loss: 0.02157084457576275\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 4.214503288269043 | KNN Loss: 4.184453964233398 | CLS Loss: 0.030049467459321022\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 4.189785003662109 | KNN Loss: 4.168893337249756 | CLS Loss: 0.02089146338403225\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 4.182406425476074 | KNN Loss: 4.168633937835693 | CLS Loss: 0.013772501610219479\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 4.188601970672607 | KNN Loss: 4.151299476623535 | CLS Loss: 0.03730225935578346\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 4.210635662078857 | KNN Loss: 4.193665504455566 | CLS Loss: 0.016970157623291016\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 4.154101371765137 | KNN Loss: 4.144765853881836 | CLS Loss: 0.009335282258689404\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 4.1909871101379395 | KNN Loss: 4.183598041534424 | CLS Loss: 0.007389129605144262\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 4.266578674316406 | KNN Loss: 4.2452921867370605 | CLS Loss: 0.021286629140377045\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 4.192327499389648 | KNN Loss: 4.177555561065674 | CLS Loss: 0.01477195043116808\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 4.247663974761963 | KNN Loss: 4.201754570007324 | CLS Loss: 0.045909199863672256\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 4.225126266479492 | KNN Loss: 4.204610824584961 | CLS Loss: 0.020515374839305878\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 4.214691162109375 | KNN Loss: 4.203042984008789 | CLS Loss: 0.011648145504295826\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 4.216461181640625 | KNN Loss: 4.1953630447387695 | CLS Loss: 0.02109827660024166\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 4.205729961395264 | KNN Loss: 4.185728549957275 | CLS Loss: 0.02000146359205246\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 4.26536226272583 | KNN Loss: 4.222139835357666 | CLS Loss: 0.0432225726544857\n",
      "Epoch: 052, Loss: 4.2024, Train: 0.9915, Valid: 0.9821, Best: 0.9867\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 4.177171230316162 | KNN Loss: 4.165677547454834 | CLS Loss: 0.01149385143071413\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 4.215643405914307 | KNN Loss: 4.198136806488037 | CLS Loss: 0.017506763339042664\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 4.207289695739746 | KNN Loss: 4.190021514892578 | CLS Loss: 0.017267964780330658\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 4.190406799316406 | KNN Loss: 4.177099227905273 | CLS Loss: 0.013307482935488224\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 4.169675350189209 | KNN Loss: 4.162030220031738 | CLS Loss: 0.007645169738680124\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 4.199552536010742 | KNN Loss: 4.170588493347168 | CLS Loss: 0.028964120894670486\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 4.185279369354248 | KNN Loss: 4.172290802001953 | CLS Loss: 0.012988346628844738\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 4.195827484130859 | KNN Loss: 4.182858467102051 | CLS Loss: 0.012969068251550198\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 4.1931023597717285 | KNN Loss: 4.173821926116943 | CLS Loss: 0.019280241802334785\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 4.225539207458496 | KNN Loss: 4.204922676086426 | CLS Loss: 0.020616495981812477\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 4.242425441741943 | KNN Loss: 4.202834606170654 | CLS Loss: 0.03959091380238533\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 4.254164218902588 | KNN Loss: 4.2128753662109375 | CLS Loss: 0.04128902405500412\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 4.188955783843994 | KNN Loss: 4.161426067352295 | CLS Loss: 0.027529854327440262\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 4.206378936767578 | KNN Loss: 4.169565200805664 | CLS Loss: 0.036813873797655106\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 4.182267189025879 | KNN Loss: 4.173726558685303 | CLS Loss: 0.008540508337318897\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 4.224247455596924 | KNN Loss: 4.1866774559021 | CLS Loss: 0.03756996989250183\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 4.189859867095947 | KNN Loss: 4.165926933288574 | CLS Loss: 0.023933131247758865\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 4.1943206787109375 | KNN Loss: 4.155874729156494 | CLS Loss: 0.03844577446579933\n",
      "Epoch: 053, Loss: 4.2022, Train: 0.9951, Valid: 0.9868, Best: 0.9868\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 4.200132369995117 | KNN Loss: 4.188228607177734 | CLS Loss: 0.011903536505997181\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 4.174153804779053 | KNN Loss: 4.157835006713867 | CLS Loss: 0.016318747773766518\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 4.189050197601318 | KNN Loss: 4.169993877410889 | CLS Loss: 0.019056275486946106\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 4.223635673522949 | KNN Loss: 4.201802730560303 | CLS Loss: 0.021832890808582306\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 4.239574432373047 | KNN Loss: 4.219203472137451 | CLS Loss: 0.020370954647660255\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 4.18991756439209 | KNN Loss: 4.183378219604492 | CLS Loss: 0.006539253983646631\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 4.216220855712891 | KNN Loss: 4.20036506652832 | CLS Loss: 0.015855932608246803\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 4.260195732116699 | KNN Loss: 4.200000286102295 | CLS Loss: 0.06019546091556549\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 4.2222371101379395 | KNN Loss: 4.188676357269287 | CLS Loss: 0.03356097266077995\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 4.17214822769165 | KNN Loss: 4.157131195068359 | CLS Loss: 0.01501699909567833\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 4.179355144500732 | KNN Loss: 4.156485080718994 | CLS Loss: 0.022870128974318504\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 4.202361106872559 | KNN Loss: 4.195876598358154 | CLS Loss: 0.006484566256403923\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 4.182533264160156 | KNN Loss: 4.1749701499938965 | CLS Loss: 0.0075629097409546375\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 4.176480770111084 | KNN Loss: 4.163699626922607 | CLS Loss: 0.012781267985701561\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 4.195620059967041 | KNN Loss: 4.182721138000488 | CLS Loss: 0.012898863293230534\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 4.192409515380859 | KNN Loss: 4.15887975692749 | CLS Loss: 0.0335298590362072\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 4.20709228515625 | KNN Loss: 4.183230876922607 | CLS Loss: 0.023861629888415337\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 4.220891952514648 | KNN Loss: 4.20039176940918 | CLS Loss: 0.02050010859966278\n",
      "Epoch: 054, Loss: 4.1975, Train: 0.9949, Valid: 0.9864, Best: 0.9868\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 4.198408603668213 | KNN Loss: 4.166372776031494 | CLS Loss: 0.03203573450446129\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 4.188113689422607 | KNN Loss: 4.177640914916992 | CLS Loss: 0.010472641326487064\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 4.193644046783447 | KNN Loss: 4.189114570617676 | CLS Loss: 0.004529327154159546\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 4.187831401824951 | KNN Loss: 4.176023483276367 | CLS Loss: 0.011808115988969803\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 4.214606761932373 | KNN Loss: 4.193933486938477 | CLS Loss: 0.020673369988799095\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 4.190776348114014 | KNN Loss: 4.179804801940918 | CLS Loss: 0.010971645824611187\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 4.19939661026001 | KNN Loss: 4.188874244689941 | CLS Loss: 0.010522410273551941\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 4.187507629394531 | KNN Loss: 4.160363674163818 | CLS Loss: 0.02714412286877632\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 4.218362808227539 | KNN Loss: 4.199986457824707 | CLS Loss: 0.018376315012574196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 4.181483745574951 | KNN Loss: 4.147748947143555 | CLS Loss: 0.033735014498233795\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 4.148003101348877 | KNN Loss: 4.136166572570801 | CLS Loss: 0.0118366414681077\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 4.198420524597168 | KNN Loss: 4.159153461456299 | CLS Loss: 0.03926724195480347\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 4.213823318481445 | KNN Loss: 4.202559947967529 | CLS Loss: 0.011263209395110607\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 4.202659606933594 | KNN Loss: 4.1685872077941895 | CLS Loss: 0.034072376787662506\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 4.193799018859863 | KNN Loss: 4.180274486541748 | CLS Loss: 0.013524500653147697\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 4.159256458282471 | KNN Loss: 4.1519622802734375 | CLS Loss: 0.0072944085113704205\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 4.164046764373779 | KNN Loss: 4.155399322509766 | CLS Loss: 0.008647329173982143\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 4.227963924407959 | KNN Loss: 4.21712064743042 | CLS Loss: 0.01084351260215044\n",
      "Epoch: 055, Loss: 4.1948, Train: 0.9955, Valid: 0.9871, Best: 0.9871\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 4.175756454467773 | KNN Loss: 4.158462047576904 | CLS Loss: 0.017294418066740036\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 4.188724040985107 | KNN Loss: 4.162916660308838 | CLS Loss: 0.025807444006204605\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 4.245387554168701 | KNN Loss: 4.229675769805908 | CLS Loss: 0.01571185141801834\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 4.217590808868408 | KNN Loss: 4.19796085357666 | CLS Loss: 0.019630182534456253\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 4.21226167678833 | KNN Loss: 4.194889545440674 | CLS Loss: 0.017372071743011475\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 4.222374439239502 | KNN Loss: 4.206532955169678 | CLS Loss: 0.015841329470276833\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 4.190835475921631 | KNN Loss: 4.179272651672363 | CLS Loss: 0.011562781408429146\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 4.208392143249512 | KNN Loss: 4.177963733673096 | CLS Loss: 0.03042817860841751\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 4.1735405921936035 | KNN Loss: 4.1680908203125 | CLS Loss: 0.005449729971587658\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 4.165414333343506 | KNN Loss: 4.160285949707031 | CLS Loss: 0.005128553137183189\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 4.180144309997559 | KNN Loss: 4.175164699554443 | CLS Loss: 0.004979663994163275\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 4.167417526245117 | KNN Loss: 4.162243843078613 | CLS Loss: 0.005173520650714636\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 4.188785552978516 | KNN Loss: 4.173861503601074 | CLS Loss: 0.014923886395990849\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 4.235872268676758 | KNN Loss: 4.2011399269104 | CLS Loss: 0.034732114523649216\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 4.193315505981445 | KNN Loss: 4.171104431152344 | CLS Loss: 0.022211143746972084\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 4.1798176765441895 | KNN Loss: 4.157058238983154 | CLS Loss: 0.022759508341550827\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 4.176339149475098 | KNN Loss: 4.167028903961182 | CLS Loss: 0.009310386143624783\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 4.195864677429199 | KNN Loss: 4.178804874420166 | CLS Loss: 0.017059754580259323\n",
      "Epoch: 056, Loss: 4.1945, Train: 0.9959, Valid: 0.9868, Best: 0.9871\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 4.181301116943359 | KNN Loss: 4.173366546630859 | CLS Loss: 0.007934603840112686\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 4.212724685668945 | KNN Loss: 4.20072603225708 | CLS Loss: 0.011998790316283703\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 4.181892395019531 | KNN Loss: 4.169782638549805 | CLS Loss: 0.012109736911952496\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 4.171956539154053 | KNN Loss: 4.151679992675781 | CLS Loss: 0.020276375114917755\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 4.244723796844482 | KNN Loss: 4.176311016082764 | CLS Loss: 0.06841257214546204\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 4.179459095001221 | KNN Loss: 4.164255619049072 | CLS Loss: 0.015203472226858139\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 4.223858833312988 | KNN Loss: 4.206472873687744 | CLS Loss: 0.01738610677421093\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 4.181468963623047 | KNN Loss: 4.167633533477783 | CLS Loss: 0.013835468329489231\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 4.1806488037109375 | KNN Loss: 4.1720805168151855 | CLS Loss: 0.00856838934123516\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 4.160043239593506 | KNN Loss: 4.145959377288818 | CLS Loss: 0.014083627611398697\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 4.196082592010498 | KNN Loss: 4.185969352722168 | CLS Loss: 0.010113395750522614\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 4.188254356384277 | KNN Loss: 4.172257423400879 | CLS Loss: 0.015997115522623062\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 4.2365264892578125 | KNN Loss: 4.2170729637146 | CLS Loss: 0.019453328102827072\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 4.213151931762695 | KNN Loss: 4.207500457763672 | CLS Loss: 0.00565126771107316\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 4.192288398742676 | KNN Loss: 4.178034782409668 | CLS Loss: 0.014253556728363037\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 4.187784671783447 | KNN Loss: 4.176318168640137 | CLS Loss: 0.011466627940535545\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 4.181060314178467 | KNN Loss: 4.163557529449463 | CLS Loss: 0.0175026748329401\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 4.1935248374938965 | KNN Loss: 4.182704925537109 | CLS Loss: 0.01082008145749569\n",
      "Epoch: 057, Loss: 4.1970, Train: 0.9958, Valid: 0.9867, Best: 0.9871\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 4.175997257232666 | KNN Loss: 4.172423839569092 | CLS Loss: 0.0035733303520828485\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 4.19401216506958 | KNN Loss: 4.166966915130615 | CLS Loss: 0.02704518847167492\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 4.200613021850586 | KNN Loss: 4.1826171875 | CLS Loss: 0.017995798960328102\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 4.211827278137207 | KNN Loss: 4.188577175140381 | CLS Loss: 0.023250004276633263\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 4.169727325439453 | KNN Loss: 4.164875030517578 | CLS Loss: 0.004852233454585075\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 4.247252464294434 | KNN Loss: 4.217679023742676 | CLS Loss: 0.029573634266853333\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 4.190803050994873 | KNN Loss: 4.175797939300537 | CLS Loss: 0.01500521320849657\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 4.256347179412842 | KNN Loss: 4.242804050445557 | CLS Loss: 0.013543015345931053\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 4.158828258514404 | KNN Loss: 4.137149810791016 | CLS Loss: 0.021678254008293152\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 4.225616455078125 | KNN Loss: 4.190029144287109 | CLS Loss: 0.03558735549449921\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 4.175967216491699 | KNN Loss: 4.1399970054626465 | CLS Loss: 0.03596997261047363\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 4.171372413635254 | KNN Loss: 4.167075157165527 | CLS Loss: 0.004297282081097364\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 4.165075778961182 | KNN Loss: 4.151904106140137 | CLS Loss: 0.013171730563044548\n",
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 4.191737174987793 | KNN Loss: 4.171916484832764 | CLS Loss: 0.01982087455689907\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 4.2261643409729 | KNN Loss: 4.2108869552612305 | CLS Loss: 0.015277269296348095\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 4.227199554443359 | KNN Loss: 4.183417797088623 | CLS Loss: 0.04378170147538185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 4.215922832489014 | KNN Loss: 4.194922924041748 | CLS Loss: 0.020999914035201073\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 4.204423427581787 | KNN Loss: 4.199481964111328 | CLS Loss: 0.004941476043313742\n",
      "Epoch: 058, Loss: 4.1947, Train: 0.9947, Valid: 0.9853, Best: 0.9871\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 4.221714973449707 | KNN Loss: 4.19355583190918 | CLS Loss: 0.028159206733107567\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 4.179389476776123 | KNN Loss: 4.159837245941162 | CLS Loss: 0.01955222710967064\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 4.170622825622559 | KNN Loss: 4.161334037780762 | CLS Loss: 0.009288894012570381\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 4.214389801025391 | KNN Loss: 4.201254367828369 | CLS Loss: 0.013135419227182865\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 4.2412190437316895 | KNN Loss: 4.2173380851745605 | CLS Loss: 0.023881033062934875\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 4.216714859008789 | KNN Loss: 4.20017671585083 | CLS Loss: 0.016538221389055252\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 4.221356391906738 | KNN Loss: 4.179570198059082 | CLS Loss: 0.041786402463912964\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 4.183526992797852 | KNN Loss: 4.171839714050293 | CLS Loss: 0.011687183752655983\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 4.182135581970215 | KNN Loss: 4.166648864746094 | CLS Loss: 0.015486950054764748\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 4.198848247528076 | KNN Loss: 4.186359882354736 | CLS Loss: 0.012488218024373055\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 4.192215442657471 | KNN Loss: 4.176893711090088 | CLS Loss: 0.0153218237683177\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 4.184263229370117 | KNN Loss: 4.153169631958008 | CLS Loss: 0.03109363466501236\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 4.211446285247803 | KNN Loss: 4.193427085876465 | CLS Loss: 0.018019329756498337\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 4.193569183349609 | KNN Loss: 4.181191921234131 | CLS Loss: 0.012377440929412842\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 4.219302177429199 | KNN Loss: 4.19675874710083 | CLS Loss: 0.02254353277385235\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 4.193309783935547 | KNN Loss: 4.172928333282471 | CLS Loss: 0.020381582900881767\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 4.246734142303467 | KNN Loss: 4.2028374671936035 | CLS Loss: 0.043896645307540894\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 4.188828945159912 | KNN Loss: 4.153067111968994 | CLS Loss: 0.03576194494962692\n",
      "Epoch: 059, Loss: 4.1980, Train: 0.9934, Valid: 0.9854, Best: 0.9871\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 4.197166919708252 | KNN Loss: 4.17581844329834 | CLS Loss: 0.02134856954216957\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 4.20614767074585 | KNN Loss: 4.195936679840088 | CLS Loss: 0.010211090557277203\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 4.246367931365967 | KNN Loss: 4.216625213623047 | CLS Loss: 0.029742853716015816\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 4.175807476043701 | KNN Loss: 4.164853572845459 | CLS Loss: 0.01095410156995058\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 4.151713848114014 | KNN Loss: 4.143974304199219 | CLS Loss: 0.007739698980003595\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 4.186537742614746 | KNN Loss: 4.177009105682373 | CLS Loss: 0.00952861737459898\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 4.18272590637207 | KNN Loss: 4.173386573791504 | CLS Loss: 0.009339539334177971\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 4.217029571533203 | KNN Loss: 4.198916912078857 | CLS Loss: 0.018112657591700554\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 4.236098766326904 | KNN Loss: 4.2248945236206055 | CLS Loss: 0.011204186826944351\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 4.1983642578125 | KNN Loss: 4.182810306549072 | CLS Loss: 0.01555403508245945\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 4.198272228240967 | KNN Loss: 4.187711715698242 | CLS Loss: 0.010560448281466961\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 4.173698902130127 | KNN Loss: 4.169773101806641 | CLS Loss: 0.003925601951777935\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 4.19206428527832 | KNN Loss: 4.177859306335449 | CLS Loss: 0.01420503668487072\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 4.184993743896484 | KNN Loss: 4.171456813812256 | CLS Loss: 0.013536700047552586\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 4.191464900970459 | KNN Loss: 4.177445411682129 | CLS Loss: 0.014019678346812725\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 4.1757097244262695 | KNN Loss: 4.169170379638672 | CLS Loss: 0.006539398804306984\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 4.166864395141602 | KNN Loss: 4.1585469245910645 | CLS Loss: 0.008317457512021065\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 4.206782341003418 | KNN Loss: 4.188478946685791 | CLS Loss: 0.018303297460079193\n",
      "Epoch: 060, Loss: 4.1966, Train: 0.9957, Valid: 0.9867, Best: 0.9871\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 4.165144443511963 | KNN Loss: 4.142240524291992 | CLS Loss: 0.022903889417648315\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 4.1720356941223145 | KNN Loss: 4.168607711791992 | CLS Loss: 0.003427769523113966\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 4.191801071166992 | KNN Loss: 4.165065288543701 | CLS Loss: 0.026735838502645493\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 4.234907150268555 | KNN Loss: 4.211211681365967 | CLS Loss: 0.02369530498981476\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 4.25294303894043 | KNN Loss: 4.212414741516113 | CLS Loss: 0.040528494864702225\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 4.1863203048706055 | KNN Loss: 4.1655168533325195 | CLS Loss: 0.020803427323698997\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 4.20945930480957 | KNN Loss: 4.188383102416992 | CLS Loss: 0.02107633836567402\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 4.152164459228516 | KNN Loss: 4.13688850402832 | CLS Loss: 0.015276148915290833\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 4.16143798828125 | KNN Loss: 4.151297569274902 | CLS Loss: 0.010140571743249893\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 4.218435764312744 | KNN Loss: 4.1951093673706055 | CLS Loss: 0.02332649938762188\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 4.231353759765625 | KNN Loss: 4.210768222808838 | CLS Loss: 0.020585328340530396\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 4.18139123916626 | KNN Loss: 4.164159297943115 | CLS Loss: 0.017231961712241173\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 4.204408645629883 | KNN Loss: 4.1803412437438965 | CLS Loss: 0.02406739816069603\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 4.182206153869629 | KNN Loss: 4.168708801269531 | CLS Loss: 0.013497281819581985\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 4.215007781982422 | KNN Loss: 4.190763473510742 | CLS Loss: 0.024244414642453194\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 4.160107612609863 | KNN Loss: 4.151086330413818 | CLS Loss: 0.009021095931529999\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 4.179776668548584 | KNN Loss: 4.168040752410889 | CLS Loss: 0.011736095882952213\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 4.179880142211914 | KNN Loss: 4.175388813018799 | CLS Loss: 0.004491566680371761\n",
      "Epoch: 061, Loss: 4.1940, Train: 0.9949, Valid: 0.9867, Best: 0.9871\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 4.173418998718262 | KNN Loss: 4.159205436706543 | CLS Loss: 0.014213564805686474\n",
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 4.148167133331299 | KNN Loss: 4.143956184387207 | CLS Loss: 0.004210929851979017\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 4.16062068939209 | KNN Loss: 4.1562018394470215 | CLS Loss: 0.004419026430696249\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 4.188444137573242 | KNN Loss: 4.166317939758301 | CLS Loss: 0.02212635427713394\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 4.1888508796691895 | KNN Loss: 4.1611647605896 | CLS Loss: 0.027686191722750664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 4.165596008300781 | KNN Loss: 4.16331148147583 | CLS Loss: 0.002284666523337364\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 4.158426761627197 | KNN Loss: 4.157233715057373 | CLS Loss: 0.001193030970171094\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 4.257723331451416 | KNN Loss: 4.219242572784424 | CLS Loss: 0.0384807325899601\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 4.183809280395508 | KNN Loss: 4.1766252517700195 | CLS Loss: 0.007184003479778767\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 4.178555011749268 | KNN Loss: 4.160491943359375 | CLS Loss: 0.01806303672492504\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 4.188300132751465 | KNN Loss: 4.170668601989746 | CLS Loss: 0.017631743103265762\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 4.186277866363525 | KNN Loss: 4.169018268585205 | CLS Loss: 0.017259778454899788\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 4.15166711807251 | KNN Loss: 4.142932415008545 | CLS Loss: 0.008734623901546001\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 4.20943021774292 | KNN Loss: 4.196139812469482 | CLS Loss: 0.013290226459503174\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 4.150513172149658 | KNN Loss: 4.1458210945129395 | CLS Loss: 0.004692008253186941\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 4.188366413116455 | KNN Loss: 4.17304801940918 | CLS Loss: 0.015318216755986214\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 4.174893379211426 | KNN Loss: 4.143382549285889 | CLS Loss: 0.03151066601276398\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 4.193066596984863 | KNN Loss: 4.181063175201416 | CLS Loss: 0.012003294192254543\n",
      "Epoch: 062, Loss: 4.1881, Train: 0.9954, Valid: 0.9857, Best: 0.9871\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 4.194191932678223 | KNN Loss: 4.181225776672363 | CLS Loss: 0.012965920381247997\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 4.177121639251709 | KNN Loss: 4.16591739654541 | CLS Loss: 0.011204227805137634\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 4.1777024269104 | KNN Loss: 4.172938346862793 | CLS Loss: 0.004764231853187084\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 4.162064552307129 | KNN Loss: 4.14869499206543 | CLS Loss: 0.013369537889957428\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 4.215183258056641 | KNN Loss: 4.19456672668457 | CLS Loss: 0.020616693422198296\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 4.183360576629639 | KNN Loss: 4.165247917175293 | CLS Loss: 0.018112873658537865\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 4.16909122467041 | KNN Loss: 4.155470848083496 | CLS Loss: 0.013620605692267418\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 4.200037002563477 | KNN Loss: 4.192481517791748 | CLS Loss: 0.007555484306067228\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 4.179000377655029 | KNN Loss: 4.1656813621521 | CLS Loss: 0.013319066725671291\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 4.162998676300049 | KNN Loss: 4.158665657043457 | CLS Loss: 0.004332853015512228\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 4.1648688316345215 | KNN Loss: 4.153695106506348 | CLS Loss: 0.011173846200108528\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 4.1467366218566895 | KNN Loss: 4.144660472869873 | CLS Loss: 0.0020761347841471434\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 4.204329013824463 | KNN Loss: 4.181800365447998 | CLS Loss: 0.02252856455743313\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 4.207453727722168 | KNN Loss: 4.19410514831543 | CLS Loss: 0.013348367065191269\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 4.171311855316162 | KNN Loss: 4.164477825164795 | CLS Loss: 0.0068340422585606575\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 4.166389465332031 | KNN Loss: 4.153250217437744 | CLS Loss: 0.013139349408447742\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 4.2089996337890625 | KNN Loss: 4.1796369552612305 | CLS Loss: 0.029362894594669342\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 4.196627140045166 | KNN Loss: 4.177107810974121 | CLS Loss: 0.019519517198204994\n",
      "Epoch: 063, Loss: 4.1901, Train: 0.9960, Valid: 0.9871, Best: 0.9871\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 4.221184253692627 | KNN Loss: 4.21021842956543 | CLS Loss: 0.010965917259454727\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 4.1810688972473145 | KNN Loss: 4.173869609832764 | CLS Loss: 0.007199139799922705\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 4.162293434143066 | KNN Loss: 4.156946182250977 | CLS Loss: 0.0053473105654120445\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 4.1624321937561035 | KNN Loss: 4.140676021575928 | CLS Loss: 0.021756388247013092\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 4.160982131958008 | KNN Loss: 4.155328750610352 | CLS Loss: 0.005653406493365765\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 4.158316612243652 | KNN Loss: 4.153642177581787 | CLS Loss: 0.004674545489251614\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 4.163911819458008 | KNN Loss: 4.138998985290527 | CLS Loss: 0.02491300366818905\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 4.201455116271973 | KNN Loss: 4.17913293838501 | CLS Loss: 0.022322366014122963\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 4.193281650543213 | KNN Loss: 4.159602165222168 | CLS Loss: 0.033679623156785965\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 4.192561626434326 | KNN Loss: 4.165615558624268 | CLS Loss: 0.026946108788251877\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 4.21829891204834 | KNN Loss: 4.206661701202393 | CLS Loss: 0.011637091636657715\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 4.158878326416016 | KNN Loss: 4.153728485107422 | CLS Loss: 0.005149900447577238\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 4.159923553466797 | KNN Loss: 4.1456098556518555 | CLS Loss: 0.014313723891973495\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 4.1675286293029785 | KNN Loss: 4.1603546142578125 | CLS Loss: 0.007174137979745865\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 4.180019855499268 | KNN Loss: 4.168046474456787 | CLS Loss: 0.011973231099545956\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 4.173214912414551 | KNN Loss: 4.156485557556152 | CLS Loss: 0.01672942377626896\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 4.1911773681640625 | KNN Loss: 4.177587032318115 | CLS Loss: 0.013590509071946144\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 4.192770004272461 | KNN Loss: 4.18202018737793 | CLS Loss: 0.010749870911240578\n",
      "Epoch: 064, Loss: 4.1871, Train: 0.9954, Valid: 0.9861, Best: 0.9871\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 4.209599494934082 | KNN Loss: 4.189496040344238 | CLS Loss: 0.020103322342038155\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 4.171814441680908 | KNN Loss: 4.15300989151001 | CLS Loss: 0.018804607912898064\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 4.207427978515625 | KNN Loss: 4.188942909240723 | CLS Loss: 0.018485167995095253\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 4.198197841644287 | KNN Loss: 4.184872150421143 | CLS Loss: 0.013325612992048264\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 4.204854965209961 | KNN Loss: 4.185985565185547 | CLS Loss: 0.018869321793317795\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 4.1593828201293945 | KNN Loss: 4.153292655944824 | CLS Loss: 0.006089931819587946\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 4.190547943115234 | KNN Loss: 4.173489570617676 | CLS Loss: 0.01705828867852688\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 4.172711372375488 | KNN Loss: 4.16605281829834 | CLS Loss: 0.006658618804067373\n",
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 4.190761089324951 | KNN Loss: 4.18699312210083 | CLS Loss: 0.003767782123759389\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 4.171319961547852 | KNN Loss: 4.1648359298706055 | CLS Loss: 0.006483875680714846\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 4.231335639953613 | KNN Loss: 4.203415870666504 | CLS Loss: 0.027919726446270943\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 4.162650108337402 | KNN Loss: 4.156855583190918 | CLS Loss: 0.00579441711306572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 4.2054572105407715 | KNN Loss: 4.190098285675049 | CLS Loss: 0.015359107404947281\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 4.203043460845947 | KNN Loss: 4.165285587310791 | CLS Loss: 0.03775806725025177\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 4.232099533081055 | KNN Loss: 4.195133686065674 | CLS Loss: 0.03696604445576668\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 4.164560794830322 | KNN Loss: 4.1569647789001465 | CLS Loss: 0.007595815230160952\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 4.187994956970215 | KNN Loss: 4.162508010864258 | CLS Loss: 0.025487020611763\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 4.232361793518066 | KNN Loss: 4.178335666656494 | CLS Loss: 0.05402589216828346\n",
      "Epoch: 065, Loss: 4.1911, Train: 0.9955, Valid: 0.9865, Best: 0.9871\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 4.16154670715332 | KNN Loss: 4.155331134796143 | CLS Loss: 0.006215378642082214\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 4.165709972381592 | KNN Loss: 4.149192810058594 | CLS Loss: 0.016516977921128273\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 4.164058208465576 | KNN Loss: 4.157752990722656 | CLS Loss: 0.0063054533675313\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 4.196110725402832 | KNN Loss: 4.170246124267578 | CLS Loss: 0.025864552706480026\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 4.178649425506592 | KNN Loss: 4.166330814361572 | CLS Loss: 0.012318756431341171\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 4.165958404541016 | KNN Loss: 4.1459197998046875 | CLS Loss: 0.020038431510329247\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 4.184397220611572 | KNN Loss: 4.175486087799072 | CLS Loss: 0.008911184966564178\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 4.14786958694458 | KNN Loss: 4.1422553062438965 | CLS Loss: 0.00561404787003994\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 4.198482990264893 | KNN Loss: 4.1708149909973145 | CLS Loss: 0.027668213471770287\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 4.223862171173096 | KNN Loss: 4.204501628875732 | CLS Loss: 0.019360575824975967\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 4.194815158843994 | KNN Loss: 4.1647539138793945 | CLS Loss: 0.030061308294534683\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 4.195051193237305 | KNN Loss: 4.163346767425537 | CLS Loss: 0.0317046195268631\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 4.165176868438721 | KNN Loss: 4.157973766326904 | CLS Loss: 0.007203217595815659\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 4.174694538116455 | KNN Loss: 4.163304328918457 | CLS Loss: 0.011390134692192078\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 4.190299987792969 | KNN Loss: 4.1640729904174805 | CLS Loss: 0.026227042078971863\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 4.2414751052856445 | KNN Loss: 4.215915679931641 | CLS Loss: 0.025559201836586\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 4.167512893676758 | KNN Loss: 4.149819850921631 | CLS Loss: 0.01769326813519001\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 4.200384616851807 | KNN Loss: 4.164086818695068 | CLS Loss: 0.03629769757390022\n",
      "Epoch: 066, Loss: 4.1905, Train: 0.9956, Valid: 0.9868, Best: 0.9871\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 4.1798505783081055 | KNN Loss: 4.165708541870117 | CLS Loss: 0.0141420504078269\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 4.172429084777832 | KNN Loss: 4.167920112609863 | CLS Loss: 0.004509103484451771\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 4.211939811706543 | KNN Loss: 4.202295780181885 | CLS Loss: 0.009644082747399807\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 4.161759376525879 | KNN Loss: 4.155942916870117 | CLS Loss: 0.005816267337650061\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 4.174972057342529 | KNN Loss: 4.165374755859375 | CLS Loss: 0.009597446769475937\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 4.154269695281982 | KNN Loss: 4.139913082122803 | CLS Loss: 0.014356502331793308\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 4.1648478507995605 | KNN Loss: 4.152198791503906 | CLS Loss: 0.01264884416013956\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 4.161448001861572 | KNN Loss: 4.157261848449707 | CLS Loss: 0.004186292178928852\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 4.152270317077637 | KNN Loss: 4.148235321044922 | CLS Loss: 0.004034811165183783\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 4.164725303649902 | KNN Loss: 4.1578049659729 | CLS Loss: 0.006920109037309885\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 4.170406341552734 | KNN Loss: 4.159748077392578 | CLS Loss: 0.010658412240445614\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 4.169106483459473 | KNN Loss: 4.1658148765563965 | CLS Loss: 0.0032917142380028963\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 4.142348289489746 | KNN Loss: 4.1355366706848145 | CLS Loss: 0.0068117897026240826\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 4.205779075622559 | KNN Loss: 4.189795970916748 | CLS Loss: 0.01598292961716652\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 4.1519365310668945 | KNN Loss: 4.136318683624268 | CLS Loss: 0.015617703087627888\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 4.227478504180908 | KNN Loss: 4.210668563842773 | CLS Loss: 0.01681002974510193\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 4.145341396331787 | KNN Loss: 4.139171600341797 | CLS Loss: 0.006169711239635944\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 4.201377868652344 | KNN Loss: 4.185428619384766 | CLS Loss: 0.015949351713061333\n",
      "Epoch: 067, Loss: 4.1880, Train: 0.9950, Valid: 0.9858, Best: 0.9871\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 4.198486328125 | KNN Loss: 4.192148208618164 | CLS Loss: 0.006338325794786215\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 4.2302775382995605 | KNN Loss: 4.198305606842041 | CLS Loss: 0.031972113996744156\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 4.180752277374268 | KNN Loss: 4.169149875640869 | CLS Loss: 0.011602603830397129\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 4.172217845916748 | KNN Loss: 4.1608099937438965 | CLS Loss: 0.011407790705561638\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 4.205661296844482 | KNN Loss: 4.190614700317383 | CLS Loss: 0.015046376734972\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 4.195671558380127 | KNN Loss: 4.1937665939331055 | CLS Loss: 0.001904987497255206\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 4.1890034675598145 | KNN Loss: 4.182412147521973 | CLS Loss: 0.006591191980987787\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 4.2093505859375 | KNN Loss: 4.183629035949707 | CLS Loss: 0.025721631944179535\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 4.222967147827148 | KNN Loss: 4.184123516082764 | CLS Loss: 0.03884370997548103\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 4.210932731628418 | KNN Loss: 4.1894354820251465 | CLS Loss: 0.021497435867786407\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 4.199244022369385 | KNN Loss: 4.184803485870361 | CLS Loss: 0.014440407045185566\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 4.176524639129639 | KNN Loss: 4.1674675941467285 | CLS Loss: 0.009057245217263699\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 4.221476078033447 | KNN Loss: 4.208914279937744 | CLS Loss: 0.012561621144413948\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 4.167834281921387 | KNN Loss: 4.149682998657227 | CLS Loss: 0.018151363357901573\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 4.213037490844727 | KNN Loss: 4.186420917510986 | CLS Loss: 0.026616590097546577\n",
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 4.198987007141113 | KNN Loss: 4.186882495880127 | CLS Loss: 0.012104683555662632\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 4.155757904052734 | KNN Loss: 4.147889137268066 | CLS Loss: 0.007868771441280842\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 4.179665565490723 | KNN Loss: 4.175609111785889 | CLS Loss: 0.00405638013035059\n",
      "Epoch: 068, Loss: 4.1882, Train: 0.9958, Valid: 0.9870, Best: 0.9871\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 4.183365345001221 | KNN Loss: 4.163654327392578 | CLS Loss: 0.01971099153161049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 4.231618881225586 | KNN Loss: 4.22288179397583 | CLS Loss: 0.008737083524465561\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 4.187717437744141 | KNN Loss: 4.164570331573486 | CLS Loss: 0.02314707450568676\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 4.168126583099365 | KNN Loss: 4.159274101257324 | CLS Loss: 0.008852286264300346\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 4.220248222351074 | KNN Loss: 4.179140567779541 | CLS Loss: 0.041107773780822754\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 4.194516658782959 | KNN Loss: 4.1766133308410645 | CLS Loss: 0.017903273925185204\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 4.203122615814209 | KNN Loss: 4.177933692932129 | CLS Loss: 0.02518889307975769\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 4.203919410705566 | KNN Loss: 4.185119152069092 | CLS Loss: 0.018800247460603714\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 4.175041198730469 | KNN Loss: 4.168982028961182 | CLS Loss: 0.006059044506400824\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 4.171083450317383 | KNN Loss: 4.156066417694092 | CLS Loss: 0.015016905963420868\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 4.202164173126221 | KNN Loss: 4.178618431091309 | CLS Loss: 0.02354581467807293\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 4.1578474044799805 | KNN Loss: 4.141349792480469 | CLS Loss: 0.016497530043125153\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 4.169320583343506 | KNN Loss: 4.152981758117676 | CLS Loss: 0.016338692978024483\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 4.17853307723999 | KNN Loss: 4.154269218444824 | CLS Loss: 0.024263817816972733\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 4.19959831237793 | KNN Loss: 4.190566062927246 | CLS Loss: 0.009032467380166054\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 4.221059799194336 | KNN Loss: 4.206625938415527 | CLS Loss: 0.014433702453970909\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 4.177174091339111 | KNN Loss: 4.170067310333252 | CLS Loss: 0.007106803357601166\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 4.193121910095215 | KNN Loss: 4.1717610359191895 | CLS Loss: 0.02136099897325039\n",
      "Epoch: 069, Loss: 4.1864, Train: 0.9953, Valid: 0.9859, Best: 0.9871\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 4.174440383911133 | KNN Loss: 4.161910057067871 | CLS Loss: 0.012530259788036346\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 4.207993507385254 | KNN Loss: 4.194612979888916 | CLS Loss: 0.013380357064306736\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 4.187587738037109 | KNN Loss: 4.151352405548096 | CLS Loss: 0.03623510152101517\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 4.158742427825928 | KNN Loss: 4.148190498352051 | CLS Loss: 0.01055208034813404\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 4.185854911804199 | KNN Loss: 4.176076412200928 | CLS Loss: 0.009778416715562344\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 4.177318572998047 | KNN Loss: 4.160857200622559 | CLS Loss: 0.016461553052067757\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 4.1609649658203125 | KNN Loss: 4.146474838256836 | CLS Loss: 0.014490047469735146\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 4.195209980010986 | KNN Loss: 4.166544437408447 | CLS Loss: 0.028665628284215927\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 4.211194038391113 | KNN Loss: 4.1872172355651855 | CLS Loss: 0.02397703379392624\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 4.186582565307617 | KNN Loss: 4.158721446990967 | CLS Loss: 0.02786109782755375\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 4.201772212982178 | KNN Loss: 4.177469730377197 | CLS Loss: 0.024302568286657333\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 4.1891326904296875 | KNN Loss: 4.180711269378662 | CLS Loss: 0.00842141080647707\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 4.1925482749938965 | KNN Loss: 4.166354656219482 | CLS Loss: 0.026193847879767418\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 4.191381454467773 | KNN Loss: 4.148809909820557 | CLS Loss: 0.04257167503237724\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 4.1839375495910645 | KNN Loss: 4.173745155334473 | CLS Loss: 0.010192317888140678\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 4.166617393493652 | KNN Loss: 4.160665988922119 | CLS Loss: 0.005951600149273872\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 4.1865692138671875 | KNN Loss: 4.169809341430664 | CLS Loss: 0.01675967499613762\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 4.183473587036133 | KNN Loss: 4.178675651550293 | CLS Loss: 0.004798028618097305\n",
      "Epoch: 070, Loss: 4.1859, Train: 0.9963, Valid: 0.9871, Best: 0.9871\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 4.200982570648193 | KNN Loss: 4.183239936828613 | CLS Loss: 0.017742397263646126\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 4.168363094329834 | KNN Loss: 4.146866798400879 | CLS Loss: 0.02149646356701851\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 4.166682243347168 | KNN Loss: 4.152807712554932 | CLS Loss: 0.013874745927751064\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 4.166824817657471 | KNN Loss: 4.163908004760742 | CLS Loss: 0.0029168284963816404\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 4.226987838745117 | KNN Loss: 4.2237725257873535 | CLS Loss: 0.003215421922504902\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 4.157617092132568 | KNN Loss: 4.149388313293457 | CLS Loss: 0.008228783495724201\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 4.184336185455322 | KNN Loss: 4.151438236236572 | CLS Loss: 0.03289809450507164\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 4.171360015869141 | KNN Loss: 4.169445037841797 | CLS Loss: 0.0019151372835040092\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 4.186259746551514 | KNN Loss: 4.16855001449585 | CLS Loss: 0.017709607258439064\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 4.220028400421143 | KNN Loss: 4.190707683563232 | CLS Loss: 0.02932063117623329\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 4.190637111663818 | KNN Loss: 4.17080020904541 | CLS Loss: 0.01983693242073059\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 4.197438716888428 | KNN Loss: 4.186737060546875 | CLS Loss: 0.01070158090442419\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 4.231460094451904 | KNN Loss: 4.220147132873535 | CLS Loss: 0.011313064023852348\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 4.180594444274902 | KNN Loss: 4.170014381408691 | CLS Loss: 0.010580124333500862\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 4.168980121612549 | KNN Loss: 4.158822059631348 | CLS Loss: 0.010157828219234943\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 4.169236660003662 | KNN Loss: 4.158188343048096 | CLS Loss: 0.011048401705920696\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 4.1915283203125 | KNN Loss: 4.180379867553711 | CLS Loss: 0.011148236691951752\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 4.228904724121094 | KNN Loss: 4.226719379425049 | CLS Loss: 0.0021851754281669855\n",
      "Epoch: 071, Loss: 4.1869, Train: 0.9960, Valid: 0.9860, Best: 0.9871\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 4.170487403869629 | KNN Loss: 4.161513805389404 | CLS Loss: 0.008973568677902222\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 4.161501884460449 | KNN Loss: 4.146472930908203 | CLS Loss: 0.015029050409793854\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 4.198243141174316 | KNN Loss: 4.165557384490967 | CLS Loss: 0.03268587216734886\n",
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 4.170547962188721 | KNN Loss: 4.161085605621338 | CLS Loss: 0.009462588466703892\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 4.174563407897949 | KNN Loss: 4.168585777282715 | CLS Loss: 0.005977729335427284\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 4.1900634765625 | KNN Loss: 4.163659572601318 | CLS Loss: 0.026403721421957016\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 4.1771087646484375 | KNN Loss: 4.171838760375977 | CLS Loss: 0.005270061083137989\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 4.202973365783691 | KNN Loss: 4.180482864379883 | CLS Loss: 0.022490303963422775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 4.180418014526367 | KNN Loss: 4.1602067947387695 | CLS Loss: 0.020211130380630493\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 4.218597888946533 | KNN Loss: 4.202602863311768 | CLS Loss: 0.01599503681063652\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 4.178929805755615 | KNN Loss: 4.15957498550415 | CLS Loss: 0.019354816526174545\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 4.216339111328125 | KNN Loss: 4.183912754058838 | CLS Loss: 0.032426562160253525\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 4.148946762084961 | KNN Loss: 4.133347511291504 | CLS Loss: 0.01559903472661972\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 4.189474582672119 | KNN Loss: 4.172037601470947 | CLS Loss: 0.01743677817285061\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 4.195927619934082 | KNN Loss: 4.191999912261963 | CLS Loss: 0.0039279405027627945\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 4.171967506408691 | KNN Loss: 4.1612653732299805 | CLS Loss: 0.010702096857130527\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 4.177084922790527 | KNN Loss: 4.155036926269531 | CLS Loss: 0.022048167884349823\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 4.182863712310791 | KNN Loss: 4.178335666656494 | CLS Loss: 0.004527933895587921\n",
      "Epoch: 072, Loss: 4.1893, Train: 0.9964, Valid: 0.9876, Best: 0.9876\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 4.168962478637695 | KNN Loss: 4.160844326019287 | CLS Loss: 0.008118144236505032\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 4.228028297424316 | KNN Loss: 4.214156150817871 | CLS Loss: 0.013872259296476841\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 4.173506736755371 | KNN Loss: 4.170041561126709 | CLS Loss: 0.00346507434733212\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 4.205255508422852 | KNN Loss: 4.187958717346191 | CLS Loss: 0.01729695498943329\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 4.2466301918029785 | KNN Loss: 4.231688499450684 | CLS Loss: 0.01494185347110033\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 4.157219886779785 | KNN Loss: 4.152824401855469 | CLS Loss: 0.004395429976284504\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 4.205855369567871 | KNN Loss: 4.165528774261475 | CLS Loss: 0.04032635688781738\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 4.1741461753845215 | KNN Loss: 4.168618679046631 | CLS Loss: 0.005527484696358442\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 4.174461364746094 | KNN Loss: 4.15995454788208 | CLS Loss: 0.01450659241527319\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 4.150095462799072 | KNN Loss: 4.136650562286377 | CLS Loss: 0.013445104472339153\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 4.150298595428467 | KNN Loss: 4.135579586029053 | CLS Loss: 0.014719041995704174\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 4.160553455352783 | KNN Loss: 4.152492046356201 | CLS Loss: 0.008061422035098076\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 4.210784435272217 | KNN Loss: 4.173561096191406 | CLS Loss: 0.0372232161462307\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 4.195312976837158 | KNN Loss: 4.187313556671143 | CLS Loss: 0.007999598048627377\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 4.161306858062744 | KNN Loss: 4.155575752258301 | CLS Loss: 0.005731166340410709\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 4.225996494293213 | KNN Loss: 4.200554370880127 | CLS Loss: 0.02544224262237549\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 4.1751813888549805 | KNN Loss: 4.164633750915527 | CLS Loss: 0.010547714307904243\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 4.174598693847656 | KNN Loss: 4.168192386627197 | CLS Loss: 0.006406085565686226\n",
      "Epoch: 073, Loss: 4.1816, Train: 0.9958, Valid: 0.9866, Best: 0.9876\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 4.186611175537109 | KNN Loss: 4.1692023277282715 | CLS Loss: 0.017408953979611397\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 4.157446384429932 | KNN Loss: 4.138841152191162 | CLS Loss: 0.018605366349220276\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 4.149792671203613 | KNN Loss: 4.143458843231201 | CLS Loss: 0.006333867087960243\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 4.213036060333252 | KNN Loss: 4.195699214935303 | CLS Loss: 0.017336897552013397\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 4.151766777038574 | KNN Loss: 4.142244338989258 | CLS Loss: 0.009522662498056889\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 4.171955108642578 | KNN Loss: 4.157216548919678 | CLS Loss: 0.014738410711288452\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 4.157841682434082 | KNN Loss: 4.142923831939697 | CLS Loss: 0.014917999505996704\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 4.188751697540283 | KNN Loss: 4.169787883758545 | CLS Loss: 0.018963783979415894\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 4.169268608093262 | KNN Loss: 4.165349006652832 | CLS Loss: 0.003919449634850025\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 4.19585657119751 | KNN Loss: 4.174796104431152 | CLS Loss: 0.02106023021042347\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 4.216125965118408 | KNN Loss: 4.202780723571777 | CLS Loss: 0.01334515493363142\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 4.191568851470947 | KNN Loss: 4.179327964782715 | CLS Loss: 0.012240748852491379\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 4.205957412719727 | KNN Loss: 4.1996564865112305 | CLS Loss: 0.006300875451415777\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 4.2092366218566895 | KNN Loss: 4.182754039764404 | CLS Loss: 0.0264827199280262\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 4.191405773162842 | KNN Loss: 4.180844306945801 | CLS Loss: 0.01056164875626564\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 4.197169780731201 | KNN Loss: 4.162726402282715 | CLS Loss: 0.034443553537130356\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 4.188716411590576 | KNN Loss: 4.177218437194824 | CLS Loss: 0.01149807870388031\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 4.171090602874756 | KNN Loss: 4.161652565002441 | CLS Loss: 0.009438122622668743\n",
      "Epoch: 074, Loss: 4.1865, Train: 0.9963, Valid: 0.9882, Best: 0.9882\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 4.1943230628967285 | KNN Loss: 4.1748223304748535 | CLS Loss: 0.01950085535645485\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 4.186799049377441 | KNN Loss: 4.164379119873047 | CLS Loss: 0.02241990715265274\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 4.1582841873168945 | KNN Loss: 4.147522449493408 | CLS Loss: 0.010761774145066738\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 4.1669793128967285 | KNN Loss: 4.1611857414245605 | CLS Loss: 0.00579374423250556\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 4.157800197601318 | KNN Loss: 4.145650386810303 | CLS Loss: 0.012149625457823277\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 4.172290325164795 | KNN Loss: 4.167708396911621 | CLS Loss: 0.004582106601446867\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 4.178803443908691 | KNN Loss: 4.165035247802734 | CLS Loss: 0.013768387958407402\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 4.17877197265625 | KNN Loss: 4.1720099449157715 | CLS Loss: 0.006762151140719652\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 4.157595634460449 | KNN Loss: 4.147735595703125 | CLS Loss: 0.009859866462647915\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 4.186380386352539 | KNN Loss: 4.178375720977783 | CLS Loss: 0.00800489354878664\n",
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 4.184226989746094 | KNN Loss: 4.172740459442139 | CLS Loss: 0.011486366391181946\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 4.169881820678711 | KNN Loss: 4.164858818054199 | CLS Loss: 0.005023120436817408\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 4.176935195922852 | KNN Loss: 4.157623767852783 | CLS Loss: 0.01931138150393963\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 4.181209087371826 | KNN Loss: 4.166598796844482 | CLS Loss: 0.014610093086957932\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 4.168465614318848 | KNN Loss: 4.146209239959717 | CLS Loss: 0.022256245836615562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 4.215743541717529 | KNN Loss: 4.198930740356445 | CLS Loss: 0.016812657937407494\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 4.2382636070251465 | KNN Loss: 4.18907356262207 | CLS Loss: 0.049190256744623184\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 4.166059494018555 | KNN Loss: 4.150218486785889 | CLS Loss: 0.015840888023376465\n",
      "Epoch: 075, Loss: 4.1784, Train: 0.9956, Valid: 0.9859, Best: 0.9882\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 4.171874523162842 | KNN Loss: 4.155615329742432 | CLS Loss: 0.01625923439860344\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 4.162373065948486 | KNN Loss: 4.1519904136657715 | CLS Loss: 0.010382474400103092\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 4.185617923736572 | KNN Loss: 4.174278736114502 | CLS Loss: 0.011339057236909866\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 4.141385078430176 | KNN Loss: 4.137580871582031 | CLS Loss: 0.0038040040526539087\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 4.171820640563965 | KNN Loss: 4.1663970947265625 | CLS Loss: 0.0054236785508692265\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 4.220548629760742 | KNN Loss: 4.1833086013793945 | CLS Loss: 0.03724025934934616\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 4.128994464874268 | KNN Loss: 4.123486042022705 | CLS Loss: 0.005508489441126585\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 4.133316516876221 | KNN Loss: 4.121405601501465 | CLS Loss: 0.011911020614206791\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 4.1793341636657715 | KNN Loss: 4.166708946228027 | CLS Loss: 0.012625426054000854\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 4.153298377990723 | KNN Loss: 4.142307758331299 | CLS Loss: 0.010990542359650135\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 4.173054218292236 | KNN Loss: 4.1525797843933105 | CLS Loss: 0.020474521443247795\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 4.1728620529174805 | KNN Loss: 4.161789894104004 | CLS Loss: 0.011072009801864624\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 4.179421424865723 | KNN Loss: 4.167692184448242 | CLS Loss: 0.011729293502867222\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 4.197960376739502 | KNN Loss: 4.192512035369873 | CLS Loss: 0.005448444280773401\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 4.163169860839844 | KNN Loss: 4.155817031860352 | CLS Loss: 0.007352644111961126\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 4.184669494628906 | KNN Loss: 4.171755790710449 | CLS Loss: 0.012913481332361698\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 4.181649684906006 | KNN Loss: 4.165802478790283 | CLS Loss: 0.01584731787443161\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 4.188366889953613 | KNN Loss: 4.170948505401611 | CLS Loss: 0.01741849072277546\n",
      "Epoch: 076, Loss: 4.1764, Train: 0.9955, Valid: 0.9858, Best: 0.9882\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 4.168053150177002 | KNN Loss: 4.146152973175049 | CLS Loss: 0.021900108084082603\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 4.166054725646973 | KNN Loss: 4.15693998336792 | CLS Loss: 0.009114536456763744\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 4.185749530792236 | KNN Loss: 4.17595911026001 | CLS Loss: 0.009790479205548763\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 4.172168731689453 | KNN Loss: 4.167486667633057 | CLS Loss: 0.004681828431785107\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 4.220398426055908 | KNN Loss: 4.1923675537109375 | CLS Loss: 0.0280307624489069\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 4.221553802490234 | KNN Loss: 4.186216831207275 | CLS Loss: 0.03533683717250824\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 4.1631011962890625 | KNN Loss: 4.142919540405273 | CLS Loss: 0.020181477069854736\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 4.209321975708008 | KNN Loss: 4.180624485015869 | CLS Loss: 0.028697460889816284\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 4.177615165710449 | KNN Loss: 4.173614501953125 | CLS Loss: 0.004000855144113302\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 4.176307201385498 | KNN Loss: 4.164576530456543 | CLS Loss: 0.011730512604117393\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 4.180546760559082 | KNN Loss: 4.164766311645508 | CLS Loss: 0.015780488029122353\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 4.2375993728637695 | KNN Loss: 4.226316452026367 | CLS Loss: 0.011282882653176785\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 4.132620811462402 | KNN Loss: 4.128695487976074 | CLS Loss: 0.003925106022506952\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 4.171454429626465 | KNN Loss: 4.148927688598633 | CLS Loss: 0.022526610642671585\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 4.169402122497559 | KNN Loss: 4.153192043304443 | CLS Loss: 0.016209999099373817\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 4.182188987731934 | KNN Loss: 4.164949893951416 | CLS Loss: 0.017239268869161606\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 4.202384948730469 | KNN Loss: 4.177987575531006 | CLS Loss: 0.02439727820456028\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 4.176456928253174 | KNN Loss: 4.161955833435059 | CLS Loss: 0.014500969089567661\n",
      "Epoch: 077, Loss: 4.1810, Train: 0.9964, Valid: 0.9870, Best: 0.9882\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 4.178918361663818 | KNN Loss: 4.173443794250488 | CLS Loss: 0.005474700126796961\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 4.192503929138184 | KNN Loss: 4.188612937927246 | CLS Loss: 0.003891010070219636\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 4.218748569488525 | KNN Loss: 4.216266632080078 | CLS Loss: 0.0024820470716804266\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 4.192636966705322 | KNN Loss: 4.170817852020264 | CLS Loss: 0.021819092333316803\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 4.167390823364258 | KNN Loss: 4.159542560577393 | CLS Loss: 0.007848091423511505\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 4.156102180480957 | KNN Loss: 4.152297496795654 | CLS Loss: 0.003804560285061598\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 4.207868576049805 | KNN Loss: 4.192581653594971 | CLS Loss: 0.01528693363070488\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 4.154170513153076 | KNN Loss: 4.13676118850708 | CLS Loss: 0.01740953139960766\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 4.226090908050537 | KNN Loss: 4.210324764251709 | CLS Loss: 0.015765968710184097\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 4.148909568786621 | KNN Loss: 4.143922328948975 | CLS Loss: 0.0049872142262756824\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 4.213314056396484 | KNN Loss: 4.195050239562988 | CLS Loss: 0.018263930454850197\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 4.187153339385986 | KNN Loss: 4.168512344360352 | CLS Loss: 0.01864096149802208\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 4.136533260345459 | KNN Loss: 4.135729789733887 | CLS Loss: 0.0008032493060454726\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 4.161984443664551 | KNN Loss: 4.150036811828613 | CLS Loss: 0.011947776190936565\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 4.2047834396362305 | KNN Loss: 4.19624662399292 | CLS Loss: 0.008536791428923607\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 4.19443941116333 | KNN Loss: 4.189919948577881 | CLS Loss: 0.004519389010965824\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 4.119057655334473 | KNN Loss: 4.115045070648193 | CLS Loss: 0.004012396093457937\n",
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 4.152289867401123 | KNN Loss: 4.150191307067871 | CLS Loss: 0.002098778262734413\n",
      "Epoch: 078, Loss: 4.1762, Train: 0.9967, Valid: 0.9860, Best: 0.9882\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 4.192624568939209 | KNN Loss: 4.1847453117370605 | CLS Loss: 0.007879158481955528\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 4.158196926116943 | KNN Loss: 4.154253959655762 | CLS Loss: 0.0039429813623428345\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 4.158955097198486 | KNN Loss: 4.138312339782715 | CLS Loss: 0.020642710849642754\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 4.163318157196045 | KNN Loss: 4.157803058624268 | CLS Loss: 0.005515280179679394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 4.22163200378418 | KNN Loss: 4.187371253967285 | CLS Loss: 0.03426066413521767\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 4.1714982986450195 | KNN Loss: 4.169597625732422 | CLS Loss: 0.001900878269225359\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 4.23212194442749 | KNN Loss: 4.210782527923584 | CLS Loss: 0.021339282393455505\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 4.201274871826172 | KNN Loss: 4.177408218383789 | CLS Loss: 0.02386642061173916\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 4.187958717346191 | KNN Loss: 4.170316696166992 | CLS Loss: 0.017641974613070488\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 4.225302696228027 | KNN Loss: 4.212100982666016 | CLS Loss: 0.013201511465013027\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 4.1854777336120605 | KNN Loss: 4.173969745635986 | CLS Loss: 0.011508071795105934\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 4.159139156341553 | KNN Loss: 4.137204170227051 | CLS Loss: 0.021934879943728447\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 4.186429977416992 | KNN Loss: 4.177387237548828 | CLS Loss: 0.009042632766067982\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 4.165518283843994 | KNN Loss: 4.146813869476318 | CLS Loss: 0.01870426908135414\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 4.1839680671691895 | KNN Loss: 4.149637222290039 | CLS Loss: 0.03433089330792427\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 4.178096294403076 | KNN Loss: 4.159439563751221 | CLS Loss: 0.018656853586435318\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 4.200379848480225 | KNN Loss: 4.176695823669434 | CLS Loss: 0.02368386834859848\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 4.205672740936279 | KNN Loss: 4.191648960113525 | CLS Loss: 0.014023832976818085\n",
      "Epoch: 079, Loss: 4.1856, Train: 0.9964, Valid: 0.9859, Best: 0.9882\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 4.193354606628418 | KNN Loss: 4.171835899353027 | CLS Loss: 0.021518627181649208\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 4.236485481262207 | KNN Loss: 4.213864326477051 | CLS Loss: 0.022621190175414085\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 4.210964202880859 | KNN Loss: 4.195358753204346 | CLS Loss: 0.0156055623665452\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 4.180723667144775 | KNN Loss: 4.145047664642334 | CLS Loss: 0.03567603603005409\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 4.197359561920166 | KNN Loss: 4.173618793487549 | CLS Loss: 0.023740870878100395\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 4.204950332641602 | KNN Loss: 4.185286998748779 | CLS Loss: 0.019663292914628983\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 4.185480117797852 | KNN Loss: 4.173520565032959 | CLS Loss: 0.011959784664213657\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 4.151925086975098 | KNN Loss: 4.143698692321777 | CLS Loss: 0.008226296864449978\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 4.162748336791992 | KNN Loss: 4.154273509979248 | CLS Loss: 0.008474599570035934\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 4.198930740356445 | KNN Loss: 4.171988487243652 | CLS Loss: 0.026942292228341103\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 4.198454856872559 | KNN Loss: 4.189987659454346 | CLS Loss: 0.008467118255794048\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 4.190862655639648 | KNN Loss: 4.161450386047363 | CLS Loss: 0.029412150382995605\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 4.1670074462890625 | KNN Loss: 4.152354717254639 | CLS Loss: 0.01465265080332756\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 4.187819480895996 | KNN Loss: 4.151660442352295 | CLS Loss: 0.0361589640378952\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 4.146444320678711 | KNN Loss: 4.135721206665039 | CLS Loss: 0.010723195970058441\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 4.234684944152832 | KNN Loss: 4.216134548187256 | CLS Loss: 0.0185505710542202\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 4.190196514129639 | KNN Loss: 4.150426387786865 | CLS Loss: 0.03977023810148239\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 4.1857123374938965 | KNN Loss: 4.1745734214782715 | CLS Loss: 0.01113914605230093\n",
      "Epoch: 080, Loss: 4.1842, Train: 0.9967, Valid: 0.9863, Best: 0.9882\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 4.164019584655762 | KNN Loss: 4.159373760223389 | CLS Loss: 0.004646004177629948\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 4.1905951499938965 | KNN Loss: 4.17513370513916 | CLS Loss: 0.01546138059347868\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 4.164133548736572 | KNN Loss: 4.154361724853516 | CLS Loss: 0.009771781973540783\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 4.179445743560791 | KNN Loss: 4.170114040374756 | CLS Loss: 0.009331501089036465\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 4.17950963973999 | KNN Loss: 4.172453880310059 | CLS Loss: 0.00705574220046401\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 4.205958366394043 | KNN Loss: 4.199763774871826 | CLS Loss: 0.006194370798766613\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 4.153000354766846 | KNN Loss: 4.140842437744141 | CLS Loss: 0.012157942168414593\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 4.20323371887207 | KNN Loss: 4.1806817054748535 | CLS Loss: 0.022552069276571274\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 4.179856300354004 | KNN Loss: 4.172146320343018 | CLS Loss: 0.007709789089858532\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 4.178806781768799 | KNN Loss: 4.152957439422607 | CLS Loss: 0.02584932930767536\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 4.157185077667236 | KNN Loss: 4.146368503570557 | CLS Loss: 0.010816444642841816\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 4.1630730628967285 | KNN Loss: 4.149957180023193 | CLS Loss: 0.013115654699504375\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 4.189422130584717 | KNN Loss: 4.177023887634277 | CLS Loss: 0.012398012913763523\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 4.178378105163574 | KNN Loss: 4.150519371032715 | CLS Loss: 0.027858557179570198\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 4.215052127838135 | KNN Loss: 4.167566299438477 | CLS Loss: 0.047485966235399246\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 4.183070659637451 | KNN Loss: 4.164032936096191 | CLS Loss: 0.01903752237558365\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 4.166937828063965 | KNN Loss: 4.159964561462402 | CLS Loss: 0.006973280105739832\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 4.190100193023682 | KNN Loss: 4.183914661407471 | CLS Loss: 0.006185474339872599\n",
      "Epoch: 081, Loss: 4.1816, Train: 0.9960, Valid: 0.9867, Best: 0.9882\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 4.190731048583984 | KNN Loss: 4.181117057800293 | CLS Loss: 0.009614103473722935\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 4.178950309753418 | KNN Loss: 4.151769161224365 | CLS Loss: 0.027180928736925125\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 4.198513507843018 | KNN Loss: 4.178976535797119 | CLS Loss: 0.01953691430389881\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 4.179169654846191 | KNN Loss: 4.1726975440979 | CLS Loss: 0.0064723193645477295\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 4.199010372161865 | KNN Loss: 4.160556793212891 | CLS Loss: 0.038453541696071625\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 4.213159561157227 | KNN Loss: 4.187947750091553 | CLS Loss: 0.02521159127354622\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 4.162558555603027 | KNN Loss: 4.147247791290283 | CLS Loss: 0.015310786664485931\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 4.173881530761719 | KNN Loss: 4.164281845092773 | CLS Loss: 0.0095995357260108\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 4.15223503112793 | KNN Loss: 4.149409294128418 | CLS Loss: 0.0028255535289645195\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 4.184088706970215 | KNN Loss: 4.161929607391357 | CLS Loss: 0.022159304469823837\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 4.157598972320557 | KNN Loss: 4.148540019989014 | CLS Loss: 0.009058794938027859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 4.202474117279053 | KNN Loss: 4.1924214363098145 | CLS Loss: 0.010052827186882496\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 4.163381576538086 | KNN Loss: 4.14677095413208 | CLS Loss: 0.016610395163297653\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 4.161956310272217 | KNN Loss: 4.155298233032227 | CLS Loss: 0.006658002734184265\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 4.190673351287842 | KNN Loss: 4.182836055755615 | CLS Loss: 0.007837367244064808\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 4.1866960525512695 | KNN Loss: 4.165360450744629 | CLS Loss: 0.021335672587156296\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 4.19980525970459 | KNN Loss: 4.171334266662598 | CLS Loss: 0.02847079187631607\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 4.149526596069336 | KNN Loss: 4.142782211303711 | CLS Loss: 0.006744252517819405\n",
      "Epoch: 082, Loss: 4.1796, Train: 0.9970, Valid: 0.9873, Best: 0.9882\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 4.211876392364502 | KNN Loss: 4.1999664306640625 | CLS Loss: 0.011910010129213333\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 4.199063301086426 | KNN Loss: 4.189116954803467 | CLS Loss: 0.009946302510797977\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 4.16474723815918 | KNN Loss: 4.152677536010742 | CLS Loss: 0.012069669552147388\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 4.181715965270996 | KNN Loss: 4.156076431274414 | CLS Loss: 0.025639697909355164\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 4.130238056182861 | KNN Loss: 4.125748634338379 | CLS Loss: 0.004489608574658632\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 4.158056259155273 | KNN Loss: 4.150502681732178 | CLS Loss: 0.0075537823140621185\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 4.178668022155762 | KNN Loss: 4.155017375946045 | CLS Loss: 0.023650530725717545\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 4.1570353507995605 | KNN Loss: 4.144590854644775 | CLS Loss: 0.012444715015590191\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 4.192145824432373 | KNN Loss: 4.181485176086426 | CLS Loss: 0.010660713538527489\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 4.173654556274414 | KNN Loss: 4.160508632659912 | CLS Loss: 0.01314575131982565\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 4.204382419586182 | KNN Loss: 4.190718650817871 | CLS Loss: 0.01366383396089077\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 4.170595645904541 | KNN Loss: 4.156555652618408 | CLS Loss: 0.014039779081940651\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 4.152525901794434 | KNN Loss: 4.144856929779053 | CLS Loss: 0.007668892852962017\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 4.144651412963867 | KNN Loss: 4.131166934967041 | CLS Loss: 0.013484581373631954\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 4.189037322998047 | KNN Loss: 4.178810119628906 | CLS Loss: 0.010227344930171967\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 4.164029598236084 | KNN Loss: 4.1591477394104 | CLS Loss: 0.004881805274635553\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 4.170479774475098 | KNN Loss: 4.153046607971191 | CLS Loss: 0.01743299886584282\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 4.169300079345703 | KNN Loss: 4.164424419403076 | CLS Loss: 0.004875808954238892\n",
      "Epoch: 083, Loss: 4.1776, Train: 0.9966, Valid: 0.9870, Best: 0.9882\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 4.1749372482299805 | KNN Loss: 4.171609878540039 | CLS Loss: 0.003327277721837163\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 4.189953327178955 | KNN Loss: 4.188063144683838 | CLS Loss: 0.0018903223099187016\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 4.165367126464844 | KNN Loss: 4.163295745849609 | CLS Loss: 0.00207160715945065\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 4.196134567260742 | KNN Loss: 4.1859941482543945 | CLS Loss: 0.01014041993767023\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 4.188238143920898 | KNN Loss: 4.173257350921631 | CLS Loss: 0.014980555512011051\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 4.118919372558594 | KNN Loss: 4.1176228523254395 | CLS Loss: 0.0012966367648914456\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 4.149631023406982 | KNN Loss: 4.138003349304199 | CLS Loss: 0.011627478525042534\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 4.156501770019531 | KNN Loss: 4.14876127243042 | CLS Loss: 0.00774063216522336\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 4.142652988433838 | KNN Loss: 4.136074542999268 | CLS Loss: 0.006578394211828709\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 4.129968166351318 | KNN Loss: 4.125530242919922 | CLS Loss: 0.004437769763171673\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 4.183507442474365 | KNN Loss: 4.171622276306152 | CLS Loss: 0.011884928680956364\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 4.2179083824157715 | KNN Loss: 4.208503246307373 | CLS Loss: 0.009405245073139668\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 4.169382095336914 | KNN Loss: 4.153563022613525 | CLS Loss: 0.01581888273358345\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 4.170961380004883 | KNN Loss: 4.157221794128418 | CLS Loss: 0.013739795424044132\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 4.150339603424072 | KNN Loss: 4.138070106506348 | CLS Loss: 0.012269603088498116\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 4.168360710144043 | KNN Loss: 4.159640789031982 | CLS Loss: 0.008719900622963905\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 4.227564811706543 | KNN Loss: 4.1888251304626465 | CLS Loss: 0.03873991593718529\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 4.186633110046387 | KNN Loss: 4.16898775100708 | CLS Loss: 0.017645321786403656\n",
      "Epoch: 084, Loss: 4.1753, Train: 0.9962, Valid: 0.9856, Best: 0.9882\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 4.16968297958374 | KNN Loss: 4.152843952178955 | CLS Loss: 0.016839005053043365\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 4.164645671844482 | KNN Loss: 4.160379409790039 | CLS Loss: 0.004266498144716024\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 4.151328086853027 | KNN Loss: 4.1448774337768555 | CLS Loss: 0.006450687535107136\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 4.142788887023926 | KNN Loss: 4.13681173324585 | CLS Loss: 0.005976916756480932\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 4.160027980804443 | KNN Loss: 4.152503490447998 | CLS Loss: 0.007524452637881041\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 4.200876235961914 | KNN Loss: 4.172679424285889 | CLS Loss: 0.028196794912219048\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 4.1965012550354 | KNN Loss: 4.167919635772705 | CLS Loss: 0.028581637889146805\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 4.1687164306640625 | KNN Loss: 4.159333229064941 | CLS Loss: 0.00938325747847557\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 4.183623313903809 | KNN Loss: 4.17758321762085 | CLS Loss: 0.006040284410119057\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 4.192100524902344 | KNN Loss: 4.17719841003418 | CLS Loss: 0.01490218285471201\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 4.155524730682373 | KNN Loss: 4.1425909996032715 | CLS Loss: 0.012933749705553055\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 4.193511486053467 | KNN Loss: 4.177942752838135 | CLS Loss: 0.015568622387945652\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 4.179270267486572 | KNN Loss: 4.1651153564453125 | CLS Loss: 0.014154881238937378\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 4.181952953338623 | KNN Loss: 4.163393020629883 | CLS Loss: 0.018560055643320084\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 4.199694633483887 | KNN Loss: 4.182484149932861 | CLS Loss: 0.01721067540347576\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 4.208916664123535 | KNN Loss: 4.186521530151367 | CLS Loss: 0.022395124658942223\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 4.169060707092285 | KNN Loss: 4.154334545135498 | CLS Loss: 0.01472616009414196\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 4.152194023132324 | KNN Loss: 4.139449119567871 | CLS Loss: 0.01274510845541954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 085, Loss: 4.1828, Train: 0.9967, Valid: 0.9861, Best: 0.9882\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 4.190130233764648 | KNN Loss: 4.1751532554626465 | CLS Loss: 0.014976749196648598\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 4.171115398406982 | KNN Loss: 4.158337593078613 | CLS Loss: 0.01277759950608015\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 4.154627323150635 | KNN Loss: 4.151052951812744 | CLS Loss: 0.0035743520129472017\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 4.193169593811035 | KNN Loss: 4.183012008666992 | CLS Loss: 0.010157492011785507\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 4.161135673522949 | KNN Loss: 4.155674934387207 | CLS Loss: 0.005460788030177355\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 4.141238212585449 | KNN Loss: 4.129074573516846 | CLS Loss: 0.012163816951215267\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 4.136568069458008 | KNN Loss: 4.132318496704102 | CLS Loss: 0.004249591380357742\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 4.179142475128174 | KNN Loss: 4.166026592254639 | CLS Loss: 0.01311570219695568\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 4.160694599151611 | KNN Loss: 4.152894020080566 | CLS Loss: 0.007800669874995947\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 4.141829013824463 | KNN Loss: 4.1389875411987305 | CLS Loss: 0.0028415482956916094\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 4.191629886627197 | KNN Loss: 4.178921222686768 | CLS Loss: 0.012708554044365883\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 4.192310810089111 | KNN Loss: 4.163764476776123 | CLS Loss: 0.02854623831808567\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 4.169770240783691 | KNN Loss: 4.145608425140381 | CLS Loss: 0.024161672219634056\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 4.164914131164551 | KNN Loss: 4.14714241027832 | CLS Loss: 0.01777184009552002\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 4.172928333282471 | KNN Loss: 4.152339935302734 | CLS Loss: 0.020588232204318047\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 4.149649620056152 | KNN Loss: 4.143661975860596 | CLS Loss: 0.005987419746816158\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 4.178233623504639 | KNN Loss: 4.152692794799805 | CLS Loss: 0.02554086595773697\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 4.205440521240234 | KNN Loss: 4.180961608886719 | CLS Loss: 0.024478968232870102\n",
      "Epoch: 086, Loss: 4.1814, Train: 0.9967, Valid: 0.9878, Best: 0.9882\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 4.146648406982422 | KNN Loss: 4.140581130981445 | CLS Loss: 0.006067355163395405\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 4.167444229125977 | KNN Loss: 4.158092021942139 | CLS Loss: 0.009352223016321659\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 4.19759464263916 | KNN Loss: 4.190300464630127 | CLS Loss: 0.007294015027582645\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 4.192431926727295 | KNN Loss: 4.186530113220215 | CLS Loss: 0.005901939235627651\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 4.17123556137085 | KNN Loss: 4.149289608001709 | CLS Loss: 0.021946169435977936\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 4.189536094665527 | KNN Loss: 4.1728434562683105 | CLS Loss: 0.01669263280928135\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 4.1733245849609375 | KNN Loss: 4.171939849853516 | CLS Loss: 0.001384963863529265\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 4.130333423614502 | KNN Loss: 4.124019145965576 | CLS Loss: 0.00631416030228138\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 4.160473346710205 | KNN Loss: 4.156909942626953 | CLS Loss: 0.0035632792860269547\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 4.188380241394043 | KNN Loss: 4.174357891082764 | CLS Loss: 0.014022544957697392\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 4.210930347442627 | KNN Loss: 4.192097187042236 | CLS Loss: 0.018832989037036896\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 4.209698677062988 | KNN Loss: 4.199384689331055 | CLS Loss: 0.010313834995031357\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 4.16778039932251 | KNN Loss: 4.160953044891357 | CLS Loss: 0.0068271872587502\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 4.1886138916015625 | KNN Loss: 4.172364234924316 | CLS Loss: 0.016249598935246468\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 4.160439968109131 | KNN Loss: 4.15512228012085 | CLS Loss: 0.0053177871741354465\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 4.169637203216553 | KNN Loss: 4.156542778015137 | CLS Loss: 0.013094531372189522\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 4.164349555969238 | KNN Loss: 4.147541522979736 | CLS Loss: 0.016808271408081055\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 4.153538703918457 | KNN Loss: 4.142502784729004 | CLS Loss: 0.011035759001970291\n",
      "Epoch: 087, Loss: 4.1749, Train: 0.9946, Valid: 0.9847, Best: 0.9882\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 4.173888683319092 | KNN Loss: 4.163446426391602 | CLS Loss: 0.010442184284329414\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 4.171552658081055 | KNN Loss: 4.153751850128174 | CLS Loss: 0.017800848931074142\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 4.182774543762207 | KNN Loss: 4.162043571472168 | CLS Loss: 0.02073081210255623\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 4.156259536743164 | KNN Loss: 4.152947902679443 | CLS Loss: 0.0033114789985120296\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 4.147972583770752 | KNN Loss: 4.144861698150635 | CLS Loss: 0.0031110646668821573\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 4.209543228149414 | KNN Loss: 4.1955976486206055 | CLS Loss: 0.013945575803518295\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 4.178700923919678 | KNN Loss: 4.160109043121338 | CLS Loss: 0.01859181374311447\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 4.185337543487549 | KNN Loss: 4.175508975982666 | CLS Loss: 0.009828628972172737\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 4.189663410186768 | KNN Loss: 4.177764415740967 | CLS Loss: 0.011899025179445744\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 4.179506778717041 | KNN Loss: 4.1653733253479 | CLS Loss: 0.014133651740849018\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 4.138657093048096 | KNN Loss: 4.129281520843506 | CLS Loss: 0.00937556754797697\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 4.170989513397217 | KNN Loss: 4.16298246383667 | CLS Loss: 0.008006878197193146\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 4.183273792266846 | KNN Loss: 4.168727397918701 | CLS Loss: 0.014546207152307034\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 4.199984550476074 | KNN Loss: 4.18324089050293 | CLS Loss: 0.01674351654946804\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 4.181359767913818 | KNN Loss: 4.161415100097656 | CLS Loss: 0.019944878295063972\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 4.173120498657227 | KNN Loss: 4.168799877166748 | CLS Loss: 0.004320490639656782\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 4.136977672576904 | KNN Loss: 4.132161617279053 | CLS Loss: 0.00481616985052824\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 4.1614909172058105 | KNN Loss: 4.150484561920166 | CLS Loss: 0.011006299406290054\n",
      "Epoch: 088, Loss: 4.1807, Train: 0.9963, Valid: 0.9856, Best: 0.9882\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 4.184041500091553 | KNN Loss: 4.158941268920898 | CLS Loss: 0.025100018829107285\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 4.214814186096191 | KNN Loss: 4.196941375732422 | CLS Loss: 0.017872881144285202\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 4.15572452545166 | KNN Loss: 4.152158260345459 | CLS Loss: 0.003566133324056864\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 4.153182506561279 | KNN Loss: 4.149152755737305 | CLS Loss: 0.004029606468975544\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 4.20025110244751 | KNN Loss: 4.199128150939941 | CLS Loss: 0.0011230572126805782\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 4.141855716705322 | KNN Loss: 4.137770175933838 | CLS Loss: 0.004085398279130459\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dfa1649219a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#     print(f\"Loss: {loss} =============================\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7ccbd69308b5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mknn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_crt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mknn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EntangledExplainableClustering/losses/knn_loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mneighbors_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mdistances_wo_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9873)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a1bfa3f8904579a5196424605b9e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2a41afafcd4466b0555ed494929fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d9f653b20c4faab9650774872dbeb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5809d3735f145faa16059559f9ec8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729e125dcedc489a85771ad586ae0dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.9535425517335891\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbf3a74672446a8a93072f55c7988dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "layer 7: 0.0\n",
      "layer 8: 0.0\n",
      "layer 9: 0.0\n",
      "layer 10: 0.0\n",
      "Epoch: 00 | Batch: 000 / 041 | Total loss: 1.802 | Reg loss: 0.014 | Tree loss: 1.802 | Accuracy: 0.035156 | 7.411 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 01 | Batch: 000 / 041 | Total loss: 1.663 | Reg loss: 0.005 | Tree loss: 1.663 | Accuracy: 0.906250 | 6.875 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 02 | Batch: 000 / 041 | Total loss: 1.586 | Reg loss: 0.008 | Tree loss: 1.586 | Accuracy: 0.917969 | 6.881 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 03 | Batch: 000 / 041 | Total loss: 1.502 | Reg loss: 0.010 | Tree loss: 1.502 | Accuracy: 0.910156 | 6.945 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 04 | Batch: 000 / 041 | Total loss: 1.390 | Reg loss: 0.011 | Tree loss: 1.390 | Accuracy: 0.917969 | 6.938 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 05 | Batch: 000 / 041 | Total loss: 1.288 | Reg loss: 0.012 | Tree loss: 1.288 | Accuracy: 0.904297 | 6.958 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 06 | Batch: 000 / 041 | Total loss: 1.184 | Reg loss: 0.013 | Tree loss: 1.184 | Accuracy: 0.898438 | 6.964 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 07 | Batch: 000 / 041 | Total loss: 1.053 | Reg loss: 0.014 | Tree loss: 1.053 | Accuracy: 0.925781 | 6.977 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 08 | Batch: 000 / 041 | Total loss: 0.973 | Reg loss: 0.014 | Tree loss: 0.973 | Accuracy: 0.912109 | 6.952 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 09 | Batch: 000 / 041 | Total loss: 0.927 | Reg loss: 0.015 | Tree loss: 0.927 | Accuracy: 0.919922 | 6.959 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 10 | Batch: 000 / 041 | Total loss: 0.842 | Reg loss: 0.015 | Tree loss: 0.842 | Accuracy: 0.923828 | 6.963 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 11 | Batch: 000 / 041 | Total loss: 0.776 | Reg loss: 0.016 | Tree loss: 0.776 | Accuracy: 0.906250 | 6.95 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 12 | Batch: 000 / 041 | Total loss: 0.710 | Reg loss: 0.016 | Tree loss: 0.710 | Accuracy: 0.916016 | 6.944 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 13 | Batch: 000 / 041 | Total loss: 0.731 | Reg loss: 0.016 | Tree loss: 0.731 | Accuracy: 0.878906 | 6.947 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 14 | Batch: 000 / 041 | Total loss: 0.668 | Reg loss: 0.016 | Tree loss: 0.668 | Accuracy: 0.898438 | 6.946 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 15 | Batch: 000 / 041 | Total loss: 0.673 | Reg loss: 0.016 | Tree loss: 0.673 | Accuracy: 0.904297 | 6.958 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 16 | Batch: 000 / 041 | Total loss: 0.583 | Reg loss: 0.017 | Tree loss: 0.583 | Accuracy: 0.919922 | 6.97 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 17 | Batch: 000 / 041 | Total loss: 0.606 | Reg loss: 0.017 | Tree loss: 0.606 | Accuracy: 0.902344 | 6.973 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 18 | Batch: 000 / 041 | Total loss: 0.590 | Reg loss: 0.017 | Tree loss: 0.590 | Accuracy: 0.896484 | 6.979 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 19 | Batch: 000 / 041 | Total loss: 0.558 | Reg loss: 0.017 | Tree loss: 0.558 | Accuracy: 0.912109 | 6.984 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 20 | Batch: 000 / 041 | Total loss: 0.540 | Reg loss: 0.017 | Tree loss: 0.540 | Accuracy: 0.916016 | 6.982 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 21 | Batch: 000 / 041 | Total loss: 0.511 | Reg loss: 0.017 | Tree loss: 0.511 | Accuracy: 0.923828 | 6.986 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 22 | Batch: 000 / 041 | Total loss: 0.581 | Reg loss: 0.017 | Tree loss: 0.581 | Accuracy: 0.900391 | 6.98 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 23 | Batch: 000 / 041 | Total loss: 0.540 | Reg loss: 0.017 | Tree loss: 0.540 | Accuracy: 0.917969 | 6.977 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 24 | Batch: 000 / 041 | Total loss: 0.584 | Reg loss: 0.017 | Tree loss: 0.584 | Accuracy: 0.898438 | 6.978 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 25 | Batch: 000 / 041 | Total loss: 0.522 | Reg loss: 0.017 | Tree loss: 0.522 | Accuracy: 0.904297 | 6.98 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 26 | Batch: 000 / 041 | Total loss: 0.586 | Reg loss: 0.017 | Tree loss: 0.586 | Accuracy: 0.894531 | 6.979 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 27 | Batch: 000 / 041 | Total loss: 0.538 | Reg loss: 0.017 | Tree loss: 0.538 | Accuracy: 0.908203 | 6.981 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 28 | Batch: 000 / 041 | Total loss: 0.615 | Reg loss: 0.017 | Tree loss: 0.615 | Accuracy: 0.888672 | 6.985 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 29 | Batch: 000 / 041 | Total loss: 0.555 | Reg loss: 0.017 | Tree loss: 0.555 | Accuracy: 0.904297 | 6.982 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 30 | Batch: 000 / 041 | Total loss: 0.535 | Reg loss: 0.017 | Tree loss: 0.535 | Accuracy: 0.896484 | 6.983 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 31 | Batch: 000 / 041 | Total loss: 0.518 | Reg loss: 0.017 | Tree loss: 0.518 | Accuracy: 0.906250 | 6.983 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 32 | Batch: 000 / 041 | Total loss: 0.539 | Reg loss: 0.017 | Tree loss: 0.539 | Accuracy: 0.906250 | 6.977 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 33 | Batch: 000 / 041 | Total loss: 0.511 | Reg loss: 0.017 | Tree loss: 0.511 | Accuracy: 0.916016 | 6.974 sec/iter\n",
      "Average sparseness: 0.9840425531914895\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "layer 9: 0.9840425531914895\n",
      "layer 10: 0.9840425531914895\n",
      "Epoch: 34 | Batch: 000 / 041 | Total loss: 0.575 | Reg loss: 0.017 | Tree loss: 0.575 | Accuracy: 0.898438 | 6.972 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
