{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "tree_depth = 10\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.200286865234375 | KNN Loss: 5.570528030395508 | CLS Loss: 1.629758596420288\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 4.334754467010498 | KNN Loss: 2.962836265563965 | CLS Loss: 1.3719182014465332\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 3.275571346282959 | KNN Loss: 2.6373131275177 | CLS Loss: 0.6382583379745483\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 3.2182888984680176 | KNN Loss: 2.552614212036133 | CLS Loss: 0.6656746864318848\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 3.1036977767944336 | KNN Loss: 2.5522866249084473 | CLS Loss: 0.5514110922813416\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 3.072950839996338 | KNN Loss: 2.5594332218170166 | CLS Loss: 0.5135177373886108\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 3.1318154335021973 | KNN Loss: 2.584388017654419 | CLS Loss: 0.5474274754524231\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 3.086531162261963 | KNN Loss: 2.600828170776367 | CLS Loss: 0.4857029914855957\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 3.050967216491699 | KNN Loss: 2.530792713165283 | CLS Loss: 0.5201745629310608\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 3.0693938732147217 | KNN Loss: 2.539116144180298 | CLS Loss: 0.530277669429779\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 2.9734549522399902 | KNN Loss: 2.5749833583831787 | CLS Loss: 0.39847153425216675\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 2.9294726848602295 | KNN Loss: 2.5584716796875 | CLS Loss: 0.37100109457969666\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 2.95113205909729 | KNN Loss: 2.5348846912384033 | CLS Loss: 0.4162473976612091\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 2.88702654838562 | KNN Loss: 2.5142126083374023 | CLS Loss: 0.372813880443573\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 2.8992059230804443 | KNN Loss: 2.545562744140625 | CLS Loss: 0.3536430895328522\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 2.8965418338775635 | KNN Loss: 2.5450143814086914 | CLS Loss: 0.35152751207351685\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 2.8724205493927 | KNN Loss: 2.550158977508545 | CLS Loss: 0.3222615122795105\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 2.874228000640869 | KNN Loss: 2.5673887729644775 | CLS Loss: 0.30683934688568115\n",
      "Epoch: 001, Loss: 3.2134, Train: 0.9194, Valid: 0.9201, Best: 0.9201\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 2.837735176086426 | KNN Loss: 2.5583982467651367 | CLS Loss: 0.2793370485305786\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 2.8299994468688965 | KNN Loss: 2.540825366973877 | CLS Loss: 0.28917399048805237\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 2.8698806762695312 | KNN Loss: 2.556692123413086 | CLS Loss: 0.3131885528564453\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 2.8751025199890137 | KNN Loss: 2.5192480087280273 | CLS Loss: 0.35585442185401917\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 2.820089817047119 | KNN Loss: 2.534524917602539 | CLS Loss: 0.2855648994445801\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 2.818516254425049 | KNN Loss: 2.5849156379699707 | CLS Loss: 0.23360052704811096\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 2.8345746994018555 | KNN Loss: 2.561408758163452 | CLS Loss: 0.27316591143608093\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 2.815385341644287 | KNN Loss: 2.5534534454345703 | CLS Loss: 0.2619319558143616\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 2.8347251415252686 | KNN Loss: 2.592802047729492 | CLS Loss: 0.24192307889461517\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 2.852928638458252 | KNN Loss: 2.5629637241363525 | CLS Loss: 0.289964884519577\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 2.8248701095581055 | KNN Loss: 2.584733486175537 | CLS Loss: 0.24013668298721313\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 2.7896718978881836 | KNN Loss: 2.5246198177337646 | CLS Loss: 0.26505205035209656\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 2.754944324493408 | KNN Loss: 2.5678014755249023 | CLS Loss: 0.1871427595615387\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 2.7634241580963135 | KNN Loss: 2.5259387493133545 | CLS Loss: 0.23748548328876495\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 2.751046895980835 | KNN Loss: 2.5425641536712646 | CLS Loss: 0.2084827721118927\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 2.713794231414795 | KNN Loss: 2.5273449420928955 | CLS Loss: 0.18644925951957703\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 2.737111806869507 | KNN Loss: 2.557971239089966 | CLS Loss: 0.17914064228534698\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 2.7199034690856934 | KNN Loss: 2.541550397872925 | CLS Loss: 0.17835310101509094\n",
      "Epoch: 002, Loss: 2.7971, Train: 0.9396, Valid: 0.9388, Best: 0.9388\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 2.7321157455444336 | KNN Loss: 2.474750280380249 | CLS Loss: 0.25736546516418457\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 2.8028087615966797 | KNN Loss: 2.5343034267425537 | CLS Loss: 0.2685052752494812\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 2.712451219558716 | KNN Loss: 2.4967281818389893 | CLS Loss: 0.2157229632139206\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 2.779477596282959 | KNN Loss: 2.4963014125823975 | CLS Loss: 0.28317612409591675\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 2.683166265487671 | KNN Loss: 2.5067861080169678 | CLS Loss: 0.17638015747070312\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 2.7036666870117188 | KNN Loss: 2.4857840538024902 | CLS Loss: 0.21788254380226135\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 2.7705142498016357 | KNN Loss: 2.5151171684265137 | CLS Loss: 0.2553970217704773\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 2.6946029663085938 | KNN Loss: 2.4800631999969482 | CLS Loss: 0.21453972160816193\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 2.7152087688446045 | KNN Loss: 2.5461690425872803 | CLS Loss: 0.16903971135616302\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 2.735790252685547 | KNN Loss: 2.513542413711548 | CLS Loss: 0.22224780917167664\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 2.6914072036743164 | KNN Loss: 2.4817867279052734 | CLS Loss: 0.20962047576904297\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 2.6917176246643066 | KNN Loss: 2.5204710960388184 | CLS Loss: 0.1712464839220047\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 2.69728684425354 | KNN Loss: 2.4864189624786377 | CLS Loss: 0.21086785197257996\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 2.6821460723876953 | KNN Loss: 2.5047407150268555 | CLS Loss: 0.1774054765701294\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 2.6486635208129883 | KNN Loss: 2.486254930496216 | CLS Loss: 0.16240854561328888\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 2.6367990970611572 | KNN Loss: 2.520200490951538 | CLS Loss: 0.11659859865903854\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 2.6875216960906982 | KNN Loss: 2.4753470420837402 | CLS Loss: 0.21217454969882965\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 2.6500673294067383 | KNN Loss: 2.524427890777588 | CLS Loss: 0.12563946843147278\n",
      "Epoch: 003, Loss: 2.6979, Train: 0.9571, Valid: 0.9558, Best: 0.9558\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 2.63851261138916 | KNN Loss: 2.501574993133545 | CLS Loss: 0.1369377076625824\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 2.6396279335021973 | KNN Loss: 2.5024569034576416 | CLS Loss: 0.13717110455036163\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 2.6313066482543945 | KNN Loss: 2.4779882431030273 | CLS Loss: 0.1533183604478836\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 2.6344316005706787 | KNN Loss: 2.4957549571990967 | CLS Loss: 0.13867655396461487\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 2.6226589679718018 | KNN Loss: 2.463252067565918 | CLS Loss: 0.1594068855047226\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 2.660752534866333 | KNN Loss: 2.4825358390808105 | CLS Loss: 0.17821674048900604\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 2.679415225982666 | KNN Loss: 2.474447250366211 | CLS Loss: 0.2049679160118103\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 2.6910347938537598 | KNN Loss: 2.533658266067505 | CLS Loss: 0.15737661719322205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 2.577674388885498 | KNN Loss: 2.4594333171844482 | CLS Loss: 0.11824096739292145\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 2.6667587757110596 | KNN Loss: 2.52266788482666 | CLS Loss: 0.14409081637859344\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 2.6705310344696045 | KNN Loss: 2.476156711578369 | CLS Loss: 0.19437432289123535\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 2.605355739593506 | KNN Loss: 2.477708578109741 | CLS Loss: 0.127647265791893\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 2.6377131938934326 | KNN Loss: 2.461115837097168 | CLS Loss: 0.176597461104393\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 2.645249605178833 | KNN Loss: 2.4669461250305176 | CLS Loss: 0.17830350995063782\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 2.6023247241973877 | KNN Loss: 2.5080676078796387 | CLS Loss: 0.09425705671310425\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 2.5906553268432617 | KNN Loss: 2.468564748764038 | CLS Loss: 0.12209063768386841\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 2.5992612838745117 | KNN Loss: 2.4844260215759277 | CLS Loss: 0.11483532190322876\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 2.5917775630950928 | KNN Loss: 2.475414991378784 | CLS Loss: 0.11636250466108322\n",
      "Epoch: 004, Loss: 2.6292, Train: 0.9667, Valid: 0.9651, Best: 0.9651\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 2.600111961364746 | KNN Loss: 2.4991374015808105 | CLS Loss: 0.10097464919090271\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 2.608602523803711 | KNN Loss: 2.4868767261505127 | CLS Loss: 0.12172583490610123\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 2.5866189002990723 | KNN Loss: 2.490325689315796 | CLS Loss: 0.09629325568675995\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 2.6418683528900146 | KNN Loss: 2.494720458984375 | CLS Loss: 0.14714789390563965\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 2.648531436920166 | KNN Loss: 2.4872686862945557 | CLS Loss: 0.16126273572444916\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 2.5968995094299316 | KNN Loss: 2.4886727333068848 | CLS Loss: 0.10822684317827225\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 2.6096720695495605 | KNN Loss: 2.463862180709839 | CLS Loss: 0.14580987393856049\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 2.608480930328369 | KNN Loss: 2.449251651763916 | CLS Loss: 0.15922920405864716\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 2.624764919281006 | KNN Loss: 2.516631841659546 | CLS Loss: 0.10813312977552414\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 2.586486339569092 | KNN Loss: 2.476985454559326 | CLS Loss: 0.10950098186731339\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 2.5638928413391113 | KNN Loss: 2.4562020301818848 | CLS Loss: 0.10769069939851761\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 2.5581202507019043 | KNN Loss: 2.4509923458099365 | CLS Loss: 0.10712790489196777\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 2.5694174766540527 | KNN Loss: 2.40651535987854 | CLS Loss: 0.16290223598480225\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 2.587960958480835 | KNN Loss: 2.4612228870391846 | CLS Loss: 0.1267380267381668\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 2.596733570098877 | KNN Loss: 2.4840264320373535 | CLS Loss: 0.11270704865455627\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 2.595489740371704 | KNN Loss: 2.4698057174682617 | CLS Loss: 0.12568402290344238\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 2.5631332397460938 | KNN Loss: 2.466315984725952 | CLS Loss: 0.09681717306375504\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 2.601938247680664 | KNN Loss: 2.4779281616210938 | CLS Loss: 0.12401019781827927\n",
      "Epoch: 005, Loss: 2.5984, Train: 0.9678, Valid: 0.9661, Best: 0.9661\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 2.533747673034668 | KNN Loss: 2.449937582015991 | CLS Loss: 0.08380997180938721\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 2.593409776687622 | KNN Loss: 2.467200756072998 | CLS Loss: 0.12620902061462402\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 2.565208673477173 | KNN Loss: 2.4470183849334717 | CLS Loss: 0.11819027364253998\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 2.6017117500305176 | KNN Loss: 2.4959611892700195 | CLS Loss: 0.10575047135353088\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 2.5557563304901123 | KNN Loss: 2.4634077548980713 | CLS Loss: 0.092348612844944\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 2.558259963989258 | KNN Loss: 2.4314165115356445 | CLS Loss: 0.12684348225593567\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 2.5434517860412598 | KNN Loss: 2.427375078201294 | CLS Loss: 0.11607670038938522\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 2.5758752822875977 | KNN Loss: 2.4539666175842285 | CLS Loss: 0.12190864980220795\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 2.588405132293701 | KNN Loss: 2.4636857509613037 | CLS Loss: 0.12471947073936462\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 2.532093048095703 | KNN Loss: 2.4452059268951416 | CLS Loss: 0.08688724040985107\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 2.5521416664123535 | KNN Loss: 2.426032543182373 | CLS Loss: 0.1261090487241745\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 2.565746784210205 | KNN Loss: 2.442915916442871 | CLS Loss: 0.12283087521791458\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 2.5698890686035156 | KNN Loss: 2.4680190086364746 | CLS Loss: 0.1018700823187828\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 2.51566481590271 | KNN Loss: 2.4269027709960938 | CLS Loss: 0.08876200020313263\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 2.572533369064331 | KNN Loss: 2.447089195251465 | CLS Loss: 0.1254441738128662\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 2.5624940395355225 | KNN Loss: 2.4451375007629395 | CLS Loss: 0.11735642701387405\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 2.557319164276123 | KNN Loss: 2.437220335006714 | CLS Loss: 0.12009876221418381\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 2.5680861473083496 | KNN Loss: 2.460848808288574 | CLS Loss: 0.10723723471164703\n",
      "Epoch: 006, Loss: 2.5674, Train: 0.9751, Valid: 0.9716, Best: 0.9716\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 2.549851417541504 | KNN Loss: 2.4483633041381836 | CLS Loss: 0.10148806124925613\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 2.52588152885437 | KNN Loss: 2.445173740386963 | CLS Loss: 0.08070780336856842\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 2.543036937713623 | KNN Loss: 2.478496789932251 | CLS Loss: 0.06454009562730789\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 2.5628902912139893 | KNN Loss: 2.4407644271850586 | CLS Loss: 0.12212575972080231\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 2.5560479164123535 | KNN Loss: 2.453706979751587 | CLS Loss: 0.10234091430902481\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 2.56669020652771 | KNN Loss: 2.4266629219055176 | CLS Loss: 0.1400272101163864\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 2.578460693359375 | KNN Loss: 2.449052333831787 | CLS Loss: 0.1294083297252655\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 2.552130699157715 | KNN Loss: 2.453246831893921 | CLS Loss: 0.09888393431901932\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 2.5439367294311523 | KNN Loss: 2.4588608741760254 | CLS Loss: 0.08507596701383591\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 2.515359878540039 | KNN Loss: 2.452845573425293 | CLS Loss: 0.06251421570777893\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 2.563382387161255 | KNN Loss: 2.4425578117370605 | CLS Loss: 0.12082462012767792\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 2.580573320388794 | KNN Loss: 2.4763600826263428 | CLS Loss: 0.1042131632566452\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 2.53798246383667 | KNN Loss: 2.4830689430236816 | CLS Loss: 0.05491358041763306\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 2.4928061962127686 | KNN Loss: 2.4124538898468018 | CLS Loss: 0.08035223931074142\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 2.532939910888672 | KNN Loss: 2.451944589614868 | CLS Loss: 0.08099541813135147\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 2.567652702331543 | KNN Loss: 2.444535732269287 | CLS Loss: 0.12311707437038422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 2.548036575317383 | KNN Loss: 2.425438404083252 | CLS Loss: 0.12259820103645325\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 2.602889060974121 | KNN Loss: 2.4497108459472656 | CLS Loss: 0.1531781554222107\n",
      "Epoch: 007, Loss: 2.5477, Train: 0.9756, Valid: 0.9728, Best: 0.9728\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 2.501044273376465 | KNN Loss: 2.4234397411346436 | CLS Loss: 0.07760453969240189\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 2.5922679901123047 | KNN Loss: 2.467078447341919 | CLS Loss: 0.1251896321773529\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 2.538774251937866 | KNN Loss: 2.4373648166656494 | CLS Loss: 0.10140953212976456\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 2.5473005771636963 | KNN Loss: 2.436347007751465 | CLS Loss: 0.11095353960990906\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 2.5847597122192383 | KNN Loss: 2.475551128387451 | CLS Loss: 0.10920850187540054\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 2.497725248336792 | KNN Loss: 2.4267210960388184 | CLS Loss: 0.07100406289100647\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 2.5270750522613525 | KNN Loss: 2.430826425552368 | CLS Loss: 0.096248559653759\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 2.5413753986358643 | KNN Loss: 2.443514108657837 | CLS Loss: 0.09786117821931839\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 2.5728132724761963 | KNN Loss: 2.41894268989563 | CLS Loss: 0.15387047827243805\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 2.5330731868743896 | KNN Loss: 2.452988862991333 | CLS Loss: 0.08008421957492828\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 2.5322165489196777 | KNN Loss: 2.4521172046661377 | CLS Loss: 0.08009926229715347\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 2.495023727416992 | KNN Loss: 2.451345205307007 | CLS Loss: 0.04367857798933983\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 2.5346319675445557 | KNN Loss: 2.4283227920532227 | CLS Loss: 0.10630907118320465\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 2.5143048763275146 | KNN Loss: 2.423809289932251 | CLS Loss: 0.09049562364816666\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 2.5159506797790527 | KNN Loss: 2.470975637435913 | CLS Loss: 0.04497513920068741\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 2.5197765827178955 | KNN Loss: 2.3885161876678467 | CLS Loss: 0.1312604397535324\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 2.5095362663269043 | KNN Loss: 2.4308629035949707 | CLS Loss: 0.07867325097322464\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 2.545321464538574 | KNN Loss: 2.4141762256622314 | CLS Loss: 0.13114535808563232\n",
      "Epoch: 008, Loss: 2.5294, Train: 0.9769, Valid: 0.9750, Best: 0.9750\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 2.5418834686279297 | KNN Loss: 2.4502458572387695 | CLS Loss: 0.09163753688335419\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 2.5608928203582764 | KNN Loss: 2.4773306846618652 | CLS Loss: 0.08356205374002457\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 2.5248939990997314 | KNN Loss: 2.4253435134887695 | CLS Loss: 0.09955059736967087\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 2.5256879329681396 | KNN Loss: 2.431612730026245 | CLS Loss: 0.09407509118318558\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 2.5033655166625977 | KNN Loss: 2.4408016204833984 | CLS Loss: 0.06256385147571564\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 2.4943060874938965 | KNN Loss: 2.4072539806365967 | CLS Loss: 0.08705213665962219\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 2.5250768661499023 | KNN Loss: 2.4324452877044678 | CLS Loss: 0.09263154119253159\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 2.537997245788574 | KNN Loss: 2.4364781379699707 | CLS Loss: 0.10151904821395874\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 2.5139896869659424 | KNN Loss: 2.437345504760742 | CLS Loss: 0.07664414495229721\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 2.5483622550964355 | KNN Loss: 2.44384503364563 | CLS Loss: 0.10451716184616089\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 2.497279405593872 | KNN Loss: 2.4071075916290283 | CLS Loss: 0.09017182886600494\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 2.4945712089538574 | KNN Loss: 2.432898759841919 | CLS Loss: 0.061672329902648926\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 2.4794156551361084 | KNN Loss: 2.423981189727783 | CLS Loss: 0.05543449893593788\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 2.5144002437591553 | KNN Loss: 2.428986072540283 | CLS Loss: 0.0854141116142273\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 2.487847328186035 | KNN Loss: 2.446950912475586 | CLS Loss: 0.04089647904038429\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 2.5004594326019287 | KNN Loss: 2.409684419631958 | CLS Loss: 0.09077510982751846\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 2.501067638397217 | KNN Loss: 2.4027652740478516 | CLS Loss: 0.0983024463057518\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 2.498769760131836 | KNN Loss: 2.4159774780273438 | CLS Loss: 0.0827922523021698\n",
      "Epoch: 009, Loss: 2.5207, Train: 0.9781, Valid: 0.9754, Best: 0.9754\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 2.482339859008789 | KNN Loss: 2.3805079460144043 | CLS Loss: 0.10183180123567581\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 2.5033764839172363 | KNN Loss: 2.4328854084014893 | CLS Loss: 0.07049105316400528\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 2.503192186355591 | KNN Loss: 2.430467367172241 | CLS Loss: 0.07272480428218842\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 2.514571189880371 | KNN Loss: 2.4303369522094727 | CLS Loss: 0.08423417806625366\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 2.477234125137329 | KNN Loss: 2.3927719593048096 | CLS Loss: 0.0844622403383255\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 2.4699320793151855 | KNN Loss: 2.410815715789795 | CLS Loss: 0.05911632254719734\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 2.5011839866638184 | KNN Loss: 2.413174629211426 | CLS Loss: 0.08800933510065079\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 2.5089194774627686 | KNN Loss: 2.4313671588897705 | CLS Loss: 0.07755225896835327\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 2.490185260772705 | KNN Loss: 2.388448476791382 | CLS Loss: 0.10173670202493668\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 2.516511917114258 | KNN Loss: 2.433187246322632 | CLS Loss: 0.08332467079162598\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 2.487765073776245 | KNN Loss: 2.4154889583587646 | CLS Loss: 0.07227613776922226\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 2.4978723526000977 | KNN Loss: 2.415372610092163 | CLS Loss: 0.0824996754527092\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 2.520902395248413 | KNN Loss: 2.4380059242248535 | CLS Loss: 0.08289649337530136\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 2.5416553020477295 | KNN Loss: 2.4167940616607666 | CLS Loss: 0.12486118823289871\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 2.517916202545166 | KNN Loss: 2.4404804706573486 | CLS Loss: 0.07743581384420395\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 2.493460178375244 | KNN Loss: 2.396040916442871 | CLS Loss: 0.09741928428411484\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 2.5133705139160156 | KNN Loss: 2.4457287788391113 | CLS Loss: 0.06764180213212967\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 2.5547094345092773 | KNN Loss: 2.4505245685577393 | CLS Loss: 0.10418489575386047\n",
      "Epoch: 010, Loss: 2.5096, Train: 0.9803, Valid: 0.9774, Best: 0.9774\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 2.5366482734680176 | KNN Loss: 2.460622549057007 | CLS Loss: 0.07602567225694656\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 2.499598503112793 | KNN Loss: 2.431708812713623 | CLS Loss: 0.06788962334394455\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 2.485588788986206 | KNN Loss: 2.417680263519287 | CLS Loss: 0.06790844351053238\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 2.510525941848755 | KNN Loss: 2.423748016357422 | CLS Loss: 0.08677792549133301\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 2.512871503829956 | KNN Loss: 2.455044746398926 | CLS Loss: 0.05782686173915863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 2.505141258239746 | KNN Loss: 2.4568467140197754 | CLS Loss: 0.04829449579119682\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 2.4942829608917236 | KNN Loss: 2.391362190246582 | CLS Loss: 0.10292084515094757\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 2.4991743564605713 | KNN Loss: 2.4225046634674072 | CLS Loss: 0.07666979730129242\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 2.461980104446411 | KNN Loss: 2.391669750213623 | CLS Loss: 0.07031026482582092\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 2.5431132316589355 | KNN Loss: 2.470979928970337 | CLS Loss: 0.07213333249092102\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 2.5163300037384033 | KNN Loss: 2.440521001815796 | CLS Loss: 0.07580895721912384\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 2.4715356826782227 | KNN Loss: 2.4231200218200684 | CLS Loss: 0.04841567203402519\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 2.4814271926879883 | KNN Loss: 2.4418323040008545 | CLS Loss: 0.03959500044584274\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 2.5180325508117676 | KNN Loss: 2.4361565113067627 | CLS Loss: 0.08187608420848846\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 2.5043163299560547 | KNN Loss: 2.4357223510742188 | CLS Loss: 0.06859397888183594\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 2.5397725105285645 | KNN Loss: 2.4323952198028564 | CLS Loss: 0.10737727582454681\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 2.4892287254333496 | KNN Loss: 2.4054434299468994 | CLS Loss: 0.08378525823354721\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 2.5130040645599365 | KNN Loss: 2.4290480613708496 | CLS Loss: 0.08395598083734512\n",
      "Epoch: 011, Loss: 2.5030, Train: 0.9803, Valid: 0.9775, Best: 0.9775\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 2.4657399654388428 | KNN Loss: 2.419362783432007 | CLS Loss: 0.0463772751390934\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 2.4778761863708496 | KNN Loss: 2.3967485427856445 | CLS Loss: 0.08112754672765732\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 2.4858782291412354 | KNN Loss: 2.384077548980713 | CLS Loss: 0.10180065780878067\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 2.4992518424987793 | KNN Loss: 2.4300122261047363 | CLS Loss: 0.06923962384462357\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 2.4814321994781494 | KNN Loss: 2.394117832183838 | CLS Loss: 0.08731439709663391\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 2.4580745697021484 | KNN Loss: 2.4210779666900635 | CLS Loss: 0.0369965136051178\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 2.4977800846099854 | KNN Loss: 2.4210290908813477 | CLS Loss: 0.07675108313560486\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 2.486339807510376 | KNN Loss: 2.4012601375579834 | CLS Loss: 0.0850796326994896\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 2.4827301502227783 | KNN Loss: 2.422804594039917 | CLS Loss: 0.05992565304040909\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 2.581207036972046 | KNN Loss: 2.4906201362609863 | CLS Loss: 0.09058678895235062\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 2.50173020362854 | KNN Loss: 2.408008098602295 | CLS Loss: 0.09372220188379288\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 2.5677425861358643 | KNN Loss: 2.456195116043091 | CLS Loss: 0.1115475445985794\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 2.4835045337677 | KNN Loss: 2.4257616996765137 | CLS Loss: 0.05774274840950966\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 2.520648241043091 | KNN Loss: 2.4459261894226074 | CLS Loss: 0.074722059071064\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 2.4970030784606934 | KNN Loss: 2.402968406677246 | CLS Loss: 0.09403463453054428\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 2.484093427658081 | KNN Loss: 2.4468040466308594 | CLS Loss: 0.03728947788476944\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 2.449744701385498 | KNN Loss: 2.386042356491089 | CLS Loss: 0.06370237469673157\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 2.484769105911255 | KNN Loss: 2.4222466945648193 | CLS Loss: 0.06252229958772659\n",
      "Epoch: 012, Loss: 2.4930, Train: 0.9827, Valid: 0.9793, Best: 0.9793\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 2.4883482456207275 | KNN Loss: 2.4236862659454346 | CLS Loss: 0.06466198712587357\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 2.510585308074951 | KNN Loss: 2.4356400966644287 | CLS Loss: 0.07494509965181351\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 2.470081090927124 | KNN Loss: 2.4144556522369385 | CLS Loss: 0.055625345557928085\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 2.482924699783325 | KNN Loss: 2.4256725311279297 | CLS Loss: 0.05725209787487984\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 2.48276686668396 | KNN Loss: 2.4320826530456543 | CLS Loss: 0.05068414285778999\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 2.490487575531006 | KNN Loss: 2.438265323638916 | CLS Loss: 0.05222231149673462\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 2.5127334594726562 | KNN Loss: 2.409238815307617 | CLS Loss: 0.10349469631910324\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 2.475745916366577 | KNN Loss: 2.4052231311798096 | CLS Loss: 0.07052288204431534\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 2.4553489685058594 | KNN Loss: 2.3962314128875732 | CLS Loss: 0.05911747366189957\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 2.468958854675293 | KNN Loss: 2.401359796524048 | CLS Loss: 0.0675990954041481\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 2.4859509468078613 | KNN Loss: 2.40496563911438 | CLS Loss: 0.08098530024290085\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 2.436182737350464 | KNN Loss: 2.4042439460754395 | CLS Loss: 0.031938761472702026\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 2.5175230503082275 | KNN Loss: 2.4449880123138428 | CLS Loss: 0.07253507524728775\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 2.4668991565704346 | KNN Loss: 2.4180171489715576 | CLS Loss: 0.048881895840168\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 2.4728739261627197 | KNN Loss: 2.4122023582458496 | CLS Loss: 0.060671623796224594\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 2.462477207183838 | KNN Loss: 2.3879151344299316 | CLS Loss: 0.07456207275390625\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 2.4999840259552 | KNN Loss: 2.4294350147247314 | CLS Loss: 0.07054895162582397\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 2.5289700031280518 | KNN Loss: 2.461989402770996 | CLS Loss: 0.06698055565357208\n",
      "Epoch: 013, Loss: 2.4884, Train: 0.9821, Valid: 0.9788, Best: 0.9793\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 2.5037477016448975 | KNN Loss: 2.437570810317993 | CLS Loss: 0.06617695838212967\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 2.486575126647949 | KNN Loss: 2.4249267578125 | CLS Loss: 0.06164844334125519\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 2.4856367111206055 | KNN Loss: 2.4241042137145996 | CLS Loss: 0.061532504856586456\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 2.537635326385498 | KNN Loss: 2.496690273284912 | CLS Loss: 0.040945012122392654\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 2.45662522315979 | KNN Loss: 2.413346290588379 | CLS Loss: 0.04327881708741188\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 2.506032705307007 | KNN Loss: 2.447068452835083 | CLS Loss: 0.058964334428310394\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 2.4612770080566406 | KNN Loss: 2.3736655712127686 | CLS Loss: 0.08761142939329147\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 2.4774787425994873 | KNN Loss: 2.434164524078369 | CLS Loss: 0.04331419989466667\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 2.4898293018341064 | KNN Loss: 2.4240942001342773 | CLS Loss: 0.06573499739170074\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 2.4770827293395996 | KNN Loss: 2.4255425930023193 | CLS Loss: 0.05154021084308624\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 2.495434284210205 | KNN Loss: 2.4298512935638428 | CLS Loss: 0.0655830055475235\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 2.4798715114593506 | KNN Loss: 2.3929896354675293 | CLS Loss: 0.08688192814588547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 2.5127854347229004 | KNN Loss: 2.414885997772217 | CLS Loss: 0.09789931774139404\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 2.5002973079681396 | KNN Loss: 2.405195951461792 | CLS Loss: 0.09510133415460587\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 2.460742473602295 | KNN Loss: 2.411587953567505 | CLS Loss: 0.04915445297956467\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 2.466646671295166 | KNN Loss: 2.4057438373565674 | CLS Loss: 0.06090276688337326\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 2.462177276611328 | KNN Loss: 2.3895647525787354 | CLS Loss: 0.07261242717504501\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 2.5027318000793457 | KNN Loss: 2.4199397563934326 | CLS Loss: 0.0827919989824295\n",
      "Epoch: 014, Loss: 2.4868, Train: 0.9833, Valid: 0.9797, Best: 0.9797\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 2.4999172687530518 | KNN Loss: 2.444162130355835 | CLS Loss: 0.05575508251786232\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 2.4821736812591553 | KNN Loss: 2.423825263977051 | CLS Loss: 0.05834844335913658\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 2.5227138996124268 | KNN Loss: 2.4238853454589844 | CLS Loss: 0.09882865101099014\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 2.4299912452697754 | KNN Loss: 2.3944573402404785 | CLS Loss: 0.03553379699587822\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 2.4944214820861816 | KNN Loss: 2.4408349990844727 | CLS Loss: 0.0535864382982254\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 2.4633255004882812 | KNN Loss: 2.414822816848755 | CLS Loss: 0.04850266873836517\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 2.448411464691162 | KNN Loss: 2.4031665325164795 | CLS Loss: 0.045244865119457245\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 2.4747536182403564 | KNN Loss: 2.4262144565582275 | CLS Loss: 0.048539090901613235\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 2.436840772628784 | KNN Loss: 2.393085241317749 | CLS Loss: 0.043755609542131424\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 2.509418487548828 | KNN Loss: 2.44358229637146 | CLS Loss: 0.06583628803491592\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 2.488978147506714 | KNN Loss: 2.424492120742798 | CLS Loss: 0.064486064016819\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 2.481374979019165 | KNN Loss: 2.3932204246520996 | CLS Loss: 0.08815458416938782\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 2.483137845993042 | KNN Loss: 2.4268298149108887 | CLS Loss: 0.056307971477508545\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 2.4969780445098877 | KNN Loss: 2.418597459793091 | CLS Loss: 0.07838061451911926\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 2.4509634971618652 | KNN Loss: 2.433457374572754 | CLS Loss: 0.017506208270788193\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 2.5142621994018555 | KNN Loss: 2.406599521636963 | CLS Loss: 0.10766264796257019\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 2.500357151031494 | KNN Loss: 2.4339730739593506 | CLS Loss: 0.06638400256633759\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 2.4743165969848633 | KNN Loss: 2.392195224761963 | CLS Loss: 0.0821213647723198\n",
      "Epoch: 015, Loss: 2.4827, Train: 0.9792, Valid: 0.9756, Best: 0.9797\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 2.5448532104492188 | KNN Loss: 2.4444074630737305 | CLS Loss: 0.10044584423303604\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 2.524160146713257 | KNN Loss: 2.445449113845825 | CLS Loss: 0.07871099561452866\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 2.489760160446167 | KNN Loss: 2.4148993492126465 | CLS Loss: 0.07486078143119812\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 2.463959217071533 | KNN Loss: 2.42120623588562 | CLS Loss: 0.04275286942720413\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 2.5025582313537598 | KNN Loss: 2.424603223800659 | CLS Loss: 0.07795503735542297\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 2.4263148307800293 | KNN Loss: 2.3955798149108887 | CLS Loss: 0.030734963715076447\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 2.4344234466552734 | KNN Loss: 2.3915395736694336 | CLS Loss: 0.042883969843387604\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 2.4674437046051025 | KNN Loss: 2.3814940452575684 | CLS Loss: 0.08594971150159836\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 2.4685771465301514 | KNN Loss: 2.4081203937530518 | CLS Loss: 0.060456790030002594\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 2.476672649383545 | KNN Loss: 2.4311561584472656 | CLS Loss: 0.04551640525460243\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 2.4764437675476074 | KNN Loss: 2.398763418197632 | CLS Loss: 0.0776803269982338\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 2.4793412685394287 | KNN Loss: 2.4396605491638184 | CLS Loss: 0.03968081250786781\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 2.4967970848083496 | KNN Loss: 2.4398353099823 | CLS Loss: 0.05696168541908264\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 2.524653196334839 | KNN Loss: 2.438802480697632 | CLS Loss: 0.08585070073604584\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 2.4733874797821045 | KNN Loss: 2.4127678871154785 | CLS Loss: 0.060619622468948364\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 2.4853715896606445 | KNN Loss: 2.4273409843444824 | CLS Loss: 0.05803069472312927\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 2.4383792877197266 | KNN Loss: 2.4054698944091797 | CLS Loss: 0.03290930762887001\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 2.431128978729248 | KNN Loss: 2.388667583465576 | CLS Loss: 0.04246141016483307\n",
      "Epoch: 016, Loss: 2.4758, Train: 0.9824, Valid: 0.9787, Best: 0.9797\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 2.4806153774261475 | KNN Loss: 2.3899552822113037 | CLS Loss: 0.0906602069735527\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 2.4579362869262695 | KNN Loss: 2.4181671142578125 | CLS Loss: 0.039769187569618225\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 2.4539361000061035 | KNN Loss: 2.3991832733154297 | CLS Loss: 0.054752763360738754\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 2.4600117206573486 | KNN Loss: 2.3762824535369873 | CLS Loss: 0.08372919261455536\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 2.4685986042022705 | KNN Loss: 2.406656503677368 | CLS Loss: 0.06194216385483742\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 2.4540958404541016 | KNN Loss: 2.392883777618408 | CLS Loss: 0.06121201068162918\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 2.4778530597686768 | KNN Loss: 2.413222551345825 | CLS Loss: 0.06463058292865753\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 2.497239351272583 | KNN Loss: 2.440495491027832 | CLS Loss: 0.056743815541267395\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 2.4622063636779785 | KNN Loss: 2.4031765460968018 | CLS Loss: 0.05902989208698273\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 2.4631500244140625 | KNN Loss: 2.425020456314087 | CLS Loss: 0.03812965378165245\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 2.472357749938965 | KNN Loss: 2.4406845569610596 | CLS Loss: 0.03167307376861572\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 2.4361355304718018 | KNN Loss: 2.383406162261963 | CLS Loss: 0.05272925645112991\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 2.5059094429016113 | KNN Loss: 2.403369665145874 | CLS Loss: 0.10253985226154327\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 2.466005563735962 | KNN Loss: 2.4217021465301514 | CLS Loss: 0.04430336877703667\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 2.515970468521118 | KNN Loss: 2.4484987258911133 | CLS Loss: 0.06747183203697205\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 2.453134059906006 | KNN Loss: 2.4062912464141846 | CLS Loss: 0.04684290662407875\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 2.447089433670044 | KNN Loss: 2.3929619789123535 | CLS Loss: 0.05412740632891655\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 2.5131051540374756 | KNN Loss: 2.4543910026550293 | CLS Loss: 0.0587141215801239\n",
      "Epoch: 017, Loss: 2.4683, Train: 0.9822, Valid: 0.9779, Best: 0.9797\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 2.4905648231506348 | KNN Loss: 2.416295051574707 | CLS Loss: 0.07426983118057251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 2.4529902935028076 | KNN Loss: 2.418497323989868 | CLS Loss: 0.03449290245771408\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 2.4805970191955566 | KNN Loss: 2.4324324131011963 | CLS Loss: 0.0481647253036499\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 2.472309112548828 | KNN Loss: 2.42435359954834 | CLS Loss: 0.04795561730861664\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 2.473250389099121 | KNN Loss: 2.416815996170044 | CLS Loss: 0.05643438547849655\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 2.468705415725708 | KNN Loss: 2.407219409942627 | CLS Loss: 0.061485905200242996\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 2.4704768657684326 | KNN Loss: 2.4206905364990234 | CLS Loss: 0.049786217510700226\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 2.485203742980957 | KNN Loss: 2.426199197769165 | CLS Loss: 0.059004444628953934\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 2.4409685134887695 | KNN Loss: 2.388836622238159 | CLS Loss: 0.05213193595409393\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 2.484654664993286 | KNN Loss: 2.4180243015289307 | CLS Loss: 0.0666302964091301\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 2.4525043964385986 | KNN Loss: 2.3937160968780518 | CLS Loss: 0.05878834053874016\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 2.4526960849761963 | KNN Loss: 2.400836944580078 | CLS Loss: 0.051859088242053986\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 2.43717622756958 | KNN Loss: 2.391012668609619 | CLS Loss: 0.04616359621286392\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 2.4721429347991943 | KNN Loss: 2.389928102493286 | CLS Loss: 0.08221472799777985\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 2.5007505416870117 | KNN Loss: 2.433627128601074 | CLS Loss: 0.06712335348129272\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 2.4906113147735596 | KNN Loss: 2.4259157180786133 | CLS Loss: 0.06469567120075226\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 2.469587564468384 | KNN Loss: 2.4166672229766846 | CLS Loss: 0.052920255810022354\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 2.4794230461120605 | KNN Loss: 2.4205162525177 | CLS Loss: 0.058906782418489456\n",
      "Epoch: 018, Loss: 2.4653, Train: 0.9859, Valid: 0.9820, Best: 0.9820\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 2.4732699394226074 | KNN Loss: 2.3993093967437744 | CLS Loss: 0.07396052032709122\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 2.4641764163970947 | KNN Loss: 2.413506031036377 | CLS Loss: 0.05067043378949165\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 2.445817470550537 | KNN Loss: 2.4073574542999268 | CLS Loss: 0.038460005074739456\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 2.495046615600586 | KNN Loss: 2.4207940101623535 | CLS Loss: 0.07425256818532944\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 2.4568707942962646 | KNN Loss: 2.4299511909484863 | CLS Loss: 0.026919491589069366\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 2.4601073265075684 | KNN Loss: 2.435093641281128 | CLS Loss: 0.02501368150115013\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 2.508816719055176 | KNN Loss: 2.4403414726257324 | CLS Loss: 0.06847532093524933\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 2.46921443939209 | KNN Loss: 2.416796922683716 | CLS Loss: 0.052417609840631485\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 2.465686798095703 | KNN Loss: 2.4207777976989746 | CLS Loss: 0.044908955693244934\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 2.453669548034668 | KNN Loss: 2.400113344192505 | CLS Loss: 0.053556155413389206\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 2.4557836055755615 | KNN Loss: 2.4098572731018066 | CLS Loss: 0.04592633992433548\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 2.525235176086426 | KNN Loss: 2.443782329559326 | CLS Loss: 0.08145279437303543\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 2.4227066040039062 | KNN Loss: 2.388310432434082 | CLS Loss: 0.03439617156982422\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 2.4786758422851562 | KNN Loss: 2.4287452697753906 | CLS Loss: 0.04993056133389473\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 2.5020461082458496 | KNN Loss: 2.422945022583008 | CLS Loss: 0.07910114526748657\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 2.5171170234680176 | KNN Loss: 2.4398720264434814 | CLS Loss: 0.07724496722221375\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 2.472698926925659 | KNN Loss: 2.3988983631134033 | CLS Loss: 0.07380063831806183\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 2.5004169940948486 | KNN Loss: 2.44063401222229 | CLS Loss: 0.059783078730106354\n",
      "Epoch: 019, Loss: 2.4639, Train: 0.9862, Valid: 0.9824, Best: 0.9824\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 2.4429848194122314 | KNN Loss: 2.403550148010254 | CLS Loss: 0.03943469375371933\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 2.439619302749634 | KNN Loss: 2.3860132694244385 | CLS Loss: 0.053606048226356506\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 2.507676362991333 | KNN Loss: 2.467385768890381 | CLS Loss: 0.04029051214456558\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 2.4546902179718018 | KNN Loss: 2.4173223972320557 | CLS Loss: 0.037367723882198334\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 2.43453049659729 | KNN Loss: 2.382075071334839 | CLS Loss: 0.052455343306064606\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 2.410745620727539 | KNN Loss: 2.381399393081665 | CLS Loss: 0.029346119612455368\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 2.426123857498169 | KNN Loss: 2.3817076683044434 | CLS Loss: 0.04441618546843529\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 2.469491958618164 | KNN Loss: 2.4109113216400146 | CLS Loss: 0.058580756187438965\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 2.502568244934082 | KNN Loss: 2.4002349376678467 | CLS Loss: 0.10233334451913834\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 2.452444314956665 | KNN Loss: 2.398672103881836 | CLS Loss: 0.05377212166786194\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 2.4802956581115723 | KNN Loss: 2.414762020111084 | CLS Loss: 0.06553351879119873\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 2.4853949546813965 | KNN Loss: 2.4469077587127686 | CLS Loss: 0.038487162441015244\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 2.498983383178711 | KNN Loss: 2.4445443153381348 | CLS Loss: 0.054439082741737366\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 2.4767770767211914 | KNN Loss: 2.4090592861175537 | CLS Loss: 0.06771776080131531\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 2.5104470252990723 | KNN Loss: 2.467918634414673 | CLS Loss: 0.042528510093688965\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 2.4458823204040527 | KNN Loss: 2.411200761795044 | CLS Loss: 0.03468148410320282\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 2.474296808242798 | KNN Loss: 2.4253339767456055 | CLS Loss: 0.04896284267306328\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 2.452259063720703 | KNN Loss: 2.407235860824585 | CLS Loss: 0.04502328857779503\n",
      "Epoch: 020, Loss: 2.4651, Train: 0.9874, Valid: 0.9822, Best: 0.9824\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 2.433943271636963 | KNN Loss: 2.368887186050415 | CLS Loss: 0.06505607068538666\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 2.487205982208252 | KNN Loss: 2.415091037750244 | CLS Loss: 0.07211501896381378\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 2.4628279209136963 | KNN Loss: 2.3924362659454346 | CLS Loss: 0.07039157301187515\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 2.4266908168792725 | KNN Loss: 2.376941204071045 | CLS Loss: 0.04974953457713127\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 2.4524500370025635 | KNN Loss: 2.4011127948760986 | CLS Loss: 0.05133712664246559\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 2.4823760986328125 | KNN Loss: 2.42484712600708 | CLS Loss: 0.05752908065915108\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 2.4696600437164307 | KNN Loss: 2.437584161758423 | CLS Loss: 0.032075878232717514\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 2.461954116821289 | KNN Loss: 2.4047367572784424 | CLS Loss: 0.05721736699342728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 2.4808499813079834 | KNN Loss: 2.4251315593719482 | CLS Loss: 0.05571844428777695\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 2.433563709259033 | KNN Loss: 2.401470422744751 | CLS Loss: 0.03209329769015312\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 2.424501657485962 | KNN Loss: 2.3625714778900146 | CLS Loss: 0.06193007156252861\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 2.490281581878662 | KNN Loss: 2.4171173572540283 | CLS Loss: 0.07316433638334274\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 2.476388454437256 | KNN Loss: 2.380314588546753 | CLS Loss: 0.09607388079166412\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 2.4758460521698 | KNN Loss: 2.372680902481079 | CLS Loss: 0.10316509753465652\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 2.4553472995758057 | KNN Loss: 2.4163966178894043 | CLS Loss: 0.03895071893930435\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 2.460681915283203 | KNN Loss: 2.4190824031829834 | CLS Loss: 0.04159942641854286\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 2.472137451171875 | KNN Loss: 2.421041488647461 | CLS Loss: 0.05109607055783272\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 2.468752861022949 | KNN Loss: 2.395392894744873 | CLS Loss: 0.07335998862981796\n",
      "Epoch: 021, Loss: 2.4619, Train: 0.9857, Valid: 0.9804, Best: 0.9824\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 2.4684486389160156 | KNN Loss: 2.4439005851745605 | CLS Loss: 0.024548090994358063\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 2.4285571575164795 | KNN Loss: 2.403203010559082 | CLS Loss: 0.025354158133268356\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 2.410210609436035 | KNN Loss: 2.377460241317749 | CLS Loss: 0.03275037929415703\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 2.4716084003448486 | KNN Loss: 2.42746901512146 | CLS Loss: 0.0441393218934536\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 2.439079999923706 | KNN Loss: 2.4264273643493652 | CLS Loss: 0.012652561999857426\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 2.4330382347106934 | KNN Loss: 2.3899433612823486 | CLS Loss: 0.043094780296087265\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 2.4245407581329346 | KNN Loss: 2.381615161895752 | CLS Loss: 0.04292554035782814\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 2.4547905921936035 | KNN Loss: 2.3985979557037354 | CLS Loss: 0.056192684918642044\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 2.452554225921631 | KNN Loss: 2.38989520072937 | CLS Loss: 0.06265900284051895\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 2.435063600540161 | KNN Loss: 2.4226951599121094 | CLS Loss: 0.012368489056825638\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 2.4756784439086914 | KNN Loss: 2.425243377685547 | CLS Loss: 0.05043508857488632\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 2.4822897911071777 | KNN Loss: 2.417503833770752 | CLS Loss: 0.06478586047887802\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 2.4497060775756836 | KNN Loss: 2.4125375747680664 | CLS Loss: 0.03716844320297241\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 2.4667985439300537 | KNN Loss: 2.400979995727539 | CLS Loss: 0.06581852585077286\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 2.4569826126098633 | KNN Loss: 2.4154255390167236 | CLS Loss: 0.04155717417597771\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 2.5123283863067627 | KNN Loss: 2.4364500045776367 | CLS Loss: 0.07587847113609314\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 2.5135793685913086 | KNN Loss: 2.4473366737365723 | CLS Loss: 0.06624278426170349\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 2.4758052825927734 | KNN Loss: 2.436640977859497 | CLS Loss: 0.03916433826088905\n",
      "Epoch: 022, Loss: 2.4588, Train: 0.9875, Valid: 0.9820, Best: 0.9824\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 2.421126365661621 | KNN Loss: 2.3791778087615967 | CLS Loss: 0.04194863140583038\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 2.4323577880859375 | KNN Loss: 2.406773567199707 | CLS Loss: 0.025584178045392036\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 2.45597505569458 | KNN Loss: 2.4191880226135254 | CLS Loss: 0.03678707778453827\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 2.4526753425598145 | KNN Loss: 2.4064977169036865 | CLS Loss: 0.04617752879858017\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 2.4923031330108643 | KNN Loss: 2.43790602684021 | CLS Loss: 0.054397109895944595\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 2.4580678939819336 | KNN Loss: 2.3747830390930176 | CLS Loss: 0.08328479528427124\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 2.5008482933044434 | KNN Loss: 2.4085683822631836 | CLS Loss: 0.09227998554706573\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 2.444955348968506 | KNN Loss: 2.4227612018585205 | CLS Loss: 0.022194083780050278\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 2.415040969848633 | KNN Loss: 2.390937566757202 | CLS Loss: 0.024103499948978424\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 2.449216365814209 | KNN Loss: 2.3990445137023926 | CLS Loss: 0.05017195641994476\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 2.4708731174468994 | KNN Loss: 2.43599009513855 | CLS Loss: 0.03488294780254364\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 2.460146903991699 | KNN Loss: 2.420459032058716 | CLS Loss: 0.03968792408704758\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 2.478303909301758 | KNN Loss: 2.407221794128418 | CLS Loss: 0.07108207792043686\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 2.4725399017333984 | KNN Loss: 2.4237220287323 | CLS Loss: 0.04881783947348595\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 2.458833694458008 | KNN Loss: 2.4030048847198486 | CLS Loss: 0.05582879111170769\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 2.430302381515503 | KNN Loss: 2.3777730464935303 | CLS Loss: 0.05252924561500549\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 2.5019772052764893 | KNN Loss: 2.399325132369995 | CLS Loss: 0.10265205055475235\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 2.4205965995788574 | KNN Loss: 2.3913931846618652 | CLS Loss: 0.029203318059444427\n",
      "Epoch: 023, Loss: 2.4540, Train: 0.9877, Valid: 0.9822, Best: 0.9824\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 2.454911231994629 | KNN Loss: 2.407545804977417 | CLS Loss: 0.04736551642417908\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 2.476393222808838 | KNN Loss: 2.433884382247925 | CLS Loss: 0.04250878468155861\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 2.5086066722869873 | KNN Loss: 2.4524102210998535 | CLS Loss: 0.056196428835392\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 2.4512996673583984 | KNN Loss: 2.384046792984009 | CLS Loss: 0.06725284457206726\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 2.475677490234375 | KNN Loss: 2.427826404571533 | CLS Loss: 0.04785110428929329\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 2.4133734703063965 | KNN Loss: 2.3899052143096924 | CLS Loss: 0.02346830442547798\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 2.4130189418792725 | KNN Loss: 2.3818516731262207 | CLS Loss: 0.031167374923825264\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 2.4514529705047607 | KNN Loss: 2.3998589515686035 | CLS Loss: 0.051594071090221405\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 2.461552858352661 | KNN Loss: 2.416104793548584 | CLS Loss: 0.04544798657298088\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 2.4077494144439697 | KNN Loss: 2.37113094329834 | CLS Loss: 0.036618538200855255\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 2.4305450916290283 | KNN Loss: 2.3945860862731934 | CLS Loss: 0.03595888987183571\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 2.4049882888793945 | KNN Loss: 2.3679440021514893 | CLS Loss: 0.037044279277324677\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 2.457496404647827 | KNN Loss: 2.4033331871032715 | CLS Loss: 0.05416329577565193\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 2.468294620513916 | KNN Loss: 2.3998165130615234 | CLS Loss: 0.06847816705703735\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 2.5531058311462402 | KNN Loss: 2.444523572921753 | CLS Loss: 0.10858218371868134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 2.4731428623199463 | KNN Loss: 2.3835816383361816 | CLS Loss: 0.08956122398376465\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 2.480616331100464 | KNN Loss: 2.431067705154419 | CLS Loss: 0.049548521637916565\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 2.4604032039642334 | KNN Loss: 2.4391157627105713 | CLS Loss: 0.02128739468753338\n",
      "Epoch: 024, Loss: 2.4561, Train: 0.9886, Valid: 0.9839, Best: 0.9839\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 2.441122531890869 | KNN Loss: 2.382991313934326 | CLS Loss: 0.05813124030828476\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 2.463212013244629 | KNN Loss: 2.4097578525543213 | CLS Loss: 0.0534542053937912\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 2.4547388553619385 | KNN Loss: 2.3924949169158936 | CLS Loss: 0.06224387139081955\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 2.4742774963378906 | KNN Loss: 2.4180617332458496 | CLS Loss: 0.05621572211384773\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 2.453037738800049 | KNN Loss: 2.4141364097595215 | CLS Loss: 0.03890121728181839\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 2.4446067810058594 | KNN Loss: 2.393432140350342 | CLS Loss: 0.051174744963645935\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 2.47312068939209 | KNN Loss: 2.422945737838745 | CLS Loss: 0.050174955278635025\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 2.430612087249756 | KNN Loss: 2.3748619556427 | CLS Loss: 0.05575018748641014\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 2.47353196144104 | KNN Loss: 2.4270594120025635 | CLS Loss: 0.04647253826260567\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 2.4839887619018555 | KNN Loss: 2.4065842628479004 | CLS Loss: 0.07740450650453568\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 2.483511447906494 | KNN Loss: 2.417048454284668 | CLS Loss: 0.06646295636892319\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 2.4089293479919434 | KNN Loss: 2.391613006591797 | CLS Loss: 0.017316244542598724\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 2.462801933288574 | KNN Loss: 2.431642770767212 | CLS Loss: 0.031159192323684692\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 2.4411203861236572 | KNN Loss: 2.4055919647216797 | CLS Loss: 0.03552844375371933\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 2.4472007751464844 | KNN Loss: 2.402569055557251 | CLS Loss: 0.0446317121386528\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 2.4870145320892334 | KNN Loss: 2.449374198913574 | CLS Loss: 0.03764033317565918\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 2.43477463722229 | KNN Loss: 2.388914108276367 | CLS Loss: 0.04586045816540718\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 2.442333936691284 | KNN Loss: 2.4036104679107666 | CLS Loss: 0.03872339427471161\n",
      "Epoch: 025, Loss: 2.4551, Train: 0.9883, Valid: 0.9845, Best: 0.9845\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 2.451465368270874 | KNN Loss: 2.384843587875366 | CLS Loss: 0.06662171334028244\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 2.4453163146972656 | KNN Loss: 2.403458833694458 | CLS Loss: 0.04185757040977478\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 2.457832098007202 | KNN Loss: 2.424363136291504 | CLS Loss: 0.033468980342149734\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 2.436022996902466 | KNN Loss: 2.421034574508667 | CLS Loss: 0.014988389797508717\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 2.4592385292053223 | KNN Loss: 2.426450729370117 | CLS Loss: 0.03278787061572075\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 2.464890718460083 | KNN Loss: 2.4253766536712646 | CLS Loss: 0.03951403498649597\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 2.426042318344116 | KNN Loss: 2.3743016719818115 | CLS Loss: 0.05174068734049797\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 2.4735889434814453 | KNN Loss: 2.3868277072906494 | CLS Loss: 0.08676120638847351\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 2.463223457336426 | KNN Loss: 2.4083149433135986 | CLS Loss: 0.05490861460566521\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 2.466296672821045 | KNN Loss: 2.403120756149292 | CLS Loss: 0.06317584961652756\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 2.4585158824920654 | KNN Loss: 2.402435541152954 | CLS Loss: 0.056080445647239685\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 2.45475172996521 | KNN Loss: 2.407025098800659 | CLS Loss: 0.047726523131132126\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 2.4662647247314453 | KNN Loss: 2.431488037109375 | CLS Loss: 0.03477679193019867\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 2.458481788635254 | KNN Loss: 2.406991481781006 | CLS Loss: 0.05149030685424805\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 2.41298770904541 | KNN Loss: 2.390200138092041 | CLS Loss: 0.022787529975175858\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 2.4481897354125977 | KNN Loss: 2.3907346725463867 | CLS Loss: 0.05745510384440422\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 2.4837892055511475 | KNN Loss: 2.441265106201172 | CLS Loss: 0.042524196207523346\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 2.4771270751953125 | KNN Loss: 2.4366469383239746 | CLS Loss: 0.04048019275069237\n",
      "Epoch: 026, Loss: 2.4515, Train: 0.9884, Valid: 0.9841, Best: 0.9845\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 2.4675426483154297 | KNN Loss: 2.4348225593566895 | CLS Loss: 0.03272015228867531\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 2.433086395263672 | KNN Loss: 2.3935892581939697 | CLS Loss: 0.0394972488284111\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 2.4532063007354736 | KNN Loss: 2.4018442630767822 | CLS Loss: 0.05136194825172424\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 2.4504377841949463 | KNN Loss: 2.4165022373199463 | CLS Loss: 0.033935658633708954\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 2.4415605068206787 | KNN Loss: 2.3963842391967773 | CLS Loss: 0.0451761931180954\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 2.451885223388672 | KNN Loss: 2.4022905826568604 | CLS Loss: 0.04959460720419884\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 2.415529727935791 | KNN Loss: 2.387838840484619 | CLS Loss: 0.027690831571817398\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 2.4951181411743164 | KNN Loss: 2.4396913051605225 | CLS Loss: 0.05542684718966484\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 2.4865365028381348 | KNN Loss: 2.437164068222046 | CLS Loss: 0.04937244951725006\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 2.426781415939331 | KNN Loss: 2.3875415325164795 | CLS Loss: 0.03923976793885231\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 2.4602105617523193 | KNN Loss: 2.413954496383667 | CLS Loss: 0.04625603184103966\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 2.438631534576416 | KNN Loss: 2.368826389312744 | CLS Loss: 0.06980513036251068\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 2.4600918292999268 | KNN Loss: 2.4015560150146484 | CLS Loss: 0.05853574723005295\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 2.4273765087127686 | KNN Loss: 2.396904230117798 | CLS Loss: 0.03047233633697033\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 2.4598541259765625 | KNN Loss: 2.3962223529815674 | CLS Loss: 0.0636318102478981\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 2.422985553741455 | KNN Loss: 2.388753890991211 | CLS Loss: 0.034231752157211304\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 2.4288744926452637 | KNN Loss: 2.414487838745117 | CLS Loss: 0.014386603608727455\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 2.4462361335754395 | KNN Loss: 2.3861775398254395 | CLS Loss: 0.06005854159593582\n",
      "Epoch: 027, Loss: 2.4479, Train: 0.9858, Valid: 0.9810, Best: 0.9845\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 2.4482948780059814 | KNN Loss: 2.4193851947784424 | CLS Loss: 0.028909722343087196\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 2.426079273223877 | KNN Loss: 2.412288188934326 | CLS Loss: 0.013790984638035297\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 2.508150815963745 | KNN Loss: 2.442310094833374 | CLS Loss: 0.0658407062292099\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 2.4517195224761963 | KNN Loss: 2.3966147899627686 | CLS Loss: 0.0551048144698143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 2.4286694526672363 | KNN Loss: 2.3808529376983643 | CLS Loss: 0.04781649261713028\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 2.4273369312286377 | KNN Loss: 2.4134469032287598 | CLS Loss: 0.013889942318201065\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 2.4584829807281494 | KNN Loss: 2.4104766845703125 | CLS Loss: 0.048006389290094376\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 2.427949905395508 | KNN Loss: 2.369306802749634 | CLS Loss: 0.05864310637116432\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 2.4265265464782715 | KNN Loss: 2.4052140712738037 | CLS Loss: 0.021312404423952103\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 2.445178508758545 | KNN Loss: 2.393740177154541 | CLS Loss: 0.051438264548778534\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 2.4476516246795654 | KNN Loss: 2.4162697792053223 | CLS Loss: 0.03138191998004913\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 2.4530062675476074 | KNN Loss: 2.413281202316284 | CLS Loss: 0.03972504287958145\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 2.412689685821533 | KNN Loss: 2.389514684677124 | CLS Loss: 0.023175064474344254\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 2.402839422225952 | KNN Loss: 2.3791658878326416 | CLS Loss: 0.02367362380027771\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 2.509983539581299 | KNN Loss: 2.458117723464966 | CLS Loss: 0.05186585709452629\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 2.4997644424438477 | KNN Loss: 2.4463577270507812 | CLS Loss: 0.05340674892067909\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 2.434274673461914 | KNN Loss: 2.393091917037964 | CLS Loss: 0.041182681918144226\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 2.463210344314575 | KNN Loss: 2.419205904006958 | CLS Loss: 0.04400433599948883\n",
      "Epoch: 028, Loss: 2.4468, Train: 0.9885, Valid: 0.9841, Best: 0.9845\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 2.46071457862854 | KNN Loss: 2.397247791290283 | CLS Loss: 0.06346669793128967\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 2.458803415298462 | KNN Loss: 2.4129037857055664 | CLS Loss: 0.04589959606528282\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 2.4101791381835938 | KNN Loss: 2.377049207687378 | CLS Loss: 0.03312983363866806\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 2.418006420135498 | KNN Loss: 2.3923823833465576 | CLS Loss: 0.025623928755521774\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 2.432157516479492 | KNN Loss: 2.3995237350463867 | CLS Loss: 0.032633792608976364\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 2.4418785572052 | KNN Loss: 2.393885850906372 | CLS Loss: 0.04799263924360275\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 2.499415874481201 | KNN Loss: 2.4387001991271973 | CLS Loss: 0.06071579456329346\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 2.4541072845458984 | KNN Loss: 2.3928732872009277 | CLS Loss: 0.06123397499322891\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 2.443650722503662 | KNN Loss: 2.406238079071045 | CLS Loss: 0.037412602454423904\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 2.494276762008667 | KNN Loss: 2.454458475112915 | CLS Loss: 0.03981834277510643\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 2.4246883392333984 | KNN Loss: 2.3875339031219482 | CLS Loss: 0.037154458463191986\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 2.4678077697753906 | KNN Loss: 2.4139881134033203 | CLS Loss: 0.05381964519619942\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 2.4318161010742188 | KNN Loss: 2.4016988277435303 | CLS Loss: 0.0301173385232687\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 2.4778690338134766 | KNN Loss: 2.4064626693725586 | CLS Loss: 0.07140644639730453\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 2.459425926208496 | KNN Loss: 2.4145424365997314 | CLS Loss: 0.04488358274102211\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 2.4812252521514893 | KNN Loss: 2.4410150051116943 | CLS Loss: 0.04021017625927925\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 2.4403562545776367 | KNN Loss: 2.410593271255493 | CLS Loss: 0.029762931168079376\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 2.458521604537964 | KNN Loss: 2.416788339614868 | CLS Loss: 0.04173325002193451\n",
      "Epoch: 029, Loss: 2.4468, Train: 0.9880, Valid: 0.9825, Best: 0.9845\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 2.4861810207366943 | KNN Loss: 2.402956008911133 | CLS Loss: 0.0832250714302063\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 2.4580185413360596 | KNN Loss: 2.44250750541687 | CLS Loss: 0.015510950237512589\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 2.4352338314056396 | KNN Loss: 2.4008822441101074 | CLS Loss: 0.0343516543507576\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 2.4166767597198486 | KNN Loss: 2.390368700027466 | CLS Loss: 0.02630803920328617\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 2.43448543548584 | KNN Loss: 2.401374101638794 | CLS Loss: 0.033111244440078735\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 2.446089029312134 | KNN Loss: 2.3979287147521973 | CLS Loss: 0.048160336911678314\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 2.427731513977051 | KNN Loss: 2.412693977355957 | CLS Loss: 0.015037632547318935\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 2.4489352703094482 | KNN Loss: 2.3974244594573975 | CLS Loss: 0.05151088535785675\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 2.473010778427124 | KNN Loss: 2.3969943523406982 | CLS Loss: 0.07601645588874817\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 2.4277870655059814 | KNN Loss: 2.3747916221618652 | CLS Loss: 0.052995506674051285\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 2.462008237838745 | KNN Loss: 2.3963520526885986 | CLS Loss: 0.06565626710653305\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 2.4635374546051025 | KNN Loss: 2.414541721343994 | CLS Loss: 0.04899568855762482\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 2.4616262912750244 | KNN Loss: 2.416874885559082 | CLS Loss: 0.044751446694135666\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 2.4026808738708496 | KNN Loss: 2.3940367698669434 | CLS Loss: 0.008644099347293377\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 2.4381721019744873 | KNN Loss: 2.4025890827178955 | CLS Loss: 0.035583022981882095\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 2.430197238922119 | KNN Loss: 2.405205726623535 | CLS Loss: 0.024991577491164207\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 2.4120113849639893 | KNN Loss: 2.386030435562134 | CLS Loss: 0.025980982929468155\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 2.42287540435791 | KNN Loss: 2.3747525215148926 | CLS Loss: 0.048122771084308624\n",
      "Epoch: 030, Loss: 2.4426, Train: 0.9857, Valid: 0.9790, Best: 0.9845\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 2.486118793487549 | KNN Loss: 2.4398269653320312 | CLS Loss: 0.04629189521074295\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 2.5110220909118652 | KNN Loss: 2.4289653301239014 | CLS Loss: 0.08205676078796387\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 2.4794766902923584 | KNN Loss: 2.408639907836914 | CLS Loss: 0.07083667069673538\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 2.437971591949463 | KNN Loss: 2.413422107696533 | CLS Loss: 0.024549409747123718\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 2.454303026199341 | KNN Loss: 2.407719612121582 | CLS Loss: 0.046583499759435654\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 2.4262208938598633 | KNN Loss: 2.3913238048553467 | CLS Loss: 0.03489703685045242\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 2.38561749458313 | KNN Loss: 2.3459856510162354 | CLS Loss: 0.039631787687540054\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 2.437437057495117 | KNN Loss: 2.417151689529419 | CLS Loss: 0.02028544619679451\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 2.4751768112182617 | KNN Loss: 2.433763027191162 | CLS Loss: 0.041413839906454086\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 2.4077677726745605 | KNN Loss: 2.359898567199707 | CLS Loss: 0.04786913841962814\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 2.447305917739868 | KNN Loss: 2.387026071548462 | CLS Loss: 0.06027992069721222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 2.448814868927002 | KNN Loss: 2.395123243331909 | CLS Loss: 0.0536915622651577\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 2.4839813709259033 | KNN Loss: 2.415451765060425 | CLS Loss: 0.06852968782186508\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 2.4616382122039795 | KNN Loss: 2.4349606037139893 | CLS Loss: 0.02667768858373165\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 2.4315826892852783 | KNN Loss: 2.379340410232544 | CLS Loss: 0.05224237218499184\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 2.464388847351074 | KNN Loss: 2.397658586502075 | CLS Loss: 0.06673017144203186\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 2.449435234069824 | KNN Loss: 2.4197943210601807 | CLS Loss: 0.029640814289450645\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 2.4375765323638916 | KNN Loss: 2.400148868560791 | CLS Loss: 0.03742769733071327\n",
      "Epoch: 031, Loss: 2.4438, Train: 0.9897, Valid: 0.9852, Best: 0.9852\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 2.403738498687744 | KNN Loss: 2.3904647827148438 | CLS Loss: 0.013273784890770912\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 2.4679036140441895 | KNN Loss: 2.3986642360687256 | CLS Loss: 0.0692392885684967\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 2.433901786804199 | KNN Loss: 2.4253034591674805 | CLS Loss: 0.00859825685620308\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 2.412022590637207 | KNN Loss: 2.387333869934082 | CLS Loss: 0.024688605219125748\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 2.439880847930908 | KNN Loss: 2.4019742012023926 | CLS Loss: 0.03790663182735443\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 2.429128646850586 | KNN Loss: 2.3993780612945557 | CLS Loss: 0.02975059673190117\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 2.4205915927886963 | KNN Loss: 2.3866076469421387 | CLS Loss: 0.03398391976952553\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 2.4829561710357666 | KNN Loss: 2.4261996746063232 | CLS Loss: 0.05675658583641052\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 2.4124886989593506 | KNN Loss: 2.3890697956085205 | CLS Loss: 0.023418983444571495\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 2.4231340885162354 | KNN Loss: 2.4023759365081787 | CLS Loss: 0.02075824700295925\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 2.4368207454681396 | KNN Loss: 2.4058096408843994 | CLS Loss: 0.031011167913675308\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 2.439838409423828 | KNN Loss: 2.4174346923828125 | CLS Loss: 0.022403687238693237\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 2.4302189350128174 | KNN Loss: 2.4065864086151123 | CLS Loss: 0.023632414638996124\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 2.4650566577911377 | KNN Loss: 2.4058964252471924 | CLS Loss: 0.05916011705994606\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 2.4238486289978027 | KNN Loss: 2.399447202682495 | CLS Loss: 0.024401405826210976\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 2.436936616897583 | KNN Loss: 2.38193416595459 | CLS Loss: 0.05500239133834839\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 2.4119269847869873 | KNN Loss: 2.365250587463379 | CLS Loss: 0.04667637497186661\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 2.4270007610321045 | KNN Loss: 2.3619399070739746 | CLS Loss: 0.06506088376045227\n",
      "Epoch: 032, Loss: 2.4421, Train: 0.9905, Valid: 0.9837, Best: 0.9852\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 2.392821788787842 | KNN Loss: 2.3571507930755615 | CLS Loss: 0.03567102551460266\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 2.4539403915405273 | KNN Loss: 2.420285940170288 | CLS Loss: 0.03365442901849747\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 2.4393043518066406 | KNN Loss: 2.3999407291412354 | CLS Loss: 0.03936360031366348\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 2.421877145767212 | KNN Loss: 2.4001078605651855 | CLS Loss: 0.021769315004348755\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 2.4272940158843994 | KNN Loss: 2.4113476276397705 | CLS Loss: 0.015946341678500175\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 2.430386781692505 | KNN Loss: 2.373879909515381 | CLS Loss: 0.05650683119893074\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 2.4370718002319336 | KNN Loss: 2.3983356952667236 | CLS Loss: 0.038736049085855484\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 2.4429359436035156 | KNN Loss: 2.3811886310577393 | CLS Loss: 0.061747245490550995\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 2.442086696624756 | KNN Loss: 2.4022629261016846 | CLS Loss: 0.0398237518966198\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 2.423140048980713 | KNN Loss: 2.369844913482666 | CLS Loss: 0.05329512432217598\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 2.3873825073242188 | KNN Loss: 2.3734610080718994 | CLS Loss: 0.013921557925641537\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 2.4637856483459473 | KNN Loss: 2.428402900695801 | CLS Loss: 0.03538280352950096\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 2.441725730895996 | KNN Loss: 2.4141299724578857 | CLS Loss: 0.027595818042755127\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 2.4931726455688477 | KNN Loss: 2.436507225036621 | CLS Loss: 0.05666537210345268\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 2.417509078979492 | KNN Loss: 2.375476121902466 | CLS Loss: 0.04203302785754204\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 2.478982925415039 | KNN Loss: 2.4278910160064697 | CLS Loss: 0.051091838628053665\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 2.4254636764526367 | KNN Loss: 2.389043092727661 | CLS Loss: 0.03642064705491066\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 2.4026284217834473 | KNN Loss: 2.377877712249756 | CLS Loss: 0.024750687181949615\n",
      "Epoch: 033, Loss: 2.4393, Train: 0.9900, Valid: 0.9835, Best: 0.9852\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 2.418917655944824 | KNN Loss: 2.3707878589630127 | CLS Loss: 0.04812968522310257\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 2.423490524291992 | KNN Loss: 2.405989408493042 | CLS Loss: 0.017501218244433403\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 2.4166390895843506 | KNN Loss: 2.3868231773376465 | CLS Loss: 0.029815969988703728\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 2.4742441177368164 | KNN Loss: 2.419515609741211 | CLS Loss: 0.05472856014966965\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 2.4588539600372314 | KNN Loss: 2.3829503059387207 | CLS Loss: 0.07590361684560776\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 2.454841375350952 | KNN Loss: 2.3837461471557617 | CLS Loss: 0.07109515368938446\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 2.4291603565216064 | KNN Loss: 2.404254674911499 | CLS Loss: 0.024905763566493988\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 2.4568028450012207 | KNN Loss: 2.4015469551086426 | CLS Loss: 0.05525585636496544\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 2.4119577407836914 | KNN Loss: 2.3728487491607666 | CLS Loss: 0.0391090027987957\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 2.430302619934082 | KNN Loss: 2.4085116386413574 | CLS Loss: 0.02179093472659588\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 2.430464506149292 | KNN Loss: 2.3937268257141113 | CLS Loss: 0.036737773567438126\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 2.440610408782959 | KNN Loss: 2.3844757080078125 | CLS Loss: 0.05613468959927559\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 2.4747636318206787 | KNN Loss: 2.434821367263794 | CLS Loss: 0.03994220122694969\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 2.4774203300476074 | KNN Loss: 2.4444518089294434 | CLS Loss: 0.0329684242606163\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 2.419034481048584 | KNN Loss: 2.3812496662139893 | CLS Loss: 0.037784792482852936\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 2.470285654067993 | KNN Loss: 2.4302823543548584 | CLS Loss: 0.040003202855587006\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 2.420182704925537 | KNN Loss: 2.3869059085845947 | CLS Loss: 0.0332767553627491\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 2.4308342933654785 | KNN Loss: 2.401522159576416 | CLS Loss: 0.029312163591384888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 2.4382, Train: 0.9904, Valid: 0.9831, Best: 0.9852\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 2.453667640686035 | KNN Loss: 2.413444757461548 | CLS Loss: 0.04022293910384178\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 2.482313394546509 | KNN Loss: 2.3888933658599854 | CLS Loss: 0.09341995418071747\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 2.4356231689453125 | KNN Loss: 2.4200551509857178 | CLS Loss: 0.015568077564239502\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 2.428253650665283 | KNN Loss: 2.3907439708709717 | CLS Loss: 0.037509772926568985\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 2.4387760162353516 | KNN Loss: 2.3981502056121826 | CLS Loss: 0.04062582179903984\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 2.39978289604187 | KNN Loss: 2.375951051712036 | CLS Loss: 0.023831866681575775\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 2.4629411697387695 | KNN Loss: 2.394022226333618 | CLS Loss: 0.06891892850399017\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 2.385370969772339 | KNN Loss: 2.3512375354766846 | CLS Loss: 0.03413335978984833\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 2.4435689449310303 | KNN Loss: 2.394941806793213 | CLS Loss: 0.048627179116010666\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 2.434873580932617 | KNN Loss: 2.4014084339141846 | CLS Loss: 0.033465199172496796\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 2.458134174346924 | KNN Loss: 2.427394390106201 | CLS Loss: 0.03073984943330288\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 2.43318772315979 | KNN Loss: 2.3960249423980713 | CLS Loss: 0.037162866443395615\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 2.435701370239258 | KNN Loss: 2.375324010848999 | CLS Loss: 0.060377269983291626\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 2.4070703983306885 | KNN Loss: 2.3871922492980957 | CLS Loss: 0.019878186285495758\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 2.446326494216919 | KNN Loss: 2.3926925659179688 | CLS Loss: 0.05363389477133751\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 2.428675413131714 | KNN Loss: 2.4005048274993896 | CLS Loss: 0.028170501813292503\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 2.4229843616485596 | KNN Loss: 2.3852264881134033 | CLS Loss: 0.03775792568922043\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 2.397608518600464 | KNN Loss: 2.378725290298462 | CLS Loss: 0.018883170560002327\n",
      "Epoch: 035, Loss: 2.4354, Train: 0.9914, Valid: 0.9849, Best: 0.9852\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 2.434083938598633 | KNN Loss: 2.402387857437134 | CLS Loss: 0.031696025282144547\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 2.4160990715026855 | KNN Loss: 2.3902015686035156 | CLS Loss: 0.025897584855556488\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 2.42596697807312 | KNN Loss: 2.403872489929199 | CLS Loss: 0.02209448255598545\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 2.3959782123565674 | KNN Loss: 2.378763198852539 | CLS Loss: 0.01721511036157608\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 2.4145309925079346 | KNN Loss: 2.397306203842163 | CLS Loss: 0.017224827781319618\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 2.4498136043548584 | KNN Loss: 2.4166488647460938 | CLS Loss: 0.03316480666399002\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 2.4387965202331543 | KNN Loss: 2.408806800842285 | CLS Loss: 0.02998967655003071\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 2.4163689613342285 | KNN Loss: 2.373645305633545 | CLS Loss: 0.0427236370742321\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 2.4381461143493652 | KNN Loss: 2.410562515258789 | CLS Loss: 0.02758350595831871\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 2.437520742416382 | KNN Loss: 2.4098403453826904 | CLS Loss: 0.027680374681949615\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 2.437427520751953 | KNN Loss: 2.4177889823913574 | CLS Loss: 0.01963847689330578\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 2.42600154876709 | KNN Loss: 2.3724260330200195 | CLS Loss: 0.0535755455493927\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 2.4319820404052734 | KNN Loss: 2.3676998615264893 | CLS Loss: 0.06428224593400955\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 2.4686570167541504 | KNN Loss: 2.403200387954712 | CLS Loss: 0.06545654684305191\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 2.457221508026123 | KNN Loss: 2.4200661182403564 | CLS Loss: 0.037155281752347946\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 2.4429590702056885 | KNN Loss: 2.405853033065796 | CLS Loss: 0.03710594400763512\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 2.4073915481567383 | KNN Loss: 2.3945252895355225 | CLS Loss: 0.012866281904280186\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 2.437328815460205 | KNN Loss: 2.371375322341919 | CLS Loss: 0.06595361232757568\n",
      "Epoch: 036, Loss: 2.4344, Train: 0.9904, Valid: 0.9849, Best: 0.9852\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 2.48941969871521 | KNN Loss: 2.418375015258789 | CLS Loss: 0.07104475796222687\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 2.420792579650879 | KNN Loss: 2.3957178592681885 | CLS Loss: 0.025074832141399384\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 2.448631763458252 | KNN Loss: 2.429335117340088 | CLS Loss: 0.019296539947390556\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 2.434642791748047 | KNN Loss: 2.401073932647705 | CLS Loss: 0.03356882557272911\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 2.446134567260742 | KNN Loss: 2.4049248695373535 | CLS Loss: 0.04120973125100136\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 2.446122884750366 | KNN Loss: 2.411308526992798 | CLS Loss: 0.03481433913111687\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 2.4075801372528076 | KNN Loss: 2.393294095993042 | CLS Loss: 0.014286034740507603\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 2.4111249446868896 | KNN Loss: 2.3953030109405518 | CLS Loss: 0.015821991488337517\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 2.424950122833252 | KNN Loss: 2.3994698524475098 | CLS Loss: 0.02548038586974144\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 2.4518611431121826 | KNN Loss: 2.413942337036133 | CLS Loss: 0.03791872784495354\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 2.4377822875976562 | KNN Loss: 2.3982105255126953 | CLS Loss: 0.03957175090909004\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 2.4450292587280273 | KNN Loss: 2.421687126159668 | CLS Loss: 0.023342082276940346\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 2.423353672027588 | KNN Loss: 2.3770954608917236 | CLS Loss: 0.04625821113586426\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 2.4422607421875 | KNN Loss: 2.3935840129852295 | CLS Loss: 0.048676665872335434\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 2.407158136367798 | KNN Loss: 2.400628089904785 | CLS Loss: 0.006530056707561016\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 2.4448719024658203 | KNN Loss: 2.3840479850769043 | CLS Loss: 0.060823939740657806\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 2.4401609897613525 | KNN Loss: 2.411674737930298 | CLS Loss: 0.028486276045441628\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 2.4547226428985596 | KNN Loss: 2.4102768898010254 | CLS Loss: 0.044445790350437164\n",
      "Epoch: 037, Loss: 2.4355, Train: 0.9917, Valid: 0.9848, Best: 0.9852\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 2.430981397628784 | KNN Loss: 2.3852803707122803 | CLS Loss: 0.04570091888308525\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 2.4380335807800293 | KNN Loss: 2.4040794372558594 | CLS Loss: 0.0339541882276535\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 2.41298508644104 | KNN Loss: 2.3888425827026367 | CLS Loss: 0.02414258010685444\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 2.417130947113037 | KNN Loss: 2.3889517784118652 | CLS Loss: 0.02817925065755844\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 2.413872003555298 | KNN Loss: 2.3819215297698975 | CLS Loss: 0.031950563192367554\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 2.4416582584381104 | KNN Loss: 2.3769922256469727 | CLS Loss: 0.06466592848300934\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 2.4141573905944824 | KNN Loss: 2.37489914894104 | CLS Loss: 0.039258331060409546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 2.4266653060913086 | KNN Loss: 2.390873670578003 | CLS Loss: 0.035791538655757904\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 2.409208059310913 | KNN Loss: 2.3874573707580566 | CLS Loss: 0.02175065688788891\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 2.4285478591918945 | KNN Loss: 2.3856167793273926 | CLS Loss: 0.04293113574385643\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 2.450925827026367 | KNN Loss: 2.38423228263855 | CLS Loss: 0.06669352203607559\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 2.432851791381836 | KNN Loss: 2.3716628551483154 | CLS Loss: 0.061188954859972\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 2.4274561405181885 | KNN Loss: 2.4031805992126465 | CLS Loss: 0.024275517091155052\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 2.439312696456909 | KNN Loss: 2.4160356521606445 | CLS Loss: 0.023277027532458305\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 2.414743185043335 | KNN Loss: 2.3620781898498535 | CLS Loss: 0.05266499146819115\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 2.4736247062683105 | KNN Loss: 2.4393932819366455 | CLS Loss: 0.034231364727020264\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 2.431187152862549 | KNN Loss: 2.411602735519409 | CLS Loss: 0.01958448439836502\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 2.4150543212890625 | KNN Loss: 2.369022846221924 | CLS Loss: 0.046031493693590164\n",
      "Epoch: 038, Loss: 2.4327, Train: 0.9920, Valid: 0.9856, Best: 0.9856\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 2.431356906890869 | KNN Loss: 2.4114458560943604 | CLS Loss: 0.019911080598831177\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 2.4292140007019043 | KNN Loss: 2.402261972427368 | CLS Loss: 0.02695203572511673\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 2.429194688796997 | KNN Loss: 2.399845838546753 | CLS Loss: 0.02934892848134041\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 2.46338152885437 | KNN Loss: 2.4358201026916504 | CLS Loss: 0.027561398223042488\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 2.456641912460327 | KNN Loss: 2.3919739723205566 | CLS Loss: 0.06466783583164215\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 2.4450464248657227 | KNN Loss: 2.4177770614624023 | CLS Loss: 0.02726929448544979\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 2.4620208740234375 | KNN Loss: 2.3927226066589355 | CLS Loss: 0.06929837167263031\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 2.4137370586395264 | KNN Loss: 2.4060873985290527 | CLS Loss: 0.007649588864296675\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 2.4265878200531006 | KNN Loss: 2.3907883167266846 | CLS Loss: 0.035799432545900345\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 2.457308530807495 | KNN Loss: 2.4073739051818848 | CLS Loss: 0.04993471875786781\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 2.495262384414673 | KNN Loss: 2.4596750736236572 | CLS Loss: 0.035587288439273834\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 2.4620652198791504 | KNN Loss: 2.4184887409210205 | CLS Loss: 0.0435764342546463\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 2.4489707946777344 | KNN Loss: 2.400063991546631 | CLS Loss: 0.04890685901045799\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 2.4261248111724854 | KNN Loss: 2.404001235961914 | CLS Loss: 0.02212347649037838\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 2.3996427059173584 | KNN Loss: 2.3529727458953857 | CLS Loss: 0.04666998237371445\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 2.429774284362793 | KNN Loss: 2.391089677810669 | CLS Loss: 0.038684722036123276\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 2.4414336681365967 | KNN Loss: 2.3792812824249268 | CLS Loss: 0.06215228885412216\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 2.4803552627563477 | KNN Loss: 2.4358606338500977 | CLS Loss: 0.04449462890625\n",
      "Epoch: 039, Loss: 2.4319, Train: 0.9911, Valid: 0.9836, Best: 0.9856\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 2.4311928749084473 | KNN Loss: 2.4024736881256104 | CLS Loss: 0.02871927246451378\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 2.396357297897339 | KNN Loss: 2.3716204166412354 | CLS Loss: 0.024736784398555756\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 2.445845365524292 | KNN Loss: 2.4033164978027344 | CLS Loss: 0.042528796941041946\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 2.4442052841186523 | KNN Loss: 2.420516014099121 | CLS Loss: 0.02368931658565998\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 2.4144060611724854 | KNN Loss: 2.3746767044067383 | CLS Loss: 0.03972930833697319\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 2.3977713584899902 | KNN Loss: 2.3623857498168945 | CLS Loss: 0.03538549691438675\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 2.409919023513794 | KNN Loss: 2.3789689540863037 | CLS Loss: 0.0309500303119421\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 2.4185409545898438 | KNN Loss: 2.385749578475952 | CLS Loss: 0.03279146924614906\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 2.4405245780944824 | KNN Loss: 2.413699150085449 | CLS Loss: 0.02682540751993656\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 2.4403810501098633 | KNN Loss: 2.3886139392852783 | CLS Loss: 0.05176717787981033\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 2.4283275604248047 | KNN Loss: 2.3882689476013184 | CLS Loss: 0.04005865752696991\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 2.409061908721924 | KNN Loss: 2.385521411895752 | CLS Loss: 0.023540401831269264\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 2.3875415325164795 | KNN Loss: 2.3660919666290283 | CLS Loss: 0.021449536085128784\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 2.4567716121673584 | KNN Loss: 2.4222593307495117 | CLS Loss: 0.034512221813201904\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 2.4199113845825195 | KNN Loss: 2.4019925594329834 | CLS Loss: 0.017918871715664864\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 2.383758306503296 | KNN Loss: 2.363250494003296 | CLS Loss: 0.02050788700580597\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 2.441904067993164 | KNN Loss: 2.3949010372161865 | CLS Loss: 0.04700302705168724\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 2.4228591918945312 | KNN Loss: 2.408414602279663 | CLS Loss: 0.014444677159190178\n",
      "Epoch: 040, Loss: 2.4317, Train: 0.9913, Valid: 0.9853, Best: 0.9856\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 2.463388681411743 | KNN Loss: 2.427779197692871 | CLS Loss: 0.03560955449938774\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 2.4173033237457275 | KNN Loss: 2.4044361114501953 | CLS Loss: 0.012867297977209091\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 2.4033122062683105 | KNN Loss: 2.3853652477264404 | CLS Loss: 0.01794690266251564\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 2.4458088874816895 | KNN Loss: 2.3964662551879883 | CLS Loss: 0.04934271052479744\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 2.434720993041992 | KNN Loss: 2.3957598209381104 | CLS Loss: 0.03896116092801094\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 2.4122886657714844 | KNN Loss: 2.3759772777557373 | CLS Loss: 0.0363113209605217\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 2.447505235671997 | KNN Loss: 2.3899483680725098 | CLS Loss: 0.05755677819252014\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 2.436204195022583 | KNN Loss: 2.3886241912841797 | CLS Loss: 0.047579895704984665\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 2.4540305137634277 | KNN Loss: 2.4257068634033203 | CLS Loss: 0.028323592618107796\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 2.4297873973846436 | KNN Loss: 2.400644063949585 | CLS Loss: 0.02914338931441307\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 2.481297731399536 | KNN Loss: 2.452423095703125 | CLS Loss: 0.028874630108475685\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 2.4310481548309326 | KNN Loss: 2.4107470512390137 | CLS Loss: 0.02030104212462902\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 2.4242868423461914 | KNN Loss: 2.3798158168792725 | CLS Loss: 0.04447092488408089\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 2.431551456451416 | KNN Loss: 2.406524419784546 | CLS Loss: 0.025027001276612282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 2.4318292140960693 | KNN Loss: 2.3899600505828857 | CLS Loss: 0.041869111359119415\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 2.4123754501342773 | KNN Loss: 2.371616840362549 | CLS Loss: 0.04075856879353523\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 2.473102569580078 | KNN Loss: 2.4372599124908447 | CLS Loss: 0.03584270179271698\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 2.409773826599121 | KNN Loss: 2.382098436355591 | CLS Loss: 0.027675427496433258\n",
      "Epoch: 041, Loss: 2.4294, Train: 0.9923, Valid: 0.9851, Best: 0.9856\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 2.407243251800537 | KNN Loss: 2.3847317695617676 | CLS Loss: 0.022511545568704605\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 2.4022576808929443 | KNN Loss: 2.3826730251312256 | CLS Loss: 0.019584763795137405\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 2.3996481895446777 | KNN Loss: 2.3610355854034424 | CLS Loss: 0.03861256688833237\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 2.4413955211639404 | KNN Loss: 2.408125877380371 | CLS Loss: 0.033269599080085754\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 2.4217560291290283 | KNN Loss: 2.3948147296905518 | CLS Loss: 0.026941342279314995\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 2.384143114089966 | KNN Loss: 2.3622491359710693 | CLS Loss: 0.021894093602895737\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 2.410825729370117 | KNN Loss: 2.368661403656006 | CLS Loss: 0.042164307087659836\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 2.473761796951294 | KNN Loss: 2.4377880096435547 | CLS Loss: 0.035973817110061646\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 2.4208078384399414 | KNN Loss: 2.38637638092041 | CLS Loss: 0.03443147614598274\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 2.420794725418091 | KNN Loss: 2.401779890060425 | CLS Loss: 0.019014889374375343\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 2.4863321781158447 | KNN Loss: 2.4702653884887695 | CLS Loss: 0.01606683060526848\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 2.431908130645752 | KNN Loss: 2.4077773094177246 | CLS Loss: 0.024130804464221\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 2.427011251449585 | KNN Loss: 2.3850393295288086 | CLS Loss: 0.04197203367948532\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 2.414400815963745 | KNN Loss: 2.381373167037964 | CLS Loss: 0.033027585595846176\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 2.429201364517212 | KNN Loss: 2.3910610675811768 | CLS Loss: 0.038140393793582916\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 2.413325548171997 | KNN Loss: 2.3931822776794434 | CLS Loss: 0.02014317363500595\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 2.4183473587036133 | KNN Loss: 2.3762261867523193 | CLS Loss: 0.042121175676584244\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 2.405444860458374 | KNN Loss: 2.3632285594940186 | CLS Loss: 0.04221633821725845\n",
      "Epoch: 042, Loss: 2.4275, Train: 0.9917, Valid: 0.9851, Best: 0.9856\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 2.440467596054077 | KNN Loss: 2.3908565044403076 | CLS Loss: 0.04961115121841431\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 2.4103481769561768 | KNN Loss: 2.392565965652466 | CLS Loss: 0.017782248556613922\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 2.3990697860717773 | KNN Loss: 2.366079330444336 | CLS Loss: 0.03299042955040932\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 2.4092304706573486 | KNN Loss: 2.3793070316314697 | CLS Loss: 0.02992338500916958\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 2.438119649887085 | KNN Loss: 2.3937225341796875 | CLS Loss: 0.04439708590507507\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 2.4176151752471924 | KNN Loss: 2.4041755199432373 | CLS Loss: 0.013439584523439407\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 2.471524477005005 | KNN Loss: 2.427111864089966 | CLS Loss: 0.0444125235080719\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 2.4747679233551025 | KNN Loss: 2.432708263397217 | CLS Loss: 0.04205957055091858\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 2.4209444522857666 | KNN Loss: 2.395179510116577 | CLS Loss: 0.025765035301446915\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 2.4363536834716797 | KNN Loss: 2.3999428749084473 | CLS Loss: 0.03641081973910332\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 2.4377827644348145 | KNN Loss: 2.394136667251587 | CLS Loss: 0.04364607483148575\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 2.410336971282959 | KNN Loss: 2.378920555114746 | CLS Loss: 0.03141651675105095\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 2.442152976989746 | KNN Loss: 2.4087374210357666 | CLS Loss: 0.03341550752520561\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 2.442329168319702 | KNN Loss: 2.3889381885528564 | CLS Loss: 0.05339096859097481\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 2.4459846019744873 | KNN Loss: 2.410367012023926 | CLS Loss: 0.035617645829916\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 2.4165332317352295 | KNN Loss: 2.4018096923828125 | CLS Loss: 0.014723509550094604\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 2.402937650680542 | KNN Loss: 2.39212965965271 | CLS Loss: 0.010807927697896957\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 2.3816657066345215 | KNN Loss: 2.349637508392334 | CLS Loss: 0.03202814236283302\n",
      "Epoch: 043, Loss: 2.4265, Train: 0.9918, Valid: 0.9837, Best: 0.9856\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 2.4478566646575928 | KNN Loss: 2.4156129360198975 | CLS Loss: 0.03224380686879158\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 2.469818592071533 | KNN Loss: 2.4148433208465576 | CLS Loss: 0.05497516691684723\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 2.412055253982544 | KNN Loss: 2.3928279876708984 | CLS Loss: 0.019227342680096626\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 2.42571759223938 | KNN Loss: 2.3689188957214355 | CLS Loss: 0.056798599660396576\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 2.447580099105835 | KNN Loss: 2.4042162895202637 | CLS Loss: 0.043363820761442184\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 2.4210007190704346 | KNN Loss: 2.3987910747528076 | CLS Loss: 0.022209638729691505\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 2.459031105041504 | KNN Loss: 2.418606996536255 | CLS Loss: 0.040424227714538574\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 2.444256544113159 | KNN Loss: 2.424022912979126 | CLS Loss: 0.02023354172706604\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 2.443786382675171 | KNN Loss: 2.422896146774292 | CLS Loss: 0.02089015580713749\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 2.392035961151123 | KNN Loss: 2.3726253509521484 | CLS Loss: 0.01941055804491043\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 2.4350759983062744 | KNN Loss: 2.414595603942871 | CLS Loss: 0.020480399951338768\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 2.43231463432312 | KNN Loss: 2.3988912105560303 | CLS Loss: 0.03342331200838089\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 2.4626352787017822 | KNN Loss: 2.4254300594329834 | CLS Loss: 0.03720516711473465\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 2.4054601192474365 | KNN Loss: 2.3858633041381836 | CLS Loss: 0.019596876576542854\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 2.4312708377838135 | KNN Loss: 2.389174222946167 | CLS Loss: 0.042096592485904694\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 2.4228568077087402 | KNN Loss: 2.4076027870178223 | CLS Loss: 0.015254105441272259\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 2.4267735481262207 | KNN Loss: 2.3966801166534424 | CLS Loss: 0.030093465000391006\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 2.372451066970825 | KNN Loss: 2.347032308578491 | CLS Loss: 0.025418739765882492\n",
      "Epoch: 044, Loss: 2.4244, Train: 0.9919, Valid: 0.9849, Best: 0.9856\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 2.441742181777954 | KNN Loss: 2.3836562633514404 | CLS Loss: 0.05808582156896591\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 2.4050464630126953 | KNN Loss: 2.399859666824341 | CLS Loss: 0.005186698865145445\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 2.4457201957702637 | KNN Loss: 2.4099996089935303 | CLS Loss: 0.03572063520550728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 2.4013092517852783 | KNN Loss: 2.364500045776367 | CLS Loss: 0.0368092842400074\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 2.4418785572052 | KNN Loss: 2.4079415798187256 | CLS Loss: 0.03393692150712013\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 2.4135656356811523 | KNN Loss: 2.361543655395508 | CLS Loss: 0.052021972835063934\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 2.453874111175537 | KNN Loss: 2.4235379695892334 | CLS Loss: 0.030336234718561172\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 2.4761056900024414 | KNN Loss: 2.446397542953491 | CLS Loss: 0.029708154499530792\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 2.3900556564331055 | KNN Loss: 2.3479058742523193 | CLS Loss: 0.04214989393949509\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 2.4200856685638428 | KNN Loss: 2.3991928100585938 | CLS Loss: 0.020892826840281487\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 2.420787811279297 | KNN Loss: 2.3883464336395264 | CLS Loss: 0.032441336661577225\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 2.451923131942749 | KNN Loss: 2.415700674057007 | CLS Loss: 0.036222536116838455\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 2.403076648712158 | KNN Loss: 2.367357015609741 | CLS Loss: 0.03571953997015953\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 2.428435802459717 | KNN Loss: 2.393500566482544 | CLS Loss: 0.03493528068065643\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 2.4378812313079834 | KNN Loss: 2.410613536834717 | CLS Loss: 0.02726770006120205\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 2.4760608673095703 | KNN Loss: 2.4269394874572754 | CLS Loss: 0.0491214320063591\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 2.4255409240722656 | KNN Loss: 2.3786840438842773 | CLS Loss: 0.04685686156153679\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 2.434856414794922 | KNN Loss: 2.4045000076293945 | CLS Loss: 0.03035651706159115\n",
      "Epoch: 045, Loss: 2.4294, Train: 0.9913, Valid: 0.9849, Best: 0.9856\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 2.4335997104644775 | KNN Loss: 2.400048017501831 | CLS Loss: 0.033551592379808426\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 2.427870988845825 | KNN Loss: 2.3807404041290283 | CLS Loss: 0.04713069647550583\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 2.4054667949676514 | KNN Loss: 2.3921167850494385 | CLS Loss: 0.013350077904760838\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 2.4172792434692383 | KNN Loss: 2.371060609817505 | CLS Loss: 0.0462186336517334\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 2.4251298904418945 | KNN Loss: 2.397235155105591 | CLS Loss: 0.02789468690752983\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 2.4482033252716064 | KNN Loss: 2.401700496673584 | CLS Loss: 0.046502891927957535\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 2.41080379486084 | KNN Loss: 2.3473141193389893 | CLS Loss: 0.06348975747823715\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 2.388624429702759 | KNN Loss: 2.3670825958251953 | CLS Loss: 0.021541910246014595\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 2.4348816871643066 | KNN Loss: 2.4054372310638428 | CLS Loss: 0.02944444864988327\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 2.4480412006378174 | KNN Loss: 2.3898279666900635 | CLS Loss: 0.05821322649717331\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 2.4014687538146973 | KNN Loss: 2.363877534866333 | CLS Loss: 0.03759113699197769\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 2.464470863342285 | KNN Loss: 2.4101104736328125 | CLS Loss: 0.05436038598418236\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 2.4269580841064453 | KNN Loss: 2.399129629135132 | CLS Loss: 0.027828358113765717\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 2.437694549560547 | KNN Loss: 2.430586814880371 | CLS Loss: 0.007107829209417105\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 2.426975965499878 | KNN Loss: 2.3830857276916504 | CLS Loss: 0.043890293687582016\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 2.435831308364868 | KNN Loss: 2.424041748046875 | CLS Loss: 0.011789530515670776\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 2.444504976272583 | KNN Loss: 2.407674551010132 | CLS Loss: 0.036830540746450424\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 2.4391465187072754 | KNN Loss: 2.4059722423553467 | CLS Loss: 0.03317435458302498\n",
      "Epoch: 046, Loss: 2.4290, Train: 0.9920, Valid: 0.9852, Best: 0.9856\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 2.39969539642334 | KNN Loss: 2.370079755783081 | CLS Loss: 0.029615668579936028\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 2.454094171524048 | KNN Loss: 2.4393606185913086 | CLS Loss: 0.014733586460351944\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 2.391188621520996 | KNN Loss: 2.365389585494995 | CLS Loss: 0.025798967108130455\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 2.417682409286499 | KNN Loss: 2.4076788425445557 | CLS Loss: 0.010003579780459404\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 2.4327173233032227 | KNN Loss: 2.392136573791504 | CLS Loss: 0.04058082774281502\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 2.429534673690796 | KNN Loss: 2.4023525714874268 | CLS Loss: 0.027182143181562424\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 2.4151973724365234 | KNN Loss: 2.3690712451934814 | CLS Loss: 0.0461261160671711\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 2.3988900184631348 | KNN Loss: 2.3886897563934326 | CLS Loss: 0.010200190357863903\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 2.418823003768921 | KNN Loss: 2.392971992492676 | CLS Loss: 0.025851082056760788\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 2.392897605895996 | KNN Loss: 2.3764917850494385 | CLS Loss: 0.01640588976442814\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 2.434910297393799 | KNN Loss: 2.4045419692993164 | CLS Loss: 0.03036835975944996\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 2.3852171897888184 | KNN Loss: 2.3540029525756836 | CLS Loss: 0.031214268878102303\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 2.4145960807800293 | KNN Loss: 2.375680923461914 | CLS Loss: 0.038915202021598816\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 2.3805158138275146 | KNN Loss: 2.365107536315918 | CLS Loss: 0.015408213250339031\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 2.438491106033325 | KNN Loss: 2.4131667613983154 | CLS Loss: 0.02532443031668663\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 2.43318510055542 | KNN Loss: 2.4003093242645264 | CLS Loss: 0.032875802367925644\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 2.461937665939331 | KNN Loss: 2.4374771118164062 | CLS Loss: 0.024460671469569206\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 2.430800676345825 | KNN Loss: 2.4154632091522217 | CLS Loss: 0.015337415039539337\n",
      "Epoch: 047, Loss: 2.4254, Train: 0.9929, Valid: 0.9859, Best: 0.9859\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 2.4469916820526123 | KNN Loss: 2.422447919845581 | CLS Loss: 0.02454371191561222\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 2.392864465713501 | KNN Loss: 2.371894359588623 | CLS Loss: 0.020969990640878677\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 2.431398630142212 | KNN Loss: 2.4101617336273193 | CLS Loss: 0.02123682014644146\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 2.386948347091675 | KNN Loss: 2.3791518211364746 | CLS Loss: 0.007796605117619038\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 2.3859522342681885 | KNN Loss: 2.368523597717285 | CLS Loss: 0.017428625375032425\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 2.4103221893310547 | KNN Loss: 2.366053581237793 | CLS Loss: 0.044268712401390076\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 2.419529438018799 | KNN Loss: 2.3877525329589844 | CLS Loss: 0.03177688643336296\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 2.416055917739868 | KNN Loss: 2.378769636154175 | CLS Loss: 0.037286292761564255\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 2.402251720428467 | KNN Loss: 2.3894925117492676 | CLS Loss: 0.012759118340909481\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 2.372880458831787 | KNN Loss: 2.3570897579193115 | CLS Loss: 0.015790734440088272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 2.4027414321899414 | KNN Loss: 2.3924121856689453 | CLS Loss: 0.010329249314963818\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 2.42620587348938 | KNN Loss: 2.406595230102539 | CLS Loss: 0.019610699266195297\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 2.406614303588867 | KNN Loss: 2.3956828117370605 | CLS Loss: 0.010931439697742462\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 2.403782606124878 | KNN Loss: 2.376964569091797 | CLS Loss: 0.026818130165338516\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 2.4145877361297607 | KNN Loss: 2.3791756629943848 | CLS Loss: 0.035412050783634186\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 2.4001307487487793 | KNN Loss: 2.372769832611084 | CLS Loss: 0.027360999956727028\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 2.4581501483917236 | KNN Loss: 2.438227891921997 | CLS Loss: 0.019922195002436638\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 2.4068164825439453 | KNN Loss: 2.387718915939331 | CLS Loss: 0.019097451120615005\n",
      "Epoch: 048, Loss: 2.4223, Train: 0.9928, Valid: 0.9847, Best: 0.9859\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 2.4480855464935303 | KNN Loss: 2.4203269481658936 | CLS Loss: 0.027758562937378883\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 2.4411439895629883 | KNN Loss: 2.42189359664917 | CLS Loss: 0.019250400364398956\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 2.4265646934509277 | KNN Loss: 2.4038069248199463 | CLS Loss: 0.022757697850465775\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 2.3845772743225098 | KNN Loss: 2.3644564151763916 | CLS Loss: 0.020120864734053612\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 2.3999581336975098 | KNN Loss: 2.385660171508789 | CLS Loss: 0.014298031106591225\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 2.401702404022217 | KNN Loss: 2.378387212753296 | CLS Loss: 0.02331526391208172\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 2.447537422180176 | KNN Loss: 2.4145545959472656 | CLS Loss: 0.032982829958200455\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 2.4415886402130127 | KNN Loss: 2.4079031944274902 | CLS Loss: 0.03368537127971649\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 2.427788019180298 | KNN Loss: 2.3901901245117188 | CLS Loss: 0.03759799897670746\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 2.4301061630249023 | KNN Loss: 2.386929750442505 | CLS Loss: 0.043176356703042984\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 2.387052536010742 | KNN Loss: 2.3688361644744873 | CLS Loss: 0.018216386437416077\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 2.367281675338745 | KNN Loss: 2.3582866191864014 | CLS Loss: 0.00899499747902155\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 2.45147967338562 | KNN Loss: 2.391474962234497 | CLS Loss: 0.06000477820634842\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 2.3884994983673096 | KNN Loss: 2.3780863285064697 | CLS Loss: 0.010413200594484806\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 2.454230546951294 | KNN Loss: 2.423365592956543 | CLS Loss: 0.030864985659718513\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 2.4069080352783203 | KNN Loss: 2.3867461681365967 | CLS Loss: 0.02016192488372326\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 2.4032657146453857 | KNN Loss: 2.376133441925049 | CLS Loss: 0.027132239192724228\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 2.4223475456237793 | KNN Loss: 2.384230136871338 | CLS Loss: 0.038117408752441406\n",
      "Epoch: 049, Loss: 2.4267, Train: 0.9916, Valid: 0.9847, Best: 0.9859\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 2.4612579345703125 | KNN Loss: 2.4254279136657715 | CLS Loss: 0.03582996502518654\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 2.387071132659912 | KNN Loss: 2.365769863128662 | CLS Loss: 0.021301211789250374\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 2.4897615909576416 | KNN Loss: 2.442763566970825 | CLS Loss: 0.046997975558042526\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 2.4040238857269287 | KNN Loss: 2.397491693496704 | CLS Loss: 0.006532240193337202\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 2.419430732727051 | KNN Loss: 2.403454065322876 | CLS Loss: 0.01597677357494831\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 2.4559900760650635 | KNN Loss: 2.4007716178894043 | CLS Loss: 0.05521838366985321\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 2.4229302406311035 | KNN Loss: 2.3778698444366455 | CLS Loss: 0.04506046697497368\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 2.462895631790161 | KNN Loss: 2.432440996170044 | CLS Loss: 0.030454520136117935\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 2.4160120487213135 | KNN Loss: 2.3841094970703125 | CLS Loss: 0.0319024883210659\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 2.467428684234619 | KNN Loss: 2.4151957035064697 | CLS Loss: 0.052232906222343445\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 2.4412500858306885 | KNN Loss: 2.429687738418579 | CLS Loss: 0.011562344618141651\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 2.4310219287872314 | KNN Loss: 2.4044973850250244 | CLS Loss: 0.026524510234594345\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 2.44987154006958 | KNN Loss: 2.4038262367248535 | CLS Loss: 0.04604535177350044\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 2.453892230987549 | KNN Loss: 2.409885883331299 | CLS Loss: 0.044006261974573135\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 2.4068970680236816 | KNN Loss: 2.39599871635437 | CLS Loss: 0.010898362845182419\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 2.479468822479248 | KNN Loss: 2.4596574306488037 | CLS Loss: 0.019811345264315605\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 2.40114426612854 | KNN Loss: 2.342761278152466 | CLS Loss: 0.05838288366794586\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 2.434450626373291 | KNN Loss: 2.4205362796783447 | CLS Loss: 0.01391426008194685\n",
      "Epoch: 050, Loss: 2.4294, Train: 0.9927, Valid: 0.9857, Best: 0.9859\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 2.4259519577026367 | KNN Loss: 2.386411666870117 | CLS Loss: 0.03954019770026207\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 2.3856394290924072 | KNN Loss: 2.3573238849639893 | CLS Loss: 0.028315505012869835\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 2.4666223526000977 | KNN Loss: 2.410517930984497 | CLS Loss: 0.056104302406311035\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 2.4600143432617188 | KNN Loss: 2.4435393810272217 | CLS Loss: 0.01647493615746498\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 2.4400711059570312 | KNN Loss: 2.3801372051239014 | CLS Loss: 0.0599338598549366\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 2.426673412322998 | KNN Loss: 2.3961760997772217 | CLS Loss: 0.03049725852906704\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 2.393584966659546 | KNN Loss: 2.3756699562072754 | CLS Loss: 0.017914989963173866\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 2.387805938720703 | KNN Loss: 2.3555779457092285 | CLS Loss: 0.03222794085741043\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 2.427097797393799 | KNN Loss: 2.3884236812591553 | CLS Loss: 0.03867407143115997\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 2.408384323120117 | KNN Loss: 2.3933656215667725 | CLS Loss: 0.0150187648832798\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 2.3977437019348145 | KNN Loss: 2.387186288833618 | CLS Loss: 0.010557364672422409\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 2.410855531692505 | KNN Loss: 2.3794591426849365 | CLS Loss: 0.03139650076627731\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 2.401855707168579 | KNN Loss: 2.374063730239868 | CLS Loss: 0.02779209427535534\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 2.441452741622925 | KNN Loss: 2.433638334274292 | CLS Loss: 0.00781442690640688\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 2.441818952560425 | KNN Loss: 2.42121958732605 | CLS Loss: 0.020599400624632835\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 2.4532599449157715 | KNN Loss: 2.4123740196228027 | CLS Loss: 0.04088594391942024\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 2.4348859786987305 | KNN Loss: 2.4101722240448 | CLS Loss: 0.024713676422834396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 2.383180856704712 | KNN Loss: 2.367116689682007 | CLS Loss: 0.016064073890447617\n",
      "Epoch: 051, Loss: 2.4296, Train: 0.9918, Valid: 0.9846, Best: 0.9859\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 2.439235210418701 | KNN Loss: 2.4167168140411377 | CLS Loss: 0.022518321871757507\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 2.4614853858947754 | KNN Loss: 2.4223248958587646 | CLS Loss: 0.03916052356362343\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 2.46586275100708 | KNN Loss: 2.429654359817505 | CLS Loss: 0.03620840609073639\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 2.4359941482543945 | KNN Loss: 2.4014086723327637 | CLS Loss: 0.03458549454808235\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 2.4478704929351807 | KNN Loss: 2.418701171875 | CLS Loss: 0.029169205576181412\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 2.4477317333221436 | KNN Loss: 2.4179015159606934 | CLS Loss: 0.02983017824590206\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 2.4124062061309814 | KNN Loss: 2.398974895477295 | CLS Loss: 0.01343129388988018\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 2.443965435028076 | KNN Loss: 2.4186525344848633 | CLS Loss: 0.02531289868056774\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 2.4078478813171387 | KNN Loss: 2.353754997253418 | CLS Loss: 0.05409293994307518\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 2.389505386352539 | KNN Loss: 2.3715436458587646 | CLS Loss: 0.017961721867322922\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 2.4046807289123535 | KNN Loss: 2.3786349296569824 | CLS Loss: 0.026045765727758408\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 2.378969669342041 | KNN Loss: 2.350621461868286 | CLS Loss: 0.02834814228117466\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 2.3994503021240234 | KNN Loss: 2.3883485794067383 | CLS Loss: 0.01110176183283329\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 2.3858089447021484 | KNN Loss: 2.363257646560669 | CLS Loss: 0.02255138009786606\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 2.419637680053711 | KNN Loss: 2.3766403198242188 | CLS Loss: 0.04299738630652428\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 2.4050538539886475 | KNN Loss: 2.372739791870117 | CLS Loss: 0.03231409564614296\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 2.4244883060455322 | KNN Loss: 2.392925500869751 | CLS Loss: 0.031562723219394684\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 2.439002752304077 | KNN Loss: 2.378763198852539 | CLS Loss: 0.06023959815502167\n",
      "Epoch: 052, Loss: 2.4306, Train: 0.9933, Valid: 0.9862, Best: 0.9862\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 2.3941216468811035 | KNN Loss: 2.37306809425354 | CLS Loss: 0.021053578704595566\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 2.4600350856781006 | KNN Loss: 2.426197052001953 | CLS Loss: 0.033837951719760895\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 2.425987958908081 | KNN Loss: 2.4011194705963135 | CLS Loss: 0.02486838772892952\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 2.436414957046509 | KNN Loss: 2.4188125133514404 | CLS Loss: 0.017602555453777313\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 2.4544174671173096 | KNN Loss: 2.3856842517852783 | CLS Loss: 0.0687331035733223\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 2.43670654296875 | KNN Loss: 2.4172279834747314 | CLS Loss: 0.01947866380214691\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 2.4308152198791504 | KNN Loss: 2.3919994831085205 | CLS Loss: 0.0388156920671463\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 2.4308671951293945 | KNN Loss: 2.4021692276000977 | CLS Loss: 0.0286979079246521\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 2.4421920776367188 | KNN Loss: 2.3939032554626465 | CLS Loss: 0.04828881099820137\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 2.428863286972046 | KNN Loss: 2.4083216190338135 | CLS Loss: 0.020541604608297348\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 2.3929555416107178 | KNN Loss: 2.380643129348755 | CLS Loss: 0.012312367558479309\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 2.438542366027832 | KNN Loss: 2.4041686058044434 | CLS Loss: 0.03437381610274315\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 2.4397687911987305 | KNN Loss: 2.39864182472229 | CLS Loss: 0.04112686216831207\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 2.3958606719970703 | KNN Loss: 2.3808391094207764 | CLS Loss: 0.015021498315036297\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 2.4256041049957275 | KNN Loss: 2.38763689994812 | CLS Loss: 0.037967223674058914\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 2.416713237762451 | KNN Loss: 2.3917758464813232 | CLS Loss: 0.024937331676483154\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 2.4413211345672607 | KNN Loss: 2.4201176166534424 | CLS Loss: 0.021203627809882164\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 2.4226255416870117 | KNN Loss: 2.386833906173706 | CLS Loss: 0.035791680216789246\n",
      "Epoch: 053, Loss: 2.4290, Train: 0.9925, Valid: 0.9858, Best: 0.9862\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 2.44154953956604 | KNN Loss: 2.406357765197754 | CLS Loss: 0.03519183397293091\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 2.4073545932769775 | KNN Loss: 2.372284412384033 | CLS Loss: 0.035070087760686874\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 2.422368049621582 | KNN Loss: 2.4036643505096436 | CLS Loss: 0.01870381459593773\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 2.4555509090423584 | KNN Loss: 2.4387197494506836 | CLS Loss: 0.0168310534209013\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 2.398092031478882 | KNN Loss: 2.3912875652313232 | CLS Loss: 0.0068044536747038364\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 2.402482271194458 | KNN Loss: 2.380281686782837 | CLS Loss: 0.022200478240847588\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 2.360142707824707 | KNN Loss: 2.3482770919799805 | CLS Loss: 0.011865679174661636\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 2.4582431316375732 | KNN Loss: 2.4165453910827637 | CLS Loss: 0.041697822511196136\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 2.386202573776245 | KNN Loss: 2.3690185546875 | CLS Loss: 0.017183946445584297\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 2.431173324584961 | KNN Loss: 2.4016027450561523 | CLS Loss: 0.029570680111646652\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 2.410529851913452 | KNN Loss: 2.4034669399261475 | CLS Loss: 0.007062872406095266\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 2.426244020462036 | KNN Loss: 2.4021639823913574 | CLS Loss: 0.02408004179596901\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 2.4018824100494385 | KNN Loss: 2.3868517875671387 | CLS Loss: 0.015030539594590664\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 2.417189598083496 | KNN Loss: 2.393476963043213 | CLS Loss: 0.02371264062821865\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 2.4176366329193115 | KNN Loss: 2.3801777362823486 | CLS Loss: 0.037458986043930054\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 2.4743247032165527 | KNN Loss: 2.455495595932007 | CLS Loss: 0.018829194828867912\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 2.4423115253448486 | KNN Loss: 2.406269073486328 | CLS Loss: 0.03604244440793991\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 2.423657178878784 | KNN Loss: 2.3786251544952393 | CLS Loss: 0.045032043009996414\n",
      "Epoch: 054, Loss: 2.4247, Train: 0.9923, Valid: 0.9847, Best: 0.9862\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 2.4051730632781982 | KNN Loss: 2.3658485412597656 | CLS Loss: 0.03932447358965874\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 2.411569356918335 | KNN Loss: 2.3959920406341553 | CLS Loss: 0.015577387996017933\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 2.4197518825531006 | KNN Loss: 2.404106378555298 | CLS Loss: 0.015645431354641914\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 2.435513496398926 | KNN Loss: 2.402092695236206 | CLS Loss: 0.033420734107494354\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 2.4161770343780518 | KNN Loss: 2.4121952056884766 | CLS Loss: 0.003981920424848795\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 2.5059614181518555 | KNN Loss: 2.4522910118103027 | CLS Loss: 0.05367043614387512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 2.4424192905426025 | KNN Loss: 2.436392307281494 | CLS Loss: 0.006027053575962782\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 2.403080701828003 | KNN Loss: 2.3860957622528076 | CLS Loss: 0.01698501594364643\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 2.408107280731201 | KNN Loss: 2.3774731159210205 | CLS Loss: 0.030634064227342606\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 2.4201889038085938 | KNN Loss: 2.4083738327026367 | CLS Loss: 0.011814998462796211\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 2.436630964279175 | KNN Loss: 2.4129209518432617 | CLS Loss: 0.023710057139396667\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 2.424551010131836 | KNN Loss: 2.398169994354248 | CLS Loss: 0.026381107047200203\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 2.4592528343200684 | KNN Loss: 2.41036319732666 | CLS Loss: 0.04888974875211716\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 2.441842555999756 | KNN Loss: 2.4138569831848145 | CLS Loss: 0.027985604479908943\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 2.4616799354553223 | KNN Loss: 2.424534797668457 | CLS Loss: 0.03714510425925255\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 2.4367294311523438 | KNN Loss: 2.4064407348632812 | CLS Loss: 0.03028864599764347\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 2.3684701919555664 | KNN Loss: 2.3315916061401367 | CLS Loss: 0.03687866032123566\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 2.4559426307678223 | KNN Loss: 2.4233906269073486 | CLS Loss: 0.03255193680524826\n",
      "Epoch: 055, Loss: 2.4275, Train: 0.9943, Valid: 0.9858, Best: 0.9862\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 2.391507148742676 | KNN Loss: 2.362161636352539 | CLS Loss: 0.029345428571105003\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 2.436563491821289 | KNN Loss: 2.3956215381622314 | CLS Loss: 0.04094184935092926\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 2.4299159049987793 | KNN Loss: 2.3957064151763916 | CLS Loss: 0.03420941159129143\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 2.4449973106384277 | KNN Loss: 2.4045939445495605 | CLS Loss: 0.040403347462415695\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 2.4107728004455566 | KNN Loss: 2.4027817249298096 | CLS Loss: 0.007991189137101173\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 2.446442127227783 | KNN Loss: 2.4368319511413574 | CLS Loss: 0.00961010716855526\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 2.418003559112549 | KNN Loss: 2.4069664478302 | CLS Loss: 0.01103711873292923\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 2.4030370712280273 | KNN Loss: 2.380849838256836 | CLS Loss: 0.0221872441470623\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 2.4346957206726074 | KNN Loss: 2.426051616668701 | CLS Loss: 0.008644193410873413\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 2.434622049331665 | KNN Loss: 2.4187474250793457 | CLS Loss: 0.015874670818448067\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 2.4501724243164062 | KNN Loss: 2.425981044769287 | CLS Loss: 0.02419133670628071\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 2.431164026260376 | KNN Loss: 2.408933639526367 | CLS Loss: 0.02223050408065319\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 2.4178807735443115 | KNN Loss: 2.399400472640991 | CLS Loss: 0.018480334430933\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 2.4342610836029053 | KNN Loss: 2.4240221977233887 | CLS Loss: 0.010239001363515854\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 2.406712055206299 | KNN Loss: 2.3957080841064453 | CLS Loss: 0.011004069820046425\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 2.4305622577667236 | KNN Loss: 2.4063007831573486 | CLS Loss: 0.02426154352724552\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 2.474736213684082 | KNN Loss: 2.411616802215576 | CLS Loss: 0.06311938166618347\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 2.4400594234466553 | KNN Loss: 2.388831377029419 | CLS Loss: 0.05122799426317215\n",
      "Epoch: 056, Loss: 2.4288, Train: 0.9944, Valid: 0.9868, Best: 0.9868\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 2.4189469814300537 | KNN Loss: 2.4101059436798096 | CLS Loss: 0.008841036818921566\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 2.386042833328247 | KNN Loss: 2.382861614227295 | CLS Loss: 0.0031812782399356365\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 2.4418463706970215 | KNN Loss: 2.425767183303833 | CLS Loss: 0.01607927493751049\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 2.454423189163208 | KNN Loss: 2.434317111968994 | CLS Loss: 0.020106079056859016\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 2.44482421875 | KNN Loss: 2.4094181060791016 | CLS Loss: 0.03540603071451187\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 2.3815553188323975 | KNN Loss: 2.3733551502227783 | CLS Loss: 0.008200252428650856\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 2.4164717197418213 | KNN Loss: 2.408217430114746 | CLS Loss: 0.008254391141235828\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 2.4447858333587646 | KNN Loss: 2.403353452682495 | CLS Loss: 0.041432321071624756\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 2.456115961074829 | KNN Loss: 2.437577724456787 | CLS Loss: 0.018538150936365128\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 2.4090232849121094 | KNN Loss: 2.398808002471924 | CLS Loss: 0.010215258225798607\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 2.4070816040039062 | KNN Loss: 2.3943421840667725 | CLS Loss: 0.012739329598844051\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 2.394620895385742 | KNN Loss: 2.369821071624756 | CLS Loss: 0.024799905717372894\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 2.4358084201812744 | KNN Loss: 2.413618564605713 | CLS Loss: 0.022189967334270477\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 2.438096523284912 | KNN Loss: 2.4215877056121826 | CLS Loss: 0.016508737578988075\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 2.4030354022979736 | KNN Loss: 2.3778388500213623 | CLS Loss: 0.025196591392159462\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 2.4109981060028076 | KNN Loss: 2.367091178894043 | CLS Loss: 0.04390687122941017\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 2.464331865310669 | KNN Loss: 2.4159586429595947 | CLS Loss: 0.04837322235107422\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 2.418583631515503 | KNN Loss: 2.3886537551879883 | CLS Loss: 0.02992984838783741\n",
      "Epoch: 057, Loss: 2.4291, Train: 0.9923, Valid: 0.9842, Best: 0.9868\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 2.4471590518951416 | KNN Loss: 2.423715591430664 | CLS Loss: 0.023443369194865227\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 2.459268569946289 | KNN Loss: 2.4402828216552734 | CLS Loss: 0.018985670059919357\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 2.418611526489258 | KNN Loss: 2.3848278522491455 | CLS Loss: 0.033783651888370514\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 2.4208006858825684 | KNN Loss: 2.4038498401641846 | CLS Loss: 0.016950756311416626\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 2.40811824798584 | KNN Loss: 2.3960471153259277 | CLS Loss: 0.012071195989847183\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 2.3616743087768555 | KNN Loss: 2.3404290676116943 | CLS Loss: 0.021245190873742104\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 2.3891749382019043 | KNN Loss: 2.3763225078582764 | CLS Loss: 0.012852387502789497\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 2.4395041465759277 | KNN Loss: 2.3969063758850098 | CLS Loss: 0.04259772598743439\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 2.4369521141052246 | KNN Loss: 2.4083237648010254 | CLS Loss: 0.028628244996070862\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 2.4391791820526123 | KNN Loss: 2.4175260066986084 | CLS Loss: 0.021653292700648308\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 2.4478702545166016 | KNN Loss: 2.4335315227508545 | CLS Loss: 0.014338701032102108\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 2.479034185409546 | KNN Loss: 2.452317237854004 | CLS Loss: 0.026716889813542366\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 2.4331674575805664 | KNN Loss: 2.421755313873291 | CLS Loss: 0.011412031948566437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 2.388741970062256 | KNN Loss: 2.3770382404327393 | CLS Loss: 0.011703667230904102\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 2.413048505783081 | KNN Loss: 2.352484941482544 | CLS Loss: 0.060563549399375916\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 2.443957805633545 | KNN Loss: 2.420886993408203 | CLS Loss: 0.023070892319083214\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 2.435236692428589 | KNN Loss: 2.4116647243499756 | CLS Loss: 0.023571966215968132\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 2.400999069213867 | KNN Loss: 2.3807828426361084 | CLS Loss: 0.020216302946209908\n",
      "Epoch: 058, Loss: 2.4274, Train: 0.9931, Valid: 0.9855, Best: 0.9868\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 2.4178919792175293 | KNN Loss: 2.3945934772491455 | CLS Loss: 0.023298412561416626\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 2.413278341293335 | KNN Loss: 2.389416456222534 | CLS Loss: 0.02386198192834854\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 2.4560861587524414 | KNN Loss: 2.4297983646392822 | CLS Loss: 0.02628781646490097\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 2.470754861831665 | KNN Loss: 2.4516987800598145 | CLS Loss: 0.01905597187578678\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 2.448951482772827 | KNN Loss: 2.441340446472168 | CLS Loss: 0.007610924541950226\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 2.398153781890869 | KNN Loss: 2.380516529083252 | CLS Loss: 0.017637278884649277\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 2.389561891555786 | KNN Loss: 2.371248960494995 | CLS Loss: 0.01831297017633915\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 2.438293218612671 | KNN Loss: 2.4174163341522217 | CLS Loss: 0.020876804366707802\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 2.438924551010132 | KNN Loss: 2.409515857696533 | CLS Loss: 0.029408587142825127\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 2.4340085983276367 | KNN Loss: 2.4054713249206543 | CLS Loss: 0.02853727526962757\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 2.3846113681793213 | KNN Loss: 2.3702564239501953 | CLS Loss: 0.014354917220771313\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 2.4412143230438232 | KNN Loss: 2.3810760974884033 | CLS Loss: 0.06013825163245201\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 2.4025700092315674 | KNN Loss: 2.394643783569336 | CLS Loss: 0.007926230318844318\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 2.43013596534729 | KNN Loss: 2.4125418663024902 | CLS Loss: 0.01759416051208973\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 2.4354162216186523 | KNN Loss: 2.415980100631714 | CLS Loss: 0.019436003640294075\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 2.4214487075805664 | KNN Loss: 2.3951847553253174 | CLS Loss: 0.02626403234899044\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 2.4390172958374023 | KNN Loss: 2.434110641479492 | CLS Loss: 0.004906677175313234\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 2.420259475708008 | KNN Loss: 2.374042510986328 | CLS Loss: 0.046216994524002075\n",
      "Epoch: 059, Loss: 2.4290, Train: 0.9941, Valid: 0.9869, Best: 0.9869\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 2.4004366397857666 | KNN Loss: 2.370443820953369 | CLS Loss: 0.029992705211043358\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 2.4098973274230957 | KNN Loss: 2.3869409561157227 | CLS Loss: 0.022956421598792076\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 2.414431095123291 | KNN Loss: 2.399143934249878 | CLS Loss: 0.015287178568542004\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 2.437678813934326 | KNN Loss: 2.406822919845581 | CLS Loss: 0.030855894088745117\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 2.402475357055664 | KNN Loss: 2.3856441974639893 | CLS Loss: 0.016831183806061745\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 2.456172227859497 | KNN Loss: 2.418280601501465 | CLS Loss: 0.03789151832461357\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 2.4059925079345703 | KNN Loss: 2.383937358856201 | CLS Loss: 0.022055232897400856\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 2.40789794921875 | KNN Loss: 2.3886656761169434 | CLS Loss: 0.019232315942645073\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 2.401559829711914 | KNN Loss: 2.3765265941619873 | CLS Loss: 0.02503335475921631\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 2.4926095008850098 | KNN Loss: 2.465637683868408 | CLS Loss: 0.02697179652750492\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 2.458076000213623 | KNN Loss: 2.444671869277954 | CLS Loss: 0.013404144905507565\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 2.4257946014404297 | KNN Loss: 2.3916330337524414 | CLS Loss: 0.0341615155339241\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 2.3763010501861572 | KNN Loss: 2.3582425117492676 | CLS Loss: 0.018058573827147484\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 2.4090096950531006 | KNN Loss: 2.3968443870544434 | CLS Loss: 0.012165376916527748\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 2.39894962310791 | KNN Loss: 2.36871075630188 | CLS Loss: 0.030238935723900795\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 2.455638885498047 | KNN Loss: 2.4301979541778564 | CLS Loss: 0.025440972298383713\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 2.461627244949341 | KNN Loss: 2.4349889755249023 | CLS Loss: 0.026638248935341835\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 2.4112017154693604 | KNN Loss: 2.395552635192871 | CLS Loss: 0.015649016946554184\n",
      "Epoch: 060, Loss: 2.4265, Train: 0.9927, Valid: 0.9847, Best: 0.9869\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 2.4060933589935303 | KNN Loss: 2.3852334022521973 | CLS Loss: 0.02085989899933338\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 2.4283270835876465 | KNN Loss: 2.4042301177978516 | CLS Loss: 0.024096880108118057\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 2.434215545654297 | KNN Loss: 2.4085819721221924 | CLS Loss: 0.025633497163653374\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 2.4182815551757812 | KNN Loss: 2.3768208026885986 | CLS Loss: 0.04146075248718262\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 2.4534668922424316 | KNN Loss: 2.419219493865967 | CLS Loss: 0.03424739092588425\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 2.4267473220825195 | KNN Loss: 2.413471221923828 | CLS Loss: 0.013276013545691967\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 2.417733907699585 | KNN Loss: 2.376185894012451 | CLS Loss: 0.04154792055487633\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 2.4091875553131104 | KNN Loss: 2.382434368133545 | CLS Loss: 0.026753244921565056\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 2.4007484912872314 | KNN Loss: 2.3685083389282227 | CLS Loss: 0.03224024921655655\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 2.403865337371826 | KNN Loss: 2.399376392364502 | CLS Loss: 0.00448892917484045\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 2.4120447635650635 | KNN Loss: 2.4035165309906006 | CLS Loss: 0.008528294041752815\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 2.403294801712036 | KNN Loss: 2.3874213695526123 | CLS Loss: 0.0158733818680048\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 2.4009647369384766 | KNN Loss: 2.382784843444824 | CLS Loss: 0.018179893493652344\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 2.447758913040161 | KNN Loss: 2.427915334701538 | CLS Loss: 0.01984368823468685\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 2.4477031230926514 | KNN Loss: 2.4232943058013916 | CLS Loss: 0.024408703669905663\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 2.4036850929260254 | KNN Loss: 2.3837666511535645 | CLS Loss: 0.01991835981607437\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 2.435580253601074 | KNN Loss: 2.3928072452545166 | CLS Loss: 0.04277307540178299\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 2.464539051055908 | KNN Loss: 2.4363653659820557 | CLS Loss: 0.02817375771701336\n",
      "Epoch: 061, Loss: 2.4273, Train: 0.9932, Valid: 0.9864, Best: 0.9869\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 2.393425226211548 | KNN Loss: 2.3865559101104736 | CLS Loss: 0.006869352422654629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 2.4439456462860107 | KNN Loss: 2.421152353286743 | CLS Loss: 0.02279340662062168\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 2.438267946243286 | KNN Loss: 2.4255149364471436 | CLS Loss: 0.01275312528014183\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 2.428596019744873 | KNN Loss: 2.4045965671539307 | CLS Loss: 0.023999415338039398\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 2.4088127613067627 | KNN Loss: 2.398982048034668 | CLS Loss: 0.00983075425028801\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 2.432647228240967 | KNN Loss: 2.407931327819824 | CLS Loss: 0.024715907871723175\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 2.3738207817077637 | KNN Loss: 2.351099967956543 | CLS Loss: 0.022720834240317345\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 2.395958423614502 | KNN Loss: 2.3737189769744873 | CLS Loss: 0.022239400073885918\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 2.447103977203369 | KNN Loss: 2.4243898391723633 | CLS Loss: 0.022714029997587204\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 2.415294647216797 | KNN Loss: 2.397538661956787 | CLS Loss: 0.01775599643588066\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 2.4650933742523193 | KNN Loss: 2.424795627593994 | CLS Loss: 0.04029763117432594\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 2.4097769260406494 | KNN Loss: 2.3775808811187744 | CLS Loss: 0.03219592943787575\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 2.4562532901763916 | KNN Loss: 2.4332692623138428 | CLS Loss: 0.022983988747000694\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 2.388259172439575 | KNN Loss: 2.368823766708374 | CLS Loss: 0.01943548582494259\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 2.4161646366119385 | KNN Loss: 2.3934571743011475 | CLS Loss: 0.02270757593214512\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 2.423182487487793 | KNN Loss: 2.4066803455352783 | CLS Loss: 0.01650221087038517\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 2.4520864486694336 | KNN Loss: 2.438725233078003 | CLS Loss: 0.013361111283302307\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 2.452193021774292 | KNN Loss: 2.4364876747131348 | CLS Loss: 0.015705274417996407\n",
      "Epoch: 062, Loss: 2.4265, Train: 0.9940, Valid: 0.9856, Best: 0.9869\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 2.4158902168273926 | KNN Loss: 2.4137203693389893 | CLS Loss: 0.0021698412019759417\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 2.398937463760376 | KNN Loss: 2.3866207599639893 | CLS Loss: 0.01231682114303112\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 2.4112744331359863 | KNN Loss: 2.3881070613861084 | CLS Loss: 0.023167401552200317\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 2.4336769580841064 | KNN Loss: 2.3987932205200195 | CLS Loss: 0.0348837748169899\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 2.4556798934936523 | KNN Loss: 2.427253246307373 | CLS Loss: 0.02842656336724758\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 2.4139997959136963 | KNN Loss: 2.3751442432403564 | CLS Loss: 0.03885558247566223\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 2.489821195602417 | KNN Loss: 2.4657769203186035 | CLS Loss: 0.024044230580329895\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 2.458604097366333 | KNN Loss: 2.436399459838867 | CLS Loss: 0.022204535081982613\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 2.45444655418396 | KNN Loss: 2.409536600112915 | CLS Loss: 0.0449100136756897\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 2.441049098968506 | KNN Loss: 2.420513153076172 | CLS Loss: 0.020535830408334732\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 2.413919687271118 | KNN Loss: 2.3909709453582764 | CLS Loss: 0.022948820143938065\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 2.488576650619507 | KNN Loss: 2.4549806118011475 | CLS Loss: 0.03359600529074669\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 2.4565160274505615 | KNN Loss: 2.405097246170044 | CLS Loss: 0.05141880363225937\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 2.4535515308380127 | KNN Loss: 2.4280452728271484 | CLS Loss: 0.025506168603897095\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 2.433079719543457 | KNN Loss: 2.422968626022339 | CLS Loss: 0.010111061856150627\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 2.4095072746276855 | KNN Loss: 2.38808012008667 | CLS Loss: 0.021427135914564133\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 2.4544997215270996 | KNN Loss: 2.4448904991149902 | CLS Loss: 0.009609339758753777\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 2.4247820377349854 | KNN Loss: 2.4052846431732178 | CLS Loss: 0.019497329369187355\n",
      "Epoch: 063, Loss: 2.4282, Train: 0.9940, Valid: 0.9856, Best: 0.9869\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 2.4098317623138428 | KNN Loss: 2.391561985015869 | CLS Loss: 0.018269836902618408\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 2.430598497390747 | KNN Loss: 2.418605327606201 | CLS Loss: 0.01199326291680336\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 2.418856382369995 | KNN Loss: 2.3954222202301025 | CLS Loss: 0.02343415468931198\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 2.4355123043060303 | KNN Loss: 2.412945032119751 | CLS Loss: 0.022567270323634148\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 2.4479384422302246 | KNN Loss: 2.413694143295288 | CLS Loss: 0.034244339913129807\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 2.4429588317871094 | KNN Loss: 2.42195725440979 | CLS Loss: 0.021001547574996948\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 2.414109706878662 | KNN Loss: 2.392890453338623 | CLS Loss: 0.02121920697391033\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 2.4379265308380127 | KNN Loss: 2.4121694564819336 | CLS Loss: 0.02575715258717537\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 2.4483962059020996 | KNN Loss: 2.431778907775879 | CLS Loss: 0.01661732979118824\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 2.441971778869629 | KNN Loss: 2.428173780441284 | CLS Loss: 0.013798050582408905\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 2.409975290298462 | KNN Loss: 2.4051737785339355 | CLS Loss: 0.00480155274271965\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 2.440967082977295 | KNN Loss: 2.408540725708008 | CLS Loss: 0.03242628276348114\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 2.459899425506592 | KNN Loss: 2.43340802192688 | CLS Loss: 0.026491491124033928\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 2.4075584411621094 | KNN Loss: 2.381450891494751 | CLS Loss: 0.02610747329890728\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 2.4257404804229736 | KNN Loss: 2.4120941162109375 | CLS Loss: 0.013646280393004417\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 2.4366700649261475 | KNN Loss: 2.4201273918151855 | CLS Loss: 0.016542749479413033\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 2.4225332736968994 | KNN Loss: 2.389340877532959 | CLS Loss: 0.03319244086742401\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 2.4424662590026855 | KNN Loss: 2.416686534881592 | CLS Loss: 0.0257797222584486\n",
      "Epoch: 064, Loss: 2.4343, Train: 0.9938, Valid: 0.9863, Best: 0.9869\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 2.41866135597229 | KNN Loss: 2.4043705463409424 | CLS Loss: 0.014290840364992619\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 2.448030471801758 | KNN Loss: 2.440717935562134 | CLS Loss: 0.007312445901334286\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 2.422037124633789 | KNN Loss: 2.4018778800964355 | CLS Loss: 0.02015913650393486\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 2.429011106491089 | KNN Loss: 2.4049742221832275 | CLS Loss: 0.024036969989538193\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 2.429438829421997 | KNN Loss: 2.4155726432800293 | CLS Loss: 0.01386614516377449\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 2.430964469909668 | KNN Loss: 2.422090530395508 | CLS Loss: 0.008873985148966312\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 2.4463210105895996 | KNN Loss: 2.4366025924682617 | CLS Loss: 0.009718453511595726\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 2.385704517364502 | KNN Loss: 2.3771612644195557 | CLS Loss: 0.008543267846107483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 2.430645704269409 | KNN Loss: 2.417114496231079 | CLS Loss: 0.01353116799145937\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 2.441927194595337 | KNN Loss: 2.4079346656799316 | CLS Loss: 0.03399248421192169\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 2.417349100112915 | KNN Loss: 2.3898544311523438 | CLS Loss: 0.02749469131231308\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 2.4397170543670654 | KNN Loss: 2.4198453426361084 | CLS Loss: 0.019871629774570465\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 2.4230477809906006 | KNN Loss: 2.407465696334839 | CLS Loss: 0.015582086518406868\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 2.4232308864593506 | KNN Loss: 2.412252426147461 | CLS Loss: 0.010978416539728642\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 2.4082701206207275 | KNN Loss: 2.404573678970337 | CLS Loss: 0.0036965401377528906\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 2.410902738571167 | KNN Loss: 2.4016168117523193 | CLS Loss: 0.009285821579396725\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 2.4288251399993896 | KNN Loss: 2.405188798904419 | CLS Loss: 0.023636285215616226\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 2.417283296585083 | KNN Loss: 2.4022228717803955 | CLS Loss: 0.015060417354106903\n",
      "Epoch: 065, Loss: 2.4327, Train: 0.9937, Valid: 0.9852, Best: 0.9869\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 2.452240228652954 | KNN Loss: 2.4259772300720215 | CLS Loss: 0.026262905448675156\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 2.451444625854492 | KNN Loss: 2.422548770904541 | CLS Loss: 0.02889574132859707\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 2.4483304023742676 | KNN Loss: 2.426257848739624 | CLS Loss: 0.022072529420256615\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 2.3957128524780273 | KNN Loss: 2.371591329574585 | CLS Loss: 0.024121420457959175\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 2.431445360183716 | KNN Loss: 2.419970989227295 | CLS Loss: 0.011474459432065487\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 2.46667218208313 | KNN Loss: 2.4439871311187744 | CLS Loss: 0.022684961557388306\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 2.413149833679199 | KNN Loss: 2.38812255859375 | CLS Loss: 0.025027163326740265\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 2.4555630683898926 | KNN Loss: 2.4294731616973877 | CLS Loss: 0.026089830324053764\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 2.436837673187256 | KNN Loss: 2.414097547531128 | CLS Loss: 0.022740041837096214\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 2.4350650310516357 | KNN Loss: 2.418764591217041 | CLS Loss: 0.016300484538078308\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 2.4438042640686035 | KNN Loss: 2.4183685779571533 | CLS Loss: 0.025435611605644226\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 2.4088571071624756 | KNN Loss: 2.397564649581909 | CLS Loss: 0.01129238959401846\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 2.4221038818359375 | KNN Loss: 2.4015393257141113 | CLS Loss: 0.020564470440149307\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 2.3999834060668945 | KNN Loss: 2.369035005569458 | CLS Loss: 0.03094838745892048\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 2.417987823486328 | KNN Loss: 2.3989551067352295 | CLS Loss: 0.01903262734413147\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 2.4564435482025146 | KNN Loss: 2.4085633754730225 | CLS Loss: 0.04788008704781532\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 2.418879747390747 | KNN Loss: 2.3958964347839355 | CLS Loss: 0.022983426228165627\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 2.4340763092041016 | KNN Loss: 2.4101717472076416 | CLS Loss: 0.023904606699943542\n",
      "Epoch: 066, Loss: 2.4283, Train: 0.9943, Valid: 0.9862, Best: 0.9869\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 2.3944363594055176 | KNN Loss: 2.3785622119903564 | CLS Loss: 0.015874085947871208\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 2.424661159515381 | KNN Loss: 2.4029242992401123 | CLS Loss: 0.02173689566552639\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 2.4090309143066406 | KNN Loss: 2.3823606967926025 | CLS Loss: 0.026670144870877266\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 2.387361526489258 | KNN Loss: 2.380971908569336 | CLS Loss: 0.006389672867953777\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 2.4569153785705566 | KNN Loss: 2.3955323696136475 | CLS Loss: 0.06138299033045769\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 2.419771671295166 | KNN Loss: 2.3901381492614746 | CLS Loss: 0.029633453115820885\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 2.4565629959106445 | KNN Loss: 2.43818998336792 | CLS Loss: 0.01837298646569252\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 2.418050765991211 | KNN Loss: 2.392242193222046 | CLS Loss: 0.025808557868003845\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 2.5123507976531982 | KNN Loss: 2.492837905883789 | CLS Loss: 0.019512826576828957\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 2.4046692848205566 | KNN Loss: 2.374735116958618 | CLS Loss: 0.02993415668606758\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 2.4141364097595215 | KNN Loss: 2.3916797637939453 | CLS Loss: 0.022456584498286247\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 2.4366512298583984 | KNN Loss: 2.384578227996826 | CLS Loss: 0.052072882652282715\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 2.4575953483581543 | KNN Loss: 2.4403738975524902 | CLS Loss: 0.017221419140696526\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 2.4037129878997803 | KNN Loss: 2.3872642517089844 | CLS Loss: 0.016448838636279106\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 2.4344868659973145 | KNN Loss: 2.413796901702881 | CLS Loss: 0.02068985067307949\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 2.4261019229888916 | KNN Loss: 2.396162986755371 | CLS Loss: 0.02993904985487461\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 2.42100191116333 | KNN Loss: 2.4070141315460205 | CLS Loss: 0.013987665064632893\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 2.439448356628418 | KNN Loss: 2.4129345417022705 | CLS Loss: 0.02651384100317955\n",
      "Epoch: 067, Loss: 2.4292, Train: 0.9920, Valid: 0.9834, Best: 0.9869\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 2.4074482917785645 | KNN Loss: 2.3963215351104736 | CLS Loss: 0.011126654222607613\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 2.4471137523651123 | KNN Loss: 2.416553497314453 | CLS Loss: 0.03056032583117485\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 2.4202382564544678 | KNN Loss: 2.398719549179077 | CLS Loss: 0.02151860110461712\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 2.4302732944488525 | KNN Loss: 2.3964223861694336 | CLS Loss: 0.033850982785224915\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 2.4291794300079346 | KNN Loss: 2.4168615341186523 | CLS Loss: 0.012317964807152748\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 2.444631338119507 | KNN Loss: 2.4164462089538574 | CLS Loss: 0.028185242787003517\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 2.3906285762786865 | KNN Loss: 2.3608052730560303 | CLS Loss: 0.02982323430478573\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 2.3998377323150635 | KNN Loss: 2.3757293224334717 | CLS Loss: 0.024108443409204483\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 2.412355661392212 | KNN Loss: 2.4091739654541016 | CLS Loss: 0.0031817771960049868\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 2.3993642330169678 | KNN Loss: 2.377134323120117 | CLS Loss: 0.022230016067624092\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 2.4165115356445312 | KNN Loss: 2.4026851654052734 | CLS Loss: 0.013826468959450722\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 2.415264368057251 | KNN Loss: 2.3881850242614746 | CLS Loss: 0.027079280465841293\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 2.4042258262634277 | KNN Loss: 2.39306902885437 | CLS Loss: 0.011156735941767693\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 2.420889139175415 | KNN Loss: 2.4052374362945557 | CLS Loss: 0.015651654452085495\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 2.4610142707824707 | KNN Loss: 2.4350533485412598 | CLS Loss: 0.02596089243888855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 2.4427478313446045 | KNN Loss: 2.4077916145324707 | CLS Loss: 0.03495631739497185\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 2.402865409851074 | KNN Loss: 2.393317222595215 | CLS Loss: 0.009548068046569824\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 2.3980324268341064 | KNN Loss: 2.392202377319336 | CLS Loss: 0.005830093752592802\n",
      "Epoch: 068, Loss: 2.4253, Train: 0.9953, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 2.4014928340911865 | KNN Loss: 2.3811848163604736 | CLS Loss: 0.02030794508755207\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 2.463613986968994 | KNN Loss: 2.417757511138916 | CLS Loss: 0.04585643857717514\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 2.390284538269043 | KNN Loss: 2.371675968170166 | CLS Loss: 0.01860848255455494\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 2.4387784004211426 | KNN Loss: 2.417240619659424 | CLS Loss: 0.021537698805332184\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 2.4408254623413086 | KNN Loss: 2.4086616039276123 | CLS Loss: 0.03216392919421196\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 2.4548521041870117 | KNN Loss: 2.435350179672241 | CLS Loss: 0.019501904025673866\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 2.4488747119903564 | KNN Loss: 2.424125909805298 | CLS Loss: 0.02474869228899479\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 2.472917318344116 | KNN Loss: 2.453216552734375 | CLS Loss: 0.019700706005096436\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 2.4359331130981445 | KNN Loss: 2.416501998901367 | CLS Loss: 0.01943116821348667\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 2.41225266456604 | KNN Loss: 2.3688366413116455 | CLS Loss: 0.0434160977602005\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 2.4075849056243896 | KNN Loss: 2.3796327114105225 | CLS Loss: 0.027952294796705246\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 2.421076774597168 | KNN Loss: 2.3671975135803223 | CLS Loss: 0.05387915298342705\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 2.4208545684814453 | KNN Loss: 2.40058970451355 | CLS Loss: 0.02026495710015297\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 2.456991672515869 | KNN Loss: 2.42275071144104 | CLS Loss: 0.03424108028411865\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 2.4158921241760254 | KNN Loss: 2.4110896587371826 | CLS Loss: 0.004802492912858725\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 2.4268462657928467 | KNN Loss: 2.4094552993774414 | CLS Loss: 0.0173910241574049\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 2.3979732990264893 | KNN Loss: 2.3888354301452637 | CLS Loss: 0.009137754328548908\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 2.423611640930176 | KNN Loss: 2.40972638130188 | CLS Loss: 0.013885234482586384\n",
      "Epoch: 069, Loss: 2.4275, Train: 0.9937, Valid: 0.9842, Best: 0.9873\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 2.3961384296417236 | KNN Loss: 2.3755409717559814 | CLS Loss: 0.02059745416045189\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 2.4288508892059326 | KNN Loss: 2.4033706188201904 | CLS Loss: 0.025480162352323532\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 2.408402919769287 | KNN Loss: 2.3928089141845703 | CLS Loss: 0.015593894757330418\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 2.4501118659973145 | KNN Loss: 2.419527292251587 | CLS Loss: 0.03058466501533985\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 2.4220151901245117 | KNN Loss: 2.3964312076568604 | CLS Loss: 0.025583913549780846\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 2.4623496532440186 | KNN Loss: 2.426517963409424 | CLS Loss: 0.035831719636917114\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 2.430025100708008 | KNN Loss: 2.3809356689453125 | CLS Loss: 0.04908932372927666\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 2.4438600540161133 | KNN Loss: 2.4128615856170654 | CLS Loss: 0.030998514965176582\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 2.461308240890503 | KNN Loss: 2.433917999267578 | CLS Loss: 0.02739022672176361\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 2.4373161792755127 | KNN Loss: 2.421238422393799 | CLS Loss: 0.016077740117907524\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 2.4172251224517822 | KNN Loss: 2.4106740951538086 | CLS Loss: 0.006551041267812252\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 2.405616283416748 | KNN Loss: 2.3888421058654785 | CLS Loss: 0.016774237155914307\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 2.422412395477295 | KNN Loss: 2.398941993713379 | CLS Loss: 0.02347041852772236\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 2.4141504764556885 | KNN Loss: 2.3794522285461426 | CLS Loss: 0.03469835966825485\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 2.433708906173706 | KNN Loss: 2.4107227325439453 | CLS Loss: 0.022986289113759995\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 2.426725149154663 | KNN Loss: 2.38875412940979 | CLS Loss: 0.03797100856900215\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 2.3998093605041504 | KNN Loss: 2.3897454738616943 | CLS Loss: 0.010063852183520794\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 2.4884870052337646 | KNN Loss: 2.4588499069213867 | CLS Loss: 0.029637135565280914\n",
      "Epoch: 070, Loss: 2.4273, Train: 0.9949, Valid: 0.9867, Best: 0.9873\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 2.4676973819732666 | KNN Loss: 2.4226791858673096 | CLS Loss: 0.04501808434724808\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 2.464552402496338 | KNN Loss: 2.416517972946167 | CLS Loss: 0.04803438112139702\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 2.3893070220947266 | KNN Loss: 2.362532615661621 | CLS Loss: 0.026774445548653603\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 2.4564807415008545 | KNN Loss: 2.4318222999572754 | CLS Loss: 0.024658454582095146\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 2.419800281524658 | KNN Loss: 2.4063360691070557 | CLS Loss: 0.013464299961924553\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 2.418989896774292 | KNN Loss: 2.393127202987671 | CLS Loss: 0.02586279809474945\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 2.43965744972229 | KNN Loss: 2.411418914794922 | CLS Loss: 0.028238575905561447\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 2.382814407348633 | KNN Loss: 2.363865613937378 | CLS Loss: 0.018948819488286972\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 2.468670606613159 | KNN Loss: 2.434612512588501 | CLS Loss: 0.034058086574077606\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 2.4607224464416504 | KNN Loss: 2.425175905227661 | CLS Loss: 0.03554665297269821\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 2.4326305389404297 | KNN Loss: 2.4195244312286377 | CLS Loss: 0.013106092810630798\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 2.4273681640625 | KNN Loss: 2.3964498043060303 | CLS Loss: 0.03091825358569622\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 2.4239115715026855 | KNN Loss: 2.4030356407165527 | CLS Loss: 0.02087591215968132\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 2.430455207824707 | KNN Loss: 2.3972108364105225 | CLS Loss: 0.03324446082115173\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 2.414522409439087 | KNN Loss: 2.4063050746917725 | CLS Loss: 0.008217344991862774\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 2.3998048305511475 | KNN Loss: 2.395240068435669 | CLS Loss: 0.00456473371013999\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 2.4335384368896484 | KNN Loss: 2.4131336212158203 | CLS Loss: 0.020404761657118797\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 2.4047043323516846 | KNN Loss: 2.382025957107544 | CLS Loss: 0.022678282111883163\n",
      "Epoch: 071, Loss: 2.4251, Train: 0.9951, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 2.4045250415802 | KNN Loss: 2.3883657455444336 | CLS Loss: 0.016159318387508392\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 2.439939498901367 | KNN Loss: 2.4184372425079346 | CLS Loss: 0.021502288058400154\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 2.397109031677246 | KNN Loss: 2.381578207015991 | CLS Loss: 0.015530924312770367\n",
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 2.3773767948150635 | KNN Loss: 2.3634557723999023 | CLS Loss: 0.013920923694968224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 2.4155778884887695 | KNN Loss: 2.408078193664551 | CLS Loss: 0.007499757222831249\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 2.3933913707733154 | KNN Loss: 2.377941131591797 | CLS Loss: 0.01545034907758236\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 2.4248249530792236 | KNN Loss: 2.4084410667419434 | CLS Loss: 0.016383929178118706\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 2.451303482055664 | KNN Loss: 2.41023588180542 | CLS Loss: 0.04106765240430832\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 2.375675678253174 | KNN Loss: 2.369980573654175 | CLS Loss: 0.005694990511983633\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 2.421900510787964 | KNN Loss: 2.4148387908935547 | CLS Loss: 0.007061742711812258\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 2.409619092941284 | KNN Loss: 2.3713834285736084 | CLS Loss: 0.03823569416999817\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 2.426363468170166 | KNN Loss: 2.4202229976654053 | CLS Loss: 0.006140482146292925\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 2.4400761127471924 | KNN Loss: 2.401804208755493 | CLS Loss: 0.038271840661764145\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 2.435253858566284 | KNN Loss: 2.413273572921753 | CLS Loss: 0.021980341523885727\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 2.4212491512298584 | KNN Loss: 2.393939733505249 | CLS Loss: 0.027309475466609\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 2.475900173187256 | KNN Loss: 2.458017110824585 | CLS Loss: 0.017883148044347763\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 2.3954291343688965 | KNN Loss: 2.3673200607299805 | CLS Loss: 0.02810918539762497\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 2.4283292293548584 | KNN Loss: 2.4127588272094727 | CLS Loss: 0.01557038351893425\n",
      "Epoch: 072, Loss: 2.4301, Train: 0.9949, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 2.3949220180511475 | KNN Loss: 2.366797924041748 | CLS Loss: 0.028124162927269936\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 2.4482452869415283 | KNN Loss: 2.428483724594116 | CLS Loss: 0.01976148597896099\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 2.449475049972534 | KNN Loss: 2.4303863048553467 | CLS Loss: 0.019088827073574066\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 2.4487030506134033 | KNN Loss: 2.4230411052703857 | CLS Loss: 0.025662004947662354\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 2.4264442920684814 | KNN Loss: 2.3946373462677 | CLS Loss: 0.03180695325136185\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 2.422396183013916 | KNN Loss: 2.414567470550537 | CLS Loss: 0.007828679867088795\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 2.404362678527832 | KNN Loss: 2.3771591186523438 | CLS Loss: 0.027203628793358803\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 2.4278147220611572 | KNN Loss: 2.412914276123047 | CLS Loss: 0.01490037888288498\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 2.4058492183685303 | KNN Loss: 2.3893771171569824 | CLS Loss: 0.01647205464541912\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 2.447559356689453 | KNN Loss: 2.433629274368286 | CLS Loss: 0.01392998918890953\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 2.40937876701355 | KNN Loss: 2.3833255767822266 | CLS Loss: 0.02605319209396839\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 2.4465157985687256 | KNN Loss: 2.426961660385132 | CLS Loss: 0.01955418847501278\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 2.4510555267333984 | KNN Loss: 2.4274215698242188 | CLS Loss: 0.023633889853954315\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 2.418260097503662 | KNN Loss: 2.3917324542999268 | CLS Loss: 0.026527579873800278\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 2.3656365871429443 | KNN Loss: 2.3561556339263916 | CLS Loss: 0.009480933658778667\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 2.3891191482543945 | KNN Loss: 2.373175859451294 | CLS Loss: 0.01594335213303566\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 2.432253360748291 | KNN Loss: 2.4207699298858643 | CLS Loss: 0.01148354820907116\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 2.403618574142456 | KNN Loss: 2.3916192054748535 | CLS Loss: 0.011999450623989105\n",
      "Epoch: 073, Loss: 2.4252, Train: 0.9951, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 2.4202780723571777 | KNN Loss: 2.4078285694122314 | CLS Loss: 0.012449470348656178\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 2.4264121055603027 | KNN Loss: 2.3963546752929688 | CLS Loss: 0.030057372525334358\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 2.436553955078125 | KNN Loss: 2.41552472114563 | CLS Loss: 0.021029172465205193\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 2.4286272525787354 | KNN Loss: 2.4092493057250977 | CLS Loss: 0.01937805488705635\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 2.4167320728302 | KNN Loss: 2.3960819244384766 | CLS Loss: 0.02065003290772438\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 2.421734571456909 | KNN Loss: 2.4084911346435547 | CLS Loss: 0.013243449851870537\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 2.4001896381378174 | KNN Loss: 2.369974136352539 | CLS Loss: 0.030215471982955933\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 2.405296564102173 | KNN Loss: 2.399385929107666 | CLS Loss: 0.005910521373152733\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 2.425382137298584 | KNN Loss: 2.4169161319732666 | CLS Loss: 0.008465948514640331\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 2.4401235580444336 | KNN Loss: 2.4240517616271973 | CLS Loss: 0.016071805730462074\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 2.4280083179473877 | KNN Loss: 2.4109623432159424 | CLS Loss: 0.017046041786670685\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 2.4009554386138916 | KNN Loss: 2.3834915161132812 | CLS Loss: 0.017463963478803635\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 2.4357779026031494 | KNN Loss: 2.4200868606567383 | CLS Loss: 0.015691133216023445\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 2.4333853721618652 | KNN Loss: 2.418236255645752 | CLS Loss: 0.015149160288274288\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 2.4661033153533936 | KNN Loss: 2.4448161125183105 | CLS Loss: 0.021287251263856888\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 2.4421751499176025 | KNN Loss: 2.408766984939575 | CLS Loss: 0.03340815007686615\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 2.417900323867798 | KNN Loss: 2.4111785888671875 | CLS Loss: 0.006721727084368467\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 2.392559051513672 | KNN Loss: 2.370410442352295 | CLS Loss: 0.022148706018924713\n",
      "Epoch: 074, Loss: 2.4279, Train: 0.9953, Valid: 0.9864, Best: 0.9873\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 2.417569637298584 | KNN Loss: 2.3966047763824463 | CLS Loss: 0.02096480131149292\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 2.4102673530578613 | KNN Loss: 2.3992104530334473 | CLS Loss: 0.01105695590376854\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 2.379565477371216 | KNN Loss: 2.3746354579925537 | CLS Loss: 0.004930045455694199\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 2.401587963104248 | KNN Loss: 2.370279550552368 | CLS Loss: 0.031308479607105255\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 2.39067006111145 | KNN Loss: 2.377326488494873 | CLS Loss: 0.013343540951609612\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 2.3718576431274414 | KNN Loss: 2.3636534214019775 | CLS Loss: 0.008204233832657337\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 2.4174866676330566 | KNN Loss: 2.4081411361694336 | CLS Loss: 0.009345460683107376\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 2.440863847732544 | KNN Loss: 2.4287850856781006 | CLS Loss: 0.012078800238668919\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 2.4043750762939453 | KNN Loss: 2.39579176902771 | CLS Loss: 0.008583293296396732\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 2.4286534786224365 | KNN Loss: 2.404893398284912 | CLS Loss: 0.023759974166750908\n",
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 2.4337382316589355 | KNN Loss: 2.4217891693115234 | CLS Loss: 0.011949148960411549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 2.4178225994110107 | KNN Loss: 2.394462823867798 | CLS Loss: 0.02335987240076065\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 2.4204583168029785 | KNN Loss: 2.3959810733795166 | CLS Loss: 0.02447732537984848\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 2.386488676071167 | KNN Loss: 2.3843629360198975 | CLS Loss: 0.002125857165083289\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 2.415059804916382 | KNN Loss: 2.4065418243408203 | CLS Loss: 0.008517922833561897\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 2.4154393672943115 | KNN Loss: 2.400676727294922 | CLS Loss: 0.01476267073303461\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 2.4131627082824707 | KNN Loss: 2.4085028171539307 | CLS Loss: 0.004659784026443958\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 2.455623149871826 | KNN Loss: 2.4258384704589844 | CLS Loss: 0.02978459745645523\n",
      "Epoch: 075, Loss: 2.4250, Train: 0.9953, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 2.4072823524475098 | KNN Loss: 2.394512414932251 | CLS Loss: 0.01276993378996849\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 2.439763307571411 | KNN Loss: 2.427924871444702 | CLS Loss: 0.011838536709547043\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 2.4524898529052734 | KNN Loss: 2.426858901977539 | CLS Loss: 0.02563096396625042\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 2.428873300552368 | KNN Loss: 2.4072296619415283 | CLS Loss: 0.021643677726387978\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 2.47241473197937 | KNN Loss: 2.4508869647979736 | CLS Loss: 0.021527789533138275\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 2.4418253898620605 | KNN Loss: 2.4148857593536377 | CLS Loss: 0.02693956159055233\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 2.469837188720703 | KNN Loss: 2.4110360145568848 | CLS Loss: 0.058801282197237015\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 2.4182825088500977 | KNN Loss: 2.4030675888061523 | CLS Loss: 0.015214973129332066\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 2.449249505996704 | KNN Loss: 2.4377377033233643 | CLS Loss: 0.011511819437146187\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 2.3837428092956543 | KNN Loss: 2.3743605613708496 | CLS Loss: 0.009382248856127262\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 2.430182695388794 | KNN Loss: 2.4039814472198486 | CLS Loss: 0.026201162487268448\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 2.4184556007385254 | KNN Loss: 2.403029680252075 | CLS Loss: 0.015425926074385643\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 2.396811008453369 | KNN Loss: 2.3829240798950195 | CLS Loss: 0.013886991888284683\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 2.432180643081665 | KNN Loss: 2.397683620452881 | CLS Loss: 0.03449695557355881\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 2.412740707397461 | KNN Loss: 2.404728889465332 | CLS Loss: 0.00801187101751566\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 2.399564266204834 | KNN Loss: 2.384897470474243 | CLS Loss: 0.01466672308743\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 2.4702255725860596 | KNN Loss: 2.4582033157348633 | CLS Loss: 0.012022336013615131\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 2.442462205886841 | KNN Loss: 2.416412830352783 | CLS Loss: 0.026049304753541946\n",
      "Epoch: 076, Loss: 2.4234, Train: 0.9955, Valid: 0.9872, Best: 0.9873\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 2.418708324432373 | KNN Loss: 2.405174732208252 | CLS Loss: 0.013533594086766243\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 2.4231183528900146 | KNN Loss: 2.409184217453003 | CLS Loss: 0.01393404696136713\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 2.4483578205108643 | KNN Loss: 2.428110361099243 | CLS Loss: 0.020247383043169975\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 2.40545392036438 | KNN Loss: 2.383514404296875 | CLS Loss: 0.0219394750893116\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 2.426823854446411 | KNN Loss: 2.4072914123535156 | CLS Loss: 0.019532334059476852\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 2.4388022422790527 | KNN Loss: 2.426283597946167 | CLS Loss: 0.012518666684627533\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 2.443150043487549 | KNN Loss: 2.424403667449951 | CLS Loss: 0.01874644309282303\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 2.4195401668548584 | KNN Loss: 2.4049322605133057 | CLS Loss: 0.014607912860810757\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 2.44150447845459 | KNN Loss: 2.42643141746521 | CLS Loss: 0.01507309265434742\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 2.423421621322632 | KNN Loss: 2.395925283432007 | CLS Loss: 0.027496328577399254\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 2.4129958152770996 | KNN Loss: 2.392333984375 | CLS Loss: 0.020661942660808563\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 2.4457290172576904 | KNN Loss: 2.4267094135284424 | CLS Loss: 0.019019542261958122\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 2.41469669342041 | KNN Loss: 2.4041080474853516 | CLS Loss: 0.010588547214865685\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 2.4219138622283936 | KNN Loss: 2.3893914222717285 | CLS Loss: 0.03252239152789116\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 2.442844867706299 | KNN Loss: 2.4109914302825928 | CLS Loss: 0.03185348957777023\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 2.4441490173339844 | KNN Loss: 2.433830976486206 | CLS Loss: 0.010318147018551826\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 2.4260478019714355 | KNN Loss: 2.421003580093384 | CLS Loss: 0.005044171586632729\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 2.436817169189453 | KNN Loss: 2.431107759475708 | CLS Loss: 0.005709338933229446\n",
      "Epoch: 077, Loss: 2.4239, Train: 0.9944, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 2.430471181869507 | KNN Loss: 2.3922808170318604 | CLS Loss: 0.0381903275847435\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 2.412550687789917 | KNN Loss: 2.3993802070617676 | CLS Loss: 0.013170557096600533\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 2.412097692489624 | KNN Loss: 2.3598711490631104 | CLS Loss: 0.0522264689207077\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 2.414844036102295 | KNN Loss: 2.3889734745025635 | CLS Loss: 0.02587060257792473\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 2.433328628540039 | KNN Loss: 2.4077439308166504 | CLS Loss: 0.025584809482097626\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 2.4177348613739014 | KNN Loss: 2.4133927822113037 | CLS Loss: 0.0043420628644526005\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 2.3816254138946533 | KNN Loss: 2.363985300064087 | CLS Loss: 0.017640067264437675\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 2.4686756134033203 | KNN Loss: 2.4364423751831055 | CLS Loss: 0.032233353704214096\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 2.440450668334961 | KNN Loss: 2.4042675495147705 | CLS Loss: 0.036183226853609085\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 2.4805493354797363 | KNN Loss: 2.423710346221924 | CLS Loss: 0.05683889240026474\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 2.4286270141601562 | KNN Loss: 2.4236183166503906 | CLS Loss: 0.0050086709670722485\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 2.419119119644165 | KNN Loss: 2.4130661487579346 | CLS Loss: 0.006053036544471979\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 2.421221971511841 | KNN Loss: 2.4041762351989746 | CLS Loss: 0.0170456413179636\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 2.4411051273345947 | KNN Loss: 2.4291770458221436 | CLS Loss: 0.011928047053515911\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 2.4305977821350098 | KNN Loss: 2.4157803058624268 | CLS Loss: 0.014817552641034126\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 2.450984477996826 | KNN Loss: 2.432229518890381 | CLS Loss: 0.018754927441477776\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 2.410893440246582 | KNN Loss: 2.3978030681610107 | CLS Loss: 0.013090427964925766\n",
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 2.4093146324157715 | KNN Loss: 2.406752586364746 | CLS Loss: 0.0025620681699365377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 078, Loss: 2.4270, Train: 0.9955, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 2.376992702484131 | KNN Loss: 2.352743625640869 | CLS Loss: 0.024249140173196793\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 2.3856430053710938 | KNN Loss: 2.361626386642456 | CLS Loss: 0.024016527459025383\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 2.421844244003296 | KNN Loss: 2.3990275859832764 | CLS Loss: 0.022816767916083336\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 2.443485736846924 | KNN Loss: 2.3931186199188232 | CLS Loss: 0.050367195159196854\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 2.4322733879089355 | KNN Loss: 2.420227527618408 | CLS Loss: 0.01204590406268835\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 2.4135196208953857 | KNN Loss: 2.390939235687256 | CLS Loss: 0.0225803442299366\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 2.396223306655884 | KNN Loss: 2.3897836208343506 | CLS Loss: 0.006439626216888428\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 2.400832176208496 | KNN Loss: 2.38090443611145 | CLS Loss: 0.01992766186594963\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 2.4093377590179443 | KNN Loss: 2.395986795425415 | CLS Loss: 0.013350887224078178\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 2.410306930541992 | KNN Loss: 2.3943161964416504 | CLS Loss: 0.015990687534213066\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 2.4278926849365234 | KNN Loss: 2.4158079624176025 | CLS Loss: 0.01208469271659851\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 2.40624737739563 | KNN Loss: 2.3783085346221924 | CLS Loss: 0.02793891355395317\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 2.449476718902588 | KNN Loss: 2.4301233291625977 | CLS Loss: 0.019353389739990234\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 2.420841693878174 | KNN Loss: 2.4007701873779297 | CLS Loss: 0.020071405917406082\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 2.4185941219329834 | KNN Loss: 2.4080700874328613 | CLS Loss: 0.010524035431444645\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 2.426771402359009 | KNN Loss: 2.4105618000030518 | CLS Loss: 0.016209717839956284\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 2.409048080444336 | KNN Loss: 2.3963606357574463 | CLS Loss: 0.012687521986663342\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 2.4386637210845947 | KNN Loss: 2.42396879196167 | CLS Loss: 0.01469497848302126\n",
      "Epoch: 079, Loss: 2.4208, Train: 0.9950, Valid: 0.9867, Best: 0.9873\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 2.415928840637207 | KNN Loss: 2.3933613300323486 | CLS Loss: 0.022567538544535637\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 2.429598569869995 | KNN Loss: 2.4121034145355225 | CLS Loss: 0.017495065927505493\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 2.4042110443115234 | KNN Loss: 2.38224458694458 | CLS Loss: 0.021966442465782166\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 2.4405782222747803 | KNN Loss: 2.4109928607940674 | CLS Loss: 0.029585419222712517\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 2.480800151824951 | KNN Loss: 2.459716558456421 | CLS Loss: 0.02108367346227169\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 2.416456460952759 | KNN Loss: 2.39503812789917 | CLS Loss: 0.02141832746565342\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 2.415907621383667 | KNN Loss: 2.4011988639831543 | CLS Loss: 0.014708847738802433\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 2.452570676803589 | KNN Loss: 2.428762197494507 | CLS Loss: 0.023808516561985016\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 2.4236416816711426 | KNN Loss: 2.398263931274414 | CLS Loss: 0.025377778336405754\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 2.4357573986053467 | KNN Loss: 2.4161367416381836 | CLS Loss: 0.019620642066001892\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 2.4250502586364746 | KNN Loss: 2.413200855255127 | CLS Loss: 0.011849324218928814\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 2.484069347381592 | KNN Loss: 2.4543776512145996 | CLS Loss: 0.029691677540540695\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 2.412234306335449 | KNN Loss: 2.386942148208618 | CLS Loss: 0.025292130187153816\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 2.4038634300231934 | KNN Loss: 2.395439863204956 | CLS Loss: 0.008423502556979656\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 2.412444829940796 | KNN Loss: 2.3973493576049805 | CLS Loss: 0.015095468610525131\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 2.4646353721618652 | KNN Loss: 2.449800491333008 | CLS Loss: 0.014834897592663765\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 2.4363393783569336 | KNN Loss: 2.4128851890563965 | CLS Loss: 0.023454133421182632\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 2.432239294052124 | KNN Loss: 2.4199469089508057 | CLS Loss: 0.012292366474866867\n",
      "Epoch: 080, Loss: 2.4258, Train: 0.9949, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 2.430865526199341 | KNN Loss: 2.4227821826934814 | CLS Loss: 0.008083377033472061\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 2.4076523780822754 | KNN Loss: 2.404299259185791 | CLS Loss: 0.003353229258209467\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 2.4203133583068848 | KNN Loss: 2.412977933883667 | CLS Loss: 0.007335428148508072\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 2.423571825027466 | KNN Loss: 2.4146437644958496 | CLS Loss: 0.008928166702389717\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 2.411773204803467 | KNN Loss: 2.4038467407226562 | CLS Loss: 0.00792649295181036\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 2.384885787963867 | KNN Loss: 2.3736791610717773 | CLS Loss: 0.011206638999283314\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 2.4448254108428955 | KNN Loss: 2.4224066734313965 | CLS Loss: 0.022418655455112457\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 2.4090542793273926 | KNN Loss: 2.397799253463745 | CLS Loss: 0.01125503983348608\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 2.431673526763916 | KNN Loss: 2.4167563915252686 | CLS Loss: 0.01491721160709858\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 2.426166296005249 | KNN Loss: 2.4096968173980713 | CLS Loss: 0.016469424590468407\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 2.4410765171051025 | KNN Loss: 2.423227548599243 | CLS Loss: 0.01784907653927803\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 2.3661556243896484 | KNN Loss: 2.356363534927368 | CLS Loss: 0.00979198794811964\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 2.4261481761932373 | KNN Loss: 2.4073989391326904 | CLS Loss: 0.01874917931854725\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 2.4612350463867188 | KNN Loss: 2.4344921112060547 | CLS Loss: 0.026743048802018166\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 2.4169774055480957 | KNN Loss: 2.395289421081543 | CLS Loss: 0.021687980741262436\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 2.4081146717071533 | KNN Loss: 2.393400192260742 | CLS Loss: 0.014714397490024567\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 2.412135362625122 | KNN Loss: 2.39719295501709 | CLS Loss: 0.0149422911927104\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 2.451174736022949 | KNN Loss: 2.43573260307312 | CLS Loss: 0.01544201746582985\n",
      "Epoch: 081, Loss: 2.4244, Train: 0.9952, Valid: 0.9870, Best: 0.9873\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 2.3662514686584473 | KNN Loss: 2.3513636589050293 | CLS Loss: 0.014887775294482708\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 2.4072422981262207 | KNN Loss: 2.3942527770996094 | CLS Loss: 0.012989617884159088\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 2.441413402557373 | KNN Loss: 2.420506000518799 | CLS Loss: 0.020907485857605934\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 2.453227996826172 | KNN Loss: 2.445359945297241 | CLS Loss: 0.007868102751672268\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 2.398721694946289 | KNN Loss: 2.3901617527008057 | CLS Loss: 0.008559909649193287\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 2.420067071914673 | KNN Loss: 2.4025232791900635 | CLS Loss: 0.01754383184015751\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 2.4096200466156006 | KNN Loss: 2.393174171447754 | CLS Loss: 0.016445832327008247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 2.405061721801758 | KNN Loss: 2.384415864944458 | CLS Loss: 0.0206457506865263\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 2.4314162731170654 | KNN Loss: 2.4019508361816406 | CLS Loss: 0.02946542389690876\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 2.4418952465057373 | KNN Loss: 2.423374652862549 | CLS Loss: 0.018520548939704895\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 2.415668249130249 | KNN Loss: 2.4099442958831787 | CLS Loss: 0.005723912268877029\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 2.4273722171783447 | KNN Loss: 2.3950557708740234 | CLS Loss: 0.032316550612449646\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 2.417983055114746 | KNN Loss: 2.3913090229034424 | CLS Loss: 0.026673946529626846\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 2.4300155639648438 | KNN Loss: 2.410757064819336 | CLS Loss: 0.019258510321378708\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 2.4115939140319824 | KNN Loss: 2.4025750160217285 | CLS Loss: 0.009018919430673122\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 2.459030866622925 | KNN Loss: 2.432013750076294 | CLS Loss: 0.02701709046959877\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 2.446457862854004 | KNN Loss: 2.4283220767974854 | CLS Loss: 0.01813572645187378\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 2.421764612197876 | KNN Loss: 2.387761116027832 | CLS Loss: 0.03400339186191559\n",
      "Epoch: 082, Loss: 2.4214, Train: 0.9956, Valid: 0.9870, Best: 0.9873\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 2.3938865661621094 | KNN Loss: 2.385190963745117 | CLS Loss: 0.008695585653185844\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 2.3934192657470703 | KNN Loss: 2.3838307857513428 | CLS Loss: 0.009588595479726791\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 2.445218324661255 | KNN Loss: 2.425896167755127 | CLS Loss: 0.019322218373417854\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 2.401341676712036 | KNN Loss: 2.3761556148529053 | CLS Loss: 0.025186069309711456\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 2.4533729553222656 | KNN Loss: 2.437877655029297 | CLS Loss: 0.01549521554261446\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 2.429090738296509 | KNN Loss: 2.380629777908325 | CLS Loss: 0.04846096783876419\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 2.3691816329956055 | KNN Loss: 2.355142593383789 | CLS Loss: 0.014039029367268085\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 2.410714864730835 | KNN Loss: 2.396873712539673 | CLS Loss: 0.013841038569808006\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 2.4426491260528564 | KNN Loss: 2.415067672729492 | CLS Loss: 0.027581505477428436\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 2.393611431121826 | KNN Loss: 2.386094093322754 | CLS Loss: 0.007517441641539335\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 2.3731582164764404 | KNN Loss: 2.368380546569824 | CLS Loss: 0.004777730442583561\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 2.4016690254211426 | KNN Loss: 2.3874354362487793 | CLS Loss: 0.014233612455427647\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 2.4519059658050537 | KNN Loss: 2.4163217544555664 | CLS Loss: 0.035584114491939545\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 2.4485435485839844 | KNN Loss: 2.416660785675049 | CLS Loss: 0.031882770359516144\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 2.4246346950531006 | KNN Loss: 2.4141805171966553 | CLS Loss: 0.010454194620251656\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 2.424675226211548 | KNN Loss: 2.4004623889923096 | CLS Loss: 0.024212907999753952\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 2.417609691619873 | KNN Loss: 2.414637804031372 | CLS Loss: 0.002971811918541789\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 2.42193341255188 | KNN Loss: 2.4095773696899414 | CLS Loss: 0.01235598511993885\n",
      "Epoch: 083, Loss: 2.4185, Train: 0.9944, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 2.4599766731262207 | KNN Loss: 2.418765068054199 | CLS Loss: 0.041211653500795364\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 2.4423913955688477 | KNN Loss: 2.4220852851867676 | CLS Loss: 0.02030603401362896\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 2.4226629734039307 | KNN Loss: 2.40059757232666 | CLS Loss: 0.02206544019281864\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 2.3999218940734863 | KNN Loss: 2.3876535892486572 | CLS Loss: 0.01226836908608675\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 2.3938205242156982 | KNN Loss: 2.3850064277648926 | CLS Loss: 0.00881411787122488\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 2.433817148208618 | KNN Loss: 2.421962022781372 | CLS Loss: 0.011855239979922771\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 2.3856940269470215 | KNN Loss: 2.381763219833374 | CLS Loss: 0.00393076753243804\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 2.4521522521972656 | KNN Loss: 2.4268951416015625 | CLS Loss: 0.02525709569454193\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 2.4603803157806396 | KNN Loss: 2.434983015060425 | CLS Loss: 0.025397364050149918\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 2.437136650085449 | KNN Loss: 2.4144890308380127 | CLS Loss: 0.0226475540548563\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 2.442335844039917 | KNN Loss: 2.4196584224700928 | CLS Loss: 0.022677533328533173\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 2.403491735458374 | KNN Loss: 2.391753911972046 | CLS Loss: 0.011737857945263386\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 2.4398081302642822 | KNN Loss: 2.4102063179016113 | CLS Loss: 0.02960171177983284\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 2.410703659057617 | KNN Loss: 2.408275842666626 | CLS Loss: 0.0024278974160552025\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 2.4230473041534424 | KNN Loss: 2.40995454788208 | CLS Loss: 0.013092713430523872\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 2.451479196548462 | KNN Loss: 2.4024224281311035 | CLS Loss: 0.049056731164455414\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 2.4144351482391357 | KNN Loss: 2.4061975479125977 | CLS Loss: 0.008237696252763271\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 2.4421591758728027 | KNN Loss: 2.4214866161346436 | CLS Loss: 0.020672552287578583\n",
      "Epoch: 084, Loss: 2.4241, Train: 0.9948, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 2.4527735710144043 | KNN Loss: 2.438441038131714 | CLS Loss: 0.014332422986626625\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 2.432452440261841 | KNN Loss: 2.40920352935791 | CLS Loss: 0.023249004036188126\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 2.407989025115967 | KNN Loss: 2.3965649604797363 | CLS Loss: 0.011423961259424686\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 2.3943064212799072 | KNN Loss: 2.383287191390991 | CLS Loss: 0.011019125580787659\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 2.4545769691467285 | KNN Loss: 2.4286398887634277 | CLS Loss: 0.025937017053365707\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 2.3796794414520264 | KNN Loss: 2.356736421585083 | CLS Loss: 0.022942980751395226\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 2.3979744911193848 | KNN Loss: 2.3964591026306152 | CLS Loss: 0.0015153057174757123\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 2.4335081577301025 | KNN Loss: 2.413112163543701 | CLS Loss: 0.020395908504724503\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 2.4350991249084473 | KNN Loss: 2.4285669326782227 | CLS Loss: 0.006532095838338137\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 2.4172427654266357 | KNN Loss: 2.4094667434692383 | CLS Loss: 0.007775948848575354\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 2.3833911418914795 | KNN Loss: 2.3636624813079834 | CLS Loss: 0.019728662446141243\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 2.4348385334014893 | KNN Loss: 2.4290523529052734 | CLS Loss: 0.005786180961877108\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 2.435940742492676 | KNN Loss: 2.415299892425537 | CLS Loss: 0.02064092643558979\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 2.4266180992126465 | KNN Loss: 2.414553165435791 | CLS Loss: 0.0120649179443717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 2.3920018672943115 | KNN Loss: 2.3878166675567627 | CLS Loss: 0.004185243975371122\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 2.433656692504883 | KNN Loss: 2.4298200607299805 | CLS Loss: 0.003836589166894555\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 2.4512534141540527 | KNN Loss: 2.437114715576172 | CLS Loss: 0.014138591475784779\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 2.4326424598693848 | KNN Loss: 2.4072489738464355 | CLS Loss: 0.025393567979335785\n",
      "Epoch: 085, Loss: 2.4234, Train: 0.9950, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 2.4308853149414062 | KNN Loss: 2.4150936603546143 | CLS Loss: 0.01579161360859871\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 2.4373247623443604 | KNN Loss: 2.4138340950012207 | CLS Loss: 0.02349069155752659\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 2.457421064376831 | KNN Loss: 2.4461724758148193 | CLS Loss: 0.011248493567109108\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 2.3843016624450684 | KNN Loss: 2.3815832138061523 | CLS Loss: 0.002718462608754635\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 2.394704580307007 | KNN Loss: 2.383044481277466 | CLS Loss: 0.01165998075157404\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 2.4135022163391113 | KNN Loss: 2.391964912414551 | CLS Loss: 0.021537289023399353\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 2.4347307682037354 | KNN Loss: 2.404245138168335 | CLS Loss: 0.030485713854432106\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 2.481405258178711 | KNN Loss: 2.4605958461761475 | CLS Loss: 0.020809374749660492\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 2.4189376831054688 | KNN Loss: 2.3914144039154053 | CLS Loss: 0.027523279190063477\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 2.4419562816619873 | KNN Loss: 2.4208285808563232 | CLS Loss: 0.02112763188779354\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 2.433795928955078 | KNN Loss: 2.421337366104126 | CLS Loss: 0.012458553537726402\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 2.45858097076416 | KNN Loss: 2.438922166824341 | CLS Loss: 0.019658856093883514\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 2.3848578929901123 | KNN Loss: 2.3762052059173584 | CLS Loss: 0.008652648888528347\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 2.3971567153930664 | KNN Loss: 2.3897111415863037 | CLS Loss: 0.007445684168487787\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 2.4075253009796143 | KNN Loss: 2.378844976425171 | CLS Loss: 0.028680212795734406\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 2.42293119430542 | KNN Loss: 2.4118096828460693 | CLS Loss: 0.011121448129415512\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 2.4309885501861572 | KNN Loss: 2.4204061031341553 | CLS Loss: 0.010582519695162773\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 2.438567876815796 | KNN Loss: 2.429823398590088 | CLS Loss: 0.008744588121771812\n",
      "Epoch: 086, Loss: 2.4227, Train: 0.9951, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 2.432666301727295 | KNN Loss: 2.409430503845215 | CLS Loss: 0.023235881701111794\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 2.4432127475738525 | KNN Loss: 2.426135540008545 | CLS Loss: 0.01707710139453411\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 2.4115781784057617 | KNN Loss: 2.4017651081085205 | CLS Loss: 0.009813051670789719\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 2.411957025527954 | KNN Loss: 2.402056932449341 | CLS Loss: 0.009900023229420185\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 2.4191958904266357 | KNN Loss: 2.4159789085388184 | CLS Loss: 0.003216973040252924\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 2.4014649391174316 | KNN Loss: 2.3901548385620117 | CLS Loss: 0.011310086585581303\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 2.4069671630859375 | KNN Loss: 2.378925085067749 | CLS Loss: 0.02804206870496273\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 2.4175992012023926 | KNN Loss: 2.4036619663238525 | CLS Loss: 0.013937249779701233\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 2.400186061859131 | KNN Loss: 2.38358736038208 | CLS Loss: 0.016598692163825035\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 2.3943777084350586 | KNN Loss: 2.392045259475708 | CLS Loss: 0.0023325285874307156\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 2.407289505004883 | KNN Loss: 2.394451379776001 | CLS Loss: 0.01283807773143053\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 2.431645154953003 | KNN Loss: 2.408726930618286 | CLS Loss: 0.02291823923587799\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 2.4155523777008057 | KNN Loss: 2.3994264602661133 | CLS Loss: 0.016125960275530815\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 2.4437596797943115 | KNN Loss: 2.4252374172210693 | CLS Loss: 0.01852220483124256\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 2.4406726360321045 | KNN Loss: 2.4206550121307373 | CLS Loss: 0.02001764625310898\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 2.423605442047119 | KNN Loss: 2.392718553543091 | CLS Loss: 0.030886858701705933\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 2.42508602142334 | KNN Loss: 2.41831111907959 | CLS Loss: 0.0067749228328466415\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 2.4620518684387207 | KNN Loss: 2.4505205154418945 | CLS Loss: 0.011531372554600239\n",
      "Epoch: 087, Loss: 2.4202, Train: 0.9946, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 2.4119017124176025 | KNN Loss: 2.4041614532470703 | CLS Loss: 0.007740306667983532\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 2.4109177589416504 | KNN Loss: 2.4002997875213623 | CLS Loss: 0.01061802264302969\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 2.380042791366577 | KNN Loss: 2.362978219985962 | CLS Loss: 0.017064616084098816\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 2.4433157444000244 | KNN Loss: 2.438429355621338 | CLS Loss: 0.004886329174041748\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 2.3970749378204346 | KNN Loss: 2.383014440536499 | CLS Loss: 0.014060487039387226\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 2.480454206466675 | KNN Loss: 2.470386505126953 | CLS Loss: 0.010067694820463657\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 2.4161550998687744 | KNN Loss: 2.401444673538208 | CLS Loss: 0.014710509218275547\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 2.4221370220184326 | KNN Loss: 2.397712230682373 | CLS Loss: 0.024424845352768898\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 2.406956195831299 | KNN Loss: 2.3733606338500977 | CLS Loss: 0.03359547257423401\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 2.4126217365264893 | KNN Loss: 2.40014910697937 | CLS Loss: 0.012472725473344326\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 2.4039509296417236 | KNN Loss: 2.389918088912964 | CLS Loss: 0.014032934792339802\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 2.447948694229126 | KNN Loss: 2.4267632961273193 | CLS Loss: 0.021185487508773804\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 2.435781240463257 | KNN Loss: 2.4298136234283447 | CLS Loss: 0.005967599339783192\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 2.384518623352051 | KNN Loss: 2.376300096511841 | CLS Loss: 0.008218580856919289\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 2.432450294494629 | KNN Loss: 2.405194044113159 | CLS Loss: 0.027256304398179054\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 2.4521501064300537 | KNN Loss: 2.4246768951416016 | CLS Loss: 0.02747330814599991\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 2.4250810146331787 | KNN Loss: 2.4067649841308594 | CLS Loss: 0.018316010013222694\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 2.4115052223205566 | KNN Loss: 2.3876781463623047 | CLS Loss: 0.02382713370025158\n",
      "Epoch: 088, Loss: 2.4187, Train: 0.9958, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 2.427924394607544 | KNN Loss: 2.421884298324585 | CLS Loss: 0.006040127482265234\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 2.4199578762054443 | KNN Loss: 2.3987038135528564 | CLS Loss: 0.02125397138297558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 2.3883755207061768 | KNN Loss: 2.3773701190948486 | CLS Loss: 0.011005382053554058\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 2.4080421924591064 | KNN Loss: 2.4008255004882812 | CLS Loss: 0.007216796278953552\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 2.4349918365478516 | KNN Loss: 2.402470111846924 | CLS Loss: 0.032521724700927734\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 2.408445358276367 | KNN Loss: 2.3998830318450928 | CLS Loss: 0.008562210947275162\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 2.40065598487854 | KNN Loss: 2.3872783184051514 | CLS Loss: 0.01337760966271162\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 2.4268054962158203 | KNN Loss: 2.3912508487701416 | CLS Loss: 0.03555469959974289\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 2.433711528778076 | KNN Loss: 2.422884702682495 | CLS Loss: 0.010826931335031986\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 2.421034097671509 | KNN Loss: 2.4086170196533203 | CLS Loss: 0.012417135760188103\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 2.4061899185180664 | KNN Loss: 2.3534717559814453 | CLS Loss: 0.052718132734298706\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 2.424212694168091 | KNN Loss: 2.4055840969085693 | CLS Loss: 0.018628550693392754\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 2.370447874069214 | KNN Loss: 2.3689475059509277 | CLS Loss: 0.0015004239976406097\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 2.422185182571411 | KNN Loss: 2.4016318321228027 | CLS Loss: 0.0205533504486084\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 2.384866952896118 | KNN Loss: 2.3806536197662354 | CLS Loss: 0.004213258158415556\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 2.458590507507324 | KNN Loss: 2.421184539794922 | CLS Loss: 0.037406075745821\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 2.418717861175537 | KNN Loss: 2.3974852561950684 | CLS Loss: 0.02123258076608181\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 2.404076337814331 | KNN Loss: 2.3995728492736816 | CLS Loss: 0.004503550939261913\n",
      "Epoch: 089, Loss: 2.4185, Train: 0.9953, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 2.4021594524383545 | KNN Loss: 2.3892905712127686 | CLS Loss: 0.012868979014456272\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 2.4306704998016357 | KNN Loss: 2.4112155437469482 | CLS Loss: 0.019455043599009514\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 2.409790277481079 | KNN Loss: 2.401235818862915 | CLS Loss: 0.008554366417229176\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 2.4421873092651367 | KNN Loss: 2.4245858192443848 | CLS Loss: 0.01760140247642994\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 2.4406228065490723 | KNN Loss: 2.411316156387329 | CLS Loss: 0.029306603595614433\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 2.3886451721191406 | KNN Loss: 2.3831822872161865 | CLS Loss: 0.005462945904582739\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 2.378418207168579 | KNN Loss: 2.3651397228240967 | CLS Loss: 0.013278599828481674\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 2.385960340499878 | KNN Loss: 2.3726727962493896 | CLS Loss: 0.013287434354424477\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 2.4023451805114746 | KNN Loss: 2.387957811355591 | CLS Loss: 0.014387400820851326\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 2.426152467727661 | KNN Loss: 2.4134414196014404 | CLS Loss: 0.01271095685660839\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 2.420747995376587 | KNN Loss: 2.4039998054504395 | CLS Loss: 0.01674809679389\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 2.4341115951538086 | KNN Loss: 2.424755811691284 | CLS Loss: 0.009355676360428333\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 2.459162473678589 | KNN Loss: 2.4329264163970947 | CLS Loss: 0.026235997676849365\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 2.396179676055908 | KNN Loss: 2.379336357116699 | CLS Loss: 0.01684333011507988\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 2.4636669158935547 | KNN Loss: 2.453017234802246 | CLS Loss: 0.010649745352566242\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 2.3787484169006348 | KNN Loss: 2.36590838432312 | CLS Loss: 0.01284004282206297\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 2.44474196434021 | KNN Loss: 2.403424024581909 | CLS Loss: 0.0413178987801075\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 2.4239726066589355 | KNN Loss: 2.4077978134155273 | CLS Loss: 0.01617486961185932\n",
      "Epoch: 090, Loss: 2.4238, Train: 0.9960, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 2.433135747909546 | KNN Loss: 2.4145631790161133 | CLS Loss: 0.01857248693704605\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 2.4080114364624023 | KNN Loss: 2.4062137603759766 | CLS Loss: 0.0017977437237277627\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 2.4491026401519775 | KNN Loss: 2.423211097717285 | CLS Loss: 0.025891434401273727\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 2.4340367317199707 | KNN Loss: 2.4144444465637207 | CLS Loss: 0.019592389464378357\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 2.4040660858154297 | KNN Loss: 2.377507448196411 | CLS Loss: 0.02655872330069542\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 2.41632080078125 | KNN Loss: 2.388981819152832 | CLS Loss: 0.027338936924934387\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 2.4422719478607178 | KNN Loss: 2.4360721111297607 | CLS Loss: 0.00619992520660162\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 2.3878657817840576 | KNN Loss: 2.380465030670166 | CLS Loss: 0.007400813978165388\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 2.415942430496216 | KNN Loss: 2.404189348220825 | CLS Loss: 0.011753108352422714\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 2.356940269470215 | KNN Loss: 2.354358196258545 | CLS Loss: 0.0025821630842983723\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 2.4116482734680176 | KNN Loss: 2.403831958770752 | CLS Loss: 0.007816200144588947\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 2.3981525897979736 | KNN Loss: 2.3872013092041016 | CLS Loss: 0.010951267555356026\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 2.387995719909668 | KNN Loss: 2.360729455947876 | CLS Loss: 0.027266226708889008\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 2.4299542903900146 | KNN Loss: 2.4023334980010986 | CLS Loss: 0.027620840817689896\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 2.4194953441619873 | KNN Loss: 2.381527900695801 | CLS Loss: 0.03796747699379921\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 2.402541399002075 | KNN Loss: 2.3894572257995605 | CLS Loss: 0.013084158301353455\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 2.3809070587158203 | KNN Loss: 2.369408130645752 | CLS Loss: 0.011499043554067612\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 2.4093923568725586 | KNN Loss: 2.3812179565429688 | CLS Loss: 0.028174467384815216\n",
      "Epoch: 091, Loss: 2.4199, Train: 0.9938, Valid: 0.9838, Best: 0.9873\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 2.483412742614746 | KNN Loss: 2.464505910873413 | CLS Loss: 0.0189068503677845\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 2.4007365703582764 | KNN Loss: 2.3906784057617188 | CLS Loss: 0.010058235377073288\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 2.400615692138672 | KNN Loss: 2.3867154121398926 | CLS Loss: 0.013900239951908588\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 2.396188974380493 | KNN Loss: 2.3824474811553955 | CLS Loss: 0.01374154631048441\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 2.41288423538208 | KNN Loss: 2.397946834564209 | CLS Loss: 0.014937367290258408\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 2.423555374145508 | KNN Loss: 2.411925792694092 | CLS Loss: 0.01162957027554512\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 2.4146041870117188 | KNN Loss: 2.409850835800171 | CLS Loss: 0.004753256216645241\n",
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 2.4409780502319336 | KNN Loss: 2.4360766410827637 | CLS Loss: 0.004901297856122255\n",
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 2.4475831985473633 | KNN Loss: 2.391221046447754 | CLS Loss: 0.05636210739612579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 2.4029977321624756 | KNN Loss: 2.3961119651794434 | CLS Loss: 0.006885819602757692\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 2.4191980361938477 | KNN Loss: 2.392493963241577 | CLS Loss: 0.026704076677560806\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 2.35256290435791 | KNN Loss: 2.3485300540924072 | CLS Loss: 0.004032933618873358\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 2.3934671878814697 | KNN Loss: 2.3859195709228516 | CLS Loss: 0.00754750519990921\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 2.419423818588257 | KNN Loss: 2.401606798171997 | CLS Loss: 0.017816966399550438\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 2.411888837814331 | KNN Loss: 2.383178949356079 | CLS Loss: 0.028709838166832924\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 2.4506752490997314 | KNN Loss: 2.4212212562561035 | CLS Loss: 0.02945406548678875\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 2.401254415512085 | KNN Loss: 2.39443302154541 | CLS Loss: 0.006821466144174337\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 2.4143617153167725 | KNN Loss: 2.394674301147461 | CLS Loss: 0.019687317311763763\n",
      "Epoch: 092, Loss: 2.4169, Train: 0.9955, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 2.447822093963623 | KNN Loss: 2.4286789894104004 | CLS Loss: 0.019143130630254745\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 2.4314260482788086 | KNN Loss: 2.4011619091033936 | CLS Loss: 0.030264250934123993\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 2.4395973682403564 | KNN Loss: 2.4103403091430664 | CLS Loss: 0.029256965965032578\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 2.467863082885742 | KNN Loss: 2.4374911785125732 | CLS Loss: 0.030371883884072304\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 2.3871560096740723 | KNN Loss: 2.374772548675537 | CLS Loss: 0.012383502908051014\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 2.41391658782959 | KNN Loss: 2.3866255283355713 | CLS Loss: 0.02729109115898609\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 2.4040019512176514 | KNN Loss: 2.3831443786621094 | CLS Loss: 0.020857546478509903\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 2.3719239234924316 | KNN Loss: 2.3630423545837402 | CLS Loss: 0.00888149719685316\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 2.3904738426208496 | KNN Loss: 2.3825113773345947 | CLS Loss: 0.007962369360029697\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 2.442483901977539 | KNN Loss: 2.4245593547821045 | CLS Loss: 0.017924513667821884\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 2.4134976863861084 | KNN Loss: 2.3918778896331787 | CLS Loss: 0.021619856357574463\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 2.4020016193389893 | KNN Loss: 2.386235475540161 | CLS Loss: 0.015766166150569916\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 2.4253504276275635 | KNN Loss: 2.415442705154419 | CLS Loss: 0.009907678700983524\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 2.417884588241577 | KNN Loss: 2.4032607078552246 | CLS Loss: 0.01462383009493351\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 2.4128520488739014 | KNN Loss: 2.4028499126434326 | CLS Loss: 0.010002213530242443\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 2.385796546936035 | KNN Loss: 2.3818893432617188 | CLS Loss: 0.00390720134600997\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 2.384542942047119 | KNN Loss: 2.3807671070098877 | CLS Loss: 0.0037758375983685255\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 2.403921365737915 | KNN Loss: 2.391225814819336 | CLS Loss: 0.01269551645964384\n",
      "Epoch: 093, Loss: 2.4215, Train: 0.9963, Valid: 0.9869, Best: 0.9873\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 2.416489362716675 | KNN Loss: 2.3951709270477295 | CLS Loss: 0.02131851762533188\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 2.40240478515625 | KNN Loss: 2.390856981277466 | CLS Loss: 0.01154776755720377\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 2.37929368019104 | KNN Loss: 2.373983144760132 | CLS Loss: 0.0053105601109564304\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 2.3588411808013916 | KNN Loss: 2.3567910194396973 | CLS Loss: 0.0020502381958067417\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 2.4285290241241455 | KNN Loss: 2.4195566177368164 | CLS Loss: 0.008972487412393093\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 2.380237579345703 | KNN Loss: 2.3594295978546143 | CLS Loss: 0.020807983353734016\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 2.4046614170074463 | KNN Loss: 2.383389949798584 | CLS Loss: 0.021271446719765663\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 2.445701837539673 | KNN Loss: 2.4208381175994873 | CLS Loss: 0.024863824248313904\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 2.3931829929351807 | KNN Loss: 2.3786239624023438 | CLS Loss: 0.01455906592309475\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 2.4370715618133545 | KNN Loss: 2.4160373210906982 | CLS Loss: 0.021034233272075653\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 2.429516077041626 | KNN Loss: 2.4143052101135254 | CLS Loss: 0.015210929326713085\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 2.4169836044311523 | KNN Loss: 2.4112770557403564 | CLS Loss: 0.005706493742763996\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 2.3993000984191895 | KNN Loss: 2.3953146934509277 | CLS Loss: 0.003985317423939705\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 2.426837682723999 | KNN Loss: 2.4007773399353027 | CLS Loss: 0.026060381904244423\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 2.430509328842163 | KNN Loss: 2.3888869285583496 | CLS Loss: 0.0416223481297493\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 2.4032905101776123 | KNN Loss: 2.391932487487793 | CLS Loss: 0.011357933282852173\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 2.407344341278076 | KNN Loss: 2.3905346393585205 | CLS Loss: 0.01680968888103962\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 2.394075393676758 | KNN Loss: 2.3864808082580566 | CLS Loss: 0.007594487629830837\n",
      "Epoch: 094, Loss: 2.4218, Train: 0.9963, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 2.4342730045318604 | KNN Loss: 2.41153621673584 | CLS Loss: 0.022736746817827225\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 2.395277738571167 | KNN Loss: 2.3822314739227295 | CLS Loss: 0.013046209700405598\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 2.417365312576294 | KNN Loss: 2.408066749572754 | CLS Loss: 0.009298626333475113\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 2.3987045288085938 | KNN Loss: 2.379812479019165 | CLS Loss: 0.018892087042331696\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 2.400240421295166 | KNN Loss: 2.381633758544922 | CLS Loss: 0.01860666833817959\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 2.398710250854492 | KNN Loss: 2.3940069675445557 | CLS Loss: 0.004703387152403593\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 2.4227936267852783 | KNN Loss: 2.414236307144165 | CLS Loss: 0.008557302877306938\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 2.4140498638153076 | KNN Loss: 2.3997719287872314 | CLS Loss: 0.014277851209044456\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 2.4243507385253906 | KNN Loss: 2.401663064956665 | CLS Loss: 0.02268778719007969\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 2.4302570819854736 | KNN Loss: 2.4221079349517822 | CLS Loss: 0.008149145171046257\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 2.411663055419922 | KNN Loss: 2.39632248878479 | CLS Loss: 0.015340630896389484\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 2.4220104217529297 | KNN Loss: 2.393448829650879 | CLS Loss: 0.0285615473985672\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 2.4270994663238525 | KNN Loss: 2.4009792804718018 | CLS Loss: 0.02612006850540638\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 2.417443037033081 | KNN Loss: 2.4101791381835938 | CLS Loss: 0.007263898849487305\n",
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 2.4031450748443604 | KNN Loss: 2.3750433921813965 | CLS Loss: 0.02810177393257618\n",
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 2.4315025806427 | KNN Loss: 2.4101955890655518 | CLS Loss: 0.021306974813342094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 2.4127485752105713 | KNN Loss: 2.4051308631896973 | CLS Loss: 0.007617610041052103\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 2.411968469619751 | KNN Loss: 2.4053170680999756 | CLS Loss: 0.006651314906775951\n",
      "Epoch: 095, Loss: 2.4203, Train: 0.9955, Valid: 0.9867, Best: 0.9873\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 2.44950795173645 | KNN Loss: 2.4479095935821533 | CLS Loss: 0.001598259201273322\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 2.3888707160949707 | KNN Loss: 2.3593785762786865 | CLS Loss: 0.02949216030538082\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 2.353353261947632 | KNN Loss: 2.3503575325012207 | CLS Loss: 0.0029957792721688747\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 2.403921604156494 | KNN Loss: 2.387380599975586 | CLS Loss: 0.016541047021746635\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 2.4101336002349854 | KNN Loss: 2.388340711593628 | CLS Loss: 0.02179277129471302\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 2.420353651046753 | KNN Loss: 2.4132027626037598 | CLS Loss: 0.00715082511305809\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 2.4105896949768066 | KNN Loss: 2.3977603912353516 | CLS Loss: 0.012829277664422989\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 2.3972175121307373 | KNN Loss: 2.372918128967285 | CLS Loss: 0.02429942600429058\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 2.3904693126678467 | KNN Loss: 2.3827121257781982 | CLS Loss: 0.007757294923067093\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 2.3965847492218018 | KNN Loss: 2.3878252506256104 | CLS Loss: 0.008759443648159504\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 2.4205291271209717 | KNN Loss: 2.4078752994537354 | CLS Loss: 0.012653728015720844\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 2.4561028480529785 | KNN Loss: 2.4442291259765625 | CLS Loss: 0.011873736046254635\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 2.42142915725708 | KNN Loss: 2.4026753902435303 | CLS Loss: 0.018753690645098686\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 2.4298417568206787 | KNN Loss: 2.423579454421997 | CLS Loss: 0.00626232847571373\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 2.4021713733673096 | KNN Loss: 2.393209934234619 | CLS Loss: 0.008961468003690243\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 2.413410186767578 | KNN Loss: 2.393723726272583 | CLS Loss: 0.01968635991215706\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 2.441438913345337 | KNN Loss: 2.4190897941589355 | CLS Loss: 0.022349130362272263\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 2.404313564300537 | KNN Loss: 2.398008108139038 | CLS Loss: 0.006305457558482885\n",
      "Epoch: 096, Loss: 2.4174, Train: 0.9959, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 2.423741340637207 | KNN Loss: 2.3995487689971924 | CLS Loss: 0.024192556738853455\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 2.4058313369750977 | KNN Loss: 2.401906967163086 | CLS Loss: 0.003924337215721607\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 2.410552501678467 | KNN Loss: 2.4044418334960938 | CLS Loss: 0.006110744550824165\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 2.412175416946411 | KNN Loss: 2.4020142555236816 | CLS Loss: 0.010161101818084717\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 2.414515256881714 | KNN Loss: 2.3950295448303223 | CLS Loss: 0.01948561519384384\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 2.445875883102417 | KNN Loss: 2.4361696243286133 | CLS Loss: 0.009706313721835613\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 2.3829760551452637 | KNN Loss: 2.376640796661377 | CLS Loss: 0.006335296668112278\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 2.396775960922241 | KNN Loss: 2.3769161701202393 | CLS Loss: 0.019859841093420982\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 2.452352285385132 | KNN Loss: 2.4311025142669678 | CLS Loss: 0.02124977298080921\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 2.420644760131836 | KNN Loss: 2.412686347961426 | CLS Loss: 0.007958460599184036\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 2.3951199054718018 | KNN Loss: 2.3920860290527344 | CLS Loss: 0.0030339076183736324\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 2.4262914657592773 | KNN Loss: 2.3889472484588623 | CLS Loss: 0.037344325333833694\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 2.391603946685791 | KNN Loss: 2.385772943496704 | CLS Loss: 0.005830999463796616\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 2.4068286418914795 | KNN Loss: 2.3779947757720947 | CLS Loss: 0.02883375622332096\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 2.4846389293670654 | KNN Loss: 2.4790234565734863 | CLS Loss: 0.00561546441167593\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 2.387143611907959 | KNN Loss: 2.383119821548462 | CLS Loss: 0.004023747052997351\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 2.386789083480835 | KNN Loss: 2.3742027282714844 | CLS Loss: 0.012586397118866444\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 2.4590566158294678 | KNN Loss: 2.439845323562622 | CLS Loss: 0.01921123079955578\n",
      "Epoch: 097, Loss: 2.4196, Train: 0.9958, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 2.3967020511627197 | KNN Loss: 2.3938791751861572 | CLS Loss: 0.0028228568844497204\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 2.3968725204467773 | KNN Loss: 2.3733999729156494 | CLS Loss: 0.023472493514418602\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 2.420654296875 | KNN Loss: 2.409242868423462 | CLS Loss: 0.011411507613956928\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 2.379281520843506 | KNN Loss: 2.3737001419067383 | CLS Loss: 0.005581322126090527\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 2.386828899383545 | KNN Loss: 2.38093638420105 | CLS Loss: 0.0058924672193825245\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 2.444809675216675 | KNN Loss: 2.437805414199829 | CLS Loss: 0.007004222366958857\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 2.4142301082611084 | KNN Loss: 2.4005165100097656 | CLS Loss: 0.013713658787310123\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 2.3988077640533447 | KNN Loss: 2.3869664669036865 | CLS Loss: 0.011841325089335442\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 2.40881085395813 | KNN Loss: 2.398233652114868 | CLS Loss: 0.010577191598713398\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 2.404191493988037 | KNN Loss: 2.392270088195801 | CLS Loss: 0.011921338737010956\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 2.430955648422241 | KNN Loss: 2.4090793132781982 | CLS Loss: 0.02187645249068737\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 2.4042043685913086 | KNN Loss: 2.3934247493743896 | CLS Loss: 0.010779592208564281\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 2.3925819396972656 | KNN Loss: 2.3768296241760254 | CLS Loss: 0.01575232297182083\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 2.462080955505371 | KNN Loss: 2.4309284687042236 | CLS Loss: 0.031152402982115746\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 2.4133901596069336 | KNN Loss: 2.38666033744812 | CLS Loss: 0.026729770004749298\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 2.391608238220215 | KNN Loss: 2.3835721015930176 | CLS Loss: 0.008036249317228794\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 2.423511266708374 | KNN Loss: 2.4037137031555176 | CLS Loss: 0.019797587767243385\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 2.4294381141662598 | KNN Loss: 2.409374952316284 | CLS Loss: 0.020063063129782677\n",
      "Epoch: 098, Loss: 2.4142, Train: 0.9946, Valid: 0.9839, Best: 0.9873\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 2.3979544639587402 | KNN Loss: 2.3855323791503906 | CLS Loss: 0.012422154657542706\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 2.40962290763855 | KNN Loss: 2.399003267288208 | CLS Loss: 0.010619535110890865\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 2.3905367851257324 | KNN Loss: 2.369194269180298 | CLS Loss: 0.02134246751666069\n",
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 2.420660972595215 | KNN Loss: 2.4141504764556885 | CLS Loss: 0.006510601844638586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 2.4299163818359375 | KNN Loss: 2.4222893714904785 | CLS Loss: 0.007626964244991541\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 2.420658826828003 | KNN Loss: 2.40999436378479 | CLS Loss: 0.010664572939276695\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 2.3870248794555664 | KNN Loss: 2.376127004623413 | CLS Loss: 0.01089776586741209\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 2.381593942642212 | KNN Loss: 2.374173164367676 | CLS Loss: 0.0074206627905368805\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 2.4164435863494873 | KNN Loss: 2.393423080444336 | CLS Loss: 0.023020509630441666\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 2.4080607891082764 | KNN Loss: 2.3970139026641846 | CLS Loss: 0.011046904139220715\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 2.4019315242767334 | KNN Loss: 2.392029285430908 | CLS Loss: 0.00990226585417986\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 2.3934903144836426 | KNN Loss: 2.38824462890625 | CLS Loss: 0.005245616193860769\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 2.430248498916626 | KNN Loss: 2.4180829524993896 | CLS Loss: 0.012165526859462261\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 2.4155564308166504 | KNN Loss: 2.4034619331359863 | CLS Loss: 0.01209447905421257\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 2.424717903137207 | KNN Loss: 2.409166097640991 | CLS Loss: 0.015551840886473656\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 2.3915295600891113 | KNN Loss: 2.3764162063598633 | CLS Loss: 0.015113463625311852\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 2.4538121223449707 | KNN Loss: 2.4162850379943848 | CLS Loss: 0.03752712905406952\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 2.4352188110351562 | KNN Loss: 2.4226131439208984 | CLS Loss: 0.01260555349290371\n",
      "Epoch: 099, Loss: 2.4176, Train: 0.9941, Valid: 0.9847, Best: 0.9873\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 2.418031692504883 | KNN Loss: 2.405416965484619 | CLS Loss: 0.012614751234650612\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 2.3926076889038086 | KNN Loss: 2.387535810470581 | CLS Loss: 0.005071769934147596\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 2.4000046253204346 | KNN Loss: 2.3832905292510986 | CLS Loss: 0.016714045777916908\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 2.435915470123291 | KNN Loss: 2.4312143325805664 | CLS Loss: 0.004701222293078899\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 2.424607992172241 | KNN Loss: 2.4030275344848633 | CLS Loss: 0.02158042974770069\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 2.4159181118011475 | KNN Loss: 2.4005305767059326 | CLS Loss: 0.015387431718409061\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 2.410011053085327 | KNN Loss: 2.404872417449951 | CLS Loss: 0.00513852946460247\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 2.4422338008880615 | KNN Loss: 2.4274773597717285 | CLS Loss: 0.01475637685507536\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 2.399350881576538 | KNN Loss: 2.3929948806762695 | CLS Loss: 0.006356063764542341\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 2.441260576248169 | KNN Loss: 2.4321601390838623 | CLS Loss: 0.009100508876144886\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 2.416886329650879 | KNN Loss: 2.3882815837860107 | CLS Loss: 0.028604719787836075\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 2.427324056625366 | KNN Loss: 2.415795087814331 | CLS Loss: 0.011528853327035904\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 2.4184842109680176 | KNN Loss: 2.4007246494293213 | CLS Loss: 0.0177596565335989\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 2.425814628601074 | KNN Loss: 2.3987040519714355 | CLS Loss: 0.027110539376735687\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 2.4047348499298096 | KNN Loss: 2.3976361751556396 | CLS Loss: 0.007098792586475611\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 2.4243552684783936 | KNN Loss: 2.418022871017456 | CLS Loss: 0.006332476157695055\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 2.4200849533081055 | KNN Loss: 2.4165029525756836 | CLS Loss: 0.0035818852484226227\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 2.416188955307007 | KNN Loss: 2.4040169715881348 | CLS Loss: 0.012171883136034012\n",
      "Epoch: 100, Loss: 2.4179, Train: 0.9965, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 2.3755364418029785 | KNN Loss: 2.3631880283355713 | CLS Loss: 0.01234833151102066\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 2.397789478302002 | KNN Loss: 2.382577419281006 | CLS Loss: 0.015212178230285645\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 2.4233570098876953 | KNN Loss: 2.4083032608032227 | CLS Loss: 0.015053798444569111\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 2.4418258666992188 | KNN Loss: 2.4281222820281982 | CLS Loss: 0.013703697361052036\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 2.3955602645874023 | KNN Loss: 2.391876220703125 | CLS Loss: 0.0036841193214058876\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 2.415024757385254 | KNN Loss: 2.4031949043273926 | CLS Loss: 0.011829804629087448\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 2.443094253540039 | KNN Loss: 2.4273221492767334 | CLS Loss: 0.015772148966789246\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 2.4618704319000244 | KNN Loss: 2.4336512088775635 | CLS Loss: 0.028219329193234444\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 2.3974621295928955 | KNN Loss: 2.3545424938201904 | CLS Loss: 0.04291952773928642\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 2.457350254058838 | KNN Loss: 2.440642833709717 | CLS Loss: 0.016707411035895348\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 2.416084051132202 | KNN Loss: 2.3973143100738525 | CLS Loss: 0.018769625574350357\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 2.4301741123199463 | KNN Loss: 2.42048978805542 | CLS Loss: 0.00968423392623663\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 2.4066779613494873 | KNN Loss: 2.404531955718994 | CLS Loss: 0.002146010985597968\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 2.4104795455932617 | KNN Loss: 2.3830482959747314 | CLS Loss: 0.027431165799498558\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 2.383415937423706 | KNN Loss: 2.3633415699005127 | CLS Loss: 0.020074378699064255\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 2.468928098678589 | KNN Loss: 2.4365592002868652 | CLS Loss: 0.03236893564462662\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 2.4413626194000244 | KNN Loss: 2.426530599594116 | CLS Loss: 0.014832007698714733\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 2.4034125804901123 | KNN Loss: 2.3847031593322754 | CLS Loss: 0.01870948076248169\n",
      "Epoch: 101, Loss: 2.4159, Train: 0.9959, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 2.4389383792877197 | KNN Loss: 2.4305686950683594 | CLS Loss: 0.008369644172489643\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 2.4293196201324463 | KNN Loss: 2.413425922393799 | CLS Loss: 0.015893712639808655\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 2.3887178897857666 | KNN Loss: 2.375129461288452 | CLS Loss: 0.013588380068540573\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 2.3890223503112793 | KNN Loss: 2.3859827518463135 | CLS Loss: 0.003039630362764001\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 2.4137768745422363 | KNN Loss: 2.388751745223999 | CLS Loss: 0.025025149807333946\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 2.4366281032562256 | KNN Loss: 2.423734426498413 | CLS Loss: 0.012893729843199253\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 2.387860059738159 | KNN Loss: 2.3712210655212402 | CLS Loss: 0.016638925299048424\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 2.464630126953125 | KNN Loss: 2.4383225440979004 | CLS Loss: 0.026307638734579086\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 2.441854476928711 | KNN Loss: 2.4356064796447754 | CLS Loss: 0.006247923243790865\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 2.4389681816101074 | KNN Loss: 2.4303152561187744 | CLS Loss: 0.00865298230201006\n",
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 2.424743890762329 | KNN Loss: 2.42153000831604 | CLS Loss: 0.003213975578546524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 2.4470889568328857 | KNN Loss: 2.440800428390503 | CLS Loss: 0.006288525182753801\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 2.419532060623169 | KNN Loss: 2.416633129119873 | CLS Loss: 0.0028988898266106844\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 2.4242331981658936 | KNN Loss: 2.400282382965088 | CLS Loss: 0.023950789123773575\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 2.397582769393921 | KNN Loss: 2.3825252056121826 | CLS Loss: 0.015057520940899849\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 2.4539170265197754 | KNN Loss: 2.4146547317504883 | CLS Loss: 0.03926220163702965\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 2.428683042526245 | KNN Loss: 2.423800230026245 | CLS Loss: 0.004882738459855318\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 2.3784542083740234 | KNN Loss: 2.3721566200256348 | CLS Loss: 0.006297666113823652\n",
      "Epoch: 102, Loss: 2.4191, Train: 0.9959, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 2.407958984375 | KNN Loss: 2.39984393119812 | CLS Loss: 0.008115016855299473\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 2.4197592735290527 | KNN Loss: 2.3965089321136475 | CLS Loss: 0.023250451311469078\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 2.4063663482666016 | KNN Loss: 2.391874074935913 | CLS Loss: 0.014492174610495567\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 2.42440128326416 | KNN Loss: 2.41929030418396 | CLS Loss: 0.005111088044941425\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 2.427642583847046 | KNN Loss: 2.4199535846710205 | CLS Loss: 0.007688938174396753\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 2.4025826454162598 | KNN Loss: 2.392772674560547 | CLS Loss: 0.009809887036681175\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 2.4304699897766113 | KNN Loss: 2.4069907665252686 | CLS Loss: 0.023479290306568146\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 2.408212661743164 | KNN Loss: 2.4043118953704834 | CLS Loss: 0.00390077312476933\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 2.4622156620025635 | KNN Loss: 2.4553682804107666 | CLS Loss: 0.0068473657593131065\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 2.3846981525421143 | KNN Loss: 2.3773484230041504 | CLS Loss: 0.007349647115916014\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 2.4071590900421143 | KNN Loss: 2.4013521671295166 | CLS Loss: 0.005806862376630306\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 2.416506290435791 | KNN Loss: 2.3941264152526855 | CLS Loss: 0.022379817441105843\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 2.4149317741394043 | KNN Loss: 2.4024767875671387 | CLS Loss: 0.012455032207071781\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 2.4189727306365967 | KNN Loss: 2.3904294967651367 | CLS Loss: 0.028543220832943916\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 2.4018914699554443 | KNN Loss: 2.3848800659179688 | CLS Loss: 0.017011508345603943\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 2.4280166625976562 | KNN Loss: 2.4174423217773438 | CLS Loss: 0.010574457235634327\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 2.4088644981384277 | KNN Loss: 2.3780128955841064 | CLS Loss: 0.030851559713482857\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 2.390076160430908 | KNN Loss: 2.3826544284820557 | CLS Loss: 0.007421796675771475\n",
      "Epoch: 103, Loss: 2.4123, Train: 0.9950, Valid: 0.9854, Best: 0.9873\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 2.4464471340179443 | KNN Loss: 2.415696144104004 | CLS Loss: 0.03075106255710125\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 2.4379985332489014 | KNN Loss: 2.413585662841797 | CLS Loss: 0.024412762373685837\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 2.4002411365509033 | KNN Loss: 2.3954243659973145 | CLS Loss: 0.004816661588847637\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 2.4024407863616943 | KNN Loss: 2.398056983947754 | CLS Loss: 0.00438371766358614\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 2.3793387413024902 | KNN Loss: 2.367828369140625 | CLS Loss: 0.011510360985994339\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 2.395099401473999 | KNN Loss: 2.3867812156677246 | CLS Loss: 0.0083180982619524\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 2.4406962394714355 | KNN Loss: 2.427534341812134 | CLS Loss: 0.013161808252334595\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 2.3969433307647705 | KNN Loss: 2.3840253353118896 | CLS Loss: 0.012918024323880672\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 2.3996565341949463 | KNN Loss: 2.3986120223999023 | CLS Loss: 0.001044537522830069\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 2.399545669555664 | KNN Loss: 2.3952479362487793 | CLS Loss: 0.004297646228224039\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 2.462838649749756 | KNN Loss: 2.4375367164611816 | CLS Loss: 0.02530195377767086\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 2.4096691608428955 | KNN Loss: 2.3997066020965576 | CLS Loss: 0.009962514042854309\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 2.415144920349121 | KNN Loss: 2.411494016647339 | CLS Loss: 0.003650897881016135\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 2.4174115657806396 | KNN Loss: 2.4108104705810547 | CLS Loss: 0.006601070519536734\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 2.4241979122161865 | KNN Loss: 2.406435966491699 | CLS Loss: 0.017761891707777977\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 2.446608543395996 | KNN Loss: 2.4297995567321777 | CLS Loss: 0.016809046268463135\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 2.3722434043884277 | KNN Loss: 2.3650965690612793 | CLS Loss: 0.007146953605115414\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 2.3860583305358887 | KNN Loss: 2.37308406829834 | CLS Loss: 0.01297419797629118\n",
      "Epoch: 104, Loss: 2.4125, Train: 0.9950, Valid: 0.9839, Best: 0.9873\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 2.415055274963379 | KNN Loss: 2.4059252738952637 | CLS Loss: 0.009130053222179413\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 2.434779405593872 | KNN Loss: 2.4284610748291016 | CLS Loss: 0.006318348925560713\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 2.425426959991455 | KNN Loss: 2.413829803466797 | CLS Loss: 0.011597199365496635\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 2.4389374256134033 | KNN Loss: 2.4177799224853516 | CLS Loss: 0.02115759253501892\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 2.434218168258667 | KNN Loss: 2.4164440631866455 | CLS Loss: 0.017774058505892754\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 2.4160211086273193 | KNN Loss: 2.390014171600342 | CLS Loss: 0.026006823405623436\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 2.418201446533203 | KNN Loss: 2.4088847637176514 | CLS Loss: 0.009316740557551384\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 2.4107346534729004 | KNN Loss: 2.401066780090332 | CLS Loss: 0.009667947888374329\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 2.4289491176605225 | KNN Loss: 2.4016737937927246 | CLS Loss: 0.027275286614894867\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 2.4214699268341064 | KNN Loss: 2.3999462127685547 | CLS Loss: 0.021523654460906982\n",
      "Epoch 105 / 200 | iteration 100 / 171 | Total Loss: 2.408961534500122 | KNN Loss: 2.3910069465637207 | CLS Loss: 0.01795470528304577\n",
      "Epoch 105 / 200 | iteration 110 / 171 | Total Loss: 2.413937568664551 | KNN Loss: 2.4053685665130615 | CLS Loss: 0.008569102734327316\n",
      "Epoch 105 / 200 | iteration 120 / 171 | Total Loss: 2.3906667232513428 | KNN Loss: 2.378693103790283 | CLS Loss: 0.011973547749221325\n",
      "Epoch 105 / 200 | iteration 130 / 171 | Total Loss: 2.4462649822235107 | KNN Loss: 2.4216361045837402 | CLS Loss: 0.024628862738609314\n",
      "Epoch 105 / 200 | iteration 140 / 171 | Total Loss: 2.4010660648345947 | KNN Loss: 2.395885705947876 | CLS Loss: 0.005180325824767351\n",
      "Epoch 105 / 200 | iteration 150 / 171 | Total Loss: 2.394763946533203 | KNN Loss: 2.373960256576538 | CLS Loss: 0.020803719758987427\n",
      "Epoch 105 / 200 | iteration 160 / 171 | Total Loss: 2.3577663898468018 | KNN Loss: 2.3505470752716064 | CLS Loss: 0.007219319231808186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 / 200 | iteration 170 / 171 | Total Loss: 2.4207677841186523 | KNN Loss: 2.3963191509246826 | CLS Loss: 0.024448616430163383\n",
      "Epoch: 105, Loss: 2.4157, Train: 0.9962, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 106 / 200 | iteration 0 / 171 | Total Loss: 2.4087765216827393 | KNN Loss: 2.388765573501587 | CLS Loss: 0.020010931417346\n",
      "Epoch 106 / 200 | iteration 10 / 171 | Total Loss: 2.422978639602661 | KNN Loss: 2.4101197719573975 | CLS Loss: 0.012858793139457703\n",
      "Epoch 106 / 200 | iteration 20 / 171 | Total Loss: 2.41858172416687 | KNN Loss: 2.3976829051971436 | CLS Loss: 0.02089879661798477\n",
      "Epoch 106 / 200 | iteration 30 / 171 | Total Loss: 2.4162795543670654 | KNN Loss: 2.411379098892212 | CLS Loss: 0.004900495987385511\n",
      "Epoch 106 / 200 | iteration 40 / 171 | Total Loss: 2.393186569213867 | KNN Loss: 2.380333423614502 | CLS Loss: 0.012853122316300869\n",
      "Epoch 106 / 200 | iteration 50 / 171 | Total Loss: 2.3979806900024414 | KNN Loss: 2.3935930728912354 | CLS Loss: 0.004387693013995886\n",
      "Epoch 106 / 200 | iteration 60 / 171 | Total Loss: 2.4045681953430176 | KNN Loss: 2.390817642211914 | CLS Loss: 0.013750605285167694\n",
      "Epoch 106 / 200 | iteration 70 / 171 | Total Loss: 2.4272727966308594 | KNN Loss: 2.4185166358947754 | CLS Loss: 0.008756236173212528\n",
      "Epoch 106 / 200 | iteration 80 / 171 | Total Loss: 2.399364471435547 | KNN Loss: 2.388519287109375 | CLS Loss: 0.01084520760923624\n",
      "Epoch 106 / 200 | iteration 90 / 171 | Total Loss: 2.4320995807647705 | KNN Loss: 2.4199533462524414 | CLS Loss: 0.012146346271038055\n",
      "Epoch 106 / 200 | iteration 100 / 171 | Total Loss: 2.4242162704467773 | KNN Loss: 2.420605182647705 | CLS Loss: 0.0036109727807343006\n",
      "Epoch 106 / 200 | iteration 110 / 171 | Total Loss: 2.3902108669281006 | KNN Loss: 2.386587619781494 | CLS Loss: 0.0036233447026461363\n",
      "Epoch 106 / 200 | iteration 120 / 171 | Total Loss: 2.3944828510284424 | KNN Loss: 2.389915943145752 | CLS Loss: 0.004566850606352091\n",
      "Epoch 106 / 200 | iteration 130 / 171 | Total Loss: 2.3891751766204834 | KNN Loss: 2.378434658050537 | CLS Loss: 0.010740501806139946\n",
      "Epoch 106 / 200 | iteration 140 / 171 | Total Loss: 2.4267826080322266 | KNN Loss: 2.418976068496704 | CLS Loss: 0.00780651718378067\n",
      "Epoch 106 / 200 | iteration 150 / 171 | Total Loss: 2.421821117401123 | KNN Loss: 2.4072554111480713 | CLS Loss: 0.014565806835889816\n",
      "Epoch 106 / 200 | iteration 160 / 171 | Total Loss: 2.440401077270508 | KNN Loss: 2.4228782653808594 | CLS Loss: 0.017522919923067093\n",
      "Epoch 106 / 200 | iteration 170 / 171 | Total Loss: 2.407083749771118 | KNN Loss: 2.397517681121826 | CLS Loss: 0.009566040709614754\n",
      "Epoch: 106, Loss: 2.4125, Train: 0.9969, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 107 / 200 | iteration 0 / 171 | Total Loss: 2.38525652885437 | KNN Loss: 2.383509635925293 | CLS Loss: 0.0017468164442107081\n",
      "Epoch 107 / 200 | iteration 10 / 171 | Total Loss: 2.4145822525024414 | KNN Loss: 2.3841824531555176 | CLS Loss: 0.030399855226278305\n",
      "Epoch 107 / 200 | iteration 20 / 171 | Total Loss: 2.4229257106781006 | KNN Loss: 2.414891004562378 | CLS Loss: 0.008034644648432732\n",
      "Epoch 107 / 200 | iteration 30 / 171 | Total Loss: 2.4124927520751953 | KNN Loss: 2.3882946968078613 | CLS Loss: 0.024198174476623535\n",
      "Epoch 107 / 200 | iteration 40 / 171 | Total Loss: 2.4036641120910645 | KNN Loss: 2.4016268253326416 | CLS Loss: 0.002037324942648411\n",
      "Epoch 107 / 200 | iteration 50 / 171 | Total Loss: 2.3953402042388916 | KNN Loss: 2.391376256942749 | CLS Loss: 0.003964021801948547\n",
      "Epoch 107 / 200 | iteration 60 / 171 | Total Loss: 2.385704278945923 | KNN Loss: 2.377615213394165 | CLS Loss: 0.008089027367532253\n",
      "Epoch 107 / 200 | iteration 70 / 171 | Total Loss: 2.3829634189605713 | KNN Loss: 2.3718414306640625 | CLS Loss: 0.011121964082121849\n",
      "Epoch 107 / 200 | iteration 80 / 171 | Total Loss: 2.4276819229125977 | KNN Loss: 2.3953120708465576 | CLS Loss: 0.03236981853842735\n",
      "Epoch 107 / 200 | iteration 90 / 171 | Total Loss: 2.423377275466919 | KNN Loss: 2.411656141281128 | CLS Loss: 0.011721250601112843\n",
      "Epoch 107 / 200 | iteration 100 / 171 | Total Loss: 2.4059252738952637 | KNN Loss: 2.403398036956787 | CLS Loss: 0.0025272085331380367\n",
      "Epoch 107 / 200 | iteration 110 / 171 | Total Loss: 2.4013402462005615 | KNN Loss: 2.3921821117401123 | CLS Loss: 0.009158055298030376\n",
      "Epoch 107 / 200 | iteration 120 / 171 | Total Loss: 2.4298300743103027 | KNN Loss: 2.3973255157470703 | CLS Loss: 0.03250466659665108\n",
      "Epoch 107 / 200 | iteration 130 / 171 | Total Loss: 2.466090202331543 | KNN Loss: 2.4395909309387207 | CLS Loss: 0.026499196887016296\n",
      "Epoch 107 / 200 | iteration 140 / 171 | Total Loss: 2.3951499462127686 | KNN Loss: 2.3895654678344727 | CLS Loss: 0.005584425758570433\n",
      "Epoch 107 / 200 | iteration 150 / 171 | Total Loss: 2.4194931983947754 | KNN Loss: 2.395118236541748 | CLS Loss: 0.024375079199671745\n",
      "Epoch 107 / 200 | iteration 160 / 171 | Total Loss: 2.42468523979187 | KNN Loss: 2.4153170585632324 | CLS Loss: 0.009368141181766987\n",
      "Epoch 107 / 200 | iteration 170 / 171 | Total Loss: 2.4541592597961426 | KNN Loss: 2.4276044368743896 | CLS Loss: 0.026554808020591736\n",
      "Epoch: 107, Loss: 2.4133, Train: 0.9967, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 108 / 200 | iteration 0 / 171 | Total Loss: 2.404633045196533 | KNN Loss: 2.3980205059051514 | CLS Loss: 0.0066125956363976\n",
      "Epoch 108 / 200 | iteration 10 / 171 | Total Loss: 2.4136030673980713 | KNN Loss: 2.39713454246521 | CLS Loss: 0.01646854728460312\n",
      "Epoch 108 / 200 | iteration 20 / 171 | Total Loss: 2.3890998363494873 | KNN Loss: 2.3698599338531494 | CLS Loss: 0.019239861518144608\n",
      "Epoch 108 / 200 | iteration 30 / 171 | Total Loss: 2.3905093669891357 | KNN Loss: 2.3874638080596924 | CLS Loss: 0.0030456450767815113\n",
      "Epoch 108 / 200 | iteration 40 / 171 | Total Loss: 2.3960471153259277 | KNN Loss: 2.383659601211548 | CLS Loss: 0.012387396767735481\n",
      "Epoch 108 / 200 | iteration 50 / 171 | Total Loss: 2.4197611808776855 | KNN Loss: 2.415955066680908 | CLS Loss: 0.003806205466389656\n",
      "Epoch 108 / 200 | iteration 60 / 171 | Total Loss: 2.3861780166625977 | KNN Loss: 2.378573417663574 | CLS Loss: 0.007604700978845358\n",
      "Epoch 108 / 200 | iteration 70 / 171 | Total Loss: 2.434659004211426 | KNN Loss: 2.4201560020446777 | CLS Loss: 0.014503024518489838\n",
      "Epoch 108 / 200 | iteration 80 / 171 | Total Loss: 2.430563449859619 | KNN Loss: 2.414353132247925 | CLS Loss: 0.01621023379266262\n",
      "Epoch 108 / 200 | iteration 90 / 171 | Total Loss: 2.4229791164398193 | KNN Loss: 2.418370246887207 | CLS Loss: 0.004608814138919115\n",
      "Epoch 108 / 200 | iteration 100 / 171 | Total Loss: 2.428682804107666 | KNN Loss: 2.409574270248413 | CLS Loss: 0.019108420237898827\n",
      "Epoch 108 / 200 | iteration 110 / 171 | Total Loss: 2.3751649856567383 | KNN Loss: 2.3645248413085938 | CLS Loss: 0.010640231892466545\n",
      "Epoch 108 / 200 | iteration 120 / 171 | Total Loss: 2.4281082153320312 | KNN Loss: 2.411564350128174 | CLS Loss: 0.016543932259082794\n",
      "Epoch 108 / 200 | iteration 130 / 171 | Total Loss: 2.415966272354126 | KNN Loss: 2.4140212535858154 | CLS Loss: 0.001944920513778925\n",
      "Epoch 108 / 200 | iteration 140 / 171 | Total Loss: 2.420311689376831 | KNN Loss: 2.415701389312744 | CLS Loss: 0.004610258154571056\n",
      "Epoch 108 / 200 | iteration 150 / 171 | Total Loss: 2.4310755729675293 | KNN Loss: 2.4129273891448975 | CLS Loss: 0.018148273229599\n",
      "Epoch 108 / 200 | iteration 160 / 171 | Total Loss: 2.4184353351593018 | KNN Loss: 2.3971004486083984 | CLS Loss: 0.021334905177354813\n",
      "Epoch 108 / 200 | iteration 170 / 171 | Total Loss: 2.4158763885498047 | KNN Loss: 2.3972387313842773 | CLS Loss: 0.018637768924236298\n",
      "Epoch: 108, Loss: 2.4161, Train: 0.9956, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 109 / 200 | iteration 0 / 171 | Total Loss: 2.404808282852173 | KNN Loss: 2.3918185234069824 | CLS Loss: 0.012989789247512817\n",
      "Epoch 109 / 200 | iteration 10 / 171 | Total Loss: 2.412463665008545 | KNN Loss: 2.381443500518799 | CLS Loss: 0.031020091846585274\n",
      "Epoch 109 / 200 | iteration 20 / 171 | Total Loss: 2.436224937438965 | KNN Loss: 2.425989866256714 | CLS Loss: 0.010235065594315529\n",
      "Epoch 109 / 200 | iteration 30 / 171 | Total Loss: 2.43691086769104 | KNN Loss: 2.4252967834472656 | CLS Loss: 0.011613969691097736\n",
      "Epoch 109 / 200 | iteration 40 / 171 | Total Loss: 2.4132635593414307 | KNN Loss: 2.39152193069458 | CLS Loss: 0.02174166403710842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 / 200 | iteration 50 / 171 | Total Loss: 2.3843092918395996 | KNN Loss: 2.3605544567108154 | CLS Loss: 0.02375483699142933\n",
      "Epoch 109 / 200 | iteration 60 / 171 | Total Loss: 2.432204484939575 | KNN Loss: 2.42305064201355 | CLS Loss: 0.009153781458735466\n",
      "Epoch 109 / 200 | iteration 70 / 171 | Total Loss: 2.3904967308044434 | KNN Loss: 2.3699452877044678 | CLS Loss: 0.020551485940814018\n",
      "Epoch 109 / 200 | iteration 80 / 171 | Total Loss: 2.406862735748291 | KNN Loss: 2.3841168880462646 | CLS Loss: 0.022745957598090172\n",
      "Epoch 109 / 200 | iteration 90 / 171 | Total Loss: 2.375570058822632 | KNN Loss: 2.3685615062713623 | CLS Loss: 0.007008666172623634\n",
      "Epoch 109 / 200 | iteration 100 / 171 | Total Loss: 2.4109108448028564 | KNN Loss: 2.3904175758361816 | CLS Loss: 0.020493384450674057\n",
      "Epoch 109 / 200 | iteration 110 / 171 | Total Loss: 2.3895843029022217 | KNN Loss: 2.375119924545288 | CLS Loss: 0.014464424923062325\n",
      "Epoch 109 / 200 | iteration 120 / 171 | Total Loss: 2.4272382259368896 | KNN Loss: 2.4180963039398193 | CLS Loss: 0.009141916409134865\n",
      "Epoch 109 / 200 | iteration 130 / 171 | Total Loss: 2.4417884349823 | KNN Loss: 2.4349002838134766 | CLS Loss: 0.006888130679726601\n",
      "Epoch 109 / 200 | iteration 140 / 171 | Total Loss: 2.4114911556243896 | KNN Loss: 2.3944365978240967 | CLS Loss: 0.017054542899131775\n",
      "Epoch 109 / 200 | iteration 150 / 171 | Total Loss: 2.4467427730560303 | KNN Loss: 2.418539524078369 | CLS Loss: 0.02820330299437046\n",
      "Epoch 109 / 200 | iteration 160 / 171 | Total Loss: 2.4520881175994873 | KNN Loss: 2.4409220218658447 | CLS Loss: 0.01116618700325489\n",
      "Epoch 109 / 200 | iteration 170 / 171 | Total Loss: 2.40077805519104 | KNN Loss: 2.3956234455108643 | CLS Loss: 0.005154693964868784\n",
      "Epoch: 109, Loss: 2.4173, Train: 0.9961, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 110 / 200 | iteration 0 / 171 | Total Loss: 2.4336307048797607 | KNN Loss: 2.4138455390930176 | CLS Loss: 0.019785070791840553\n",
      "Epoch 110 / 200 | iteration 10 / 171 | Total Loss: 2.432863473892212 | KNN Loss: 2.4255528450012207 | CLS Loss: 0.007310531567782164\n",
      "Epoch 110 / 200 | iteration 20 / 171 | Total Loss: 2.4357213973999023 | KNN Loss: 2.408754825592041 | CLS Loss: 0.02696656435728073\n",
      "Epoch 110 / 200 | iteration 30 / 171 | Total Loss: 2.4398882389068604 | KNN Loss: 2.4342188835144043 | CLS Loss: 0.005669381469488144\n",
      "Epoch 110 / 200 | iteration 40 / 171 | Total Loss: 2.4029667377471924 | KNN Loss: 2.399681329727173 | CLS Loss: 0.0032852948643267155\n",
      "Epoch 110 / 200 | iteration 50 / 171 | Total Loss: 2.405470848083496 | KNN Loss: 2.4040982723236084 | CLS Loss: 0.0013726770412176847\n",
      "Epoch 110 / 200 | iteration 60 / 171 | Total Loss: 2.3885276317596436 | KNN Loss: 2.3752877712249756 | CLS Loss: 0.013239778578281403\n",
      "Epoch 110 / 200 | iteration 70 / 171 | Total Loss: 2.374537706375122 | KNN Loss: 2.365947961807251 | CLS Loss: 0.00858977995812893\n",
      "Epoch 110 / 200 | iteration 80 / 171 | Total Loss: 2.41701602935791 | KNN Loss: 2.411125659942627 | CLS Loss: 0.005890293512493372\n",
      "Epoch 110 / 200 | iteration 90 / 171 | Total Loss: 2.4248547554016113 | KNN Loss: 2.4025886058807373 | CLS Loss: 0.022266115993261337\n",
      "Epoch 110 / 200 | iteration 100 / 171 | Total Loss: 2.40328049659729 | KNN Loss: 2.3986270427703857 | CLS Loss: 0.004653461277484894\n",
      "Epoch 110 / 200 | iteration 110 / 171 | Total Loss: 2.3945322036743164 | KNN Loss: 2.3890798091888428 | CLS Loss: 0.0054524666629731655\n",
      "Epoch 110 / 200 | iteration 120 / 171 | Total Loss: 2.4184916019439697 | KNN Loss: 2.3888981342315674 | CLS Loss: 0.029593391343951225\n",
      "Epoch 110 / 200 | iteration 130 / 171 | Total Loss: 2.4281837940216064 | KNN Loss: 2.4034881591796875 | CLS Loss: 0.024695711210370064\n",
      "Epoch 110 / 200 | iteration 140 / 171 | Total Loss: 2.4307937622070312 | KNN Loss: 2.3988444805145264 | CLS Loss: 0.03194936364889145\n",
      "Epoch 110 / 200 | iteration 150 / 171 | Total Loss: 2.4005444049835205 | KNN Loss: 2.3932976722717285 | CLS Loss: 0.0072467513382434845\n",
      "Epoch 110 / 200 | iteration 160 / 171 | Total Loss: 2.462663173675537 | KNN Loss: 2.4533770084381104 | CLS Loss: 0.009286213666200638\n",
      "Epoch 110 / 200 | iteration 170 / 171 | Total Loss: 2.3865957260131836 | KNN Loss: 2.369246244430542 | CLS Loss: 0.017349539324641228\n",
      "Epoch: 110, Loss: 2.4168, Train: 0.9955, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 111 / 200 | iteration 0 / 171 | Total Loss: 2.417935371398926 | KNN Loss: 2.3881843090057373 | CLS Loss: 0.029751043766736984\n",
      "Epoch 111 / 200 | iteration 10 / 171 | Total Loss: 2.4699244499206543 | KNN Loss: 2.439509868621826 | CLS Loss: 0.030414696782827377\n",
      "Epoch 111 / 200 | iteration 20 / 171 | Total Loss: 2.382822275161743 | KNN Loss: 2.3781394958496094 | CLS Loss: 0.004682890139520168\n",
      "Epoch 111 / 200 | iteration 30 / 171 | Total Loss: 2.3980712890625 | KNN Loss: 2.384047269821167 | CLS Loss: 0.014023968949913979\n",
      "Epoch 111 / 200 | iteration 40 / 171 | Total Loss: 2.4378230571746826 | KNN Loss: 2.4098119735717773 | CLS Loss: 0.028011023998260498\n",
      "Epoch 111 / 200 | iteration 50 / 171 | Total Loss: 2.369117498397827 | KNN Loss: 2.3580849170684814 | CLS Loss: 0.011032666079699993\n",
      "Epoch 111 / 200 | iteration 60 / 171 | Total Loss: 2.4187562465667725 | KNN Loss: 2.4169411659240723 | CLS Loss: 0.001815092982724309\n",
      "Epoch 111 / 200 | iteration 70 / 171 | Total Loss: 2.436056137084961 | KNN Loss: 2.412360191345215 | CLS Loss: 0.023695869371294975\n",
      "Epoch 111 / 200 | iteration 80 / 171 | Total Loss: 2.4031982421875 | KNN Loss: 2.372420310974121 | CLS Loss: 0.030777832493185997\n",
      "Epoch 111 / 200 | iteration 90 / 171 | Total Loss: 2.4077160358428955 | KNN Loss: 2.381885290145874 | CLS Loss: 0.025830687955021858\n",
      "Epoch 111 / 200 | iteration 100 / 171 | Total Loss: 2.3932862281799316 | KNN Loss: 2.386378288269043 | CLS Loss: 0.00690796272829175\n",
      "Epoch 111 / 200 | iteration 110 / 171 | Total Loss: 2.429981231689453 | KNN Loss: 2.408447504043579 | CLS Loss: 0.021533630788326263\n",
      "Epoch 111 / 200 | iteration 120 / 171 | Total Loss: 2.425774097442627 | KNN Loss: 2.420593738555908 | CLS Loss: 0.005180327221751213\n",
      "Epoch 111 / 200 | iteration 130 / 171 | Total Loss: 2.4184138774871826 | KNN Loss: 2.405322551727295 | CLS Loss: 0.013091220520436764\n",
      "Epoch 111 / 200 | iteration 140 / 171 | Total Loss: 2.4218482971191406 | KNN Loss: 2.4057934284210205 | CLS Loss: 0.016054917126893997\n",
      "Epoch 111 / 200 | iteration 150 / 171 | Total Loss: 2.39271879196167 | KNN Loss: 2.388312816619873 | CLS Loss: 0.004406067077070475\n",
      "Epoch 111 / 200 | iteration 160 / 171 | Total Loss: 2.4229087829589844 | KNN Loss: 2.408689022064209 | CLS Loss: 0.014219772070646286\n",
      "Epoch 111 / 200 | iteration 170 / 171 | Total Loss: 2.407236337661743 | KNN Loss: 2.3811421394348145 | CLS Loss: 0.026094092056155205\n",
      "Epoch: 111, Loss: 2.4144, Train: 0.9966, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 112 / 200 | iteration 0 / 171 | Total Loss: 2.4369869232177734 | KNN Loss: 2.4245402812957764 | CLS Loss: 0.012446623295545578\n",
      "Epoch 112 / 200 | iteration 10 / 171 | Total Loss: 2.4105682373046875 | KNN Loss: 2.3986358642578125 | CLS Loss: 0.011932400986552238\n",
      "Epoch 112 / 200 | iteration 20 / 171 | Total Loss: 2.3899996280670166 | KNN Loss: 2.3794684410095215 | CLS Loss: 0.010531068779528141\n",
      "Epoch 112 / 200 | iteration 30 / 171 | Total Loss: 2.420194625854492 | KNN Loss: 2.4117631912231445 | CLS Loss: 0.008431452326476574\n",
      "Epoch 112 / 200 | iteration 40 / 171 | Total Loss: 2.4061009883880615 | KNN Loss: 2.3964741230010986 | CLS Loss: 0.009626845829188824\n",
      "Epoch 112 / 200 | iteration 50 / 171 | Total Loss: 2.4039645195007324 | KNN Loss: 2.3928380012512207 | CLS Loss: 0.01112663559615612\n",
      "Epoch 112 / 200 | iteration 60 / 171 | Total Loss: 2.3872873783111572 | KNN Loss: 2.3780252933502197 | CLS Loss: 0.009262089617550373\n",
      "Epoch 112 / 200 | iteration 70 / 171 | Total Loss: 2.366037130355835 | KNN Loss: 2.359355926513672 | CLS Loss: 0.006681107450276613\n",
      "Epoch 112 / 200 | iteration 80 / 171 | Total Loss: 2.4042418003082275 | KNN Loss: 2.3995871543884277 | CLS Loss: 0.004654543474316597\n",
      "Epoch 112 / 200 | iteration 90 / 171 | Total Loss: 2.409809112548828 | KNN Loss: 2.405850648880005 | CLS Loss: 0.003958395216614008\n",
      "Epoch 112 / 200 | iteration 100 / 171 | Total Loss: 2.384406089782715 | KNN Loss: 2.3803303241729736 | CLS Loss: 0.004075704608112574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 / 200 | iteration 110 / 171 | Total Loss: 2.430297613143921 | KNN Loss: 2.4236857891082764 | CLS Loss: 0.0066117895767092705\n",
      "Epoch 112 / 200 | iteration 120 / 171 | Total Loss: 2.3980236053466797 | KNN Loss: 2.39180326461792 | CLS Loss: 0.006220315583050251\n",
      "Epoch 112 / 200 | iteration 130 / 171 | Total Loss: 2.383681058883667 | KNN Loss: 2.3762366771698 | CLS Loss: 0.007444469723850489\n",
      "Epoch 112 / 200 | iteration 140 / 171 | Total Loss: 2.403081178665161 | KNN Loss: 2.3907902240753174 | CLS Loss: 0.012291030958294868\n",
      "Epoch 112 / 200 | iteration 150 / 171 | Total Loss: 2.39434552192688 | KNN Loss: 2.387427806854248 | CLS Loss: 0.006917779799550772\n",
      "Epoch 112 / 200 | iteration 160 / 171 | Total Loss: 2.3927085399627686 | KNN Loss: 2.3909246921539307 | CLS Loss: 0.0017838198691606522\n",
      "Epoch 112 / 200 | iteration 170 / 171 | Total Loss: 2.402440309524536 | KNN Loss: 2.39227557182312 | CLS Loss: 0.010164712555706501\n",
      "Epoch: 112, Loss: 2.4140, Train: 0.9967, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 113 / 200 | iteration 0 / 171 | Total Loss: 2.3952713012695312 | KNN Loss: 2.3769142627716064 | CLS Loss: 0.018357010558247566\n",
      "Epoch 113 / 200 | iteration 10 / 171 | Total Loss: 2.4002437591552734 | KNN Loss: 2.386596202850342 | CLS Loss: 0.013647668994963169\n",
      "Epoch 113 / 200 | iteration 20 / 171 | Total Loss: 2.452014923095703 | KNN Loss: 2.4387776851654053 | CLS Loss: 0.013237119652330875\n",
      "Epoch 113 / 200 | iteration 30 / 171 | Total Loss: 2.3870036602020264 | KNN Loss: 2.3792223930358887 | CLS Loss: 0.007781291846185923\n",
      "Epoch 113 / 200 | iteration 40 / 171 | Total Loss: 2.432868719100952 | KNN Loss: 2.4251317977905273 | CLS Loss: 0.007737033534795046\n",
      "Epoch 113 / 200 | iteration 50 / 171 | Total Loss: 2.405667304992676 | KNN Loss: 2.4000396728515625 | CLS Loss: 0.005627726204693317\n",
      "Epoch 113 / 200 | iteration 60 / 171 | Total Loss: 2.3809726238250732 | KNN Loss: 2.36851167678833 | CLS Loss: 0.012460843659937382\n",
      "Epoch 113 / 200 | iteration 70 / 171 | Total Loss: 2.411578893661499 | KNN Loss: 2.401851177215576 | CLS Loss: 0.009727651253342628\n",
      "Epoch 113 / 200 | iteration 80 / 171 | Total Loss: 2.3697617053985596 | KNN Loss: 2.3669488430023193 | CLS Loss: 0.002812788123264909\n",
      "Epoch 113 / 200 | iteration 90 / 171 | Total Loss: 2.414968490600586 | KNN Loss: 2.397213935852051 | CLS Loss: 0.017754577100276947\n",
      "Epoch 113 / 200 | iteration 100 / 171 | Total Loss: 2.4606895446777344 | KNN Loss: 2.441347360610962 | CLS Loss: 0.01934210956096649\n",
      "Epoch 113 / 200 | iteration 110 / 171 | Total Loss: 2.46419620513916 | KNN Loss: 2.4341564178466797 | CLS Loss: 0.030039839446544647\n",
      "Epoch 113 / 200 | iteration 120 / 171 | Total Loss: 2.373239040374756 | KNN Loss: 2.3701391220092773 | CLS Loss: 0.003099891124293208\n",
      "Epoch 113 / 200 | iteration 130 / 171 | Total Loss: 2.4159739017486572 | KNN Loss: 2.4081790447235107 | CLS Loss: 0.007794884964823723\n",
      "Epoch 113 / 200 | iteration 140 / 171 | Total Loss: 2.407449722290039 | KNN Loss: 2.4014954566955566 | CLS Loss: 0.005954263731837273\n",
      "Epoch 113 / 200 | iteration 150 / 171 | Total Loss: 2.411187171936035 | KNN Loss: 2.403764009475708 | CLS Loss: 0.007423105649650097\n",
      "Epoch 113 / 200 | iteration 160 / 171 | Total Loss: 2.387099266052246 | KNN Loss: 2.381422996520996 | CLS Loss: 0.00567633705213666\n",
      "Epoch 113 / 200 | iteration 170 / 171 | Total Loss: 2.425445318222046 | KNN Loss: 2.410796880722046 | CLS Loss: 0.01464847382158041\n",
      "Epoch: 113, Loss: 2.4147, Train: 0.9962, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 114 / 200 | iteration 0 / 171 | Total Loss: 2.39422869682312 | KNN Loss: 2.3857383728027344 | CLS Loss: 0.008490223437547684\n",
      "Epoch 114 / 200 | iteration 10 / 171 | Total Loss: 2.4048922061920166 | KNN Loss: 2.396616220474243 | CLS Loss: 0.008276019245386124\n",
      "Epoch 114 / 200 | iteration 20 / 171 | Total Loss: 2.4761135578155518 | KNN Loss: 2.4667084217071533 | CLS Loss: 0.009405247867107391\n",
      "Epoch 114 / 200 | iteration 30 / 171 | Total Loss: 2.4136061668395996 | KNN Loss: 2.398160934448242 | CLS Loss: 0.015445166267454624\n",
      "Epoch 114 / 200 | iteration 40 / 171 | Total Loss: 2.483761787414551 | KNN Loss: 2.47725248336792 | CLS Loss: 0.0065094223245978355\n",
      "Epoch 114 / 200 | iteration 50 / 171 | Total Loss: 2.354382038116455 | KNN Loss: 2.3457388877868652 | CLS Loss: 0.00864309724420309\n",
      "Epoch 114 / 200 | iteration 60 / 171 | Total Loss: 2.456458806991577 | KNN Loss: 2.4288952350616455 | CLS Loss: 0.02756354585289955\n",
      "Epoch 114 / 200 | iteration 70 / 171 | Total Loss: 2.4403669834136963 | KNN Loss: 2.4279298782348633 | CLS Loss: 0.012437019497156143\n",
      "Epoch 114 / 200 | iteration 80 / 171 | Total Loss: 2.430215358734131 | KNN Loss: 2.4104979038238525 | CLS Loss: 0.019717363640666008\n",
      "Epoch 114 / 200 | iteration 90 / 171 | Total Loss: 2.4265334606170654 | KNN Loss: 2.4067165851593018 | CLS Loss: 0.01981690153479576\n",
      "Epoch 114 / 200 | iteration 100 / 171 | Total Loss: 2.3924505710601807 | KNN Loss: 2.385129451751709 | CLS Loss: 0.007321107666939497\n",
      "Epoch 114 / 200 | iteration 110 / 171 | Total Loss: 2.4161720275878906 | KNN Loss: 2.3953235149383545 | CLS Loss: 0.020848628133535385\n",
      "Epoch 114 / 200 | iteration 120 / 171 | Total Loss: 2.419452667236328 | KNN Loss: 2.3946375846862793 | CLS Loss: 0.02481510490179062\n",
      "Epoch 114 / 200 | iteration 130 / 171 | Total Loss: 2.436612129211426 | KNN Loss: 2.416464328765869 | CLS Loss: 0.020147789269685745\n",
      "Epoch 114 / 200 | iteration 140 / 171 | Total Loss: 2.4036223888397217 | KNN Loss: 2.389369487762451 | CLS Loss: 0.014252893626689911\n",
      "Epoch 114 / 200 | iteration 150 / 171 | Total Loss: 2.4229798316955566 | KNN Loss: 2.4125711917877197 | CLS Loss: 0.010408618487417698\n",
      "Epoch 114 / 200 | iteration 160 / 171 | Total Loss: 2.430950164794922 | KNN Loss: 2.410065174102783 | CLS Loss: 0.02088490128517151\n",
      "Epoch 114 / 200 | iteration 170 / 171 | Total Loss: 2.432349443435669 | KNN Loss: 2.4176204204559326 | CLS Loss: 0.014728926122188568\n",
      "Epoch: 114, Loss: 2.4129, Train: 0.9972, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 115 / 200 | iteration 0 / 171 | Total Loss: 2.397461175918579 | KNN Loss: 2.3677046298980713 | CLS Loss: 0.029756654053926468\n",
      "Epoch 115 / 200 | iteration 10 / 171 | Total Loss: 2.4172441959381104 | KNN Loss: 2.4087202548980713 | CLS Loss: 0.008523890748620033\n",
      "Epoch 115 / 200 | iteration 20 / 171 | Total Loss: 2.408518075942993 | KNN Loss: 2.393643379211426 | CLS Loss: 0.014874709770083427\n",
      "Epoch 115 / 200 | iteration 30 / 171 | Total Loss: 2.4081757068634033 | KNN Loss: 2.4037246704101562 | CLS Loss: 0.0044511351734399796\n",
      "Epoch 115 / 200 | iteration 40 / 171 | Total Loss: 2.4018638134002686 | KNN Loss: 2.387622356414795 | CLS Loss: 0.014241466298699379\n",
      "Epoch 115 / 200 | iteration 50 / 171 | Total Loss: 2.394681692123413 | KNN Loss: 2.3882288932800293 | CLS Loss: 0.006452842149883509\n",
      "Epoch 115 / 200 | iteration 60 / 171 | Total Loss: 2.4156908988952637 | KNN Loss: 2.4099676609039307 | CLS Loss: 0.00572316674515605\n",
      "Epoch 115 / 200 | iteration 70 / 171 | Total Loss: 2.3847105503082275 | KNN Loss: 2.3792507648468018 | CLS Loss: 0.005459805950522423\n",
      "Epoch 115 / 200 | iteration 80 / 171 | Total Loss: 2.3866934776306152 | KNN Loss: 2.3778860569000244 | CLS Loss: 0.008807537145912647\n",
      "Epoch 115 / 200 | iteration 90 / 171 | Total Loss: 2.397428274154663 | KNN Loss: 2.39056658744812 | CLS Loss: 0.006861603818833828\n",
      "Epoch 115 / 200 | iteration 100 / 171 | Total Loss: 2.4069485664367676 | KNN Loss: 2.400049924850464 | CLS Loss: 0.00689869187772274\n",
      "Epoch 115 / 200 | iteration 110 / 171 | Total Loss: 2.3937110900878906 | KNN Loss: 2.388324499130249 | CLS Loss: 0.005386548116803169\n",
      "Epoch 115 / 200 | iteration 120 / 171 | Total Loss: 2.395897150039673 | KNN Loss: 2.393376588821411 | CLS Loss: 0.002520609414204955\n",
      "Epoch 115 / 200 | iteration 130 / 171 | Total Loss: 2.4083962440490723 | KNN Loss: 2.406420946121216 | CLS Loss: 0.0019752176012843847\n",
      "Epoch 115 / 200 | iteration 140 / 171 | Total Loss: 2.457641839981079 | KNN Loss: 2.4285683631896973 | CLS Loss: 0.029073454439640045\n",
      "Epoch 115 / 200 | iteration 150 / 171 | Total Loss: 2.37774920463562 | KNN Loss: 2.3629329204559326 | CLS Loss: 0.014816250652074814\n",
      "Epoch 115 / 200 | iteration 160 / 171 | Total Loss: 2.4113962650299072 | KNN Loss: 2.4037675857543945 | CLS Loss: 0.007628627587109804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 / 200 | iteration 170 / 171 | Total Loss: 2.423062801361084 | KNN Loss: 2.4049456119537354 | CLS Loss: 0.018117304891347885\n",
      "Epoch: 115, Loss: 2.4119, Train: 0.9962, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 116 / 200 | iteration 0 / 171 | Total Loss: 2.4032175540924072 | KNN Loss: 2.3933804035186768 | CLS Loss: 0.009837208315730095\n",
      "Epoch 116 / 200 | iteration 10 / 171 | Total Loss: 2.440272092819214 | KNN Loss: 2.409156084060669 | CLS Loss: 0.031116044148802757\n",
      "Epoch 116 / 200 | iteration 20 / 171 | Total Loss: 2.3997416496276855 | KNN Loss: 2.395519495010376 | CLS Loss: 0.0042221397161483765\n",
      "Epoch 116 / 200 | iteration 30 / 171 | Total Loss: 2.438030242919922 | KNN Loss: 2.4234163761138916 | CLS Loss: 0.014613796956837177\n",
      "Epoch 116 / 200 | iteration 40 / 171 | Total Loss: 2.362839460372925 | KNN Loss: 2.359600305557251 | CLS Loss: 0.0032391392160207033\n",
      "Epoch 116 / 200 | iteration 50 / 171 | Total Loss: 2.4195475578308105 | KNN Loss: 2.409435510635376 | CLS Loss: 0.010111944749951363\n",
      "Epoch 116 / 200 | iteration 60 / 171 | Total Loss: 2.460292100906372 | KNN Loss: 2.4474124908447266 | CLS Loss: 0.012879528105258942\n",
      "Epoch 116 / 200 | iteration 70 / 171 | Total Loss: 2.3888070583343506 | KNN Loss: 2.3808858394622803 | CLS Loss: 0.00792129710316658\n",
      "Epoch 116 / 200 | iteration 80 / 171 | Total Loss: 2.3983235359191895 | KNN Loss: 2.386380910873413 | CLS Loss: 0.011942644603550434\n",
      "Epoch 116 / 200 | iteration 90 / 171 | Total Loss: 2.429424285888672 | KNN Loss: 2.416969060897827 | CLS Loss: 0.012455269694328308\n",
      "Epoch 116 / 200 | iteration 100 / 171 | Total Loss: 2.389029026031494 | KNN Loss: 2.366079092025757 | CLS Loss: 0.022949831560254097\n",
      "Epoch 116 / 200 | iteration 110 / 171 | Total Loss: 2.38981294631958 | KNN Loss: 2.369161605834961 | CLS Loss: 0.020651454105973244\n",
      "Epoch 116 / 200 | iteration 120 / 171 | Total Loss: 2.4184741973876953 | KNN Loss: 2.4106972217559814 | CLS Loss: 0.007776928599923849\n",
      "Epoch 116 / 200 | iteration 130 / 171 | Total Loss: 2.4462294578552246 | KNN Loss: 2.4295425415039062 | CLS Loss: 0.016686972230672836\n",
      "Epoch 116 / 200 | iteration 140 / 171 | Total Loss: 2.393277168273926 | KNN Loss: 2.385399341583252 | CLS Loss: 0.007877809926867485\n",
      "Epoch 116 / 200 | iteration 150 / 171 | Total Loss: 2.3894076347351074 | KNN Loss: 2.3809621334075928 | CLS Loss: 0.008445559069514275\n",
      "Epoch 116 / 200 | iteration 160 / 171 | Total Loss: 2.3829236030578613 | KNN Loss: 2.378995418548584 | CLS Loss: 0.003928158897906542\n",
      "Epoch 116 / 200 | iteration 170 / 171 | Total Loss: 2.4540023803710938 | KNN Loss: 2.4442801475524902 | CLS Loss: 0.0097222700715065\n",
      "Epoch: 116, Loss: 2.4114, Train: 0.9966, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 117 / 200 | iteration 0 / 171 | Total Loss: 2.3706159591674805 | KNN Loss: 2.360452175140381 | CLS Loss: 0.01016389299184084\n",
      "Epoch 117 / 200 | iteration 10 / 171 | Total Loss: 2.4165899753570557 | KNN Loss: 2.4090023040771484 | CLS Loss: 0.007587580010294914\n",
      "Epoch 117 / 200 | iteration 20 / 171 | Total Loss: 2.3972742557525635 | KNN Loss: 2.396124839782715 | CLS Loss: 0.0011494607897475362\n",
      "Epoch 117 / 200 | iteration 30 / 171 | Total Loss: 2.4221112728118896 | KNN Loss: 2.4134531021118164 | CLS Loss: 0.008658254519104958\n",
      "Epoch 117 / 200 | iteration 40 / 171 | Total Loss: 2.395632028579712 | KNN Loss: 2.3889033794403076 | CLS Loss: 0.0067287348210811615\n",
      "Epoch 117 / 200 | iteration 50 / 171 | Total Loss: 2.4404897689819336 | KNN Loss: 2.4146511554718018 | CLS Loss: 0.02583853155374527\n",
      "Epoch 117 / 200 | iteration 60 / 171 | Total Loss: 2.4649784564971924 | KNN Loss: 2.4487998485565186 | CLS Loss: 0.016178613528609276\n",
      "Epoch 117 / 200 | iteration 70 / 171 | Total Loss: 2.415614604949951 | KNN Loss: 2.3975813388824463 | CLS Loss: 0.018033185973763466\n",
      "Epoch 117 / 200 | iteration 80 / 171 | Total Loss: 2.4088568687438965 | KNN Loss: 2.3958845138549805 | CLS Loss: 0.012972339987754822\n",
      "Epoch 117 / 200 | iteration 90 / 171 | Total Loss: 2.4155843257904053 | KNN Loss: 2.4133946895599365 | CLS Loss: 0.0021896176040172577\n",
      "Epoch 117 / 200 | iteration 100 / 171 | Total Loss: 2.388012409210205 | KNN Loss: 2.378444194793701 | CLS Loss: 0.009568311274051666\n",
      "Epoch 117 / 200 | iteration 110 / 171 | Total Loss: 2.387573480606079 | KNN Loss: 2.369499444961548 | CLS Loss: 0.018074113875627518\n",
      "Epoch 117 / 200 | iteration 120 / 171 | Total Loss: 2.425920248031616 | KNN Loss: 2.406688928604126 | CLS Loss: 0.01923137530684471\n",
      "Epoch 117 / 200 | iteration 130 / 171 | Total Loss: 2.4366257190704346 | KNN Loss: 2.411336660385132 | CLS Loss: 0.025289148092269897\n",
      "Epoch 117 / 200 | iteration 140 / 171 | Total Loss: 2.441164255142212 | KNN Loss: 2.4314820766448975 | CLS Loss: 0.009682266972959042\n",
      "Epoch 117 / 200 | iteration 150 / 171 | Total Loss: 2.4278156757354736 | KNN Loss: 2.4040238857269287 | CLS Loss: 0.023791786283254623\n",
      "Epoch 117 / 200 | iteration 160 / 171 | Total Loss: 2.384469509124756 | KNN Loss: 2.3720524311065674 | CLS Loss: 0.012417024001479149\n",
      "Epoch 117 / 200 | iteration 170 / 171 | Total Loss: 2.463135004043579 | KNN Loss: 2.3957135677337646 | CLS Loss: 0.06742137670516968\n",
      "Epoch: 117, Loss: 2.4149, Train: 0.9960, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 118 / 200 | iteration 0 / 171 | Total Loss: 2.4049811363220215 | KNN Loss: 2.3939340114593506 | CLS Loss: 0.01104715559631586\n",
      "Epoch 118 / 200 | iteration 10 / 171 | Total Loss: 2.4034035205841064 | KNN Loss: 2.39078426361084 | CLS Loss: 0.012619231827557087\n",
      "Epoch 118 / 200 | iteration 20 / 171 | Total Loss: 2.4444844722747803 | KNN Loss: 2.4164633750915527 | CLS Loss: 0.028021102771162987\n",
      "Epoch 118 / 200 | iteration 30 / 171 | Total Loss: 2.4283695220947266 | KNN Loss: 2.4169905185699463 | CLS Loss: 0.011378911323845387\n",
      "Epoch 118 / 200 | iteration 40 / 171 | Total Loss: 2.4048268795013428 | KNN Loss: 2.3947629928588867 | CLS Loss: 0.010063880123198032\n",
      "Epoch 118 / 200 | iteration 50 / 171 | Total Loss: 2.407942533493042 | KNN Loss: 2.402963876724243 | CLS Loss: 0.004978688899427652\n",
      "Epoch 118 / 200 | iteration 60 / 171 | Total Loss: 2.4501988887786865 | KNN Loss: 2.4192750453948975 | CLS Loss: 0.030923940241336823\n",
      "Epoch 118 / 200 | iteration 70 / 171 | Total Loss: 2.394005537033081 | KNN Loss: 2.3750598430633545 | CLS Loss: 0.018945643678307533\n",
      "Epoch 118 / 200 | iteration 80 / 171 | Total Loss: 2.410869598388672 | KNN Loss: 2.4096243381500244 | CLS Loss: 0.0012452247319743037\n",
      "Epoch 118 / 200 | iteration 90 / 171 | Total Loss: 2.4132165908813477 | KNN Loss: 2.404093027114868 | CLS Loss: 0.009123669937252998\n",
      "Epoch 118 / 200 | iteration 100 / 171 | Total Loss: 2.4174282550811768 | KNN Loss: 2.3877902030944824 | CLS Loss: 0.029638106003403664\n",
      "Epoch 118 / 200 | iteration 110 / 171 | Total Loss: 2.4228508472442627 | KNN Loss: 2.398167610168457 | CLS Loss: 0.024683158844709396\n",
      "Epoch 118 / 200 | iteration 120 / 171 | Total Loss: 2.3965094089508057 | KNN Loss: 2.3775265216827393 | CLS Loss: 0.01898282766342163\n",
      "Epoch 118 / 200 | iteration 130 / 171 | Total Loss: 2.4363062381744385 | KNN Loss: 2.4130914211273193 | CLS Loss: 0.023214805871248245\n",
      "Epoch 118 / 200 | iteration 140 / 171 | Total Loss: 2.433810234069824 | KNN Loss: 2.411100387573242 | CLS Loss: 0.022709950804710388\n",
      "Epoch 118 / 200 | iteration 150 / 171 | Total Loss: 2.424358367919922 | KNN Loss: 2.412795305252075 | CLS Loss: 0.011563140898942947\n",
      "Epoch 118 / 200 | iteration 160 / 171 | Total Loss: 2.4346232414245605 | KNN Loss: 2.42510724067688 | CLS Loss: 0.009516089223325253\n",
      "Epoch 118 / 200 | iteration 170 / 171 | Total Loss: 2.454326629638672 | KNN Loss: 2.450643539428711 | CLS Loss: 0.0036831211764365435\n",
      "Epoch: 118, Loss: 2.4165, Train: 0.9966, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 119 / 200 | iteration 0 / 171 | Total Loss: 2.3791537284851074 | KNN Loss: 2.373833417892456 | CLS Loss: 0.005320220720022917\n",
      "Epoch 119 / 200 | iteration 10 / 171 | Total Loss: 2.435497283935547 | KNN Loss: 2.4009478092193604 | CLS Loss: 0.03454951196908951\n",
      "Epoch 119 / 200 | iteration 20 / 171 | Total Loss: 2.4154536724090576 | KNN Loss: 2.4017834663391113 | CLS Loss: 0.013670266605913639\n",
      "Epoch 119 / 200 | iteration 30 / 171 | Total Loss: 2.42724347114563 | KNN Loss: 2.417349100112915 | CLS Loss: 0.009894484654068947\n",
      "Epoch 119 / 200 | iteration 40 / 171 | Total Loss: 2.3991377353668213 | KNN Loss: 2.384334087371826 | CLS Loss: 0.01480366662144661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 / 200 | iteration 50 / 171 | Total Loss: 2.384678602218628 | KNN Loss: 2.3718409538269043 | CLS Loss: 0.012837736867368221\n",
      "Epoch 119 / 200 | iteration 60 / 171 | Total Loss: 2.421987295150757 | KNN Loss: 2.4131510257720947 | CLS Loss: 0.008836383931338787\n",
      "Epoch 119 / 200 | iteration 70 / 171 | Total Loss: 2.380098581314087 | KNN Loss: 2.378784418106079 | CLS Loss: 0.0013142063980922103\n",
      "Epoch 119 / 200 | iteration 80 / 171 | Total Loss: 2.4195339679718018 | KNN Loss: 2.39725661277771 | CLS Loss: 0.02227729558944702\n",
      "Epoch 119 / 200 | iteration 90 / 171 | Total Loss: 2.4090404510498047 | KNN Loss: 2.4065518379211426 | CLS Loss: 0.0024885262828320265\n",
      "Epoch 119 / 200 | iteration 100 / 171 | Total Loss: 2.411806344985962 | KNN Loss: 2.4074387550354004 | CLS Loss: 0.004367700777947903\n",
      "Epoch 119 / 200 | iteration 110 / 171 | Total Loss: 2.4145240783691406 | KNN Loss: 2.407722234725952 | CLS Loss: 0.006801781244575977\n",
      "Epoch 119 / 200 | iteration 120 / 171 | Total Loss: 2.3874950408935547 | KNN Loss: 2.3865435123443604 | CLS Loss: 0.0009515775600448251\n",
      "Epoch 119 / 200 | iteration 130 / 171 | Total Loss: 2.4040980339050293 | KNN Loss: 2.395490884780884 | CLS Loss: 0.008607137016952038\n",
      "Epoch 119 / 200 | iteration 140 / 171 | Total Loss: 2.406280040740967 | KNN Loss: 2.405066728591919 | CLS Loss: 0.0012133527779951692\n",
      "Epoch 119 / 200 | iteration 150 / 171 | Total Loss: 2.445068836212158 | KNN Loss: 2.43882417678833 | CLS Loss: 0.006244648713618517\n",
      "Epoch 119 / 200 | iteration 160 / 171 | Total Loss: 2.4323699474334717 | KNN Loss: 2.420058250427246 | CLS Loss: 0.01231161318719387\n",
      "Epoch 119 / 200 | iteration 170 / 171 | Total Loss: 2.4119162559509277 | KNN Loss: 2.394774913787842 | CLS Loss: 0.017141425982117653\n",
      "Epoch: 119, Loss: 2.4109, Train: 0.9952, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 120 / 200 | iteration 0 / 171 | Total Loss: 2.382521390914917 | KNN Loss: 2.379479169845581 | CLS Loss: 0.0030421949923038483\n",
      "Epoch 120 / 200 | iteration 10 / 171 | Total Loss: 2.441189765930176 | KNN Loss: 2.4209160804748535 | CLS Loss: 0.0202737245708704\n",
      "Epoch 120 / 200 | iteration 20 / 171 | Total Loss: 2.409971237182617 | KNN Loss: 2.3921775817871094 | CLS Loss: 0.017793726176023483\n",
      "Epoch 120 / 200 | iteration 30 / 171 | Total Loss: 2.4051589965820312 | KNN Loss: 2.39334774017334 | CLS Loss: 0.011811146512627602\n",
      "Epoch 120 / 200 | iteration 40 / 171 | Total Loss: 2.4419596195220947 | KNN Loss: 2.42232608795166 | CLS Loss: 0.019633492454886436\n",
      "Epoch 120 / 200 | iteration 50 / 171 | Total Loss: 2.4086434841156006 | KNN Loss: 2.3921704292297363 | CLS Loss: 0.016473164781928062\n",
      "Epoch 120 / 200 | iteration 60 / 171 | Total Loss: 2.4268391132354736 | KNN Loss: 2.412269115447998 | CLS Loss: 0.014569946564733982\n",
      "Epoch 120 / 200 | iteration 70 / 171 | Total Loss: 2.4007956981658936 | KNN Loss: 2.3908207416534424 | CLS Loss: 0.00997488759458065\n",
      "Epoch 120 / 200 | iteration 80 / 171 | Total Loss: 2.4439475536346436 | KNN Loss: 2.432542562484741 | CLS Loss: 0.011404960416257381\n",
      "Epoch 120 / 200 | iteration 90 / 171 | Total Loss: 2.3843319416046143 | KNN Loss: 2.3742563724517822 | CLS Loss: 0.0100755849853158\n",
      "Epoch 120 / 200 | iteration 100 / 171 | Total Loss: 2.4248151779174805 | KNN Loss: 2.3975346088409424 | CLS Loss: 0.027280651032924652\n",
      "Epoch 120 / 200 | iteration 110 / 171 | Total Loss: 2.44687819480896 | KNN Loss: 2.4109673500061035 | CLS Loss: 0.03591092303395271\n",
      "Epoch 120 / 200 | iteration 120 / 171 | Total Loss: 2.3950018882751465 | KNN Loss: 2.3907575607299805 | CLS Loss: 0.004244247917085886\n",
      "Epoch 120 / 200 | iteration 130 / 171 | Total Loss: 2.3818204402923584 | KNN Loss: 2.375448703765869 | CLS Loss: 0.006371776573359966\n",
      "Epoch 120 / 200 | iteration 140 / 171 | Total Loss: 2.39823055267334 | KNN Loss: 2.3401670455932617 | CLS Loss: 0.05806347355246544\n",
      "Epoch 120 / 200 | iteration 150 / 171 | Total Loss: 2.4548723697662354 | KNN Loss: 2.433577299118042 | CLS Loss: 0.021294957026839256\n",
      "Epoch 120 / 200 | iteration 160 / 171 | Total Loss: 2.4543752670288086 | KNN Loss: 2.406188488006592 | CLS Loss: 0.04818679392337799\n",
      "Epoch 120 / 200 | iteration 170 / 171 | Total Loss: 2.414173126220703 | KNN Loss: 2.389460563659668 | CLS Loss: 0.024712657555937767\n",
      "Epoch: 120, Loss: 2.4134, Train: 0.9955, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 121 / 200 | iteration 0 / 171 | Total Loss: 2.482105255126953 | KNN Loss: 2.4369280338287354 | CLS Loss: 0.04517730325460434\n",
      "Epoch 121 / 200 | iteration 10 / 171 | Total Loss: 2.4085378646850586 | KNN Loss: 2.3874802589416504 | CLS Loss: 0.021057628095149994\n",
      "Epoch 121 / 200 | iteration 20 / 171 | Total Loss: 2.429901123046875 | KNN Loss: 2.424351692199707 | CLS Loss: 0.005549378227442503\n",
      "Epoch 121 / 200 | iteration 30 / 171 | Total Loss: 2.454270362854004 | KNN Loss: 2.445739507675171 | CLS Loss: 0.008530826307833195\n",
      "Epoch 121 / 200 | iteration 40 / 171 | Total Loss: 2.3967926502227783 | KNN Loss: 2.3865513801574707 | CLS Loss: 0.010241379961371422\n",
      "Epoch 121 / 200 | iteration 50 / 171 | Total Loss: 2.401231050491333 | KNN Loss: 2.3854827880859375 | CLS Loss: 0.015748221427202225\n",
      "Epoch 121 / 200 | iteration 60 / 171 | Total Loss: 2.4451565742492676 | KNN Loss: 2.436951160430908 | CLS Loss: 0.008205363526940346\n",
      "Epoch 121 / 200 | iteration 70 / 171 | Total Loss: 2.3949968814849854 | KNN Loss: 2.3929717540740967 | CLS Loss: 0.002025078283622861\n",
      "Epoch 121 / 200 | iteration 80 / 171 | Total Loss: 2.447730302810669 | KNN Loss: 2.4315788745880127 | CLS Loss: 0.016151398420333862\n",
      "Epoch 121 / 200 | iteration 90 / 171 | Total Loss: 2.4250571727752686 | KNN Loss: 2.4040637016296387 | CLS Loss: 0.020993459969758987\n",
      "Epoch 121 / 200 | iteration 100 / 171 | Total Loss: 2.401738166809082 | KNN Loss: 2.3834404945373535 | CLS Loss: 0.018297597765922546\n",
      "Epoch 121 / 200 | iteration 110 / 171 | Total Loss: 2.423776626586914 | KNN Loss: 2.406129837036133 | CLS Loss: 0.017646724358201027\n",
      "Epoch 121 / 200 | iteration 120 / 171 | Total Loss: 2.431302547454834 | KNN Loss: 2.415933609008789 | CLS Loss: 0.015368837863206863\n",
      "Epoch 121 / 200 | iteration 130 / 171 | Total Loss: 2.3759312629699707 | KNN Loss: 2.370814800262451 | CLS Loss: 0.005116470158100128\n",
      "Epoch 121 / 200 | iteration 140 / 171 | Total Loss: 2.4095845222473145 | KNN Loss: 2.3801732063293457 | CLS Loss: 0.029411369934678078\n",
      "Epoch 121 / 200 | iteration 150 / 171 | Total Loss: 2.4379160404205322 | KNN Loss: 2.411135196685791 | CLS Loss: 0.02678084187209606\n",
      "Epoch 121 / 200 | iteration 160 / 171 | Total Loss: 2.4471096992492676 | KNN Loss: 2.423746109008789 | CLS Loss: 0.023363661020994186\n",
      "Epoch 121 / 200 | iteration 170 / 171 | Total Loss: 2.453340530395508 | KNN Loss: 2.4349722862243652 | CLS Loss: 0.01836828514933586\n",
      "Epoch: 121, Loss: 2.4121, Train: 0.9960, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 122 / 200 | iteration 0 / 171 | Total Loss: 2.4317939281463623 | KNN Loss: 2.4234530925750732 | CLS Loss: 0.008340930566191673\n",
      "Epoch 122 / 200 | iteration 10 / 171 | Total Loss: 2.4647562503814697 | KNN Loss: 2.4470913410186768 | CLS Loss: 0.0176648311316967\n",
      "Epoch 122 / 200 | iteration 20 / 171 | Total Loss: 2.4235544204711914 | KNN Loss: 2.410729169845581 | CLS Loss: 0.012825212441384792\n",
      "Epoch 122 / 200 | iteration 30 / 171 | Total Loss: 2.415428638458252 | KNN Loss: 2.4089133739471436 | CLS Loss: 0.006515153683722019\n",
      "Epoch 122 / 200 | iteration 40 / 171 | Total Loss: 2.4331538677215576 | KNN Loss: 2.4299464225769043 | CLS Loss: 0.003207483794540167\n",
      "Epoch 122 / 200 | iteration 50 / 171 | Total Loss: 2.41017746925354 | KNN Loss: 2.4038171768188477 | CLS Loss: 0.006360199768096209\n",
      "Epoch 122 / 200 | iteration 60 / 171 | Total Loss: 2.407902956008911 | KNN Loss: 2.405614137649536 | CLS Loss: 0.002288764575496316\n",
      "Epoch 122 / 200 | iteration 70 / 171 | Total Loss: 2.468646287918091 | KNN Loss: 2.453277587890625 | CLS Loss: 0.015368773601949215\n",
      "Epoch 122 / 200 | iteration 80 / 171 | Total Loss: 2.424156427383423 | KNN Loss: 2.4123024940490723 | CLS Loss: 0.011854027397930622\n",
      "Epoch 122 / 200 | iteration 90 / 171 | Total Loss: 2.410568952560425 | KNN Loss: 2.391054153442383 | CLS Loss: 0.01951468549668789\n",
      "Epoch 122 / 200 | iteration 100 / 171 | Total Loss: 2.3863658905029297 | KNN Loss: 2.383960247039795 | CLS Loss: 0.0024055331014096737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 / 200 | iteration 110 / 171 | Total Loss: 2.4538934230804443 | KNN Loss: 2.4384639263153076 | CLS Loss: 0.015429539605975151\n",
      "Epoch 122 / 200 | iteration 120 / 171 | Total Loss: 2.4427754878997803 | KNN Loss: 2.4245285987854004 | CLS Loss: 0.01824679970741272\n",
      "Epoch 122 / 200 | iteration 130 / 171 | Total Loss: 2.392854690551758 | KNN Loss: 2.3757922649383545 | CLS Loss: 0.01706242561340332\n",
      "Epoch 122 / 200 | iteration 140 / 171 | Total Loss: 2.4179563522338867 | KNN Loss: 2.4107754230499268 | CLS Loss: 0.007181039545685053\n",
      "Epoch 122 / 200 | iteration 150 / 171 | Total Loss: 2.4148714542388916 | KNN Loss: 2.3898143768310547 | CLS Loss: 0.02505703642964363\n",
      "Epoch 122 / 200 | iteration 160 / 171 | Total Loss: 2.4245173931121826 | KNN Loss: 2.4049861431121826 | CLS Loss: 0.01953134499490261\n",
      "Epoch 122 / 200 | iteration 170 / 171 | Total Loss: 2.4076144695281982 | KNN Loss: 2.3962197303771973 | CLS Loss: 0.011394725181162357\n",
      "Epoch: 122, Loss: 2.4161, Train: 0.9962, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 123 / 200 | iteration 0 / 171 | Total Loss: 2.4102020263671875 | KNN Loss: 2.4000163078308105 | CLS Loss: 0.01018578466027975\n",
      "Epoch 123 / 200 | iteration 10 / 171 | Total Loss: 2.406770706176758 | KNN Loss: 2.389760971069336 | CLS Loss: 0.017009658738970757\n",
      "Epoch 123 / 200 | iteration 20 / 171 | Total Loss: 2.443251132965088 | KNN Loss: 2.4256937503814697 | CLS Loss: 0.017557349056005478\n",
      "Epoch 123 / 200 | iteration 30 / 171 | Total Loss: 2.404127836227417 | KNN Loss: 2.3824946880340576 | CLS Loss: 0.02163318358361721\n",
      "Epoch 123 / 200 | iteration 40 / 171 | Total Loss: 2.422772169113159 | KNN Loss: 2.404059410095215 | CLS Loss: 0.018712718039751053\n",
      "Epoch 123 / 200 | iteration 50 / 171 | Total Loss: 2.44874906539917 | KNN Loss: 2.429932117462158 | CLS Loss: 0.018816912546753883\n",
      "Epoch 123 / 200 | iteration 60 / 171 | Total Loss: 2.390796661376953 | KNN Loss: 2.3733158111572266 | CLS Loss: 0.0174808781594038\n",
      "Epoch 123 / 200 | iteration 70 / 171 | Total Loss: 2.396738052368164 | KNN Loss: 2.382634162902832 | CLS Loss: 0.014103857800364494\n",
      "Epoch 123 / 200 | iteration 80 / 171 | Total Loss: 2.4404468536376953 | KNN Loss: 2.4184019565582275 | CLS Loss: 0.02204478718340397\n",
      "Epoch 123 / 200 | iteration 90 / 171 | Total Loss: 2.4175429344177246 | KNN Loss: 2.409857988357544 | CLS Loss: 0.007684831973165274\n",
      "Epoch 123 / 200 | iteration 100 / 171 | Total Loss: 2.3909177780151367 | KNN Loss: 2.3840725421905518 | CLS Loss: 0.00684519624337554\n",
      "Epoch 123 / 200 | iteration 110 / 171 | Total Loss: 2.3928568363189697 | KNN Loss: 2.383415460586548 | CLS Loss: 0.009441443718969822\n",
      "Epoch 123 / 200 | iteration 120 / 171 | Total Loss: 2.387631893157959 | KNN Loss: 2.375584363937378 | CLS Loss: 0.012047570198774338\n",
      "Epoch 123 / 200 | iteration 130 / 171 | Total Loss: 2.4211864471435547 | KNN Loss: 2.4061625003814697 | CLS Loss: 0.015024061314761639\n",
      "Epoch 123 / 200 | iteration 140 / 171 | Total Loss: 2.390864849090576 | KNN Loss: 2.366180658340454 | CLS Loss: 0.024684131145477295\n",
      "Epoch 123 / 200 | iteration 150 / 171 | Total Loss: 2.375481367111206 | KNN Loss: 2.3624227046966553 | CLS Loss: 0.013058770447969437\n",
      "Epoch 123 / 200 | iteration 160 / 171 | Total Loss: 2.387450695037842 | KNN Loss: 2.379176616668701 | CLS Loss: 0.008274184539914131\n",
      "Epoch 123 / 200 | iteration 170 / 171 | Total Loss: 2.3949239253997803 | KNN Loss: 2.3753302097320557 | CLS Loss: 0.01959363743662834\n",
      "Epoch: 123, Loss: 2.4122, Train: 0.9962, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 124 / 200 | iteration 0 / 171 | Total Loss: 2.414649724960327 | KNN Loss: 2.3950676918029785 | CLS Loss: 0.019582120701670647\n",
      "Epoch 124 / 200 | iteration 10 / 171 | Total Loss: 2.4331836700439453 | KNN Loss: 2.424513101577759 | CLS Loss: 0.008670618757605553\n",
      "Epoch 124 / 200 | iteration 20 / 171 | Total Loss: 2.40155029296875 | KNN Loss: 2.3923535346984863 | CLS Loss: 0.009196705184876919\n",
      "Epoch 124 / 200 | iteration 30 / 171 | Total Loss: 2.3909249305725098 | KNN Loss: 2.382404327392578 | CLS Loss: 0.008520680479705334\n",
      "Epoch 124 / 200 | iteration 40 / 171 | Total Loss: 2.4169201850891113 | KNN Loss: 2.3995420932769775 | CLS Loss: 0.017378171905875206\n",
      "Epoch 124 / 200 | iteration 50 / 171 | Total Loss: 2.4094419479370117 | KNN Loss: 2.4009320735931396 | CLS Loss: 0.0085098035633564\n",
      "Epoch 124 / 200 | iteration 60 / 171 | Total Loss: 2.405653715133667 | KNN Loss: 2.387932062149048 | CLS Loss: 0.017721597105264664\n",
      "Epoch 124 / 200 | iteration 70 / 171 | Total Loss: 2.392709732055664 | KNN Loss: 2.3876256942749023 | CLS Loss: 0.005084042437374592\n",
      "Epoch 124 / 200 | iteration 80 / 171 | Total Loss: 2.4211018085479736 | KNN Loss: 2.4108474254608154 | CLS Loss: 0.010254353284835815\n",
      "Epoch 124 / 200 | iteration 90 / 171 | Total Loss: 2.3901009559631348 | KNN Loss: 2.3783276081085205 | CLS Loss: 0.011773306876420975\n",
      "Epoch 124 / 200 | iteration 100 / 171 | Total Loss: 2.401823043823242 | KNN Loss: 2.396303415298462 | CLS Loss: 0.005519622005522251\n",
      "Epoch 124 / 200 | iteration 110 / 171 | Total Loss: 2.371746301651001 | KNN Loss: 2.3592824935913086 | CLS Loss: 0.012463835068047047\n",
      "Epoch 124 / 200 | iteration 120 / 171 | Total Loss: 2.4264886379241943 | KNN Loss: 2.404656410217285 | CLS Loss: 0.02183222770690918\n",
      "Epoch 124 / 200 | iteration 130 / 171 | Total Loss: 2.3761982917785645 | KNN Loss: 2.370396137237549 | CLS Loss: 0.0058022490702569485\n",
      "Epoch 124 / 200 | iteration 140 / 171 | Total Loss: 2.386617422103882 | KNN Loss: 2.38358211517334 | CLS Loss: 0.003035274799913168\n",
      "Epoch 124 / 200 | iteration 150 / 171 | Total Loss: 2.3946430683135986 | KNN Loss: 2.3850231170654297 | CLS Loss: 0.009620052762329578\n",
      "Epoch 124 / 200 | iteration 160 / 171 | Total Loss: 2.429431915283203 | KNN Loss: 2.4080851078033447 | CLS Loss: 0.021346908062696457\n",
      "Epoch 124 / 200 | iteration 170 / 171 | Total Loss: 2.4051835536956787 | KNN Loss: 2.402162551879883 | CLS Loss: 0.0030210320837795734\n",
      "Epoch: 124, Loss: 2.4104, Train: 0.9971, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 125 / 200 | iteration 0 / 171 | Total Loss: 2.384805202484131 | KNN Loss: 2.3828625679016113 | CLS Loss: 0.0019425477366894484\n",
      "Epoch 125 / 200 | iteration 10 / 171 | Total Loss: 2.375582695007324 | KNN Loss: 2.3735556602478027 | CLS Loss: 0.0020269574597477913\n",
      "Epoch 125 / 200 | iteration 20 / 171 | Total Loss: 2.399038314819336 | KNN Loss: 2.3903355598449707 | CLS Loss: 0.008702791295945644\n",
      "Epoch 125 / 200 | iteration 30 / 171 | Total Loss: 2.427314043045044 | KNN Loss: 2.4251420497894287 | CLS Loss: 0.0021720079239457846\n",
      "Epoch 125 / 200 | iteration 40 / 171 | Total Loss: 2.398432970046997 | KNN Loss: 2.3858706951141357 | CLS Loss: 0.012562164105474949\n",
      "Epoch 125 / 200 | iteration 50 / 171 | Total Loss: 2.434600353240967 | KNN Loss: 2.400925636291504 | CLS Loss: 0.03367463871836662\n",
      "Epoch 125 / 200 | iteration 60 / 171 | Total Loss: 2.391550302505493 | KNN Loss: 2.382343053817749 | CLS Loss: 0.0092072868719697\n",
      "Epoch 125 / 200 | iteration 70 / 171 | Total Loss: 2.47586727142334 | KNN Loss: 2.465595006942749 | CLS Loss: 0.010272156447172165\n",
      "Epoch 125 / 200 | iteration 80 / 171 | Total Loss: 2.415008068084717 | KNN Loss: 2.4035935401916504 | CLS Loss: 0.011414505541324615\n",
      "Epoch 125 / 200 | iteration 90 / 171 | Total Loss: 2.438175678253174 | KNN Loss: 2.4272356033325195 | CLS Loss: 0.010940187610685825\n",
      "Epoch 125 / 200 | iteration 100 / 171 | Total Loss: 2.431793451309204 | KNN Loss: 2.4276771545410156 | CLS Loss: 0.004116343799978495\n",
      "Epoch 125 / 200 | iteration 110 / 171 | Total Loss: 2.3878488540649414 | KNN Loss: 2.3857738971710205 | CLS Loss: 0.002074858173727989\n",
      "Epoch 125 / 200 | iteration 120 / 171 | Total Loss: 2.4344935417175293 | KNN Loss: 2.4191136360168457 | CLS Loss: 0.015380017459392548\n",
      "Epoch 125 / 200 | iteration 130 / 171 | Total Loss: 2.398128032684326 | KNN Loss: 2.3900718688964844 | CLS Loss: 0.008056281134486198\n",
      "Epoch 125 / 200 | iteration 140 / 171 | Total Loss: 2.4110970497131348 | KNN Loss: 2.400561571121216 | CLS Loss: 0.010535409674048424\n",
      "Epoch 125 / 200 | iteration 150 / 171 | Total Loss: 2.4400432109832764 | KNN Loss: 2.435777187347412 | CLS Loss: 0.004265913739800453\n",
      "Epoch 125 / 200 | iteration 160 / 171 | Total Loss: 2.3980135917663574 | KNN Loss: 2.3944759368896484 | CLS Loss: 0.0035375719889998436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 / 200 | iteration 170 / 171 | Total Loss: 2.3640105724334717 | KNN Loss: 2.349822998046875 | CLS Loss: 0.014187674038112164\n",
      "Epoch: 125, Loss: 2.4091, Train: 0.9969, Valid: 0.9870, Best: 0.9873\n",
      "Epoch 126 / 200 | iteration 0 / 171 | Total Loss: 2.3790769577026367 | KNN Loss: 2.3695647716522217 | CLS Loss: 0.009512077085673809\n",
      "Epoch 126 / 200 | iteration 10 / 171 | Total Loss: 2.4047458171844482 | KNN Loss: 2.400683641433716 | CLS Loss: 0.004062094260007143\n",
      "Epoch 126 / 200 | iteration 20 / 171 | Total Loss: 2.3958306312561035 | KNN Loss: 2.38499116897583 | CLS Loss: 0.010839428752660751\n",
      "Epoch 126 / 200 | iteration 30 / 171 | Total Loss: 2.389822244644165 | KNN Loss: 2.381594657897949 | CLS Loss: 0.008227543905377388\n",
      "Epoch 126 / 200 | iteration 40 / 171 | Total Loss: 2.4305593967437744 | KNN Loss: 2.4210057258605957 | CLS Loss: 0.009553560987114906\n",
      "Epoch 126 / 200 | iteration 50 / 171 | Total Loss: 2.431279420852661 | KNN Loss: 2.4188268184661865 | CLS Loss: 0.012452551163733006\n",
      "Epoch 126 / 200 | iteration 60 / 171 | Total Loss: 2.3695337772369385 | KNN Loss: 2.36185622215271 | CLS Loss: 0.007677593734115362\n",
      "Epoch 126 / 200 | iteration 70 / 171 | Total Loss: 2.4472005367279053 | KNN Loss: 2.4269094467163086 | CLS Loss: 0.020291127264499664\n",
      "Epoch 126 / 200 | iteration 80 / 171 | Total Loss: 2.430650472640991 | KNN Loss: 2.4231441020965576 | CLS Loss: 0.00750627089291811\n",
      "Epoch 126 / 200 | iteration 90 / 171 | Total Loss: 2.440805435180664 | KNN Loss: 2.4359686374664307 | CLS Loss: 0.0048367539420723915\n",
      "Epoch 126 / 200 | iteration 100 / 171 | Total Loss: 2.39862060546875 | KNN Loss: 2.3877382278442383 | CLS Loss: 0.010882481001317501\n",
      "Epoch 126 / 200 | iteration 110 / 171 | Total Loss: 2.4075722694396973 | KNN Loss: 2.3995361328125 | CLS Loss: 0.008036202751100063\n",
      "Epoch 126 / 200 | iteration 120 / 171 | Total Loss: 2.4262535572052 | KNN Loss: 2.412869691848755 | CLS Loss: 0.013383752666413784\n",
      "Epoch 126 / 200 | iteration 130 / 171 | Total Loss: 2.4450788497924805 | KNN Loss: 2.4273462295532227 | CLS Loss: 0.017732592299580574\n",
      "Epoch 126 / 200 | iteration 140 / 171 | Total Loss: 2.409022331237793 | KNN Loss: 2.4039416313171387 | CLS Loss: 0.00508074602112174\n",
      "Epoch 126 / 200 | iteration 150 / 171 | Total Loss: 2.3978023529052734 | KNN Loss: 2.396280288696289 | CLS Loss: 0.0015220489585772157\n",
      "Epoch 126 / 200 | iteration 160 / 171 | Total Loss: 2.4334888458251953 | KNN Loss: 2.4229214191436768 | CLS Loss: 0.01056752447038889\n",
      "Epoch 126 / 200 | iteration 170 / 171 | Total Loss: 2.4045708179473877 | KNN Loss: 2.3937244415283203 | CLS Loss: 0.010846377350389957\n",
      "Epoch: 126, Loss: 2.4115, Train: 0.9969, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 127 / 200 | iteration 0 / 171 | Total Loss: 2.3779499530792236 | KNN Loss: 2.368732452392578 | CLS Loss: 0.009217615239322186\n",
      "Epoch 127 / 200 | iteration 10 / 171 | Total Loss: 2.445739507675171 | KNN Loss: 2.435983180999756 | CLS Loss: 0.009756272658705711\n",
      "Epoch 127 / 200 | iteration 20 / 171 | Total Loss: 2.409114122390747 | KNN Loss: 2.398404121398926 | CLS Loss: 0.010709937661886215\n",
      "Epoch 127 / 200 | iteration 30 / 171 | Total Loss: 2.399425745010376 | KNN Loss: 2.38045334815979 | CLS Loss: 0.01897248439490795\n",
      "Epoch 127 / 200 | iteration 40 / 171 | Total Loss: 2.437253475189209 | KNN Loss: 2.4161245822906494 | CLS Loss: 0.021128976717591286\n",
      "Epoch 127 / 200 | iteration 50 / 171 | Total Loss: 2.3870065212249756 | KNN Loss: 2.3847625255584717 | CLS Loss: 0.002244094153866172\n",
      "Epoch 127 / 200 | iteration 60 / 171 | Total Loss: 2.395920991897583 | KNN Loss: 2.3892455101013184 | CLS Loss: 0.006675423122942448\n",
      "Epoch 127 / 200 | iteration 70 / 171 | Total Loss: 2.417898416519165 | KNN Loss: 2.413867473602295 | CLS Loss: 0.004031043034046888\n",
      "Epoch 127 / 200 | iteration 80 / 171 | Total Loss: 2.3918240070343018 | KNN Loss: 2.389103889465332 | CLS Loss: 0.0027200300246477127\n",
      "Epoch 127 / 200 | iteration 90 / 171 | Total Loss: 2.4348883628845215 | KNN Loss: 2.4206223487854004 | CLS Loss: 0.014266063459217548\n",
      "Epoch 127 / 200 | iteration 100 / 171 | Total Loss: 2.439164876937866 | KNN Loss: 2.4314680099487305 | CLS Loss: 0.007696959190070629\n",
      "Epoch 127 / 200 | iteration 110 / 171 | Total Loss: 2.3938300609588623 | KNN Loss: 2.388514757156372 | CLS Loss: 0.005315378773957491\n",
      "Epoch 127 / 200 | iteration 120 / 171 | Total Loss: 2.4519355297088623 | KNN Loss: 2.427865505218506 | CLS Loss: 0.024070048704743385\n",
      "Epoch 127 / 200 | iteration 130 / 171 | Total Loss: 2.38966965675354 | KNN Loss: 2.3808300495147705 | CLS Loss: 0.008839618414640427\n",
      "Epoch 127 / 200 | iteration 140 / 171 | Total Loss: 2.403878688812256 | KNN Loss: 2.3744075298309326 | CLS Loss: 0.029471145942807198\n",
      "Epoch 127 / 200 | iteration 150 / 171 | Total Loss: 2.426776885986328 | KNN Loss: 2.4126088619232178 | CLS Loss: 0.014168019406497478\n",
      "Epoch 127 / 200 | iteration 160 / 171 | Total Loss: 2.374729871749878 | KNN Loss: 2.368363618850708 | CLS Loss: 0.0063661676831543446\n",
      "Epoch 127 / 200 | iteration 170 / 171 | Total Loss: 2.4243617057800293 | KNN Loss: 2.411581516265869 | CLS Loss: 0.012780092656612396\n",
      "Epoch: 127, Loss: 2.4145, Train: 0.9951, Valid: 0.9855, Best: 0.9873\n",
      "Epoch 128 / 200 | iteration 0 / 171 | Total Loss: 2.4161245822906494 | KNN Loss: 2.401423215866089 | CLS Loss: 0.014701261185109615\n",
      "Epoch 128 / 200 | iteration 10 / 171 | Total Loss: 2.406855344772339 | KNN Loss: 2.3984978199005127 | CLS Loss: 0.008357486687600613\n",
      "Epoch 128 / 200 | iteration 20 / 171 | Total Loss: 2.442816972732544 | KNN Loss: 2.4390902519226074 | CLS Loss: 0.003726757364347577\n",
      "Epoch 128 / 200 | iteration 30 / 171 | Total Loss: 2.3864293098449707 | KNN Loss: 2.368187665939331 | CLS Loss: 0.01824156567454338\n",
      "Epoch 128 / 200 | iteration 40 / 171 | Total Loss: 2.4297800064086914 | KNN Loss: 2.4257113933563232 | CLS Loss: 0.004068505484610796\n",
      "Epoch 128 / 200 | iteration 50 / 171 | Total Loss: 2.407198429107666 | KNN Loss: 2.397665500640869 | CLS Loss: 0.009532899595797062\n",
      "Epoch 128 / 200 | iteration 60 / 171 | Total Loss: 2.3778600692749023 | KNN Loss: 2.3665077686309814 | CLS Loss: 0.01135222427546978\n",
      "Epoch 128 / 200 | iteration 70 / 171 | Total Loss: 2.382833242416382 | KNN Loss: 2.3813881874084473 | CLS Loss: 0.0014450307935476303\n",
      "Epoch 128 / 200 | iteration 80 / 171 | Total Loss: 2.4212117195129395 | KNN Loss: 2.4118216037750244 | CLS Loss: 0.00939016044139862\n",
      "Epoch 128 / 200 | iteration 90 / 171 | Total Loss: 2.398867130279541 | KNN Loss: 2.3834378719329834 | CLS Loss: 0.01542933750897646\n",
      "Epoch 128 / 200 | iteration 100 / 171 | Total Loss: 2.4004383087158203 | KNN Loss: 2.3760268688201904 | CLS Loss: 0.024411464110016823\n",
      "Epoch 128 / 200 | iteration 110 / 171 | Total Loss: 2.378955364227295 | KNN Loss: 2.3624138832092285 | CLS Loss: 0.01654140092432499\n",
      "Epoch 128 / 200 | iteration 120 / 171 | Total Loss: 2.415104866027832 | KNN Loss: 2.4119324684143066 | CLS Loss: 0.003172411350533366\n",
      "Epoch 128 / 200 | iteration 130 / 171 | Total Loss: 2.4250762462615967 | KNN Loss: 2.4223740100860596 | CLS Loss: 0.0027021351270377636\n",
      "Epoch 128 / 200 | iteration 140 / 171 | Total Loss: 2.3875949382781982 | KNN Loss: 2.377390146255493 | CLS Loss: 0.010204740799963474\n",
      "Epoch 128 / 200 | iteration 150 / 171 | Total Loss: 2.422954559326172 | KNN Loss: 2.4032254219055176 | CLS Loss: 0.01972903124988079\n",
      "Epoch 128 / 200 | iteration 160 / 171 | Total Loss: 2.442852258682251 | KNN Loss: 2.430260181427002 | CLS Loss: 0.012591995298862457\n",
      "Epoch 128 / 200 | iteration 170 / 171 | Total Loss: 2.429659128189087 | KNN Loss: 2.4240987300872803 | CLS Loss: 0.005560498218983412\n",
      "Epoch: 128, Loss: 2.4092, Train: 0.9972, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 129 / 200 | iteration 0 / 171 | Total Loss: 2.428718328475952 | KNN Loss: 2.4009289741516113 | CLS Loss: 0.027789365500211716\n",
      "Epoch 129 / 200 | iteration 10 / 171 | Total Loss: 2.415390968322754 | KNN Loss: 2.394294500350952 | CLS Loss: 0.021096492186188698\n",
      "Epoch 129 / 200 | iteration 20 / 171 | Total Loss: 2.4108517169952393 | KNN Loss: 2.3961832523345947 | CLS Loss: 0.014668412506580353\n",
      "Epoch 129 / 200 | iteration 30 / 171 | Total Loss: 2.3876404762268066 | KNN Loss: 2.384575366973877 | CLS Loss: 0.0030650831758975983\n",
      "Epoch 129 / 200 | iteration 40 / 171 | Total Loss: 2.4194529056549072 | KNN Loss: 2.4136152267456055 | CLS Loss: 0.005837728269398212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 / 200 | iteration 50 / 171 | Total Loss: 2.396239995956421 | KNN Loss: 2.3921101093292236 | CLS Loss: 0.004129784647375345\n",
      "Epoch 129 / 200 | iteration 60 / 171 | Total Loss: 2.383392572402954 | KNN Loss: 2.3664088249206543 | CLS Loss: 0.01698373444378376\n",
      "Epoch 129 / 200 | iteration 70 / 171 | Total Loss: 2.4110445976257324 | KNN Loss: 2.404224395751953 | CLS Loss: 0.006820301990956068\n",
      "Epoch 129 / 200 | iteration 80 / 171 | Total Loss: 2.4406089782714844 | KNN Loss: 2.4294238090515137 | CLS Loss: 0.01118509005755186\n",
      "Epoch 129 / 200 | iteration 90 / 171 | Total Loss: 2.3722786903381348 | KNN Loss: 2.3647451400756836 | CLS Loss: 0.007533631287515163\n",
      "Epoch 129 / 200 | iteration 100 / 171 | Total Loss: 2.4363529682159424 | KNN Loss: 2.4068217277526855 | CLS Loss: 0.029531141743063927\n",
      "Epoch 129 / 200 | iteration 110 / 171 | Total Loss: 2.4161946773529053 | KNN Loss: 2.4145376682281494 | CLS Loss: 0.0016569711733609438\n",
      "Epoch 129 / 200 | iteration 120 / 171 | Total Loss: 2.3672382831573486 | KNN Loss: 2.347283363342285 | CLS Loss: 0.019955020397901535\n",
      "Epoch 129 / 200 | iteration 130 / 171 | Total Loss: 2.3940396308898926 | KNN Loss: 2.3848791122436523 | CLS Loss: 0.009160524234175682\n",
      "Epoch 129 / 200 | iteration 140 / 171 | Total Loss: 2.387847423553467 | KNN Loss: 2.384821891784668 | CLS Loss: 0.003025493584573269\n",
      "Epoch 129 / 200 | iteration 150 / 171 | Total Loss: 2.401102066040039 | KNN Loss: 2.3894739151000977 | CLS Loss: 0.011628102511167526\n",
      "Epoch 129 / 200 | iteration 160 / 171 | Total Loss: 2.4243721961975098 | KNN Loss: 2.4168026447296143 | CLS Loss: 0.007569467183202505\n",
      "Epoch 129 / 200 | iteration 170 / 171 | Total Loss: 2.416550397872925 | KNN Loss: 2.388705015182495 | CLS Loss: 0.02784539759159088\n",
      "Epoch: 129, Loss: 2.4083, Train: 0.9970, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 130 / 200 | iteration 0 / 171 | Total Loss: 2.4018609523773193 | KNN Loss: 2.396880626678467 | CLS Loss: 0.004980320110917091\n",
      "Epoch 130 / 200 | iteration 10 / 171 | Total Loss: 2.4095261096954346 | KNN Loss: 2.4002199172973633 | CLS Loss: 0.009306075051426888\n",
      "Epoch 130 / 200 | iteration 20 / 171 | Total Loss: 2.3900675773620605 | KNN Loss: 2.3749589920043945 | CLS Loss: 0.015108518302440643\n",
      "Epoch 130 / 200 | iteration 30 / 171 | Total Loss: 2.4130337238311768 | KNN Loss: 2.3905491828918457 | CLS Loss: 0.022484472021460533\n",
      "Epoch 130 / 200 | iteration 40 / 171 | Total Loss: 2.4280717372894287 | KNN Loss: 2.4227454662323 | CLS Loss: 0.005326354876160622\n",
      "Epoch 130 / 200 | iteration 50 / 171 | Total Loss: 2.384669065475464 | KNN Loss: 2.3756251335144043 | CLS Loss: 0.0090438611805439\n",
      "Epoch 130 / 200 | iteration 60 / 171 | Total Loss: 2.4141147136688232 | KNN Loss: 2.4113197326660156 | CLS Loss: 0.002795047825202346\n",
      "Epoch 130 / 200 | iteration 70 / 171 | Total Loss: 2.397860288619995 | KNN Loss: 2.392730712890625 | CLS Loss: 0.0051294662989676\n",
      "Epoch 130 / 200 | iteration 80 / 171 | Total Loss: 2.410200834274292 | KNN Loss: 2.378655195236206 | CLS Loss: 0.031545527279376984\n",
      "Epoch 130 / 200 | iteration 90 / 171 | Total Loss: 2.4012086391448975 | KNN Loss: 2.3804404735565186 | CLS Loss: 0.02076813019812107\n",
      "Epoch 130 / 200 | iteration 100 / 171 | Total Loss: 2.4116530418395996 | KNN Loss: 2.4063827991485596 | CLS Loss: 0.005270141176879406\n",
      "Epoch 130 / 200 | iteration 110 / 171 | Total Loss: 2.3642213344573975 | KNN Loss: 2.354630470275879 | CLS Loss: 0.009590782225131989\n",
      "Epoch 130 / 200 | iteration 120 / 171 | Total Loss: 2.4212446212768555 | KNN Loss: 2.4132041931152344 | CLS Loss: 0.008040336892008781\n",
      "Epoch 130 / 200 | iteration 130 / 171 | Total Loss: 2.4163689613342285 | KNN Loss: 2.4059677124023438 | CLS Loss: 0.01040124986320734\n",
      "Epoch 130 / 200 | iteration 140 / 171 | Total Loss: 2.390082836151123 | KNN Loss: 2.3810572624206543 | CLS Loss: 0.009025481529533863\n",
      "Epoch 130 / 200 | iteration 150 / 171 | Total Loss: 2.401050567626953 | KNN Loss: 2.3647756576538086 | CLS Loss: 0.036274805665016174\n",
      "Epoch 130 / 200 | iteration 160 / 171 | Total Loss: 2.425966501235962 | KNN Loss: 2.4016575813293457 | CLS Loss: 0.024308914318680763\n",
      "Epoch 130 / 200 | iteration 170 / 171 | Total Loss: 2.408895492553711 | KNN Loss: 2.3968288898468018 | CLS Loss: 0.012066520750522614\n",
      "Epoch: 130, Loss: 2.4087, Train: 0.9972, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 131 / 200 | iteration 0 / 171 | Total Loss: 2.4395816326141357 | KNN Loss: 2.431683301925659 | CLS Loss: 0.007898414507508278\n",
      "Epoch 131 / 200 | iteration 10 / 171 | Total Loss: 2.411604404449463 | KNN Loss: 2.3714118003845215 | CLS Loss: 0.04019258916378021\n",
      "Epoch 131 / 200 | iteration 20 / 171 | Total Loss: 2.365173816680908 | KNN Loss: 2.3599510192871094 | CLS Loss: 0.005222783423960209\n",
      "Epoch 131 / 200 | iteration 30 / 171 | Total Loss: 2.396832227706909 | KNN Loss: 2.393810987472534 | CLS Loss: 0.003021231619641185\n",
      "Epoch 131 / 200 | iteration 40 / 171 | Total Loss: 2.4123809337615967 | KNN Loss: 2.397042989730835 | CLS Loss: 0.015337871387600899\n",
      "Epoch 131 / 200 | iteration 50 / 171 | Total Loss: 2.4118597507476807 | KNN Loss: 2.404428720474243 | CLS Loss: 0.007430983241647482\n",
      "Epoch 131 / 200 | iteration 60 / 171 | Total Loss: 2.4169809818267822 | KNN Loss: 2.4020657539367676 | CLS Loss: 0.01491520181298256\n",
      "Epoch 131 / 200 | iteration 70 / 171 | Total Loss: 2.446676731109619 | KNN Loss: 2.444185972213745 | CLS Loss: 0.0024907358456403017\n",
      "Epoch 131 / 200 | iteration 80 / 171 | Total Loss: 2.4023120403289795 | KNN Loss: 2.3999714851379395 | CLS Loss: 0.0023406618274748325\n",
      "Epoch 131 / 200 | iteration 90 / 171 | Total Loss: 2.442920446395874 | KNN Loss: 2.4402785301208496 | CLS Loss: 0.0026418284978717566\n",
      "Epoch 131 / 200 | iteration 100 / 171 | Total Loss: 2.415411949157715 | KNN Loss: 2.3952085971832275 | CLS Loss: 0.02020331844687462\n",
      "Epoch 131 / 200 | iteration 110 / 171 | Total Loss: 2.3908488750457764 | KNN Loss: 2.36336350440979 | CLS Loss: 0.027485260739922523\n",
      "Epoch 131 / 200 | iteration 120 / 171 | Total Loss: 2.4088757038116455 | KNN Loss: 2.4054067134857178 | CLS Loss: 0.0034688813611865044\n",
      "Epoch 131 / 200 | iteration 130 / 171 | Total Loss: 2.4231560230255127 | KNN Loss: 2.4176666736602783 | CLS Loss: 0.0054894001223146915\n",
      "Epoch 131 / 200 | iteration 140 / 171 | Total Loss: 2.4073479175567627 | KNN Loss: 2.3857481479644775 | CLS Loss: 0.02159987762570381\n",
      "Epoch 131 / 200 | iteration 150 / 171 | Total Loss: 2.390489101409912 | KNN Loss: 2.379181146621704 | CLS Loss: 0.011307908222079277\n",
      "Epoch 131 / 200 | iteration 160 / 171 | Total Loss: 2.4306087493896484 | KNN Loss: 2.4264333248138428 | CLS Loss: 0.004175432026386261\n",
      "Epoch 131 / 200 | iteration 170 / 171 | Total Loss: 2.41709566116333 | KNN Loss: 2.4062299728393555 | CLS Loss: 0.010865669697523117\n",
      "Epoch: 131, Loss: 2.4119, Train: 0.9960, Valid: 0.9853, Best: 0.9873\n",
      "Epoch 132 / 200 | iteration 0 / 171 | Total Loss: 2.4346165657043457 | KNN Loss: 2.41438889503479 | CLS Loss: 0.02022763341665268\n",
      "Epoch 132 / 200 | iteration 10 / 171 | Total Loss: 2.4080591201782227 | KNN Loss: 2.393599271774292 | CLS Loss: 0.014459957368671894\n",
      "Epoch 132 / 200 | iteration 20 / 171 | Total Loss: 2.430814743041992 | KNN Loss: 2.427696943283081 | CLS Loss: 0.00311788497492671\n",
      "Epoch 132 / 200 | iteration 30 / 171 | Total Loss: 2.385953187942505 | KNN Loss: 2.3803038597106934 | CLS Loss: 0.005649249535053968\n",
      "Epoch 132 / 200 | iteration 40 / 171 | Total Loss: 2.4382216930389404 | KNN Loss: 2.421536922454834 | CLS Loss: 0.016684874892234802\n",
      "Epoch 132 / 200 | iteration 50 / 171 | Total Loss: 2.41373610496521 | KNN Loss: 2.3988239765167236 | CLS Loss: 0.014912150800228119\n",
      "Epoch 132 / 200 | iteration 60 / 171 | Total Loss: 2.390662670135498 | KNN Loss: 2.373538017272949 | CLS Loss: 0.01712457649409771\n",
      "Epoch 132 / 200 | iteration 70 / 171 | Total Loss: 2.4073140621185303 | KNN Loss: 2.405491828918457 | CLS Loss: 0.00182213238440454\n",
      "Epoch 132 / 200 | iteration 80 / 171 | Total Loss: 2.4322590827941895 | KNN Loss: 2.4295239448547363 | CLS Loss: 0.002735247602686286\n",
      "Epoch 132 / 200 | iteration 90 / 171 | Total Loss: 2.4079723358154297 | KNN Loss: 2.4014899730682373 | CLS Loss: 0.0064824651926755905\n",
      "Epoch 132 / 200 | iteration 100 / 171 | Total Loss: 2.413289785385132 | KNN Loss: 2.403907060623169 | CLS Loss: 0.009382707998156548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 / 200 | iteration 110 / 171 | Total Loss: 2.4385828971862793 | KNN Loss: 2.43265962600708 | CLS Loss: 0.0059232865460217\n",
      "Epoch 132 / 200 | iteration 120 / 171 | Total Loss: 2.4079086780548096 | KNN Loss: 2.4016733169555664 | CLS Loss: 0.006235423032194376\n",
      "Epoch 132 / 200 | iteration 130 / 171 | Total Loss: 2.449580669403076 | KNN Loss: 2.4338555335998535 | CLS Loss: 0.01572505570948124\n",
      "Epoch 132 / 200 | iteration 140 / 171 | Total Loss: 2.3679986000061035 | KNN Loss: 2.360365629196167 | CLS Loss: 0.007633047178387642\n",
      "Epoch 132 / 200 | iteration 150 / 171 | Total Loss: 2.3914036750793457 | KNN Loss: 2.382167100906372 | CLS Loss: 0.009236661717295647\n",
      "Epoch 132 / 200 | iteration 160 / 171 | Total Loss: 2.386888265609741 | KNN Loss: 2.3850085735321045 | CLS Loss: 0.001879691262729466\n",
      "Epoch 132 / 200 | iteration 170 / 171 | Total Loss: 2.3856234550476074 | KNN Loss: 2.3746795654296875 | CLS Loss: 0.010943992994725704\n",
      "Epoch: 132, Loss: 2.4078, Train: 0.9974, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 133 / 200 | iteration 0 / 171 | Total Loss: 2.4148569107055664 | KNN Loss: 2.4118270874023438 | CLS Loss: 0.0030297962948679924\n",
      "Epoch 133 / 200 | iteration 10 / 171 | Total Loss: 2.4333741664886475 | KNN Loss: 2.428128719329834 | CLS Loss: 0.0052454303950071335\n",
      "Epoch 133 / 200 | iteration 20 / 171 | Total Loss: 2.3785369396209717 | KNN Loss: 2.3698008060455322 | CLS Loss: 0.008736250922083855\n",
      "Epoch 133 / 200 | iteration 30 / 171 | Total Loss: 2.388698101043701 | KNN Loss: 2.3847596645355225 | CLS Loss: 0.00393845047801733\n",
      "Epoch 133 / 200 | iteration 40 / 171 | Total Loss: 2.406043767929077 | KNN Loss: 2.387789487838745 | CLS Loss: 0.018254252150654793\n",
      "Epoch 133 / 200 | iteration 50 / 171 | Total Loss: 2.4104034900665283 | KNN Loss: 2.4068381786346436 | CLS Loss: 0.003565408755093813\n",
      "Epoch 133 / 200 | iteration 60 / 171 | Total Loss: 2.395331859588623 | KNN Loss: 2.393831253051758 | CLS Loss: 0.001500684185884893\n",
      "Epoch 133 / 200 | iteration 70 / 171 | Total Loss: 2.4096853733062744 | KNN Loss: 2.3852503299713135 | CLS Loss: 0.024434925988316536\n",
      "Epoch 133 / 200 | iteration 80 / 171 | Total Loss: 2.3485066890716553 | KNN Loss: 2.345811128616333 | CLS Loss: 0.002695478266105056\n",
      "Epoch 133 / 200 | iteration 90 / 171 | Total Loss: 2.407125949859619 | KNN Loss: 2.395394802093506 | CLS Loss: 0.011731084436178207\n",
      "Epoch 133 / 200 | iteration 100 / 171 | Total Loss: 2.4481663703918457 | KNN Loss: 2.42348575592041 | CLS Loss: 0.024680601432919502\n",
      "Epoch 133 / 200 | iteration 110 / 171 | Total Loss: 2.403752088546753 | KNN Loss: 2.393075466156006 | CLS Loss: 0.010676535777747631\n",
      "Epoch 133 / 200 | iteration 120 / 171 | Total Loss: 2.3886361122131348 | KNN Loss: 2.3837931156158447 | CLS Loss: 0.004842964932322502\n",
      "Epoch 133 / 200 | iteration 130 / 171 | Total Loss: 2.3979125022888184 | KNN Loss: 2.3931567668914795 | CLS Loss: 0.004755807109177113\n",
      "Epoch 133 / 200 | iteration 140 / 171 | Total Loss: 2.4214324951171875 | KNN Loss: 2.4064443111419678 | CLS Loss: 0.014988146722316742\n",
      "Epoch 133 / 200 | iteration 150 / 171 | Total Loss: 2.424252986907959 | KNN Loss: 2.418673515319824 | CLS Loss: 0.005579453893005848\n",
      "Epoch 133 / 200 | iteration 160 / 171 | Total Loss: 2.4417340755462646 | KNN Loss: 2.4347543716430664 | CLS Loss: 0.006979695986956358\n",
      "Epoch 133 / 200 | iteration 170 / 171 | Total Loss: 2.3978798389434814 | KNN Loss: 2.3817391395568848 | CLS Loss: 0.016140663996338844\n",
      "Epoch: 133, Loss: 2.4094, Train: 0.9970, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 134 / 200 | iteration 0 / 171 | Total Loss: 2.4578194618225098 | KNN Loss: 2.4534754753112793 | CLS Loss: 0.0043440451845526695\n",
      "Epoch 134 / 200 | iteration 10 / 171 | Total Loss: 2.4272451400756836 | KNN Loss: 2.4193904399871826 | CLS Loss: 0.00785481184720993\n",
      "Epoch 134 / 200 | iteration 20 / 171 | Total Loss: 2.417093515396118 | KNN Loss: 2.383002996444702 | CLS Loss: 0.034090541303157806\n",
      "Epoch 134 / 200 | iteration 30 / 171 | Total Loss: 2.380255699157715 | KNN Loss: 2.3756940364837646 | CLS Loss: 0.004561740905046463\n",
      "Epoch 134 / 200 | iteration 40 / 171 | Total Loss: 2.3971939086914062 | KNN Loss: 2.392733573913574 | CLS Loss: 0.004460400436073542\n",
      "Epoch 134 / 200 | iteration 50 / 171 | Total Loss: 2.3957090377807617 | KNN Loss: 2.389535427093506 | CLS Loss: 0.006173630710691214\n",
      "Epoch 134 / 200 | iteration 60 / 171 | Total Loss: 2.417933702468872 | KNN Loss: 2.404989719390869 | CLS Loss: 0.01294396910816431\n",
      "Epoch 134 / 200 | iteration 70 / 171 | Total Loss: 2.42437744140625 | KNN Loss: 2.4223434925079346 | CLS Loss: 0.002033940516412258\n",
      "Epoch 134 / 200 | iteration 80 / 171 | Total Loss: 2.4096169471740723 | KNN Loss: 2.4058752059936523 | CLS Loss: 0.0037417327985167503\n",
      "Epoch 134 / 200 | iteration 90 / 171 | Total Loss: 2.4427971839904785 | KNN Loss: 2.4253783226013184 | CLS Loss: 0.01741890050470829\n",
      "Epoch 134 / 200 | iteration 100 / 171 | Total Loss: 2.4286136627197266 | KNN Loss: 2.426178455352783 | CLS Loss: 0.0024350988678634167\n",
      "Epoch 134 / 200 | iteration 110 / 171 | Total Loss: 2.413858413696289 | KNN Loss: 2.411386728286743 | CLS Loss: 0.0024715701583772898\n",
      "Epoch 134 / 200 | iteration 120 / 171 | Total Loss: 2.4052059650421143 | KNN Loss: 2.3911917209625244 | CLS Loss: 0.014014286920428276\n",
      "Epoch 134 / 200 | iteration 130 / 171 | Total Loss: 2.433565378189087 | KNN Loss: 2.4283640384674072 | CLS Loss: 0.005201438907533884\n",
      "Epoch 134 / 200 | iteration 140 / 171 | Total Loss: 2.3806285858154297 | KNN Loss: 2.370501756668091 | CLS Loss: 0.010126776993274689\n",
      "Epoch 134 / 200 | iteration 150 / 171 | Total Loss: 2.426253318786621 | KNN Loss: 2.4019691944122314 | CLS Loss: 0.02428417094051838\n",
      "Epoch 134 / 200 | iteration 160 / 171 | Total Loss: 2.370365619659424 | KNN Loss: 2.358105421066284 | CLS Loss: 0.01226014830172062\n",
      "Epoch 134 / 200 | iteration 170 / 171 | Total Loss: 2.44417667388916 | KNN Loss: 2.4336867332458496 | CLS Loss: 0.010489843785762787\n",
      "Epoch: 134, Loss: 2.4089, Train: 0.9969, Valid: 0.9867, Best: 0.9873\n",
      "Epoch 135 / 200 | iteration 0 / 171 | Total Loss: 2.4009785652160645 | KNN Loss: 2.3914263248443604 | CLS Loss: 0.00955223385244608\n",
      "Epoch 135 / 200 | iteration 10 / 171 | Total Loss: 2.4395337104797363 | KNN Loss: 2.4347033500671387 | CLS Loss: 0.004830399062484503\n",
      "Epoch 135 / 200 | iteration 20 / 171 | Total Loss: 2.4215264320373535 | KNN Loss: 2.4032623767852783 | CLS Loss: 0.018264077603816986\n",
      "Epoch 135 / 200 | iteration 30 / 171 | Total Loss: 2.3793046474456787 | KNN Loss: 2.3606786727905273 | CLS Loss: 0.018626078963279724\n",
      "Epoch 135 / 200 | iteration 40 / 171 | Total Loss: 2.3960390090942383 | KNN Loss: 2.388740062713623 | CLS Loss: 0.007298858370631933\n",
      "Epoch 135 / 200 | iteration 50 / 171 | Total Loss: 2.3971054553985596 | KNN Loss: 2.373170852661133 | CLS Loss: 0.02393452636897564\n",
      "Epoch 135 / 200 | iteration 60 / 171 | Total Loss: 2.377256155014038 | KNN Loss: 2.3736627101898193 | CLS Loss: 0.0035933677572757006\n",
      "Epoch 135 / 200 | iteration 70 / 171 | Total Loss: 2.391226053237915 | KNN Loss: 2.3869855403900146 | CLS Loss: 0.004240579903125763\n",
      "Epoch 135 / 200 | iteration 80 / 171 | Total Loss: 2.43023943901062 | KNN Loss: 2.408301830291748 | CLS Loss: 0.021937638521194458\n",
      "Epoch 135 / 200 | iteration 90 / 171 | Total Loss: 2.3981380462646484 | KNN Loss: 2.3941900730133057 | CLS Loss: 0.00394799280911684\n",
      "Epoch 135 / 200 | iteration 100 / 171 | Total Loss: 2.416315793991089 | KNN Loss: 2.4068796634674072 | CLS Loss: 0.009436223655939102\n",
      "Epoch 135 / 200 | iteration 110 / 171 | Total Loss: 2.4130027294158936 | KNN Loss: 2.4094595909118652 | CLS Loss: 0.0035432088188827038\n",
      "Epoch 135 / 200 | iteration 120 / 171 | Total Loss: 2.4187543392181396 | KNN Loss: 2.3928017616271973 | CLS Loss: 0.025952626019716263\n",
      "Epoch 135 / 200 | iteration 130 / 171 | Total Loss: 2.3760323524475098 | KNN Loss: 2.372678518295288 | CLS Loss: 0.0033539230935275555\n",
      "Epoch 135 / 200 | iteration 140 / 171 | Total Loss: 2.4241280555725098 | KNN Loss: 2.42342209815979 | CLS Loss: 0.0007059522322379053\n",
      "Epoch 135 / 200 | iteration 150 / 171 | Total Loss: 2.4192333221435547 | KNN Loss: 2.404404878616333 | CLS Loss: 0.014828477054834366\n",
      "Epoch 135 / 200 | iteration 160 / 171 | Total Loss: 2.4330239295959473 | KNN Loss: 2.4236252307891846 | CLS Loss: 0.009398641996085644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 / 200 | iteration 170 / 171 | Total Loss: 2.3749632835388184 | KNN Loss: 2.370333433151245 | CLS Loss: 0.004629960283637047\n",
      "Epoch: 135, Loss: 2.4093, Train: 0.9967, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 136 / 200 | iteration 0 / 171 | Total Loss: 2.407447576522827 | KNN Loss: 2.4050748348236084 | CLS Loss: 0.0023726823274046183\n",
      "Epoch 136 / 200 | iteration 10 / 171 | Total Loss: 2.4324264526367188 | KNN Loss: 2.423845052719116 | CLS Loss: 0.008581466972827911\n",
      "Epoch 136 / 200 | iteration 20 / 171 | Total Loss: 2.4318933486938477 | KNN Loss: 2.4183642864227295 | CLS Loss: 0.01352910976856947\n",
      "Epoch 136 / 200 | iteration 30 / 171 | Total Loss: 2.426661968231201 | KNN Loss: 2.4244561195373535 | CLS Loss: 0.0022057692985981703\n",
      "Epoch 136 / 200 | iteration 40 / 171 | Total Loss: 2.367790937423706 | KNN Loss: 2.3606414794921875 | CLS Loss: 0.007149370387196541\n",
      "Epoch 136 / 200 | iteration 50 / 171 | Total Loss: 2.4401955604553223 | KNN Loss: 2.422445774078369 | CLS Loss: 0.017749682068824768\n",
      "Epoch 136 / 200 | iteration 60 / 171 | Total Loss: 2.4280431270599365 | KNN Loss: 2.420468330383301 | CLS Loss: 0.007574779912829399\n",
      "Epoch 136 / 200 | iteration 70 / 171 | Total Loss: 2.3774003982543945 | KNN Loss: 2.367647886276245 | CLS Loss: 0.009752440266311169\n",
      "Epoch 136 / 200 | iteration 80 / 171 | Total Loss: 2.3762123584747314 | KNN Loss: 2.3721230030059814 | CLS Loss: 0.004089350812137127\n",
      "Epoch 136 / 200 | iteration 90 / 171 | Total Loss: 2.4133176803588867 | KNN Loss: 2.408982992172241 | CLS Loss: 0.004334694240242243\n",
      "Epoch 136 / 200 | iteration 100 / 171 | Total Loss: 2.449049711227417 | KNN Loss: 2.443864583969116 | CLS Loss: 0.005185205955058336\n",
      "Epoch 136 / 200 | iteration 110 / 171 | Total Loss: 2.3965256214141846 | KNN Loss: 2.383185863494873 | CLS Loss: 0.013339642435312271\n",
      "Epoch 136 / 200 | iteration 120 / 171 | Total Loss: 2.437868356704712 | KNN Loss: 2.432770013809204 | CLS Loss: 0.005098307505249977\n",
      "Epoch 136 / 200 | iteration 130 / 171 | Total Loss: 2.4370830059051514 | KNN Loss: 2.4285025596618652 | CLS Loss: 0.00858039129525423\n",
      "Epoch 136 / 200 | iteration 140 / 171 | Total Loss: 2.4000322818756104 | KNN Loss: 2.3934166431427 | CLS Loss: 0.006615681108087301\n",
      "Epoch 136 / 200 | iteration 150 / 171 | Total Loss: 2.3917760848999023 | KNN Loss: 2.3770062923431396 | CLS Loss: 0.014769891276955605\n",
      "Epoch 136 / 200 | iteration 160 / 171 | Total Loss: 2.401431083679199 | KNN Loss: 2.3975863456726074 | CLS Loss: 0.003844726597890258\n",
      "Epoch 136 / 200 | iteration 170 / 171 | Total Loss: 2.4137215614318848 | KNN Loss: 2.4038453102111816 | CLS Loss: 0.009876271709799767\n",
      "Epoch: 136, Loss: 2.4115, Train: 0.9966, Valid: 0.9869, Best: 0.9873\n",
      "Epoch 137 / 200 | iteration 0 / 171 | Total Loss: 2.424959659576416 | KNN Loss: 2.4119746685028076 | CLS Loss: 0.012984982691705227\n",
      "Epoch 137 / 200 | iteration 10 / 171 | Total Loss: 2.4047348499298096 | KNN Loss: 2.4015684127807617 | CLS Loss: 0.003166522830724716\n",
      "Epoch 137 / 200 | iteration 20 / 171 | Total Loss: 2.3972296714782715 | KNN Loss: 2.3818202018737793 | CLS Loss: 0.015409477055072784\n",
      "Epoch 137 / 200 | iteration 30 / 171 | Total Loss: 2.3689920902252197 | KNN Loss: 2.364069938659668 | CLS Loss: 0.004922123625874519\n",
      "Epoch 137 / 200 | iteration 40 / 171 | Total Loss: 2.4463906288146973 | KNN Loss: 2.4319915771484375 | CLS Loss: 0.014399131760001183\n",
      "Epoch 137 / 200 | iteration 50 / 171 | Total Loss: 2.429320812225342 | KNN Loss: 2.378871440887451 | CLS Loss: 0.050449371337890625\n",
      "Epoch 137 / 200 | iteration 60 / 171 | Total Loss: 2.3768370151519775 | KNN Loss: 2.3587300777435303 | CLS Loss: 0.018106890842318535\n",
      "Epoch 137 / 200 | iteration 70 / 171 | Total Loss: 2.4421074390411377 | KNN Loss: 2.4323391914367676 | CLS Loss: 0.009768174029886723\n",
      "Epoch 137 / 200 | iteration 80 / 171 | Total Loss: 2.4483962059020996 | KNN Loss: 2.415226697921753 | CLS Loss: 0.033169616013765335\n",
      "Epoch 137 / 200 | iteration 90 / 171 | Total Loss: 2.377781867980957 | KNN Loss: 2.3686094284057617 | CLS Loss: 0.00917236041277647\n",
      "Epoch 137 / 200 | iteration 100 / 171 | Total Loss: 2.377283811569214 | KNN Loss: 2.374650001525879 | CLS Loss: 0.00263370294123888\n",
      "Epoch 137 / 200 | iteration 110 / 171 | Total Loss: 2.4107892513275146 | KNN Loss: 2.391848564147949 | CLS Loss: 0.018940672278404236\n",
      "Epoch 137 / 200 | iteration 120 / 171 | Total Loss: 2.429943561553955 | KNN Loss: 2.418015718460083 | CLS Loss: 0.011927749961614609\n",
      "Epoch 137 / 200 | iteration 130 / 171 | Total Loss: 2.3982436656951904 | KNN Loss: 2.3852436542510986 | CLS Loss: 0.013000075705349445\n",
      "Epoch 137 / 200 | iteration 140 / 171 | Total Loss: 2.4262232780456543 | KNN Loss: 2.4082765579223633 | CLS Loss: 0.01794661022722721\n",
      "Epoch 137 / 200 | iteration 150 / 171 | Total Loss: 2.4631898403167725 | KNN Loss: 2.445371627807617 | CLS Loss: 0.017818300053477287\n",
      "Epoch 137 / 200 | iteration 160 / 171 | Total Loss: 2.428926467895508 | KNN Loss: 2.399914264678955 | CLS Loss: 0.029012126848101616\n",
      "Epoch 137 / 200 | iteration 170 / 171 | Total Loss: 2.3895087242126465 | KNN Loss: 2.3840129375457764 | CLS Loss: 0.0054956721141934395\n",
      "Epoch: 137, Loss: 2.4121, Train: 0.9970, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 138 / 200 | iteration 0 / 171 | Total Loss: 2.4312398433685303 | KNN Loss: 2.414193630218506 | CLS Loss: 0.01704614982008934\n",
      "Epoch 138 / 200 | iteration 10 / 171 | Total Loss: 2.369544744491577 | KNN Loss: 2.356849193572998 | CLS Loss: 0.012695539742708206\n",
      "Epoch 138 / 200 | iteration 20 / 171 | Total Loss: 2.4265050888061523 | KNN Loss: 2.4138505458831787 | CLS Loss: 0.012654505670070648\n",
      "Epoch 138 / 200 | iteration 30 / 171 | Total Loss: 2.4049415588378906 | KNN Loss: 2.3998210430145264 | CLS Loss: 0.005120566114783287\n",
      "Epoch 138 / 200 | iteration 40 / 171 | Total Loss: 2.3864831924438477 | KNN Loss: 2.37251615524292 | CLS Loss: 0.01396708283573389\n",
      "Epoch 138 / 200 | iteration 50 / 171 | Total Loss: 2.40981388092041 | KNN Loss: 2.405116319656372 | CLS Loss: 0.004697534255683422\n",
      "Epoch 138 / 200 | iteration 60 / 171 | Total Loss: 2.3753228187561035 | KNN Loss: 2.36673903465271 | CLS Loss: 0.008583766408264637\n",
      "Epoch 138 / 200 | iteration 70 / 171 | Total Loss: 2.406061887741089 | KNN Loss: 2.3867998123168945 | CLS Loss: 0.01926206238567829\n",
      "Epoch 138 / 200 | iteration 80 / 171 | Total Loss: 2.419156551361084 | KNN Loss: 2.409224510192871 | CLS Loss: 0.009932097978889942\n",
      "Epoch 138 / 200 | iteration 90 / 171 | Total Loss: 2.4182028770446777 | KNN Loss: 2.4080333709716797 | CLS Loss: 0.01016960944980383\n",
      "Epoch 138 / 200 | iteration 100 / 171 | Total Loss: 2.428175210952759 | KNN Loss: 2.400242328643799 | CLS Loss: 0.02793290466070175\n",
      "Epoch 138 / 200 | iteration 110 / 171 | Total Loss: 2.4051406383514404 | KNN Loss: 2.3898587226867676 | CLS Loss: 0.0152819799259305\n",
      "Epoch 138 / 200 | iteration 120 / 171 | Total Loss: 2.4097108840942383 | KNN Loss: 2.404329538345337 | CLS Loss: 0.005381447263062\n",
      "Epoch 138 / 200 | iteration 130 / 171 | Total Loss: 2.448486566543579 | KNN Loss: 2.4318747520446777 | CLS Loss: 0.016611825674772263\n",
      "Epoch 138 / 200 | iteration 140 / 171 | Total Loss: 2.4304842948913574 | KNN Loss: 2.4154889583587646 | CLS Loss: 0.014995415695011616\n",
      "Epoch 138 / 200 | iteration 150 / 171 | Total Loss: 2.388331890106201 | KNN Loss: 2.3849878311157227 | CLS Loss: 0.0033441532868891954\n",
      "Epoch 138 / 200 | iteration 160 / 171 | Total Loss: 2.4212653636932373 | KNN Loss: 2.4136736392974854 | CLS Loss: 0.007591736502945423\n",
      "Epoch 138 / 200 | iteration 170 / 171 | Total Loss: 2.355999231338501 | KNN Loss: 2.35081148147583 | CLS Loss: 0.005187779664993286\n",
      "Epoch: 138, Loss: 2.4084, Train: 0.9964, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 139 / 200 | iteration 0 / 171 | Total Loss: 2.3781871795654297 | KNN Loss: 2.366926431655884 | CLS Loss: 0.01126074232161045\n",
      "Epoch 139 / 200 | iteration 10 / 171 | Total Loss: 2.4001898765563965 | KNN Loss: 2.3938112258911133 | CLS Loss: 0.006378750316798687\n",
      "Epoch 139 / 200 | iteration 20 / 171 | Total Loss: 2.4020442962646484 | KNN Loss: 2.3909802436828613 | CLS Loss: 0.011064166203141212\n",
      "Epoch 139 / 200 | iteration 30 / 171 | Total Loss: 2.4068002700805664 | KNN Loss: 2.3995494842529297 | CLS Loss: 0.007250877562910318\n",
      "Epoch 139 / 200 | iteration 40 / 171 | Total Loss: 2.379567861557007 | KNN Loss: 2.375783920288086 | CLS Loss: 0.0037839978467673063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 / 200 | iteration 50 / 171 | Total Loss: 2.4172120094299316 | KNN Loss: 2.412446975708008 | CLS Loss: 0.0047649601474404335\n",
      "Epoch 139 / 200 | iteration 60 / 171 | Total Loss: 2.431915521621704 | KNN Loss: 2.3994805812835693 | CLS Loss: 0.0324348509311676\n",
      "Epoch 139 / 200 | iteration 70 / 171 | Total Loss: 2.405132293701172 | KNN Loss: 2.400583505630493 | CLS Loss: 0.0045488192699849606\n",
      "Epoch 139 / 200 | iteration 80 / 171 | Total Loss: 2.4302492141723633 | KNN Loss: 2.4075887203216553 | CLS Loss: 0.022660406306385994\n",
      "Epoch 139 / 200 | iteration 90 / 171 | Total Loss: 2.4307241439819336 | KNN Loss: 2.3914613723754883 | CLS Loss: 0.039262741804122925\n",
      "Epoch 139 / 200 | iteration 100 / 171 | Total Loss: 2.4382901191711426 | KNN Loss: 2.429764747619629 | CLS Loss: 0.00852537713944912\n",
      "Epoch 139 / 200 | iteration 110 / 171 | Total Loss: 2.398163318634033 | KNN Loss: 2.3860394954681396 | CLS Loss: 0.012123714201152325\n",
      "Epoch 139 / 200 | iteration 120 / 171 | Total Loss: 2.3919785022735596 | KNN Loss: 2.3896968364715576 | CLS Loss: 0.0022816990967839956\n",
      "Epoch 139 / 200 | iteration 130 / 171 | Total Loss: 2.4329419136047363 | KNN Loss: 2.41902232170105 | CLS Loss: 0.013919530436396599\n",
      "Epoch 139 / 200 | iteration 140 / 171 | Total Loss: 2.376781463623047 | KNN Loss: 2.375826597213745 | CLS Loss: 0.0009548278758302331\n",
      "Epoch 139 / 200 | iteration 150 / 171 | Total Loss: 2.4331889152526855 | KNN Loss: 2.424867868423462 | CLS Loss: 0.008321014232933521\n",
      "Epoch 139 / 200 | iteration 160 / 171 | Total Loss: 2.439851760864258 | KNN Loss: 2.4337191581726074 | CLS Loss: 0.0061325328424572945\n",
      "Epoch 139 / 200 | iteration 170 / 171 | Total Loss: 2.4129486083984375 | KNN Loss: 2.3983259201049805 | CLS Loss: 0.014622732065618038\n",
      "Epoch: 139, Loss: 2.4115, Train: 0.9962, Valid: 0.9849, Best: 0.9873\n",
      "Epoch 140 / 200 | iteration 0 / 171 | Total Loss: 2.4101133346557617 | KNN Loss: 2.4017493724823 | CLS Loss: 0.008363878354430199\n",
      "Epoch 140 / 200 | iteration 10 / 171 | Total Loss: 2.465884208679199 | KNN Loss: 2.4596550464630127 | CLS Loss: 0.006229107733815908\n",
      "Epoch 140 / 200 | iteration 20 / 171 | Total Loss: 2.4267020225524902 | KNN Loss: 2.420219659805298 | CLS Loss: 0.006482391618192196\n",
      "Epoch 140 / 200 | iteration 30 / 171 | Total Loss: 2.447141647338867 | KNN Loss: 2.425633668899536 | CLS Loss: 0.021507862955331802\n",
      "Epoch 140 / 200 | iteration 40 / 171 | Total Loss: 2.4018561840057373 | KNN Loss: 2.388124704360962 | CLS Loss: 0.013731444254517555\n",
      "Epoch 140 / 200 | iteration 50 / 171 | Total Loss: 2.4129772186279297 | KNN Loss: 2.4012067317962646 | CLS Loss: 0.011770484037697315\n",
      "Epoch 140 / 200 | iteration 60 / 171 | Total Loss: 2.398977518081665 | KNN Loss: 2.391056537628174 | CLS Loss: 0.007921080105006695\n",
      "Epoch 140 / 200 | iteration 70 / 171 | Total Loss: 2.3921384811401367 | KNN Loss: 2.3758187294006348 | CLS Loss: 0.016319774091243744\n",
      "Epoch 140 / 200 | iteration 80 / 171 | Total Loss: 2.4099066257476807 | KNN Loss: 2.383227586746216 | CLS Loss: 0.026679014787077904\n",
      "Epoch 140 / 200 | iteration 90 / 171 | Total Loss: 2.409215211868286 | KNN Loss: 2.391083240509033 | CLS Loss: 0.018131952732801437\n",
      "Epoch 140 / 200 | iteration 100 / 171 | Total Loss: 2.4208667278289795 | KNN Loss: 2.4037539958953857 | CLS Loss: 0.01711280643939972\n",
      "Epoch 140 / 200 | iteration 110 / 171 | Total Loss: 2.416609048843384 | KNN Loss: 2.3909752368927 | CLS Loss: 0.025633888319134712\n",
      "Epoch 140 / 200 | iteration 120 / 171 | Total Loss: 2.4113426208496094 | KNN Loss: 2.410479784011841 | CLS Loss: 0.0008627865463495255\n",
      "Epoch 140 / 200 | iteration 130 / 171 | Total Loss: 2.394965648651123 | KNN Loss: 2.384168863296509 | CLS Loss: 0.010796810500323772\n",
      "Epoch 140 / 200 | iteration 140 / 171 | Total Loss: 2.4302635192871094 | KNN Loss: 2.421374797821045 | CLS Loss: 0.00888882763683796\n",
      "Epoch 140 / 200 | iteration 150 / 171 | Total Loss: 2.3762869834899902 | KNN Loss: 2.3698151111602783 | CLS Loss: 0.006471960339695215\n",
      "Epoch 140 / 200 | iteration 160 / 171 | Total Loss: 2.3836851119995117 | KNN Loss: 2.3695435523986816 | CLS Loss: 0.014141591265797615\n",
      "Epoch 140 / 200 | iteration 170 / 171 | Total Loss: 2.410938262939453 | KNN Loss: 2.407198429107666 | CLS Loss: 0.0037399448920041323\n",
      "Epoch: 140, Loss: 2.4085, Train: 0.9962, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 141 / 200 | iteration 0 / 171 | Total Loss: 2.4178829193115234 | KNN Loss: 2.3920750617980957 | CLS Loss: 0.0258079394698143\n",
      "Epoch 141 / 200 | iteration 10 / 171 | Total Loss: 2.36552357673645 | KNN Loss: 2.346538782119751 | CLS Loss: 0.018984757363796234\n",
      "Epoch 141 / 200 | iteration 20 / 171 | Total Loss: 2.457345724105835 | KNN Loss: 2.452425241470337 | CLS Loss: 0.004920374136418104\n",
      "Epoch 141 / 200 | iteration 30 / 171 | Total Loss: 2.3896539211273193 | KNN Loss: 2.376605749130249 | CLS Loss: 0.0130481431260705\n",
      "Epoch 141 / 200 | iteration 40 / 171 | Total Loss: 2.4357657432556152 | KNN Loss: 2.427309036254883 | CLS Loss: 0.008456742390990257\n",
      "Epoch 141 / 200 | iteration 50 / 171 | Total Loss: 2.4029579162597656 | KNN Loss: 2.396923303604126 | CLS Loss: 0.006034723483026028\n",
      "Epoch 141 / 200 | iteration 60 / 171 | Total Loss: 2.4010002613067627 | KNN Loss: 2.3835678100585938 | CLS Loss: 0.01743248663842678\n",
      "Epoch 141 / 200 | iteration 70 / 171 | Total Loss: 2.3971924781799316 | KNN Loss: 2.384972333908081 | CLS Loss: 0.012220068834722042\n",
      "Epoch 141 / 200 | iteration 80 / 171 | Total Loss: 2.436483860015869 | KNN Loss: 2.4251513481140137 | CLS Loss: 0.011332597583532333\n",
      "Epoch 141 / 200 | iteration 90 / 171 | Total Loss: 2.4381003379821777 | KNN Loss: 2.42111873626709 | CLS Loss: 0.016981635242700577\n",
      "Epoch 141 / 200 | iteration 100 / 171 | Total Loss: 2.349736213684082 | KNN Loss: 2.3470239639282227 | CLS Loss: 0.0027122902683913708\n",
      "Epoch 141 / 200 | iteration 110 / 171 | Total Loss: 2.4197161197662354 | KNN Loss: 2.4041879177093506 | CLS Loss: 0.015528310090303421\n",
      "Epoch 141 / 200 | iteration 120 / 171 | Total Loss: 2.427450180053711 | KNN Loss: 2.399588108062744 | CLS Loss: 0.027862144634127617\n",
      "Epoch 141 / 200 | iteration 130 / 171 | Total Loss: 2.4176716804504395 | KNN Loss: 2.4111320972442627 | CLS Loss: 0.0065396749414503574\n",
      "Epoch 141 / 200 | iteration 140 / 171 | Total Loss: 2.422651767730713 | KNN Loss: 2.4055514335632324 | CLS Loss: 0.017100423574447632\n",
      "Epoch 141 / 200 | iteration 150 / 171 | Total Loss: 2.419829845428467 | KNN Loss: 2.407162666320801 | CLS Loss: 0.012667198665440083\n",
      "Epoch 141 / 200 | iteration 160 / 171 | Total Loss: 2.423543691635132 | KNN Loss: 2.4194111824035645 | CLS Loss: 0.00413258234038949\n",
      "Epoch 141 / 200 | iteration 170 / 171 | Total Loss: 2.4037492275238037 | KNN Loss: 2.3957066535949707 | CLS Loss: 0.008042479865252972\n",
      "Epoch: 141, Loss: 2.4108, Train: 0.9971, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 142 / 200 | iteration 0 / 171 | Total Loss: 2.435744047164917 | KNN Loss: 2.4282126426696777 | CLS Loss: 0.007531309500336647\n",
      "Epoch 142 / 200 | iteration 10 / 171 | Total Loss: 2.3886756896972656 | KNN Loss: 2.3809051513671875 | CLS Loss: 0.007770642172545195\n",
      "Epoch 142 / 200 | iteration 20 / 171 | Total Loss: 2.389378786087036 | KNN Loss: 2.3816957473754883 | CLS Loss: 0.00768308574333787\n",
      "Epoch 142 / 200 | iteration 30 / 171 | Total Loss: 2.3961288928985596 | KNN Loss: 2.3884501457214355 | CLS Loss: 0.007678628899157047\n",
      "Epoch 142 / 200 | iteration 40 / 171 | Total Loss: 2.4184389114379883 | KNN Loss: 2.398682117462158 | CLS Loss: 0.019756857305765152\n",
      "Epoch 142 / 200 | iteration 50 / 171 | Total Loss: 2.3890199661254883 | KNN Loss: 2.362816333770752 | CLS Loss: 0.026203682646155357\n",
      "Epoch 142 / 200 | iteration 60 / 171 | Total Loss: 2.3978941440582275 | KNN Loss: 2.3944008350372314 | CLS Loss: 0.003493337891995907\n",
      "Epoch 142 / 200 | iteration 70 / 171 | Total Loss: 2.4299049377441406 | KNN Loss: 2.4187114238739014 | CLS Loss: 0.011193426325917244\n",
      "Epoch 142 / 200 | iteration 80 / 171 | Total Loss: 2.407519817352295 | KNN Loss: 2.39018177986145 | CLS Loss: 0.017337994650006294\n",
      "Epoch 142 / 200 | iteration 90 / 171 | Total Loss: 2.4154717922210693 | KNN Loss: 2.4099578857421875 | CLS Loss: 0.005513972602784634\n",
      "Epoch 142 / 200 | iteration 100 / 171 | Total Loss: 2.4463980197906494 | KNN Loss: 2.4426538944244385 | CLS Loss: 0.0037441630847752094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 / 200 | iteration 110 / 171 | Total Loss: 2.388078451156616 | KNN Loss: 2.378056049346924 | CLS Loss: 0.010022372007369995\n",
      "Epoch 142 / 200 | iteration 120 / 171 | Total Loss: 2.386617422103882 | KNN Loss: 2.3847668170928955 | CLS Loss: 0.0018505797488614917\n",
      "Epoch 142 / 200 | iteration 130 / 171 | Total Loss: 2.3819990158081055 | KNN Loss: 2.3765296936035156 | CLS Loss: 0.005469375289976597\n",
      "Epoch 142 / 200 | iteration 140 / 171 | Total Loss: 2.4530091285705566 | KNN Loss: 2.432772397994995 | CLS Loss: 0.02023683302104473\n",
      "Epoch 142 / 200 | iteration 150 / 171 | Total Loss: 2.3915677070617676 | KNN Loss: 2.368978500366211 | CLS Loss: 0.022589117288589478\n",
      "Epoch 142 / 200 | iteration 160 / 171 | Total Loss: 2.406944513320923 | KNN Loss: 2.402430772781372 | CLS Loss: 0.00451385322958231\n",
      "Epoch 142 / 200 | iteration 170 / 171 | Total Loss: 2.4577558040618896 | KNN Loss: 2.440119981765747 | CLS Loss: 0.01763584278523922\n",
      "Epoch: 142, Loss: 2.4103, Train: 0.9970, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 143 / 200 | iteration 0 / 171 | Total Loss: 2.4240846633911133 | KNN Loss: 2.4082083702087402 | CLS Loss: 0.015876205638051033\n",
      "Epoch 143 / 200 | iteration 10 / 171 | Total Loss: 2.4171204566955566 | KNN Loss: 2.414367437362671 | CLS Loss: 0.002753116888925433\n",
      "Epoch 143 / 200 | iteration 20 / 171 | Total Loss: 2.3926775455474854 | KNN Loss: 2.3911941051483154 | CLS Loss: 0.0014835511101409793\n",
      "Epoch 143 / 200 | iteration 30 / 171 | Total Loss: 2.4144785404205322 | KNN Loss: 2.401909828186035 | CLS Loss: 0.012568691745400429\n",
      "Epoch 143 / 200 | iteration 40 / 171 | Total Loss: 2.4391143321990967 | KNN Loss: 2.383615732192993 | CLS Loss: 0.0554986409842968\n",
      "Epoch 143 / 200 | iteration 50 / 171 | Total Loss: 2.4101498126983643 | KNN Loss: 2.3947291374206543 | CLS Loss: 0.015420595183968544\n",
      "Epoch 143 / 200 | iteration 60 / 171 | Total Loss: 2.4053053855895996 | KNN Loss: 2.403784990310669 | CLS Loss: 0.0015203106449916959\n",
      "Epoch 143 / 200 | iteration 70 / 171 | Total Loss: 2.4047865867614746 | KNN Loss: 2.3724405765533447 | CLS Loss: 0.032345958054065704\n",
      "Epoch 143 / 200 | iteration 80 / 171 | Total Loss: 2.3749613761901855 | KNN Loss: 2.3732519149780273 | CLS Loss: 0.0017094711074605584\n",
      "Epoch 143 / 200 | iteration 90 / 171 | Total Loss: 2.4116404056549072 | KNN Loss: 2.4103140830993652 | CLS Loss: 0.0013262630673125386\n",
      "Epoch 143 / 200 | iteration 100 / 171 | Total Loss: 2.395735502243042 | KNN Loss: 2.38242244720459 | CLS Loss: 0.0133130494505167\n",
      "Epoch 143 / 200 | iteration 110 / 171 | Total Loss: 2.371136426925659 | KNN Loss: 2.3691914081573486 | CLS Loss: 0.0019450477557256818\n",
      "Epoch 143 / 200 | iteration 120 / 171 | Total Loss: 2.389871120452881 | KNN Loss: 2.3827919960021973 | CLS Loss: 0.007079039700329304\n",
      "Epoch 143 / 200 | iteration 130 / 171 | Total Loss: 2.3941843509674072 | KNN Loss: 2.3889358043670654 | CLS Loss: 0.005248552653938532\n",
      "Epoch 143 / 200 | iteration 140 / 171 | Total Loss: 2.408010721206665 | KNN Loss: 2.4041786193847656 | CLS Loss: 0.0038320356979966164\n",
      "Epoch 143 / 200 | iteration 150 / 171 | Total Loss: 2.4288253784179688 | KNN Loss: 2.3964290618896484 | CLS Loss: 0.03239630535244942\n",
      "Epoch 143 / 200 | iteration 160 / 171 | Total Loss: 2.43686580657959 | KNN Loss: 2.423341989517212 | CLS Loss: 0.01352385152131319\n",
      "Epoch 143 / 200 | iteration 170 / 171 | Total Loss: 2.418226957321167 | KNN Loss: 2.405393362045288 | CLS Loss: 0.01283355988562107\n",
      "Epoch: 143, Loss: 2.4077, Train: 0.9969, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 144 / 200 | iteration 0 / 171 | Total Loss: 2.3816463947296143 | KNN Loss: 2.376161575317383 | CLS Loss: 0.005484866909682751\n",
      "Epoch 144 / 200 | iteration 10 / 171 | Total Loss: 2.426146984100342 | KNN Loss: 2.413205146789551 | CLS Loss: 0.012941800057888031\n",
      "Epoch 144 / 200 | iteration 20 / 171 | Total Loss: 2.4321911334991455 | KNN Loss: 2.4227311611175537 | CLS Loss: 0.009459991939365864\n",
      "Epoch 144 / 200 | iteration 30 / 171 | Total Loss: 2.412609338760376 | KNN Loss: 2.40511417388916 | CLS Loss: 0.007495119236409664\n",
      "Epoch 144 / 200 | iteration 40 / 171 | Total Loss: 2.3969240188598633 | KNN Loss: 2.390249252319336 | CLS Loss: 0.006674750242382288\n",
      "Epoch 144 / 200 | iteration 50 / 171 | Total Loss: 2.4164133071899414 | KNN Loss: 2.399977684020996 | CLS Loss: 0.01643570512533188\n",
      "Epoch 144 / 200 | iteration 60 / 171 | Total Loss: 2.3985798358917236 | KNN Loss: 2.389052391052246 | CLS Loss: 0.009527375921607018\n",
      "Epoch 144 / 200 | iteration 70 / 171 | Total Loss: 2.3867616653442383 | KNN Loss: 2.378335952758789 | CLS Loss: 0.008425813168287277\n",
      "Epoch 144 / 200 | iteration 80 / 171 | Total Loss: 2.387542247772217 | KNN Loss: 2.377642869949341 | CLS Loss: 0.009899280965328217\n",
      "Epoch 144 / 200 | iteration 90 / 171 | Total Loss: 2.388319969177246 | KNN Loss: 2.386183738708496 | CLS Loss: 0.0021362940315157175\n",
      "Epoch 144 / 200 | iteration 100 / 171 | Total Loss: 2.3841140270233154 | KNN Loss: 2.379758358001709 | CLS Loss: 0.004355587996542454\n",
      "Epoch 144 / 200 | iteration 110 / 171 | Total Loss: 2.462019681930542 | KNN Loss: 2.4273459911346436 | CLS Loss: 0.034673694521188736\n",
      "Epoch 144 / 200 | iteration 120 / 171 | Total Loss: 2.362788677215576 | KNN Loss: 2.3555283546447754 | CLS Loss: 0.007260219193994999\n",
      "Epoch 144 / 200 | iteration 130 / 171 | Total Loss: 2.395179271697998 | KNN Loss: 2.389284133911133 | CLS Loss: 0.005895069334656\n",
      "Epoch 144 / 200 | iteration 140 / 171 | Total Loss: 2.4312822818756104 | KNN Loss: 2.4272847175598145 | CLS Loss: 0.003997532185167074\n",
      "Epoch 144 / 200 | iteration 150 / 171 | Total Loss: 2.4155139923095703 | KNN Loss: 2.3860411643981934 | CLS Loss: 0.029472943395376205\n",
      "Epoch 144 / 200 | iteration 160 / 171 | Total Loss: 2.3850653171539307 | KNN Loss: 2.3746495246887207 | CLS Loss: 0.010415860451757908\n",
      "Epoch 144 / 200 | iteration 170 / 171 | Total Loss: 2.4244582653045654 | KNN Loss: 2.414208173751831 | CLS Loss: 0.010250004008412361\n",
      "Epoch: 144, Loss: 2.4042, Train: 0.9969, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 145 / 200 | iteration 0 / 171 | Total Loss: 2.4677951335906982 | KNN Loss: 2.4631969928741455 | CLS Loss: 0.0045980485156178474\n",
      "Epoch 145 / 200 | iteration 10 / 171 | Total Loss: 2.4048430919647217 | KNN Loss: 2.3969602584838867 | CLS Loss: 0.007882864214479923\n",
      "Epoch 145 / 200 | iteration 20 / 171 | Total Loss: 2.4737040996551514 | KNN Loss: 2.4422709941864014 | CLS Loss: 0.03143301233649254\n",
      "Epoch 145 / 200 | iteration 30 / 171 | Total Loss: 2.368218183517456 | KNN Loss: 2.363844871520996 | CLS Loss: 0.004373237490653992\n",
      "Epoch 145 / 200 | iteration 40 / 171 | Total Loss: 2.4252922534942627 | KNN Loss: 2.411548614501953 | CLS Loss: 0.013743610121309757\n",
      "Epoch 145 / 200 | iteration 50 / 171 | Total Loss: 2.410987138748169 | KNN Loss: 2.3816757202148438 | CLS Loss: 0.029311388731002808\n",
      "Epoch 145 / 200 | iteration 60 / 171 | Total Loss: 2.408195734024048 | KNN Loss: 2.4041478633880615 | CLS Loss: 0.004047825932502747\n",
      "Epoch 145 / 200 | iteration 70 / 171 | Total Loss: 2.3989968299865723 | KNN Loss: 2.3918721675872803 | CLS Loss: 0.007124698720872402\n",
      "Epoch 145 / 200 | iteration 80 / 171 | Total Loss: 2.417755365371704 | KNN Loss: 2.414623498916626 | CLS Loss: 0.003131815930828452\n",
      "Epoch 145 / 200 | iteration 90 / 171 | Total Loss: 2.390460252761841 | KNN Loss: 2.3822343349456787 | CLS Loss: 0.008225969970226288\n",
      "Epoch 145 / 200 | iteration 100 / 171 | Total Loss: 2.4005539417266846 | KNN Loss: 2.3927202224731445 | CLS Loss: 0.007833829149603844\n",
      "Epoch 145 / 200 | iteration 110 / 171 | Total Loss: 2.4599926471710205 | KNN Loss: 2.4238672256469727 | CLS Loss: 0.03612550348043442\n",
      "Epoch 145 / 200 | iteration 120 / 171 | Total Loss: 2.407101631164551 | KNN Loss: 2.381342887878418 | CLS Loss: 0.02575869672000408\n",
      "Epoch 145 / 200 | iteration 130 / 171 | Total Loss: 2.408886194229126 | KNN Loss: 2.3901171684265137 | CLS Loss: 0.018769042566418648\n",
      "Epoch 145 / 200 | iteration 140 / 171 | Total Loss: 2.4595115184783936 | KNN Loss: 2.4324309825897217 | CLS Loss: 0.027080515399575233\n",
      "Epoch 145 / 200 | iteration 150 / 171 | Total Loss: 2.3789286613464355 | KNN Loss: 2.3669607639312744 | CLS Loss: 0.011967875994741917\n",
      "Epoch 145 / 200 | iteration 160 / 171 | Total Loss: 2.3613548278808594 | KNN Loss: 2.3513708114624023 | CLS Loss: 0.009983927942812443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 / 200 | iteration 170 / 171 | Total Loss: 2.362464189529419 | KNN Loss: 2.3520984649658203 | CLS Loss: 0.010365644469857216\n",
      "Epoch: 145, Loss: 2.4098, Train: 0.9973, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 146 / 200 | iteration 0 / 171 | Total Loss: 2.4505908489227295 | KNN Loss: 2.4496190547943115 | CLS Loss: 0.0009716874337755144\n",
      "Epoch 146 / 200 | iteration 10 / 171 | Total Loss: 2.373491048812866 | KNN Loss: 2.371509313583374 | CLS Loss: 0.001981850014999509\n",
      "Epoch 146 / 200 | iteration 20 / 171 | Total Loss: 2.424107074737549 | KNN Loss: 2.418142318725586 | CLS Loss: 0.005964841693639755\n",
      "Epoch 146 / 200 | iteration 30 / 171 | Total Loss: 2.3825972080230713 | KNN Loss: 2.370879650115967 | CLS Loss: 0.011717663146555424\n",
      "Epoch 146 / 200 | iteration 40 / 171 | Total Loss: 2.4214975833892822 | KNN Loss: 2.411771774291992 | CLS Loss: 0.009725798852741718\n",
      "Epoch 146 / 200 | iteration 50 / 171 | Total Loss: 2.3817975521087646 | KNN Loss: 2.377549171447754 | CLS Loss: 0.0042483326978981495\n",
      "Epoch 146 / 200 | iteration 60 / 171 | Total Loss: 2.427449941635132 | KNN Loss: 2.4140801429748535 | CLS Loss: 0.013369821012020111\n",
      "Epoch 146 / 200 | iteration 70 / 171 | Total Loss: 2.3914544582366943 | KNN Loss: 2.388770580291748 | CLS Loss: 0.0026838858611881733\n",
      "Epoch 146 / 200 | iteration 80 / 171 | Total Loss: 2.4358303546905518 | KNN Loss: 2.4256885051727295 | CLS Loss: 0.010141963139176369\n",
      "Epoch 146 / 200 | iteration 90 / 171 | Total Loss: 2.4196150302886963 | KNN Loss: 2.401787042617798 | CLS Loss: 0.017827901989221573\n",
      "Epoch 146 / 200 | iteration 100 / 171 | Total Loss: 2.418428421020508 | KNN Loss: 2.385084867477417 | CLS Loss: 0.03334346413612366\n",
      "Epoch 146 / 200 | iteration 110 / 171 | Total Loss: 2.4017908573150635 | KNN Loss: 2.389427900314331 | CLS Loss: 0.012363005429506302\n",
      "Epoch 146 / 200 | iteration 120 / 171 | Total Loss: 2.4276621341705322 | KNN Loss: 2.4146833419799805 | CLS Loss: 0.012978898361325264\n",
      "Epoch 146 / 200 | iteration 130 / 171 | Total Loss: 2.397353172302246 | KNN Loss: 2.3928775787353516 | CLS Loss: 0.004475641530007124\n",
      "Epoch 146 / 200 | iteration 140 / 171 | Total Loss: 2.375983715057373 | KNN Loss: 2.372476577758789 | CLS Loss: 0.0035070786252617836\n",
      "Epoch 146 / 200 | iteration 150 / 171 | Total Loss: 2.416187047958374 | KNN Loss: 2.413759469985962 | CLS Loss: 0.0024276296608150005\n",
      "Epoch 146 / 200 | iteration 160 / 171 | Total Loss: 2.3746538162231445 | KNN Loss: 2.3659253120422363 | CLS Loss: 0.008728409186005592\n",
      "Epoch 146 / 200 | iteration 170 / 171 | Total Loss: 2.4697084426879883 | KNN Loss: 2.451117515563965 | CLS Loss: 0.018591029569506645\n",
      "Epoch: 146, Loss: 2.4094, Train: 0.9946, Valid: 0.9844, Best: 0.9873\n",
      "Epoch 147 / 200 | iteration 0 / 171 | Total Loss: 2.41546630859375 | KNN Loss: 2.4063191413879395 | CLS Loss: 0.009147108532488346\n",
      "Epoch 147 / 200 | iteration 10 / 171 | Total Loss: 2.3574931621551514 | KNN Loss: 2.347992181777954 | CLS Loss: 0.009501030668616295\n",
      "Epoch 147 / 200 | iteration 20 / 171 | Total Loss: 2.414513111114502 | KNN Loss: 2.4112017154693604 | CLS Loss: 0.0033114722464233637\n",
      "Epoch 147 / 200 | iteration 30 / 171 | Total Loss: 2.4265224933624268 | KNN Loss: 2.415513038635254 | CLS Loss: 0.011009475216269493\n",
      "Epoch 147 / 200 | iteration 40 / 171 | Total Loss: 2.3804714679718018 | KNN Loss: 2.3642451763153076 | CLS Loss: 0.01622629165649414\n",
      "Epoch 147 / 200 | iteration 50 / 171 | Total Loss: 2.4209394454956055 | KNN Loss: 2.407910108566284 | CLS Loss: 0.013029259629547596\n",
      "Epoch 147 / 200 | iteration 60 / 171 | Total Loss: 2.411329984664917 | KNN Loss: 2.4044010639190674 | CLS Loss: 0.006928952876478434\n",
      "Epoch 147 / 200 | iteration 70 / 171 | Total Loss: 2.4152731895446777 | KNN Loss: 2.3949577808380127 | CLS Loss: 0.020315447822213173\n",
      "Epoch 147 / 200 | iteration 80 / 171 | Total Loss: 2.454329013824463 | KNN Loss: 2.44649338722229 | CLS Loss: 0.007835552096366882\n",
      "Epoch 147 / 200 | iteration 90 / 171 | Total Loss: 2.4208850860595703 | KNN Loss: 2.4163289070129395 | CLS Loss: 0.004556166473776102\n",
      "Epoch 147 / 200 | iteration 100 / 171 | Total Loss: 2.386674165725708 | KNN Loss: 2.3743510246276855 | CLS Loss: 0.012323151342570782\n",
      "Epoch 147 / 200 | iteration 110 / 171 | Total Loss: 2.416593074798584 | KNN Loss: 2.408912181854248 | CLS Loss: 0.007680934388190508\n",
      "Epoch 147 / 200 | iteration 120 / 171 | Total Loss: 2.4488441944122314 | KNN Loss: 2.445408582687378 | CLS Loss: 0.0034355458337813616\n",
      "Epoch 147 / 200 | iteration 130 / 171 | Total Loss: 2.434980869293213 | KNN Loss: 2.4159789085388184 | CLS Loss: 0.019001901149749756\n",
      "Epoch 147 / 200 | iteration 140 / 171 | Total Loss: 2.362346649169922 | KNN Loss: 2.361527442932129 | CLS Loss: 0.0008191170636564493\n",
      "Epoch 147 / 200 | iteration 150 / 171 | Total Loss: 2.442068099975586 | KNN Loss: 2.4364304542541504 | CLS Loss: 0.005637663882225752\n",
      "Epoch 147 / 200 | iteration 160 / 171 | Total Loss: 2.43192720413208 | KNN Loss: 2.4252567291259766 | CLS Loss: 0.006670594215393066\n",
      "Epoch 147 / 200 | iteration 170 / 171 | Total Loss: 2.3977551460266113 | KNN Loss: 2.380803108215332 | CLS Loss: 0.016951942816376686\n",
      "Epoch: 147, Loss: 2.4083, Train: 0.9969, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 148 / 200 | iteration 0 / 171 | Total Loss: 2.4166817665100098 | KNN Loss: 2.4155335426330566 | CLS Loss: 0.0011482249246910214\n",
      "Epoch 148 / 200 | iteration 10 / 171 | Total Loss: 2.432730197906494 | KNN Loss: 2.425252676010132 | CLS Loss: 0.0074774762615561485\n",
      "Epoch 148 / 200 | iteration 20 / 171 | Total Loss: 2.4276037216186523 | KNN Loss: 2.419755697250366 | CLS Loss: 0.007847960107028484\n",
      "Epoch 148 / 200 | iteration 30 / 171 | Total Loss: 2.44773006439209 | KNN Loss: 2.440788507461548 | CLS Loss: 0.006941536907106638\n",
      "Epoch 148 / 200 | iteration 40 / 171 | Total Loss: 2.3954405784606934 | KNN Loss: 2.3874759674072266 | CLS Loss: 0.00796471070498228\n",
      "Epoch 148 / 200 | iteration 50 / 171 | Total Loss: 2.3682162761688232 | KNN Loss: 2.367438316345215 | CLS Loss: 0.0007778789731673896\n",
      "Epoch 148 / 200 | iteration 60 / 171 | Total Loss: 2.4132018089294434 | KNN Loss: 2.391230344772339 | CLS Loss: 0.021971559152007103\n",
      "Epoch 148 / 200 | iteration 70 / 171 | Total Loss: 2.3953473567962646 | KNN Loss: 2.384476661682129 | CLS Loss: 0.010870619677007198\n",
      "Epoch 148 / 200 | iteration 80 / 171 | Total Loss: 2.441474676132202 | KNN Loss: 2.4271585941314697 | CLS Loss: 0.014316166751086712\n",
      "Epoch 148 / 200 | iteration 90 / 171 | Total Loss: 2.378298044204712 | KNN Loss: 2.3748576641082764 | CLS Loss: 0.0034402867313474417\n",
      "Epoch 148 / 200 | iteration 100 / 171 | Total Loss: 2.3737332820892334 | KNN Loss: 2.3669755458831787 | CLS Loss: 0.00675775483250618\n",
      "Epoch 148 / 200 | iteration 110 / 171 | Total Loss: 2.364637851715088 | KNN Loss: 2.363365888595581 | CLS Loss: 0.001272026915103197\n",
      "Epoch 148 / 200 | iteration 120 / 171 | Total Loss: 2.386566400527954 | KNN Loss: 2.3849825859069824 | CLS Loss: 0.0015837523387745023\n",
      "Epoch 148 / 200 | iteration 130 / 171 | Total Loss: 2.3592441082000732 | KNN Loss: 2.3493306636810303 | CLS Loss: 0.009913414716720581\n",
      "Epoch 148 / 200 | iteration 140 / 171 | Total Loss: 2.39206600189209 | KNN Loss: 2.380387306213379 | CLS Loss: 0.011678630486130714\n",
      "Epoch 148 / 200 | iteration 150 / 171 | Total Loss: 2.409273147583008 | KNN Loss: 2.4055821895599365 | CLS Loss: 0.0036908667534589767\n",
      "Epoch 148 / 200 | iteration 160 / 171 | Total Loss: 2.423527240753174 | KNN Loss: 2.409062147140503 | CLS Loss: 0.014465024694800377\n",
      "Epoch 148 / 200 | iteration 170 / 171 | Total Loss: 2.3885464668273926 | KNN Loss: 2.38460636138916 | CLS Loss: 0.00394020089879632\n",
      "Epoch: 148, Loss: 2.4049, Train: 0.9969, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 149 / 200 | iteration 0 / 171 | Total Loss: 2.4161524772644043 | KNN Loss: 2.4123525619506836 | CLS Loss: 0.00379999540746212\n",
      "Epoch 149 / 200 | iteration 10 / 171 | Total Loss: 2.4818878173828125 | KNN Loss: 2.479691505432129 | CLS Loss: 0.0021962926257401705\n",
      "Epoch 149 / 200 | iteration 20 / 171 | Total Loss: 2.400728225708008 | KNN Loss: 2.357816457748413 | CLS Loss: 0.04291166365146637\n",
      "Epoch 149 / 200 | iteration 30 / 171 | Total Loss: 2.4153151512145996 | KNN Loss: 2.4100818634033203 | CLS Loss: 0.005233308300375938\n",
      "Epoch 149 / 200 | iteration 40 / 171 | Total Loss: 2.403233766555786 | KNN Loss: 2.384538173675537 | CLS Loss: 0.018695570528507233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 / 200 | iteration 50 / 171 | Total Loss: 2.4287261962890625 | KNN Loss: 2.4239253997802734 | CLS Loss: 0.004800730384886265\n",
      "Epoch 149 / 200 | iteration 60 / 171 | Total Loss: 2.3656692504882812 | KNN Loss: 2.362079381942749 | CLS Loss: 0.0035899209324270487\n",
      "Epoch 149 / 200 | iteration 70 / 171 | Total Loss: 2.3981258869171143 | KNN Loss: 2.394566774368286 | CLS Loss: 0.0035590820480138063\n",
      "Epoch 149 / 200 | iteration 80 / 171 | Total Loss: 2.4138548374176025 | KNN Loss: 2.39920973777771 | CLS Loss: 0.014645061455667019\n",
      "Epoch 149 / 200 | iteration 90 / 171 | Total Loss: 2.4016120433807373 | KNN Loss: 2.3813247680664062 | CLS Loss: 0.020287370309233665\n",
      "Epoch 149 / 200 | iteration 100 / 171 | Total Loss: 2.4095265865325928 | KNN Loss: 2.4061920642852783 | CLS Loss: 0.003334427485242486\n",
      "Epoch 149 / 200 | iteration 110 / 171 | Total Loss: 2.385101556777954 | KNN Loss: 2.381878614425659 | CLS Loss: 0.0032228983473032713\n",
      "Epoch 149 / 200 | iteration 120 / 171 | Total Loss: 2.410022020339966 | KNN Loss: 2.4054036140441895 | CLS Loss: 0.004618485923856497\n",
      "Epoch 149 / 200 | iteration 130 / 171 | Total Loss: 2.4049274921417236 | KNN Loss: 2.3977458477020264 | CLS Loss: 0.0071816761046648026\n",
      "Epoch 149 / 200 | iteration 140 / 171 | Total Loss: 2.3918681144714355 | KNN Loss: 2.382775068283081 | CLS Loss: 0.00909312255680561\n",
      "Epoch 149 / 200 | iteration 150 / 171 | Total Loss: 2.421623468399048 | KNN Loss: 2.419327974319458 | CLS Loss: 0.0022953825537115335\n",
      "Epoch 149 / 200 | iteration 160 / 171 | Total Loss: 2.3955934047698975 | KNN Loss: 2.38911509513855 | CLS Loss: 0.006478324066847563\n",
      "Epoch 149 / 200 | iteration 170 / 171 | Total Loss: 2.4225120544433594 | KNN Loss: 2.4074783325195312 | CLS Loss: 0.015033688396215439\n",
      "Epoch: 149, Loss: 2.4108, Train: 0.9973, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 150 / 200 | iteration 0 / 171 | Total Loss: 2.429051399230957 | KNN Loss: 2.4271886348724365 | CLS Loss: 0.001862683449871838\n",
      "Epoch 150 / 200 | iteration 10 / 171 | Total Loss: 2.403090476989746 | KNN Loss: 2.3997740745544434 | CLS Loss: 0.003316494869068265\n",
      "Epoch 150 / 200 | iteration 20 / 171 | Total Loss: 2.3874106407165527 | KNN Loss: 2.3826675415039062 | CLS Loss: 0.004743094556033611\n",
      "Epoch 150 / 200 | iteration 30 / 171 | Total Loss: 2.4300377368927 | KNN Loss: 2.4023325443267822 | CLS Loss: 0.027705177664756775\n",
      "Epoch 150 / 200 | iteration 40 / 171 | Total Loss: 2.4346776008605957 | KNN Loss: 2.4247729778289795 | CLS Loss: 0.009904555976390839\n",
      "Epoch 150 / 200 | iteration 50 / 171 | Total Loss: 2.4546921253204346 | KNN Loss: 2.4269285202026367 | CLS Loss: 0.027763502672314644\n",
      "Epoch 150 / 200 | iteration 60 / 171 | Total Loss: 2.426464319229126 | KNN Loss: 2.4026222229003906 | CLS Loss: 0.023842066526412964\n",
      "Epoch 150 / 200 | iteration 70 / 171 | Total Loss: 2.3820767402648926 | KNN Loss: 2.3735713958740234 | CLS Loss: 0.008505262434482574\n",
      "Epoch 150 / 200 | iteration 80 / 171 | Total Loss: 2.3862764835357666 | KNN Loss: 2.3820481300354004 | CLS Loss: 0.004228448960930109\n",
      "Epoch 150 / 200 | iteration 90 / 171 | Total Loss: 2.390585422515869 | KNN Loss: 2.3810296058654785 | CLS Loss: 0.009555750526487827\n",
      "Epoch 150 / 200 | iteration 100 / 171 | Total Loss: 2.3691558837890625 | KNN Loss: 2.361851215362549 | CLS Loss: 0.007304674480110407\n",
      "Epoch 150 / 200 | iteration 110 / 171 | Total Loss: 2.4237520694732666 | KNN Loss: 2.4034106731414795 | CLS Loss: 0.020341310650110245\n",
      "Epoch 150 / 200 | iteration 120 / 171 | Total Loss: 2.4175102710723877 | KNN Loss: 2.4087681770324707 | CLS Loss: 0.008742153644561768\n",
      "Epoch 150 / 200 | iteration 130 / 171 | Total Loss: 2.420351266860962 | KNN Loss: 2.404547929763794 | CLS Loss: 0.015803340822458267\n",
      "Epoch 150 / 200 | iteration 140 / 171 | Total Loss: 2.4215545654296875 | KNN Loss: 2.4198966026306152 | CLS Loss: 0.0016580319497734308\n",
      "Epoch 150 / 200 | iteration 150 / 171 | Total Loss: 2.3994979858398438 | KNN Loss: 2.389279365539551 | CLS Loss: 0.010218547657132149\n",
      "Epoch 150 / 200 | iteration 160 / 171 | Total Loss: 2.4228525161743164 | KNN Loss: 2.413923740386963 | CLS Loss: 0.008928745053708553\n",
      "Epoch 150 / 200 | iteration 170 / 171 | Total Loss: 2.4288299083709717 | KNN Loss: 2.4211342334747314 | CLS Loss: 0.007695712149143219\n",
      "Epoch: 150, Loss: 2.4059, Train: 0.9974, Valid: 0.9871, Best: 0.9873\n",
      "Epoch 151 / 200 | iteration 0 / 171 | Total Loss: 2.387491464614868 | KNN Loss: 2.3861188888549805 | CLS Loss: 0.0013725290773436427\n",
      "Epoch 151 / 200 | iteration 10 / 171 | Total Loss: 2.4082229137420654 | KNN Loss: 2.4022226333618164 | CLS Loss: 0.006000255234539509\n",
      "Epoch 151 / 200 | iteration 20 / 171 | Total Loss: 2.445643663406372 | KNN Loss: 2.440187931060791 | CLS Loss: 0.005455851089209318\n",
      "Epoch 151 / 200 | iteration 30 / 171 | Total Loss: 2.4043569564819336 | KNN Loss: 2.396975517272949 | CLS Loss: 0.00738146249204874\n",
      "Epoch 151 / 200 | iteration 40 / 171 | Total Loss: 2.405740261077881 | KNN Loss: 2.4010791778564453 | CLS Loss: 0.004661155864596367\n",
      "Epoch 151 / 200 | iteration 50 / 171 | Total Loss: 2.416110038757324 | KNN Loss: 2.4118664264678955 | CLS Loss: 0.004243577364832163\n",
      "Epoch 151 / 200 | iteration 60 / 171 | Total Loss: 2.418165922164917 | KNN Loss: 2.4088656902313232 | CLS Loss: 0.009300126694142818\n",
      "Epoch 151 / 200 | iteration 70 / 171 | Total Loss: 2.4243812561035156 | KNN Loss: 2.41693377494812 | CLS Loss: 0.007447369396686554\n",
      "Epoch 151 / 200 | iteration 80 / 171 | Total Loss: 2.3785688877105713 | KNN Loss: 2.3725781440734863 | CLS Loss: 0.005990675650537014\n",
      "Epoch 151 / 200 | iteration 90 / 171 | Total Loss: 2.4316399097442627 | KNN Loss: 2.4274888038635254 | CLS Loss: 0.0041510360315442085\n",
      "Epoch 151 / 200 | iteration 100 / 171 | Total Loss: 2.3995368480682373 | KNN Loss: 2.3987693786621094 | CLS Loss: 0.0007675836677663028\n",
      "Epoch 151 / 200 | iteration 110 / 171 | Total Loss: 2.4153366088867188 | KNN Loss: 2.4139437675476074 | CLS Loss: 0.0013929104898124933\n",
      "Epoch 151 / 200 | iteration 120 / 171 | Total Loss: 2.424423933029175 | KNN Loss: 2.3969106674194336 | CLS Loss: 0.02751336432993412\n",
      "Epoch 151 / 200 | iteration 130 / 171 | Total Loss: 2.4118340015411377 | KNN Loss: 2.4003217220306396 | CLS Loss: 0.01151231024414301\n",
      "Epoch 151 / 200 | iteration 140 / 171 | Total Loss: 2.4370646476745605 | KNN Loss: 2.4127299785614014 | CLS Loss: 0.024334730580449104\n",
      "Epoch 151 / 200 | iteration 150 / 171 | Total Loss: 2.3776488304138184 | KNN Loss: 2.3675315380096436 | CLS Loss: 0.010117310099303722\n",
      "Epoch 151 / 200 | iteration 160 / 171 | Total Loss: 2.3917958736419678 | KNN Loss: 2.3866775035858154 | CLS Loss: 0.005118369124829769\n",
      "Epoch 151 / 200 | iteration 170 / 171 | Total Loss: 2.3939759731292725 | KNN Loss: 2.3849987983703613 | CLS Loss: 0.008977084420621395\n",
      "Epoch: 151, Loss: 2.4063, Train: 0.9969, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 152 / 200 | iteration 0 / 171 | Total Loss: 2.390453338623047 | KNN Loss: 2.3869009017944336 | CLS Loss: 0.003552427049726248\n",
      "Epoch 152 / 200 | iteration 10 / 171 | Total Loss: 2.424635648727417 | KNN Loss: 2.421586751937866 | CLS Loss: 0.003049009246751666\n",
      "Epoch 152 / 200 | iteration 20 / 171 | Total Loss: 2.4230148792266846 | KNN Loss: 2.409374237060547 | CLS Loss: 0.013640756718814373\n",
      "Epoch 152 / 200 | iteration 30 / 171 | Total Loss: 2.375270128250122 | KNN Loss: 2.361189126968384 | CLS Loss: 0.014081104658544064\n",
      "Epoch 152 / 200 | iteration 40 / 171 | Total Loss: 2.400477409362793 | KNN Loss: 2.3986263275146484 | CLS Loss: 0.001851053792051971\n",
      "Epoch 152 / 200 | iteration 50 / 171 | Total Loss: 2.399909019470215 | KNN Loss: 2.383019208908081 | CLS Loss: 0.016889788210392\n",
      "Epoch 152 / 200 | iteration 60 / 171 | Total Loss: 2.403594493865967 | KNN Loss: 2.4008779525756836 | CLS Loss: 0.002716576447710395\n",
      "Epoch 152 / 200 | iteration 70 / 171 | Total Loss: 2.412086248397827 | KNN Loss: 2.40155291557312 | CLS Loss: 0.010533344931900501\n",
      "Epoch 152 / 200 | iteration 80 / 171 | Total Loss: 2.402259111404419 | KNN Loss: 2.3902337551116943 | CLS Loss: 0.012025438249111176\n",
      "Epoch 152 / 200 | iteration 90 / 171 | Total Loss: 2.4372498989105225 | KNN Loss: 2.4082136154174805 | CLS Loss: 0.029036201536655426\n",
      "Epoch 152 / 200 | iteration 100 / 171 | Total Loss: 2.406491279602051 | KNN Loss: 2.39888858795166 | CLS Loss: 0.0076026455499231815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 / 200 | iteration 110 / 171 | Total Loss: 2.420301675796509 | KNN Loss: 2.4019999504089355 | CLS Loss: 0.01830165460705757\n",
      "Epoch 152 / 200 | iteration 120 / 171 | Total Loss: 2.375483512878418 | KNN Loss: 2.3714241981506348 | CLS Loss: 0.004059280268847942\n",
      "Epoch 152 / 200 | iteration 130 / 171 | Total Loss: 2.406527042388916 | KNN Loss: 2.398822784423828 | CLS Loss: 0.007704178337007761\n",
      "Epoch 152 / 200 | iteration 140 / 171 | Total Loss: 2.4117586612701416 | KNN Loss: 2.3906869888305664 | CLS Loss: 0.02107161283493042\n",
      "Epoch 152 / 200 | iteration 150 / 171 | Total Loss: 2.4128150939941406 | KNN Loss: 2.404513120651245 | CLS Loss: 0.0083018708974123\n",
      "Epoch 152 / 200 | iteration 160 / 171 | Total Loss: 2.3998820781707764 | KNN Loss: 2.3982737064361572 | CLS Loss: 0.0016084040980786085\n",
      "Epoch 152 / 200 | iteration 170 / 171 | Total Loss: 2.40511417388916 | KNN Loss: 2.398831367492676 | CLS Loss: 0.00628284877166152\n",
      "Epoch: 152, Loss: 2.4084, Train: 0.9971, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 153 / 200 | iteration 0 / 171 | Total Loss: 2.3940823078155518 | KNN Loss: 2.37823748588562 | CLS Loss: 0.015844762325286865\n",
      "Epoch 153 / 200 | iteration 10 / 171 | Total Loss: 2.368379592895508 | KNN Loss: 2.367628574371338 | CLS Loss: 0.0007511172443628311\n",
      "Epoch 153 / 200 | iteration 20 / 171 | Total Loss: 2.3916015625 | KNN Loss: 2.3867874145507812 | CLS Loss: 0.004814257379621267\n",
      "Epoch 153 / 200 | iteration 30 / 171 | Total Loss: 2.4514927864074707 | KNN Loss: 2.4285032749176025 | CLS Loss: 0.022989487275481224\n",
      "Epoch 153 / 200 | iteration 40 / 171 | Total Loss: 2.4078991413116455 | KNN Loss: 2.394386053085327 | CLS Loss: 0.013513067737221718\n",
      "Epoch 153 / 200 | iteration 50 / 171 | Total Loss: 2.3853390216827393 | KNN Loss: 2.3830983638763428 | CLS Loss: 0.002240600995719433\n",
      "Epoch 153 / 200 | iteration 60 / 171 | Total Loss: 2.3930575847625732 | KNN Loss: 2.385892391204834 | CLS Loss: 0.007165237329900265\n",
      "Epoch 153 / 200 | iteration 70 / 171 | Total Loss: 2.3865721225738525 | KNN Loss: 2.382081985473633 | CLS Loss: 0.004490039311349392\n",
      "Epoch 153 / 200 | iteration 80 / 171 | Total Loss: 2.3694732189178467 | KNN Loss: 2.3656492233276367 | CLS Loss: 0.0038240922149270773\n",
      "Epoch 153 / 200 | iteration 90 / 171 | Total Loss: 2.3969898223876953 | KNN Loss: 2.393989086151123 | CLS Loss: 0.0030006919987499714\n",
      "Epoch 153 / 200 | iteration 100 / 171 | Total Loss: 2.3671011924743652 | KNN Loss: 2.3632967472076416 | CLS Loss: 0.003804490901529789\n",
      "Epoch 153 / 200 | iteration 110 / 171 | Total Loss: 2.4157283306121826 | KNN Loss: 2.4097087383270264 | CLS Loss: 0.006019688677042723\n",
      "Epoch 153 / 200 | iteration 120 / 171 | Total Loss: 2.443582057952881 | KNN Loss: 2.433304786682129 | CLS Loss: 0.010277326218783855\n",
      "Epoch 153 / 200 | iteration 130 / 171 | Total Loss: 2.4460296630859375 | KNN Loss: 2.4405596256256104 | CLS Loss: 0.005470056552439928\n",
      "Epoch 153 / 200 | iteration 140 / 171 | Total Loss: 2.4066007137298584 | KNN Loss: 2.3940041065216064 | CLS Loss: 0.012596705928444862\n",
      "Epoch 153 / 200 | iteration 150 / 171 | Total Loss: 2.402423143386841 | KNN Loss: 2.397881031036377 | CLS Loss: 0.004542153794318438\n",
      "Epoch 153 / 200 | iteration 160 / 171 | Total Loss: 2.4125611782073975 | KNN Loss: 2.40343976020813 | CLS Loss: 0.00912142638117075\n",
      "Epoch 153 / 200 | iteration 170 / 171 | Total Loss: 2.4004454612731934 | KNN Loss: 2.3929643630981445 | CLS Loss: 0.007481002248823643\n",
      "Epoch: 153, Loss: 2.4085, Train: 0.9971, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 154 / 200 | iteration 0 / 171 | Total Loss: 2.410571336746216 | KNN Loss: 2.4068524837493896 | CLS Loss: 0.0037188807036727667\n",
      "Epoch 154 / 200 | iteration 10 / 171 | Total Loss: 2.402689218521118 | KNN Loss: 2.399479389190674 | CLS Loss: 0.0032099296804517508\n",
      "Epoch 154 / 200 | iteration 20 / 171 | Total Loss: 2.3797621726989746 | KNN Loss: 2.370565414428711 | CLS Loss: 0.009196802973747253\n",
      "Epoch 154 / 200 | iteration 30 / 171 | Total Loss: 2.407257556915283 | KNN Loss: 2.3988306522369385 | CLS Loss: 0.008426797576248646\n",
      "Epoch 154 / 200 | iteration 40 / 171 | Total Loss: 2.3755764961242676 | KNN Loss: 2.3745839595794678 | CLS Loss: 0.0009924356127157807\n",
      "Epoch 154 / 200 | iteration 50 / 171 | Total Loss: 2.3799796104431152 | KNN Loss: 2.3773882389068604 | CLS Loss: 0.0025914208963513374\n",
      "Epoch 154 / 200 | iteration 60 / 171 | Total Loss: 2.488039016723633 | KNN Loss: 2.4856321811676025 | CLS Loss: 0.002406845800578594\n",
      "Epoch 154 / 200 | iteration 70 / 171 | Total Loss: 2.3978192806243896 | KNN Loss: 2.391310930252075 | CLS Loss: 0.006508320569992065\n",
      "Epoch 154 / 200 | iteration 80 / 171 | Total Loss: 2.4262027740478516 | KNN Loss: 2.4187679290771484 | CLS Loss: 0.007434861734509468\n",
      "Epoch 154 / 200 | iteration 90 / 171 | Total Loss: 2.396740674972534 | KNN Loss: 2.382706642150879 | CLS Loss: 0.014034034684300423\n",
      "Epoch 154 / 200 | iteration 100 / 171 | Total Loss: 2.4122869968414307 | KNN Loss: 2.3918213844299316 | CLS Loss: 0.02046569250524044\n",
      "Epoch 154 / 200 | iteration 110 / 171 | Total Loss: 2.3668079376220703 | KNN Loss: 2.36053466796875 | CLS Loss: 0.00627325102686882\n",
      "Epoch 154 / 200 | iteration 120 / 171 | Total Loss: 2.415842294692993 | KNN Loss: 2.4124984741210938 | CLS Loss: 0.0033437300007790327\n",
      "Epoch 154 / 200 | iteration 130 / 171 | Total Loss: 2.484851598739624 | KNN Loss: 2.458449125289917 | CLS Loss: 0.026402566581964493\n",
      "Epoch 154 / 200 | iteration 140 / 171 | Total Loss: 2.4496562480926514 | KNN Loss: 2.4208664894104004 | CLS Loss: 0.028789836913347244\n",
      "Epoch 154 / 200 | iteration 150 / 171 | Total Loss: 2.4165878295898438 | KNN Loss: 2.385519027709961 | CLS Loss: 0.03106876276433468\n",
      "Epoch 154 / 200 | iteration 160 / 171 | Total Loss: 2.438687562942505 | KNN Loss: 2.42087984085083 | CLS Loss: 0.017807774245738983\n",
      "Epoch 154 / 200 | iteration 170 / 171 | Total Loss: 2.3900792598724365 | KNN Loss: 2.363502264022827 | CLS Loss: 0.026577053591609\n",
      "Epoch: 154, Loss: 2.4085, Train: 0.9969, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 155 / 200 | iteration 0 / 171 | Total Loss: 2.4536452293395996 | KNN Loss: 2.4330010414123535 | CLS Loss: 0.02064412832260132\n",
      "Epoch 155 / 200 | iteration 10 / 171 | Total Loss: 2.4099392890930176 | KNN Loss: 2.3846259117126465 | CLS Loss: 0.02531338855624199\n",
      "Epoch 155 / 200 | iteration 20 / 171 | Total Loss: 2.423691749572754 | KNN Loss: 2.4213767051696777 | CLS Loss: 0.0023150283377617598\n",
      "Epoch 155 / 200 | iteration 30 / 171 | Total Loss: 2.3918538093566895 | KNN Loss: 2.3813178539276123 | CLS Loss: 0.01053586881607771\n",
      "Epoch 155 / 200 | iteration 40 / 171 | Total Loss: 2.422283172607422 | KNN Loss: 2.4070653915405273 | CLS Loss: 0.015217708423733711\n",
      "Epoch 155 / 200 | iteration 50 / 171 | Total Loss: 2.3900532722473145 | KNN Loss: 2.3842849731445312 | CLS Loss: 0.005768365692347288\n",
      "Epoch 155 / 200 | iteration 60 / 171 | Total Loss: 2.37691068649292 | KNN Loss: 2.3751587867736816 | CLS Loss: 0.0017519493121653795\n",
      "Epoch 155 / 200 | iteration 70 / 171 | Total Loss: 2.3873958587646484 | KNN Loss: 2.385382652282715 | CLS Loss: 0.002013307297602296\n",
      "Epoch 155 / 200 | iteration 80 / 171 | Total Loss: 2.4085023403167725 | KNN Loss: 2.40051531791687 | CLS Loss: 0.007987137883901596\n",
      "Epoch 155 / 200 | iteration 90 / 171 | Total Loss: 2.411757707595825 | KNN Loss: 2.39699387550354 | CLS Loss: 0.014763803221285343\n",
      "Epoch 155 / 200 | iteration 100 / 171 | Total Loss: 2.412595272064209 | KNN Loss: 2.409787178039551 | CLS Loss: 0.002807997865602374\n",
      "Epoch 155 / 200 | iteration 110 / 171 | Total Loss: 2.3962862491607666 | KNN Loss: 2.3897769451141357 | CLS Loss: 0.006509202532470226\n",
      "Epoch 155 / 200 | iteration 120 / 171 | Total Loss: 2.4432806968688965 | KNN Loss: 2.4403748512268066 | CLS Loss: 0.002905776724219322\n",
      "Epoch 155 / 200 | iteration 130 / 171 | Total Loss: 2.4245758056640625 | KNN Loss: 2.4168460369110107 | CLS Loss: 0.007729885168373585\n",
      "Epoch 155 / 200 | iteration 140 / 171 | Total Loss: 2.401449203491211 | KNN Loss: 2.381368398666382 | CLS Loss: 0.020080823451280594\n",
      "Epoch 155 / 200 | iteration 150 / 171 | Total Loss: 2.478679895401001 | KNN Loss: 2.460134983062744 | CLS Loss: 0.01854494959115982\n",
      "Epoch 155 / 200 | iteration 160 / 171 | Total Loss: 2.4120733737945557 | KNN Loss: 2.398183584213257 | CLS Loss: 0.013889721594750881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 / 200 | iteration 170 / 171 | Total Loss: 2.4034264087677 | KNN Loss: 2.3831756114959717 | CLS Loss: 0.020250700414180756\n",
      "Epoch: 155, Loss: 2.4100, Train: 0.9973, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 156 / 200 | iteration 0 / 171 | Total Loss: 2.4005753993988037 | KNN Loss: 2.3992385864257812 | CLS Loss: 0.0013368421932682395\n",
      "Epoch 156 / 200 | iteration 10 / 171 | Total Loss: 2.4437615871429443 | KNN Loss: 2.441312789916992 | CLS Loss: 0.0024488456547260284\n",
      "Epoch 156 / 200 | iteration 20 / 171 | Total Loss: 2.394867181777954 | KNN Loss: 2.3931117057800293 | CLS Loss: 0.0017554920632392168\n",
      "Epoch 156 / 200 | iteration 30 / 171 | Total Loss: 2.3774962425231934 | KNN Loss: 2.3681440353393555 | CLS Loss: 0.00935214851051569\n",
      "Epoch 156 / 200 | iteration 40 / 171 | Total Loss: 2.3658230304718018 | KNN Loss: 2.3592936992645264 | CLS Loss: 0.006529365200549364\n",
      "Epoch 156 / 200 | iteration 50 / 171 | Total Loss: 2.388507604598999 | KNN Loss: 2.3818066120147705 | CLS Loss: 0.006700947415083647\n",
      "Epoch 156 / 200 | iteration 60 / 171 | Total Loss: 2.4143970012664795 | KNN Loss: 2.4104926586151123 | CLS Loss: 0.003904409008100629\n",
      "Epoch 156 / 200 | iteration 70 / 171 | Total Loss: 2.4214346408843994 | KNN Loss: 2.403339147567749 | CLS Loss: 0.01809549704194069\n",
      "Epoch 156 / 200 | iteration 80 / 171 | Total Loss: 2.409420967102051 | KNN Loss: 2.382822036743164 | CLS Loss: 0.026598824188113213\n",
      "Epoch 156 / 200 | iteration 90 / 171 | Total Loss: 2.4242022037506104 | KNN Loss: 2.4167463779449463 | CLS Loss: 0.007455851417034864\n",
      "Epoch 156 / 200 | iteration 100 / 171 | Total Loss: 2.4111757278442383 | KNN Loss: 2.396327018737793 | CLS Loss: 0.014848743565380573\n",
      "Epoch 156 / 200 | iteration 110 / 171 | Total Loss: 2.449284791946411 | KNN Loss: 2.4427456855773926 | CLS Loss: 0.006539121735841036\n",
      "Epoch 156 / 200 | iteration 120 / 171 | Total Loss: 2.3928475379943848 | KNN Loss: 2.3820462226867676 | CLS Loss: 0.010801352560520172\n",
      "Epoch 156 / 200 | iteration 130 / 171 | Total Loss: 2.4078547954559326 | KNN Loss: 2.378862142562866 | CLS Loss: 0.028992583975195885\n",
      "Epoch 156 / 200 | iteration 140 / 171 | Total Loss: 2.402801513671875 | KNN Loss: 2.3864777088165283 | CLS Loss: 0.016323840245604515\n",
      "Epoch 156 / 200 | iteration 150 / 171 | Total Loss: 2.4002745151519775 | KNN Loss: 2.3857851028442383 | CLS Loss: 0.014489476568996906\n",
      "Epoch 156 / 200 | iteration 160 / 171 | Total Loss: 2.3914475440979004 | KNN Loss: 2.3876891136169434 | CLS Loss: 0.003758514765650034\n",
      "Epoch 156 / 200 | iteration 170 / 171 | Total Loss: 2.4077110290527344 | KNN Loss: 2.395615577697754 | CLS Loss: 0.012095564976334572\n",
      "Epoch: 156, Loss: 2.4099, Train: 0.9965, Valid: 0.9850, Best: 0.9873\n",
      "Epoch 157 / 200 | iteration 0 / 171 | Total Loss: 2.4113540649414062 | KNN Loss: 2.4062888622283936 | CLS Loss: 0.005065237637609243\n",
      "Epoch 157 / 200 | iteration 10 / 171 | Total Loss: 2.3940768241882324 | KNN Loss: 2.362757921218872 | CLS Loss: 0.031318992376327515\n",
      "Epoch 157 / 200 | iteration 20 / 171 | Total Loss: 2.4167208671569824 | KNN Loss: 2.4076218605041504 | CLS Loss: 0.00909893773496151\n",
      "Epoch 157 / 200 | iteration 30 / 171 | Total Loss: 2.397442102432251 | KNN Loss: 2.3919999599456787 | CLS Loss: 0.005442250054329634\n",
      "Epoch 157 / 200 | iteration 40 / 171 | Total Loss: 2.392352342605591 | KNN Loss: 2.387481927871704 | CLS Loss: 0.0048705157823860645\n",
      "Epoch 157 / 200 | iteration 50 / 171 | Total Loss: 2.3745615482330322 | KNN Loss: 2.3697638511657715 | CLS Loss: 0.004797779954969883\n",
      "Epoch 157 / 200 | iteration 60 / 171 | Total Loss: 2.382885694503784 | KNN Loss: 2.375581979751587 | CLS Loss: 0.007303665392100811\n",
      "Epoch 157 / 200 | iteration 70 / 171 | Total Loss: 2.3660221099853516 | KNN Loss: 2.357649326324463 | CLS Loss: 0.008372758515179157\n",
      "Epoch 157 / 200 | iteration 80 / 171 | Total Loss: 2.404935121536255 | KNN Loss: 2.3842339515686035 | CLS Loss: 0.02070128172636032\n",
      "Epoch 157 / 200 | iteration 90 / 171 | Total Loss: 2.4299654960632324 | KNN Loss: 2.4283013343811035 | CLS Loss: 0.0016642218688502908\n",
      "Epoch 157 / 200 | iteration 100 / 171 | Total Loss: 2.428807497024536 | KNN Loss: 2.4081785678863525 | CLS Loss: 0.020628971979022026\n",
      "Epoch 157 / 200 | iteration 110 / 171 | Total Loss: 2.3615152835845947 | KNN Loss: 2.356397867202759 | CLS Loss: 0.005117441993206739\n",
      "Epoch 157 / 200 | iteration 120 / 171 | Total Loss: 2.404431104660034 | KNN Loss: 2.384997844696045 | CLS Loss: 0.01943322643637657\n",
      "Epoch 157 / 200 | iteration 130 / 171 | Total Loss: 2.4074866771698 | KNN Loss: 2.3952102661132812 | CLS Loss: 0.012276461347937584\n",
      "Epoch 157 / 200 | iteration 140 / 171 | Total Loss: 2.4382762908935547 | KNN Loss: 2.4343624114990234 | CLS Loss: 0.00391396414488554\n",
      "Epoch 157 / 200 | iteration 150 / 171 | Total Loss: 2.4383058547973633 | KNN Loss: 2.4291248321533203 | CLS Loss: 0.009181054309010506\n",
      "Epoch 157 / 200 | iteration 160 / 171 | Total Loss: 2.395177125930786 | KNN Loss: 2.388214588165283 | CLS Loss: 0.006962609477341175\n",
      "Epoch 157 / 200 | iteration 170 / 171 | Total Loss: 2.398334503173828 | KNN Loss: 2.377509593963623 | CLS Loss: 0.020824972540140152\n",
      "Epoch: 157, Loss: 2.4080, Train: 0.9979, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 158 / 200 | iteration 0 / 171 | Total Loss: 2.394562005996704 | KNN Loss: 2.3894143104553223 | CLS Loss: 0.005147664342075586\n",
      "Epoch 158 / 200 | iteration 10 / 171 | Total Loss: 2.4148716926574707 | KNN Loss: 2.3998353481292725 | CLS Loss: 0.015036439523100853\n",
      "Epoch 158 / 200 | iteration 20 / 171 | Total Loss: 2.4231858253479004 | KNN Loss: 2.395056962966919 | CLS Loss: 0.02812887914478779\n",
      "Epoch 158 / 200 | iteration 30 / 171 | Total Loss: 2.3958041667938232 | KNN Loss: 2.3860511779785156 | CLS Loss: 0.009752967394888401\n",
      "Epoch 158 / 200 | iteration 40 / 171 | Total Loss: 2.4104349613189697 | KNN Loss: 2.3904659748077393 | CLS Loss: 0.019968973472714424\n",
      "Epoch 158 / 200 | iteration 50 / 171 | Total Loss: 2.3951995372772217 | KNN Loss: 2.385122060775757 | CLS Loss: 0.010077366605401039\n",
      "Epoch 158 / 200 | iteration 60 / 171 | Total Loss: 2.387895345687866 | KNN Loss: 2.3796772956848145 | CLS Loss: 0.008218011818826199\n",
      "Epoch 158 / 200 | iteration 70 / 171 | Total Loss: 2.44736909866333 | KNN Loss: 2.442002534866333 | CLS Loss: 0.00536651024594903\n",
      "Epoch 158 / 200 | iteration 80 / 171 | Total Loss: 2.423637866973877 | KNN Loss: 2.4160773754119873 | CLS Loss: 0.007560498546808958\n",
      "Epoch 158 / 200 | iteration 90 / 171 | Total Loss: 2.4122471809387207 | KNN Loss: 2.407802104949951 | CLS Loss: 0.004445004742592573\n",
      "Epoch 158 / 200 | iteration 100 / 171 | Total Loss: 2.4115147590637207 | KNN Loss: 2.401428461074829 | CLS Loss: 0.010086257010698318\n",
      "Epoch 158 / 200 | iteration 110 / 171 | Total Loss: 2.389618396759033 | KNN Loss: 2.3834736347198486 | CLS Loss: 0.006144762970507145\n",
      "Epoch 158 / 200 | iteration 120 / 171 | Total Loss: 2.398864507675171 | KNN Loss: 2.3962244987487793 | CLS Loss: 0.0026399886701256037\n",
      "Epoch 158 / 200 | iteration 130 / 171 | Total Loss: 2.403027296066284 | KNN Loss: 2.399235486984253 | CLS Loss: 0.0037918193265795708\n",
      "Epoch 158 / 200 | iteration 140 / 171 | Total Loss: 2.4623215198516846 | KNN Loss: 2.437741279602051 | CLS Loss: 0.02458024211227894\n",
      "Epoch 158 / 200 | iteration 150 / 171 | Total Loss: 2.4409210681915283 | KNN Loss: 2.4382517337799072 | CLS Loss: 0.0026694436091929674\n",
      "Epoch 158 / 200 | iteration 160 / 171 | Total Loss: 2.4520647525787354 | KNN Loss: 2.4463722705841064 | CLS Loss: 0.005692511796951294\n",
      "Epoch 158 / 200 | iteration 170 / 171 | Total Loss: 2.4023139476776123 | KNN Loss: 2.3805627822875977 | CLS Loss: 0.02175113931298256\n",
      "Epoch: 158, Loss: 2.4086, Train: 0.9975, Valid: 0.9872, Best: 0.9873\n",
      "Epoch 159 / 200 | iteration 0 / 171 | Total Loss: 2.4048001766204834 | KNN Loss: 2.394641399383545 | CLS Loss: 0.010158698074519634\n",
      "Epoch 159 / 200 | iteration 10 / 171 | Total Loss: 2.3979015350341797 | KNN Loss: 2.3833231925964355 | CLS Loss: 0.01457828376442194\n",
      "Epoch 159 / 200 | iteration 20 / 171 | Total Loss: 2.453821897506714 | KNN Loss: 2.449449300765991 | CLS Loss: 0.004372591618448496\n",
      "Epoch 159 / 200 | iteration 30 / 171 | Total Loss: 2.409620523452759 | KNN Loss: 2.398402452468872 | CLS Loss: 0.011218106374144554\n",
      "Epoch 159 / 200 | iteration 40 / 171 | Total Loss: 2.355860710144043 | KNN Loss: 2.3440093994140625 | CLS Loss: 0.011851324699819088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 / 200 | iteration 50 / 171 | Total Loss: 2.4185779094696045 | KNN Loss: 2.4077422618865967 | CLS Loss: 0.0108357397839427\n",
      "Epoch 159 / 200 | iteration 60 / 171 | Total Loss: 2.423785924911499 | KNN Loss: 2.407517194747925 | CLS Loss: 0.016268765553832054\n",
      "Epoch 159 / 200 | iteration 70 / 171 | Total Loss: 2.415050506591797 | KNN Loss: 2.4125800132751465 | CLS Loss: 0.002470549661666155\n",
      "Epoch 159 / 200 | iteration 80 / 171 | Total Loss: 2.3834667205810547 | KNN Loss: 2.3739535808563232 | CLS Loss: 0.00951309222728014\n",
      "Epoch 159 / 200 | iteration 90 / 171 | Total Loss: 2.381997585296631 | KNN Loss: 2.379599094390869 | CLS Loss: 0.0023984508588910103\n",
      "Epoch 159 / 200 | iteration 100 / 171 | Total Loss: 2.4311444759368896 | KNN Loss: 2.4003872871398926 | CLS Loss: 0.03075719252228737\n",
      "Epoch 159 / 200 | iteration 110 / 171 | Total Loss: 2.4444899559020996 | KNN Loss: 2.4251363277435303 | CLS Loss: 0.019353697076439857\n",
      "Epoch 159 / 200 | iteration 120 / 171 | Total Loss: 2.4169538021087646 | KNN Loss: 2.4080095291137695 | CLS Loss: 0.008944342844188213\n",
      "Epoch 159 / 200 | iteration 130 / 171 | Total Loss: 2.4052467346191406 | KNN Loss: 2.3967738151550293 | CLS Loss: 0.00847291387617588\n",
      "Epoch 159 / 200 | iteration 140 / 171 | Total Loss: 2.3642117977142334 | KNN Loss: 2.3382601737976074 | CLS Loss: 0.025951595976948738\n",
      "Epoch 159 / 200 | iteration 150 / 171 | Total Loss: 2.392188787460327 | KNN Loss: 2.381124973297119 | CLS Loss: 0.011063779704272747\n",
      "Epoch 159 / 200 | iteration 160 / 171 | Total Loss: 2.3950443267822266 | KNN Loss: 2.3869693279266357 | CLS Loss: 0.008075050078332424\n",
      "Epoch 159 / 200 | iteration 170 / 171 | Total Loss: 2.411682367324829 | KNN Loss: 2.402627944946289 | CLS Loss: 0.009054304100573063\n",
      "Epoch: 159, Loss: 2.4081, Train: 0.9976, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 160 / 200 | iteration 0 / 171 | Total Loss: 2.3728270530700684 | KNN Loss: 2.370326519012451 | CLS Loss: 0.002500537782907486\n",
      "Epoch 160 / 200 | iteration 10 / 171 | Total Loss: 2.39406156539917 | KNN Loss: 2.390748977661133 | CLS Loss: 0.0033126387279480696\n",
      "Epoch 160 / 200 | iteration 20 / 171 | Total Loss: 2.4017114639282227 | KNN Loss: 2.400834321975708 | CLS Loss: 0.0008772558066993952\n",
      "Epoch 160 / 200 | iteration 30 / 171 | Total Loss: 2.4224929809570312 | KNN Loss: 2.421121120452881 | CLS Loss: 0.0013718926347792149\n",
      "Epoch 160 / 200 | iteration 40 / 171 | Total Loss: 2.3841519355773926 | KNN Loss: 2.382648468017578 | CLS Loss: 0.0015034923562780023\n",
      "Epoch 160 / 200 | iteration 50 / 171 | Total Loss: 2.4163665771484375 | KNN Loss: 2.40879487991333 | CLS Loss: 0.007571701426059008\n",
      "Epoch 160 / 200 | iteration 60 / 171 | Total Loss: 2.398895740509033 | KNN Loss: 2.3867318630218506 | CLS Loss: 0.012163776904344559\n",
      "Epoch 160 / 200 | iteration 70 / 171 | Total Loss: 2.4238905906677246 | KNN Loss: 2.4069747924804688 | CLS Loss: 0.016915874555706978\n",
      "Epoch 160 / 200 | iteration 80 / 171 | Total Loss: 2.3926026821136475 | KNN Loss: 2.3849666118621826 | CLS Loss: 0.007636020425707102\n",
      "Epoch 160 / 200 | iteration 90 / 171 | Total Loss: 2.423616647720337 | KNN Loss: 2.419574499130249 | CLS Loss: 0.004042035434395075\n",
      "Epoch 160 / 200 | iteration 100 / 171 | Total Loss: 2.41705060005188 | KNN Loss: 2.413978099822998 | CLS Loss: 0.0030724373646080494\n",
      "Epoch 160 / 200 | iteration 110 / 171 | Total Loss: 2.412550687789917 | KNN Loss: 2.404772996902466 | CLS Loss: 0.007777727209031582\n",
      "Epoch 160 / 200 | iteration 120 / 171 | Total Loss: 2.4313161373138428 | KNN Loss: 2.416759729385376 | CLS Loss: 0.01455636229366064\n",
      "Epoch 160 / 200 | iteration 130 / 171 | Total Loss: 2.3871757984161377 | KNN Loss: 2.3787670135498047 | CLS Loss: 0.00840869452804327\n",
      "Epoch 160 / 200 | iteration 140 / 171 | Total Loss: 2.393730640411377 | KNN Loss: 2.3883707523345947 | CLS Loss: 0.0053598927333951\n",
      "Epoch 160 / 200 | iteration 150 / 171 | Total Loss: 2.4017348289489746 | KNN Loss: 2.399771213531494 | CLS Loss: 0.0019636540673673153\n",
      "Epoch 160 / 200 | iteration 160 / 171 | Total Loss: 2.4002983570098877 | KNN Loss: 2.3933956623077393 | CLS Loss: 0.0069027310237288475\n",
      "Epoch 160 / 200 | iteration 170 / 171 | Total Loss: 2.4203503131866455 | KNN Loss: 2.404726266860962 | CLS Loss: 0.015624092891812325\n",
      "Epoch: 160, Loss: 2.4038, Train: 0.9965, Valid: 0.9850, Best: 0.9873\n",
      "Epoch 161 / 200 | iteration 0 / 171 | Total Loss: 2.420647144317627 | KNN Loss: 2.4069252014160156 | CLS Loss: 0.013721856288611889\n",
      "Epoch 161 / 200 | iteration 10 / 171 | Total Loss: 2.419935464859009 | KNN Loss: 2.4057929515838623 | CLS Loss: 0.014142608270049095\n",
      "Epoch 161 / 200 | iteration 20 / 171 | Total Loss: 2.387583017349243 | KNN Loss: 2.3821802139282227 | CLS Loss: 0.005402711220085621\n",
      "Epoch 161 / 200 | iteration 30 / 171 | Total Loss: 2.42166805267334 | KNN Loss: 2.40150785446167 | CLS Loss: 0.02016020007431507\n",
      "Epoch 161 / 200 | iteration 40 / 171 | Total Loss: 2.431032419204712 | KNN Loss: 2.422248601913452 | CLS Loss: 0.008783863857388496\n",
      "Epoch 161 / 200 | iteration 50 / 171 | Total Loss: 2.406994581222534 | KNN Loss: 2.4020652770996094 | CLS Loss: 0.004929290618747473\n",
      "Epoch 161 / 200 | iteration 60 / 171 | Total Loss: 2.409743309020996 | KNN Loss: 2.404362678527832 | CLS Loss: 0.005380745977163315\n",
      "Epoch 161 / 200 | iteration 70 / 171 | Total Loss: 2.4184377193450928 | KNN Loss: 2.414710760116577 | CLS Loss: 0.003727043978869915\n",
      "Epoch 161 / 200 | iteration 80 / 171 | Total Loss: 2.3802404403686523 | KNN Loss: 2.3779704570770264 | CLS Loss: 0.0022698871325701475\n",
      "Epoch 161 / 200 | iteration 90 / 171 | Total Loss: 2.451883554458618 | KNN Loss: 2.4407997131347656 | CLS Loss: 0.011083900928497314\n",
      "Epoch 161 / 200 | iteration 100 / 171 | Total Loss: 2.420708656311035 | KNN Loss: 2.4109718799591064 | CLS Loss: 0.009736867621541023\n",
      "Epoch 161 / 200 | iteration 110 / 171 | Total Loss: 2.416156053543091 | KNN Loss: 2.413134813308716 | CLS Loss: 0.0030212861020118\n",
      "Epoch 161 / 200 | iteration 120 / 171 | Total Loss: 2.4191689491271973 | KNN Loss: 2.40906023979187 | CLS Loss: 0.010108736343681812\n",
      "Epoch 161 / 200 | iteration 130 / 171 | Total Loss: 2.415947675704956 | KNN Loss: 2.4129207134246826 | CLS Loss: 0.003026902209967375\n",
      "Epoch 161 / 200 | iteration 140 / 171 | Total Loss: 2.3974218368530273 | KNN Loss: 2.3855419158935547 | CLS Loss: 0.011879842728376389\n",
      "Epoch 161 / 200 | iteration 150 / 171 | Total Loss: 2.396652936935425 | KNN Loss: 2.392660140991211 | CLS Loss: 0.0039927479811012745\n",
      "Epoch 161 / 200 | iteration 160 / 171 | Total Loss: 2.427635431289673 | KNN Loss: 2.417121410369873 | CLS Loss: 0.010513938963413239\n",
      "Epoch 161 / 200 | iteration 170 / 171 | Total Loss: 2.4111239910125732 | KNN Loss: 2.397503614425659 | CLS Loss: 0.013620303943753242\n",
      "Epoch: 161, Loss: 2.4089, Train: 0.9969, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 162 / 200 | iteration 0 / 171 | Total Loss: 2.436307191848755 | KNN Loss: 2.4311792850494385 | CLS Loss: 0.0051279738545417786\n",
      "Epoch 162 / 200 | iteration 10 / 171 | Total Loss: 2.3757081031799316 | KNN Loss: 2.373140811920166 | CLS Loss: 0.002567324787378311\n",
      "Epoch 162 / 200 | iteration 20 / 171 | Total Loss: 2.412946939468384 | KNN Loss: 2.3953819274902344 | CLS Loss: 0.017565036192536354\n",
      "Epoch 162 / 200 | iteration 30 / 171 | Total Loss: 2.4081361293792725 | KNN Loss: 2.3915536403656006 | CLS Loss: 0.016582390293478966\n",
      "Epoch 162 / 200 | iteration 40 / 171 | Total Loss: 2.4034109115600586 | KNN Loss: 2.3923556804656982 | CLS Loss: 0.011055245995521545\n",
      "Epoch 162 / 200 | iteration 50 / 171 | Total Loss: 2.4148969650268555 | KNN Loss: 2.4051525592803955 | CLS Loss: 0.009744448587298393\n",
      "Epoch 162 / 200 | iteration 60 / 171 | Total Loss: 2.3889498710632324 | KNN Loss: 2.386241912841797 | CLS Loss: 0.0027078823186457157\n",
      "Epoch 162 / 200 | iteration 70 / 171 | Total Loss: 2.3913381099700928 | KNN Loss: 2.38500714302063 | CLS Loss: 0.006331045646220446\n",
      "Epoch 162 / 200 | iteration 80 / 171 | Total Loss: 2.408449649810791 | KNN Loss: 2.407175064086914 | CLS Loss: 0.0012744952691718936\n",
      "Epoch 162 / 200 | iteration 90 / 171 | Total Loss: 2.389949083328247 | KNN Loss: 2.384068012237549 | CLS Loss: 0.005881139077246189\n",
      "Epoch 162 / 200 | iteration 100 / 171 | Total Loss: 2.4229185581207275 | KNN Loss: 2.411764144897461 | CLS Loss: 0.011154360137879848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 / 200 | iteration 110 / 171 | Total Loss: 2.405320405960083 | KNN Loss: 2.3948957920074463 | CLS Loss: 0.010424529202282429\n",
      "Epoch 162 / 200 | iteration 120 / 171 | Total Loss: 2.3790550231933594 | KNN Loss: 2.3770594596862793 | CLS Loss: 0.0019956075120717287\n",
      "Epoch 162 / 200 | iteration 130 / 171 | Total Loss: 2.41799259185791 | KNN Loss: 2.4140822887420654 | CLS Loss: 0.003910236991941929\n",
      "Epoch 162 / 200 | iteration 140 / 171 | Total Loss: 2.421107292175293 | KNN Loss: 2.401874303817749 | CLS Loss: 0.019232885912060738\n",
      "Epoch 162 / 200 | iteration 150 / 171 | Total Loss: 2.3934381008148193 | KNN Loss: 2.3866894245147705 | CLS Loss: 0.006748669780790806\n",
      "Epoch 162 / 200 | iteration 160 / 171 | Total Loss: 2.398024797439575 | KNN Loss: 2.3891639709472656 | CLS Loss: 0.008860744535923004\n",
      "Epoch 162 / 200 | iteration 170 / 171 | Total Loss: 2.4304285049438477 | KNN Loss: 2.408466100692749 | CLS Loss: 0.0219624824821949\n",
      "Epoch: 162, Loss: 2.4038, Train: 0.9976, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 163 / 200 | iteration 0 / 171 | Total Loss: 2.397127151489258 | KNN Loss: 2.3926925659179688 | CLS Loss: 0.0044345548376441\n",
      "Epoch 163 / 200 | iteration 10 / 171 | Total Loss: 2.413698673248291 | KNN Loss: 2.4113686084747314 | CLS Loss: 0.002330085728317499\n",
      "Epoch 163 / 200 | iteration 20 / 171 | Total Loss: 2.4211671352386475 | KNN Loss: 2.4141335487365723 | CLS Loss: 0.007033625151962042\n",
      "Epoch 163 / 200 | iteration 30 / 171 | Total Loss: 2.422417640686035 | KNN Loss: 2.4196441173553467 | CLS Loss: 0.0027735966723412275\n",
      "Epoch 163 / 200 | iteration 40 / 171 | Total Loss: 2.3888516426086426 | KNN Loss: 2.3730268478393555 | CLS Loss: 0.015824809670448303\n",
      "Epoch 163 / 200 | iteration 50 / 171 | Total Loss: 2.404298782348633 | KNN Loss: 2.3940627574920654 | CLS Loss: 0.010236071422696114\n",
      "Epoch 163 / 200 | iteration 60 / 171 | Total Loss: 2.456907272338867 | KNN Loss: 2.4434099197387695 | CLS Loss: 0.013497397303581238\n",
      "Epoch 163 / 200 | iteration 70 / 171 | Total Loss: 2.4255056381225586 | KNN Loss: 2.421565532684326 | CLS Loss: 0.003940151538699865\n",
      "Epoch 163 / 200 | iteration 80 / 171 | Total Loss: 2.3904125690460205 | KNN Loss: 2.3832967281341553 | CLS Loss: 0.0071158697828650475\n",
      "Epoch 163 / 200 | iteration 90 / 171 | Total Loss: 2.4048829078674316 | KNN Loss: 2.393209934234619 | CLS Loss: 0.011673062108457088\n",
      "Epoch 163 / 200 | iteration 100 / 171 | Total Loss: 2.364581346511841 | KNN Loss: 2.362212896347046 | CLS Loss: 0.0023683877661824226\n",
      "Epoch 163 / 200 | iteration 110 / 171 | Total Loss: 2.4022982120513916 | KNN Loss: 2.399327278137207 | CLS Loss: 0.002970979316160083\n",
      "Epoch 163 / 200 | iteration 120 / 171 | Total Loss: 2.4283199310302734 | KNN Loss: 2.406592845916748 | CLS Loss: 0.021726977080106735\n",
      "Epoch 163 / 200 | iteration 130 / 171 | Total Loss: 2.3876638412475586 | KNN Loss: 2.3620903491973877 | CLS Loss: 0.025573601946234703\n",
      "Epoch 163 / 200 | iteration 140 / 171 | Total Loss: 2.393603801727295 | KNN Loss: 2.387425184249878 | CLS Loss: 0.006178704090416431\n",
      "Epoch 163 / 200 | iteration 150 / 171 | Total Loss: 2.444780111312866 | KNN Loss: 2.414419651031494 | CLS Loss: 0.03036043420433998\n",
      "Epoch 163 / 200 | iteration 160 / 171 | Total Loss: 2.4224956035614014 | KNN Loss: 2.406097888946533 | CLS Loss: 0.016397660598158836\n",
      "Epoch 163 / 200 | iteration 170 / 171 | Total Loss: 2.3716533184051514 | KNN Loss: 2.3667311668395996 | CLS Loss: 0.004922146908938885\n",
      "Epoch: 163, Loss: 2.4050, Train: 0.9972, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 164 / 200 | iteration 0 / 171 | Total Loss: 2.419616222381592 | KNN Loss: 2.417341709136963 | CLS Loss: 0.002274550264701247\n",
      "Epoch 164 / 200 | iteration 10 / 171 | Total Loss: 2.3957715034484863 | KNN Loss: 2.3915352821350098 | CLS Loss: 0.004236170556396246\n",
      "Epoch 164 / 200 | iteration 20 / 171 | Total Loss: 2.398193597793579 | KNN Loss: 2.3940045833587646 | CLS Loss: 0.004189032595604658\n",
      "Epoch 164 / 200 | iteration 30 / 171 | Total Loss: 2.410637617111206 | KNN Loss: 2.4038631916046143 | CLS Loss: 0.006774399895220995\n",
      "Epoch 164 / 200 | iteration 40 / 171 | Total Loss: 2.442905902862549 | KNN Loss: 2.421527624130249 | CLS Loss: 0.021378174424171448\n",
      "Epoch 164 / 200 | iteration 50 / 171 | Total Loss: 2.411341905593872 | KNN Loss: 2.40466046333313 | CLS Loss: 0.006681389175355434\n",
      "Epoch 164 / 200 | iteration 60 / 171 | Total Loss: 2.410548448562622 | KNN Loss: 2.4086639881134033 | CLS Loss: 0.0018844272708520293\n",
      "Epoch 164 / 200 | iteration 70 / 171 | Total Loss: 2.3928728103637695 | KNN Loss: 2.3849523067474365 | CLS Loss: 0.00792038906365633\n",
      "Epoch 164 / 200 | iteration 80 / 171 | Total Loss: 2.388533592224121 | KNN Loss: 2.3846311569213867 | CLS Loss: 0.003902347991243005\n",
      "Epoch 164 / 200 | iteration 90 / 171 | Total Loss: 2.3829214572906494 | KNN Loss: 2.363738536834717 | CLS Loss: 0.01918286457657814\n",
      "Epoch 164 / 200 | iteration 100 / 171 | Total Loss: 2.383575439453125 | KNN Loss: 2.37636661529541 | CLS Loss: 0.00720891822129488\n",
      "Epoch 164 / 200 | iteration 110 / 171 | Total Loss: 2.4045913219451904 | KNN Loss: 2.3958585262298584 | CLS Loss: 0.008732703514397144\n",
      "Epoch 164 / 200 | iteration 120 / 171 | Total Loss: 2.4012038707733154 | KNN Loss: 2.388596773147583 | CLS Loss: 0.012607131153345108\n",
      "Epoch 164 / 200 | iteration 130 / 171 | Total Loss: 2.381415367126465 | KNN Loss: 2.3681094646453857 | CLS Loss: 0.013305885717272758\n",
      "Epoch 164 / 200 | iteration 140 / 171 | Total Loss: 2.3929662704467773 | KNN Loss: 2.385084629058838 | CLS Loss: 0.007881676778197289\n",
      "Epoch 164 / 200 | iteration 150 / 171 | Total Loss: 2.451625347137451 | KNN Loss: 2.4320263862609863 | CLS Loss: 0.019598959013819695\n",
      "Epoch 164 / 200 | iteration 160 / 171 | Total Loss: 2.422682285308838 | KNN Loss: 2.3934290409088135 | CLS Loss: 0.029253192245960236\n",
      "Epoch 164 / 200 | iteration 170 / 171 | Total Loss: 2.3931121826171875 | KNN Loss: 2.3914616107940674 | CLS Loss: 0.0016504927771165967\n",
      "Epoch: 164, Loss: 2.4072, Train: 0.9976, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 165 / 200 | iteration 0 / 171 | Total Loss: 2.3876395225524902 | KNN Loss: 2.3809354305267334 | CLS Loss: 0.006704210303723812\n",
      "Epoch 165 / 200 | iteration 10 / 171 | Total Loss: 2.3750600814819336 | KNN Loss: 2.3703818321228027 | CLS Loss: 0.004678335506469011\n",
      "Epoch 165 / 200 | iteration 20 / 171 | Total Loss: 2.3881027698516846 | KNN Loss: 2.382507562637329 | CLS Loss: 0.005595220252871513\n",
      "Epoch 165 / 200 | iteration 30 / 171 | Total Loss: 2.4223251342773438 | KNN Loss: 2.400404691696167 | CLS Loss: 0.021920369938015938\n",
      "Epoch 165 / 200 | iteration 40 / 171 | Total Loss: 2.4173665046691895 | KNN Loss: 2.407101631164551 | CLS Loss: 0.010264761745929718\n",
      "Epoch 165 / 200 | iteration 50 / 171 | Total Loss: 2.385145902633667 | KNN Loss: 2.3798322677612305 | CLS Loss: 0.005313714034855366\n",
      "Epoch 165 / 200 | iteration 60 / 171 | Total Loss: 2.3942055702209473 | KNN Loss: 2.387620449066162 | CLS Loss: 0.0065852138213813305\n",
      "Epoch 165 / 200 | iteration 70 / 171 | Total Loss: 2.358055591583252 | KNN Loss: 2.356107711791992 | CLS Loss: 0.0019478253088891506\n",
      "Epoch 165 / 200 | iteration 80 / 171 | Total Loss: 2.458855628967285 | KNN Loss: 2.430757999420166 | CLS Loss: 0.02809753082692623\n",
      "Epoch 165 / 200 | iteration 90 / 171 | Total Loss: 2.4380812644958496 | KNN Loss: 2.428040027618408 | CLS Loss: 0.010041214525699615\n",
      "Epoch 165 / 200 | iteration 100 / 171 | Total Loss: 2.406198740005493 | KNN Loss: 2.403106451034546 | CLS Loss: 0.003092375351116061\n",
      "Epoch 165 / 200 | iteration 110 / 171 | Total Loss: 2.4213461875915527 | KNN Loss: 2.395583391189575 | CLS Loss: 0.025762861594557762\n",
      "Epoch 165 / 200 | iteration 120 / 171 | Total Loss: 2.3883018493652344 | KNN Loss: 2.3812801837921143 | CLS Loss: 0.007021703757345676\n",
      "Epoch 165 / 200 | iteration 130 / 171 | Total Loss: 2.3994741439819336 | KNN Loss: 2.3901548385620117 | CLS Loss: 0.009319422766566277\n",
      "Epoch 165 / 200 | iteration 140 / 171 | Total Loss: 2.397148847579956 | KNN Loss: 2.3878579139709473 | CLS Loss: 0.009290846064686775\n",
      "Epoch 165 / 200 | iteration 150 / 171 | Total Loss: 2.4080958366394043 | KNN Loss: 2.385356903076172 | CLS Loss: 0.02273891307413578\n",
      "Epoch 165 / 200 | iteration 160 / 171 | Total Loss: 2.4020004272460938 | KNN Loss: 2.3859167098999023 | CLS Loss: 0.016083626076579094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165 / 200 | iteration 170 / 171 | Total Loss: 2.4317097663879395 | KNN Loss: 2.424625873565674 | CLS Loss: 0.007083808537572622\n",
      "Epoch: 165, Loss: 2.4065, Train: 0.9963, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 166 / 200 | iteration 0 / 171 | Total Loss: 2.4341816902160645 | KNN Loss: 2.418151617050171 | CLS Loss: 0.01602996699512005\n",
      "Epoch 166 / 200 | iteration 10 / 171 | Total Loss: 2.392561435699463 | KNN Loss: 2.379124641418457 | CLS Loss: 0.01343678031116724\n",
      "Epoch 166 / 200 | iteration 20 / 171 | Total Loss: 2.390676736831665 | KNN Loss: 2.382258892059326 | CLS Loss: 0.008417951874434948\n",
      "Epoch 166 / 200 | iteration 30 / 171 | Total Loss: 2.424752712249756 | KNN Loss: 2.4215316772460938 | CLS Loss: 0.0032210731878876686\n",
      "Epoch 166 / 200 | iteration 40 / 171 | Total Loss: 2.3880441188812256 | KNN Loss: 2.384467363357544 | CLS Loss: 0.0035768328234553337\n",
      "Epoch 166 / 200 | iteration 50 / 171 | Total Loss: 2.4430792331695557 | KNN Loss: 2.4369232654571533 | CLS Loss: 0.0061558568850159645\n",
      "Epoch 166 / 200 | iteration 60 / 171 | Total Loss: 2.4252569675445557 | KNN Loss: 2.417285919189453 | CLS Loss: 0.007971091195940971\n",
      "Epoch 166 / 200 | iteration 70 / 171 | Total Loss: 2.365684747695923 | KNN Loss: 2.3619651794433594 | CLS Loss: 0.003719514701515436\n",
      "Epoch 166 / 200 | iteration 80 / 171 | Total Loss: 2.3962855339050293 | KNN Loss: 2.388890027999878 | CLS Loss: 0.007395520806312561\n",
      "Epoch 166 / 200 | iteration 90 / 171 | Total Loss: 2.375791311264038 | KNN Loss: 2.37353253364563 | CLS Loss: 0.002258855616673827\n",
      "Epoch 166 / 200 | iteration 100 / 171 | Total Loss: 2.454355478286743 | KNN Loss: 2.4510703086853027 | CLS Loss: 0.003285166574642062\n",
      "Epoch 166 / 200 | iteration 110 / 171 | Total Loss: 2.417720079421997 | KNN Loss: 2.4103147983551025 | CLS Loss: 0.007405213080346584\n",
      "Epoch 166 / 200 | iteration 120 / 171 | Total Loss: 2.3734378814697266 | KNN Loss: 2.360616445541382 | CLS Loss: 0.01282138004899025\n",
      "Epoch 166 / 200 | iteration 130 / 171 | Total Loss: 2.389984607696533 | KNN Loss: 2.38655686378479 | CLS Loss: 0.0034278291277587414\n",
      "Epoch 166 / 200 | iteration 140 / 171 | Total Loss: 2.4491617679595947 | KNN Loss: 2.434061050415039 | CLS Loss: 0.015100788325071335\n",
      "Epoch 166 / 200 | iteration 150 / 171 | Total Loss: 2.4201500415802 | KNN Loss: 2.416062831878662 | CLS Loss: 0.004087129142135382\n",
      "Epoch 166 / 200 | iteration 160 / 171 | Total Loss: 2.4188170433044434 | KNN Loss: 2.4115312099456787 | CLS Loss: 0.00728576397523284\n",
      "Epoch 166 / 200 | iteration 170 / 171 | Total Loss: 2.441729784011841 | KNN Loss: 2.4299466609954834 | CLS Loss: 0.011783132329583168\n",
      "Epoch: 166, Loss: 2.4079, Train: 0.9963, Valid: 0.9846, Best: 0.9873\n",
      "Epoch 167 / 200 | iteration 0 / 171 | Total Loss: 2.409698009490967 | KNN Loss: 2.4070470333099365 | CLS Loss: 0.0026510858442634344\n",
      "Epoch 167 / 200 | iteration 10 / 171 | Total Loss: 2.4113876819610596 | KNN Loss: 2.405203342437744 | CLS Loss: 0.006184410769492388\n",
      "Epoch 167 / 200 | iteration 20 / 171 | Total Loss: 2.3800745010375977 | KNN Loss: 2.377714157104492 | CLS Loss: 0.0023604617454111576\n",
      "Epoch 167 / 200 | iteration 30 / 171 | Total Loss: 2.4302432537078857 | KNN Loss: 2.409250259399414 | CLS Loss: 0.020993011072278023\n",
      "Epoch 167 / 200 | iteration 40 / 171 | Total Loss: 2.3738017082214355 | KNN Loss: 2.3713228702545166 | CLS Loss: 0.0024788444861769676\n",
      "Epoch 167 / 200 | iteration 50 / 171 | Total Loss: 2.396087646484375 | KNN Loss: 2.3951730728149414 | CLS Loss: 0.0009145877556875348\n",
      "Epoch 167 / 200 | iteration 60 / 171 | Total Loss: 2.410447120666504 | KNN Loss: 2.4071216583251953 | CLS Loss: 0.0033255640882998705\n",
      "Epoch 167 / 200 | iteration 70 / 171 | Total Loss: 2.4190385341644287 | KNN Loss: 2.412484645843506 | CLS Loss: 0.006553934887051582\n",
      "Epoch 167 / 200 | iteration 80 / 171 | Total Loss: 2.3943498134613037 | KNN Loss: 2.380164384841919 | CLS Loss: 0.01418551616370678\n",
      "Epoch 167 / 200 | iteration 90 / 171 | Total Loss: 2.3998379707336426 | KNN Loss: 2.395608425140381 | CLS Loss: 0.004229621030390263\n",
      "Epoch 167 / 200 | iteration 100 / 171 | Total Loss: 2.3859407901763916 | KNN Loss: 2.3824644088745117 | CLS Loss: 0.0034764879383146763\n",
      "Epoch 167 / 200 | iteration 110 / 171 | Total Loss: 2.3862252235412598 | KNN Loss: 2.380370855331421 | CLS Loss: 0.005854420363903046\n",
      "Epoch 167 / 200 | iteration 120 / 171 | Total Loss: 2.444791316986084 | KNN Loss: 2.4111711978912354 | CLS Loss: 0.03362002223730087\n",
      "Epoch 167 / 200 | iteration 130 / 171 | Total Loss: 2.40673828125 | KNN Loss: 2.3890187740325928 | CLS Loss: 0.01771947182714939\n",
      "Epoch 167 / 200 | iteration 140 / 171 | Total Loss: 2.383514642715454 | KNN Loss: 2.3739545345306396 | CLS Loss: 0.009559990838170052\n",
      "Epoch 167 / 200 | iteration 150 / 171 | Total Loss: 2.464029312133789 | KNN Loss: 2.435976028442383 | CLS Loss: 0.028053220361471176\n",
      "Epoch 167 / 200 | iteration 160 / 171 | Total Loss: 2.3849825859069824 | KNN Loss: 2.371068000793457 | CLS Loss: 0.013914468698203564\n",
      "Epoch 167 / 200 | iteration 170 / 171 | Total Loss: 2.388016700744629 | KNN Loss: 2.3750853538513184 | CLS Loss: 0.012931420467793941\n",
      "Epoch: 167, Loss: 2.4095, Train: 0.9974, Valid: 0.9867, Best: 0.9873\n",
      "Epoch 168 / 200 | iteration 0 / 171 | Total Loss: 2.391702890396118 | KNN Loss: 2.3748838901519775 | CLS Loss: 0.0168189387768507\n",
      "Epoch 168 / 200 | iteration 10 / 171 | Total Loss: 2.438694953918457 | KNN Loss: 2.437793254852295 | CLS Loss: 0.0009017655975185335\n",
      "Epoch 168 / 200 | iteration 20 / 171 | Total Loss: 2.4330787658691406 | KNN Loss: 2.4175899028778076 | CLS Loss: 0.015488761477172375\n",
      "Epoch 168 / 200 | iteration 30 / 171 | Total Loss: 2.4369421005249023 | KNN Loss: 2.434896469116211 | CLS Loss: 0.0020456670317798853\n",
      "Epoch 168 / 200 | iteration 40 / 171 | Total Loss: 2.390976667404175 | KNN Loss: 2.386878490447998 | CLS Loss: 0.004098295699805021\n",
      "Epoch 168 / 200 | iteration 50 / 171 | Total Loss: 2.4012670516967773 | KNN Loss: 2.3872153759002686 | CLS Loss: 0.01405162364244461\n",
      "Epoch 168 / 200 | iteration 60 / 171 | Total Loss: 2.4009387493133545 | KNN Loss: 2.3944790363311768 | CLS Loss: 0.0064597781747579575\n",
      "Epoch 168 / 200 | iteration 70 / 171 | Total Loss: 2.3502674102783203 | KNN Loss: 2.348639726638794 | CLS Loss: 0.0016277279937639832\n",
      "Epoch 168 / 200 | iteration 80 / 171 | Total Loss: 2.384787082672119 | KNN Loss: 2.3783154487609863 | CLS Loss: 0.006471580825746059\n",
      "Epoch 168 / 200 | iteration 90 / 171 | Total Loss: 2.3928747177124023 | KNN Loss: 2.3815758228302 | CLS Loss: 0.011298933066427708\n",
      "Epoch 168 / 200 | iteration 100 / 171 | Total Loss: 2.3945977687835693 | KNN Loss: 2.3872263431549072 | CLS Loss: 0.00737133901566267\n",
      "Epoch 168 / 200 | iteration 110 / 171 | Total Loss: 2.389819622039795 | KNN Loss: 2.3873682022094727 | CLS Loss: 0.0024513944517821074\n",
      "Epoch 168 / 200 | iteration 120 / 171 | Total Loss: 2.4483323097229004 | KNN Loss: 2.428626775741577 | CLS Loss: 0.019705528393387794\n",
      "Epoch 168 / 200 | iteration 130 / 171 | Total Loss: 2.4294533729553223 | KNN Loss: 2.425407886505127 | CLS Loss: 0.004045439884066582\n",
      "Epoch 168 / 200 | iteration 140 / 171 | Total Loss: 2.403715133666992 | KNN Loss: 2.3931450843811035 | CLS Loss: 0.010569986887276173\n",
      "Epoch 168 / 200 | iteration 150 / 171 | Total Loss: 2.4075632095336914 | KNN Loss: 2.4020159244537354 | CLS Loss: 0.0055471849627792835\n",
      "Epoch 168 / 200 | iteration 160 / 171 | Total Loss: 2.4090309143066406 | KNN Loss: 2.397650957107544 | CLS Loss: 0.011380001902580261\n",
      "Epoch 168 / 200 | iteration 170 / 171 | Total Loss: 2.41442608833313 | KNN Loss: 2.407431125640869 | CLS Loss: 0.006995001807808876\n",
      "Epoch: 168, Loss: 2.4035, Train: 0.9977, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 169 / 200 | iteration 0 / 171 | Total Loss: 2.3870372772216797 | KNN Loss: 2.385484457015991 | CLS Loss: 0.0015527389477938414\n",
      "Epoch 169 / 200 | iteration 10 / 171 | Total Loss: 2.4311888217926025 | KNN Loss: 2.429776668548584 | CLS Loss: 0.0014121466083452106\n",
      "Epoch 169 / 200 | iteration 20 / 171 | Total Loss: 2.386631727218628 | KNN Loss: 2.3715457916259766 | CLS Loss: 0.015085828490555286\n",
      "Epoch 169 / 200 | iteration 30 / 171 | Total Loss: 2.4000144004821777 | KNN Loss: 2.3931210041046143 | CLS Loss: 0.006893312558531761\n",
      "Epoch 169 / 200 | iteration 40 / 171 | Total Loss: 2.4643266201019287 | KNN Loss: 2.458411455154419 | CLS Loss: 0.005915077868849039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 / 200 | iteration 50 / 171 | Total Loss: 2.4255077838897705 | KNN Loss: 2.420090436935425 | CLS Loss: 0.005417464766651392\n",
      "Epoch 169 / 200 | iteration 60 / 171 | Total Loss: 2.390815496444702 | KNN Loss: 2.3847062587738037 | CLS Loss: 0.006109143141657114\n",
      "Epoch 169 / 200 | iteration 70 / 171 | Total Loss: 2.4227755069732666 | KNN Loss: 2.4192752838134766 | CLS Loss: 0.0035002168733626604\n",
      "Epoch 169 / 200 | iteration 80 / 171 | Total Loss: 2.4134175777435303 | KNN Loss: 2.4037513732910156 | CLS Loss: 0.009666308760643005\n",
      "Epoch 169 / 200 | iteration 90 / 171 | Total Loss: 2.426567554473877 | KNN Loss: 2.424578905105591 | CLS Loss: 0.001988608855754137\n",
      "Epoch 169 / 200 | iteration 100 / 171 | Total Loss: 2.382051944732666 | KNN Loss: 2.3725602626800537 | CLS Loss: 0.009491756558418274\n",
      "Epoch 169 / 200 | iteration 110 / 171 | Total Loss: 2.378204345703125 | KNN Loss: 2.362532615661621 | CLS Loss: 0.015671750530600548\n",
      "Epoch 169 / 200 | iteration 120 / 171 | Total Loss: 2.4175498485565186 | KNN Loss: 2.4061436653137207 | CLS Loss: 0.01140612456947565\n",
      "Epoch 169 / 200 | iteration 130 / 171 | Total Loss: 2.389934778213501 | KNN Loss: 2.3687758445739746 | CLS Loss: 0.021158916875720024\n",
      "Epoch 169 / 200 | iteration 140 / 171 | Total Loss: 2.391899585723877 | KNN Loss: 2.379647731781006 | CLS Loss: 0.012251874431967735\n",
      "Epoch 169 / 200 | iteration 150 / 171 | Total Loss: 2.3739335536956787 | KNN Loss: 2.344785213470459 | CLS Loss: 0.029148422181606293\n",
      "Epoch 169 / 200 | iteration 160 / 171 | Total Loss: 2.4325976371765137 | KNN Loss: 2.419524669647217 | CLS Loss: 0.01307289395481348\n",
      "Epoch 169 / 200 | iteration 170 / 171 | Total Loss: 2.3759639263153076 | KNN Loss: 2.3707776069641113 | CLS Loss: 0.005186420399695635\n",
      "Epoch: 169, Loss: 2.4068, Train: 0.9976, Valid: 0.9864, Best: 0.9873\n",
      "Epoch 170 / 200 | iteration 0 / 171 | Total Loss: 2.4233651161193848 | KNN Loss: 2.411614418029785 | CLS Loss: 0.011750766076147556\n",
      "Epoch 170 / 200 | iteration 10 / 171 | Total Loss: 2.389169454574585 | KNN Loss: 2.3876423835754395 | CLS Loss: 0.0015270222211256623\n",
      "Epoch 170 / 200 | iteration 20 / 171 | Total Loss: 2.4382686614990234 | KNN Loss: 2.4341256618499756 | CLS Loss: 0.004143064841628075\n",
      "Epoch 170 / 200 | iteration 30 / 171 | Total Loss: 2.4902870655059814 | KNN Loss: 2.476682662963867 | CLS Loss: 0.013604407198727131\n",
      "Epoch 170 / 200 | iteration 40 / 171 | Total Loss: 2.3921732902526855 | KNN Loss: 2.3903675079345703 | CLS Loss: 0.0018058882560580969\n",
      "Epoch 170 / 200 | iteration 50 / 171 | Total Loss: 2.384474277496338 | KNN Loss: 2.3785672187805176 | CLS Loss: 0.005906945094466209\n",
      "Epoch 170 / 200 | iteration 60 / 171 | Total Loss: 2.410753011703491 | KNN Loss: 2.4058525562286377 | CLS Loss: 0.004900461528450251\n",
      "Epoch 170 / 200 | iteration 70 / 171 | Total Loss: 2.4235458374023438 | KNN Loss: 2.409881591796875 | CLS Loss: 0.013664144091308117\n",
      "Epoch 170 / 200 | iteration 80 / 171 | Total Loss: 2.4380860328674316 | KNN Loss: 2.418039560317993 | CLS Loss: 0.020046571269631386\n",
      "Epoch 170 / 200 | iteration 90 / 171 | Total Loss: 2.433108329772949 | KNN Loss: 2.4130477905273438 | CLS Loss: 0.02006063237786293\n",
      "Epoch 170 / 200 | iteration 100 / 171 | Total Loss: 2.397219181060791 | KNN Loss: 2.3801183700561523 | CLS Loss: 0.01710084266960621\n",
      "Epoch 170 / 200 | iteration 110 / 171 | Total Loss: 2.4299721717834473 | KNN Loss: 2.4077908992767334 | CLS Loss: 0.022181257605552673\n",
      "Epoch 170 / 200 | iteration 120 / 171 | Total Loss: 2.4573168754577637 | KNN Loss: 2.4413139820098877 | CLS Loss: 0.01600278727710247\n",
      "Epoch 170 / 200 | iteration 130 / 171 | Total Loss: 2.4076526165008545 | KNN Loss: 2.400474786758423 | CLS Loss: 0.007177927531301975\n",
      "Epoch 170 / 200 | iteration 140 / 171 | Total Loss: 2.4144651889801025 | KNN Loss: 2.412044048309326 | CLS Loss: 0.002421117154881358\n",
      "Epoch 170 / 200 | iteration 150 / 171 | Total Loss: 2.38763427734375 | KNN Loss: 2.3570520877838135 | CLS Loss: 0.030582088977098465\n",
      "Epoch 170 / 200 | iteration 160 / 171 | Total Loss: 2.4142215251922607 | KNN Loss: 2.402625560760498 | CLS Loss: 0.011596006341278553\n",
      "Epoch 170 / 200 | iteration 170 / 171 | Total Loss: 2.392343759536743 | KNN Loss: 2.378819704055786 | CLS Loss: 0.013524024747312069\n",
      "Epoch: 170, Loss: 2.4089, Train: 0.9968, Valid: 0.9851, Best: 0.9873\n",
      "Epoch 171 / 200 | iteration 0 / 171 | Total Loss: 2.3814268112182617 | KNN Loss: 2.3780837059020996 | CLS Loss: 0.0033431020565330982\n",
      "Epoch 171 / 200 | iteration 10 / 171 | Total Loss: 2.420058488845825 | KNN Loss: 2.4041736125946045 | CLS Loss: 0.01588493399322033\n",
      "Epoch 171 / 200 | iteration 20 / 171 | Total Loss: 2.4061522483825684 | KNN Loss: 2.390404462814331 | CLS Loss: 0.015747858211398125\n",
      "Epoch 171 / 200 | iteration 30 / 171 | Total Loss: 2.3866894245147705 | KNN Loss: 2.3833014965057373 | CLS Loss: 0.0033878234680742025\n",
      "Epoch 171 / 200 | iteration 40 / 171 | Total Loss: 2.4036455154418945 | KNN Loss: 2.4000885486602783 | CLS Loss: 0.003557054325938225\n",
      "Epoch 171 / 200 | iteration 50 / 171 | Total Loss: 2.4239814281463623 | KNN Loss: 2.41817045211792 | CLS Loss: 0.005811051931232214\n",
      "Epoch 171 / 200 | iteration 60 / 171 | Total Loss: 2.4429709911346436 | KNN Loss: 2.437288999557495 | CLS Loss: 0.005681989248842001\n",
      "Epoch 171 / 200 | iteration 70 / 171 | Total Loss: 2.411712408065796 | KNN Loss: 2.3914783000946045 | CLS Loss: 0.020233996212482452\n",
      "Epoch 171 / 200 | iteration 80 / 171 | Total Loss: 2.416011333465576 | KNN Loss: 2.4121782779693604 | CLS Loss: 0.0038331439718604088\n",
      "Epoch 171 / 200 | iteration 90 / 171 | Total Loss: 2.397939443588257 | KNN Loss: 2.3938851356506348 | CLS Loss: 0.004054301418364048\n",
      "Epoch 171 / 200 | iteration 100 / 171 | Total Loss: 2.4028806686401367 | KNN Loss: 2.3960635662078857 | CLS Loss: 0.006817015819251537\n",
      "Epoch 171 / 200 | iteration 110 / 171 | Total Loss: 2.3941433429718018 | KNN Loss: 2.375934600830078 | CLS Loss: 0.018208714202046394\n",
      "Epoch 171 / 200 | iteration 120 / 171 | Total Loss: 2.426978588104248 | KNN Loss: 2.4238483905792236 | CLS Loss: 0.003130092052742839\n",
      "Epoch 171 / 200 | iteration 130 / 171 | Total Loss: 2.449127435684204 | KNN Loss: 2.4354407787323 | CLS Loss: 0.013686674647033215\n",
      "Epoch 171 / 200 | iteration 140 / 171 | Total Loss: 2.406047821044922 | KNN Loss: 2.3953287601470947 | CLS Loss: 0.010718955658376217\n",
      "Epoch 171 / 200 | iteration 150 / 171 | Total Loss: 2.361931800842285 | KNN Loss: 2.3584280014038086 | CLS Loss: 0.003503690008074045\n",
      "Epoch 171 / 200 | iteration 160 / 171 | Total Loss: 2.4138784408569336 | KNN Loss: 2.4005634784698486 | CLS Loss: 0.013314962387084961\n",
      "Epoch 171 / 200 | iteration 170 / 171 | Total Loss: 2.433201551437378 | KNN Loss: 2.4229705333709717 | CLS Loss: 0.010231003165245056\n",
      "Epoch: 171, Loss: 2.4059, Train: 0.9969, Valid: 0.9853, Best: 0.9873\n",
      "Epoch 172 / 200 | iteration 0 / 171 | Total Loss: 2.3862390518188477 | KNN Loss: 2.3810694217681885 | CLS Loss: 0.005169617012143135\n",
      "Epoch 172 / 200 | iteration 10 / 171 | Total Loss: 2.406759262084961 | KNN Loss: 2.4062697887420654 | CLS Loss: 0.0004895739839412272\n",
      "Epoch 172 / 200 | iteration 20 / 171 | Total Loss: 2.3999011516571045 | KNN Loss: 2.3879690170288086 | CLS Loss: 0.01193214114755392\n",
      "Epoch 172 / 200 | iteration 30 / 171 | Total Loss: 2.3729441165924072 | KNN Loss: 2.3645596504211426 | CLS Loss: 0.00838435534387827\n",
      "Epoch 172 / 200 | iteration 40 / 171 | Total Loss: 2.4095513820648193 | KNN Loss: 2.408327341079712 | CLS Loss: 0.0012240979121997952\n",
      "Epoch 172 / 200 | iteration 50 / 171 | Total Loss: 2.4127559661865234 | KNN Loss: 2.395778179168701 | CLS Loss: 0.01697787269949913\n",
      "Epoch 172 / 200 | iteration 60 / 171 | Total Loss: 2.432387351989746 | KNN Loss: 2.4252750873565674 | CLS Loss: 0.007112243678420782\n",
      "Epoch 172 / 200 | iteration 70 / 171 | Total Loss: 2.38493013381958 | KNN Loss: 2.383113145828247 | CLS Loss: 0.0018169551622122526\n",
      "Epoch 172 / 200 | iteration 80 / 171 | Total Loss: 2.400775194168091 | KNN Loss: 2.3961801528930664 | CLS Loss: 0.004595049191266298\n",
      "Epoch 172 / 200 | iteration 90 / 171 | Total Loss: 2.378589153289795 | KNN Loss: 2.3766698837280273 | CLS Loss: 0.0019192980835214257\n",
      "Epoch 172 / 200 | iteration 100 / 171 | Total Loss: 2.424154758453369 | KNN Loss: 2.418951988220215 | CLS Loss: 0.005202683620154858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 / 200 | iteration 110 / 171 | Total Loss: 2.4419405460357666 | KNN Loss: 2.4361395835876465 | CLS Loss: 0.005800983402878046\n",
      "Epoch 172 / 200 | iteration 120 / 171 | Total Loss: 2.3599190711975098 | KNN Loss: 2.349717855453491 | CLS Loss: 0.010201255790889263\n",
      "Epoch 172 / 200 | iteration 130 / 171 | Total Loss: 2.407052755355835 | KNN Loss: 2.4011101722717285 | CLS Loss: 0.005942523945122957\n",
      "Epoch 172 / 200 | iteration 140 / 171 | Total Loss: 2.421414613723755 | KNN Loss: 2.418891668319702 | CLS Loss: 0.002522991504520178\n",
      "Epoch 172 / 200 | iteration 150 / 171 | Total Loss: 2.388122797012329 | KNN Loss: 2.3839452266693115 | CLS Loss: 0.00417746976017952\n",
      "Epoch 172 / 200 | iteration 160 / 171 | Total Loss: 2.420609474182129 | KNN Loss: 2.402312994003296 | CLS Loss: 0.018296560272574425\n",
      "Epoch 172 / 200 | iteration 170 / 171 | Total Loss: 2.4343409538269043 | KNN Loss: 2.4047329425811768 | CLS Loss: 0.029607970267534256\n",
      "Epoch: 172, Loss: 2.4056, Train: 0.9975, Valid: 0.9879, Best: 0.9879\n",
      "Epoch 173 / 200 | iteration 0 / 171 | Total Loss: 2.4245405197143555 | KNN Loss: 2.396667957305908 | CLS Loss: 0.027872487902641296\n",
      "Epoch 173 / 200 | iteration 10 / 171 | Total Loss: 2.3840043544769287 | KNN Loss: 2.3819217681884766 | CLS Loss: 0.002082614228129387\n",
      "Epoch 173 / 200 | iteration 20 / 171 | Total Loss: 2.421987771987915 | KNN Loss: 2.417048692703247 | CLS Loss: 0.004939147736877203\n",
      "Epoch 173 / 200 | iteration 30 / 171 | Total Loss: 2.4206020832061768 | KNN Loss: 2.3978993892669678 | CLS Loss: 0.022702686488628387\n",
      "Epoch 173 / 200 | iteration 40 / 171 | Total Loss: 2.4163315296173096 | KNN Loss: 2.409729480743408 | CLS Loss: 0.006601936649531126\n",
      "Epoch 173 / 200 | iteration 50 / 171 | Total Loss: 2.3974709510803223 | KNN Loss: 2.390822649002075 | CLS Loss: 0.006648354697972536\n",
      "Epoch 173 / 200 | iteration 60 / 171 | Total Loss: 2.377258062362671 | KNN Loss: 2.3725430965423584 | CLS Loss: 0.004714876413345337\n",
      "Epoch 173 / 200 | iteration 70 / 171 | Total Loss: 2.3969640731811523 | KNN Loss: 2.393223762512207 | CLS Loss: 0.0037403907626867294\n",
      "Epoch 173 / 200 | iteration 80 / 171 | Total Loss: 2.3790881633758545 | KNN Loss: 2.3715529441833496 | CLS Loss: 0.007535168901085854\n",
      "Epoch 173 / 200 | iteration 90 / 171 | Total Loss: 2.392665386199951 | KNN Loss: 2.37896728515625 | CLS Loss: 0.013698074035346508\n",
      "Epoch 173 / 200 | iteration 100 / 171 | Total Loss: 2.387660026550293 | KNN Loss: 2.384495973587036 | CLS Loss: 0.003164051566272974\n",
      "Epoch 173 / 200 | iteration 110 / 171 | Total Loss: 2.423374652862549 | KNN Loss: 2.4028115272521973 | CLS Loss: 0.02056306228041649\n",
      "Epoch 173 / 200 | iteration 120 / 171 | Total Loss: 2.427830934524536 | KNN Loss: 2.4256904125213623 | CLS Loss: 0.002140514086931944\n",
      "Epoch 173 / 200 | iteration 130 / 171 | Total Loss: 2.4241418838500977 | KNN Loss: 2.407742738723755 | CLS Loss: 0.016399027779698372\n",
      "Epoch 173 / 200 | iteration 140 / 171 | Total Loss: 2.413907527923584 | KNN Loss: 2.408031702041626 | CLS Loss: 0.005875927396118641\n",
      "Epoch 173 / 200 | iteration 150 / 171 | Total Loss: 2.4044532775878906 | KNN Loss: 2.3940069675445557 | CLS Loss: 0.010446193628013134\n",
      "Epoch 173 / 200 | iteration 160 / 171 | Total Loss: 2.419552803039551 | KNN Loss: 2.409832715988159 | CLS Loss: 0.009720202535390854\n",
      "Epoch 173 / 200 | iteration 170 / 171 | Total Loss: 2.4395079612731934 | KNN Loss: 2.435554265975952 | CLS Loss: 0.00395358307287097\n",
      "Epoch: 173, Loss: 2.4053, Train: 0.9965, Valid: 0.9861, Best: 0.9879\n",
      "Epoch 174 / 200 | iteration 0 / 171 | Total Loss: 2.391805410385132 | KNN Loss: 2.390721082687378 | CLS Loss: 0.0010843041818588972\n",
      "Epoch 174 / 200 | iteration 10 / 171 | Total Loss: 2.470184564590454 | KNN Loss: 2.463284492492676 | CLS Loss: 0.006900135427713394\n",
      "Epoch 174 / 200 | iteration 20 / 171 | Total Loss: 2.446363687515259 | KNN Loss: 2.4073879718780518 | CLS Loss: 0.03897564858198166\n",
      "Epoch 174 / 200 | iteration 30 / 171 | Total Loss: 2.3901426792144775 | KNN Loss: 2.38759183883667 | CLS Loss: 0.0025508685503154993\n",
      "Epoch 174 / 200 | iteration 40 / 171 | Total Loss: 2.3749027252197266 | KNN Loss: 2.369429588317871 | CLS Loss: 0.005473194178193808\n",
      "Epoch 174 / 200 | iteration 50 / 171 | Total Loss: 2.4286656379699707 | KNN Loss: 2.422597885131836 | CLS Loss: 0.006067791488021612\n",
      "Epoch 174 / 200 | iteration 60 / 171 | Total Loss: 2.484933376312256 | KNN Loss: 2.4842188358306885 | CLS Loss: 0.0007144333212636411\n",
      "Epoch 174 / 200 | iteration 70 / 171 | Total Loss: 2.3987016677856445 | KNN Loss: 2.394979238510132 | CLS Loss: 0.0037223848048597574\n",
      "Epoch 174 / 200 | iteration 80 / 171 | Total Loss: 2.4172770977020264 | KNN Loss: 2.4002037048339844 | CLS Loss: 0.01707341894507408\n",
      "Epoch 174 / 200 | iteration 90 / 171 | Total Loss: 2.392347574234009 | KNN Loss: 2.384134292602539 | CLS Loss: 0.008213361725211143\n",
      "Epoch 174 / 200 | iteration 100 / 171 | Total Loss: 2.422759532928467 | KNN Loss: 2.410726308822632 | CLS Loss: 0.012033323757350445\n",
      "Epoch 174 / 200 | iteration 110 / 171 | Total Loss: 2.393054962158203 | KNN Loss: 2.390028238296509 | CLS Loss: 0.00302673177793622\n",
      "Epoch 174 / 200 | iteration 120 / 171 | Total Loss: 2.4208972454071045 | KNN Loss: 2.412971019744873 | CLS Loss: 0.007926306687295437\n",
      "Epoch 174 / 200 | iteration 130 / 171 | Total Loss: 2.3773159980773926 | KNN Loss: 2.365706443786621 | CLS Loss: 0.011609495617449284\n",
      "Epoch 174 / 200 | iteration 140 / 171 | Total Loss: 2.4128639698028564 | KNN Loss: 2.3897807598114014 | CLS Loss: 0.023083267733454704\n",
      "Epoch 174 / 200 | iteration 150 / 171 | Total Loss: 2.4385902881622314 | KNN Loss: 2.4180288314819336 | CLS Loss: 0.020561527460813522\n",
      "Epoch 174 / 200 | iteration 160 / 171 | Total Loss: 2.4196436405181885 | KNN Loss: 2.4030632972717285 | CLS Loss: 0.016580265015363693\n",
      "Epoch 174 / 200 | iteration 170 / 171 | Total Loss: 2.4074149131774902 | KNN Loss: 2.401017665863037 | CLS Loss: 0.006397295277565718\n",
      "Epoch: 174, Loss: 2.4109, Train: 0.9979, Valid: 0.9876, Best: 0.9879\n",
      "Epoch 175 / 200 | iteration 0 / 171 | Total Loss: 2.371366024017334 | KNN Loss: 2.358510732650757 | CLS Loss: 0.012855279259383678\n",
      "Epoch 175 / 200 | iteration 10 / 171 | Total Loss: 2.4401910305023193 | KNN Loss: 2.433589458465576 | CLS Loss: 0.006601459812372923\n",
      "Epoch 175 / 200 | iteration 20 / 171 | Total Loss: 2.417039155960083 | KNN Loss: 2.404481887817383 | CLS Loss: 0.012557268142700195\n",
      "Epoch 175 / 200 | iteration 30 / 171 | Total Loss: 2.3694374561309814 | KNN Loss: 2.368593454360962 | CLS Loss: 0.0008440388482995331\n",
      "Epoch 175 / 200 | iteration 40 / 171 | Total Loss: 2.390587329864502 | KNN Loss: 2.3852484226226807 | CLS Loss: 0.005338822491466999\n",
      "Epoch 175 / 200 | iteration 50 / 171 | Total Loss: 2.389648675918579 | KNN Loss: 2.3873820304870605 | CLS Loss: 0.002266526687890291\n",
      "Epoch 175 / 200 | iteration 60 / 171 | Total Loss: 2.4142396450042725 | KNN Loss: 2.3982737064361572 | CLS Loss: 0.015966003760695457\n",
      "Epoch 175 / 200 | iteration 70 / 171 | Total Loss: 2.415867805480957 | KNN Loss: 2.3882415294647217 | CLS Loss: 0.027626238763332367\n",
      "Epoch 175 / 200 | iteration 80 / 171 | Total Loss: 2.4251513481140137 | KNN Loss: 2.416163444519043 | CLS Loss: 0.008987803012132645\n",
      "Epoch 175 / 200 | iteration 90 / 171 | Total Loss: 2.416405439376831 | KNN Loss: 2.4004061222076416 | CLS Loss: 0.01599939353764057\n",
      "Epoch 175 / 200 | iteration 100 / 171 | Total Loss: 2.3914055824279785 | KNN Loss: 2.385852575302124 | CLS Loss: 0.005553005263209343\n",
      "Epoch 175 / 200 | iteration 110 / 171 | Total Loss: 2.4389426708221436 | KNN Loss: 2.416990041732788 | CLS Loss: 0.021952543407678604\n",
      "Epoch 175 / 200 | iteration 120 / 171 | Total Loss: 2.389799118041992 | KNN Loss: 2.3857500553131104 | CLS Loss: 0.004049139562994242\n",
      "Epoch 175 / 200 | iteration 130 / 171 | Total Loss: 2.404935359954834 | KNN Loss: 2.3913567066192627 | CLS Loss: 0.013578731566667557\n",
      "Epoch 175 / 200 | iteration 140 / 171 | Total Loss: 2.4386582374572754 | KNN Loss: 2.4264047145843506 | CLS Loss: 0.012253633700311184\n",
      "Epoch 175 / 200 | iteration 150 / 171 | Total Loss: 2.3962225914001465 | KNN Loss: 2.394061803817749 | CLS Loss: 0.002160687232390046\n",
      "Epoch 175 / 200 | iteration 160 / 171 | Total Loss: 2.4274232387542725 | KNN Loss: 2.4224658012390137 | CLS Loss: 0.004957401193678379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175 / 200 | iteration 170 / 171 | Total Loss: 2.447420597076416 | KNN Loss: 2.435206890106201 | CLS Loss: 0.012213627807796001\n",
      "Epoch: 175, Loss: 2.4076, Train: 0.9976, Valid: 0.9866, Best: 0.9879\n",
      "Epoch 176 / 200 | iteration 0 / 171 | Total Loss: 2.3773133754730225 | KNN Loss: 2.3642430305480957 | CLS Loss: 0.013070271350443363\n",
      "Epoch 176 / 200 | iteration 10 / 171 | Total Loss: 2.3882036209106445 | KNN Loss: 2.3842883110046387 | CLS Loss: 0.0039153448306024075\n",
      "Epoch 176 / 200 | iteration 20 / 171 | Total Loss: 2.4226443767547607 | KNN Loss: 2.4037094116210938 | CLS Loss: 0.018934909254312515\n",
      "Epoch 176 / 200 | iteration 30 / 171 | Total Loss: 2.4463536739349365 | KNN Loss: 2.431215286254883 | CLS Loss: 0.015138499438762665\n",
      "Epoch 176 / 200 | iteration 40 / 171 | Total Loss: 2.397960662841797 | KNN Loss: 2.3858954906463623 | CLS Loss: 0.0120651014149189\n",
      "Epoch 176 / 200 | iteration 50 / 171 | Total Loss: 2.412271738052368 | KNN Loss: 2.4024672508239746 | CLS Loss: 0.009804506786167622\n",
      "Epoch 176 / 200 | iteration 60 / 171 | Total Loss: 2.3996963500976562 | KNN Loss: 2.3969602584838867 | CLS Loss: 0.0027362057007849216\n",
      "Epoch 176 / 200 | iteration 70 / 171 | Total Loss: 2.4129858016967773 | KNN Loss: 2.410834789276123 | CLS Loss: 0.0021510173100978136\n",
      "Epoch 176 / 200 | iteration 80 / 171 | Total Loss: 2.435514211654663 | KNN Loss: 2.430513858795166 | CLS Loss: 0.005000337027013302\n",
      "Epoch 176 / 200 | iteration 90 / 171 | Total Loss: 2.429264783859253 | KNN Loss: 2.4128823280334473 | CLS Loss: 0.01638244092464447\n",
      "Epoch 176 / 200 | iteration 100 / 171 | Total Loss: 2.4102425575256348 | KNN Loss: 2.3981659412384033 | CLS Loss: 0.012076514773070812\n",
      "Epoch 176 / 200 | iteration 110 / 171 | Total Loss: 2.4363279342651367 | KNN Loss: 2.42752742767334 | CLS Loss: 0.008800571784377098\n",
      "Epoch 176 / 200 | iteration 120 / 171 | Total Loss: 2.4260616302490234 | KNN Loss: 2.415055513381958 | CLS Loss: 0.0110061289742589\n",
      "Epoch 176 / 200 | iteration 130 / 171 | Total Loss: 2.430279493331909 | KNN Loss: 2.4289746284484863 | CLS Loss: 0.001304839737713337\n",
      "Epoch 176 / 200 | iteration 140 / 171 | Total Loss: 2.4299521446228027 | KNN Loss: 2.413635015487671 | CLS Loss: 0.01631711609661579\n",
      "Epoch 176 / 200 | iteration 150 / 171 | Total Loss: 2.4279580116271973 | KNN Loss: 2.4097225666046143 | CLS Loss: 0.01823539473116398\n",
      "Epoch 176 / 200 | iteration 160 / 171 | Total Loss: 2.4318673610687256 | KNN Loss: 2.420949935913086 | CLS Loss: 0.01091753039509058\n",
      "Epoch 176 / 200 | iteration 170 / 171 | Total Loss: 2.431974411010742 | KNN Loss: 2.420433521270752 | CLS Loss: 0.011540899984538555\n",
      "Epoch: 176, Loss: 2.4074, Train: 0.9966, Valid: 0.9870, Best: 0.9879\n",
      "Epoch 177 / 200 | iteration 0 / 171 | Total Loss: 2.4335179328918457 | KNN Loss: 2.4048328399658203 | CLS Loss: 0.02868511527776718\n",
      "Epoch 177 / 200 | iteration 10 / 171 | Total Loss: 2.461190700531006 | KNN Loss: 2.4573659896850586 | CLS Loss: 0.0038246549665927887\n",
      "Epoch 177 / 200 | iteration 20 / 171 | Total Loss: 2.405423164367676 | KNN Loss: 2.3936398029327393 | CLS Loss: 0.011783471331000328\n",
      "Epoch 177 / 200 | iteration 30 / 171 | Total Loss: 2.405013084411621 | KNN Loss: 2.4019970893859863 | CLS Loss: 0.0030158802401274443\n",
      "Epoch 177 / 200 | iteration 40 / 171 | Total Loss: 2.4136242866516113 | KNN Loss: 2.3958005905151367 | CLS Loss: 0.017823683097958565\n",
      "Epoch 177 / 200 | iteration 50 / 171 | Total Loss: 2.455036163330078 | KNN Loss: 2.4504311084747314 | CLS Loss: 0.00460499944165349\n",
      "Epoch 177 / 200 | iteration 60 / 171 | Total Loss: 2.407379150390625 | KNN Loss: 2.4033279418945312 | CLS Loss: 0.00405123783275485\n",
      "Epoch 177 / 200 | iteration 70 / 171 | Total Loss: 2.3920507431030273 | KNN Loss: 2.3689863681793213 | CLS Loss: 0.023064294829964638\n",
      "Epoch 177 / 200 | iteration 80 / 171 | Total Loss: 2.4314045906066895 | KNN Loss: 2.4096906185150146 | CLS Loss: 0.021714018657803535\n",
      "Epoch 177 / 200 | iteration 90 / 171 | Total Loss: 2.3824496269226074 | KNN Loss: 2.3808112144470215 | CLS Loss: 0.0016383342444896698\n",
      "Epoch 177 / 200 | iteration 100 / 171 | Total Loss: 2.4796321392059326 | KNN Loss: 2.450937032699585 | CLS Loss: 0.028695007786154747\n",
      "Epoch 177 / 200 | iteration 110 / 171 | Total Loss: 2.433349370956421 | KNN Loss: 2.4050395488739014 | CLS Loss: 0.02830982208251953\n",
      "Epoch 177 / 200 | iteration 120 / 171 | Total Loss: 2.4290473461151123 | KNN Loss: 2.421984910964966 | CLS Loss: 0.007062343880534172\n",
      "Epoch 177 / 200 | iteration 130 / 171 | Total Loss: 2.4078307151794434 | KNN Loss: 2.3986713886260986 | CLS Loss: 0.009159370325505733\n",
      "Epoch 177 / 200 | iteration 140 / 171 | Total Loss: 2.414088726043701 | KNN Loss: 2.4070885181427 | CLS Loss: 0.0070001520216465\n",
      "Epoch 177 / 200 | iteration 150 / 171 | Total Loss: 2.40376877784729 | KNN Loss: 2.396650791168213 | CLS Loss: 0.007117891684174538\n",
      "Epoch 177 / 200 | iteration 160 / 171 | Total Loss: 2.394486665725708 | KNN Loss: 2.379464626312256 | CLS Loss: 0.015022004954516888\n",
      "Epoch 177 / 200 | iteration 170 / 171 | Total Loss: 2.4071273803710938 | KNN Loss: 2.401484727859497 | CLS Loss: 0.005642644129693508\n",
      "Epoch: 177, Loss: 2.4071, Train: 0.9979, Valid: 0.9871, Best: 0.9879\n",
      "Epoch 178 / 200 | iteration 0 / 171 | Total Loss: 2.4251890182495117 | KNN Loss: 2.4211342334747314 | CLS Loss: 0.004054882097989321\n",
      "Epoch 178 / 200 | iteration 10 / 171 | Total Loss: 2.4206860065460205 | KNN Loss: 2.4191882610321045 | CLS Loss: 0.0014978635590523481\n",
      "Epoch 178 / 200 | iteration 20 / 171 | Total Loss: 2.413464307785034 | KNN Loss: 2.395622730255127 | CLS Loss: 0.017841525375843048\n",
      "Epoch 178 / 200 | iteration 30 / 171 | Total Loss: 2.3994946479797363 | KNN Loss: 2.394717216491699 | CLS Loss: 0.004777329973876476\n",
      "Epoch 178 / 200 | iteration 40 / 171 | Total Loss: 2.3971869945526123 | KNN Loss: 2.389972448348999 | CLS Loss: 0.0072145164012908936\n",
      "Epoch 178 / 200 | iteration 50 / 171 | Total Loss: 2.441102981567383 | KNN Loss: 2.4286019802093506 | CLS Loss: 0.012500949203968048\n",
      "Epoch 178 / 200 | iteration 60 / 171 | Total Loss: 2.399419069290161 | KNN Loss: 2.3895187377929688 | CLS Loss: 0.009900433011353016\n",
      "Epoch 178 / 200 | iteration 70 / 171 | Total Loss: 2.4169085025787354 | KNN Loss: 2.4032862186431885 | CLS Loss: 0.013622189871966839\n",
      "Epoch 178 / 200 | iteration 80 / 171 | Total Loss: 2.3911399841308594 | KNN Loss: 2.3903281688690186 | CLS Loss: 0.0008118461119011045\n",
      "Epoch 178 / 200 | iteration 90 / 171 | Total Loss: 2.419353485107422 | KNN Loss: 2.4130077362060547 | CLS Loss: 0.006345643196254969\n",
      "Epoch 178 / 200 | iteration 100 / 171 | Total Loss: 2.4006097316741943 | KNN Loss: 2.3798890113830566 | CLS Loss: 0.020720679312944412\n",
      "Epoch 178 / 200 | iteration 110 / 171 | Total Loss: 2.431422233581543 | KNN Loss: 2.4207944869995117 | CLS Loss: 0.010627785697579384\n",
      "Epoch 178 / 200 | iteration 120 / 171 | Total Loss: 2.388352870941162 | KNN Loss: 2.369486093521118 | CLS Loss: 0.018866870552301407\n",
      "Epoch 178 / 200 | iteration 130 / 171 | Total Loss: 2.4182538986206055 | KNN Loss: 2.3953046798706055 | CLS Loss: 0.02294912189245224\n",
      "Epoch 178 / 200 | iteration 140 / 171 | Total Loss: 2.378593921661377 | KNN Loss: 2.375945568084717 | CLS Loss: 0.0026483715046197176\n",
      "Epoch 178 / 200 | iteration 150 / 171 | Total Loss: 2.4356822967529297 | KNN Loss: 2.431119441986084 | CLS Loss: 0.004562824964523315\n",
      "Epoch 178 / 200 | iteration 160 / 171 | Total Loss: 2.4266881942749023 | KNN Loss: 2.413400173187256 | CLS Loss: 0.013288051821291447\n",
      "Epoch 178 / 200 | iteration 170 / 171 | Total Loss: 2.3964662551879883 | KNN Loss: 2.373579263687134 | CLS Loss: 0.022887079045176506\n",
      "Epoch: 178, Loss: 2.4093, Train: 0.9981, Valid: 0.9861, Best: 0.9879\n",
      "Epoch 179 / 200 | iteration 0 / 171 | Total Loss: 2.3711726665496826 | KNN Loss: 2.3589532375335693 | CLS Loss: 0.012219512835144997\n",
      "Epoch 179 / 200 | iteration 10 / 171 | Total Loss: 2.4123494625091553 | KNN Loss: 2.40613055229187 | CLS Loss: 0.006218981929123402\n",
      "Epoch 179 / 200 | iteration 20 / 171 | Total Loss: 2.3654673099517822 | KNN Loss: 2.346737861633301 | CLS Loss: 0.01872933842241764\n",
      "Epoch 179 / 200 | iteration 30 / 171 | Total Loss: 2.370884418487549 | KNN Loss: 2.368068218231201 | CLS Loss: 0.00281621259637177\n",
      "Epoch 179 / 200 | iteration 40 / 171 | Total Loss: 2.386780261993408 | KNN Loss: 2.3812806606292725 | CLS Loss: 0.005499664228409529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 / 200 | iteration 50 / 171 | Total Loss: 2.3864083290100098 | KNN Loss: 2.374725580215454 | CLS Loss: 0.011682683601975441\n",
      "Epoch 179 / 200 | iteration 60 / 171 | Total Loss: 2.3844540119171143 | KNN Loss: 2.3769640922546387 | CLS Loss: 0.007490007672458887\n",
      "Epoch 179 / 200 | iteration 70 / 171 | Total Loss: 2.49143385887146 | KNN Loss: 2.4787652492523193 | CLS Loss: 0.012668697163462639\n",
      "Epoch 179 / 200 | iteration 80 / 171 | Total Loss: 2.3748507499694824 | KNN Loss: 2.3733279705047607 | CLS Loss: 0.0015228955307975411\n",
      "Epoch 179 / 200 | iteration 90 / 171 | Total Loss: 2.3721649646759033 | KNN Loss: 2.367286443710327 | CLS Loss: 0.004878529813140631\n",
      "Epoch 179 / 200 | iteration 100 / 171 | Total Loss: 2.4086239337921143 | KNN Loss: 2.3939995765686035 | CLS Loss: 0.014624453149735928\n",
      "Epoch 179 / 200 | iteration 110 / 171 | Total Loss: 2.388645648956299 | KNN Loss: 2.3852450847625732 | CLS Loss: 0.0034006594214588404\n",
      "Epoch 179 / 200 | iteration 120 / 171 | Total Loss: 2.3657917976379395 | KNN Loss: 2.3534021377563477 | CLS Loss: 0.012389580719172955\n",
      "Epoch 179 / 200 | iteration 130 / 171 | Total Loss: 2.429250478744507 | KNN Loss: 2.413006067276001 | CLS Loss: 0.016244327649474144\n",
      "Epoch 179 / 200 | iteration 140 / 171 | Total Loss: 2.384206533432007 | KNN Loss: 2.3755486011505127 | CLS Loss: 0.008657898753881454\n",
      "Epoch 179 / 200 | iteration 150 / 171 | Total Loss: 2.444345712661743 | KNN Loss: 2.431509256362915 | CLS Loss: 0.012836437672376633\n",
      "Epoch 179 / 200 | iteration 160 / 171 | Total Loss: 2.3970248699188232 | KNN Loss: 2.3942437171936035 | CLS Loss: 0.0027811648324131966\n",
      "Epoch 179 / 200 | iteration 170 / 171 | Total Loss: 2.3962180614471436 | KNN Loss: 2.377290964126587 | CLS Loss: 0.01892719976603985\n",
      "Epoch: 179, Loss: 2.4006, Train: 0.9972, Valid: 0.9860, Best: 0.9879\n",
      "Epoch 180 / 200 | iteration 0 / 171 | Total Loss: 2.4207839965820312 | KNN Loss: 2.399186134338379 | CLS Loss: 0.021597765386104584\n",
      "Epoch 180 / 200 | iteration 10 / 171 | Total Loss: 2.3751935958862305 | KNN Loss: 2.3674824237823486 | CLS Loss: 0.007711200509220362\n",
      "Epoch 180 / 200 | iteration 20 / 171 | Total Loss: 2.3526923656463623 | KNN Loss: 2.350224494934082 | CLS Loss: 0.0024678674526512623\n",
      "Epoch 180 / 200 | iteration 30 / 171 | Total Loss: 2.3616867065429688 | KNN Loss: 2.359189033508301 | CLS Loss: 0.00249757943674922\n",
      "Epoch 180 / 200 | iteration 40 / 171 | Total Loss: 2.4100701808929443 | KNN Loss: 2.4061479568481445 | CLS Loss: 0.0039221132174134254\n",
      "Epoch 180 / 200 | iteration 50 / 171 | Total Loss: 2.406930446624756 | KNN Loss: 2.4040791988372803 | CLS Loss: 0.0028513309080153704\n",
      "Epoch 180 / 200 | iteration 60 / 171 | Total Loss: 2.410104513168335 | KNN Loss: 2.4037201404571533 | CLS Loss: 0.006384345702826977\n",
      "Epoch 180 / 200 | iteration 70 / 171 | Total Loss: 2.3782529830932617 | KNN Loss: 2.3747925758361816 | CLS Loss: 0.003460440319031477\n",
      "Epoch 180 / 200 | iteration 80 / 171 | Total Loss: 2.4127066135406494 | KNN Loss: 2.40775990486145 | CLS Loss: 0.004946713335812092\n",
      "Epoch 180 / 200 | iteration 90 / 171 | Total Loss: 2.3988091945648193 | KNN Loss: 2.392944574356079 | CLS Loss: 0.005864710081368685\n",
      "Epoch 180 / 200 | iteration 100 / 171 | Total Loss: 2.401388168334961 | KNN Loss: 2.4001691341400146 | CLS Loss: 0.0012189655099064112\n",
      "Epoch 180 / 200 | iteration 110 / 171 | Total Loss: 2.4237935543060303 | KNN Loss: 2.412827968597412 | CLS Loss: 0.010965527035295963\n",
      "Epoch 180 / 200 | iteration 120 / 171 | Total Loss: 2.4055423736572266 | KNN Loss: 2.401092767715454 | CLS Loss: 0.0044496627524495125\n",
      "Epoch 180 / 200 | iteration 130 / 171 | Total Loss: 2.4206948280334473 | KNN Loss: 2.4172959327697754 | CLS Loss: 0.003398923436179757\n",
      "Epoch 180 / 200 | iteration 140 / 171 | Total Loss: 2.402146577835083 | KNN Loss: 2.3875956535339355 | CLS Loss: 0.014550912193953991\n",
      "Epoch 180 / 200 | iteration 150 / 171 | Total Loss: 2.4133076667785645 | KNN Loss: 2.403343677520752 | CLS Loss: 0.009964102879166603\n",
      "Epoch 180 / 200 | iteration 160 / 171 | Total Loss: 2.3892741203308105 | KNN Loss: 2.375082015991211 | CLS Loss: 0.014192170463502407\n",
      "Epoch 180 / 200 | iteration 170 / 171 | Total Loss: 2.4087131023406982 | KNN Loss: 2.4043121337890625 | CLS Loss: 0.004401000682264566\n",
      "Epoch: 180, Loss: 2.4052, Train: 0.9978, Valid: 0.9860, Best: 0.9879\n",
      "Epoch 181 / 200 | iteration 0 / 171 | Total Loss: 2.3864636421203613 | KNN Loss: 2.379479169845581 | CLS Loss: 0.006984565407037735\n",
      "Epoch 181 / 200 | iteration 10 / 171 | Total Loss: 2.3792145252227783 | KNN Loss: 2.369702100753784 | CLS Loss: 0.00951250921934843\n",
      "Epoch 181 / 200 | iteration 20 / 171 | Total Loss: 2.412412166595459 | KNN Loss: 2.3963520526885986 | CLS Loss: 0.01606007292866707\n",
      "Epoch 181 / 200 | iteration 30 / 171 | Total Loss: 2.400789737701416 | KNN Loss: 2.389392375946045 | CLS Loss: 0.01139745768159628\n",
      "Epoch 181 / 200 | iteration 40 / 171 | Total Loss: 2.378904342651367 | KNN Loss: 2.376260995864868 | CLS Loss: 0.002643457381054759\n",
      "Epoch 181 / 200 | iteration 50 / 171 | Total Loss: 2.4031476974487305 | KNN Loss: 2.3961284160614014 | CLS Loss: 0.007019320502877235\n",
      "Epoch 181 / 200 | iteration 60 / 171 | Total Loss: 2.427368640899658 | KNN Loss: 2.40940260887146 | CLS Loss: 0.017965998500585556\n",
      "Epoch 181 / 200 | iteration 70 / 171 | Total Loss: 2.4096052646636963 | KNN Loss: 2.4034154415130615 | CLS Loss: 0.0061898441053926945\n",
      "Epoch 181 / 200 | iteration 80 / 171 | Total Loss: 2.439574718475342 | KNN Loss: 2.4320032596588135 | CLS Loss: 0.007571504916995764\n",
      "Epoch 181 / 200 | iteration 90 / 171 | Total Loss: 2.4413299560546875 | KNN Loss: 2.4273600578308105 | CLS Loss: 0.013969942927360535\n",
      "Epoch 181 / 200 | iteration 100 / 171 | Total Loss: 2.4461405277252197 | KNN Loss: 2.425368547439575 | CLS Loss: 0.02077188529074192\n",
      "Epoch 181 / 200 | iteration 110 / 171 | Total Loss: 2.3614087104797363 | KNN Loss: 2.358363628387451 | CLS Loss: 0.0030450073536485434\n",
      "Epoch 181 / 200 | iteration 120 / 171 | Total Loss: 2.42574143409729 | KNN Loss: 2.4151570796966553 | CLS Loss: 0.010584418661892414\n",
      "Epoch 181 / 200 | iteration 130 / 171 | Total Loss: 2.395199775695801 | KNN Loss: 2.385042667388916 | CLS Loss: 0.010157219134271145\n",
      "Epoch 181 / 200 | iteration 140 / 171 | Total Loss: 2.4330437183380127 | KNN Loss: 2.429323673248291 | CLS Loss: 0.003720072563737631\n",
      "Epoch 181 / 200 | iteration 150 / 171 | Total Loss: 2.4251019954681396 | KNN Loss: 2.40671968460083 | CLS Loss: 0.018382418900728226\n",
      "Epoch 181 / 200 | iteration 160 / 171 | Total Loss: 2.432507276535034 | KNN Loss: 2.4270236492156982 | CLS Loss: 0.005483672954142094\n",
      "Epoch 181 / 200 | iteration 170 / 171 | Total Loss: 2.3692145347595215 | KNN Loss: 2.3617632389068604 | CLS Loss: 0.007451259531080723\n",
      "Epoch: 181, Loss: 2.4055, Train: 0.9964, Valid: 0.9846, Best: 0.9879\n",
      "Epoch 182 / 200 | iteration 0 / 171 | Total Loss: 2.41819429397583 | KNN Loss: 2.389930486679077 | CLS Loss: 0.028263814747333527\n",
      "Epoch 182 / 200 | iteration 10 / 171 | Total Loss: 2.3998959064483643 | KNN Loss: 2.3853938579559326 | CLS Loss: 0.014502044767141342\n",
      "Epoch 182 / 200 | iteration 20 / 171 | Total Loss: 2.383559226989746 | KNN Loss: 2.3737740516662598 | CLS Loss: 0.00978519581258297\n",
      "Epoch 182 / 200 | iteration 30 / 171 | Total Loss: 2.4288957118988037 | KNN Loss: 2.4199647903442383 | CLS Loss: 0.008930856361985207\n",
      "Epoch 182 / 200 | iteration 40 / 171 | Total Loss: 2.4142017364501953 | KNN Loss: 2.4063498973846436 | CLS Loss: 0.007851846516132355\n",
      "Epoch 182 / 200 | iteration 50 / 171 | Total Loss: 2.4042274951934814 | KNN Loss: 2.402444839477539 | CLS Loss: 0.001782669685781002\n",
      "Epoch 182 / 200 | iteration 60 / 171 | Total Loss: 2.4281885623931885 | KNN Loss: 2.407578229904175 | CLS Loss: 0.020610405132174492\n",
      "Epoch 182 / 200 | iteration 70 / 171 | Total Loss: 2.416821002960205 | KNN Loss: 2.4157705307006836 | CLS Loss: 0.0010503748198971152\n",
      "Epoch 182 / 200 | iteration 80 / 171 | Total Loss: 2.421902656555176 | KNN Loss: 2.4094274044036865 | CLS Loss: 0.012475191615521908\n",
      "Epoch 182 / 200 | iteration 90 / 171 | Total Loss: 2.3801820278167725 | KNN Loss: 2.378873109817505 | CLS Loss: 0.0013088657287880778\n",
      "Epoch 182 / 200 | iteration 100 / 171 | Total Loss: 2.4006295204162598 | KNN Loss: 2.3972582817077637 | CLS Loss: 0.003371176077052951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 / 200 | iteration 110 / 171 | Total Loss: 2.4333391189575195 | KNN Loss: 2.402238368988037 | CLS Loss: 0.031100701540708542\n",
      "Epoch 182 / 200 | iteration 120 / 171 | Total Loss: 2.443258047103882 | KNN Loss: 2.4226553440093994 | CLS Loss: 0.020602649077773094\n",
      "Epoch 182 / 200 | iteration 130 / 171 | Total Loss: 2.461087465286255 | KNN Loss: 2.448310136795044 | CLS Loss: 0.012777361087501049\n",
      "Epoch 182 / 200 | iteration 140 / 171 | Total Loss: 2.4481472969055176 | KNN Loss: 2.4400370121002197 | CLS Loss: 0.008110394701361656\n",
      "Epoch 182 / 200 | iteration 150 / 171 | Total Loss: 2.4079201221466064 | KNN Loss: 2.3979594707489014 | CLS Loss: 0.009960675612092018\n",
      "Epoch 182 / 200 | iteration 160 / 171 | Total Loss: 2.4123709201812744 | KNN Loss: 2.4099221229553223 | CLS Loss: 0.002448693383485079\n",
      "Epoch 182 / 200 | iteration 170 / 171 | Total Loss: 2.4348597526550293 | KNN Loss: 2.4313321113586426 | CLS Loss: 0.003527525346726179\n",
      "Epoch: 182, Loss: 2.4061, Train: 0.9966, Valid: 0.9868, Best: 0.9879\n",
      "Epoch 183 / 200 | iteration 0 / 171 | Total Loss: 2.4162378311157227 | KNN Loss: 2.4088966846466064 | CLS Loss: 0.007341200020164251\n",
      "Epoch 183 / 200 | iteration 10 / 171 | Total Loss: 2.4258227348327637 | KNN Loss: 2.4133596420288086 | CLS Loss: 0.012462991289794445\n",
      "Epoch 183 / 200 | iteration 20 / 171 | Total Loss: 2.432528018951416 | KNN Loss: 2.424609899520874 | CLS Loss: 0.007918142713606358\n",
      "Epoch 183 / 200 | iteration 30 / 171 | Total Loss: 2.3992960453033447 | KNN Loss: 2.3949391841888428 | CLS Loss: 0.004356839694082737\n",
      "Epoch 183 / 200 | iteration 40 / 171 | Total Loss: 2.400604009628296 | KNN Loss: 2.3935813903808594 | CLS Loss: 0.00702254381030798\n",
      "Epoch 183 / 200 | iteration 50 / 171 | Total Loss: 2.413156270980835 | KNN Loss: 2.3949928283691406 | CLS Loss: 0.018163420259952545\n",
      "Epoch 183 / 200 | iteration 60 / 171 | Total Loss: 2.388357639312744 | KNN Loss: 2.371441602706909 | CLS Loss: 0.016916025429964066\n",
      "Epoch 183 / 200 | iteration 70 / 171 | Total Loss: 2.398512363433838 | KNN Loss: 2.397308588027954 | CLS Loss: 0.001203889842145145\n",
      "Epoch 183 / 200 | iteration 80 / 171 | Total Loss: 2.3858466148376465 | KNN Loss: 2.3745925426483154 | CLS Loss: 0.011253966949880123\n",
      "Epoch 183 / 200 | iteration 90 / 171 | Total Loss: 2.4028995037078857 | KNN Loss: 2.398033380508423 | CLS Loss: 0.004866071045398712\n",
      "Epoch 183 / 200 | iteration 100 / 171 | Total Loss: 2.426776647567749 | KNN Loss: 2.4026243686676025 | CLS Loss: 0.024152306839823723\n",
      "Epoch 183 / 200 | iteration 110 / 171 | Total Loss: 2.416363000869751 | KNN Loss: 2.4137187004089355 | CLS Loss: 0.002644279971718788\n",
      "Epoch 183 / 200 | iteration 120 / 171 | Total Loss: 2.3947417736053467 | KNN Loss: 2.3826963901519775 | CLS Loss: 0.012045378796756268\n",
      "Epoch 183 / 200 | iteration 130 / 171 | Total Loss: 2.3786110877990723 | KNN Loss: 2.374513626098633 | CLS Loss: 0.0040975757874548435\n",
      "Epoch 183 / 200 | iteration 140 / 171 | Total Loss: 2.386577606201172 | KNN Loss: 2.3832736015319824 | CLS Loss: 0.0033040419220924377\n",
      "Epoch 183 / 200 | iteration 150 / 171 | Total Loss: 2.3942604064941406 | KNN Loss: 2.387589454650879 | CLS Loss: 0.006671026814728975\n",
      "Epoch 183 / 200 | iteration 160 / 171 | Total Loss: 2.3740739822387695 | KNN Loss: 2.358452796936035 | CLS Loss: 0.015621177852153778\n",
      "Epoch 183 / 200 | iteration 170 / 171 | Total Loss: 2.379566192626953 | KNN Loss: 2.3782026767730713 | CLS Loss: 0.0013634603237733245\n",
      "Epoch: 183, Loss: 2.4049, Train: 0.9977, Valid: 0.9870, Best: 0.9879\n",
      "Epoch 184 / 200 | iteration 0 / 171 | Total Loss: 2.3938276767730713 | KNN Loss: 2.374814510345459 | CLS Loss: 0.019013188779354095\n",
      "Epoch 184 / 200 | iteration 10 / 171 | Total Loss: 2.3859925270080566 | KNN Loss: 2.3768112659454346 | CLS Loss: 0.00918126106262207\n",
      "Epoch 184 / 200 | iteration 20 / 171 | Total Loss: 2.4124233722686768 | KNN Loss: 2.4090707302093506 | CLS Loss: 0.0033525878097862005\n",
      "Epoch 184 / 200 | iteration 30 / 171 | Total Loss: 2.422821521759033 | KNN Loss: 2.4133265018463135 | CLS Loss: 0.009495070204138756\n",
      "Epoch 184 / 200 | iteration 40 / 171 | Total Loss: 2.3951189517974854 | KNN Loss: 2.3910787105560303 | CLS Loss: 0.004040200728923082\n",
      "Epoch 184 / 200 | iteration 50 / 171 | Total Loss: 2.430638074874878 | KNN Loss: 2.418701410293579 | CLS Loss: 0.011936573311686516\n",
      "Epoch 184 / 200 | iteration 60 / 171 | Total Loss: 2.4137675762176514 | KNN Loss: 2.407203197479248 | CLS Loss: 0.0065643978305161\n",
      "Epoch 184 / 200 | iteration 70 / 171 | Total Loss: 2.4085893630981445 | KNN Loss: 2.398810863494873 | CLS Loss: 0.00977851077914238\n",
      "Epoch 184 / 200 | iteration 80 / 171 | Total Loss: 2.3710074424743652 | KNN Loss: 2.3664283752441406 | CLS Loss: 0.004579172004014254\n",
      "Epoch 184 / 200 | iteration 90 / 171 | Total Loss: 2.4089043140411377 | KNN Loss: 2.4081666469573975 | CLS Loss: 0.0007376564317382872\n",
      "Epoch 184 / 200 | iteration 100 / 171 | Total Loss: 2.386636257171631 | KNN Loss: 2.3667993545532227 | CLS Loss: 0.01983698643743992\n",
      "Epoch 184 / 200 | iteration 110 / 171 | Total Loss: 2.421365976333618 | KNN Loss: 2.418741226196289 | CLS Loss: 0.002624777378514409\n",
      "Epoch 184 / 200 | iteration 120 / 171 | Total Loss: 2.4105124473571777 | KNN Loss: 2.4084343910217285 | CLS Loss: 0.002078027930110693\n",
      "Epoch 184 / 200 | iteration 130 / 171 | Total Loss: 2.4055254459381104 | KNN Loss: 2.3922715187072754 | CLS Loss: 0.013253956101834774\n",
      "Epoch 184 / 200 | iteration 140 / 171 | Total Loss: 2.394479513168335 | KNN Loss: 2.3927550315856934 | CLS Loss: 0.0017244643531739712\n",
      "Epoch 184 / 200 | iteration 150 / 171 | Total Loss: 2.424072742462158 | KNN Loss: 2.4103307723999023 | CLS Loss: 0.013742010109126568\n",
      "Epoch 184 / 200 | iteration 160 / 171 | Total Loss: 2.414498805999756 | KNN Loss: 2.400038242340088 | CLS Loss: 0.014460592530667782\n",
      "Epoch 184 / 200 | iteration 170 / 171 | Total Loss: 2.412493944168091 | KNN Loss: 2.40828537940979 | CLS Loss: 0.004208512604236603\n",
      "Epoch: 184, Loss: 2.4138, Train: 0.9968, Valid: 0.9859, Best: 0.9879\n",
      "Epoch 185 / 200 | iteration 0 / 171 | Total Loss: 2.4336822032928467 | KNN Loss: 2.4176583290100098 | CLS Loss: 0.016023771837353706\n",
      "Epoch 185 / 200 | iteration 10 / 171 | Total Loss: 2.436591148376465 | KNN Loss: 2.429609775543213 | CLS Loss: 0.006981309037655592\n",
      "Epoch 185 / 200 | iteration 20 / 171 | Total Loss: 2.434678554534912 | KNN Loss: 2.4198484420776367 | CLS Loss: 0.014830012805759907\n",
      "Epoch 185 / 200 | iteration 30 / 171 | Total Loss: 2.4008917808532715 | KNN Loss: 2.3978865146636963 | CLS Loss: 0.003005286445841193\n",
      "Epoch 185 / 200 | iteration 40 / 171 | Total Loss: 2.41593599319458 | KNN Loss: 2.404514789581299 | CLS Loss: 0.011421087197959423\n",
      "Epoch 185 / 200 | iteration 50 / 171 | Total Loss: 2.406146287918091 | KNN Loss: 2.4002857208251953 | CLS Loss: 0.005860670004040003\n",
      "Epoch 185 / 200 | iteration 60 / 171 | Total Loss: 2.4309184551239014 | KNN Loss: 2.4200475215911865 | CLS Loss: 0.01087095495313406\n",
      "Epoch 185 / 200 | iteration 70 / 171 | Total Loss: 2.4536383152008057 | KNN Loss: 2.4301674365997314 | CLS Loss: 0.023470917716622353\n",
      "Epoch 185 / 200 | iteration 80 / 171 | Total Loss: 2.4208908081054688 | KNN Loss: 2.4181759357452393 | CLS Loss: 0.002714874455705285\n",
      "Epoch 185 / 200 | iteration 90 / 171 | Total Loss: 2.3917953968048096 | KNN Loss: 2.378821611404419 | CLS Loss: 0.012973790057003498\n",
      "Epoch 185 / 200 | iteration 100 / 171 | Total Loss: 2.4350264072418213 | KNN Loss: 2.422999620437622 | CLS Loss: 0.01202689204365015\n",
      "Epoch 185 / 200 | iteration 110 / 171 | Total Loss: 2.4206044673919678 | KNN Loss: 2.404909133911133 | CLS Loss: 0.015695367008447647\n",
      "Epoch 185 / 200 | iteration 120 / 171 | Total Loss: 2.3943233489990234 | KNN Loss: 2.390220880508423 | CLS Loss: 0.004102547653019428\n",
      "Epoch 185 / 200 | iteration 130 / 171 | Total Loss: 2.4159915447235107 | KNN Loss: 2.4064598083496094 | CLS Loss: 0.009531626477837563\n",
      "Epoch 185 / 200 | iteration 140 / 171 | Total Loss: 2.4404163360595703 | KNN Loss: 2.4297702312469482 | CLS Loss: 0.010646111331880093\n",
      "Epoch 185 / 200 | iteration 150 / 171 | Total Loss: 2.4176695346832275 | KNN Loss: 2.4147825241088867 | CLS Loss: 0.0028869735542684793\n",
      "Epoch 185 / 200 | iteration 160 / 171 | Total Loss: 2.392719268798828 | KNN Loss: 2.3877856731414795 | CLS Loss: 0.004933637101203203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185 / 200 | iteration 170 / 171 | Total Loss: 2.418367862701416 | KNN Loss: 2.410569667816162 | CLS Loss: 0.007798283360898495\n",
      "Epoch: 185, Loss: 2.4164, Train: 0.9969, Valid: 0.9858, Best: 0.9879\n",
      "Epoch 186 / 200 | iteration 0 / 171 | Total Loss: 2.4439210891723633 | KNN Loss: 2.420003890991211 | CLS Loss: 0.023917116224765778\n",
      "Epoch 186 / 200 | iteration 10 / 171 | Total Loss: 2.424248456954956 | KNN Loss: 2.4124906063079834 | CLS Loss: 0.011757914908230305\n",
      "Epoch 186 / 200 | iteration 20 / 171 | Total Loss: 2.4127585887908936 | KNN Loss: 2.4028172492980957 | CLS Loss: 0.00994129665195942\n",
      "Epoch 186 / 200 | iteration 30 / 171 | Total Loss: 2.4063804149627686 | KNN Loss: 2.396390914916992 | CLS Loss: 0.009989582002162933\n",
      "Epoch 186 / 200 | iteration 40 / 171 | Total Loss: 2.385514259338379 | KNN Loss: 2.378171920776367 | CLS Loss: 0.00734240235760808\n",
      "Epoch 186 / 200 | iteration 50 / 171 | Total Loss: 2.4034523963928223 | KNN Loss: 2.3900885581970215 | CLS Loss: 0.013363897800445557\n",
      "Epoch 186 / 200 | iteration 60 / 171 | Total Loss: 2.4122848510742188 | KNN Loss: 2.408957004547119 | CLS Loss: 0.0033279147464782\n",
      "Epoch 186 / 200 | iteration 70 / 171 | Total Loss: 2.4231250286102295 | KNN Loss: 2.396704912185669 | CLS Loss: 0.026420198380947113\n",
      "Epoch 186 / 200 | iteration 80 / 171 | Total Loss: 2.4407150745391846 | KNN Loss: 2.427987575531006 | CLS Loss: 0.012727455236017704\n",
      "Epoch 186 / 200 | iteration 90 / 171 | Total Loss: 2.421372413635254 | KNN Loss: 2.4187111854553223 | CLS Loss: 0.002661200938746333\n",
      "Epoch 186 / 200 | iteration 100 / 171 | Total Loss: 2.3844666481018066 | KNN Loss: 2.383066177368164 | CLS Loss: 0.0014004709664732218\n",
      "Epoch 186 / 200 | iteration 110 / 171 | Total Loss: 2.3929548263549805 | KNN Loss: 2.382965326309204 | CLS Loss: 0.009989431127905846\n",
      "Epoch 186 / 200 | iteration 120 / 171 | Total Loss: 2.429705858230591 | KNN Loss: 2.426576852798462 | CLS Loss: 0.0031289902981370687\n",
      "Epoch 186 / 200 | iteration 130 / 171 | Total Loss: 2.404099225997925 | KNN Loss: 2.396759033203125 | CLS Loss: 0.007340214680880308\n",
      "Epoch 186 / 200 | iteration 140 / 171 | Total Loss: 2.399930953979492 | KNN Loss: 2.39853572845459 | CLS Loss: 0.001395249622873962\n",
      "Epoch 186 / 200 | iteration 150 / 171 | Total Loss: 2.4121997356414795 | KNN Loss: 2.3958685398101807 | CLS Loss: 0.01633121445775032\n",
      "Epoch 186 / 200 | iteration 160 / 171 | Total Loss: 2.4174771308898926 | KNN Loss: 2.3922486305236816 | CLS Loss: 0.025228582322597504\n",
      "Epoch 186 / 200 | iteration 170 / 171 | Total Loss: 2.411630153656006 | KNN Loss: 2.405857801437378 | CLS Loss: 0.005772439297288656\n",
      "Epoch: 186, Loss: 2.4176, Train: 0.9976, Valid: 0.9863, Best: 0.9879\n",
      "Epoch 187 / 200 | iteration 0 / 171 | Total Loss: 2.4721364974975586 | KNN Loss: 2.4670233726501465 | CLS Loss: 0.005113091319799423\n",
      "Epoch 187 / 200 | iteration 10 / 171 | Total Loss: 2.4516372680664062 | KNN Loss: 2.4304113388061523 | CLS Loss: 0.02122603729367256\n",
      "Epoch 187 / 200 | iteration 20 / 171 | Total Loss: 2.430582046508789 | KNN Loss: 2.4131247997283936 | CLS Loss: 0.017457157373428345\n",
      "Epoch 187 / 200 | iteration 30 / 171 | Total Loss: 2.411858081817627 | KNN Loss: 2.3902781009674072 | CLS Loss: 0.02158001996576786\n",
      "Epoch 187 / 200 | iteration 40 / 171 | Total Loss: 2.46614670753479 | KNN Loss: 2.4630584716796875 | CLS Loss: 0.003088305937126279\n",
      "Epoch 187 / 200 | iteration 50 / 171 | Total Loss: 2.3809804916381836 | KNN Loss: 2.35711932182312 | CLS Loss: 0.02386106364428997\n",
      "Epoch 187 / 200 | iteration 60 / 171 | Total Loss: 2.4171009063720703 | KNN Loss: 2.4128270149230957 | CLS Loss: 0.004273786675184965\n",
      "Epoch 187 / 200 | iteration 70 / 171 | Total Loss: 2.3970041275024414 | KNN Loss: 2.3939523696899414 | CLS Loss: 0.0030518488492816687\n",
      "Epoch 187 / 200 | iteration 80 / 171 | Total Loss: 2.398982048034668 | KNN Loss: 2.3838961124420166 | CLS Loss: 0.015085863880813122\n",
      "Epoch 187 / 200 | iteration 90 / 171 | Total Loss: 2.437030553817749 | KNN Loss: 2.409198760986328 | CLS Loss: 0.027831777930259705\n",
      "Epoch 187 / 200 | iteration 100 / 171 | Total Loss: 2.43254017829895 | KNN Loss: 2.4141907691955566 | CLS Loss: 0.018349526450037956\n",
      "Epoch 187 / 200 | iteration 110 / 171 | Total Loss: 2.439836025238037 | KNN Loss: 2.4234907627105713 | CLS Loss: 0.016345269978046417\n",
      "Epoch 187 / 200 | iteration 120 / 171 | Total Loss: 2.4554831981658936 | KNN Loss: 2.449075222015381 | CLS Loss: 0.006408093962818384\n",
      "Epoch 187 / 200 | iteration 130 / 171 | Total Loss: 2.3996126651763916 | KNN Loss: 2.389821767807007 | CLS Loss: 0.009790923446416855\n",
      "Epoch 187 / 200 | iteration 140 / 171 | Total Loss: 2.460183620452881 | KNN Loss: 2.4431591033935547 | CLS Loss: 0.01702447235584259\n",
      "Epoch 187 / 200 | iteration 150 / 171 | Total Loss: 2.3941540718078613 | KNN Loss: 2.3890163898468018 | CLS Loss: 0.005137658212333918\n",
      "Epoch 187 / 200 | iteration 160 / 171 | Total Loss: 2.414888381958008 | KNN Loss: 2.391618013381958 | CLS Loss: 0.023270389065146446\n",
      "Epoch 187 / 200 | iteration 170 / 171 | Total Loss: 2.4474878311157227 | KNN Loss: 2.4337728023529053 | CLS Loss: 0.013714948669075966\n",
      "Epoch: 187, Loss: 2.4212, Train: 0.9972, Valid: 0.9863, Best: 0.9879\n",
      "Epoch 188 / 200 | iteration 0 / 171 | Total Loss: 2.400775671005249 | KNN Loss: 2.3998372554779053 | CLS Loss: 0.0009384609293192625\n",
      "Epoch 188 / 200 | iteration 10 / 171 | Total Loss: 2.4466679096221924 | KNN Loss: 2.4243717193603516 | CLS Loss: 0.02229626663029194\n",
      "Epoch 188 / 200 | iteration 20 / 171 | Total Loss: 2.4224774837493896 | KNN Loss: 2.417689085006714 | CLS Loss: 0.004788389895111322\n",
      "Epoch 188 / 200 | iteration 30 / 171 | Total Loss: 2.4341650009155273 | KNN Loss: 2.4237701892852783 | CLS Loss: 0.01039474830031395\n",
      "Epoch 188 / 200 | iteration 40 / 171 | Total Loss: 2.427778959274292 | KNN Loss: 2.4247827529907227 | CLS Loss: 0.002996229100972414\n",
      "Epoch 188 / 200 | iteration 50 / 171 | Total Loss: 2.3896191120147705 | KNN Loss: 2.3835208415985107 | CLS Loss: 0.006098214536905289\n",
      "Epoch 188 / 200 | iteration 60 / 171 | Total Loss: 2.425199508666992 | KNN Loss: 2.4217095375061035 | CLS Loss: 0.0034900736063718796\n",
      "Epoch 188 / 200 | iteration 70 / 171 | Total Loss: 2.4246468544006348 | KNN Loss: 2.4218087196350098 | CLS Loss: 0.0028380595613271\n",
      "Epoch 188 / 200 | iteration 80 / 171 | Total Loss: 2.397199869155884 | KNN Loss: 2.39345121383667 | CLS Loss: 0.0037486935034394264\n",
      "Epoch 188 / 200 | iteration 90 / 171 | Total Loss: 2.3982481956481934 | KNN Loss: 2.3856678009033203 | CLS Loss: 0.01258028857409954\n",
      "Epoch 188 / 200 | iteration 100 / 171 | Total Loss: 2.46401309967041 | KNN Loss: 2.4578161239624023 | CLS Loss: 0.006197008304297924\n",
      "Epoch 188 / 200 | iteration 110 / 171 | Total Loss: 2.388410806655884 | KNN Loss: 2.383401870727539 | CLS Loss: 0.005008886102586985\n",
      "Epoch 188 / 200 | iteration 120 / 171 | Total Loss: 2.39544415473938 | KNN Loss: 2.3885304927825928 | CLS Loss: 0.006913603283464909\n",
      "Epoch 188 / 200 | iteration 130 / 171 | Total Loss: 2.44398832321167 | KNN Loss: 2.414985418319702 | CLS Loss: 0.029003005474805832\n",
      "Epoch 188 / 200 | iteration 140 / 171 | Total Loss: 2.4304845333099365 | KNN Loss: 2.4165470600128174 | CLS Loss: 0.013937495648860931\n",
      "Epoch 188 / 200 | iteration 150 / 171 | Total Loss: 2.3880228996276855 | KNN Loss: 2.38191819190979 | CLS Loss: 0.006104708649218082\n",
      "Epoch 188 / 200 | iteration 160 / 171 | Total Loss: 2.4446234703063965 | KNN Loss: 2.4276437759399414 | CLS Loss: 0.016979582607746124\n",
      "Epoch 188 / 200 | iteration 170 / 171 | Total Loss: 2.4129998683929443 | KNN Loss: 2.408154249191284 | CLS Loss: 0.004845707211643457\n",
      "Epoch: 188, Loss: 2.4143, Train: 0.9975, Valid: 0.9871, Best: 0.9879\n",
      "Epoch 189 / 200 | iteration 0 / 171 | Total Loss: 2.415924072265625 | KNN Loss: 2.413226366043091 | CLS Loss: 0.0026975905057042837\n",
      "Epoch 189 / 200 | iteration 10 / 171 | Total Loss: 2.442546844482422 | KNN Loss: 2.427201986312866 | CLS Loss: 0.015344871208071709\n",
      "Epoch 189 / 200 | iteration 20 / 171 | Total Loss: 2.453674793243408 | KNN Loss: 2.4418928623199463 | CLS Loss: 0.01178192999213934\n",
      "Epoch 189 / 200 | iteration 30 / 171 | Total Loss: 2.3864688873291016 | KNN Loss: 2.3723325729370117 | CLS Loss: 0.014136315323412418\n",
      "Epoch 189 / 200 | iteration 40 / 171 | Total Loss: 2.37221360206604 | KNN Loss: 2.3699374198913574 | CLS Loss: 0.0022760757710784674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 / 200 | iteration 50 / 171 | Total Loss: 2.4163219928741455 | KNN Loss: 2.404879331588745 | CLS Loss: 0.011442761868238449\n",
      "Epoch 189 / 200 | iteration 60 / 171 | Total Loss: 2.388144016265869 | KNN Loss: 2.3862338066101074 | CLS Loss: 0.00191009440459311\n",
      "Epoch 189 / 200 | iteration 70 / 171 | Total Loss: 2.4168198108673096 | KNN Loss: 2.4165663719177246 | CLS Loss: 0.0002535441890358925\n",
      "Epoch 189 / 200 | iteration 80 / 171 | Total Loss: 2.3894286155700684 | KNN Loss: 2.382960081100464 | CLS Loss: 0.006468483246862888\n",
      "Epoch 189 / 200 | iteration 90 / 171 | Total Loss: 2.3842203617095947 | KNN Loss: 2.3822245597839355 | CLS Loss: 0.0019959076307713985\n",
      "Epoch 189 / 200 | iteration 100 / 171 | Total Loss: 2.443408966064453 | KNN Loss: 2.442505121231079 | CLS Loss: 0.0009037788840942085\n",
      "Epoch 189 / 200 | iteration 110 / 171 | Total Loss: 2.414090156555176 | KNN Loss: 2.3917224407196045 | CLS Loss: 0.022367624565958977\n",
      "Epoch 189 / 200 | iteration 120 / 171 | Total Loss: 2.41288685798645 | KNN Loss: 2.400524616241455 | CLS Loss: 0.0123622240498662\n",
      "Epoch 189 / 200 | iteration 130 / 171 | Total Loss: 2.4124088287353516 | KNN Loss: 2.4072766304016113 | CLS Loss: 0.005132273305207491\n",
      "Epoch 189 / 200 | iteration 140 / 171 | Total Loss: 2.374952554702759 | KNN Loss: 2.3745529651641846 | CLS Loss: 0.00039959122659638524\n",
      "Epoch 189 / 200 | iteration 150 / 171 | Total Loss: 2.395510196685791 | KNN Loss: 2.3934879302978516 | CLS Loss: 0.00202223751693964\n",
      "Epoch 189 / 200 | iteration 160 / 171 | Total Loss: 2.3965399265289307 | KNN Loss: 2.372441530227661 | CLS Loss: 0.024098407477140427\n",
      "Epoch 189 / 200 | iteration 170 / 171 | Total Loss: 2.413710832595825 | KNN Loss: 2.3929548263549805 | CLS Loss: 0.020755896344780922\n",
      "Epoch: 189, Loss: 2.4127, Train: 0.9975, Valid: 0.9863, Best: 0.9879\n",
      "Epoch 190 / 200 | iteration 0 / 171 | Total Loss: 2.4779889583587646 | KNN Loss: 2.4745068550109863 | CLS Loss: 0.0034821717999875546\n",
      "Epoch 190 / 200 | iteration 10 / 171 | Total Loss: 2.3643319606781006 | KNN Loss: 2.3625242710113525 | CLS Loss: 0.0018076589331030846\n",
      "Epoch 190 / 200 | iteration 20 / 171 | Total Loss: 2.4021191596984863 | KNN Loss: 2.3960297107696533 | CLS Loss: 0.006089491304010153\n",
      "Epoch 190 / 200 | iteration 30 / 171 | Total Loss: 2.422452688217163 | KNN Loss: 2.406101703643799 | CLS Loss: 0.016351033002138138\n",
      "Epoch 190 / 200 | iteration 40 / 171 | Total Loss: 2.4610843658447266 | KNN Loss: 2.4501078128814697 | CLS Loss: 0.01097665261477232\n",
      "Epoch 190 / 200 | iteration 50 / 171 | Total Loss: 2.4861934185028076 | KNN Loss: 2.4794816970825195 | CLS Loss: 0.0067116799764335155\n",
      "Epoch 190 / 200 | iteration 60 / 171 | Total Loss: 2.4047188758850098 | KNN Loss: 2.394237995147705 | CLS Loss: 0.010480857454240322\n",
      "Epoch 190 / 200 | iteration 70 / 171 | Total Loss: 2.466887950897217 | KNN Loss: 2.4612135887145996 | CLS Loss: 0.005674343090504408\n",
      "Epoch 190 / 200 | iteration 80 / 171 | Total Loss: 2.4330086708068848 | KNN Loss: 2.4241883754730225 | CLS Loss: 0.008820382878184319\n",
      "Epoch 190 / 200 | iteration 90 / 171 | Total Loss: 2.3763771057128906 | KNN Loss: 2.3564183712005615 | CLS Loss: 0.019958827644586563\n",
      "Epoch 190 / 200 | iteration 100 / 171 | Total Loss: 2.4298934936523438 | KNN Loss: 2.4263925552368164 | CLS Loss: 0.0035008741542696953\n",
      "Epoch 190 / 200 | iteration 110 / 171 | Total Loss: 2.4254672527313232 | KNN Loss: 2.414693593978882 | CLS Loss: 0.010773560032248497\n",
      "Epoch 190 / 200 | iteration 120 / 171 | Total Loss: 2.415811538696289 | KNN Loss: 2.4009292125701904 | CLS Loss: 0.01488236989825964\n",
      "Epoch 190 / 200 | iteration 130 / 171 | Total Loss: 2.3949618339538574 | KNN Loss: 2.394415855407715 | CLS Loss: 0.0005458967061713338\n",
      "Epoch 190 / 200 | iteration 140 / 171 | Total Loss: 2.416825771331787 | KNN Loss: 2.411608934402466 | CLS Loss: 0.005216791294515133\n",
      "Epoch 190 / 200 | iteration 150 / 171 | Total Loss: 2.4202311038970947 | KNN Loss: 2.410071611404419 | CLS Loss: 0.01015951856970787\n",
      "Epoch 190 / 200 | iteration 160 / 171 | Total Loss: 2.4172286987304688 | KNN Loss: 2.4112966060638428 | CLS Loss: 0.005932185798883438\n",
      "Epoch 190 / 200 | iteration 170 / 171 | Total Loss: 2.4187872409820557 | KNN Loss: 2.4109573364257812 | CLS Loss: 0.007829951122403145\n",
      "Epoch: 190, Loss: 2.4156, Train: 0.9974, Valid: 0.9861, Best: 0.9879\n",
      "Epoch 191 / 200 | iteration 0 / 171 | Total Loss: 2.3890299797058105 | KNN Loss: 2.37249493598938 | CLS Loss: 0.01653498411178589\n",
      "Epoch 191 / 200 | iteration 10 / 171 | Total Loss: 2.438051700592041 | KNN Loss: 2.4356765747070312 | CLS Loss: 0.002375236712396145\n",
      "Epoch 191 / 200 | iteration 20 / 171 | Total Loss: 2.385580539703369 | KNN Loss: 2.384495973587036 | CLS Loss: 0.0010845307260751724\n",
      "Epoch 191 / 200 | iteration 30 / 171 | Total Loss: 2.4343559741973877 | KNN Loss: 2.4326884746551514 | CLS Loss: 0.001667428994551301\n",
      "Epoch 191 / 200 | iteration 40 / 171 | Total Loss: 2.3978893756866455 | KNN Loss: 2.3935256004333496 | CLS Loss: 0.004363871179521084\n",
      "Epoch 191 / 200 | iteration 50 / 171 | Total Loss: 2.4218709468841553 | KNN Loss: 2.412125825881958 | CLS Loss: 0.009745071642100811\n",
      "Epoch 191 / 200 | iteration 60 / 171 | Total Loss: 2.4042587280273438 | KNN Loss: 2.4019269943237305 | CLS Loss: 0.0023318103048950434\n",
      "Epoch 191 / 200 | iteration 70 / 171 | Total Loss: 2.3971450328826904 | KNN Loss: 2.3922765254974365 | CLS Loss: 0.004868407733738422\n",
      "Epoch 191 / 200 | iteration 80 / 171 | Total Loss: 2.416844367980957 | KNN Loss: 2.414489984512329 | CLS Loss: 0.0023543029092252254\n",
      "Epoch 191 / 200 | iteration 90 / 171 | Total Loss: 2.442110061645508 | KNN Loss: 2.436267137527466 | CLS Loss: 0.005842978600412607\n",
      "Epoch 191 / 200 | iteration 100 / 171 | Total Loss: 2.403811454772949 | KNN Loss: 2.3975250720977783 | CLS Loss: 0.006286486517637968\n",
      "Epoch 191 / 200 | iteration 110 / 171 | Total Loss: 2.417419195175171 | KNN Loss: 2.414517641067505 | CLS Loss: 0.002901672385632992\n",
      "Epoch 191 / 200 | iteration 120 / 171 | Total Loss: 2.452357292175293 | KNN Loss: 2.4375247955322266 | CLS Loss: 0.014832420274615288\n",
      "Epoch 191 / 200 | iteration 130 / 171 | Total Loss: 2.423032522201538 | KNN Loss: 2.4111196994781494 | CLS Loss: 0.011912706308066845\n",
      "Epoch 191 / 200 | iteration 140 / 171 | Total Loss: 2.4650418758392334 | KNN Loss: 2.4517369270324707 | CLS Loss: 0.013305050320923328\n",
      "Epoch 191 / 200 | iteration 150 / 171 | Total Loss: 2.409878969192505 | KNN Loss: 2.390195369720459 | CLS Loss: 0.01968351937830448\n",
      "Epoch 191 / 200 | iteration 160 / 171 | Total Loss: 2.4118692874908447 | KNN Loss: 2.4043989181518555 | CLS Loss: 0.007470371667295694\n",
      "Epoch 191 / 200 | iteration 170 / 171 | Total Loss: 2.4531712532043457 | KNN Loss: 2.4399826526641846 | CLS Loss: 0.013188696466386318\n",
      "Epoch: 191, Loss: 2.4149, Train: 0.9968, Valid: 0.9863, Best: 0.9879\n",
      "Epoch 192 / 200 | iteration 0 / 171 | Total Loss: 2.38594388961792 | KNN Loss: 2.3647000789642334 | CLS Loss: 0.021243732422590256\n",
      "Epoch 192 / 200 | iteration 10 / 171 | Total Loss: 2.3860907554626465 | KNN Loss: 2.3840548992156982 | CLS Loss: 0.002035797806456685\n",
      "Epoch 192 / 200 | iteration 20 / 171 | Total Loss: 2.423353910446167 | KNN Loss: 2.418574810028076 | CLS Loss: 0.004778983071446419\n",
      "Epoch 192 / 200 | iteration 30 / 171 | Total Loss: 2.3975534439086914 | KNN Loss: 2.3917794227600098 | CLS Loss: 0.005774134304374456\n",
      "Epoch 192 / 200 | iteration 40 / 171 | Total Loss: 2.436220645904541 | KNN Loss: 2.417487621307373 | CLS Loss: 0.0187329463660717\n",
      "Epoch 192 / 200 | iteration 50 / 171 | Total Loss: 2.432054042816162 | KNN Loss: 2.3981103897094727 | CLS Loss: 0.03394373506307602\n",
      "Epoch 192 / 200 | iteration 60 / 171 | Total Loss: 2.4126040935516357 | KNN Loss: 2.4096803665161133 | CLS Loss: 0.0029236311092972755\n",
      "Epoch 192 / 200 | iteration 70 / 171 | Total Loss: 2.4187347888946533 | KNN Loss: 2.4044058322906494 | CLS Loss: 0.014329008758068085\n",
      "Epoch 192 / 200 | iteration 80 / 171 | Total Loss: 2.438122510910034 | KNN Loss: 2.423668384552002 | CLS Loss: 0.014454119838774204\n",
      "Epoch 192 / 200 | iteration 90 / 171 | Total Loss: 2.3780415058135986 | KNN Loss: 2.3713600635528564 | CLS Loss: 0.006681419909000397\n",
      "Epoch 192 / 200 | iteration 100 / 171 | Total Loss: 2.4202122688293457 | KNN Loss: 2.4162707328796387 | CLS Loss: 0.0039415680803358555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 / 200 | iteration 110 / 171 | Total Loss: 2.43387508392334 | KNN Loss: 2.4193668365478516 | CLS Loss: 0.014508312568068504\n",
      "Epoch 192 / 200 | iteration 120 / 171 | Total Loss: 2.4155220985412598 | KNN Loss: 2.3944644927978516 | CLS Loss: 0.021057486534118652\n",
      "Epoch 192 / 200 | iteration 130 / 171 | Total Loss: 2.4336280822753906 | KNN Loss: 2.4298341274261475 | CLS Loss: 0.0037940246984362602\n",
      "Epoch 192 / 200 | iteration 140 / 171 | Total Loss: 2.422480344772339 | KNN Loss: 2.409694194793701 | CLS Loss: 0.012786205857992172\n",
      "Epoch 192 / 200 | iteration 150 / 171 | Total Loss: 2.4170117378234863 | KNN Loss: 2.4160447120666504 | CLS Loss: 0.0009671399020589888\n",
      "Epoch 192 / 200 | iteration 160 / 171 | Total Loss: 2.416262626647949 | KNN Loss: 2.410883903503418 | CLS Loss: 0.005378612782806158\n",
      "Epoch 192 / 200 | iteration 170 / 171 | Total Loss: 2.4066991806030273 | KNN Loss: 2.402902364730835 | CLS Loss: 0.003796837292611599\n",
      "Epoch: 192, Loss: 2.4150, Train: 0.9973, Valid: 0.9873, Best: 0.9879\n",
      "Epoch 193 / 200 | iteration 0 / 171 | Total Loss: 2.4385898113250732 | KNN Loss: 2.4348044395446777 | CLS Loss: 0.0037853303365409374\n",
      "Epoch 193 / 200 | iteration 10 / 171 | Total Loss: 2.445056915283203 | KNN Loss: 2.4380862712860107 | CLS Loss: 0.006970535032451153\n",
      "Epoch 193 / 200 | iteration 20 / 171 | Total Loss: 2.434954881668091 | KNN Loss: 2.4304914474487305 | CLS Loss: 0.004463549703359604\n",
      "Epoch 193 / 200 | iteration 30 / 171 | Total Loss: 2.420011520385742 | KNN Loss: 2.4170005321502686 | CLS Loss: 0.003011087654158473\n",
      "Epoch 193 / 200 | iteration 40 / 171 | Total Loss: 2.407733678817749 | KNN Loss: 2.3993656635284424 | CLS Loss: 0.008367929607629776\n",
      "Epoch 193 / 200 | iteration 50 / 171 | Total Loss: 2.438499927520752 | KNN Loss: 2.4359965324401855 | CLS Loss: 0.002503501484170556\n",
      "Epoch 193 / 200 | iteration 60 / 171 | Total Loss: 2.396230459213257 | KNN Loss: 2.385438919067383 | CLS Loss: 0.010791550390422344\n",
      "Epoch 193 / 200 | iteration 70 / 171 | Total Loss: 2.393601894378662 | KNN Loss: 2.3868813514709473 | CLS Loss: 0.00672062486410141\n",
      "Epoch 193 / 200 | iteration 80 / 171 | Total Loss: 2.407158136367798 | KNN Loss: 2.4044880867004395 | CLS Loss: 0.0026700713206082582\n",
      "Epoch 193 / 200 | iteration 90 / 171 | Total Loss: 2.39445161819458 | KNN Loss: 2.393428325653076 | CLS Loss: 0.0010233143111690879\n",
      "Epoch 193 / 200 | iteration 100 / 171 | Total Loss: 2.415541172027588 | KNN Loss: 2.4147937297821045 | CLS Loss: 0.0007475250749848783\n",
      "Epoch 193 / 200 | iteration 110 / 171 | Total Loss: 2.417029619216919 | KNN Loss: 2.4122042655944824 | CLS Loss: 0.004825282376259565\n",
      "Epoch 193 / 200 | iteration 120 / 171 | Total Loss: 2.407111167907715 | KNN Loss: 2.3964555263519287 | CLS Loss: 0.010655693709850311\n",
      "Epoch 193 / 200 | iteration 130 / 171 | Total Loss: 2.402256727218628 | KNN Loss: 2.4007582664489746 | CLS Loss: 0.0014983571600168943\n",
      "Epoch 193 / 200 | iteration 140 / 171 | Total Loss: 2.3716180324554443 | KNN Loss: 2.367551326751709 | CLS Loss: 0.004066721070557833\n",
      "Epoch 193 / 200 | iteration 150 / 171 | Total Loss: 2.396148681640625 | KNN Loss: 2.3911898136138916 | CLS Loss: 0.004958906210958958\n",
      "Epoch 193 / 200 | iteration 160 / 171 | Total Loss: 2.4177772998809814 | KNN Loss: 2.4149153232574463 | CLS Loss: 0.0028619763907045126\n",
      "Epoch 193 / 200 | iteration 170 / 171 | Total Loss: 2.407275915145874 | KNN Loss: 2.3943634033203125 | CLS Loss: 0.012912523001432419\n",
      "Epoch: 193, Loss: 2.4098, Train: 0.9979, Valid: 0.9867, Best: 0.9879\n",
      "Epoch 194 / 200 | iteration 0 / 171 | Total Loss: 2.443260908126831 | KNN Loss: 2.4399187564849854 | CLS Loss: 0.0033422529231756926\n",
      "Epoch 194 / 200 | iteration 10 / 171 | Total Loss: 2.4238674640655518 | KNN Loss: 2.4195191860198975 | CLS Loss: 0.004348329268395901\n",
      "Epoch 194 / 200 | iteration 20 / 171 | Total Loss: 2.410205364227295 | KNN Loss: 2.386789321899414 | CLS Loss: 0.0234160665422678\n",
      "Epoch 194 / 200 | iteration 30 / 171 | Total Loss: 2.424726963043213 | KNN Loss: 2.3991763591766357 | CLS Loss: 0.025550642982125282\n",
      "Epoch 194 / 200 | iteration 40 / 171 | Total Loss: 2.363631010055542 | KNN Loss: 2.357492446899414 | CLS Loss: 0.006138623226433992\n",
      "Epoch 194 / 200 | iteration 50 / 171 | Total Loss: 2.43558931350708 | KNN Loss: 2.4322195053100586 | CLS Loss: 0.0033698196057230234\n",
      "Epoch 194 / 200 | iteration 60 / 171 | Total Loss: 2.394437313079834 | KNN Loss: 2.377957582473755 | CLS Loss: 0.016479672864079475\n",
      "Epoch 194 / 200 | iteration 70 / 171 | Total Loss: 2.4239063262939453 | KNN Loss: 2.4197754859924316 | CLS Loss: 0.0041309441439807415\n",
      "Epoch 194 / 200 | iteration 80 / 171 | Total Loss: 2.435086488723755 | KNN Loss: 2.4309980869293213 | CLS Loss: 0.004088310990482569\n",
      "Epoch 194 / 200 | iteration 90 / 171 | Total Loss: 2.450490951538086 | KNN Loss: 2.4413702487945557 | CLS Loss: 0.009120611473917961\n",
      "Epoch 194 / 200 | iteration 100 / 171 | Total Loss: 2.4008796215057373 | KNN Loss: 2.397526741027832 | CLS Loss: 0.003352939151227474\n",
      "Epoch 194 / 200 | iteration 110 / 171 | Total Loss: 2.405557870864868 | KNN Loss: 2.379283905029297 | CLS Loss: 0.026274017989635468\n",
      "Epoch 194 / 200 | iteration 120 / 171 | Total Loss: 2.4555959701538086 | KNN Loss: 2.443026542663574 | CLS Loss: 0.012569358572363853\n",
      "Epoch 194 / 200 | iteration 130 / 171 | Total Loss: 2.4576799869537354 | KNN Loss: 2.431515693664551 | CLS Loss: 0.02616439200937748\n",
      "Epoch 194 / 200 | iteration 140 / 171 | Total Loss: 2.402463912963867 | KNN Loss: 2.39420747756958 | CLS Loss: 0.008256510831415653\n",
      "Epoch 194 / 200 | iteration 150 / 171 | Total Loss: 2.410243272781372 | KNN Loss: 2.4021880626678467 | CLS Loss: 0.008055252954363823\n",
      "Epoch 194 / 200 | iteration 160 / 171 | Total Loss: 2.4128191471099854 | KNN Loss: 2.4037585258483887 | CLS Loss: 0.009060697630047798\n",
      "Epoch 194 / 200 | iteration 170 / 171 | Total Loss: 2.4384257793426514 | KNN Loss: 2.4264893531799316 | CLS Loss: 0.011936325579881668\n",
      "Epoch: 194, Loss: 2.4141, Train: 0.9975, Valid: 0.9871, Best: 0.9879\n",
      "Epoch 195 / 200 | iteration 0 / 171 | Total Loss: 2.414292335510254 | KNN Loss: 2.401686429977417 | CLS Loss: 0.012605829164385796\n",
      "Epoch 195 / 200 | iteration 10 / 171 | Total Loss: 2.3980188369750977 | KNN Loss: 2.3935706615448 | CLS Loss: 0.00444808229804039\n",
      "Epoch 195 / 200 | iteration 20 / 171 | Total Loss: 2.412137269973755 | KNN Loss: 2.4090445041656494 | CLS Loss: 0.0030928771011531353\n",
      "Epoch 195 / 200 | iteration 30 / 171 | Total Loss: 2.4435665607452393 | KNN Loss: 2.4347591400146484 | CLS Loss: 0.008807397447526455\n",
      "Epoch 195 / 200 | iteration 40 / 171 | Total Loss: 2.424187660217285 | KNN Loss: 2.406773328781128 | CLS Loss: 0.01741435006260872\n",
      "Epoch 195 / 200 | iteration 50 / 171 | Total Loss: 2.429863929748535 | KNN Loss: 2.402097463607788 | CLS Loss: 0.027766374871134758\n",
      "Epoch 195 / 200 | iteration 60 / 171 | Total Loss: 2.4322550296783447 | KNN Loss: 2.430525302886963 | CLS Loss: 0.0017297550803050399\n",
      "Epoch 195 / 200 | iteration 70 / 171 | Total Loss: 2.392540454864502 | KNN Loss: 2.3778486251831055 | CLS Loss: 0.014691800810396671\n",
      "Epoch 195 / 200 | iteration 80 / 171 | Total Loss: 2.3956844806671143 | KNN Loss: 2.383876085281372 | CLS Loss: 0.011808407492935658\n",
      "Epoch 195 / 200 | iteration 90 / 171 | Total Loss: 2.428800344467163 | KNN Loss: 2.4209141731262207 | CLS Loss: 0.007886126637458801\n",
      "Epoch 195 / 200 | iteration 100 / 171 | Total Loss: 2.441243886947632 | KNN Loss: 2.435567855834961 | CLS Loss: 0.005675956141203642\n",
      "Epoch 195 / 200 | iteration 110 / 171 | Total Loss: 2.39532208442688 | KNN Loss: 2.3922019004821777 | CLS Loss: 0.003120159264653921\n",
      "Epoch 195 / 200 | iteration 120 / 171 | Total Loss: 2.416827917098999 | KNN Loss: 2.4069583415985107 | CLS Loss: 0.009869690053164959\n",
      "Epoch 195 / 200 | iteration 130 / 171 | Total Loss: 2.3962879180908203 | KNN Loss: 2.3948850631713867 | CLS Loss: 0.0014028252335265279\n",
      "Epoch 195 / 200 | iteration 140 / 171 | Total Loss: 2.403381109237671 | KNN Loss: 2.3769946098327637 | CLS Loss: 0.026386525481939316\n",
      "Epoch 195 / 200 | iteration 150 / 171 | Total Loss: 2.4172868728637695 | KNN Loss: 2.4155218601226807 | CLS Loss: 0.0017649756046012044\n",
      "Epoch 195 / 200 | iteration 160 / 171 | Total Loss: 2.4239799976348877 | KNN Loss: 2.415170192718506 | CLS Loss: 0.008809909224510193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195 / 200 | iteration 170 / 171 | Total Loss: 2.4165523052215576 | KNN Loss: 2.3889713287353516 | CLS Loss: 0.02758098393678665\n",
      "Epoch: 195, Loss: 2.4115, Train: 0.9972, Valid: 0.9874, Best: 0.9879\n",
      "Epoch 196 / 200 | iteration 0 / 171 | Total Loss: 2.4283392429351807 | KNN Loss: 2.4202663898468018 | CLS Loss: 0.008072968572378159\n",
      "Epoch 196 / 200 | iteration 10 / 171 | Total Loss: 2.3838796615600586 | KNN Loss: 2.382077932357788 | CLS Loss: 0.0018016919493675232\n",
      "Epoch 196 / 200 | iteration 20 / 171 | Total Loss: 2.477060079574585 | KNN Loss: 2.4472100734710693 | CLS Loss: 0.02985006384551525\n",
      "Epoch 196 / 200 | iteration 30 / 171 | Total Loss: 2.4015281200408936 | KNN Loss: 2.390451669692993 | CLS Loss: 0.011076342314481735\n",
      "Epoch 196 / 200 | iteration 40 / 171 | Total Loss: 2.4147157669067383 | KNN Loss: 2.410370111465454 | CLS Loss: 0.004345686640590429\n",
      "Epoch 196 / 200 | iteration 50 / 171 | Total Loss: 2.4007561206817627 | KNN Loss: 2.390831708908081 | CLS Loss: 0.009924476966261864\n",
      "Epoch 196 / 200 | iteration 60 / 171 | Total Loss: 2.436551332473755 | KNN Loss: 2.4253861904144287 | CLS Loss: 0.011165150441229343\n",
      "Epoch 196 / 200 | iteration 70 / 171 | Total Loss: 2.4260618686676025 | KNN Loss: 2.4187076091766357 | CLS Loss: 0.007354261819273233\n",
      "Epoch 196 / 200 | iteration 80 / 171 | Total Loss: 2.4451980590820312 | KNN Loss: 2.43621826171875 | CLS Loss: 0.008979897014796734\n",
      "Epoch 196 / 200 | iteration 90 / 171 | Total Loss: 2.433319568634033 | KNN Loss: 2.4291160106658936 | CLS Loss: 0.004203485324978828\n",
      "Epoch 196 / 200 | iteration 100 / 171 | Total Loss: 2.3969366550445557 | KNN Loss: 2.374267816543579 | CLS Loss: 0.022668881341814995\n",
      "Epoch 196 / 200 | iteration 110 / 171 | Total Loss: 2.3873002529144287 | KNN Loss: 2.3761610984802246 | CLS Loss: 0.011139069683849812\n",
      "Epoch 196 / 200 | iteration 120 / 171 | Total Loss: 2.3991196155548096 | KNN Loss: 2.3961360454559326 | CLS Loss: 0.002983655082061887\n",
      "Epoch 196 / 200 | iteration 130 / 171 | Total Loss: 2.4180984497070312 | KNN Loss: 2.4041385650634766 | CLS Loss: 0.013959797099232674\n",
      "Epoch 196 / 200 | iteration 140 / 171 | Total Loss: 2.422114372253418 | KNN Loss: 2.4070732593536377 | CLS Loss: 0.01504113432019949\n",
      "Epoch 196 / 200 | iteration 150 / 171 | Total Loss: 2.4237194061279297 | KNN Loss: 2.4120893478393555 | CLS Loss: 0.011630176566541195\n",
      "Epoch 196 / 200 | iteration 160 / 171 | Total Loss: 2.379925489425659 | KNN Loss: 2.36793851852417 | CLS Loss: 0.011987024918198586\n",
      "Epoch 196 / 200 | iteration 170 / 171 | Total Loss: 2.4221177101135254 | KNN Loss: 2.4179484844207764 | CLS Loss: 0.004169229883700609\n",
      "Epoch: 196, Loss: 2.4134, Train: 0.9977, Valid: 0.9875, Best: 0.9879\n",
      "Epoch 197 / 200 | iteration 0 / 171 | Total Loss: 2.4121124744415283 | KNN Loss: 2.3944365978240967 | CLS Loss: 0.017675774171948433\n",
      "Epoch 197 / 200 | iteration 10 / 171 | Total Loss: 2.4362523555755615 | KNN Loss: 2.4313511848449707 | CLS Loss: 0.004901067819446325\n",
      "Epoch 197 / 200 | iteration 20 / 171 | Total Loss: 2.432927131652832 | KNN Loss: 2.4231674671173096 | CLS Loss: 0.0097597511485219\n",
      "Epoch 197 / 200 | iteration 30 / 171 | Total Loss: 2.412929058074951 | KNN Loss: 2.408633232116699 | CLS Loss: 0.004295845981687307\n",
      "Epoch 197 / 200 | iteration 40 / 171 | Total Loss: 2.41477632522583 | KNN Loss: 2.4030518531799316 | CLS Loss: 0.011724456213414669\n",
      "Epoch 197 / 200 | iteration 50 / 171 | Total Loss: 2.3956708908081055 | KNN Loss: 2.3884267807006836 | CLS Loss: 0.007244074251502752\n",
      "Epoch 197 / 200 | iteration 60 / 171 | Total Loss: 2.37872052192688 | KNN Loss: 2.376521348953247 | CLS Loss: 0.002199203707277775\n",
      "Epoch 197 / 200 | iteration 70 / 171 | Total Loss: 2.4409914016723633 | KNN Loss: 2.4228310585021973 | CLS Loss: 0.018160400912165642\n",
      "Epoch 197 / 200 | iteration 80 / 171 | Total Loss: 2.3996596336364746 | KNN Loss: 2.394956350326538 | CLS Loss: 0.004703185521066189\n",
      "Epoch 197 / 200 | iteration 90 / 171 | Total Loss: 2.3780715465545654 | KNN Loss: 2.3671913146972656 | CLS Loss: 0.01088023092597723\n",
      "Epoch 197 / 200 | iteration 100 / 171 | Total Loss: 2.40608811378479 | KNN Loss: 2.4025418758392334 | CLS Loss: 0.00354630290530622\n",
      "Epoch 197 / 200 | iteration 110 / 171 | Total Loss: 2.4215452671051025 | KNN Loss: 2.4156150817871094 | CLS Loss: 0.0059301299042999744\n",
      "Epoch 197 / 200 | iteration 120 / 171 | Total Loss: 2.426178216934204 | KNN Loss: 2.4200141429901123 | CLS Loss: 0.006164044141769409\n",
      "Epoch 197 / 200 | iteration 130 / 171 | Total Loss: 2.4247348308563232 | KNN Loss: 2.4211678504943848 | CLS Loss: 0.0035670700017362833\n",
      "Epoch 197 / 200 | iteration 140 / 171 | Total Loss: 2.4133119583129883 | KNN Loss: 2.4049267768859863 | CLS Loss: 0.008385149762034416\n",
      "Epoch 197 / 200 | iteration 150 / 171 | Total Loss: 2.42866587638855 | KNN Loss: 2.4263722896575928 | CLS Loss: 0.002293588127940893\n",
      "Epoch 197 / 200 | iteration 160 / 171 | Total Loss: 2.41251277923584 | KNN Loss: 2.4081501960754395 | CLS Loss: 0.004362701904028654\n",
      "Epoch 197 / 200 | iteration 170 / 171 | Total Loss: 2.3988871574401855 | KNN Loss: 2.39389705657959 | CLS Loss: 0.004990041721612215\n",
      "Epoch: 197, Loss: 2.4104, Train: 0.9975, Valid: 0.9855, Best: 0.9879\n",
      "Epoch 198 / 200 | iteration 0 / 171 | Total Loss: 2.419175386428833 | KNN Loss: 2.402984619140625 | CLS Loss: 0.016190821304917336\n",
      "Epoch 198 / 200 | iteration 10 / 171 | Total Loss: 2.4441280364990234 | KNN Loss: 2.4328784942626953 | CLS Loss: 0.011249431408941746\n",
      "Epoch 198 / 200 | iteration 20 / 171 | Total Loss: 2.400602102279663 | KNN Loss: 2.398907423019409 | CLS Loss: 0.0016946530668064952\n",
      "Epoch 198 / 200 | iteration 30 / 171 | Total Loss: 2.4007906913757324 | KNN Loss: 2.396679162979126 | CLS Loss: 0.004111442714929581\n",
      "Epoch 198 / 200 | iteration 40 / 171 | Total Loss: 2.4392664432525635 | KNN Loss: 2.4360830783843994 | CLS Loss: 0.0031834279652684927\n",
      "Epoch 198 / 200 | iteration 50 / 171 | Total Loss: 2.3685221672058105 | KNN Loss: 2.3545889854431152 | CLS Loss: 0.013933064416050911\n",
      "Epoch 198 / 200 | iteration 60 / 171 | Total Loss: 2.4620742797851562 | KNN Loss: 2.4531636238098145 | CLS Loss: 0.008910619653761387\n",
      "Epoch 198 / 200 | iteration 70 / 171 | Total Loss: 2.4043209552764893 | KNN Loss: 2.3945186138153076 | CLS Loss: 0.00980223435908556\n",
      "Epoch 198 / 200 | iteration 80 / 171 | Total Loss: 2.4101550579071045 | KNN Loss: 2.405910015106201 | CLS Loss: 0.004245115909725428\n",
      "Epoch 198 / 200 | iteration 90 / 171 | Total Loss: 2.3877437114715576 | KNN Loss: 2.385694742202759 | CLS Loss: 0.002049063565209508\n",
      "Epoch 198 / 200 | iteration 100 / 171 | Total Loss: 2.410815954208374 | KNN Loss: 2.405595064163208 | CLS Loss: 0.00522082531824708\n",
      "Epoch 198 / 200 | iteration 110 / 171 | Total Loss: 2.407369613647461 | KNN Loss: 2.393049478530884 | CLS Loss: 0.014320183545351028\n",
      "Epoch 198 / 200 | iteration 120 / 171 | Total Loss: 2.404707908630371 | KNN Loss: 2.3929834365844727 | CLS Loss: 0.011724364943802357\n",
      "Epoch 198 / 200 | iteration 130 / 171 | Total Loss: 2.390660047531128 | KNN Loss: 2.386113405227661 | CLS Loss: 0.00454660365357995\n",
      "Epoch 198 / 200 | iteration 140 / 171 | Total Loss: 2.384645700454712 | KNN Loss: 2.379361867904663 | CLS Loss: 0.005283946171402931\n",
      "Epoch 198 / 200 | iteration 150 / 171 | Total Loss: 2.3935327529907227 | KNN Loss: 2.3875668048858643 | CLS Loss: 0.005965843331068754\n",
      "Epoch 198 / 200 | iteration 160 / 171 | Total Loss: 2.417757272720337 | KNN Loss: 2.3999733924865723 | CLS Loss: 0.017783764749765396\n",
      "Epoch 198 / 200 | iteration 170 / 171 | Total Loss: 2.3957908153533936 | KNN Loss: 2.392031192779541 | CLS Loss: 0.003759518964216113\n",
      "Epoch: 198, Loss: 2.4145, Train: 0.9967, Valid: 0.9861, Best: 0.9879\n",
      "Epoch 199 / 200 | iteration 0 / 171 | Total Loss: 2.411424160003662 | KNN Loss: 2.3983266353607178 | CLS Loss: 0.013097544200718403\n",
      "Epoch 199 / 200 | iteration 10 / 171 | Total Loss: 2.431405782699585 | KNN Loss: 2.43017578125 | CLS Loss: 0.0012298886431381106\n",
      "Epoch 199 / 200 | iteration 20 / 171 | Total Loss: 2.41660213470459 | KNN Loss: 2.4067060947418213 | CLS Loss: 0.009896103292703629\n",
      "Epoch 199 / 200 | iteration 30 / 171 | Total Loss: 2.428313732147217 | KNN Loss: 2.4272263050079346 | CLS Loss: 0.0010875018779188395\n",
      "Epoch 199 / 200 | iteration 40 / 171 | Total Loss: 2.412458658218384 | KNN Loss: 2.4105496406555176 | CLS Loss: 0.0019089692505076528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 / 200 | iteration 50 / 171 | Total Loss: 2.4234280586242676 | KNN Loss: 2.4157543182373047 | CLS Loss: 0.007673816755414009\n",
      "Epoch 199 / 200 | iteration 60 / 171 | Total Loss: 2.4474942684173584 | KNN Loss: 2.423646926879883 | CLS Loss: 0.023847365751862526\n",
      "Epoch 199 / 200 | iteration 70 / 171 | Total Loss: 2.4488182067871094 | KNN Loss: 2.435717821121216 | CLS Loss: 0.013100458309054375\n",
      "Epoch 199 / 200 | iteration 80 / 171 | Total Loss: 2.396406412124634 | KNN Loss: 2.3829433917999268 | CLS Loss: 0.013462989591062069\n",
      "Epoch 199 / 200 | iteration 90 / 171 | Total Loss: 2.4728357791900635 | KNN Loss: 2.4690585136413574 | CLS Loss: 0.0037773221265524626\n",
      "Epoch 199 / 200 | iteration 100 / 171 | Total Loss: 2.397653818130493 | KNN Loss: 2.389310598373413 | CLS Loss: 0.008343221619725227\n",
      "Epoch 199 / 200 | iteration 110 / 171 | Total Loss: 2.431727409362793 | KNN Loss: 2.4261274337768555 | CLS Loss: 0.0055998992174863815\n",
      "Epoch 199 / 200 | iteration 120 / 171 | Total Loss: 2.3848183155059814 | KNN Loss: 2.381561517715454 | CLS Loss: 0.0032567752059549093\n",
      "Epoch 199 / 200 | iteration 130 / 171 | Total Loss: 2.4414069652557373 | KNN Loss: 2.417722463607788 | CLS Loss: 0.02368454821407795\n",
      "Epoch 199 / 200 | iteration 140 / 171 | Total Loss: 2.4169600009918213 | KNN Loss: 2.4083383083343506 | CLS Loss: 0.008621643297374249\n",
      "Epoch 199 / 200 | iteration 150 / 171 | Total Loss: 2.4647908210754395 | KNN Loss: 2.4518401622772217 | CLS Loss: 0.012950651347637177\n",
      "Epoch 199 / 200 | iteration 160 / 171 | Total Loss: 2.422333002090454 | KNN Loss: 2.41513991355896 | CLS Loss: 0.0071929930709302425\n",
      "Epoch 199 / 200 | iteration 170 / 171 | Total Loss: 2.4260692596435547 | KNN Loss: 2.4126081466674805 | CLS Loss: 0.013461094349622726\n",
      "Epoch: 199, Loss: 2.4160, Train: 0.9964, Valid: 0.9851, Best: 0.9879\n",
      "Epoch 200 / 200 | iteration 0 / 171 | Total Loss: 2.4640512466430664 | KNN Loss: 2.4487128257751465 | CLS Loss: 0.0153384730219841\n",
      "Epoch 200 / 200 | iteration 10 / 171 | Total Loss: 2.4408810138702393 | KNN Loss: 2.4321749210357666 | CLS Loss: 0.008706048130989075\n",
      "Epoch 200 / 200 | iteration 20 / 171 | Total Loss: 2.44297456741333 | KNN Loss: 2.426830530166626 | CLS Loss: 0.01614408940076828\n",
      "Epoch 200 / 200 | iteration 30 / 171 | Total Loss: 2.41825795173645 | KNN Loss: 2.4143800735473633 | CLS Loss: 0.00387782184407115\n",
      "Epoch 200 / 200 | iteration 40 / 171 | Total Loss: 2.400444269180298 | KNN Loss: 2.392594337463379 | CLS Loss: 0.0078499186784029\n",
      "Epoch 200 / 200 | iteration 50 / 171 | Total Loss: 2.4227168560028076 | KNN Loss: 2.4116179943084717 | CLS Loss: 0.011098862625658512\n",
      "Epoch 200 / 200 | iteration 60 / 171 | Total Loss: 2.4044148921966553 | KNN Loss: 2.382673740386963 | CLS Loss: 0.021741168573498726\n",
      "Epoch 200 / 200 | iteration 70 / 171 | Total Loss: 2.3988542556762695 | KNN Loss: 2.395333766937256 | CLS Loss: 0.003520451718941331\n",
      "Epoch 200 / 200 | iteration 80 / 171 | Total Loss: 2.428849458694458 | KNN Loss: 2.4124646186828613 | CLS Loss: 0.016384800896048546\n",
      "Epoch 200 / 200 | iteration 90 / 171 | Total Loss: 2.42669677734375 | KNN Loss: 2.420847177505493 | CLS Loss: 0.0058495583944022655\n",
      "Epoch 200 / 200 | iteration 100 / 171 | Total Loss: 2.437126636505127 | KNN Loss: 2.4180824756622314 | CLS Loss: 0.01904428005218506\n",
      "Epoch 200 / 200 | iteration 110 / 171 | Total Loss: 2.4057724475860596 | KNN Loss: 2.3964381217956543 | CLS Loss: 0.009334375150501728\n",
      "Epoch 200 / 200 | iteration 120 / 171 | Total Loss: 2.3810489177703857 | KNN Loss: 2.379561185836792 | CLS Loss: 0.001487805973738432\n",
      "Epoch 200 / 200 | iteration 130 / 171 | Total Loss: 2.4072017669677734 | KNN Loss: 2.3943443298339844 | CLS Loss: 0.012857533060014248\n",
      "Epoch 200 / 200 | iteration 140 / 171 | Total Loss: 2.422666072845459 | KNN Loss: 2.4027717113494873 | CLS Loss: 0.019894257187843323\n",
      "Epoch 200 / 200 | iteration 150 / 171 | Total Loss: 2.3926005363464355 | KNN Loss: 2.380732536315918 | CLS Loss: 0.011868037283420563\n",
      "Epoch 200 / 200 | iteration 160 / 171 | Total Loss: 2.428121328353882 | KNN Loss: 2.4225964546203613 | CLS Loss: 0.005524974782019854\n",
      "Epoch 200 / 200 | iteration 170 / 171 | Total Loss: 2.3926689624786377 | KNN Loss: 2.3887345790863037 | CLS Loss: 0.003934495151042938\n",
      "Epoch: 200, Loss: 2.4180, Train: 0.9972, Valid: 0.9867, Best: 0.9879\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9867, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb352882df34da39163f6b25c2fb4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c642616ad97418a9c2a1024fbe799e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0181244fba43d6b416b7f63d67ffb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2134cc0f74a42cdbf948e0cac87c70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7e76101fb84cf0b265a0f17ae1f8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.9194646201635375\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40707d495bc543f798a2c684558952e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "layer 7: 0.0\n",
      "layer 8: 0.0\n",
      "Epoch: 00 | Batch: 000 / 040 | Total loss: 3.146 | Reg loss: 0.012 | Tree loss: 3.146 | Accuracy: 0.015625 | 0.885 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 01 | Batch: 000 / 040 | Total loss: 3.107 | Reg loss: 0.006 | Tree loss: 3.107 | Accuracy: 0.166016 | 0.768 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 02 | Batch: 000 / 040 | Total loss: 3.093 | Reg loss: 0.008 | Tree loss: 3.093 | Accuracy: 0.158203 | 0.766 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 03 | Batch: 000 / 040 | Total loss: 3.082 | Reg loss: 0.009 | Tree loss: 3.082 | Accuracy: 0.132812 | 0.764 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 04 | Batch: 000 / 040 | Total loss: 3.048 | Reg loss: 0.011 | Tree loss: 3.048 | Accuracy: 0.144531 | 0.762 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 05 | Batch: 000 / 040 | Total loss: 3.006 | Reg loss: 0.012 | Tree loss: 3.006 | Accuracy: 0.169922 | 0.762 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 06 | Batch: 000 / 040 | Total loss: 2.958 | Reg loss: 0.013 | Tree loss: 2.958 | Accuracy: 0.195312 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 07 | Batch: 000 / 040 | Total loss: 2.910 | Reg loss: 0.015 | Tree loss: 2.910 | Accuracy: 0.199219 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 08 | Batch: 000 / 040 | Total loss: 2.898 | Reg loss: 0.016 | Tree loss: 2.898 | Accuracy: 0.171875 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 09 | Batch: 000 / 040 | Total loss: 2.840 | Reg loss: 0.017 | Tree loss: 2.840 | Accuracy: 0.208984 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 10 | Batch: 000 / 040 | Total loss: 2.810 | Reg loss: 0.018 | Tree loss: 2.810 | Accuracy: 0.210938 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 11 | Batch: 000 / 040 | Total loss: 2.741 | Reg loss: 0.018 | Tree loss: 2.741 | Accuracy: 0.255859 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 12 | Batch: 000 / 040 | Total loss: 2.686 | Reg loss: 0.019 | Tree loss: 2.686 | Accuracy: 0.283203 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 13 | Batch: 000 / 040 | Total loss: 2.681 | Reg loss: 0.020 | Tree loss: 2.681 | Accuracy: 0.273438 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 14 | Batch: 000 / 040 | Total loss: 2.684 | Reg loss: 0.021 | Tree loss: 2.684 | Accuracy: 0.250000 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 15 | Batch: 000 / 040 | Total loss: 2.622 | Reg loss: 0.021 | Tree loss: 2.622 | Accuracy: 0.314453 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 16 | Batch: 000 / 040 | Total loss: 2.616 | Reg loss: 0.022 | Tree loss: 2.616 | Accuracy: 0.314453 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 17 | Batch: 000 / 040 | Total loss: 2.612 | Reg loss: 0.022 | Tree loss: 2.612 | Accuracy: 0.285156 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 18 | Batch: 000 / 040 | Total loss: 2.549 | Reg loss: 0.023 | Tree loss: 2.549 | Accuracy: 0.316406 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 19 | Batch: 000 / 040 | Total loss: 2.548 | Reg loss: 0.023 | Tree loss: 2.548 | Accuracy: 0.318359 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Batch: 000 / 040 | Total loss: 2.533 | Reg loss: 0.024 | Tree loss: 2.533 | Accuracy: 0.310547 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 21 | Batch: 000 / 040 | Total loss: 2.529 | Reg loss: 0.024 | Tree loss: 2.529 | Accuracy: 0.314453 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 22 | Batch: 000 / 040 | Total loss: 2.505 | Reg loss: 0.025 | Tree loss: 2.505 | Accuracy: 0.322266 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 23 | Batch: 000 / 040 | Total loss: 2.456 | Reg loss: 0.025 | Tree loss: 2.456 | Accuracy: 0.347656 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 24 | Batch: 000 / 040 | Total loss: 2.453 | Reg loss: 0.025 | Tree loss: 2.453 | Accuracy: 0.345703 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 25 | Batch: 000 / 040 | Total loss: 2.461 | Reg loss: 0.026 | Tree loss: 2.461 | Accuracy: 0.349609 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 26 | Batch: 000 / 040 | Total loss: 2.432 | Reg loss: 0.026 | Tree loss: 2.432 | Accuracy: 0.341797 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 27 | Batch: 000 / 040 | Total loss: 2.452 | Reg loss: 0.026 | Tree loss: 2.452 | Accuracy: 0.328125 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 28 | Batch: 000 / 040 | Total loss: 2.384 | Reg loss: 0.026 | Tree loss: 2.384 | Accuracy: 0.363281 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 29 | Batch: 000 / 040 | Total loss: 2.426 | Reg loss: 0.026 | Tree loss: 2.426 | Accuracy: 0.326172 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 30 | Batch: 000 / 040 | Total loss: 2.426 | Reg loss: 0.027 | Tree loss: 2.426 | Accuracy: 0.318359 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 31 | Batch: 000 / 040 | Total loss: 2.394 | Reg loss: 0.027 | Tree loss: 2.394 | Accuracy: 0.341797 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 32 | Batch: 000 / 040 | Total loss: 2.396 | Reg loss: 0.027 | Tree loss: 2.396 | Accuracy: 0.343750 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 33 | Batch: 000 / 040 | Total loss: 2.387 | Reg loss: 0.027 | Tree loss: 2.387 | Accuracy: 0.347656 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 34 | Batch: 000 / 040 | Total loss: 2.371 | Reg loss: 0.027 | Tree loss: 2.371 | Accuracy: 0.345703 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 35 | Batch: 000 / 040 | Total loss: 2.357 | Reg loss: 0.027 | Tree loss: 2.357 | Accuracy: 0.363281 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 36 | Batch: 000 / 040 | Total loss: 2.383 | Reg loss: 0.027 | Tree loss: 2.383 | Accuracy: 0.326172 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 37 | Batch: 000 / 040 | Total loss: 2.350 | Reg loss: 0.028 | Tree loss: 2.350 | Accuracy: 0.359375 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 38 | Batch: 000 / 040 | Total loss: 2.362 | Reg loss: 0.028 | Tree loss: 2.362 | Accuracy: 0.353516 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 39 | Batch: 000 / 040 | Total loss: 2.353 | Reg loss: 0.028 | Tree loss: 2.353 | Accuracy: 0.359375 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Batch: 000 / 040 | Total loss: 2.398 | Reg loss: 0.028 | Tree loss: 2.398 | Accuracy: 0.347656 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 41 | Batch: 000 / 040 | Total loss: 2.389 | Reg loss: 0.028 | Tree loss: 2.389 | Accuracy: 0.384766 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 42 | Batch: 000 / 040 | Total loss: 2.342 | Reg loss: 0.028 | Tree loss: 2.342 | Accuracy: 0.375000 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 43 | Batch: 000 / 040 | Total loss: 2.329 | Reg loss: 0.028 | Tree loss: 2.329 | Accuracy: 0.373047 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 44 | Batch: 000 / 040 | Total loss: 2.348 | Reg loss: 0.028 | Tree loss: 2.348 | Accuracy: 0.376953 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 45 | Batch: 000 / 040 | Total loss: 2.349 | Reg loss: 0.028 | Tree loss: 2.349 | Accuracy: 0.353516 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 46 | Batch: 000 / 040 | Total loss: 2.357 | Reg loss: 0.028 | Tree loss: 2.357 | Accuracy: 0.347656 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 47 | Batch: 000 / 040 | Total loss: 2.364 | Reg loss: 0.028 | Tree loss: 2.364 | Accuracy: 0.382812 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 48 | Batch: 000 / 040 | Total loss: 2.385 | Reg loss: 0.028 | Tree loss: 2.385 | Accuracy: 0.365234 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 49 | Batch: 000 / 040 | Total loss: 2.385 | Reg loss: 0.028 | Tree loss: 2.385 | Accuracy: 0.351562 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 50 | Batch: 000 / 040 | Total loss: 2.364 | Reg loss: 0.028 | Tree loss: 2.364 | Accuracy: 0.357422 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 51 | Batch: 000 / 040 | Total loss: 2.404 | Reg loss: 0.028 | Tree loss: 2.404 | Accuracy: 0.318359 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 52 | Batch: 000 / 040 | Total loss: 2.347 | Reg loss: 0.028 | Tree loss: 2.347 | Accuracy: 0.380859 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 53 | Batch: 000 / 040 | Total loss: 2.376 | Reg loss: 0.028 | Tree loss: 2.376 | Accuracy: 0.349609 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 54 | Batch: 000 / 040 | Total loss: 2.372 | Reg loss: 0.029 | Tree loss: 2.372 | Accuracy: 0.376953 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 55 | Batch: 000 / 040 | Total loss: 2.404 | Reg loss: 0.029 | Tree loss: 2.404 | Accuracy: 0.355469 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 56 | Batch: 000 / 040 | Total loss: 2.352 | Reg loss: 0.029 | Tree loss: 2.352 | Accuracy: 0.359375 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 57 | Batch: 000 / 040 | Total loss: 2.431 | Reg loss: 0.029 | Tree loss: 2.431 | Accuracy: 0.320312 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 58 | Batch: 000 / 040 | Total loss: 2.305 | Reg loss: 0.029 | Tree loss: 2.305 | Accuracy: 0.402344 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 59 | Batch: 000 / 040 | Total loss: 2.428 | Reg loss: 0.029 | Tree loss: 2.428 | Accuracy: 0.312500 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | Batch: 000 / 040 | Total loss: 2.353 | Reg loss: 0.029 | Tree loss: 2.353 | Accuracy: 0.361328 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 61 | Batch: 000 / 040 | Total loss: 2.365 | Reg loss: 0.029 | Tree loss: 2.365 | Accuracy: 0.347656 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 62 | Batch: 000 / 040 | Total loss: 2.348 | Reg loss: 0.029 | Tree loss: 2.348 | Accuracy: 0.367188 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 63 | Batch: 000 / 040 | Total loss: 2.386 | Reg loss: 0.029 | Tree loss: 2.386 | Accuracy: 0.345703 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 64 | Batch: 000 / 040 | Total loss: 2.376 | Reg loss: 0.030 | Tree loss: 2.376 | Accuracy: 0.355469 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 65 | Batch: 000 / 040 | Total loss: 2.445 | Reg loss: 0.030 | Tree loss: 2.445 | Accuracy: 0.320312 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 66 | Batch: 000 / 040 | Total loss: 2.424 | Reg loss: 0.030 | Tree loss: 2.424 | Accuracy: 0.337891 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 67 | Batch: 000 / 040 | Total loss: 2.358 | Reg loss: 0.030 | Tree loss: 2.358 | Accuracy: 0.382812 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 68 | Batch: 000 / 040 | Total loss: 2.380 | Reg loss: 0.030 | Tree loss: 2.380 | Accuracy: 0.330078 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 69 | Batch: 000 / 040 | Total loss: 2.352 | Reg loss: 0.030 | Tree loss: 2.352 | Accuracy: 0.353516 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 70 | Batch: 000 / 040 | Total loss: 2.318 | Reg loss: 0.030 | Tree loss: 2.318 | Accuracy: 0.380859 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 71 | Batch: 000 / 040 | Total loss: 2.400 | Reg loss: 0.030 | Tree loss: 2.400 | Accuracy: 0.343750 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 72 | Batch: 000 / 040 | Total loss: 2.378 | Reg loss: 0.030 | Tree loss: 2.378 | Accuracy: 0.347656 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 73 | Batch: 000 / 040 | Total loss: 2.353 | Reg loss: 0.030 | Tree loss: 2.353 | Accuracy: 0.363281 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 74 | Batch: 000 / 040 | Total loss: 2.319 | Reg loss: 0.030 | Tree loss: 2.319 | Accuracy: 0.376953 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 75 | Batch: 000 / 040 | Total loss: 2.371 | Reg loss: 0.031 | Tree loss: 2.371 | Accuracy: 0.361328 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 76 | Batch: 000 / 040 | Total loss: 2.412 | Reg loss: 0.031 | Tree loss: 2.412 | Accuracy: 0.326172 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 77 | Batch: 000 / 040 | Total loss: 2.394 | Reg loss: 0.031 | Tree loss: 2.394 | Accuracy: 0.349609 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 78 | Batch: 000 / 040 | Total loss: 2.316 | Reg loss: 0.031 | Tree loss: 2.316 | Accuracy: 0.384766 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 79 | Batch: 000 / 040 | Total loss: 2.345 | Reg loss: 0.031 | Tree loss: 2.345 | Accuracy: 0.390625 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | Batch: 000 / 040 | Total loss: 2.288 | Reg loss: 0.031 | Tree loss: 2.288 | Accuracy: 0.365234 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 81 | Batch: 000 / 040 | Total loss: 2.402 | Reg loss: 0.031 | Tree loss: 2.402 | Accuracy: 0.343750 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 82 | Batch: 000 / 040 | Total loss: 2.367 | Reg loss: 0.031 | Tree loss: 2.367 | Accuracy: 0.357422 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 83 | Batch: 000 / 040 | Total loss: 2.309 | Reg loss: 0.031 | Tree loss: 2.309 | Accuracy: 0.400391 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 84 | Batch: 000 / 040 | Total loss: 2.371 | Reg loss: 0.031 | Tree loss: 2.371 | Accuracy: 0.337891 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 85 | Batch: 000 / 040 | Total loss: 2.368 | Reg loss: 0.031 | Tree loss: 2.368 | Accuracy: 0.345703 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 86 | Batch: 000 / 040 | Total loss: 2.346 | Reg loss: 0.031 | Tree loss: 2.346 | Accuracy: 0.365234 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 87 | Batch: 000 / 040 | Total loss: 2.334 | Reg loss: 0.031 | Tree loss: 2.334 | Accuracy: 0.365234 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 88 | Batch: 000 / 040 | Total loss: 2.321 | Reg loss: 0.031 | Tree loss: 2.321 | Accuracy: 0.378906 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 89 | Batch: 000 / 040 | Total loss: 2.345 | Reg loss: 0.031 | Tree loss: 2.345 | Accuracy: 0.369141 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 90 | Batch: 000 / 040 | Total loss: 2.300 | Reg loss: 0.031 | Tree loss: 2.300 | Accuracy: 0.343750 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 91 | Batch: 000 / 040 | Total loss: 2.333 | Reg loss: 0.031 | Tree loss: 2.333 | Accuracy: 0.376953 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 92 | Batch: 000 / 040 | Total loss: 2.334 | Reg loss: 0.031 | Tree loss: 2.334 | Accuracy: 0.351562 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 93 | Batch: 000 / 040 | Total loss: 2.297 | Reg loss: 0.032 | Tree loss: 2.297 | Accuracy: 0.357422 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 94 | Batch: 000 / 040 | Total loss: 2.355 | Reg loss: 0.032 | Tree loss: 2.355 | Accuracy: 0.355469 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 95 | Batch: 000 / 040 | Total loss: 2.364 | Reg loss: 0.032 | Tree loss: 2.364 | Accuracy: 0.353516 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 96 | Batch: 000 / 040 | Total loss: 2.370 | Reg loss: 0.032 | Tree loss: 2.370 | Accuracy: 0.355469 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 97 | Batch: 000 / 040 | Total loss: 2.298 | Reg loss: 0.032 | Tree loss: 2.298 | Accuracy: 0.353516 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 98 | Batch: 000 / 040 | Total loss: 2.297 | Reg loss: 0.032 | Tree loss: 2.297 | Accuracy: 0.382812 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 99 | Batch: 000 / 040 | Total loss: 2.327 | Reg loss: 0.032 | Tree loss: 2.327 | Accuracy: 0.353516 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Batch: 000 / 040 | Total loss: 2.335 | Reg loss: 0.032 | Tree loss: 2.335 | Accuracy: 0.355469 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 101 | Batch: 000 / 040 | Total loss: 2.328 | Reg loss: 0.032 | Tree loss: 2.328 | Accuracy: 0.378906 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 102 | Batch: 000 / 040 | Total loss: 2.286 | Reg loss: 0.032 | Tree loss: 2.286 | Accuracy: 0.376953 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 103 | Batch: 000 / 040 | Total loss: 2.292 | Reg loss: 0.032 | Tree loss: 2.292 | Accuracy: 0.394531 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 104 | Batch: 000 / 040 | Total loss: 2.358 | Reg loss: 0.032 | Tree loss: 2.358 | Accuracy: 0.343750 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 105 | Batch: 000 / 040 | Total loss: 2.391 | Reg loss: 0.032 | Tree loss: 2.391 | Accuracy: 0.314453 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 106 | Batch: 000 / 040 | Total loss: 2.328 | Reg loss: 0.032 | Tree loss: 2.328 | Accuracy: 0.382812 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 107 | Batch: 000 / 040 | Total loss: 2.364 | Reg loss: 0.032 | Tree loss: 2.364 | Accuracy: 0.361328 | 0.761 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 108 | Batch: 000 / 040 | Total loss: 2.324 | Reg loss: 0.032 | Tree loss: 2.324 | Accuracy: 0.382812 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 109 | Batch: 000 / 040 | Total loss: 2.314 | Reg loss: 0.032 | Tree loss: 2.314 | Accuracy: 0.388672 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 110 | Batch: 000 / 040 | Total loss: 2.355 | Reg loss: 0.032 | Tree loss: 2.355 | Accuracy: 0.355469 | 0.76 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 111 | Batch: 000 / 040 | Total loss: 2.294 | Reg loss: 0.032 | Tree loss: 2.294 | Accuracy: 0.367188 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 112 | Batch: 000 / 040 | Total loss: 2.344 | Reg loss: 0.032 | Tree loss: 2.344 | Accuracy: 0.351562 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 113 | Batch: 000 / 040 | Total loss: 2.357 | Reg loss: 0.032 | Tree loss: 2.357 | Accuracy: 0.355469 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 114 | Batch: 000 / 040 | Total loss: 2.305 | Reg loss: 0.032 | Tree loss: 2.305 | Accuracy: 0.380859 | 0.759 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 115 | Batch: 000 / 040 | Total loss: 2.320 | Reg loss: 0.032 | Tree loss: 2.320 | Accuracy: 0.347656 | 0.758 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 116 | Batch: 000 / 040 | Total loss: 2.327 | Reg loss: 0.032 | Tree loss: 2.327 | Accuracy: 0.369141 | 0.758 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 117 | Batch: 000 / 040 | Total loss: 2.346 | Reg loss: 0.032 | Tree loss: 2.346 | Accuracy: 0.365234 | 0.758 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 118 | Batch: 000 / 040 | Total loss: 2.368 | Reg loss: 0.032 | Tree loss: 2.368 | Accuracy: 0.371094 | 0.757 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 119 | Batch: 000 / 040 | Total loss: 2.347 | Reg loss: 0.032 | Tree loss: 2.347 | Accuracy: 0.373047 | 0.757 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120 | Batch: 000 / 040 | Total loss: 2.330 | Reg loss: 0.032 | Tree loss: 2.330 | Accuracy: 0.363281 | 0.757 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 121 | Batch: 000 / 040 | Total loss: 2.333 | Reg loss: 0.032 | Tree loss: 2.333 | Accuracy: 0.382812 | 0.757 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 122 | Batch: 000 / 040 | Total loss: 2.333 | Reg loss: 0.032 | Tree loss: 2.333 | Accuracy: 0.365234 | 0.756 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 123 | Batch: 000 / 040 | Total loss: 2.317 | Reg loss: 0.032 | Tree loss: 2.317 | Accuracy: 0.382812 | 0.756 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 124 | Batch: 000 / 040 | Total loss: 2.391 | Reg loss: 0.032 | Tree loss: 2.391 | Accuracy: 0.322266 | 0.756 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 125 | Batch: 000 / 040 | Total loss: 2.354 | Reg loss: 0.032 | Tree loss: 2.354 | Accuracy: 0.380859 | 0.756 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 126 | Batch: 000 / 040 | Total loss: 2.288 | Reg loss: 0.032 | Tree loss: 2.288 | Accuracy: 0.394531 | 0.756 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 127 | Batch: 000 / 040 | Total loss: 2.330 | Reg loss: 0.032 | Tree loss: 2.330 | Accuracy: 0.375000 | 0.755 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 128 | Batch: 000 / 040 | Total loss: 2.296 | Reg loss: 0.032 | Tree loss: 2.296 | Accuracy: 0.369141 | 0.755 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 129 | Batch: 000 / 040 | Total loss: 2.366 | Reg loss: 0.032 | Tree loss: 2.366 | Accuracy: 0.369141 | 0.755 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 130 | Batch: 000 / 040 | Total loss: 2.372 | Reg loss: 0.032 | Tree loss: 2.372 | Accuracy: 0.339844 | 0.755 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 131 | Batch: 000 / 040 | Total loss: 2.363 | Reg loss: 0.032 | Tree loss: 2.363 | Accuracy: 0.328125 | 0.754 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 132 | Batch: 000 / 040 | Total loss: 2.334 | Reg loss: 0.032 | Tree loss: 2.334 | Accuracy: 0.367188 | 0.754 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 133 | Batch: 000 / 040 | Total loss: 2.350 | Reg loss: 0.032 | Tree loss: 2.350 | Accuracy: 0.355469 | 0.754 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 134 | Batch: 000 / 040 | Total loss: 2.307 | Reg loss: 0.032 | Tree loss: 2.307 | Accuracy: 0.378906 | 0.754 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 135 | Batch: 000 / 040 | Total loss: 2.368 | Reg loss: 0.032 | Tree loss: 2.368 | Accuracy: 0.339844 | 0.754 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 136 | Batch: 000 / 040 | Total loss: 2.321 | Reg loss: 0.032 | Tree loss: 2.321 | Accuracy: 0.398438 | 0.753 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 137 | Batch: 000 / 040 | Total loss: 2.331 | Reg loss: 0.032 | Tree loss: 2.331 | Accuracy: 0.347656 | 0.753 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 138 | Batch: 000 / 040 | Total loss: 2.289 | Reg loss: 0.032 | Tree loss: 2.289 | Accuracy: 0.390625 | 0.753 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 139 | Batch: 000 / 040 | Total loss: 2.265 | Reg loss: 0.032 | Tree loss: 2.265 | Accuracy: 0.423828 | 0.753 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140 | Batch: 000 / 040 | Total loss: 2.323 | Reg loss: 0.032 | Tree loss: 2.323 | Accuracy: 0.392578 | 0.752 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 141 | Batch: 000 / 040 | Total loss: 2.377 | Reg loss: 0.032 | Tree loss: 2.377 | Accuracy: 0.328125 | 0.752 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 142 | Batch: 000 / 040 | Total loss: 2.346 | Reg loss: 0.032 | Tree loss: 2.346 | Accuracy: 0.367188 | 0.752 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 143 | Batch: 000 / 040 | Total loss: 2.286 | Reg loss: 0.032 | Tree loss: 2.286 | Accuracy: 0.378906 | 0.752 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 144 | Batch: 000 / 040 | Total loss: 2.293 | Reg loss: 0.032 | Tree loss: 2.293 | Accuracy: 0.386719 | 0.752 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 145 | Batch: 000 / 040 | Total loss: 2.313 | Reg loss: 0.032 | Tree loss: 2.313 | Accuracy: 0.396484 | 0.751 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 146 | Batch: 000 / 040 | Total loss: 2.380 | Reg loss: 0.032 | Tree loss: 2.380 | Accuracy: 0.345703 | 0.751 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 147 | Batch: 000 / 040 | Total loss: 2.330 | Reg loss: 0.032 | Tree loss: 2.330 | Accuracy: 0.361328 | 0.751 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 148 | Batch: 000 / 040 | Total loss: 2.331 | Reg loss: 0.032 | Tree loss: 2.331 | Accuracy: 0.353516 | 0.751 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 149 | Batch: 000 / 040 | Total loss: 2.312 | Reg loss: 0.032 | Tree loss: 2.312 | Accuracy: 0.400391 | 0.751 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 150 | Batch: 000 / 040 | Total loss: 2.310 | Reg loss: 0.032 | Tree loss: 2.310 | Accuracy: 0.394531 | 0.75 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 151 | Batch: 000 / 040 | Total loss: 2.358 | Reg loss: 0.032 | Tree loss: 2.358 | Accuracy: 0.349609 | 0.75 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 152 | Batch: 000 / 040 | Total loss: 2.294 | Reg loss: 0.032 | Tree loss: 2.294 | Accuracy: 0.394531 | 0.75 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 153 | Batch: 000 / 040 | Total loss: 2.342 | Reg loss: 0.032 | Tree loss: 2.342 | Accuracy: 0.365234 | 0.75 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 154 | Batch: 000 / 040 | Total loss: 2.357 | Reg loss: 0.032 | Tree loss: 2.357 | Accuracy: 0.367188 | 0.75 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 155 | Batch: 000 / 040 | Total loss: 2.367 | Reg loss: 0.032 | Tree loss: 2.367 | Accuracy: 0.359375 | 0.749 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 156 | Batch: 000 / 040 | Total loss: 2.340 | Reg loss: 0.032 | Tree loss: 2.340 | Accuracy: 0.371094 | 0.749 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 157 | Batch: 000 / 040 | Total loss: 2.301 | Reg loss: 0.032 | Tree loss: 2.301 | Accuracy: 0.380859 | 0.749 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 158 | Batch: 000 / 040 | Total loss: 2.327 | Reg loss: 0.032 | Tree loss: 2.327 | Accuracy: 0.359375 | 0.749 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 159 | Batch: 000 / 040 | Total loss: 2.326 | Reg loss: 0.032 | Tree loss: 2.326 | Accuracy: 0.384766 | 0.749 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160 | Batch: 000 / 040 | Total loss: 2.356 | Reg loss: 0.032 | Tree loss: 2.356 | Accuracy: 0.343750 | 0.749 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 161 | Batch: 000 / 040 | Total loss: 2.341 | Reg loss: 0.032 | Tree loss: 2.341 | Accuracy: 0.365234 | 0.748 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 162 | Batch: 000 / 040 | Total loss: 2.356 | Reg loss: 0.032 | Tree loss: 2.356 | Accuracy: 0.376953 | 0.748 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 163 | Batch: 000 / 040 | Total loss: 2.359 | Reg loss: 0.032 | Tree loss: 2.359 | Accuracy: 0.343750 | 0.748 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 164 | Batch: 000 / 040 | Total loss: 2.326 | Reg loss: 0.032 | Tree loss: 2.326 | Accuracy: 0.361328 | 0.748 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 165 | Batch: 000 / 040 | Total loss: 2.387 | Reg loss: 0.032 | Tree loss: 2.387 | Accuracy: 0.335938 | 0.748 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 166 | Batch: 000 / 040 | Total loss: 2.342 | Reg loss: 0.032 | Tree loss: 2.342 | Accuracy: 0.384766 | 0.747 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 167 | Batch: 000 / 040 | Total loss: 2.321 | Reg loss: 0.032 | Tree loss: 2.321 | Accuracy: 0.378906 | 0.747 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 168 | Batch: 000 / 040 | Total loss: 2.315 | Reg loss: 0.032 | Tree loss: 2.315 | Accuracy: 0.394531 | 0.747 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 169 | Batch: 000 / 040 | Total loss: 2.358 | Reg loss: 0.032 | Tree loss: 2.358 | Accuracy: 0.339844 | 0.747 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 170 | Batch: 000 / 040 | Total loss: 2.370 | Reg loss: 0.032 | Tree loss: 2.370 | Accuracy: 0.367188 | 0.747 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 171 | Batch: 000 / 040 | Total loss: 2.320 | Reg loss: 0.032 | Tree loss: 2.320 | Accuracy: 0.394531 | 0.747 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 172 | Batch: 000 / 040 | Total loss: 2.348 | Reg loss: 0.032 | Tree loss: 2.348 | Accuracy: 0.341797 | 0.746 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 173 | Batch: 000 / 040 | Total loss: 2.368 | Reg loss: 0.032 | Tree loss: 2.368 | Accuracy: 0.373047 | 0.746 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 174 | Batch: 000 / 040 | Total loss: 2.373 | Reg loss: 0.032 | Tree loss: 2.373 | Accuracy: 0.337891 | 0.746 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 175 | Batch: 000 / 040 | Total loss: 2.331 | Reg loss: 0.032 | Tree loss: 2.331 | Accuracy: 0.361328 | 0.746 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 176 | Batch: 000 / 040 | Total loss: 2.307 | Reg loss: 0.032 | Tree loss: 2.307 | Accuracy: 0.378906 | 0.746 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 177 | Batch: 000 / 040 | Total loss: 2.341 | Reg loss: 0.032 | Tree loss: 2.341 | Accuracy: 0.363281 | 0.746 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 178 | Batch: 000 / 040 | Total loss: 2.352 | Reg loss: 0.032 | Tree loss: 2.352 | Accuracy: 0.400391 | 0.745 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 179 | Batch: 000 / 040 | Total loss: 2.314 | Reg loss: 0.032 | Tree loss: 2.314 | Accuracy: 0.375000 | 0.745 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180 | Batch: 000 / 040 | Total loss: 2.380 | Reg loss: 0.032 | Tree loss: 2.380 | Accuracy: 0.341797 | 0.745 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 181 | Batch: 000 / 040 | Total loss: 2.382 | Reg loss: 0.032 | Tree loss: 2.382 | Accuracy: 0.330078 | 0.745 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 182 | Batch: 000 / 040 | Total loss: 2.316 | Reg loss: 0.032 | Tree loss: 2.316 | Accuracy: 0.384766 | 0.745 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 183 | Batch: 000 / 040 | Total loss: 2.294 | Reg loss: 0.032 | Tree loss: 2.294 | Accuracy: 0.402344 | 0.745 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 184 | Batch: 000 / 040 | Total loss: 2.306 | Reg loss: 0.032 | Tree loss: 2.306 | Accuracy: 0.384766 | 0.745 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 185 | Batch: 000 / 040 | Total loss: 2.359 | Reg loss: 0.032 | Tree loss: 2.359 | Accuracy: 0.333984 | 0.745 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 186 | Batch: 000 / 040 | Total loss: 2.362 | Reg loss: 0.032 | Tree loss: 2.362 | Accuracy: 0.341797 | 0.745 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 187 | Batch: 000 / 040 | Total loss: 2.363 | Reg loss: 0.032 | Tree loss: 2.363 | Accuracy: 0.351562 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 188 | Batch: 000 / 040 | Total loss: 2.366 | Reg loss: 0.032 | Tree loss: 2.366 | Accuracy: 0.343750 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 189 | Batch: 000 / 040 | Total loss: 2.351 | Reg loss: 0.032 | Tree loss: 2.351 | Accuracy: 0.371094 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 190 | Batch: 000 / 040 | Total loss: 2.332 | Reg loss: 0.033 | Tree loss: 2.332 | Accuracy: 0.388672 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 191 | Batch: 000 / 040 | Total loss: 2.309 | Reg loss: 0.033 | Tree loss: 2.309 | Accuracy: 0.376953 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 192 | Batch: 000 / 040 | Total loss: 2.350 | Reg loss: 0.033 | Tree loss: 2.350 | Accuracy: 0.343750 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 193 | Batch: 000 / 040 | Total loss: 2.332 | Reg loss: 0.033 | Tree loss: 2.332 | Accuracy: 0.382812 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 194 | Batch: 000 / 040 | Total loss: 2.341 | Reg loss: 0.033 | Tree loss: 2.341 | Accuracy: 0.398438 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 195 | Batch: 000 / 040 | Total loss: 2.379 | Reg loss: 0.033 | Tree loss: 2.379 | Accuracy: 0.337891 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 196 | Batch: 000 / 040 | Total loss: 2.282 | Reg loss: 0.033 | Tree loss: 2.282 | Accuracy: 0.392578 | 0.744 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 197 | Batch: 000 / 040 | Total loss: 2.362 | Reg loss: 0.033 | Tree loss: 2.362 | Accuracy: 0.375000 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 198 | Batch: 000 / 040 | Total loss: 2.365 | Reg loss: 0.033 | Tree loss: 2.365 | Accuracy: 0.361328 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 199 | Batch: 000 / 040 | Total loss: 2.425 | Reg loss: 0.033 | Tree loss: 2.425 | Accuracy: 0.335938 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200 | Batch: 000 / 040 | Total loss: 2.323 | Reg loss: 0.033 | Tree loss: 2.323 | Accuracy: 0.363281 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 201 | Batch: 000 / 040 | Total loss: 2.341 | Reg loss: 0.033 | Tree loss: 2.341 | Accuracy: 0.378906 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 202 | Batch: 000 / 040 | Total loss: 2.321 | Reg loss: 0.033 | Tree loss: 2.321 | Accuracy: 0.349609 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 203 | Batch: 000 / 040 | Total loss: 2.361 | Reg loss: 0.033 | Tree loss: 2.361 | Accuracy: 0.369141 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 204 | Batch: 000 / 040 | Total loss: 2.335 | Reg loss: 0.033 | Tree loss: 2.335 | Accuracy: 0.373047 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 205 | Batch: 000 / 040 | Total loss: 2.276 | Reg loss: 0.033 | Tree loss: 2.276 | Accuracy: 0.392578 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 206 | Batch: 000 / 040 | Total loss: 2.305 | Reg loss: 0.033 | Tree loss: 2.305 | Accuracy: 0.355469 | 0.743 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 207 | Batch: 000 / 040 | Total loss: 2.339 | Reg loss: 0.033 | Tree loss: 2.339 | Accuracy: 0.384766 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 208 | Batch: 000 / 040 | Total loss: 2.324 | Reg loss: 0.033 | Tree loss: 2.324 | Accuracy: 0.345703 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 209 | Batch: 000 / 040 | Total loss: 2.355 | Reg loss: 0.033 | Tree loss: 2.355 | Accuracy: 0.337891 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 210 | Batch: 000 / 040 | Total loss: 2.375 | Reg loss: 0.033 | Tree loss: 2.375 | Accuracy: 0.361328 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 211 | Batch: 000 / 040 | Total loss: 2.307 | Reg loss: 0.033 | Tree loss: 2.307 | Accuracy: 0.380859 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 212 | Batch: 000 / 040 | Total loss: 2.335 | Reg loss: 0.033 | Tree loss: 2.335 | Accuracy: 0.376953 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 213 | Batch: 000 / 040 | Total loss: 2.316 | Reg loss: 0.033 | Tree loss: 2.316 | Accuracy: 0.380859 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 214 | Batch: 000 / 040 | Total loss: 2.313 | Reg loss: 0.033 | Tree loss: 2.313 | Accuracy: 0.404297 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 215 | Batch: 000 / 040 | Total loss: 2.371 | Reg loss: 0.033 | Tree loss: 2.371 | Accuracy: 0.357422 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 216 | Batch: 000 / 040 | Total loss: 2.368 | Reg loss: 0.033 | Tree loss: 2.368 | Accuracy: 0.328125 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 217 | Batch: 000 / 040 | Total loss: 2.310 | Reg loss: 0.033 | Tree loss: 2.310 | Accuracy: 0.406250 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 218 | Batch: 000 / 040 | Total loss: 2.380 | Reg loss: 0.033 | Tree loss: 2.380 | Accuracy: 0.330078 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 219 | Batch: 000 / 040 | Total loss: 2.300 | Reg loss: 0.033 | Tree loss: 2.300 | Accuracy: 0.363281 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220 | Batch: 000 / 040 | Total loss: 2.324 | Reg loss: 0.033 | Tree loss: 2.324 | Accuracy: 0.371094 | 0.742 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 221 | Batch: 000 / 040 | Total loss: 2.354 | Reg loss: 0.033 | Tree loss: 2.354 | Accuracy: 0.365234 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 222 | Batch: 000 / 040 | Total loss: 2.298 | Reg loss: 0.033 | Tree loss: 2.298 | Accuracy: 0.378906 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 223 | Batch: 000 / 040 | Total loss: 2.368 | Reg loss: 0.033 | Tree loss: 2.368 | Accuracy: 0.330078 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 224 | Batch: 000 / 040 | Total loss: 2.359 | Reg loss: 0.033 | Tree loss: 2.359 | Accuracy: 0.365234 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 225 | Batch: 000 / 040 | Total loss: 2.341 | Reg loss: 0.033 | Tree loss: 2.341 | Accuracy: 0.355469 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 226 | Batch: 000 / 040 | Total loss: 2.369 | Reg loss: 0.033 | Tree loss: 2.369 | Accuracy: 0.345703 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 227 | Batch: 000 / 040 | Total loss: 2.320 | Reg loss: 0.033 | Tree loss: 2.320 | Accuracy: 0.371094 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 228 | Batch: 000 / 040 | Total loss: 2.378 | Reg loss: 0.033 | Tree loss: 2.378 | Accuracy: 0.357422 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 229 | Batch: 000 / 040 | Total loss: 2.334 | Reg loss: 0.033 | Tree loss: 2.334 | Accuracy: 0.351562 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 230 | Batch: 000 / 040 | Total loss: 2.328 | Reg loss: 0.033 | Tree loss: 2.328 | Accuracy: 0.375000 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 231 | Batch: 000 / 040 | Total loss: 2.303 | Reg loss: 0.033 | Tree loss: 2.303 | Accuracy: 0.378906 | 0.741 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 232 | Batch: 000 / 040 | Total loss: 2.342 | Reg loss: 0.033 | Tree loss: 2.342 | Accuracy: 0.341797 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 233 | Batch: 000 / 040 | Total loss: 2.323 | Reg loss: 0.033 | Tree loss: 2.323 | Accuracy: 0.349609 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 234 | Batch: 000 / 040 | Total loss: 2.297 | Reg loss: 0.033 | Tree loss: 2.297 | Accuracy: 0.375000 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 235 | Batch: 000 / 040 | Total loss: 2.303 | Reg loss: 0.033 | Tree loss: 2.303 | Accuracy: 0.378906 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 236 | Batch: 000 / 040 | Total loss: 2.293 | Reg loss: 0.033 | Tree loss: 2.293 | Accuracy: 0.386719 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 237 | Batch: 000 / 040 | Total loss: 2.300 | Reg loss: 0.033 | Tree loss: 2.300 | Accuracy: 0.363281 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 238 | Batch: 000 / 040 | Total loss: 2.346 | Reg loss: 0.033 | Tree loss: 2.346 | Accuracy: 0.363281 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 239 | Batch: 000 / 040 | Total loss: 2.279 | Reg loss: 0.033 | Tree loss: 2.279 | Accuracy: 0.386719 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240 | Batch: 000 / 040 | Total loss: 2.305 | Reg loss: 0.033 | Tree loss: 2.305 | Accuracy: 0.384766 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 241 | Batch: 000 / 040 | Total loss: 2.277 | Reg loss: 0.033 | Tree loss: 2.277 | Accuracy: 0.414062 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 242 | Batch: 000 / 040 | Total loss: 2.357 | Reg loss: 0.033 | Tree loss: 2.357 | Accuracy: 0.347656 | 0.74 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 243 | Batch: 000 / 040 | Total loss: 2.345 | Reg loss: 0.033 | Tree loss: 2.345 | Accuracy: 0.332031 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 244 | Batch: 000 / 040 | Total loss: 2.328 | Reg loss: 0.033 | Tree loss: 2.328 | Accuracy: 0.365234 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 245 | Batch: 000 / 040 | Total loss: 2.277 | Reg loss: 0.033 | Tree loss: 2.277 | Accuracy: 0.417969 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 246 | Batch: 000 / 040 | Total loss: 2.347 | Reg loss: 0.033 | Tree loss: 2.347 | Accuracy: 0.371094 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 247 | Batch: 000 / 040 | Total loss: 2.319 | Reg loss: 0.033 | Tree loss: 2.319 | Accuracy: 0.363281 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 248 | Batch: 000 / 040 | Total loss: 2.344 | Reg loss: 0.033 | Tree loss: 2.344 | Accuracy: 0.371094 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 249 | Batch: 000 / 040 | Total loss: 2.405 | Reg loss: 0.033 | Tree loss: 2.405 | Accuracy: 0.320312 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 250 | Batch: 000 / 040 | Total loss: 2.300 | Reg loss: 0.033 | Tree loss: 2.300 | Accuracy: 0.376953 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 251 | Batch: 000 / 040 | Total loss: 2.302 | Reg loss: 0.033 | Tree loss: 2.302 | Accuracy: 0.373047 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 252 | Batch: 000 / 040 | Total loss: 2.362 | Reg loss: 0.033 | Tree loss: 2.362 | Accuracy: 0.335938 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 256 | Batch: 000 / 040 | Total loss: 2.345 | Reg loss: 0.033 | Tree loss: 2.345 | Accuracy: 0.371094 | 0.739 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 257 | Batch: 000 / 040 | Total loss: 2.353 | Reg loss: 0.033 | Tree loss: 2.353 | Accuracy: 0.351562 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 258 | Batch: 000 / 040 | Total loss: 2.389 | Reg loss: 0.033 | Tree loss: 2.389 | Accuracy: 0.353516 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 259 | Batch: 000 / 040 | Total loss: 2.287 | Reg loss: 0.033 | Tree loss: 2.287 | Accuracy: 0.392578 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 260 | Batch: 000 / 040 | Total loss: 2.317 | Reg loss: 0.033 | Tree loss: 2.317 | Accuracy: 0.361328 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 261 | Batch: 000 / 040 | Total loss: 2.364 | Reg loss: 0.033 | Tree loss: 2.364 | Accuracy: 0.347656 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 262 | Batch: 000 / 040 | Total loss: 2.331 | Reg loss: 0.033 | Tree loss: 2.331 | Accuracy: 0.343750 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 263 | Batch: 000 / 040 | Total loss: 2.312 | Reg loss: 0.033 | Tree loss: 2.312 | Accuracy: 0.386719 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 264 | Batch: 000 / 040 | Total loss: 2.333 | Reg loss: 0.033 | Tree loss: 2.333 | Accuracy: 0.402344 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 265 | Batch: 000 / 040 | Total loss: 2.344 | Reg loss: 0.033 | Tree loss: 2.344 | Accuracy: 0.357422 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 266 | Batch: 000 / 040 | Total loss: 2.359 | Reg loss: 0.033 | Tree loss: 2.359 | Accuracy: 0.355469 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 267 | Batch: 000 / 040 | Total loss: 2.320 | Reg loss: 0.033 | Tree loss: 2.320 | Accuracy: 0.390625 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 268 | Batch: 000 / 040 | Total loss: 2.302 | Reg loss: 0.033 | Tree loss: 2.302 | Accuracy: 0.365234 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 269 | Batch: 000 / 040 | Total loss: 2.358 | Reg loss: 0.033 | Tree loss: 2.358 | Accuracy: 0.343750 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 270 | Batch: 000 / 040 | Total loss: 2.311 | Reg loss: 0.033 | Tree loss: 2.311 | Accuracy: 0.384766 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 271 | Batch: 000 / 040 | Total loss: 2.359 | Reg loss: 0.033 | Tree loss: 2.359 | Accuracy: 0.396484 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 272 | Batch: 000 / 040 | Total loss: 2.326 | Reg loss: 0.033 | Tree loss: 2.326 | Accuracy: 0.361328 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 273 | Batch: 000 / 040 | Total loss: 2.382 | Reg loss: 0.033 | Tree loss: 2.382 | Accuracy: 0.328125 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 274 | Batch: 000 / 040 | Total loss: 2.395 | Reg loss: 0.033 | Tree loss: 2.395 | Accuracy: 0.332031 | 0.738 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 275 | Batch: 000 / 040 | Total loss: 2.349 | Reg loss: 0.033 | Tree loss: 2.349 | Accuracy: 0.335938 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 276 | Batch: 000 / 040 | Total loss: 2.311 | Reg loss: 0.033 | Tree loss: 2.311 | Accuracy: 0.371094 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 277 | Batch: 000 / 040 | Total loss: 2.350 | Reg loss: 0.033 | Tree loss: 2.350 | Accuracy: 0.353516 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 278 | Batch: 000 / 040 | Total loss: 2.350 | Reg loss: 0.033 | Tree loss: 2.350 | Accuracy: 0.343750 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 279 | Batch: 000 / 040 | Total loss: 2.302 | Reg loss: 0.033 | Tree loss: 2.302 | Accuracy: 0.353516 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 280 | Batch: 000 / 040 | Total loss: 2.312 | Reg loss: 0.033 | Tree loss: 2.312 | Accuracy: 0.375000 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 281 | Batch: 000 / 040 | Total loss: 2.322 | Reg loss: 0.033 | Tree loss: 2.322 | Accuracy: 0.369141 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 282 | Batch: 000 / 040 | Total loss: 2.368 | Reg loss: 0.033 | Tree loss: 2.368 | Accuracy: 0.353516 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 283 | Batch: 000 / 040 | Total loss: 2.298 | Reg loss: 0.033 | Tree loss: 2.298 | Accuracy: 0.394531 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 284 | Batch: 000 / 040 | Total loss: 2.348 | Reg loss: 0.033 | Tree loss: 2.348 | Accuracy: 0.376953 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 285 | Batch: 000 / 040 | Total loss: 2.372 | Reg loss: 0.033 | Tree loss: 2.372 | Accuracy: 0.343750 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 286 | Batch: 000 / 040 | Total loss: 2.339 | Reg loss: 0.033 | Tree loss: 2.339 | Accuracy: 0.367188 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 287 | Batch: 000 / 040 | Total loss: 2.329 | Reg loss: 0.033 | Tree loss: 2.329 | Accuracy: 0.365234 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 288 | Batch: 000 / 040 | Total loss: 2.324 | Reg loss: 0.033 | Tree loss: 2.324 | Accuracy: 0.373047 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 289 | Batch: 000 / 040 | Total loss: 2.359 | Reg loss: 0.033 | Tree loss: 2.359 | Accuracy: 0.320312 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 290 | Batch: 000 / 040 | Total loss: 2.274 | Reg loss: 0.033 | Tree loss: 2.274 | Accuracy: 0.369141 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 291 | Batch: 000 / 040 | Total loss: 2.301 | Reg loss: 0.033 | Tree loss: 2.301 | Accuracy: 0.357422 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 292 | Batch: 000 / 040 | Total loss: 2.313 | Reg loss: 0.033 | Tree loss: 2.313 | Accuracy: 0.349609 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 293 | Batch: 000 / 040 | Total loss: 2.353 | Reg loss: 0.033 | Tree loss: 2.353 | Accuracy: 0.339844 | 0.737 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 294 | Batch: 000 / 040 | Total loss: 2.383 | Reg loss: 0.033 | Tree loss: 2.383 | Accuracy: 0.332031 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 295 | Batch: 000 / 040 | Total loss: 2.361 | Reg loss: 0.033 | Tree loss: 2.361 | Accuracy: 0.355469 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 296 | Batch: 000 / 040 | Total loss: 2.355 | Reg loss: 0.033 | Tree loss: 2.355 | Accuracy: 0.347656 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 297 | Batch: 000 / 040 | Total loss: 2.358 | Reg loss: 0.033 | Tree loss: 2.358 | Accuracy: 0.333984 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 298 | Batch: 000 / 040 | Total loss: 2.344 | Reg loss: 0.033 | Tree loss: 2.344 | Accuracy: 0.378906 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 299 | Batch: 000 / 040 | Total loss: 2.308 | Reg loss: 0.033 | Tree loss: 2.308 | Accuracy: 0.357422 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 300 | Batch: 000 / 040 | Total loss: 2.316 | Reg loss: 0.033 | Tree loss: 2.316 | Accuracy: 0.369141 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 301 | Batch: 000 / 040 | Total loss: 2.394 | Reg loss: 0.033 | Tree loss: 2.394 | Accuracy: 0.330078 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 302 | Batch: 000 / 040 | Total loss: 2.257 | Reg loss: 0.033 | Tree loss: 2.257 | Accuracy: 0.392578 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 303 | Batch: 000 / 040 | Total loss: 2.387 | Reg loss: 0.033 | Tree loss: 2.387 | Accuracy: 0.322266 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 304 | Batch: 000 / 040 | Total loss: 2.338 | Reg loss: 0.033 | Tree loss: 2.338 | Accuracy: 0.365234 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 305 | Batch: 000 / 040 | Total loss: 2.330 | Reg loss: 0.033 | Tree loss: 2.330 | Accuracy: 0.373047 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 306 | Batch: 000 / 040 | Total loss: 2.381 | Reg loss: 0.033 | Tree loss: 2.381 | Accuracy: 0.347656 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 307 | Batch: 000 / 040 | Total loss: 2.275 | Reg loss: 0.033 | Tree loss: 2.275 | Accuracy: 0.390625 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 308 | Batch: 000 / 040 | Total loss: 2.315 | Reg loss: 0.033 | Tree loss: 2.315 | Accuracy: 0.376953 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 309 | Batch: 000 / 040 | Total loss: 2.365 | Reg loss: 0.033 | Tree loss: 2.365 | Accuracy: 0.349609 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 310 | Batch: 000 / 040 | Total loss: 2.347 | Reg loss: 0.033 | Tree loss: 2.347 | Accuracy: 0.380859 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 311 | Batch: 000 / 040 | Total loss: 2.336 | Reg loss: 0.033 | Tree loss: 2.336 | Accuracy: 0.330078 | 0.736 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 312 | Batch: 000 / 040 | Total loss: 2.294 | Reg loss: 0.033 | Tree loss: 2.294 | Accuracy: 0.371094 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 313 | Batch: 000 / 040 | Total loss: 2.364 | Reg loss: 0.033 | Tree loss: 2.364 | Accuracy: 0.332031 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 314 | Batch: 000 / 040 | Total loss: 2.318 | Reg loss: 0.033 | Tree loss: 2.318 | Accuracy: 0.357422 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 315 | Batch: 000 / 040 | Total loss: 2.307 | Reg loss: 0.033 | Tree loss: 2.307 | Accuracy: 0.380859 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 316 | Batch: 000 / 040 | Total loss: 2.317 | Reg loss: 0.033 | Tree loss: 2.317 | Accuracy: 0.386719 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 317 | Batch: 000 / 040 | Total loss: 2.384 | Reg loss: 0.033 | Tree loss: 2.384 | Accuracy: 0.335938 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 318 | Batch: 000 / 040 | Total loss: 2.302 | Reg loss: 0.033 | Tree loss: 2.302 | Accuracy: 0.390625 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 319 | Batch: 000 / 040 | Total loss: 2.329 | Reg loss: 0.033 | Tree loss: 2.329 | Accuracy: 0.355469 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 320 | Batch: 000 / 040 | Total loss: 2.361 | Reg loss: 0.033 | Tree loss: 2.361 | Accuracy: 0.363281 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 321 | Batch: 000 / 040 | Total loss: 2.291 | Reg loss: 0.033 | Tree loss: 2.291 | Accuracy: 0.390625 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 322 | Batch: 000 / 040 | Total loss: 2.350 | Reg loss: 0.033 | Tree loss: 2.350 | Accuracy: 0.322266 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 323 | Batch: 000 / 040 | Total loss: 2.333 | Reg loss: 0.033 | Tree loss: 2.333 | Accuracy: 0.347656 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 324 | Batch: 000 / 040 | Total loss: 2.359 | Reg loss: 0.033 | Tree loss: 2.359 | Accuracy: 0.353516 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 325 | Batch: 000 / 040 | Total loss: 2.302 | Reg loss: 0.033 | Tree loss: 2.302 | Accuracy: 0.402344 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 326 | Batch: 000 / 040 | Total loss: 2.308 | Reg loss: 0.033 | Tree loss: 2.308 | Accuracy: 0.382812 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 327 | Batch: 000 / 040 | Total loss: 2.349 | Reg loss: 0.033 | Tree loss: 2.349 | Accuracy: 0.347656 | 0.735 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 328 | Batch: 000 / 040 | Total loss: 2.342 | Reg loss: 0.033 | Tree loss: 2.342 | Accuracy: 0.349609 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 329 | Batch: 000 / 040 | Total loss: 2.319 | Reg loss: 0.033 | Tree loss: 2.319 | Accuracy: 0.414062 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 330 | Batch: 000 / 040 | Total loss: 2.341 | Reg loss: 0.033 | Tree loss: 2.341 | Accuracy: 0.337891 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 331 | Batch: 000 / 040 | Total loss: 2.321 | Reg loss: 0.033 | Tree loss: 2.321 | Accuracy: 0.359375 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 332 | Batch: 000 / 040 | Total loss: 2.317 | Reg loss: 0.033 | Tree loss: 2.317 | Accuracy: 0.373047 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 333 | Batch: 000 / 040 | Total loss: 2.320 | Reg loss: 0.033 | Tree loss: 2.320 | Accuracy: 0.384766 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 334 | Batch: 000 / 040 | Total loss: 2.296 | Reg loss: 0.033 | Tree loss: 2.296 | Accuracy: 0.378906 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 335 | Batch: 000 / 040 | Total loss: 2.310 | Reg loss: 0.033 | Tree loss: 2.310 | Accuracy: 0.357422 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 336 | Batch: 000 / 040 | Total loss: 2.352 | Reg loss: 0.033 | Tree loss: 2.352 | Accuracy: 0.339844 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 337 | Batch: 000 / 040 | Total loss: 2.278 | Reg loss: 0.033 | Tree loss: 2.278 | Accuracy: 0.376953 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 338 | Batch: 000 / 040 | Total loss: 2.355 | Reg loss: 0.033 | Tree loss: 2.355 | Accuracy: 0.359375 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 339 | Batch: 000 / 040 | Total loss: 2.317 | Reg loss: 0.033 | Tree loss: 2.317 | Accuracy: 0.359375 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 340 | Batch: 000 / 040 | Total loss: 2.339 | Reg loss: 0.033 | Tree loss: 2.339 | Accuracy: 0.355469 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 341 | Batch: 000 / 040 | Total loss: 2.386 | Reg loss: 0.033 | Tree loss: 2.386 | Accuracy: 0.341797 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 342 | Batch: 000 / 040 | Total loss: 2.355 | Reg loss: 0.033 | Tree loss: 2.355 | Accuracy: 0.365234 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 343 | Batch: 000 / 040 | Total loss: 2.329 | Reg loss: 0.033 | Tree loss: 2.329 | Accuracy: 0.378906 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 344 | Batch: 000 / 040 | Total loss: 2.323 | Reg loss: 0.033 | Tree loss: 2.323 | Accuracy: 0.390625 | 0.734 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 345 | Batch: 000 / 040 | Total loss: 2.336 | Reg loss: 0.033 | Tree loss: 2.336 | Accuracy: 0.367188 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 346 | Batch: 000 / 040 | Total loss: 2.350 | Reg loss: 0.033 | Tree loss: 2.350 | Accuracy: 0.341797 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 347 | Batch: 000 / 040 | Total loss: 2.349 | Reg loss: 0.033 | Tree loss: 2.349 | Accuracy: 0.330078 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 348 | Batch: 000 / 040 | Total loss: 2.326 | Reg loss: 0.033 | Tree loss: 2.326 | Accuracy: 0.404297 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 349 | Batch: 000 / 040 | Total loss: 2.317 | Reg loss: 0.033 | Tree loss: 2.317 | Accuracy: 0.388672 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 350 | Batch: 000 / 040 | Total loss: 2.328 | Reg loss: 0.033 | Tree loss: 2.328 | Accuracy: 0.357422 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 351 | Batch: 000 / 040 | Total loss: 2.351 | Reg loss: 0.033 | Tree loss: 2.351 | Accuracy: 0.359375 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 352 | Batch: 000 / 040 | Total loss: 2.380 | Reg loss: 0.033 | Tree loss: 2.380 | Accuracy: 0.324219 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 353 | Batch: 000 / 040 | Total loss: 2.358 | Reg loss: 0.033 | Tree loss: 2.358 | Accuracy: 0.333984 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 354 | Batch: 000 / 040 | Total loss: 2.380 | Reg loss: 0.033 | Tree loss: 2.380 | Accuracy: 0.322266 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 355 | Batch: 000 / 040 | Total loss: 2.271 | Reg loss: 0.033 | Tree loss: 2.271 | Accuracy: 0.388672 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 356 | Batch: 000 / 040 | Total loss: 2.354 | Reg loss: 0.033 | Tree loss: 2.354 | Accuracy: 0.343750 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 357 | Batch: 000 / 040 | Total loss: 2.333 | Reg loss: 0.033 | Tree loss: 2.333 | Accuracy: 0.363281 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 358 | Batch: 000 / 040 | Total loss: 2.281 | Reg loss: 0.033 | Tree loss: 2.281 | Accuracy: 0.357422 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 359 | Batch: 000 / 040 | Total loss: 2.327 | Reg loss: 0.033 | Tree loss: 2.327 | Accuracy: 0.378906 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 360 | Batch: 000 / 040 | Total loss: 2.333 | Reg loss: 0.033 | Tree loss: 2.333 | Accuracy: 0.396484 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 361 | Batch: 000 / 040 | Total loss: 2.377 | Reg loss: 0.033 | Tree loss: 2.377 | Accuracy: 0.320312 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 362 | Batch: 000 / 040 | Total loss: 2.333 | Reg loss: 0.033 | Tree loss: 2.333 | Accuracy: 0.375000 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 363 | Batch: 000 / 040 | Total loss: 2.355 | Reg loss: 0.033 | Tree loss: 2.355 | Accuracy: 0.347656 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 364 | Batch: 000 / 040 | Total loss: 2.356 | Reg loss: 0.033 | Tree loss: 2.356 | Accuracy: 0.349609 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 365 | Batch: 000 / 040 | Total loss: 2.362 | Reg loss: 0.033 | Tree loss: 2.362 | Accuracy: 0.337891 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 366 | Batch: 000 / 040 | Total loss: 2.298 | Reg loss: 0.033 | Tree loss: 2.298 | Accuracy: 0.384766 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 367 | Batch: 000 / 040 | Total loss: 2.373 | Reg loss: 0.033 | Tree loss: 2.373 | Accuracy: 0.347656 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 368 | Batch: 000 / 040 | Total loss: 2.318 | Reg loss: 0.033 | Tree loss: 2.318 | Accuracy: 0.345703 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 369 | Batch: 000 / 040 | Total loss: 2.356 | Reg loss: 0.033 | Tree loss: 2.356 | Accuracy: 0.337891 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 370 | Batch: 000 / 040 | Total loss: 2.241 | Reg loss: 0.033 | Tree loss: 2.241 | Accuracy: 0.412109 | 0.733 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 371 | Batch: 000 / 040 | Total loss: 2.329 | Reg loss: 0.033 | Tree loss: 2.329 | Accuracy: 0.367188 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 372 | Batch: 000 / 040 | Total loss: 2.371 | Reg loss: 0.033 | Tree loss: 2.371 | Accuracy: 0.328125 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 373 | Batch: 000 / 040 | Total loss: 2.307 | Reg loss: 0.033 | Tree loss: 2.307 | Accuracy: 0.390625 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 374 | Batch: 000 / 040 | Total loss: 2.362 | Reg loss: 0.033 | Tree loss: 2.362 | Accuracy: 0.353516 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 375 | Batch: 000 / 040 | Total loss: 2.344 | Reg loss: 0.033 | Tree loss: 2.344 | Accuracy: 0.341797 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 376 | Batch: 000 / 040 | Total loss: 2.352 | Reg loss: 0.033 | Tree loss: 2.352 | Accuracy: 0.357422 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 377 | Batch: 000 / 040 | Total loss: 2.394 | Reg loss: 0.033 | Tree loss: 2.394 | Accuracy: 0.302734 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 378 | Batch: 000 / 040 | Total loss: 2.307 | Reg loss: 0.033 | Tree loss: 2.307 | Accuracy: 0.378906 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 379 | Batch: 000 / 040 | Total loss: 2.305 | Reg loss: 0.033 | Tree loss: 2.305 | Accuracy: 0.363281 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 380 | Batch: 000 / 040 | Total loss: 2.392 | Reg loss: 0.033 | Tree loss: 2.392 | Accuracy: 0.330078 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 381 | Batch: 000 / 040 | Total loss: 2.337 | Reg loss: 0.033 | Tree loss: 2.337 | Accuracy: 0.359375 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 382 | Batch: 000 / 040 | Total loss: 2.326 | Reg loss: 0.033 | Tree loss: 2.326 | Accuracy: 0.351562 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 383 | Batch: 000 / 040 | Total loss: 2.336 | Reg loss: 0.033 | Tree loss: 2.336 | Accuracy: 0.361328 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 384 | Batch: 000 / 040 | Total loss: 2.362 | Reg loss: 0.033 | Tree loss: 2.362 | Accuracy: 0.369141 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 385 | Batch: 000 / 040 | Total loss: 2.390 | Reg loss: 0.033 | Tree loss: 2.390 | Accuracy: 0.341797 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 386 | Batch: 000 / 040 | Total loss: 2.359 | Reg loss: 0.033 | Tree loss: 2.359 | Accuracy: 0.347656 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 387 | Batch: 000 / 040 | Total loss: 2.374 | Reg loss: 0.033 | Tree loss: 2.374 | Accuracy: 0.353516 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 388 | Batch: 000 / 040 | Total loss: 2.332 | Reg loss: 0.033 | Tree loss: 2.332 | Accuracy: 0.382812 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 389 | Batch: 000 / 040 | Total loss: 2.318 | Reg loss: 0.033 | Tree loss: 2.318 | Accuracy: 0.373047 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 390 | Batch: 000 / 040 | Total loss: 2.320 | Reg loss: 0.033 | Tree loss: 2.320 | Accuracy: 0.382812 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 391 | Batch: 000 / 040 | Total loss: 2.276 | Reg loss: 0.033 | Tree loss: 2.276 | Accuracy: 0.396484 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 392 | Batch: 000 / 040 | Total loss: 2.354 | Reg loss: 0.033 | Tree loss: 2.354 | Accuracy: 0.373047 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 393 | Batch: 000 / 040 | Total loss: 2.292 | Reg loss: 0.033 | Tree loss: 2.292 | Accuracy: 0.386719 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 394 | Batch: 000 / 040 | Total loss: 2.333 | Reg loss: 0.033 | Tree loss: 2.333 | Accuracy: 0.355469 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 395 | Batch: 000 / 040 | Total loss: 2.324 | Reg loss: 0.033 | Tree loss: 2.324 | Accuracy: 0.408203 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 396 | Batch: 000 / 040 | Total loss: 2.288 | Reg loss: 0.033 | Tree loss: 2.288 | Accuracy: 0.378906 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 397 | Batch: 000 / 040 | Total loss: 2.319 | Reg loss: 0.033 | Tree loss: 2.319 | Accuracy: 0.402344 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 398 | Batch: 000 / 040 | Total loss: 2.334 | Reg loss: 0.033 | Tree loss: 2.334 | Accuracy: 0.357422 | 0.732 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 399 | Batch: 000 / 040 | Total loss: 2.348 | Reg loss: 0.033 | Tree loss: 2.348 | Accuracy: 0.369141 | 0.732 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa4779e96774e28ac385d997bc3713b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9536bda765f04f7f9f18b24ec9646983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f627d17d1866400093e94c3ddb8f9192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106a9aaf64674c2dbf3f3a0f75e15e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 8.075471698113208\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 53\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "============== Pattern 2 ==============\n",
      "============== Pattern 3 ==============\n",
      "============== Pattern 4 ==============\n",
      "============== Pattern 5 ==============\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "40\n",
      "============== Pattern 8 ==============\n",
      "============== Pattern 9 ==============\n",
      "30\n",
      "============== Pattern 10 ==============\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "============== Pattern 16 ==============\n",
      "9615\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "8687\n",
      "============== Pattern 19 ==============\n",
      "============== Pattern 20 ==============\n",
      "============== Pattern 21 ==============\n",
      "============== Pattern 22 ==============\n",
      "============== Pattern 23 ==============\n",
      "============== Pattern 24 ==============\n",
      "============== Pattern 25 ==============\n",
      "============== Pattern 26 ==============\n",
      "============== Pattern 27 ==============\n",
      "============== Pattern 28 ==============\n",
      "============== Pattern 29 ==============\n",
      "============== Pattern 30 ==============\n",
      "============== Pattern 31 ==============\n",
      "============== Pattern 32 ==============\n",
      "============== Pattern 33 ==============\n",
      "============== Pattern 34 ==============\n",
      "============== Pattern 35 ==============\n",
      "============== Pattern 36 ==============\n",
      "============== Pattern 37 ==============\n",
      "============== Pattern 38 ==============\n",
      "============== Pattern 39 ==============\n",
      "============== Pattern 40 ==============\n",
      "============== Pattern 41 ==============\n",
      "============== Pattern 42 ==============\n",
      "============== Pattern 43 ==============\n",
      "============== Pattern 44 ==============\n",
      "============== Pattern 45 ==============\n",
      "============== Pattern 46 ==============\n",
      "============== Pattern 47 ==============\n",
      "============== Pattern 48 ==============\n",
      "============== Pattern 49 ==============\n",
      "1756\n",
      "============== Pattern 50 ==============\n",
      "============== Pattern 51 ==============\n",
      "============== Pattern 52 ==============\n",
      "============== Pattern 53 ==============\n",
      "Average comprehensibility: 45.77358490566038\n",
      "std comprehensibility: 12.515110126885581\n",
      "var comprehensibility: 156.62798148807403\n",
      "minimum comprehensibility: 12\n",
      "maximum comprehensibility: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    }
   ],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
