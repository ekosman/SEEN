{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "tree_depth = 6\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.52977180480957 | KNN Loss: 5.478849411010742 | CLS Loss: 2.050922155380249\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 3.683405876159668 | KNN Loss: 2.786168098449707 | CLS Loss: 0.8972376585006714\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 3.446229934692383 | KNN Loss: 2.6365323066711426 | CLS Loss: 0.8096975684165955\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 3.278867721557617 | KNN Loss: 2.509679079055786 | CLS Loss: 0.769188642501831\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 3.1989879608154297 | KNN Loss: 2.5724802017211914 | CLS Loss: 0.6265076994895935\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 3.1702568531036377 | KNN Loss: 2.635077953338623 | CLS Loss: 0.5351788997650146\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 3.150221586227417 | KNN Loss: 2.5995898246765137 | CLS Loss: 0.5506318211555481\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 3.1188483238220215 | KNN Loss: 2.5542352199554443 | CLS Loss: 0.5646130442619324\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 3.1099038124084473 | KNN Loss: 2.570258378982544 | CLS Loss: 0.5396453142166138\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 2.995448589324951 | KNN Loss: 2.5809385776519775 | CLS Loss: 0.41451001167297363\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 2.991208791732788 | KNN Loss: 2.5492875576019287 | CLS Loss: 0.4419211447238922\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 2.947025775909424 | KNN Loss: 2.549268960952759 | CLS Loss: 0.3977569341659546\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 3.051589250564575 | KNN Loss: 2.603893280029297 | CLS Loss: 0.4476960003376007\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 2.9671833515167236 | KNN Loss: 2.572936534881592 | CLS Loss: 0.394246906042099\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 2.9008824825286865 | KNN Loss: 2.5370683670043945 | CLS Loss: 0.3638141453266144\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 2.8475229740142822 | KNN Loss: 2.545799493789673 | CLS Loss: 0.30172351002693176\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 2.8948116302490234 | KNN Loss: 2.5118305683135986 | CLS Loss: 0.38298097252845764\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 2.8812265396118164 | KNN Loss: 2.5124692916870117 | CLS Loss: 0.36875736713409424\n",
      "Epoch: 001, Loss: 3.2538, Train: 0.9187, Valid: 0.9186, Best: 0.9186\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 2.8362929821014404 | KNN Loss: 2.5730197429656982 | CLS Loss: 0.2632732391357422\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 2.893979787826538 | KNN Loss: 2.5802462100982666 | CLS Loss: 0.31373366713523865\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 2.85506272315979 | KNN Loss: 2.560690402984619 | CLS Loss: 0.29437223076820374\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 2.8855979442596436 | KNN Loss: 2.5527889728546143 | CLS Loss: 0.3328089714050293\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 2.802124261856079 | KNN Loss: 2.504338026046753 | CLS Loss: 0.29778632521629333\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 2.7959160804748535 | KNN Loss: 2.5539844036102295 | CLS Loss: 0.24193179607391357\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 2.854004144668579 | KNN Loss: 2.530318021774292 | CLS Loss: 0.3236861228942871\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 2.880629539489746 | KNN Loss: 2.59938907623291 | CLS Loss: 0.28124040365219116\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 2.8059446811676025 | KNN Loss: 2.5601859092712402 | CLS Loss: 0.24575883150100708\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 2.7780613899230957 | KNN Loss: 2.5414648056030273 | CLS Loss: 0.23659662902355194\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 2.8177082538604736 | KNN Loss: 2.547158718109131 | CLS Loss: 0.27054962515830994\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 2.791043519973755 | KNN Loss: 2.5577385425567627 | CLS Loss: 0.2333049774169922\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 2.7746191024780273 | KNN Loss: 2.494921922683716 | CLS Loss: 0.27969714999198914\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 2.7409040927886963 | KNN Loss: 2.530062675476074 | CLS Loss: 0.21084149181842804\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 2.7569236755371094 | KNN Loss: 2.5288450717926025 | CLS Loss: 0.22807860374450684\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 2.724100112915039 | KNN Loss: 2.5704903602600098 | CLS Loss: 0.15360985696315765\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 2.766688108444214 | KNN Loss: 2.551358461380005 | CLS Loss: 0.2153296172618866\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 2.7302823066711426 | KNN Loss: 2.531715154647827 | CLS Loss: 0.19856709241867065\n",
      "Epoch: 002, Loss: 2.8062, Train: 0.9387, Valid: 0.9384, Best: 0.9384\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 2.7010598182678223 | KNN Loss: 2.5170094966888428 | CLS Loss: 0.1840502768754959\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 2.6884543895721436 | KNN Loss: 2.5113534927368164 | CLS Loss: 0.17710086703300476\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 2.716007709503174 | KNN Loss: 2.4766969680786133 | CLS Loss: 0.2393108606338501\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 2.747431755065918 | KNN Loss: 2.513436794281006 | CLS Loss: 0.2339949756860733\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 2.7658510208129883 | KNN Loss: 2.542851448059082 | CLS Loss: 0.22299951314926147\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 2.662127733230591 | KNN Loss: 2.509000301361084 | CLS Loss: 0.1531275361776352\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 2.7489469051361084 | KNN Loss: 2.5181632041931152 | CLS Loss: 0.23078367114067078\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 2.7185678482055664 | KNN Loss: 2.5625457763671875 | CLS Loss: 0.15602219104766846\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 2.6708240509033203 | KNN Loss: 2.5019490718841553 | CLS Loss: 0.1688748598098755\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 2.6460559368133545 | KNN Loss: 2.5029544830322266 | CLS Loss: 0.1431015431880951\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 2.7525932788848877 | KNN Loss: 2.513997793197632 | CLS Loss: 0.2385954111814499\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 2.708265781402588 | KNN Loss: 2.530639171600342 | CLS Loss: 0.17762650549411774\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 2.695206880569458 | KNN Loss: 2.5221686363220215 | CLS Loss: 0.17303818464279175\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 2.6787755489349365 | KNN Loss: 2.541390895843506 | CLS Loss: 0.1373845636844635\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 2.659492015838623 | KNN Loss: 2.522264003753662 | CLS Loss: 0.13722802698612213\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 2.690593719482422 | KNN Loss: 2.519911527633667 | CLS Loss: 0.17068207263946533\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 2.689732789993286 | KNN Loss: 2.527498245239258 | CLS Loss: 0.16223450005054474\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 2.683439016342163 | KNN Loss: 2.5095345973968506 | CLS Loss: 0.1739044487476349\n",
      "Epoch: 003, Loss: 2.6936, Train: 0.9586, Valid: 0.9560, Best: 0.9560\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 2.651737689971924 | KNN Loss: 2.5041465759277344 | CLS Loss: 0.1475909948348999\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 2.6411964893341064 | KNN Loss: 2.4846925735473633 | CLS Loss: 0.15650396049022675\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 2.6344003677368164 | KNN Loss: 2.5117475986480713 | CLS Loss: 0.12265287339687347\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 2.705408811569214 | KNN Loss: 2.530479907989502 | CLS Loss: 0.17492884397506714\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 2.604762554168701 | KNN Loss: 2.4814200401306152 | CLS Loss: 0.12334253638982773\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 2.6454858779907227 | KNN Loss: 2.5063729286193848 | CLS Loss: 0.13911300897598267\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 2.610813617706299 | KNN Loss: 2.4557888507843018 | CLS Loss: 0.15502479672431946\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 2.6581106185913086 | KNN Loss: 2.5115110874176025 | CLS Loss: 0.1465994268655777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 2.6416022777557373 | KNN Loss: 2.507258892059326 | CLS Loss: 0.1343434751033783\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 2.6252903938293457 | KNN Loss: 2.466026544570923 | CLS Loss: 0.15926380455493927\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 2.632112503051758 | KNN Loss: 2.4795005321502686 | CLS Loss: 0.15261198580265045\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 2.6179697513580322 | KNN Loss: 2.491077184677124 | CLS Loss: 0.12689253687858582\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 2.622281074523926 | KNN Loss: 2.503100633621216 | CLS Loss: 0.11918036639690399\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 2.625605583190918 | KNN Loss: 2.4916012287139893 | CLS Loss: 0.13400425016880035\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 2.697336435317993 | KNN Loss: 2.5071699619293213 | CLS Loss: 0.1901664286851883\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 2.6291849613189697 | KNN Loss: 2.5208449363708496 | CLS Loss: 0.10833998024463654\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 2.6070265769958496 | KNN Loss: 2.47969126701355 | CLS Loss: 0.1273353099822998\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 2.594407081604004 | KNN Loss: 2.4692094326019287 | CLS Loss: 0.12519773840904236\n",
      "Epoch: 004, Loss: 2.6390, Train: 0.9688, Valid: 0.9664, Best: 0.9664\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 2.6200296878814697 | KNN Loss: 2.456991672515869 | CLS Loss: 0.16303810477256775\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 2.6217496395111084 | KNN Loss: 2.4903581142425537 | CLS Loss: 0.13139154016971588\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 2.599299669265747 | KNN Loss: 2.47751784324646 | CLS Loss: 0.1217818558216095\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 2.606628894805908 | KNN Loss: 2.471132278442383 | CLS Loss: 0.1354966014623642\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 2.6495585441589355 | KNN Loss: 2.4744482040405273 | CLS Loss: 0.17511023581027985\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 2.5819318294525146 | KNN Loss: 2.458754062652588 | CLS Loss: 0.12317769229412079\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 2.6165738105773926 | KNN Loss: 2.4828786849975586 | CLS Loss: 0.1336950808763504\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 2.604506015777588 | KNN Loss: 2.4443554878234863 | CLS Loss: 0.16015061736106873\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 2.5913186073303223 | KNN Loss: 2.486922264099121 | CLS Loss: 0.10439635068178177\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 2.5605573654174805 | KNN Loss: 2.4691848754882812 | CLS Loss: 0.09137240052223206\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 2.6390249729156494 | KNN Loss: 2.5227065086364746 | CLS Loss: 0.116318479180336\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 2.559555768966675 | KNN Loss: 2.4720940589904785 | CLS Loss: 0.08746160566806793\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 2.621356248855591 | KNN Loss: 2.474721670150757 | CLS Loss: 0.14663463830947876\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 2.5578224658966064 | KNN Loss: 2.4160475730895996 | CLS Loss: 0.14177489280700684\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 2.5475847721099854 | KNN Loss: 2.4446332454681396 | CLS Loss: 0.10295155644416809\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 2.600914478302002 | KNN Loss: 2.473877429962158 | CLS Loss: 0.12703701853752136\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 2.6033291816711426 | KNN Loss: 2.4832472801208496 | CLS Loss: 0.120081827044487\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 2.6385138034820557 | KNN Loss: 2.4841623306274414 | CLS Loss: 0.1543513685464859\n",
      "Epoch: 005, Loss: 2.5945, Train: 0.9705, Valid: 0.9674, Best: 0.9674\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 2.597743272781372 | KNN Loss: 2.5017929077148438 | CLS Loss: 0.09595039486885071\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 2.5772013664245605 | KNN Loss: 2.4501278400421143 | CLS Loss: 0.1270734816789627\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 2.6570181846618652 | KNN Loss: 2.4674453735351562 | CLS Loss: 0.18957288563251495\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 2.5701324939727783 | KNN Loss: 2.4902641773223877 | CLS Loss: 0.07986826449632645\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 2.5864360332489014 | KNN Loss: 2.4823555946350098 | CLS Loss: 0.10408049076795578\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 2.5889954566955566 | KNN Loss: 2.4596731662750244 | CLS Loss: 0.12932217121124268\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 2.5650436878204346 | KNN Loss: 2.4729321002960205 | CLS Loss: 0.09211160987615585\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 2.5387721061706543 | KNN Loss: 2.4428229331970215 | CLS Loss: 0.09594909101724625\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 2.565451145172119 | KNN Loss: 2.4364845752716064 | CLS Loss: 0.12896665930747986\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 2.5760915279388428 | KNN Loss: 2.456040859222412 | CLS Loss: 0.12005074322223663\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 2.569289445877075 | KNN Loss: 2.4668128490448 | CLS Loss: 0.10247660428285599\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 2.6044998168945312 | KNN Loss: 2.4321064949035645 | CLS Loss: 0.17239324748516083\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 2.5536446571350098 | KNN Loss: 2.4190917015075684 | CLS Loss: 0.13455304503440857\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 2.5659847259521484 | KNN Loss: 2.512096643447876 | CLS Loss: 0.053888145834207535\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 2.5590603351593018 | KNN Loss: 2.465264320373535 | CLS Loss: 0.09379597753286362\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 2.591721534729004 | KNN Loss: 2.4515976905822754 | CLS Loss: 0.14012376964092255\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 2.564704656600952 | KNN Loss: 2.446922540664673 | CLS Loss: 0.11778208613395691\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 2.5624496936798096 | KNN Loss: 2.44907546043396 | CLS Loss: 0.11337420344352722\n",
      "Epoch: 006, Loss: 2.5642, Train: 0.9718, Valid: 0.9693, Best: 0.9693\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 2.6026430130004883 | KNN Loss: 2.4922263622283936 | CLS Loss: 0.11041676998138428\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 2.595094680786133 | KNN Loss: 2.4645700454711914 | CLS Loss: 0.13052454590797424\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 2.5595836639404297 | KNN Loss: 2.466543674468994 | CLS Loss: 0.09304004907608032\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 2.551867723464966 | KNN Loss: 2.465669870376587 | CLS Loss: 0.0861978605389595\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 2.5408122539520264 | KNN Loss: 2.4344656467437744 | CLS Loss: 0.10634653270244598\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 2.541018486022949 | KNN Loss: 2.4573137760162354 | CLS Loss: 0.08370479196310043\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 2.538142681121826 | KNN Loss: 2.4581282138824463 | CLS Loss: 0.08001434803009033\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 2.620182991027832 | KNN Loss: 2.5283937454223633 | CLS Loss: 0.09178918600082397\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 2.5976951122283936 | KNN Loss: 2.510303258895874 | CLS Loss: 0.08739174902439117\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 2.5392351150512695 | KNN Loss: 2.4413962364196777 | CLS Loss: 0.09783890843391418\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 2.5415658950805664 | KNN Loss: 2.433391571044922 | CLS Loss: 0.10817437618970871\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 2.5222840309143066 | KNN Loss: 2.4326491355895996 | CLS Loss: 0.0896349549293518\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 2.5698399543762207 | KNN Loss: 2.4393868446350098 | CLS Loss: 0.13045312464237213\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 2.507755756378174 | KNN Loss: 2.4156441688537598 | CLS Loss: 0.09211163967847824\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 2.5093581676483154 | KNN Loss: 2.4304916858673096 | CLS Loss: 0.07886645942926407\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 2.5619654655456543 | KNN Loss: 2.4799375534057617 | CLS Loss: 0.0820278450846672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 2.5521764755249023 | KNN Loss: 2.437957763671875 | CLS Loss: 0.11421866714954376\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 2.560342788696289 | KNN Loss: 2.450408935546875 | CLS Loss: 0.10993392020463943\n",
      "Epoch: 007, Loss: 2.5501, Train: 0.9765, Valid: 0.9739, Best: 0.9739\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 2.5339887142181396 | KNN Loss: 2.462736129760742 | CLS Loss: 0.07125262171030045\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 2.5076987743377686 | KNN Loss: 2.4443304538726807 | CLS Loss: 0.06336834281682968\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 2.5391862392425537 | KNN Loss: 2.462339162826538 | CLS Loss: 0.07684702426195145\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 2.537283420562744 | KNN Loss: 2.4383511543273926 | CLS Loss: 0.0989321619272232\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 2.5249199867248535 | KNN Loss: 2.42889666557312 | CLS Loss: 0.096023328602314\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 2.492112636566162 | KNN Loss: 2.4311511516571045 | CLS Loss: 0.06096142902970314\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 2.5652546882629395 | KNN Loss: 2.4693281650543213 | CLS Loss: 0.09592646360397339\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 2.5350821018218994 | KNN Loss: 2.424785614013672 | CLS Loss: 0.11029655486345291\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 2.537949323654175 | KNN Loss: 2.4761946201324463 | CLS Loss: 0.06175476312637329\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 2.5248031616210938 | KNN Loss: 2.4324872493743896 | CLS Loss: 0.09231581538915634\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 2.5336954593658447 | KNN Loss: 2.4780540466308594 | CLS Loss: 0.055641479790210724\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 2.5862233638763428 | KNN Loss: 2.485872268676758 | CLS Loss: 0.10035105049610138\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 2.5167129039764404 | KNN Loss: 2.445943593978882 | CLS Loss: 0.07076942175626755\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 2.503955125808716 | KNN Loss: 2.3956010341644287 | CLS Loss: 0.1083541288971901\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 2.529398202896118 | KNN Loss: 2.4539620876312256 | CLS Loss: 0.07543601840734482\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 2.498969316482544 | KNN Loss: 2.4488232135772705 | CLS Loss: 0.0501461885869503\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 2.5056655406951904 | KNN Loss: 2.4261746406555176 | CLS Loss: 0.07949098944664001\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 2.5651023387908936 | KNN Loss: 2.4642302989959717 | CLS Loss: 0.10087204724550247\n",
      "Epoch: 008, Loss: 2.5343, Train: 0.9771, Valid: 0.9726, Best: 0.9739\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 2.560577869415283 | KNN Loss: 2.4736173152923584 | CLS Loss: 0.08696044236421585\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 2.5346333980560303 | KNN Loss: 2.43157958984375 | CLS Loss: 0.10305391997098923\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 2.593201160430908 | KNN Loss: 2.464226722717285 | CLS Loss: 0.12897448241710663\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 2.528653383255005 | KNN Loss: 2.453383207321167 | CLS Loss: 0.0752701386809349\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 2.525702953338623 | KNN Loss: 2.438131093978882 | CLS Loss: 0.08757190406322479\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 2.517963409423828 | KNN Loss: 2.424464464187622 | CLS Loss: 0.09349885582923889\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 2.518911361694336 | KNN Loss: 2.4403538703918457 | CLS Loss: 0.07855754345655441\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 2.485705614089966 | KNN Loss: 2.4351372718811035 | CLS Loss: 0.05056832358241081\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 2.5254852771759033 | KNN Loss: 2.4363155364990234 | CLS Loss: 0.08916974812746048\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 2.559546709060669 | KNN Loss: 2.445192337036133 | CLS Loss: 0.11435437202453613\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 2.580565929412842 | KNN Loss: 2.4618945121765137 | CLS Loss: 0.11867149919271469\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 2.5287084579467773 | KNN Loss: 2.466526746749878 | CLS Loss: 0.0621817372739315\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 2.5399839878082275 | KNN Loss: 2.477687120437622 | CLS Loss: 0.06229695677757263\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 2.4998459815979004 | KNN Loss: 2.4225447177886963 | CLS Loss: 0.07730137556791306\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 2.565046548843384 | KNN Loss: 2.474585771560669 | CLS Loss: 0.09046082943677902\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 2.5483293533325195 | KNN Loss: 2.450756072998047 | CLS Loss: 0.09757328778505325\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 2.552948474884033 | KNN Loss: 2.472649335861206 | CLS Loss: 0.08029913157224655\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 2.5287508964538574 | KNN Loss: 2.453686237335205 | CLS Loss: 0.0750647634267807\n",
      "Epoch: 009, Loss: 2.5392, Train: 0.9784, Valid: 0.9750, Best: 0.9750\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 2.5623533725738525 | KNN Loss: 2.4510726928710938 | CLS Loss: 0.11128074675798416\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 2.5278501510620117 | KNN Loss: 2.444859266281128 | CLS Loss: 0.08299081772565842\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 2.5520777702331543 | KNN Loss: 2.441269874572754 | CLS Loss: 0.11080783605575562\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 2.5340359210968018 | KNN Loss: 2.457967519760132 | CLS Loss: 0.07606850564479828\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 2.504382848739624 | KNN Loss: 2.4277520179748535 | CLS Loss: 0.07663087546825409\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 2.510423183441162 | KNN Loss: 2.418869972229004 | CLS Loss: 0.09155324846506119\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 2.5465331077575684 | KNN Loss: 2.451465606689453 | CLS Loss: 0.09506752341985703\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 2.527601957321167 | KNN Loss: 2.431565999984741 | CLS Loss: 0.09603597968816757\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 2.558469772338867 | KNN Loss: 2.4634671211242676 | CLS Loss: 0.09500255435705185\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 2.5575313568115234 | KNN Loss: 2.4845423698425293 | CLS Loss: 0.07298889756202698\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 2.527700185775757 | KNN Loss: 2.473431348800659 | CLS Loss: 0.05426890775561333\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 2.4958674907684326 | KNN Loss: 2.4421451091766357 | CLS Loss: 0.05372248589992523\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 2.534087657928467 | KNN Loss: 2.4630887508392334 | CLS Loss: 0.07099878787994385\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 2.5254218578338623 | KNN Loss: 2.457423210144043 | CLS Loss: 0.06799854338169098\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 2.548259973526001 | KNN Loss: 2.4667487144470215 | CLS Loss: 0.08151125907897949\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 2.4799959659576416 | KNN Loss: 2.4188950061798096 | CLS Loss: 0.06110097095370293\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 2.5333354473114014 | KNN Loss: 2.4540984630584717 | CLS Loss: 0.07923704385757446\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 2.532334327697754 | KNN Loss: 2.436241388320923 | CLS Loss: 0.09609303623437881\n",
      "Epoch: 010, Loss: 2.5237, Train: 0.9807, Valid: 0.9764, Best: 0.9764\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 2.5681118965148926 | KNN Loss: 2.4708454608917236 | CLS Loss: 0.09726640582084656\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 2.524890899658203 | KNN Loss: 2.459613800048828 | CLS Loss: 0.06527721881866455\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 2.5635781288146973 | KNN Loss: 2.4303247928619385 | CLS Loss: 0.1332533061504364\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 2.5343613624572754 | KNN Loss: 2.4510929584503174 | CLS Loss: 0.08326844125986099\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 2.549700975418091 | KNN Loss: 2.4486188888549805 | CLS Loss: 0.10108213126659393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 2.533390760421753 | KNN Loss: 2.4464941024780273 | CLS Loss: 0.08689658343791962\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 2.504801034927368 | KNN Loss: 2.42911434173584 | CLS Loss: 0.07568667083978653\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 2.5146284103393555 | KNN Loss: 2.4148519039154053 | CLS Loss: 0.09977652877569199\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 2.5232040882110596 | KNN Loss: 2.4557511806488037 | CLS Loss: 0.06745290011167526\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 2.4928107261657715 | KNN Loss: 2.41213321685791 | CLS Loss: 0.08067762106657028\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 2.5432424545288086 | KNN Loss: 2.459280252456665 | CLS Loss: 0.08396217226982117\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 2.536130666732788 | KNN Loss: 2.4660532474517822 | CLS Loss: 0.07007752358913422\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 2.5211100578308105 | KNN Loss: 2.4254403114318848 | CLS Loss: 0.09566966444253922\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 2.4851772785186768 | KNN Loss: 2.4313747882843018 | CLS Loss: 0.053802408277988434\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 2.509813070297241 | KNN Loss: 2.4418530464172363 | CLS Loss: 0.06796001642942429\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 2.505686044692993 | KNN Loss: 2.4401838779449463 | CLS Loss: 0.0655021220445633\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 2.502056360244751 | KNN Loss: 2.4521524906158447 | CLS Loss: 0.04990386590361595\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 2.455709218978882 | KNN Loss: 2.4189655780792236 | CLS Loss: 0.036743659526109695\n",
      "Epoch: 011, Loss: 2.5134, Train: 0.9823, Valid: 0.9779, Best: 0.9779\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 2.481153964996338 | KNN Loss: 2.4425220489501953 | CLS Loss: 0.038631923496723175\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 2.4783835411071777 | KNN Loss: 2.4313199520111084 | CLS Loss: 0.0470636710524559\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 2.4891791343688965 | KNN Loss: 2.4231624603271484 | CLS Loss: 0.0660167783498764\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 2.507748603820801 | KNN Loss: 2.4189705848693848 | CLS Loss: 0.0887780413031578\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 2.469425678253174 | KNN Loss: 2.430122137069702 | CLS Loss: 0.03930354118347168\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 2.471245050430298 | KNN Loss: 2.428481101989746 | CLS Loss: 0.04276399686932564\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 2.517376661300659 | KNN Loss: 2.4516420364379883 | CLS Loss: 0.06573456525802612\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 2.4953083992004395 | KNN Loss: 2.4070687294006348 | CLS Loss: 0.08823961764574051\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 2.5276079177856445 | KNN Loss: 2.4626247882843018 | CLS Loss: 0.06498318910598755\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 2.4969820976257324 | KNN Loss: 2.433382034301758 | CLS Loss: 0.06360014528036118\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 2.505829095840454 | KNN Loss: 2.4152629375457764 | CLS Loss: 0.09056616574525833\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 2.506091356277466 | KNN Loss: 2.4688947200775146 | CLS Loss: 0.03719666227698326\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 2.498514175415039 | KNN Loss: 2.4215569496154785 | CLS Loss: 0.07695713639259338\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 2.4860336780548096 | KNN Loss: 2.4053092002868652 | CLS Loss: 0.08072443306446075\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 2.4849905967712402 | KNN Loss: 2.42452073097229 | CLS Loss: 0.060469843447208405\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 2.5447192192077637 | KNN Loss: 2.476224899291992 | CLS Loss: 0.06849435716867447\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 2.554931163787842 | KNN Loss: 2.481696844100952 | CLS Loss: 0.07323436439037323\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 2.5090150833129883 | KNN Loss: 2.4695000648498535 | CLS Loss: 0.03951499983668327\n",
      "Epoch: 012, Loss: 2.5094, Train: 0.9801, Valid: 0.9769, Best: 0.9779\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 2.516237258911133 | KNN Loss: 2.480334758758545 | CLS Loss: 0.03590256720781326\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 2.472747325897217 | KNN Loss: 2.423656702041626 | CLS Loss: 0.04909073933959007\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 2.5253748893737793 | KNN Loss: 2.4664201736450195 | CLS Loss: 0.058954790234565735\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 2.480193614959717 | KNN Loss: 2.410658597946167 | CLS Loss: 0.06953497231006622\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 2.471127986907959 | KNN Loss: 2.4146430492401123 | CLS Loss: 0.0564848929643631\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 2.5309407711029053 | KNN Loss: 2.4636731147766113 | CLS Loss: 0.06726765632629395\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 2.517043352127075 | KNN Loss: 2.449429750442505 | CLS Loss: 0.06761369854211807\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 2.501910448074341 | KNN Loss: 2.4424126148223877 | CLS Loss: 0.05949778109788895\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 2.5698933601379395 | KNN Loss: 2.4879305362701416 | CLS Loss: 0.08196283131837845\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 2.518785238265991 | KNN Loss: 2.4456517696380615 | CLS Loss: 0.0731334313750267\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 2.5108113288879395 | KNN Loss: 2.4732422828674316 | CLS Loss: 0.03756905347108841\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 2.508985757827759 | KNN Loss: 2.4513494968414307 | CLS Loss: 0.05763622373342514\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 2.4674603939056396 | KNN Loss: 2.3921995162963867 | CLS Loss: 0.07526098936796188\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 2.5566892623901367 | KNN Loss: 2.4798026084899902 | CLS Loss: 0.07688667625188828\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 2.5372793674468994 | KNN Loss: 2.455512046813965 | CLS Loss: 0.08176729083061218\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 2.5276050567626953 | KNN Loss: 2.47525691986084 | CLS Loss: 0.0523480623960495\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 2.5268704891204834 | KNN Loss: 2.4142539501190186 | CLS Loss: 0.11261657625436783\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 2.5070996284484863 | KNN Loss: 2.4215457439422607 | CLS Loss: 0.08555400371551514\n",
      "Epoch: 013, Loss: 2.5042, Train: 0.9823, Valid: 0.9780, Best: 0.9780\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 2.481721878051758 | KNN Loss: 2.4327638149261475 | CLS Loss: 0.048958051949739456\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 2.5026605129241943 | KNN Loss: 2.4266324043273926 | CLS Loss: 0.07602804899215698\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 2.472900390625 | KNN Loss: 2.3828370571136475 | CLS Loss: 0.0900634154677391\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 2.495234727859497 | KNN Loss: 2.4373717308044434 | CLS Loss: 0.05786309018731117\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 2.475707530975342 | KNN Loss: 2.403848886489868 | CLS Loss: 0.07185854017734528\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 2.5306529998779297 | KNN Loss: 2.453575372695923 | CLS Loss: 0.07707751542329788\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 2.539280652999878 | KNN Loss: 2.48002028465271 | CLS Loss: 0.05926033481955528\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 2.515719175338745 | KNN Loss: 2.469843626022339 | CLS Loss: 0.045875560492277145\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 2.5139567852020264 | KNN Loss: 2.44320011138916 | CLS Loss: 0.07075660675764084\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 2.5088813304901123 | KNN Loss: 2.4068732261657715 | CLS Loss: 0.10200799256563187\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 2.493162155151367 | KNN Loss: 2.4578816890716553 | CLS Loss: 0.035280488431453705\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 2.488745927810669 | KNN Loss: 2.4250941276550293 | CLS Loss: 0.06365171074867249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 2.4870569705963135 | KNN Loss: 2.4060440063476562 | CLS Loss: 0.0810130164027214\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 2.472944974899292 | KNN Loss: 2.4321982860565186 | CLS Loss: 0.04074675589799881\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 2.482830047607422 | KNN Loss: 2.402920961380005 | CLS Loss: 0.07990897446870804\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 2.436797618865967 | KNN Loss: 2.4038889408111572 | CLS Loss: 0.032908715307712555\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 2.4863297939300537 | KNN Loss: 2.436267375946045 | CLS Loss: 0.050062377005815506\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 2.4573404788970947 | KNN Loss: 2.401641607284546 | CLS Loss: 0.05569878965616226\n",
      "Epoch: 014, Loss: 2.4987, Train: 0.9845, Valid: 0.9803, Best: 0.9803\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 2.478961706161499 | KNN Loss: 2.4204139709472656 | CLS Loss: 0.05854771286249161\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 2.4813458919525146 | KNN Loss: 2.4267258644104004 | CLS Loss: 0.05462006852030754\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 2.5097122192382812 | KNN Loss: 2.448842763900757 | CLS Loss: 0.06086947023868561\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 2.4665400981903076 | KNN Loss: 2.4314966201782227 | CLS Loss: 0.03504353016614914\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 2.494960308074951 | KNN Loss: 2.41888165473938 | CLS Loss: 0.07607860118150711\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 2.5178873538970947 | KNN Loss: 2.472428560256958 | CLS Loss: 0.045458849519491196\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 2.486445188522339 | KNN Loss: 2.4185268878936768 | CLS Loss: 0.06791828572750092\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 2.4515435695648193 | KNN Loss: 2.407374143600464 | CLS Loss: 0.04416954144835472\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 2.525376081466675 | KNN Loss: 2.4506454467773438 | CLS Loss: 0.07473061978816986\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 2.5114264488220215 | KNN Loss: 2.457731246948242 | CLS Loss: 0.05369516462087631\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 2.4802660942077637 | KNN Loss: 2.4364328384399414 | CLS Loss: 0.04383314773440361\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 2.473423480987549 | KNN Loss: 2.419814109802246 | CLS Loss: 0.053609319031238556\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 2.5095181465148926 | KNN Loss: 2.4344022274017334 | CLS Loss: 0.07511589676141739\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 2.492906093597412 | KNN Loss: 2.44810152053833 | CLS Loss: 0.04480447247624397\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 2.5179624557495117 | KNN Loss: 2.4032044410705566 | CLS Loss: 0.1147579774260521\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 2.4714009761810303 | KNN Loss: 2.4233736991882324 | CLS Loss: 0.04802727699279785\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 2.5216174125671387 | KNN Loss: 2.4547970294952393 | CLS Loss: 0.06682034581899643\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 2.5334765911102295 | KNN Loss: 2.4660708904266357 | CLS Loss: 0.06740572303533554\n",
      "Epoch: 015, Loss: 2.4934, Train: 0.9797, Valid: 0.9763, Best: 0.9803\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 2.5430989265441895 | KNN Loss: 2.4099607467651367 | CLS Loss: 0.13313820958137512\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 2.457714557647705 | KNN Loss: 2.388956308364868 | CLS Loss: 0.06875825673341751\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 2.4957141876220703 | KNN Loss: 2.4315803050994873 | CLS Loss: 0.06413393467664719\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 2.4847817420959473 | KNN Loss: 2.424788475036621 | CLS Loss: 0.05999337509274483\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 2.471275568008423 | KNN Loss: 2.38952374458313 | CLS Loss: 0.0817517414689064\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 2.4922802448272705 | KNN Loss: 2.4346694946289062 | CLS Loss: 0.05761072039604187\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 2.4833076000213623 | KNN Loss: 2.429042100906372 | CLS Loss: 0.05426561087369919\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 2.4682769775390625 | KNN Loss: 2.426403522491455 | CLS Loss: 0.041873395442962646\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 2.469566583633423 | KNN Loss: 2.4489834308624268 | CLS Loss: 0.020583050325512886\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 2.5265953540802 | KNN Loss: 2.460205078125 | CLS Loss: 0.066390261054039\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 2.5332283973693848 | KNN Loss: 2.4058420658111572 | CLS Loss: 0.12738624215126038\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 2.4742989540100098 | KNN Loss: 2.3942880630493164 | CLS Loss: 0.08001098781824112\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 2.49429988861084 | KNN Loss: 2.450934648513794 | CLS Loss: 0.04336529225111008\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 2.5018393993377686 | KNN Loss: 2.426260232925415 | CLS Loss: 0.07557907700538635\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 2.4817147254943848 | KNN Loss: 2.394207000732422 | CLS Loss: 0.08750762045383453\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 2.487790822982788 | KNN Loss: 2.4243946075439453 | CLS Loss: 0.0633961483836174\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 2.513267993927002 | KNN Loss: 2.4509971141815186 | CLS Loss: 0.062270909547805786\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 2.441608190536499 | KNN Loss: 2.3756754398345947 | CLS Loss: 0.06593284755945206\n",
      "Epoch: 016, Loss: 2.4877, Train: 0.9841, Valid: 0.9796, Best: 0.9803\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 2.464449644088745 | KNN Loss: 2.419185161590576 | CLS Loss: 0.04526445269584656\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 2.4428651332855225 | KNN Loss: 2.401578903198242 | CLS Loss: 0.04128631204366684\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 2.4688103199005127 | KNN Loss: 2.41298246383667 | CLS Loss: 0.05582794174551964\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 2.4864070415496826 | KNN Loss: 2.417497158050537 | CLS Loss: 0.06890987604856491\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 2.4889352321624756 | KNN Loss: 2.4248292446136475 | CLS Loss: 0.06410609185695648\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 2.4891645908355713 | KNN Loss: 2.4199564456939697 | CLS Loss: 0.06920816004276276\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 2.4865312576293945 | KNN Loss: 2.4246037006378174 | CLS Loss: 0.061927638947963715\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 2.5051896572113037 | KNN Loss: 2.4452900886535645 | CLS Loss: 0.05989949405193329\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 2.515855550765991 | KNN Loss: 2.464493989944458 | CLS Loss: 0.051361508667469025\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 2.494232654571533 | KNN Loss: 2.407119035720825 | CLS Loss: 0.08711367845535278\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 2.447650194168091 | KNN Loss: 2.3954851627349854 | CLS Loss: 0.05216492339968681\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 2.4675469398498535 | KNN Loss: 2.424518346786499 | CLS Loss: 0.04302860423922539\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 2.5235486030578613 | KNN Loss: 2.4575467109680176 | CLS Loss: 0.06600197404623032\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 2.4637796878814697 | KNN Loss: 2.3895931243896484 | CLS Loss: 0.07418646663427353\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 2.5015783309936523 | KNN Loss: 2.4620816707611084 | CLS Loss: 0.03949662297964096\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 2.482356309890747 | KNN Loss: 2.4179904460906982 | CLS Loss: 0.06436597555875778\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 2.4989583492279053 | KNN Loss: 2.4298558235168457 | CLS Loss: 0.06910254806280136\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 2.481452703475952 | KNN Loss: 2.4122140407562256 | CLS Loss: 0.06923871487379074\n",
      "Epoch: 017, Loss: 2.4851, Train: 0.9821, Valid: 0.9770, Best: 0.9803\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 2.483031988143921 | KNN Loss: 2.402377128601074 | CLS Loss: 0.08065488934516907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 2.4539005756378174 | KNN Loss: 2.4090795516967773 | CLS Loss: 0.04482097178697586\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 2.49318790435791 | KNN Loss: 2.4290058612823486 | CLS Loss: 0.06418205797672272\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 2.469351291656494 | KNN Loss: 2.4031410217285156 | CLS Loss: 0.06621021777391434\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 2.4979114532470703 | KNN Loss: 2.417506217956543 | CLS Loss: 0.0804053321480751\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 2.484232187271118 | KNN Loss: 2.4077649116516113 | CLS Loss: 0.07646722346544266\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 2.4698147773742676 | KNN Loss: 2.4296364784240723 | CLS Loss: 0.040178414434194565\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 2.477363348007202 | KNN Loss: 2.4143216609954834 | CLS Loss: 0.06304175406694412\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 2.446329116821289 | KNN Loss: 2.3898191452026367 | CLS Loss: 0.05651002749800682\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 2.457963466644287 | KNN Loss: 2.3896186351776123 | CLS Loss: 0.06834490597248077\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 2.5125861167907715 | KNN Loss: 2.440058708190918 | CLS Loss: 0.07252752780914307\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 2.4746313095092773 | KNN Loss: 2.392484664916992 | CLS Loss: 0.08214662969112396\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 2.503563404083252 | KNN Loss: 2.4230587482452393 | CLS Loss: 0.08050461858510971\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 2.4968807697296143 | KNN Loss: 2.397148609161377 | CLS Loss: 0.09973223507404327\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 2.4588615894317627 | KNN Loss: 2.398641347885132 | CLS Loss: 0.06022019311785698\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 2.4843528270721436 | KNN Loss: 2.4169106483459473 | CLS Loss: 0.06744207441806793\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 2.4856760501861572 | KNN Loss: 2.3971285820007324 | CLS Loss: 0.08854737877845764\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 2.506258726119995 | KNN Loss: 2.4420275688171387 | CLS Loss: 0.06423116475343704\n",
      "Epoch: 018, Loss: 2.4835, Train: 0.9828, Valid: 0.9789, Best: 0.9803\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 2.511528491973877 | KNN Loss: 2.438713550567627 | CLS Loss: 0.07281490415334702\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 2.4964070320129395 | KNN Loss: 2.4157514572143555 | CLS Loss: 0.08065568655729294\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 2.4445993900299072 | KNN Loss: 2.391903877258301 | CLS Loss: 0.0526956245303154\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 2.474574327468872 | KNN Loss: 2.4488906860351562 | CLS Loss: 0.02568364329636097\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 2.4648401737213135 | KNN Loss: 2.4256954193115234 | CLS Loss: 0.0391448512673378\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 2.50012469291687 | KNN Loss: 2.425118923187256 | CLS Loss: 0.07500568777322769\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 2.4772846698760986 | KNN Loss: 2.4476075172424316 | CLS Loss: 0.02967717871069908\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 2.4683103561401367 | KNN Loss: 2.3921055793762207 | CLS Loss: 0.07620465755462646\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 2.4693169593811035 | KNN Loss: 2.3760569095611572 | CLS Loss: 0.09326004236936569\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 2.470071315765381 | KNN Loss: 2.4188053607940674 | CLS Loss: 0.05126588046550751\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 2.4960556030273438 | KNN Loss: 2.4463319778442383 | CLS Loss: 0.04972357302904129\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 2.4354496002197266 | KNN Loss: 2.406802177429199 | CLS Loss: 0.028647389262914658\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 2.4404594898223877 | KNN Loss: 2.392503023147583 | CLS Loss: 0.04795649275183678\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 2.495636224746704 | KNN Loss: 2.4055562019348145 | CLS Loss: 0.09007992595434189\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 2.5149362087249756 | KNN Loss: 2.45177960395813 | CLS Loss: 0.06315653026103973\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 2.4716224670410156 | KNN Loss: 2.42024564743042 | CLS Loss: 0.051376886665821075\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 2.4542734622955322 | KNN Loss: 2.3995556831359863 | CLS Loss: 0.05471784994006157\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 2.5016562938690186 | KNN Loss: 2.4535183906555176 | CLS Loss: 0.04813797399401665\n",
      "Epoch: 019, Loss: 2.4753, Train: 0.9838, Valid: 0.9795, Best: 0.9803\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 2.4502336978912354 | KNN Loss: 2.4233875274658203 | CLS Loss: 0.026846151798963547\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 2.4627065658569336 | KNN Loss: 2.396101236343384 | CLS Loss: 0.06660524755716324\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 2.489102363586426 | KNN Loss: 2.4310050010681152 | CLS Loss: 0.05809725448489189\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 2.518848180770874 | KNN Loss: 2.398686408996582 | CLS Loss: 0.1201617643237114\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 2.5095479488372803 | KNN Loss: 2.412365436553955 | CLS Loss: 0.09718253463506699\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 2.465174913406372 | KNN Loss: 2.4180643558502197 | CLS Loss: 0.04711059853434563\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 2.446667194366455 | KNN Loss: 2.4022843837738037 | CLS Loss: 0.04438270255923271\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 2.4654386043548584 | KNN Loss: 2.390066385269165 | CLS Loss: 0.07537227869033813\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 2.4908230304718018 | KNN Loss: 2.438293218612671 | CLS Loss: 0.052529823035001755\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 2.4728634357452393 | KNN Loss: 2.4229183197021484 | CLS Loss: 0.049945224076509476\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 2.491770029067993 | KNN Loss: 2.4351933002471924 | CLS Loss: 0.056576699018478394\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 2.5079538822174072 | KNN Loss: 2.4716148376464844 | CLS Loss: 0.03633901849389076\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 2.4609451293945312 | KNN Loss: 2.416677236557007 | CLS Loss: 0.04426787421107292\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 2.4735546112060547 | KNN Loss: 2.4199297428131104 | CLS Loss: 0.053624823689460754\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 2.481473445892334 | KNN Loss: 2.450320243835449 | CLS Loss: 0.031153198331594467\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 2.48215651512146 | KNN Loss: 2.423290967941284 | CLS Loss: 0.058865439146757126\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 2.4773612022399902 | KNN Loss: 2.4442453384399414 | CLS Loss: 0.03311584144830704\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 2.4557602405548096 | KNN Loss: 2.438157796859741 | CLS Loss: 0.017602531239390373\n",
      "Epoch: 020, Loss: 2.4754, Train: 0.9862, Valid: 0.9818, Best: 0.9818\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 2.477447986602783 | KNN Loss: 2.4177300930023193 | CLS Loss: 0.059717852622270584\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 2.46407151222229 | KNN Loss: 2.3931894302368164 | CLS Loss: 0.07088202238082886\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 2.5107898712158203 | KNN Loss: 2.446037769317627 | CLS Loss: 0.0647520199418068\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 2.5006489753723145 | KNN Loss: 2.432830572128296 | CLS Loss: 0.06781840324401855\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 2.493978261947632 | KNN Loss: 2.442517042160034 | CLS Loss: 0.05146132409572601\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 2.4475784301757812 | KNN Loss: 2.389615297317505 | CLS Loss: 0.05796302855014801\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 2.49888014793396 | KNN Loss: 2.454474925994873 | CLS Loss: 0.044405169785022736\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 2.501976251602173 | KNN Loss: 2.4296793937683105 | CLS Loss: 0.07229688763618469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 2.460493564605713 | KNN Loss: 2.4292216300964355 | CLS Loss: 0.0312720388174057\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 2.4652044773101807 | KNN Loss: 2.40796160697937 | CLS Loss: 0.05724276602268219\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 2.481473445892334 | KNN Loss: 2.4282922744750977 | CLS Loss: 0.053181279450654984\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 2.482329845428467 | KNN Loss: 2.4284374713897705 | CLS Loss: 0.05389241501688957\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 2.483583927154541 | KNN Loss: 2.4493372440338135 | CLS Loss: 0.03424671292304993\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 2.5140562057495117 | KNN Loss: 2.4761171340942383 | CLS Loss: 0.03793904557824135\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 2.4397835731506348 | KNN Loss: 2.4003894329071045 | CLS Loss: 0.0393940731883049\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 2.4839394092559814 | KNN Loss: 2.442272663116455 | CLS Loss: 0.04166685789823532\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 2.454256296157837 | KNN Loss: 2.3928050994873047 | CLS Loss: 0.06145123764872551\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 2.5196664333343506 | KNN Loss: 2.4248154163360596 | CLS Loss: 0.0948510393500328\n",
      "Epoch: 021, Loss: 2.4741, Train: 0.9847, Valid: 0.9800, Best: 0.9818\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 2.5070416927337646 | KNN Loss: 2.4091105461120605 | CLS Loss: 0.0979311466217041\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 2.4825026988983154 | KNN Loss: 2.40409255027771 | CLS Loss: 0.07841024547815323\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 2.4763553142547607 | KNN Loss: 2.4356155395507812 | CLS Loss: 0.04073970392346382\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 2.45055890083313 | KNN Loss: 2.389566659927368 | CLS Loss: 0.0609922930598259\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 2.45025372505188 | KNN Loss: 2.4165749549865723 | CLS Loss: 0.03367873653769493\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 2.471377372741699 | KNN Loss: 2.395474672317505 | CLS Loss: 0.07590259611606598\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 2.453124761581421 | KNN Loss: 2.4206812381744385 | CLS Loss: 0.03244355693459511\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 2.439304828643799 | KNN Loss: 2.3903684616088867 | CLS Loss: 0.0489363931119442\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 2.4502856731414795 | KNN Loss: 2.3983752727508545 | CLS Loss: 0.05191047489643097\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 2.4370803833007812 | KNN Loss: 2.41310977935791 | CLS Loss: 0.02397063560783863\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 2.4405758380889893 | KNN Loss: 2.3888869285583496 | CLS Loss: 0.05168884992599487\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 2.4816224575042725 | KNN Loss: 2.384122371673584 | CLS Loss: 0.09750000387430191\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 2.5253171920776367 | KNN Loss: 2.458477735519409 | CLS Loss: 0.06683941185474396\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 2.4974353313446045 | KNN Loss: 2.441387176513672 | CLS Loss: 0.05604805797338486\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 2.5285427570343018 | KNN Loss: 2.4534497261047363 | CLS Loss: 0.07509295642375946\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 2.46164608001709 | KNN Loss: 2.3957653045654297 | CLS Loss: 0.06588084250688553\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 2.445314407348633 | KNN Loss: 2.4094228744506836 | CLS Loss: 0.035891544073820114\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 2.4422407150268555 | KNN Loss: 2.4022037982940674 | CLS Loss: 0.040036991238594055\n",
      "Epoch: 022, Loss: 2.4724, Train: 0.9844, Valid: 0.9800, Best: 0.9818\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 2.4751694202423096 | KNN Loss: 2.4146571159362793 | CLS Loss: 0.06051240116357803\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 2.4947075843811035 | KNN Loss: 2.4096765518188477 | CLS Loss: 0.0850309431552887\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 2.447913408279419 | KNN Loss: 2.4161903858184814 | CLS Loss: 0.031723055988550186\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 2.5001678466796875 | KNN Loss: 2.423537254333496 | CLS Loss: 0.07663069665431976\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 2.468855619430542 | KNN Loss: 2.4357686042785645 | CLS Loss: 0.033086977899074554\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 2.4759795665740967 | KNN Loss: 2.4159257411956787 | CLS Loss: 0.060053907334804535\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 2.4660260677337646 | KNN Loss: 2.4232139587402344 | CLS Loss: 0.04281208664178848\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 2.5101397037506104 | KNN Loss: 2.442863702774048 | CLS Loss: 0.06727593392133713\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 2.457552909851074 | KNN Loss: 2.383638381958008 | CLS Loss: 0.07391440868377686\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 2.4350972175598145 | KNN Loss: 2.3938751220703125 | CLS Loss: 0.04122214764356613\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 2.4960811138153076 | KNN Loss: 2.4605422019958496 | CLS Loss: 0.03553896024823189\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 2.504006862640381 | KNN Loss: 2.4537203311920166 | CLS Loss: 0.05028657242655754\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 2.4905147552490234 | KNN Loss: 2.4000346660614014 | CLS Loss: 0.09048012644052505\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 2.435804605484009 | KNN Loss: 2.4004855155944824 | CLS Loss: 0.035319000482559204\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 2.472074031829834 | KNN Loss: 2.435776710510254 | CLS Loss: 0.036297328770160675\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 2.502756118774414 | KNN Loss: 2.436584949493408 | CLS Loss: 0.0661710798740387\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 2.4468905925750732 | KNN Loss: 2.3964831829071045 | CLS Loss: 0.050407297909259796\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 2.479774236679077 | KNN Loss: 2.4291574954986572 | CLS Loss: 0.050616730004549026\n",
      "Epoch: 023, Loss: 2.4691, Train: 0.9856, Valid: 0.9820, Best: 0.9820\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 2.443222761154175 | KNN Loss: 2.424696207046509 | CLS Loss: 0.018526466563344002\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 2.4412710666656494 | KNN Loss: 2.399587631225586 | CLS Loss: 0.04168354347348213\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 2.4534356594085693 | KNN Loss: 2.402865171432495 | CLS Loss: 0.05057040974497795\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 2.4409677982330322 | KNN Loss: 2.4024438858032227 | CLS Loss: 0.03852381557226181\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 2.469940185546875 | KNN Loss: 2.412989377975464 | CLS Loss: 0.056950829923152924\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 2.495483875274658 | KNN Loss: 2.431431293487549 | CLS Loss: 0.06405255198478699\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 2.4744455814361572 | KNN Loss: 2.427077054977417 | CLS Loss: 0.04736851528286934\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 2.4760916233062744 | KNN Loss: 2.440365791320801 | CLS Loss: 0.03572582080960274\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 2.4648382663726807 | KNN Loss: 2.4163897037506104 | CLS Loss: 0.048448652029037476\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 2.4494264125823975 | KNN Loss: 2.4190685749053955 | CLS Loss: 0.030357928946614265\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 2.4837095737457275 | KNN Loss: 2.429354190826416 | CLS Loss: 0.05435546487569809\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 2.4570205211639404 | KNN Loss: 2.4038748741149902 | CLS Loss: 0.053145550191402435\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 2.4875540733337402 | KNN Loss: 2.422117233276367 | CLS Loss: 0.06543678790330887\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 2.4339213371276855 | KNN Loss: 2.400320053100586 | CLS Loss: 0.03360123187303543\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 2.528235673904419 | KNN Loss: 2.4551591873168945 | CLS Loss: 0.07307647913694382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 2.4883062839508057 | KNN Loss: 2.4558558464050293 | CLS Loss: 0.03245038911700249\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 2.4675092697143555 | KNN Loss: 2.445359230041504 | CLS Loss: 0.022149983793497086\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 2.449309825897217 | KNN Loss: 2.4265058040618896 | CLS Loss: 0.02280394360423088\n",
      "Epoch: 024, Loss: 2.4654, Train: 0.9890, Valid: 0.9832, Best: 0.9832\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 2.475696086883545 | KNN Loss: 2.415036916732788 | CLS Loss: 0.06065918877720833\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 2.46584415435791 | KNN Loss: 2.416666269302368 | CLS Loss: 0.049177780747413635\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 2.4355766773223877 | KNN Loss: 2.3894009590148926 | CLS Loss: 0.04617573693394661\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 2.4771034717559814 | KNN Loss: 2.4271039962768555 | CLS Loss: 0.04999959096312523\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 2.4546523094177246 | KNN Loss: 2.425076484680176 | CLS Loss: 0.029575899243354797\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 2.4701902866363525 | KNN Loss: 2.412776231765747 | CLS Loss: 0.05741405114531517\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 2.4387996196746826 | KNN Loss: 2.4111733436584473 | CLS Loss: 0.02762630023062229\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 2.4631247520446777 | KNN Loss: 2.3962671756744385 | CLS Loss: 0.06685745716094971\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 2.4361181259155273 | KNN Loss: 2.3910443782806396 | CLS Loss: 0.04507376626133919\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 2.4847800731658936 | KNN Loss: 2.4272022247314453 | CLS Loss: 0.05757778137922287\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 2.4533843994140625 | KNN Loss: 2.41556453704834 | CLS Loss: 0.037819940596818924\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 2.450747013092041 | KNN Loss: 2.4080259799957275 | CLS Loss: 0.04272112622857094\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 2.49066162109375 | KNN Loss: 2.414743661880493 | CLS Loss: 0.07591799646615982\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 2.4778289794921875 | KNN Loss: 2.395487070083618 | CLS Loss: 0.08234197646379471\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 2.4187045097351074 | KNN Loss: 2.3824803829193115 | CLS Loss: 0.036224108189344406\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 2.4306447505950928 | KNN Loss: 2.3895182609558105 | CLS Loss: 0.0411265566945076\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 2.4788050651550293 | KNN Loss: 2.4602746963500977 | CLS Loss: 0.01853039860725403\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 2.445436716079712 | KNN Loss: 2.414367198944092 | CLS Loss: 0.03106963075697422\n",
      "Epoch: 025, Loss: 2.4629, Train: 0.9879, Valid: 0.9836, Best: 0.9836\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 2.439211845397949 | KNN Loss: 2.405425786972046 | CLS Loss: 0.033785950392484665\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 2.457892894744873 | KNN Loss: 2.386050224304199 | CLS Loss: 0.07184261828660965\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 2.4533684253692627 | KNN Loss: 2.375232219696045 | CLS Loss: 0.07813622802495956\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 2.4845378398895264 | KNN Loss: 2.420919895172119 | CLS Loss: 0.06361792981624603\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 2.4721789360046387 | KNN Loss: 2.4375150203704834 | CLS Loss: 0.03466399386525154\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 2.435042142868042 | KNN Loss: 2.4039418697357178 | CLS Loss: 0.0311003178358078\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 2.4824013710021973 | KNN Loss: 2.416961193084717 | CLS Loss: 0.06544016301631927\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 2.4580984115600586 | KNN Loss: 2.4118192195892334 | CLS Loss: 0.046279177069664\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 2.484894275665283 | KNN Loss: 2.4302563667297363 | CLS Loss: 0.05463779345154762\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 2.4099228382110596 | KNN Loss: 2.3920931816101074 | CLS Loss: 0.01782977394759655\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 2.4694459438323975 | KNN Loss: 2.4173929691314697 | CLS Loss: 0.052053045481443405\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 2.4663572311401367 | KNN Loss: 2.4082770347595215 | CLS Loss: 0.058080144226551056\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 2.4709057807922363 | KNN Loss: 2.426407814025879 | CLS Loss: 0.04449796304106712\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 2.4730494022369385 | KNN Loss: 2.4053597450256348 | CLS Loss: 0.06768957525491714\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 2.408676862716675 | KNN Loss: 2.367835521697998 | CLS Loss: 0.04084125906229019\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 2.4346559047698975 | KNN Loss: 2.4175643920898438 | CLS Loss: 0.017091495916247368\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 2.479016065597534 | KNN Loss: 2.4363174438476562 | CLS Loss: 0.04269866645336151\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 2.4602062702178955 | KNN Loss: 2.4250218868255615 | CLS Loss: 0.03518427908420563\n",
      "Epoch: 026, Loss: 2.4605, Train: 0.9866, Valid: 0.9811, Best: 0.9836\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 2.4634757041931152 | KNN Loss: 2.410454511642456 | CLS Loss: 0.05302117019891739\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 2.4340262413024902 | KNN Loss: 2.401639699935913 | CLS Loss: 0.032386548817157745\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 2.4422295093536377 | KNN Loss: 2.416680335998535 | CLS Loss: 0.02554910257458687\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 2.4545884132385254 | KNN Loss: 2.4126482009887695 | CLS Loss: 0.04194021597504616\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 2.4761741161346436 | KNN Loss: 2.425617218017578 | CLS Loss: 0.050556909292936325\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 2.4949355125427246 | KNN Loss: 2.4087274074554443 | CLS Loss: 0.08620810508728027\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 2.4312028884887695 | KNN Loss: 2.407289505004883 | CLS Loss: 0.02391345053911209\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 2.4346115589141846 | KNN Loss: 2.3976757526397705 | CLS Loss: 0.036935728043317795\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 2.4753763675689697 | KNN Loss: 2.419236421585083 | CLS Loss: 0.056139856576919556\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 2.4796953201293945 | KNN Loss: 2.4149258136749268 | CLS Loss: 0.06476953625679016\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 2.412816286087036 | KNN Loss: 2.3534812927246094 | CLS Loss: 0.059334926307201385\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 2.4866042137145996 | KNN Loss: 2.4273769855499268 | CLS Loss: 0.05922723561525345\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 2.4762206077575684 | KNN Loss: 2.4247140884399414 | CLS Loss: 0.05150660499930382\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 2.4272115230560303 | KNN Loss: 2.403691530227661 | CLS Loss: 0.023520058020949364\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 2.4395647048950195 | KNN Loss: 2.4068477153778076 | CLS Loss: 0.03271697834134102\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 2.4623095989227295 | KNN Loss: 2.372959613800049 | CLS Loss: 0.08935007452964783\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 2.5108530521392822 | KNN Loss: 2.4579575061798096 | CLS Loss: 0.052895478904247284\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 2.4469668865203857 | KNN Loss: 2.409763813018799 | CLS Loss: 0.03720295801758766\n",
      "Epoch: 027, Loss: 2.4628, Train: 0.9880, Valid: 0.9821, Best: 0.9836\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 2.4892325401306152 | KNN Loss: 2.4324681758880615 | CLS Loss: 0.0567643940448761\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 2.4710328578948975 | KNN Loss: 2.438331365585327 | CLS Loss: 0.032701391726732254\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 2.448246955871582 | KNN Loss: 2.3956105709075928 | CLS Loss: 0.05263635143637657\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 2.4627106189727783 | KNN Loss: 2.4328737258911133 | CLS Loss: 0.029836788773536682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 2.4825997352600098 | KNN Loss: 2.4116973876953125 | CLS Loss: 0.07090230286121368\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 2.4778966903686523 | KNN Loss: 2.411468029022217 | CLS Loss: 0.06642865389585495\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 2.41678786277771 | KNN Loss: 2.3814404010772705 | CLS Loss: 0.03534757345914841\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 2.4440457820892334 | KNN Loss: 2.3942651748657227 | CLS Loss: 0.04978051781654358\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 2.4999334812164307 | KNN Loss: 2.444127082824707 | CLS Loss: 0.0558064840734005\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 2.4510903358459473 | KNN Loss: 2.3916826248168945 | CLS Loss: 0.05940760299563408\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 2.4633383750915527 | KNN Loss: 2.41359543800354 | CLS Loss: 0.04974288493394852\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 2.42134165763855 | KNN Loss: 2.3941898345947266 | CLS Loss: 0.027151785790920258\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 2.4368600845336914 | KNN Loss: 2.375802755355835 | CLS Loss: 0.06105722114443779\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 2.47637939453125 | KNN Loss: 2.3840572834014893 | CLS Loss: 0.0923222154378891\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 2.4200215339660645 | KNN Loss: 2.3597021102905273 | CLS Loss: 0.06031952425837517\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 2.489159345626831 | KNN Loss: 2.439392328262329 | CLS Loss: 0.049767088145017624\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 2.446284294128418 | KNN Loss: 2.4204232692718506 | CLS Loss: 0.025861134752631187\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 2.487520217895508 | KNN Loss: 2.44075870513916 | CLS Loss: 0.04676147922873497\n",
      "Epoch: 028, Loss: 2.4613, Train: 0.9881, Valid: 0.9829, Best: 0.9836\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 2.504190444946289 | KNN Loss: 2.4591636657714844 | CLS Loss: 0.045026782900094986\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 2.4877917766571045 | KNN Loss: 2.421597480773926 | CLS Loss: 0.06619437038898468\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 2.448413848876953 | KNN Loss: 2.3875198364257812 | CLS Loss: 0.06089412420988083\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 2.4222936630249023 | KNN Loss: 2.37776780128479 | CLS Loss: 0.044525790959596634\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 2.459152936935425 | KNN Loss: 2.4317708015441895 | CLS Loss: 0.02738219127058983\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 2.464177131652832 | KNN Loss: 2.4453237056732178 | CLS Loss: 0.01885349117219448\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 2.4420993328094482 | KNN Loss: 2.4262290000915527 | CLS Loss: 0.01587025821208954\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 2.4799773693084717 | KNN Loss: 2.44085693359375 | CLS Loss: 0.03912033885717392\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 2.4445245265960693 | KNN Loss: 2.410991907119751 | CLS Loss: 0.03353269770741463\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 2.4519550800323486 | KNN Loss: 2.383106231689453 | CLS Loss: 0.06884875148534775\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 2.433304786682129 | KNN Loss: 2.3923957347869873 | CLS Loss: 0.0409090481698513\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 2.4589881896972656 | KNN Loss: 2.4290735721588135 | CLS Loss: 0.029914703220129013\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 2.4812841415405273 | KNN Loss: 2.422011375427246 | CLS Loss: 0.05927273631095886\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 2.4757602214813232 | KNN Loss: 2.399646282196045 | CLS Loss: 0.07611384987831116\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 2.4443328380584717 | KNN Loss: 2.4251222610473633 | CLS Loss: 0.019210567697882652\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 2.4485671520233154 | KNN Loss: 2.407602310180664 | CLS Loss: 0.04096478223800659\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 2.4806294441223145 | KNN Loss: 2.4182748794555664 | CLS Loss: 0.062354475259780884\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 2.432620048522949 | KNN Loss: 2.4024298191070557 | CLS Loss: 0.030190126970410347\n",
      "Epoch: 029, Loss: 2.4580, Train: 0.9889, Valid: 0.9841, Best: 0.9841\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 2.4255764484405518 | KNN Loss: 2.406144380569458 | CLS Loss: 0.01943216472864151\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 2.462019681930542 | KNN Loss: 2.4289703369140625 | CLS Loss: 0.033049363642930984\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 2.4755008220672607 | KNN Loss: 2.4218227863311768 | CLS Loss: 0.05367808789014816\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 2.453258991241455 | KNN Loss: 2.4146854877471924 | CLS Loss: 0.03857354447245598\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 2.4759764671325684 | KNN Loss: 2.4077305793762207 | CLS Loss: 0.0682457685470581\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 2.5177907943725586 | KNN Loss: 2.4727203845977783 | CLS Loss: 0.04507029429078102\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 2.4834847450256348 | KNN Loss: 2.4213123321533203 | CLS Loss: 0.06217237934470177\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 2.463186264038086 | KNN Loss: 2.4159679412841797 | CLS Loss: 0.04721841588616371\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 2.4677140712738037 | KNN Loss: 2.4187259674072266 | CLS Loss: 0.048988211899995804\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 2.4532387256622314 | KNN Loss: 2.395411491394043 | CLS Loss: 0.05782712623476982\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 2.4409825801849365 | KNN Loss: 2.389592170715332 | CLS Loss: 0.05139036476612091\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 2.4568512439727783 | KNN Loss: 2.4160895347595215 | CLS Loss: 0.04076159745454788\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 2.4554128646850586 | KNN Loss: 2.4154789447784424 | CLS Loss: 0.039933960884809494\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 2.4285004138946533 | KNN Loss: 2.378492593765259 | CLS Loss: 0.050007857382297516\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 2.4933128356933594 | KNN Loss: 2.4521923065185547 | CLS Loss: 0.04112042114138603\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 2.436365842819214 | KNN Loss: 2.405393123626709 | CLS Loss: 0.03097277320921421\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 2.4447414875030518 | KNN Loss: 2.4078776836395264 | CLS Loss: 0.03686368837952614\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 2.457237482070923 | KNN Loss: 2.4166500568389893 | CLS Loss: 0.04058745875954628\n",
      "Epoch: 030, Loss: 2.4548, Train: 0.9901, Valid: 0.9845, Best: 0.9845\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 2.4573683738708496 | KNN Loss: 2.389322280883789 | CLS Loss: 0.06804610043764114\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 2.4619619846343994 | KNN Loss: 2.3976545333862305 | CLS Loss: 0.06430745124816895\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 2.4706287384033203 | KNN Loss: 2.422001600265503 | CLS Loss: 0.04862701892852783\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 2.4759042263031006 | KNN Loss: 2.4574084281921387 | CLS Loss: 0.018495699390769005\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 2.462844133377075 | KNN Loss: 2.4117114543914795 | CLS Loss: 0.0511326901614666\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 2.4910502433776855 | KNN Loss: 2.4420974254608154 | CLS Loss: 0.04895288497209549\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 2.527364730834961 | KNN Loss: 2.4096388816833496 | CLS Loss: 0.11772585660219193\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 2.458390474319458 | KNN Loss: 2.418855667114258 | CLS Loss: 0.03953489288687706\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 2.461226224899292 | KNN Loss: 2.4413959980010986 | CLS Loss: 0.019830135628581047\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 2.4538321495056152 | KNN Loss: 2.4000566005706787 | CLS Loss: 0.053775668144226074\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 2.460681915283203 | KNN Loss: 2.399501085281372 | CLS Loss: 0.061180803924798965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 2.4818503856658936 | KNN Loss: 2.434185266494751 | CLS Loss: 0.04766512289643288\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 2.4273600578308105 | KNN Loss: 2.3936688899993896 | CLS Loss: 0.033691149204969406\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 2.489271402359009 | KNN Loss: 2.447596549987793 | CLS Loss: 0.04167487099766731\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 2.460070848464966 | KNN Loss: 2.4281094074249268 | CLS Loss: 0.03196144476532936\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 2.418210506439209 | KNN Loss: 2.3808417320251465 | CLS Loss: 0.037368666380643845\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 2.445751190185547 | KNN Loss: 2.411686658859253 | CLS Loss: 0.03406447917222977\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 2.4296584129333496 | KNN Loss: 2.4023871421813965 | CLS Loss: 0.027271229773759842\n",
      "Epoch: 031, Loss: 2.4526, Train: 0.9907, Valid: 0.9839, Best: 0.9845\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 2.4263339042663574 | KNN Loss: 2.3937859535217285 | CLS Loss: 0.03254794329404831\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 2.4615800380706787 | KNN Loss: 2.4115288257598877 | CLS Loss: 0.050051234662532806\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 2.4514527320861816 | KNN Loss: 2.4020426273345947 | CLS Loss: 0.04941018670797348\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 2.422701597213745 | KNN Loss: 2.3748788833618164 | CLS Loss: 0.04782275855541229\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 2.4458985328674316 | KNN Loss: 2.368347644805908 | CLS Loss: 0.07755085825920105\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 2.4911344051361084 | KNN Loss: 2.420091152191162 | CLS Loss: 0.0710432380437851\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 2.433472156524658 | KNN Loss: 2.402705669403076 | CLS Loss: 0.030766597017645836\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 2.4556467533111572 | KNN Loss: 2.4210286140441895 | CLS Loss: 0.03461809456348419\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 2.443236827850342 | KNN Loss: 2.405432939529419 | CLS Loss: 0.037803955376148224\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 2.444183111190796 | KNN Loss: 2.423522710800171 | CLS Loss: 0.020660310983657837\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 2.5017547607421875 | KNN Loss: 2.4227294921875 | CLS Loss: 0.07902535796165466\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 2.492116928100586 | KNN Loss: 2.4227893352508545 | CLS Loss: 0.06932752579450607\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 2.455434799194336 | KNN Loss: 2.4142634868621826 | CLS Loss: 0.04117124155163765\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 2.4276881217956543 | KNN Loss: 2.3963284492492676 | CLS Loss: 0.031359583139419556\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 2.4577362537384033 | KNN Loss: 2.394700288772583 | CLS Loss: 0.06303602457046509\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 2.439547061920166 | KNN Loss: 2.397202491760254 | CLS Loss: 0.042344480752944946\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 2.5057597160339355 | KNN Loss: 2.47369122505188 | CLS Loss: 0.03206854686141014\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 2.4592795372009277 | KNN Loss: 2.4208333492279053 | CLS Loss: 0.03844607248902321\n",
      "Epoch: 032, Loss: 2.4600, Train: 0.9881, Valid: 0.9816, Best: 0.9845\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 2.4455409049987793 | KNN Loss: 2.391160249710083 | CLS Loss: 0.05438073351979256\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 2.4599153995513916 | KNN Loss: 2.4170234203338623 | CLS Loss: 0.04289192333817482\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 2.4946305751800537 | KNN Loss: 2.401829957962036 | CLS Loss: 0.09280069917440414\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 2.4469635486602783 | KNN Loss: 2.392733573913574 | CLS Loss: 0.05423000454902649\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 2.4105076789855957 | KNN Loss: 2.374708652496338 | CLS Loss: 0.035799141973257065\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 2.439716339111328 | KNN Loss: 2.411682605743408 | CLS Loss: 0.028033822774887085\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 2.4097554683685303 | KNN Loss: 2.392310619354248 | CLS Loss: 0.01744481362402439\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 2.4546256065368652 | KNN Loss: 2.406707286834717 | CLS Loss: 0.04791821166872978\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 2.4718825817108154 | KNN Loss: 2.4300596714019775 | CLS Loss: 0.04182285815477371\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 2.4697859287261963 | KNN Loss: 2.42199969291687 | CLS Loss: 0.04778626561164856\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 2.4526631832122803 | KNN Loss: 2.413890838623047 | CLS Loss: 0.03877236321568489\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 2.458961009979248 | KNN Loss: 2.423959970474243 | CLS Loss: 0.03500095009803772\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 2.431947708129883 | KNN Loss: 2.396751880645752 | CLS Loss: 0.03519578278064728\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 2.4519565105438232 | KNN Loss: 2.4209136962890625 | CLS Loss: 0.031042782589793205\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 2.4527814388275146 | KNN Loss: 2.4198055267333984 | CLS Loss: 0.032975804060697556\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 2.451019048690796 | KNN Loss: 2.415738582611084 | CLS Loss: 0.035280514508485794\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 2.4288673400878906 | KNN Loss: 2.356388807296753 | CLS Loss: 0.0724785327911377\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 2.4791665077209473 | KNN Loss: 2.4545037746429443 | CLS Loss: 0.024662667885422707\n",
      "Epoch: 033, Loss: 2.4543, Train: 0.9897, Valid: 0.9837, Best: 0.9845\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 2.4378082752227783 | KNN Loss: 2.3856184482574463 | CLS Loss: 0.052189718931913376\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 2.444410562515259 | KNN Loss: 2.399088144302368 | CLS Loss: 0.045322395861148834\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 2.4899556636810303 | KNN Loss: 2.419956922531128 | CLS Loss: 0.06999880820512772\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 2.4228296279907227 | KNN Loss: 2.4021244049072266 | CLS Loss: 0.020705224946141243\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 2.4120187759399414 | KNN Loss: 2.3914520740509033 | CLS Loss: 0.020566748455166817\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 2.475973129272461 | KNN Loss: 2.431802749633789 | CLS Loss: 0.04417043924331665\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 2.4671075344085693 | KNN Loss: 2.4428374767303467 | CLS Loss: 0.024270091205835342\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 2.4514522552490234 | KNN Loss: 2.419853687286377 | CLS Loss: 0.03159865364432335\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 2.4900054931640625 | KNN Loss: 2.443427324295044 | CLS Loss: 0.04657809063792229\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 2.4632694721221924 | KNN Loss: 2.4248769283294678 | CLS Loss: 0.03839258477091789\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 2.406409502029419 | KNN Loss: 2.3749806880950928 | CLS Loss: 0.03142884373664856\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 2.4290757179260254 | KNN Loss: 2.3887181282043457 | CLS Loss: 0.040357522666454315\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 2.469468355178833 | KNN Loss: 2.4419798851013184 | CLS Loss: 0.02748856693506241\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 2.4562923908233643 | KNN Loss: 2.4202651977539062 | CLS Loss: 0.03602723032236099\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 2.429142475128174 | KNN Loss: 2.409034252166748 | CLS Loss: 0.020108265802264214\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 2.4682934284210205 | KNN Loss: 2.414393186569214 | CLS Loss: 0.05390028655529022\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 2.4075911045074463 | KNN Loss: 2.385864496231079 | CLS Loss: 0.02172665484249592\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 2.40626859664917 | KNN Loss: 2.369283676147461 | CLS Loss: 0.03698490187525749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 2.4532, Train: 0.9897, Valid: 0.9841, Best: 0.9845\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 2.517206907272339 | KNN Loss: 2.4651033878326416 | CLS Loss: 0.05210347846150398\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 2.483157157897949 | KNN Loss: 2.4534711837768555 | CLS Loss: 0.029685938730835915\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 2.4959094524383545 | KNN Loss: 2.4635841846466064 | CLS Loss: 0.03232528641819954\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 2.441018581390381 | KNN Loss: 2.3870441913604736 | CLS Loss: 0.05397440120577812\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 2.457491636276245 | KNN Loss: 2.4232401847839355 | CLS Loss: 0.03425145149230957\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 2.4416353702545166 | KNN Loss: 2.381139039993286 | CLS Loss: 0.06049637123942375\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 2.4496896266937256 | KNN Loss: 2.4001247882843018 | CLS Loss: 0.04956480860710144\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 2.4319374561309814 | KNN Loss: 2.4054362773895264 | CLS Loss: 0.026501091197133064\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 2.4566516876220703 | KNN Loss: 2.4162111282348633 | CLS Loss: 0.040440648794174194\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 2.460752487182617 | KNN Loss: 2.4316203594207764 | CLS Loss: 0.02913202904164791\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 2.464778184890747 | KNN Loss: 2.435619592666626 | CLS Loss: 0.02915852703154087\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 2.439836263656616 | KNN Loss: 2.4191224575042725 | CLS Loss: 0.020713811740279198\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 2.4828267097473145 | KNN Loss: 2.447047710418701 | CLS Loss: 0.0357789620757103\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 2.4691109657287598 | KNN Loss: 2.3913087844848633 | CLS Loss: 0.07780223339796066\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 2.454378366470337 | KNN Loss: 2.412505626678467 | CLS Loss: 0.041872717440128326\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 2.447786569595337 | KNN Loss: 2.4185564517974854 | CLS Loss: 0.029230086132884026\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 2.4733502864837646 | KNN Loss: 2.426480531692505 | CLS Loss: 0.0468696653842926\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 2.446685791015625 | KNN Loss: 2.396026372909546 | CLS Loss: 0.05065935105085373\n",
      "Epoch: 035, Loss: 2.4496, Train: 0.9901, Valid: 0.9835, Best: 0.9845\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 2.457960367202759 | KNN Loss: 2.4036147594451904 | CLS Loss: 0.054345495998859406\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 2.434138536453247 | KNN Loss: 2.413787841796875 | CLS Loss: 0.020350633189082146\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 2.4383065700531006 | KNN Loss: 2.385582208633423 | CLS Loss: 0.05272435024380684\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 2.421861410140991 | KNN Loss: 2.397151470184326 | CLS Loss: 0.024709906429052353\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 2.417111396789551 | KNN Loss: 2.37760329246521 | CLS Loss: 0.0395081490278244\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 2.444148302078247 | KNN Loss: 2.4092626571655273 | CLS Loss: 0.03488574177026749\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 2.425868511199951 | KNN Loss: 2.40195631980896 | CLS Loss: 0.023912077769637108\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 2.437047243118286 | KNN Loss: 2.4228250980377197 | CLS Loss: 0.014222164638340473\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 2.4391138553619385 | KNN Loss: 2.3951215744018555 | CLS Loss: 0.04399239271879196\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 2.4288554191589355 | KNN Loss: 2.3868050575256348 | CLS Loss: 0.04205041751265526\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 2.472088575363159 | KNN Loss: 2.428011655807495 | CLS Loss: 0.04407688230276108\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 2.4649651050567627 | KNN Loss: 2.42029070854187 | CLS Loss: 0.044674310833215714\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 2.4094109535217285 | KNN Loss: 2.3687479496002197 | CLS Loss: 0.04066310450434685\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 2.426912546157837 | KNN Loss: 2.371818780899048 | CLS Loss: 0.0550936684012413\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 2.4904494285583496 | KNN Loss: 2.396913766860962 | CLS Loss: 0.09353569149971008\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 2.418358325958252 | KNN Loss: 2.368119955062866 | CLS Loss: 0.050238415598869324\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 2.411151170730591 | KNN Loss: 2.3760900497436523 | CLS Loss: 0.035061076283454895\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 2.4905059337615967 | KNN Loss: 2.4366910457611084 | CLS Loss: 0.053815003484487534\n",
      "Epoch: 036, Loss: 2.4462, Train: 0.9897, Valid: 0.9838, Best: 0.9845\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 2.4492828845977783 | KNN Loss: 2.3871676921844482 | CLS Loss: 0.06211530789732933\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 2.4767465591430664 | KNN Loss: 2.431450605392456 | CLS Loss: 0.045296039432287216\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 2.4738364219665527 | KNN Loss: 2.411513328552246 | CLS Loss: 0.06232311204075813\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 2.456183671951294 | KNN Loss: 2.4046292304992676 | CLS Loss: 0.051554493606090546\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 2.456873893737793 | KNN Loss: 2.4376847743988037 | CLS Loss: 0.01918919011950493\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 2.4266490936279297 | KNN Loss: 2.401482343673706 | CLS Loss: 0.025166837498545647\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 2.488720417022705 | KNN Loss: 2.445816993713379 | CLS Loss: 0.04290349781513214\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 2.4497580528259277 | KNN Loss: 2.4346413612365723 | CLS Loss: 0.01511659286916256\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 2.4133615493774414 | KNN Loss: 2.3875365257263184 | CLS Loss: 0.025825124233961105\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 2.437561511993408 | KNN Loss: 2.3892016410827637 | CLS Loss: 0.0483599491417408\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 2.4470744132995605 | KNN Loss: 2.426543712615967 | CLS Loss: 0.020530592650175095\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 2.4461755752563477 | KNN Loss: 2.4138638973236084 | CLS Loss: 0.03231159597635269\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 2.423994541168213 | KNN Loss: 2.3886399269104004 | CLS Loss: 0.03535457327961922\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 2.411756992340088 | KNN Loss: 2.378596305847168 | CLS Loss: 0.03316066041588783\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 2.4578983783721924 | KNN Loss: 2.4297664165496826 | CLS Loss: 0.028131887316703796\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 2.4722321033477783 | KNN Loss: 2.437270402908325 | CLS Loss: 0.03496168553829193\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 2.421243190765381 | KNN Loss: 2.3888561725616455 | CLS Loss: 0.032387059181928635\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 2.472698926925659 | KNN Loss: 2.424166202545166 | CLS Loss: 0.048532817512750626\n",
      "Epoch: 037, Loss: 2.4491, Train: 0.9908, Valid: 0.9844, Best: 0.9845\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 2.4752871990203857 | KNN Loss: 2.4352729320526123 | CLS Loss: 0.04001424461603165\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 2.415855884552002 | KNN Loss: 2.3827686309814453 | CLS Loss: 0.033087268471717834\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 2.4407970905303955 | KNN Loss: 2.3950209617614746 | CLS Loss: 0.045776233077049255\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 2.4218811988830566 | KNN Loss: 2.404432773590088 | CLS Loss: 0.01744852028787136\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 2.4730589389801025 | KNN Loss: 2.429067611694336 | CLS Loss: 0.04399123042821884\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 2.4532716274261475 | KNN Loss: 2.4151077270507812 | CLS Loss: 0.03816382959485054\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 2.4483888149261475 | KNN Loss: 2.4135005474090576 | CLS Loss: 0.03488826006650925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 2.454136848449707 | KNN Loss: 2.418821096420288 | CLS Loss: 0.03531566262245178\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 2.4294815063476562 | KNN Loss: 2.3769097328186035 | CLS Loss: 0.05257188901305199\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 2.469087600708008 | KNN Loss: 2.441887378692627 | CLS Loss: 0.02720019780099392\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 2.466557502746582 | KNN Loss: 2.4054830074310303 | CLS Loss: 0.06107444316148758\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 2.4904024600982666 | KNN Loss: 2.454918622970581 | CLS Loss: 0.035483818501234055\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 2.4492619037628174 | KNN Loss: 2.4023635387420654 | CLS Loss: 0.04689840227365494\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 2.4208014011383057 | KNN Loss: 2.4107556343078613 | CLS Loss: 0.010045796632766724\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 2.4701249599456787 | KNN Loss: 2.397670269012451 | CLS Loss: 0.07245463132858276\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 2.4249839782714844 | KNN Loss: 2.4127402305603027 | CLS Loss: 0.012243710458278656\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 2.4683735370635986 | KNN Loss: 2.4238431453704834 | CLS Loss: 0.0445304736495018\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 2.459380865097046 | KNN Loss: 2.4387741088867188 | CLS Loss: 0.020606856793165207\n",
      "Epoch: 038, Loss: 2.4471, Train: 0.9896, Valid: 0.9841, Best: 0.9845\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 2.526430368423462 | KNN Loss: 2.453684091567993 | CLS Loss: 0.07274623960256577\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 2.449516534805298 | KNN Loss: 2.417515993118286 | CLS Loss: 0.032000601291656494\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 2.4643659591674805 | KNN Loss: 2.4337329864501953 | CLS Loss: 0.03063291683793068\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 2.4479870796203613 | KNN Loss: 2.405056953430176 | CLS Loss: 0.04293016344308853\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 2.4578051567077637 | KNN Loss: 2.4292869567871094 | CLS Loss: 0.028518306091427803\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 2.473071575164795 | KNN Loss: 2.438113212585449 | CLS Loss: 0.034958478063344955\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 2.438436269760132 | KNN Loss: 2.4020731449127197 | CLS Loss: 0.036363087594509125\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 2.4708287715911865 | KNN Loss: 2.4083304405212402 | CLS Loss: 0.0624983087182045\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 2.4572293758392334 | KNN Loss: 2.431126117706299 | CLS Loss: 0.026103200390934944\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 2.4628102779388428 | KNN Loss: 2.4436991214752197 | CLS Loss: 0.019111094996333122\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 2.4482288360595703 | KNN Loss: 2.4132349491119385 | CLS Loss: 0.03499384969472885\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 2.474275588989258 | KNN Loss: 2.4163615703582764 | CLS Loss: 0.05791407823562622\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 2.4466898441314697 | KNN Loss: 2.4323582649230957 | CLS Loss: 0.014331518672406673\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 2.4888830184936523 | KNN Loss: 2.4434471130371094 | CLS Loss: 0.045436009764671326\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 2.4074037075042725 | KNN Loss: 2.387460470199585 | CLS Loss: 0.01994314417243004\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 2.440453052520752 | KNN Loss: 2.4028029441833496 | CLS Loss: 0.037650108337402344\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 2.4495596885681152 | KNN Loss: 2.4237871170043945 | CLS Loss: 0.025772642344236374\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 2.4457297325134277 | KNN Loss: 2.4099621772766113 | CLS Loss: 0.03576758876442909\n",
      "Epoch: 039, Loss: 2.4494, Train: 0.9905, Valid: 0.9844, Best: 0.9845\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 2.4019179344177246 | KNN Loss: 2.386467456817627 | CLS Loss: 0.015450588427484035\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 2.46085786819458 | KNN Loss: 2.4510059356689453 | CLS Loss: 0.00985196977853775\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 2.466423749923706 | KNN Loss: 2.44940447807312 | CLS Loss: 0.017019348219037056\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 2.4963440895080566 | KNN Loss: 2.4252562522888184 | CLS Loss: 0.07108794152736664\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 2.431039810180664 | KNN Loss: 2.410658597946167 | CLS Loss: 0.020381160080432892\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 2.4579200744628906 | KNN Loss: 2.4267942905426025 | CLS Loss: 0.0311257503926754\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 2.5075113773345947 | KNN Loss: 2.4720444679260254 | CLS Loss: 0.035466957837343216\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 2.449070692062378 | KNN Loss: 2.418001651763916 | CLS Loss: 0.0310689564794302\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 2.450164318084717 | KNN Loss: 2.410663366317749 | CLS Loss: 0.03950095921754837\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 2.4009716510772705 | KNN Loss: 2.3839776515960693 | CLS Loss: 0.01699403114616871\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 2.4630439281463623 | KNN Loss: 2.4065537452697754 | CLS Loss: 0.056490182876586914\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 2.46356201171875 | KNN Loss: 2.417684555053711 | CLS Loss: 0.04587751254439354\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 2.4884145259857178 | KNN Loss: 2.4627602100372314 | CLS Loss: 0.025654226541519165\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 2.4349796772003174 | KNN Loss: 2.4177451133728027 | CLS Loss: 0.01723463647067547\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 2.4691483974456787 | KNN Loss: 2.4418768882751465 | CLS Loss: 0.02727149985730648\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 2.46464467048645 | KNN Loss: 2.431452512741089 | CLS Loss: 0.033192228525877\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 2.4914798736572266 | KNN Loss: 2.4563519954681396 | CLS Loss: 0.035127900540828705\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 2.4910178184509277 | KNN Loss: 2.442246437072754 | CLS Loss: 0.048771411180496216\n",
      "Epoch: 040, Loss: 2.4541, Train: 0.9906, Valid: 0.9846, Best: 0.9846\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 2.42976450920105 | KNN Loss: 2.4072611331939697 | CLS Loss: 0.022503407672047615\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 2.4533889293670654 | KNN Loss: 2.4195449352264404 | CLS Loss: 0.033843882381916046\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 2.459916830062866 | KNN Loss: 2.4301981925964355 | CLS Loss: 0.02971862256526947\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 2.4597725868225098 | KNN Loss: 2.421478271484375 | CLS Loss: 0.03829433023929596\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 2.482001543045044 | KNN Loss: 2.4399948120117188 | CLS Loss: 0.04200679808855057\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 2.4685373306274414 | KNN Loss: 2.452983856201172 | CLS Loss: 0.01555346604436636\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 2.4733903408050537 | KNN Loss: 2.4408178329467773 | CLS Loss: 0.03257252648472786\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 2.478743553161621 | KNN Loss: 2.4362807273864746 | CLS Loss: 0.04246271029114723\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 2.4503750801086426 | KNN Loss: 2.390502452850342 | CLS Loss: 0.059872597455978394\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 2.4346702098846436 | KNN Loss: 2.4091694355010986 | CLS Loss: 0.02550072781741619\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 2.4839396476745605 | KNN Loss: 2.447378158569336 | CLS Loss: 0.0365615077316761\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 2.4592907428741455 | KNN Loss: 2.4315950870513916 | CLS Loss: 0.027695629745721817\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 2.4107115268707275 | KNN Loss: 2.3852779865264893 | CLS Loss: 0.025433463975787163\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 2.4491465091705322 | KNN Loss: 2.4229326248168945 | CLS Loss: 0.0262139942497015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 2.44218111038208 | KNN Loss: 2.4063808917999268 | CLS Loss: 0.03580012544989586\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 2.4464876651763916 | KNN Loss: 2.4155213832855225 | CLS Loss: 0.030966177582740784\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 2.446061372756958 | KNN Loss: 2.4275972843170166 | CLS Loss: 0.01846412755548954\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 2.4749808311462402 | KNN Loss: 2.4332032203674316 | CLS Loss: 0.041777580976486206\n",
      "Epoch: 041, Loss: 2.4464, Train: 0.9891, Valid: 0.9827, Best: 0.9846\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 2.4944796562194824 | KNN Loss: 2.446552038192749 | CLS Loss: 0.047927673906087875\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 2.452305793762207 | KNN Loss: 2.4282050132751465 | CLS Loss: 0.0241008959710598\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 2.4339780807495117 | KNN Loss: 2.4152019023895264 | CLS Loss: 0.01877608895301819\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 2.5144195556640625 | KNN Loss: 2.4549620151519775 | CLS Loss: 0.059457436203956604\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 2.4074811935424805 | KNN Loss: 2.3814990520477295 | CLS Loss: 0.025982195511460304\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 2.4522342681884766 | KNN Loss: 2.434792995452881 | CLS Loss: 0.01744121126830578\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 2.4677846431732178 | KNN Loss: 2.393643379211426 | CLS Loss: 0.0741412341594696\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 2.449197292327881 | KNN Loss: 2.396890640258789 | CLS Loss: 0.052306704223155975\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 2.4378280639648438 | KNN Loss: 2.4091973304748535 | CLS Loss: 0.028630824759602547\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 2.4036664962768555 | KNN Loss: 2.386138677597046 | CLS Loss: 0.017527740448713303\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 2.466299533843994 | KNN Loss: 2.4334685802459717 | CLS Loss: 0.032830849289894104\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 2.4503049850463867 | KNN Loss: 2.440873861312866 | CLS Loss: 0.009431044571101665\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 2.4411492347717285 | KNN Loss: 2.4027342796325684 | CLS Loss: 0.03841494023799896\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 2.4593710899353027 | KNN Loss: 2.4407145977020264 | CLS Loss: 0.018656568601727486\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 2.416248083114624 | KNN Loss: 2.4019386768341064 | CLS Loss: 0.014309480786323547\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 2.4184792041778564 | KNN Loss: 2.388150930404663 | CLS Loss: 0.030328335240483284\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 2.4502079486846924 | KNN Loss: 2.4257612228393555 | CLS Loss: 0.02444678544998169\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 2.447558879852295 | KNN Loss: 2.429596185684204 | CLS Loss: 0.01796267181634903\n",
      "Epoch: 042, Loss: 2.4480, Train: 0.9906, Valid: 0.9842, Best: 0.9846\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 2.4536190032958984 | KNN Loss: 2.4343388080596924 | CLS Loss: 0.019280191510915756\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 2.4196794033050537 | KNN Loss: 2.372000217437744 | CLS Loss: 0.04767908155918121\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 2.4247989654541016 | KNN Loss: 2.3906290531158447 | CLS Loss: 0.034169793128967285\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 2.436833620071411 | KNN Loss: 2.4065678119659424 | CLS Loss: 0.03026590496301651\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 2.427248239517212 | KNN Loss: 2.4006388187408447 | CLS Loss: 0.02660936489701271\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 2.435762643814087 | KNN Loss: 2.4264607429504395 | CLS Loss: 0.009301896207034588\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 2.4350926876068115 | KNN Loss: 2.410231590270996 | CLS Loss: 0.024861127138137817\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 2.420410633087158 | KNN Loss: 2.3919363021850586 | CLS Loss: 0.02847430855035782\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 2.4829368591308594 | KNN Loss: 2.427687168121338 | CLS Loss: 0.055249642580747604\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 2.440927267074585 | KNN Loss: 2.4111011028289795 | CLS Loss: 0.029826151207089424\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 2.4316394329071045 | KNN Loss: 2.408888339996338 | CLS Loss: 0.022750994190573692\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 2.4396557807922363 | KNN Loss: 2.4186851978302 | CLS Loss: 0.02097051776945591\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 2.4666690826416016 | KNN Loss: 2.4203503131866455 | CLS Loss: 0.04631885513663292\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 2.4461140632629395 | KNN Loss: 2.4227747917175293 | CLS Loss: 0.02333918958902359\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 2.467648983001709 | KNN Loss: 2.4316487312316895 | CLS Loss: 0.03600017726421356\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 2.475567102432251 | KNN Loss: 2.4517064094543457 | CLS Loss: 0.023860719054937363\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 2.4627926349639893 | KNN Loss: 2.3985848426818848 | CLS Loss: 0.0642077699303627\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 2.4673655033111572 | KNN Loss: 2.4020605087280273 | CLS Loss: 0.06530497223138809\n",
      "Epoch: 043, Loss: 2.4512, Train: 0.9906, Valid: 0.9844, Best: 0.9846\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 2.4477550983428955 | KNN Loss: 2.4177186489105225 | CLS Loss: 0.030036529526114464\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 2.445380210876465 | KNN Loss: 2.4017586708068848 | CLS Loss: 0.04362159222364426\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 2.4711685180664062 | KNN Loss: 2.434175729751587 | CLS Loss: 0.03699280694127083\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 2.4367339611053467 | KNN Loss: 2.4063656330108643 | CLS Loss: 0.030368294566869736\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 2.4268851280212402 | KNN Loss: 2.398395299911499 | CLS Loss: 0.028489762917160988\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 2.420991897583008 | KNN Loss: 2.3911120891571045 | CLS Loss: 0.02987978421151638\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 2.428642511367798 | KNN Loss: 2.385669708251953 | CLS Loss: 0.04297279566526413\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 2.440948486328125 | KNN Loss: 2.41579008102417 | CLS Loss: 0.025158490985631943\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 2.4241209030151367 | KNN Loss: 2.39607310295105 | CLS Loss: 0.028047863394021988\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 2.442265272140503 | KNN Loss: 2.4189960956573486 | CLS Loss: 0.023269183933734894\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 2.4799232482910156 | KNN Loss: 2.448293447494507 | CLS Loss: 0.03162982314825058\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 2.4621715545654297 | KNN Loss: 2.4245200157165527 | CLS Loss: 0.03765154629945755\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 2.464853286743164 | KNN Loss: 2.4079904556274414 | CLS Loss: 0.05686277896165848\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 2.4676966667175293 | KNN Loss: 2.4136126041412354 | CLS Loss: 0.05408412218093872\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 2.4277212619781494 | KNN Loss: 2.417233943939209 | CLS Loss: 0.010487212799489498\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 2.4350130558013916 | KNN Loss: 2.377190351486206 | CLS Loss: 0.05782276391983032\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 2.4415245056152344 | KNN Loss: 2.406947135925293 | CLS Loss: 0.034577421844005585\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 2.4185571670532227 | KNN Loss: 2.404453754425049 | CLS Loss: 0.01410332415252924\n",
      "Epoch: 044, Loss: 2.4460, Train: 0.9916, Valid: 0.9834, Best: 0.9846\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 2.430079936981201 | KNN Loss: 2.3987233638763428 | CLS Loss: 0.03135651722550392\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 2.4586310386657715 | KNN Loss: 2.4256865978240967 | CLS Loss: 0.0329444482922554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 2.442269802093506 | KNN Loss: 2.4124035835266113 | CLS Loss: 0.029866263270378113\n",
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 2.4533894062042236 | KNN Loss: 2.4183874130249023 | CLS Loss: 0.0350019671022892\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 2.435678482055664 | KNN Loss: 2.4068074226379395 | CLS Loss: 0.028871044516563416\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 2.398043155670166 | KNN Loss: 2.3812410831451416 | CLS Loss: 0.016802074387669563\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 2.450256824493408 | KNN Loss: 2.4234704971313477 | CLS Loss: 0.026786241680383682\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 2.481976270675659 | KNN Loss: 2.451282262802124 | CLS Loss: 0.030694114044308662\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 2.421339273452759 | KNN Loss: 2.396886110305786 | CLS Loss: 0.024453258141875267\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 2.4625027179718018 | KNN Loss: 2.3932065963745117 | CLS Loss: 0.06929607689380646\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 2.444628953933716 | KNN Loss: 2.4256279468536377 | CLS Loss: 0.01900089532136917\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 2.4437294006347656 | KNN Loss: 2.4342989921569824 | CLS Loss: 0.009430386126041412\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 2.4328455924987793 | KNN Loss: 2.415523052215576 | CLS Loss: 0.01732264831662178\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 2.457777261734009 | KNN Loss: 2.4364025592803955 | CLS Loss: 0.02137465588748455\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 2.436553716659546 | KNN Loss: 2.4081034660339355 | CLS Loss: 0.02845025062561035\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 2.4399466514587402 | KNN Loss: 2.4133074283599854 | CLS Loss: 0.026639139279723167\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 2.4290308952331543 | KNN Loss: 2.3788557052612305 | CLS Loss: 0.05017515644431114\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 2.4278781414031982 | KNN Loss: 2.409902334213257 | CLS Loss: 0.017975762486457825\n",
      "Epoch: 045, Loss: 2.4466, Train: 0.9911, Valid: 0.9838, Best: 0.9846\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 2.4605133533477783 | KNN Loss: 2.4205515384674072 | CLS Loss: 0.039961736649274826\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 2.4362831115722656 | KNN Loss: 2.3890442848205566 | CLS Loss: 0.047238826751708984\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 2.451472043991089 | KNN Loss: 2.4351437091827393 | CLS Loss: 0.01632826030254364\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 2.4384188652038574 | KNN Loss: 2.4213876724243164 | CLS Loss: 0.017031211405992508\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 2.4176721572875977 | KNN Loss: 2.3777945041656494 | CLS Loss: 0.03987759351730347\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 2.4168970584869385 | KNN Loss: 2.368117332458496 | CLS Loss: 0.04877966642379761\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 2.4301719665527344 | KNN Loss: 2.4208269119262695 | CLS Loss: 0.009344954043626785\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 2.4589333534240723 | KNN Loss: 2.4323928356170654 | CLS Loss: 0.026540445163846016\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 2.4301178455352783 | KNN Loss: 2.4176154136657715 | CLS Loss: 0.01250237412750721\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 2.4344284534454346 | KNN Loss: 2.412337303161621 | CLS Loss: 0.022091267630457878\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 2.4339640140533447 | KNN Loss: 2.40702748298645 | CLS Loss: 0.026936525478959084\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 2.4157140254974365 | KNN Loss: 2.390990972518921 | CLS Loss: 0.02472316287457943\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 2.419304370880127 | KNN Loss: 2.401494026184082 | CLS Loss: 0.017810242250561714\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 2.452465295791626 | KNN Loss: 2.4195401668548584 | CLS Loss: 0.03292518109083176\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 2.445640802383423 | KNN Loss: 2.4144840240478516 | CLS Loss: 0.03115687519311905\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 2.457280158996582 | KNN Loss: 2.4195168018341064 | CLS Loss: 0.03776342421770096\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 2.4552154541015625 | KNN Loss: 2.4094059467315674 | CLS Loss: 0.04580949991941452\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 2.4351866245269775 | KNN Loss: 2.4186365604400635 | CLS Loss: 0.016550060361623764\n",
      "Epoch: 046, Loss: 2.4411, Train: 0.9926, Valid: 0.9851, Best: 0.9851\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 2.4248411655426025 | KNN Loss: 2.4014952182769775 | CLS Loss: 0.023345906287431717\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 2.432255506515503 | KNN Loss: 2.4122791290283203 | CLS Loss: 0.01997644081711769\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 2.472867727279663 | KNN Loss: 2.428879976272583 | CLS Loss: 0.0439876951277256\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 2.4484450817108154 | KNN Loss: 2.376709222793579 | CLS Loss: 0.07173582911491394\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 2.4203689098358154 | KNN Loss: 2.389030694961548 | CLS Loss: 0.03133811429142952\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 2.4333579540252686 | KNN Loss: 2.4088549613952637 | CLS Loss: 0.02450302056968212\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 2.448756217956543 | KNN Loss: 2.405439853668213 | CLS Loss: 0.04331646114587784\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 2.42551326751709 | KNN Loss: 2.410010814666748 | CLS Loss: 0.015502496622502804\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 2.4201455116271973 | KNN Loss: 2.396244764328003 | CLS Loss: 0.023900799453258514\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 2.4981532096862793 | KNN Loss: 2.4771947860717773 | CLS Loss: 0.02095838263630867\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 2.4076569080352783 | KNN Loss: 2.3977463245391846 | CLS Loss: 0.009910467080771923\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 2.448852777481079 | KNN Loss: 2.4064366817474365 | CLS Loss: 0.04241614416241646\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 2.455756902694702 | KNN Loss: 2.393420934677124 | CLS Loss: 0.062336068600416183\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 2.430347442626953 | KNN Loss: 2.4096286296844482 | CLS Loss: 0.020718790590763092\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 2.463216543197632 | KNN Loss: 2.406085729598999 | CLS Loss: 0.05713086947798729\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 2.4381158351898193 | KNN Loss: 2.4168543815612793 | CLS Loss: 0.021261557936668396\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 2.461829423904419 | KNN Loss: 2.447315216064453 | CLS Loss: 0.014514264650642872\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 2.4346230030059814 | KNN Loss: 2.400231122970581 | CLS Loss: 0.03439177945256233\n",
      "Epoch: 047, Loss: 2.4420, Train: 0.9924, Valid: 0.9857, Best: 0.9857\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 2.4031460285186768 | KNN Loss: 2.3894147872924805 | CLS Loss: 0.013731191866099834\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 2.484628438949585 | KNN Loss: 2.452662229537964 | CLS Loss: 0.03196616470813751\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 2.4812936782836914 | KNN Loss: 2.4388368129730225 | CLS Loss: 0.042456842958927155\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 2.4497621059417725 | KNN Loss: 2.415971517562866 | CLS Loss: 0.03379068896174431\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 2.418468713760376 | KNN Loss: 2.3923745155334473 | CLS Loss: 0.026094166561961174\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 2.4121475219726562 | KNN Loss: 2.39338755607605 | CLS Loss: 0.018759870901703835\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 2.42582106590271 | KNN Loss: 2.381248712539673 | CLS Loss: 0.04457230120897293\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 2.4351162910461426 | KNN Loss: 2.397834300994873 | CLS Loss: 0.037282031029462814\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 2.4539570808410645 | KNN Loss: 2.4231863021850586 | CLS Loss: 0.030770884826779366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 2.4567718505859375 | KNN Loss: 2.4055402278900146 | CLS Loss: 0.051231712102890015\n",
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 2.4219202995300293 | KNN Loss: 2.3998847007751465 | CLS Loss: 0.022035673260688782\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 2.4557180404663086 | KNN Loss: 2.4037559032440186 | CLS Loss: 0.05196215584874153\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 2.4206645488739014 | KNN Loss: 2.386237382888794 | CLS Loss: 0.03442712128162384\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 2.4688076972961426 | KNN Loss: 2.4180307388305664 | CLS Loss: 0.05077705159783363\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 2.424656391143799 | KNN Loss: 2.4016687870025635 | CLS Loss: 0.02298755757510662\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 2.411862850189209 | KNN Loss: 2.390775442123413 | CLS Loss: 0.021087318658828735\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 2.4263827800750732 | KNN Loss: 2.4008941650390625 | CLS Loss: 0.025488613173365593\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 2.4437763690948486 | KNN Loss: 2.4083738327026367 | CLS Loss: 0.035402629524469376\n",
      "Epoch: 048, Loss: 2.4405, Train: 0.9913, Valid: 0.9831, Best: 0.9857\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 2.4667999744415283 | KNN Loss: 2.4328293800354004 | CLS Loss: 0.03397064656019211\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 2.469590663909912 | KNN Loss: 2.425191640853882 | CLS Loss: 0.04439901188015938\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 2.452122211456299 | KNN Loss: 2.4114909172058105 | CLS Loss: 0.04063131660223007\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 2.459806203842163 | KNN Loss: 2.400754451751709 | CLS Loss: 0.059051740914583206\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 2.408876895904541 | KNN Loss: 2.3990745544433594 | CLS Loss: 0.00980233121663332\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 2.4412245750427246 | KNN Loss: 2.419670581817627 | CLS Loss: 0.021554049104452133\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 2.4527485370635986 | KNN Loss: 2.4119436740875244 | CLS Loss: 0.04080486297607422\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 2.4376747608184814 | KNN Loss: 2.3991928100585938 | CLS Loss: 0.03848206624388695\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 2.41692852973938 | KNN Loss: 2.3914592266082764 | CLS Loss: 0.025469396263360977\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 2.4357457160949707 | KNN Loss: 2.405789852142334 | CLS Loss: 0.029955752193927765\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 2.464909076690674 | KNN Loss: 2.4284796714782715 | CLS Loss: 0.03642934560775757\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 2.436702251434326 | KNN Loss: 2.3804032802581787 | CLS Loss: 0.05629885941743851\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 2.4106686115264893 | KNN Loss: 2.3897886276245117 | CLS Loss: 0.020879989489912987\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 2.473259687423706 | KNN Loss: 2.434896945953369 | CLS Loss: 0.03836284577846527\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 2.460920810699463 | KNN Loss: 2.4425554275512695 | CLS Loss: 0.01836542785167694\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 2.423165798187256 | KNN Loss: 2.400181293487549 | CLS Loss: 0.022984541952610016\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 2.4312987327575684 | KNN Loss: 2.3886029720306396 | CLS Loss: 0.04269564896821976\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 2.4433140754699707 | KNN Loss: 2.4269442558288574 | CLS Loss: 0.016369914636015892\n",
      "Epoch: 049, Loss: 2.4377, Train: 0.9929, Valid: 0.9857, Best: 0.9857\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 2.427694082260132 | KNN Loss: 2.3926496505737305 | CLS Loss: 0.03504447266459465\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 2.4260571002960205 | KNN Loss: 2.399020195007324 | CLS Loss: 0.02703699842095375\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 2.469200372695923 | KNN Loss: 2.4175450801849365 | CLS Loss: 0.051655363291502\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 2.4091107845306396 | KNN Loss: 2.3926336765289307 | CLS Loss: 0.016477063298225403\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 2.4413230419158936 | KNN Loss: 2.4156036376953125 | CLS Loss: 0.025719329714775085\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 2.4251489639282227 | KNN Loss: 2.3845245838165283 | CLS Loss: 0.040624409914016724\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 2.417891263961792 | KNN Loss: 2.393397808074951 | CLS Loss: 0.0244935043156147\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 2.428335666656494 | KNN Loss: 2.3995003700256348 | CLS Loss: 0.028835410252213478\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 2.4126601219177246 | KNN Loss: 2.367070436477661 | CLS Loss: 0.04558965563774109\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 2.4395265579223633 | KNN Loss: 2.3987278938293457 | CLS Loss: 0.040798719972372055\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 2.492755889892578 | KNN Loss: 2.4227733612060547 | CLS Loss: 0.0699826255440712\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 2.4615657329559326 | KNN Loss: 2.3960201740264893 | CLS Loss: 0.06554552167654037\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 2.4815168380737305 | KNN Loss: 2.4439210891723633 | CLS Loss: 0.03759573772549629\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 2.424733877182007 | KNN Loss: 2.4079387187957764 | CLS Loss: 0.016795245930552483\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 2.4232053756713867 | KNN Loss: 2.39974308013916 | CLS Loss: 0.0234622061252594\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 2.4413137435913086 | KNN Loss: 2.3993988037109375 | CLS Loss: 0.041914936155080795\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 2.4201791286468506 | KNN Loss: 2.3968989849090576 | CLS Loss: 0.023280169814825058\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 2.4427671432495117 | KNN Loss: 2.416527032852173 | CLS Loss: 0.026240097358822823\n",
      "Epoch: 050, Loss: 2.4391, Train: 0.9927, Valid: 0.9847, Best: 0.9857\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 2.4342572689056396 | KNN Loss: 2.3930959701538086 | CLS Loss: 0.04116123169660568\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 2.4468555450439453 | KNN Loss: 2.4141998291015625 | CLS Loss: 0.03265566751360893\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 2.4193270206451416 | KNN Loss: 2.3988685607910156 | CLS Loss: 0.020458508282899857\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 2.439714193344116 | KNN Loss: 2.42287015914917 | CLS Loss: 0.01684408076107502\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 2.445605754852295 | KNN Loss: 2.41628098487854 | CLS Loss: 0.029324669390916824\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 2.4455416202545166 | KNN Loss: 2.3818304538726807 | CLS Loss: 0.0637112408876419\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 2.4569668769836426 | KNN Loss: 2.4301888942718506 | CLS Loss: 0.026777945458889008\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 2.3865153789520264 | KNN Loss: 2.3594963550567627 | CLS Loss: 0.027019105851650238\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 2.442389965057373 | KNN Loss: 2.4298605918884277 | CLS Loss: 0.012529435567557812\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 2.4219412803649902 | KNN Loss: 2.3881168365478516 | CLS Loss: 0.03382445499300957\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 2.4550998210906982 | KNN Loss: 2.4337515830993652 | CLS Loss: 0.02134823426604271\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 2.444899082183838 | KNN Loss: 2.404935121536255 | CLS Loss: 0.03996394947171211\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 2.4176435470581055 | KNN Loss: 2.405118703842163 | CLS Loss: 0.012524756602942944\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 2.464923620223999 | KNN Loss: 2.414031505584717 | CLS Loss: 0.050892122089862823\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 2.448512077331543 | KNN Loss: 2.398607015609741 | CLS Loss: 0.04990503937005997\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 2.414067029953003 | KNN Loss: 2.396634817123413 | CLS Loss: 0.017432134598493576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 2.409090757369995 | KNN Loss: 2.3777310848236084 | CLS Loss: 0.03135956451296806\n",
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 2.402597665786743 | KNN Loss: 2.367567539215088 | CLS Loss: 0.03503013774752617\n",
      "Epoch: 051, Loss: 2.4357, Train: 0.9929, Valid: 0.9860, Best: 0.9860\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 2.415120840072632 | KNN Loss: 2.4008758068084717 | CLS Loss: 0.014245065860450268\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 2.444334030151367 | KNN Loss: 2.418369770050049 | CLS Loss: 0.025964368134737015\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 2.470932722091675 | KNN Loss: 2.4322025775909424 | CLS Loss: 0.03873008117079735\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 2.439960241317749 | KNN Loss: 2.421548843383789 | CLS Loss: 0.018411358818411827\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 2.435547351837158 | KNN Loss: 2.4010045528411865 | CLS Loss: 0.0345427580177784\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 2.4274768829345703 | KNN Loss: 2.4165587425231934 | CLS Loss: 0.010918174870312214\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 2.4005799293518066 | KNN Loss: 2.369799852371216 | CLS Loss: 0.03077998198568821\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 2.4729862213134766 | KNN Loss: 2.4369359016418457 | CLS Loss: 0.03605038300156593\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 2.4668326377868652 | KNN Loss: 2.4271883964538574 | CLS Loss: 0.03964420408010483\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 2.429154872894287 | KNN Loss: 2.3959851264953613 | CLS Loss: 0.033169712871313095\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 2.4529190063476562 | KNN Loss: 2.4328341484069824 | CLS Loss: 0.020084954798221588\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 2.432068347930908 | KNN Loss: 2.3978536128997803 | CLS Loss: 0.034214671701192856\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 2.459484577178955 | KNN Loss: 2.4328715801239014 | CLS Loss: 0.02661307156085968\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 2.490687370300293 | KNN Loss: 2.450392246246338 | CLS Loss: 0.040295008569955826\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 2.452894449234009 | KNN Loss: 2.432837724685669 | CLS Loss: 0.020056672394275665\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 2.4481072425842285 | KNN Loss: 2.4162065982818604 | CLS Loss: 0.031900640577077866\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 2.426382303237915 | KNN Loss: 2.386101245880127 | CLS Loss: 0.04028099775314331\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 2.4459071159362793 | KNN Loss: 2.409447193145752 | CLS Loss: 0.03645995259284973\n",
      "Epoch: 052, Loss: 2.4394, Train: 0.9914, Valid: 0.9851, Best: 0.9860\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 2.4332966804504395 | KNN Loss: 2.415550947189331 | CLS Loss: 0.017745645716786385\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 2.427415132522583 | KNN Loss: 2.4132189750671387 | CLS Loss: 0.014196251519024372\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 2.4075112342834473 | KNN Loss: 2.390763998031616 | CLS Loss: 0.016747143119573593\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 2.462031364440918 | KNN Loss: 2.426774024963379 | CLS Loss: 0.035257235169410706\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 2.4556753635406494 | KNN Loss: 2.432595729827881 | CLS Loss: 0.023079581558704376\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 2.398576021194458 | KNN Loss: 2.3748385906219482 | CLS Loss: 0.02373739331960678\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 2.447636604309082 | KNN Loss: 2.4303791522979736 | CLS Loss: 0.017257433384656906\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 2.4889113903045654 | KNN Loss: 2.462402105331421 | CLS Loss: 0.026509279385209084\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 2.4610648155212402 | KNN Loss: 2.4433181285858154 | CLS Loss: 0.017746759578585625\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 2.4533438682556152 | KNN Loss: 2.4233622550964355 | CLS Loss: 0.029981620609760284\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 2.424732208251953 | KNN Loss: 2.4019196033477783 | CLS Loss: 0.02281249314546585\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 2.434415340423584 | KNN Loss: 2.3932459354400635 | CLS Loss: 0.04116947203874588\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 2.4783501625061035 | KNN Loss: 2.4421584606170654 | CLS Loss: 0.03619161248207092\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 2.423180103302002 | KNN Loss: 2.4122233390808105 | CLS Loss: 0.010956783778965473\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 2.4046497344970703 | KNN Loss: 2.3830320835113525 | CLS Loss: 0.021617749705910683\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 2.457388162612915 | KNN Loss: 2.4451112747192383 | CLS Loss: 0.0122767873108387\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 2.4564428329467773 | KNN Loss: 2.432497262954712 | CLS Loss: 0.023945588618516922\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 2.432227611541748 | KNN Loss: 2.405792236328125 | CLS Loss: 0.02643529884517193\n",
      "Epoch: 053, Loss: 2.4387, Train: 0.9926, Valid: 0.9845, Best: 0.9860\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 2.4323675632476807 | KNN Loss: 2.3948543071746826 | CLS Loss: 0.037513211369514465\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 2.459657907485962 | KNN Loss: 2.417740821838379 | CLS Loss: 0.04191708192229271\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 2.439610242843628 | KNN Loss: 2.43154239654541 | CLS Loss: 0.0080677829682827\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 2.443629741668701 | KNN Loss: 2.4369559288024902 | CLS Loss: 0.0066737099550664425\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 2.4323372840881348 | KNN Loss: 2.4002935886383057 | CLS Loss: 0.03204379230737686\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 2.4421496391296387 | KNN Loss: 2.418105125427246 | CLS Loss: 0.02404441498219967\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 2.4421098232269287 | KNN Loss: 2.4005112648010254 | CLS Loss: 0.04159855470061302\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 2.412428617477417 | KNN Loss: 2.3907759189605713 | CLS Loss: 0.02165273018181324\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 2.4697554111480713 | KNN Loss: 2.4197962284088135 | CLS Loss: 0.04995906725525856\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 2.4623196125030518 | KNN Loss: 2.4238040447235107 | CLS Loss: 0.038515541702508926\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 2.459196090698242 | KNN Loss: 2.419016122817993 | CLS Loss: 0.040180083364248276\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 2.43009352684021 | KNN Loss: 2.41119384765625 | CLS Loss: 0.01889965496957302\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 2.3960366249084473 | KNN Loss: 2.3857576847076416 | CLS Loss: 0.010278944857418537\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 2.4726171493530273 | KNN Loss: 2.4370181560516357 | CLS Loss: 0.035598982125520706\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 2.4458212852478027 | KNN Loss: 2.4279701709747314 | CLS Loss: 0.017851099371910095\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 2.4370081424713135 | KNN Loss: 2.411205291748047 | CLS Loss: 0.02580278553068638\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 2.469176769256592 | KNN Loss: 2.450023651123047 | CLS Loss: 0.019153080880641937\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 2.4330148696899414 | KNN Loss: 2.405714273452759 | CLS Loss: 0.02730058878660202\n",
      "Epoch: 054, Loss: 2.4409, Train: 0.9930, Valid: 0.9857, Best: 0.9860\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 2.4259817600250244 | KNN Loss: 2.397073984146118 | CLS Loss: 0.02890780009329319\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 2.4268414974212646 | KNN Loss: 2.409787178039551 | CLS Loss: 0.017054347321391106\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 2.4665801525115967 | KNN Loss: 2.4033682346343994 | CLS Loss: 0.06321197748184204\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 2.404613733291626 | KNN Loss: 2.3979837894439697 | CLS Loss: 0.0066299596801400185\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 2.4458229541778564 | KNN Loss: 2.4011099338531494 | CLS Loss: 0.04471302404999733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 2.47633695602417 | KNN Loss: 2.455465793609619 | CLS Loss: 0.020871154963970184\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 2.4389569759368896 | KNN Loss: 2.403843879699707 | CLS Loss: 0.03511308133602142\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 2.3977174758911133 | KNN Loss: 2.3854451179504395 | CLS Loss: 0.0122722452506423\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 2.436746597290039 | KNN Loss: 2.413393020629883 | CLS Loss: 0.023353606462478638\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 2.4991507530212402 | KNN Loss: 2.4536969661712646 | CLS Loss: 0.04545385017991066\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 2.4004952907562256 | KNN Loss: 2.372343063354492 | CLS Loss: 0.02815225161612034\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 2.4772653579711914 | KNN Loss: 2.4401230812072754 | CLS Loss: 0.03714223578572273\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 2.4260425567626953 | KNN Loss: 2.4123623371124268 | CLS Loss: 0.013680185191333294\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 2.4542198181152344 | KNN Loss: 2.4485957622528076 | CLS Loss: 0.005623973906040192\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 2.446274518966675 | KNN Loss: 2.376377820968628 | CLS Loss: 0.06989670544862747\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 2.483581304550171 | KNN Loss: 2.454115867614746 | CLS Loss: 0.02946532517671585\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 2.459744691848755 | KNN Loss: 2.420832633972168 | CLS Loss: 0.03891211748123169\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 2.394174337387085 | KNN Loss: 2.376765489578247 | CLS Loss: 0.017408793792128563\n",
      "Epoch: 055, Loss: 2.4408, Train: 0.9923, Valid: 0.9849, Best: 0.9860\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 2.4323740005493164 | KNN Loss: 2.4127326011657715 | CLS Loss: 0.019641295075416565\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 2.4832658767700195 | KNN Loss: 2.4513912200927734 | CLS Loss: 0.0318746417760849\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 2.4501421451568604 | KNN Loss: 2.3899998664855957 | CLS Loss: 0.06014221906661987\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 2.445448875427246 | KNN Loss: 2.4184861183166504 | CLS Loss: 0.026962745934724808\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 2.440204620361328 | KNN Loss: 2.4260754585266113 | CLS Loss: 0.014129179529845715\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 2.398763418197632 | KNN Loss: 2.3648154735565186 | CLS Loss: 0.03394804149866104\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 2.4299657344818115 | KNN Loss: 2.426575183868408 | CLS Loss: 0.003390643512830138\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 2.4078915119171143 | KNN Loss: 2.382686138153076 | CLS Loss: 0.025205301120877266\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 2.429898977279663 | KNN Loss: 2.3885481357574463 | CLS Loss: 0.041350893676280975\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 2.4386837482452393 | KNN Loss: 2.422078847885132 | CLS Loss: 0.016604971140623093\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 2.4182076454162598 | KNN Loss: 2.3927083015441895 | CLS Loss: 0.025499338284134865\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 2.463505268096924 | KNN Loss: 2.4380831718444824 | CLS Loss: 0.025422101840376854\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 2.4617629051208496 | KNN Loss: 2.404439926147461 | CLS Loss: 0.0573229156434536\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 2.416577100753784 | KNN Loss: 2.4067294597625732 | CLS Loss: 0.009847573935985565\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 2.4356493949890137 | KNN Loss: 2.4102118015289307 | CLS Loss: 0.02543768472969532\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 2.424572467803955 | KNN Loss: 2.409740447998047 | CLS Loss: 0.01483212411403656\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 2.4414260387420654 | KNN Loss: 2.415275812149048 | CLS Loss: 0.026150112971663475\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 2.4676554203033447 | KNN Loss: 2.407735586166382 | CLS Loss: 0.05991991236805916\n",
      "Epoch: 056, Loss: 2.4371, Train: 0.9920, Valid: 0.9834, Best: 0.9860\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 2.464284896850586 | KNN Loss: 2.436947822570801 | CLS Loss: 0.02733711712062359\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 2.466381788253784 | KNN Loss: 2.4339985847473145 | CLS Loss: 0.03238314017653465\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 2.436984062194824 | KNN Loss: 2.398961067199707 | CLS Loss: 0.038022954016923904\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 2.434467077255249 | KNN Loss: 2.4164674282073975 | CLS Loss: 0.01799965277314186\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 2.4449470043182373 | KNN Loss: 2.3914873600006104 | CLS Loss: 0.053459532558918\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 2.477541923522949 | KNN Loss: 2.439624071121216 | CLS Loss: 0.03791783004999161\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 2.4373939037323 | KNN Loss: 2.422203540802002 | CLS Loss: 0.015190430916845798\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 2.4725852012634277 | KNN Loss: 2.413261890411377 | CLS Loss: 0.059323251247406006\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 2.449223756790161 | KNN Loss: 2.4145314693450928 | CLS Loss: 0.03469228744506836\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 2.4408786296844482 | KNN Loss: 2.424835205078125 | CLS Loss: 0.016043342649936676\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 2.4324495792388916 | KNN Loss: 2.3790626525878906 | CLS Loss: 0.05338696390390396\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 2.4834389686584473 | KNN Loss: 2.45668363571167 | CLS Loss: 0.026755215600132942\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 2.4480154514312744 | KNN Loss: 2.425175189971924 | CLS Loss: 0.02284036949276924\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 2.4631919860839844 | KNN Loss: 2.4406633377075195 | CLS Loss: 0.022528639063239098\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 2.4034371376037598 | KNN Loss: 2.382991313934326 | CLS Loss: 0.020445872098207474\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 2.466437578201294 | KNN Loss: 2.4219276905059814 | CLS Loss: 0.0445098914206028\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 2.4091875553131104 | KNN Loss: 2.3719499111175537 | CLS Loss: 0.03723771870136261\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 2.4118027687072754 | KNN Loss: 2.385619878768921 | CLS Loss: 0.026182886213064194\n",
      "Epoch: 057, Loss: 2.4394, Train: 0.9937, Valid: 0.9855, Best: 0.9860\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 2.394277572631836 | KNN Loss: 2.376772403717041 | CLS Loss: 0.017505276948213577\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 2.4305593967437744 | KNN Loss: 2.408912420272827 | CLS Loss: 0.021646957844495773\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 2.4103305339813232 | KNN Loss: 2.394127130508423 | CLS Loss: 0.01620335690677166\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 2.4217464923858643 | KNN Loss: 2.4022839069366455 | CLS Loss: 0.019462665542960167\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 2.428509473800659 | KNN Loss: 2.3976070880889893 | CLS Loss: 0.030902286991477013\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 2.411818027496338 | KNN Loss: 2.3960492610931396 | CLS Loss: 0.01576877199113369\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 2.4237093925476074 | KNN Loss: 2.416882038116455 | CLS Loss: 0.006827330216765404\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 2.439262866973877 | KNN Loss: 2.413928508758545 | CLS Loss: 0.02533424086868763\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 2.4213027954101562 | KNN Loss: 2.3886654376983643 | CLS Loss: 0.03263743966817856\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 2.415503740310669 | KNN Loss: 2.4015443325042725 | CLS Loss: 0.013959450647234917\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 2.412482976913452 | KNN Loss: 2.3777525424957275 | CLS Loss: 0.0347304493188858\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 2.446280002593994 | KNN Loss: 2.427528142929077 | CLS Loss: 0.018751852214336395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 2.4304449558258057 | KNN Loss: 2.4017574787139893 | CLS Loss: 0.028687389567494392\n",
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 2.394601821899414 | KNN Loss: 2.381950855255127 | CLS Loss: 0.012651074677705765\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 2.461202621459961 | KNN Loss: 2.4432148933410645 | CLS Loss: 0.01798783428966999\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 2.4144227504730225 | KNN Loss: 2.406914234161377 | CLS Loss: 0.007508426439017057\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 2.4096717834472656 | KNN Loss: 2.388731002807617 | CLS Loss: 0.020940696820616722\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 2.426217555999756 | KNN Loss: 2.4011027812957764 | CLS Loss: 0.025114860385656357\n",
      "Epoch: 058, Loss: 2.4342, Train: 0.9936, Valid: 0.9856, Best: 0.9860\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 2.460653305053711 | KNN Loss: 2.427990674972534 | CLS Loss: 0.032662615180015564\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 2.467381715774536 | KNN Loss: 2.4413931369781494 | CLS Loss: 0.025988534092903137\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 2.4434070587158203 | KNN Loss: 2.4242591857910156 | CLS Loss: 0.019147910177707672\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 2.4779751300811768 | KNN Loss: 2.4508180618286133 | CLS Loss: 0.02715699002146721\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 2.3903591632843018 | KNN Loss: 2.3673856258392334 | CLS Loss: 0.02297358773648739\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 2.4079670906066895 | KNN Loss: 2.38270902633667 | CLS Loss: 0.02525801956653595\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 2.428898572921753 | KNN Loss: 2.3879449367523193 | CLS Loss: 0.04095358029007912\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 2.4302587509155273 | KNN Loss: 2.413149356842041 | CLS Loss: 0.017109405249357224\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 2.438194990158081 | KNN Loss: 2.419581890106201 | CLS Loss: 0.018613096326589584\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 2.442110538482666 | KNN Loss: 2.4219071865081787 | CLS Loss: 0.02020343393087387\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 2.4926798343658447 | KNN Loss: 2.467968463897705 | CLS Loss: 0.024711325764656067\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 2.4047000408172607 | KNN Loss: 2.387969493865967 | CLS Loss: 0.016730627045035362\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 2.472200632095337 | KNN Loss: 2.431823253631592 | CLS Loss: 0.040377385914325714\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 2.4282472133636475 | KNN Loss: 2.422084093093872 | CLS Loss: 0.0061630201525986195\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 2.444589853286743 | KNN Loss: 2.427818536758423 | CLS Loss: 0.016771350055933\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 2.4279091358184814 | KNN Loss: 2.3891777992248535 | CLS Loss: 0.038731351494789124\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 2.406055450439453 | KNN Loss: 2.39656138420105 | CLS Loss: 0.009494058787822723\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 2.4121551513671875 | KNN Loss: 2.384150505065918 | CLS Loss: 0.02800457365810871\n",
      "Epoch: 059, Loss: 2.4379, Train: 0.9941, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 2.413079023361206 | KNN Loss: 2.3767731189727783 | CLS Loss: 0.03630594164133072\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 2.472630023956299 | KNN Loss: 2.4603662490844727 | CLS Loss: 0.012263745069503784\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 2.4469621181488037 | KNN Loss: 2.4199986457824707 | CLS Loss: 0.02696339599788189\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 2.4189860820770264 | KNN Loss: 2.3900482654571533 | CLS Loss: 0.028937775641679764\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 2.4423434734344482 | KNN Loss: 2.4088668823242188 | CLS Loss: 0.033476557582616806\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 2.446441650390625 | KNN Loss: 2.3938562870025635 | CLS Loss: 0.05258535221219063\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 2.3998732566833496 | KNN Loss: 2.3708980083465576 | CLS Loss: 0.0289752334356308\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 2.489035129547119 | KNN Loss: 2.476393461227417 | CLS Loss: 0.012641586363315582\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 2.4686200618743896 | KNN Loss: 2.4374473094940186 | CLS Loss: 0.03117273561656475\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 2.4453601837158203 | KNN Loss: 2.4161391258239746 | CLS Loss: 0.029221102595329285\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 2.4530787467956543 | KNN Loss: 2.4243481159210205 | CLS Loss: 0.028730664402246475\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 2.4393351078033447 | KNN Loss: 2.405632495880127 | CLS Loss: 0.03370271623134613\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 2.4357142448425293 | KNN Loss: 2.4109716415405273 | CLS Loss: 0.02474253810942173\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 2.4401636123657227 | KNN Loss: 2.4135091304779053 | CLS Loss: 0.026654517278075218\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 2.477231502532959 | KNN Loss: 2.4672250747680664 | CLS Loss: 0.010006400756537914\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 2.4381096363067627 | KNN Loss: 2.4223153591156006 | CLS Loss: 0.01579437404870987\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 2.4399430751800537 | KNN Loss: 2.4250378608703613 | CLS Loss: 0.014905255287885666\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 2.4188320636749268 | KNN Loss: 2.4059154987335205 | CLS Loss: 0.012916545383632183\n",
      "Epoch: 060, Loss: 2.4359, Train: 0.9922, Valid: 0.9840, Best: 0.9866\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 2.428243637084961 | KNN Loss: 2.399322509765625 | CLS Loss: 0.028921108692884445\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 2.408496141433716 | KNN Loss: 2.381955146789551 | CLS Loss: 0.02654094621539116\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 2.4176337718963623 | KNN Loss: 2.4034414291381836 | CLS Loss: 0.014192448928952217\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 2.46337628364563 | KNN Loss: 2.427565813064575 | CLS Loss: 0.03581051155924797\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 2.401808023452759 | KNN Loss: 2.38152813911438 | CLS Loss: 0.02027995139360428\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 2.4130859375 | KNN Loss: 2.381293773651123 | CLS Loss: 0.03179222717881203\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 2.4177777767181396 | KNN Loss: 2.408090353012085 | CLS Loss: 0.009687536396086216\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 2.492455005645752 | KNN Loss: 2.4639892578125 | CLS Loss: 0.02846570312976837\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 2.427751302719116 | KNN Loss: 2.41239857673645 | CLS Loss: 0.015352818183600903\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 2.4571590423583984 | KNN Loss: 2.4282445907592773 | CLS Loss: 0.028914423659443855\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 2.414452075958252 | KNN Loss: 2.3877482414245605 | CLS Loss: 0.02670374885201454\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 2.4045372009277344 | KNN Loss: 2.3922007083892822 | CLS Loss: 0.012336506508290768\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 2.4239342212677 | KNN Loss: 2.412654399871826 | CLS Loss: 0.011279752478003502\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 2.43440580368042 | KNN Loss: 2.403005599975586 | CLS Loss: 0.03140031918883324\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 2.4492743015289307 | KNN Loss: 2.4255576133728027 | CLS Loss: 0.023716606199741364\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 2.467984914779663 | KNN Loss: 2.4258058071136475 | CLS Loss: 0.04217913746833801\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 2.425689220428467 | KNN Loss: 2.3733890056610107 | CLS Loss: 0.05230012163519859\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 2.4370224475860596 | KNN Loss: 2.407979726791382 | CLS Loss: 0.029042700305581093\n",
      "Epoch: 061, Loss: 2.4363, Train: 0.9932, Valid: 0.9850, Best: 0.9866\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 2.4255247116088867 | KNN Loss: 2.3906643390655518 | CLS Loss: 0.034860365092754364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 2.4191205501556396 | KNN Loss: 2.394473075866699 | CLS Loss: 0.02464747615158558\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 2.399761438369751 | KNN Loss: 2.379631280899048 | CLS Loss: 0.020130233839154243\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 2.4271254539489746 | KNN Loss: 2.3896608352661133 | CLS Loss: 0.037464678287506104\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 2.4202849864959717 | KNN Loss: 2.3849093914031982 | CLS Loss: 0.03537552058696747\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 2.4359982013702393 | KNN Loss: 2.382061719894409 | CLS Loss: 0.053936492651700974\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 2.4417028427124023 | KNN Loss: 2.4204752445220947 | CLS Loss: 0.02122764103114605\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 2.459484577178955 | KNN Loss: 2.443368434906006 | CLS Loss: 0.016116205602884293\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 2.479203939437866 | KNN Loss: 2.4433746337890625 | CLS Loss: 0.03582921624183655\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 2.4503886699676514 | KNN Loss: 2.4418485164642334 | CLS Loss: 0.008540106937289238\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 2.4288384914398193 | KNN Loss: 2.3669111728668213 | CLS Loss: 0.061927273869514465\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 2.4236583709716797 | KNN Loss: 2.404052495956421 | CLS Loss: 0.01960575580596924\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 2.39904522895813 | KNN Loss: 2.3845672607421875 | CLS Loss: 0.014478001743555069\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 2.425307035446167 | KNN Loss: 2.4115445613861084 | CLS Loss: 0.013762502931058407\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 2.437770128250122 | KNN Loss: 2.405362367630005 | CLS Loss: 0.03240768611431122\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 2.4543826580047607 | KNN Loss: 2.4106316566467285 | CLS Loss: 0.04375101625919342\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 2.402510166168213 | KNN Loss: 2.395832061767578 | CLS Loss: 0.006678115576505661\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 2.4265172481536865 | KNN Loss: 2.388650417327881 | CLS Loss: 0.03786693140864372\n",
      "Epoch: 062, Loss: 2.4316, Train: 0.9936, Valid: 0.9847, Best: 0.9866\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 2.428318738937378 | KNN Loss: 2.394533634185791 | CLS Loss: 0.03378502279520035\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 2.421053409576416 | KNN Loss: 2.4006664752960205 | CLS Loss: 0.020386965945363045\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 2.428093433380127 | KNN Loss: 2.4090375900268555 | CLS Loss: 0.019055785611271858\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 2.428090810775757 | KNN Loss: 2.41342830657959 | CLS Loss: 0.014662583358585835\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 2.444000244140625 | KNN Loss: 2.4313032627105713 | CLS Loss: 0.012697084806859493\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 2.4473071098327637 | KNN Loss: 2.429640531539917 | CLS Loss: 0.017666548490524292\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 2.466628313064575 | KNN Loss: 2.420400381088257 | CLS Loss: 0.04622804373502731\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 2.4601101875305176 | KNN Loss: 2.420846939086914 | CLS Loss: 0.03926322981715202\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 2.453564405441284 | KNN Loss: 2.4277265071868896 | CLS Loss: 0.02583780698478222\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 2.4578135013580322 | KNN Loss: 2.4237847328186035 | CLS Loss: 0.034028854221105576\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 2.4789156913757324 | KNN Loss: 2.448758125305176 | CLS Loss: 0.030157633125782013\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 2.4624578952789307 | KNN Loss: 2.4480197429656982 | CLS Loss: 0.014438068494200706\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 2.4035298824310303 | KNN Loss: 2.3953895568847656 | CLS Loss: 0.008140292018651962\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 2.486668825149536 | KNN Loss: 2.459669828414917 | CLS Loss: 0.026999082416296005\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 2.4124903678894043 | KNN Loss: 2.37660551071167 | CLS Loss: 0.03588492423295975\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 2.410139799118042 | KNN Loss: 2.3964715003967285 | CLS Loss: 0.013668414205312729\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 2.419985771179199 | KNN Loss: 2.3985304832458496 | CLS Loss: 0.0214553065598011\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 2.421687602996826 | KNN Loss: 2.4108731746673584 | CLS Loss: 0.010814446024596691\n",
      "Epoch: 063, Loss: 2.4385, Train: 0.9923, Valid: 0.9856, Best: 0.9866\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 2.43270206451416 | KNN Loss: 2.405996322631836 | CLS Loss: 0.02670574188232422\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 2.4099366664886475 | KNN Loss: 2.382143259048462 | CLS Loss: 0.027793440967798233\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 2.4281651973724365 | KNN Loss: 2.397404909133911 | CLS Loss: 0.03076018951833248\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 2.410339117050171 | KNN Loss: 2.369920015335083 | CLS Loss: 0.04041902720928192\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 2.4240643978118896 | KNN Loss: 2.4170892238616943 | CLS Loss: 0.006975118536502123\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 2.404927968978882 | KNN Loss: 2.3954391479492188 | CLS Loss: 0.00948871485888958\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 2.441492795944214 | KNN Loss: 2.4192142486572266 | CLS Loss: 0.02227853424847126\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 2.429785966873169 | KNN Loss: 2.4117534160614014 | CLS Loss: 0.018032491207122803\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 2.4114980697631836 | KNN Loss: 2.396777629852295 | CLS Loss: 0.014720329083502293\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 2.4636435508728027 | KNN Loss: 2.422471046447754 | CLS Loss: 0.041172564029693604\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 2.4824917316436768 | KNN Loss: 2.4524004459381104 | CLS Loss: 0.030091222375631332\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 2.441580057144165 | KNN Loss: 2.4162659645080566 | CLS Loss: 0.025314055383205414\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 2.4299466609954834 | KNN Loss: 2.4033963680267334 | CLS Loss: 0.02655022218823433\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 2.4181923866271973 | KNN Loss: 2.385537624359131 | CLS Loss: 0.032654762268066406\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 2.448014259338379 | KNN Loss: 2.417421817779541 | CLS Loss: 0.030592424795031548\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 2.450746536254883 | KNN Loss: 2.44576096534729 | CLS Loss: 0.004985529463738203\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 2.4480793476104736 | KNN Loss: 2.4111695289611816 | CLS Loss: 0.036909837275743484\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 2.4530842304229736 | KNN Loss: 2.4224586486816406 | CLS Loss: 0.03062557429075241\n",
      "Epoch: 064, Loss: 2.4360, Train: 0.9935, Valid: 0.9850, Best: 0.9866\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 2.4039247035980225 | KNN Loss: 2.379621744155884 | CLS Loss: 0.02430303394794464\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 2.4937825202941895 | KNN Loss: 2.4693849086761475 | CLS Loss: 0.024397607892751694\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 2.405733108520508 | KNN Loss: 2.3781888484954834 | CLS Loss: 0.027544314041733742\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 2.49773907661438 | KNN Loss: 2.4580183029174805 | CLS Loss: 0.03972073271870613\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 2.428297519683838 | KNN Loss: 2.395023822784424 | CLS Loss: 0.0332736000418663\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 2.446194887161255 | KNN Loss: 2.4266104698181152 | CLS Loss: 0.019584327936172485\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 2.397731304168701 | KNN Loss: 2.3909902572631836 | CLS Loss: 0.006741133518517017\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 2.4271926879882812 | KNN Loss: 2.39280104637146 | CLS Loss: 0.03439159691333771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 2.437222719192505 | KNN Loss: 2.396211624145508 | CLS Loss: 0.041011132299900055\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 2.4104537963867188 | KNN Loss: 2.3935484886169434 | CLS Loss: 0.016905302181839943\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 2.4210989475250244 | KNN Loss: 2.4019148349761963 | CLS Loss: 0.0191841721534729\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 2.386496067047119 | KNN Loss: 2.378312826156616 | CLS Loss: 0.008183357305824757\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 2.4694080352783203 | KNN Loss: 2.446728467941284 | CLS Loss: 0.022679666057229042\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 2.4052248001098633 | KNN Loss: 2.3882646560668945 | CLS Loss: 0.016960179433226585\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 2.4872426986694336 | KNN Loss: 2.445955276489258 | CLS Loss: 0.04128730297088623\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 2.456246852874756 | KNN Loss: 2.4207100868225098 | CLS Loss: 0.035536717623472214\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 2.466998338699341 | KNN Loss: 2.4262924194335938 | CLS Loss: 0.04070581495761871\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 2.433192014694214 | KNN Loss: 2.4152004718780518 | CLS Loss: 0.017991606146097183\n",
      "Epoch: 065, Loss: 2.4355, Train: 0.9940, Valid: 0.9865, Best: 0.9866\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 2.460923433303833 | KNN Loss: 2.430104970932007 | CLS Loss: 0.030818553641438484\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 2.4116334915161133 | KNN Loss: 2.387510299682617 | CLS Loss: 0.024123158305883408\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 2.4613802433013916 | KNN Loss: 2.452246904373169 | CLS Loss: 0.009133229963481426\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 2.419088363647461 | KNN Loss: 2.401137113571167 | CLS Loss: 0.01795133575797081\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 2.44572114944458 | KNN Loss: 2.4164252281188965 | CLS Loss: 0.029295913875102997\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 2.416722536087036 | KNN Loss: 2.4023382663726807 | CLS Loss: 0.014384154230356216\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 2.4368820190429688 | KNN Loss: 2.4255990982055664 | CLS Loss: 0.011282923631370068\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 2.4411494731903076 | KNN Loss: 2.4062931537628174 | CLS Loss: 0.03485637530684471\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 2.4133756160736084 | KNN Loss: 2.3984451293945312 | CLS Loss: 0.014930556528270245\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 2.4532101154327393 | KNN Loss: 2.4172677993774414 | CLS Loss: 0.035942401736974716\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 2.453273057937622 | KNN Loss: 2.4435811042785645 | CLS Loss: 0.009692019782960415\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 2.4744551181793213 | KNN Loss: 2.453559637069702 | CLS Loss: 0.02089547924697399\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 2.398960590362549 | KNN Loss: 2.390070915222168 | CLS Loss: 0.008889753371477127\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 2.4034271240234375 | KNN Loss: 2.392017364501953 | CLS Loss: 0.01140979491174221\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 2.4507505893707275 | KNN Loss: 2.427501678466797 | CLS Loss: 0.023248933255672455\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 2.419146776199341 | KNN Loss: 2.40847110748291 | CLS Loss: 0.010675659403204918\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 2.4153640270233154 | KNN Loss: 2.383516311645508 | CLS Loss: 0.03184773772954941\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 2.409791946411133 | KNN Loss: 2.393073081970215 | CLS Loss: 0.016718877479434013\n",
      "Epoch: 066, Loss: 2.4316, Train: 0.9932, Valid: 0.9852, Best: 0.9866\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 2.42189621925354 | KNN Loss: 2.408082962036133 | CLS Loss: 0.013813357800245285\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 2.4802443981170654 | KNN Loss: 2.4539504051208496 | CLS Loss: 0.02629406377673149\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 2.4618079662323 | KNN Loss: 2.4076805114746094 | CLS Loss: 0.05412744730710983\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 2.4132182598114014 | KNN Loss: 2.3688457012176514 | CLS Loss: 0.044372498989105225\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 2.450204849243164 | KNN Loss: 2.4400761127471924 | CLS Loss: 0.010128658264875412\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 2.4604604244232178 | KNN Loss: 2.4244701862335205 | CLS Loss: 0.03599018231034279\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 2.438533067703247 | KNN Loss: 2.414187431335449 | CLS Loss: 0.02434570901095867\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 2.46500301361084 | KNN Loss: 2.4255387783050537 | CLS Loss: 0.039464227855205536\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 2.420132875442505 | KNN Loss: 2.4111785888671875 | CLS Loss: 0.008954302407801151\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 2.435474157333374 | KNN Loss: 2.421445846557617 | CLS Loss: 0.014028259553015232\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 2.410571575164795 | KNN Loss: 2.3958213329315186 | CLS Loss: 0.014750286936759949\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 2.452045202255249 | KNN Loss: 2.4027159214019775 | CLS Loss: 0.04932916909456253\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 2.442107677459717 | KNN Loss: 2.4112021923065186 | CLS Loss: 0.030905505642294884\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 2.430798053741455 | KNN Loss: 2.4079504013061523 | CLS Loss: 0.022847699001431465\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 2.477652072906494 | KNN Loss: 2.453770875930786 | CLS Loss: 0.023881174623966217\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 2.410863161087036 | KNN Loss: 2.3836007118225098 | CLS Loss: 0.027262380346655846\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 2.43117094039917 | KNN Loss: 2.4253125190734863 | CLS Loss: 0.005858359392732382\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 2.4286587238311768 | KNN Loss: 2.4077603816986084 | CLS Loss: 0.02089843526482582\n",
      "Epoch: 067, Loss: 2.4345, Train: 0.9936, Valid: 0.9859, Best: 0.9866\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 2.4432802200317383 | KNN Loss: 2.414456844329834 | CLS Loss: 0.028823301196098328\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 2.405294179916382 | KNN Loss: 2.3910694122314453 | CLS Loss: 0.014224734157323837\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 2.420957565307617 | KNN Loss: 2.404755115509033 | CLS Loss: 0.016202380880713463\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 2.4413034915924072 | KNN Loss: 2.4336347579956055 | CLS Loss: 0.007668832316994667\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 2.4374632835388184 | KNN Loss: 2.405104398727417 | CLS Loss: 0.03235888108611107\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 2.3863394260406494 | KNN Loss: 2.354809045791626 | CLS Loss: 0.03153030574321747\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 2.4168882369995117 | KNN Loss: 2.4082584381103516 | CLS Loss: 0.0086298119276762\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 2.3937039375305176 | KNN Loss: 2.3813836574554443 | CLS Loss: 0.012320169247686863\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 2.4604153633117676 | KNN Loss: 2.437268018722534 | CLS Loss: 0.023147307336330414\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 2.4351181983947754 | KNN Loss: 2.4181811809539795 | CLS Loss: 0.016937024891376495\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 2.4342477321624756 | KNN Loss: 2.384200096130371 | CLS Loss: 0.05004753917455673\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 2.4698848724365234 | KNN Loss: 2.4355239868164062 | CLS Loss: 0.034360822290182114\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 2.401998519897461 | KNN Loss: 2.389390707015991 | CLS Loss: 0.012607784010469913\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 2.449050188064575 | KNN Loss: 2.406782388687134 | CLS Loss: 0.04226778447628021\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 2.4330263137817383 | KNN Loss: 2.424961805343628 | CLS Loss: 0.008064595982432365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 2.4303667545318604 | KNN Loss: 2.3876781463623047 | CLS Loss: 0.04268871620297432\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 2.4061567783355713 | KNN Loss: 2.383423089981079 | CLS Loss: 0.022733604535460472\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 2.436418056488037 | KNN Loss: 2.423677921295166 | CLS Loss: 0.012740061618387699\n",
      "Epoch: 068, Loss: 2.4277, Train: 0.9944, Valid: 0.9857, Best: 0.9866\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 2.436387062072754 | KNN Loss: 2.422041177749634 | CLS Loss: 0.0143458666279912\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 2.457785129547119 | KNN Loss: 2.423933744430542 | CLS Loss: 0.03385132551193237\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 2.3917553424835205 | KNN Loss: 2.3669304847717285 | CLS Loss: 0.02482491545379162\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 2.4182498455047607 | KNN Loss: 2.4029653072357178 | CLS Loss: 0.015284519642591476\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 2.408339023590088 | KNN Loss: 2.3606693744659424 | CLS Loss: 0.04766959697008133\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 2.4357292652130127 | KNN Loss: 2.4270336627960205 | CLS Loss: 0.008695531636476517\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 2.445557117462158 | KNN Loss: 2.4305684566497803 | CLS Loss: 0.014988547191023827\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 2.4172322750091553 | KNN Loss: 2.400254487991333 | CLS Loss: 0.01697782427072525\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 2.4287819862365723 | KNN Loss: 2.418436288833618 | CLS Loss: 0.010345741175115108\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 2.4307289123535156 | KNN Loss: 2.4085752964019775 | CLS Loss: 0.022153658792376518\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 2.4697744846343994 | KNN Loss: 2.442699670791626 | CLS Loss: 0.02707471139729023\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 2.431442975997925 | KNN Loss: 2.381030321121216 | CLS Loss: 0.05041273683309555\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 2.430424690246582 | KNN Loss: 2.408202886581421 | CLS Loss: 0.022221915423870087\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 2.425394296646118 | KNN Loss: 2.410294771194458 | CLS Loss: 0.015099488198757172\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 2.4843087196350098 | KNN Loss: 2.446096897125244 | CLS Loss: 0.038211796432733536\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 2.409311532974243 | KNN Loss: 2.37060546875 | CLS Loss: 0.0387059785425663\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 2.432729721069336 | KNN Loss: 2.4045157432556152 | CLS Loss: 0.028214093297719955\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 2.4636526107788086 | KNN Loss: 2.4471919536590576 | CLS Loss: 0.016460580751299858\n",
      "Epoch: 069, Loss: 2.4350, Train: 0.9949, Valid: 0.9867, Best: 0.9867\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 2.432260274887085 | KNN Loss: 2.4228570461273193 | CLS Loss: 0.009403124451637268\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 2.4109487533569336 | KNN Loss: 2.3766744136810303 | CLS Loss: 0.03427426517009735\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 2.417273759841919 | KNN Loss: 2.4070167541503906 | CLS Loss: 0.010256953537464142\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 2.4658470153808594 | KNN Loss: 2.450310230255127 | CLS Loss: 0.015536813996732235\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 2.48203182220459 | KNN Loss: 2.45424747467041 | CLS Loss: 0.027784336358308792\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 2.4262943267822266 | KNN Loss: 2.4047000408172607 | CLS Loss: 0.021594246849417686\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 2.4884867668151855 | KNN Loss: 2.4621150493621826 | CLS Loss: 0.026371732354164124\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 2.4276084899902344 | KNN Loss: 2.3973634243011475 | CLS Loss: 0.030245063826441765\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 2.4204249382019043 | KNN Loss: 2.4133591651916504 | CLS Loss: 0.007065776269882917\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 2.4462008476257324 | KNN Loss: 2.4135901927948 | CLS Loss: 0.03261066973209381\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 2.441939353942871 | KNN Loss: 2.424466609954834 | CLS Loss: 0.017472637817263603\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 2.4144415855407715 | KNN Loss: 2.403761148452759 | CLS Loss: 0.010680414736270905\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 2.419752597808838 | KNN Loss: 2.400773763656616 | CLS Loss: 0.01897875964641571\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 2.420518398284912 | KNN Loss: 2.3933231830596924 | CLS Loss: 0.027195295318961143\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 2.424140691757202 | KNN Loss: 2.3982441425323486 | CLS Loss: 0.025896547362208366\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 2.4100961685180664 | KNN Loss: 2.382460355758667 | CLS Loss: 0.027635721489787102\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 2.4490551948547363 | KNN Loss: 2.411466598510742 | CLS Loss: 0.03758860379457474\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 2.4818613529205322 | KNN Loss: 2.435157060623169 | CLS Loss: 0.04670420661568642\n",
      "Epoch: 070, Loss: 2.4339, Train: 0.9931, Valid: 0.9861, Best: 0.9867\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 2.4606618881225586 | KNN Loss: 2.4311416149139404 | CLS Loss: 0.029520196840167046\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 2.3823673725128174 | KNN Loss: 2.3637115955352783 | CLS Loss: 0.01865580305457115\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 2.465562343597412 | KNN Loss: 2.437814950942993 | CLS Loss: 0.027747416868805885\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 2.4142181873321533 | KNN Loss: 2.4068477153778076 | CLS Loss: 0.007370359264314175\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 2.425673246383667 | KNN Loss: 2.4150266647338867 | CLS Loss: 0.010646475479006767\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 2.449187994003296 | KNN Loss: 2.4110546112060547 | CLS Loss: 0.03813343495130539\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 2.416060447692871 | KNN Loss: 2.402270555496216 | CLS Loss: 0.013789922930300236\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 2.44299578666687 | KNN Loss: 2.4208362102508545 | CLS Loss: 0.022159526124596596\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 2.4427995681762695 | KNN Loss: 2.4131081104278564 | CLS Loss: 0.029691549018025398\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 2.4087092876434326 | KNN Loss: 2.3880717754364014 | CLS Loss: 0.020637542009353638\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 2.433950662612915 | KNN Loss: 2.4277710914611816 | CLS Loss: 0.0061796195805072784\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 2.4108994007110596 | KNN Loss: 2.397614002227783 | CLS Loss: 0.013285472057759762\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 2.4241106510162354 | KNN Loss: 2.415644407272339 | CLS Loss: 0.008466293103992939\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 2.4512791633605957 | KNN Loss: 2.4297661781311035 | CLS Loss: 0.021512944251298904\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 2.3903181552886963 | KNN Loss: 2.381073236465454 | CLS Loss: 0.009244897402822971\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 2.425938844680786 | KNN Loss: 2.4219601154327393 | CLS Loss: 0.003978670109063387\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 2.4390058517456055 | KNN Loss: 2.41774845123291 | CLS Loss: 0.021257309243083\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 2.4157304763793945 | KNN Loss: 2.3904802799224854 | CLS Loss: 0.025250308215618134\n",
      "Epoch: 071, Loss: 2.4317, Train: 0.9939, Valid: 0.9854, Best: 0.9867\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 2.4508960247039795 | KNN Loss: 2.423738479614258 | CLS Loss: 0.027157530188560486\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 2.431036949157715 | KNN Loss: 2.3990845680236816 | CLS Loss: 0.03195243701338768\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 2.4046168327331543 | KNN Loss: 2.3677806854248047 | CLS Loss: 0.03683607280254364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 2.430877447128296 | KNN Loss: 2.417602062225342 | CLS Loss: 0.013275275938212872\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 2.464191198348999 | KNN Loss: 2.429706573486328 | CLS Loss: 0.034484680742025375\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 2.448460340499878 | KNN Loss: 2.4159939289093018 | CLS Loss: 0.032466430217027664\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 2.4413986206054688 | KNN Loss: 2.4285240173339844 | CLS Loss: 0.012874648906290531\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 2.411278247833252 | KNN Loss: 2.4019155502319336 | CLS Loss: 0.009362760931253433\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 2.4497344493865967 | KNN Loss: 2.412018060684204 | CLS Loss: 0.03771643340587616\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 2.401552200317383 | KNN Loss: 2.382859706878662 | CLS Loss: 0.018692491576075554\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 2.404322862625122 | KNN Loss: 2.392749547958374 | CLS Loss: 0.011573205702006817\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 2.4183290004730225 | KNN Loss: 2.4142069816589355 | CLS Loss: 0.004122090060263872\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 2.423656702041626 | KNN Loss: 2.3936519622802734 | CLS Loss: 0.030004749074578285\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 2.4704911708831787 | KNN Loss: 2.4425430297851562 | CLS Loss: 0.027948131784796715\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 2.4440269470214844 | KNN Loss: 2.435171127319336 | CLS Loss: 0.008855744265019894\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 2.438822031021118 | KNN Loss: 2.433830976486206 | CLS Loss: 0.004991055000573397\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 2.4591424465179443 | KNN Loss: 2.4071202278137207 | CLS Loss: 0.05202222988009453\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 2.4638144969940186 | KNN Loss: 2.4286000728607178 | CLS Loss: 0.03521434962749481\n",
      "Epoch: 072, Loss: 2.4304, Train: 0.9937, Valid: 0.9858, Best: 0.9867\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 2.4558541774749756 | KNN Loss: 2.4250943660736084 | CLS Loss: 0.03075980953872204\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 2.463050365447998 | KNN Loss: 2.4449853897094727 | CLS Loss: 0.018064970150589943\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 2.432661533355713 | KNN Loss: 2.4125263690948486 | CLS Loss: 0.02013515494763851\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 2.4243526458740234 | KNN Loss: 2.414250612258911 | CLS Loss: 0.01010198425501585\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 2.417379140853882 | KNN Loss: 2.3934977054595947 | CLS Loss: 0.023881467059254646\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 2.476444721221924 | KNN Loss: 2.440369129180908 | CLS Loss: 0.03607554733753204\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 2.4477219581604004 | KNN Loss: 2.4393367767333984 | CLS Loss: 0.008385215885937214\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 2.4212911128997803 | KNN Loss: 2.4059064388275146 | CLS Loss: 0.015384789556264877\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 2.4689066410064697 | KNN Loss: 2.4449784755706787 | CLS Loss: 0.02392817847430706\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 2.460099935531616 | KNN Loss: 2.4539356231689453 | CLS Loss: 0.006164411548525095\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 2.4215080738067627 | KNN Loss: 2.40242075920105 | CLS Loss: 0.01908724382519722\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 2.436380386352539 | KNN Loss: 2.4024758338928223 | CLS Loss: 0.03390458598732948\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 2.433439016342163 | KNN Loss: 2.414368152618408 | CLS Loss: 0.019070833921432495\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 2.400480270385742 | KNN Loss: 2.385195016860962 | CLS Loss: 0.015285259112715721\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 2.4292221069335938 | KNN Loss: 2.4078516960144043 | CLS Loss: 0.021370425820350647\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 2.4368200302124023 | KNN Loss: 2.4068338871002197 | CLS Loss: 0.029986180365085602\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 2.4690732955932617 | KNN Loss: 2.4649689197540283 | CLS Loss: 0.00410426827147603\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 2.4380500316619873 | KNN Loss: 2.4188761711120605 | CLS Loss: 0.019173866137862206\n",
      "Epoch: 073, Loss: 2.4335, Train: 0.9929, Valid: 0.9854, Best: 0.9867\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 2.4200031757354736 | KNN Loss: 2.3901560306549072 | CLS Loss: 0.0298471562564373\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 2.425233840942383 | KNN Loss: 2.4050981998443604 | CLS Loss: 0.02013571746647358\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 2.440795660018921 | KNN Loss: 2.400787591934204 | CLS Loss: 0.040008094161748886\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 2.421691656112671 | KNN Loss: 2.418412923812866 | CLS Loss: 0.003278682939708233\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 2.440721035003662 | KNN Loss: 2.410806894302368 | CLS Loss: 0.02991417609155178\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 2.4332449436187744 | KNN Loss: 2.40429425239563 | CLS Loss: 0.02895071543753147\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 2.429455280303955 | KNN Loss: 2.4066250324249268 | CLS Loss: 0.022830167785286903\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 2.4547431468963623 | KNN Loss: 2.4461934566497803 | CLS Loss: 0.008549606427550316\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 2.3906893730163574 | KNN Loss: 2.37807297706604 | CLS Loss: 0.01261636707931757\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 2.4130725860595703 | KNN Loss: 2.368583917617798 | CLS Loss: 0.04448862001299858\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 2.4216408729553223 | KNN Loss: 2.3983192443847656 | CLS Loss: 0.023321721702814102\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 2.4292476177215576 | KNN Loss: 2.4195609092712402 | CLS Loss: 0.009686652570962906\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 2.425386667251587 | KNN Loss: 2.4053845405578613 | CLS Loss: 0.020002134144306183\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 2.424065589904785 | KNN Loss: 2.4005753993988037 | CLS Loss: 0.02349015697836876\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 2.392591714859009 | KNN Loss: 2.3808350563049316 | CLS Loss: 0.011756776832044125\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 2.427417755126953 | KNN Loss: 2.4184439182281494 | CLS Loss: 0.008973956108093262\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 2.4650137424468994 | KNN Loss: 2.4099698066711426 | CLS Loss: 0.055043965578079224\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 2.446798086166382 | KNN Loss: 2.4197397232055664 | CLS Loss: 0.02705831080675125\n",
      "Epoch: 074, Loss: 2.4275, Train: 0.9949, Valid: 0.9863, Best: 0.9867\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 2.462914228439331 | KNN Loss: 2.4465835094451904 | CLS Loss: 0.016330711543560028\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 2.457885265350342 | KNN Loss: 2.437389612197876 | CLS Loss: 0.020495573058724403\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 2.484945297241211 | KNN Loss: 2.4655215740203857 | CLS Loss: 0.019423779100179672\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 2.406747341156006 | KNN Loss: 2.390059471130371 | CLS Loss: 0.016687916591763496\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 2.4676012992858887 | KNN Loss: 2.436246871948242 | CLS Loss: 0.03135434538125992\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 2.417682647705078 | KNN Loss: 2.413179874420166 | CLS Loss: 0.004502712283283472\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 2.4223477840423584 | KNN Loss: 2.3893280029296875 | CLS Loss: 0.033019863069057465\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 2.4647512435913086 | KNN Loss: 2.4262619018554688 | CLS Loss: 0.03848936781287193\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 2.417300224304199 | KNN Loss: 2.408525228500366 | CLS Loss: 0.008775027468800545\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 2.4328410625457764 | KNN Loss: 2.402888536453247 | CLS Loss: 0.029952451586723328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 2.4048728942871094 | KNN Loss: 2.392854928970337 | CLS Loss: 0.012018021196126938\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 2.466926336288452 | KNN Loss: 2.4456522464752197 | CLS Loss: 0.02127411775290966\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 2.405311107635498 | KNN Loss: 2.393173933029175 | CLS Loss: 0.012137136422097683\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 2.438831329345703 | KNN Loss: 2.384939432144165 | CLS Loss: 0.05389198288321495\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 2.4550788402557373 | KNN Loss: 2.433105230331421 | CLS Loss: 0.021973541006445885\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 2.463841676712036 | KNN Loss: 2.4456517696380615 | CLS Loss: 0.01818997785449028\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 2.4163732528686523 | KNN Loss: 2.3851430416107178 | CLS Loss: 0.03123011253774166\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 2.428574323654175 | KNN Loss: 2.4097282886505127 | CLS Loss: 0.018845977261662483\n",
      "Epoch: 075, Loss: 2.4299, Train: 0.9948, Valid: 0.9858, Best: 0.9867\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 2.4252541065216064 | KNN Loss: 2.4133567810058594 | CLS Loss: 0.011897347867488861\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 2.4428064823150635 | KNN Loss: 2.4118120670318604 | CLS Loss: 0.030994322150945663\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 2.4687912464141846 | KNN Loss: 2.4488940238952637 | CLS Loss: 0.01989719830453396\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 2.423112154006958 | KNN Loss: 2.398907423019409 | CLS Loss: 0.024204745888710022\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 2.4570415019989014 | KNN Loss: 2.4511935710906982 | CLS Loss: 0.00584784708917141\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 2.4052159786224365 | KNN Loss: 2.384458065032959 | CLS Loss: 0.020757872611284256\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 2.430262327194214 | KNN Loss: 2.395458698272705 | CLS Loss: 0.03480374068021774\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 2.460852861404419 | KNN Loss: 2.437981605529785 | CLS Loss: 0.022871224209666252\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 2.438652753829956 | KNN Loss: 2.4194326400756836 | CLS Loss: 0.019220076501369476\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 2.4266393184661865 | KNN Loss: 2.401512622833252 | CLS Loss: 0.025126751512289047\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 2.460893392562866 | KNN Loss: 2.444366216659546 | CLS Loss: 0.016527120023965836\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 2.3948419094085693 | KNN Loss: 2.377441883087158 | CLS Loss: 0.01740000955760479\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 2.4267492294311523 | KNN Loss: 2.40464448928833 | CLS Loss: 0.022104837000370026\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 2.428025484085083 | KNN Loss: 2.4173145294189453 | CLS Loss: 0.010711056180298328\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 2.4075565338134766 | KNN Loss: 2.375246524810791 | CLS Loss: 0.03231003135442734\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 2.414405584335327 | KNN Loss: 2.391542911529541 | CLS Loss: 0.022862620651721954\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 2.451169967651367 | KNN Loss: 2.4195303916931152 | CLS Loss: 0.03163962811231613\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 2.4512667655944824 | KNN Loss: 2.440016746520996 | CLS Loss: 0.011250079609453678\n",
      "Epoch: 076, Loss: 2.4357, Train: 0.9940, Valid: 0.9867, Best: 0.9867\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 2.404576539993286 | KNN Loss: 2.4006175994873047 | CLS Loss: 0.003958948887884617\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 2.4235265254974365 | KNN Loss: 2.396583318710327 | CLS Loss: 0.026943160220980644\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 2.4587931632995605 | KNN Loss: 2.427905559539795 | CLS Loss: 0.03088749758899212\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 2.435274839401245 | KNN Loss: 2.4080190658569336 | CLS Loss: 0.02725580707192421\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 2.4427974224090576 | KNN Loss: 2.41975998878479 | CLS Loss: 0.0230374988168478\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 2.4586305618286133 | KNN Loss: 2.447791337966919 | CLS Loss: 0.010839305818080902\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 2.4418861865997314 | KNN Loss: 2.4394967555999756 | CLS Loss: 0.002389435423538089\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 2.411167860031128 | KNN Loss: 2.3939239978790283 | CLS Loss: 0.01724376156926155\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 2.4399092197418213 | KNN Loss: 2.424180269241333 | CLS Loss: 0.01572898030281067\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 2.404137134552002 | KNN Loss: 2.3820302486419678 | CLS Loss: 0.022106848657131195\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 2.411417007446289 | KNN Loss: 2.3836770057678223 | CLS Loss: 0.02774001657962799\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 2.407421112060547 | KNN Loss: 2.3787970542907715 | CLS Loss: 0.02862415835261345\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 2.4134931564331055 | KNN Loss: 2.391511917114258 | CLS Loss: 0.02198135294020176\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 2.456270217895508 | KNN Loss: 2.418639898300171 | CLS Loss: 0.037630390375852585\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 2.435772180557251 | KNN Loss: 2.3917903900146484 | CLS Loss: 0.04398178681731224\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 2.411569356918335 | KNN Loss: 2.375725507736206 | CLS Loss: 0.035843830555677414\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 2.476943016052246 | KNN Loss: 2.4517018795013428 | CLS Loss: 0.025241145864129066\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 2.448662519454956 | KNN Loss: 2.423935890197754 | CLS Loss: 0.024726521223783493\n",
      "Epoch: 077, Loss: 2.4312, Train: 0.9942, Valid: 0.9865, Best: 0.9867\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 2.4159440994262695 | KNN Loss: 2.384615182876587 | CLS Loss: 0.03132893517613411\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 2.4515902996063232 | KNN Loss: 2.4292874336242676 | CLS Loss: 0.022302774712443352\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 2.4064762592315674 | KNN Loss: 2.3856966495513916 | CLS Loss: 0.020779650658369064\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 2.3866281509399414 | KNN Loss: 2.3719141483306885 | CLS Loss: 0.014714105054736137\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 2.44134521484375 | KNN Loss: 2.4304513931274414 | CLS Loss: 0.010893774218857288\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 2.4228618144989014 | KNN Loss: 2.400294065475464 | CLS Loss: 0.022567829117178917\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 2.4480252265930176 | KNN Loss: 2.4213614463806152 | CLS Loss: 0.02666378580033779\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 2.40741229057312 | KNN Loss: 2.383028984069824 | CLS Loss: 0.024383366107940674\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 2.432704210281372 | KNN Loss: 2.3891122341156006 | CLS Loss: 0.04359201341867447\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 2.430842638015747 | KNN Loss: 2.4210898876190186 | CLS Loss: 0.009752854704856873\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 2.42968487739563 | KNN Loss: 2.4039173126220703 | CLS Loss: 0.025767521932721138\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 2.421095848083496 | KNN Loss: 2.3985958099365234 | CLS Loss: 0.022499961778521538\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 2.4360883235931396 | KNN Loss: 2.423821449279785 | CLS Loss: 0.012266863137483597\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 2.434502363204956 | KNN Loss: 2.3943004608154297 | CLS Loss: 0.0402018241584301\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 2.429227113723755 | KNN Loss: 2.3876659870147705 | CLS Loss: 0.04156104102730751\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 2.43381404876709 | KNN Loss: 2.4157304763793945 | CLS Loss: 0.018083637580275536\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 2.3998730182647705 | KNN Loss: 2.389246702194214 | CLS Loss: 0.010626432485878468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 2.4345672130584717 | KNN Loss: 2.4214274883270264 | CLS Loss: 0.013139664195477962\n",
      "Epoch: 078, Loss: 2.4296, Train: 0.9949, Valid: 0.9866, Best: 0.9867\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 2.4269144535064697 | KNN Loss: 2.4038190841674805 | CLS Loss: 0.023095306009054184\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 2.443507432937622 | KNN Loss: 2.431255340576172 | CLS Loss: 0.012252112850546837\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 2.4081921577453613 | KNN Loss: 2.3945302963256836 | CLS Loss: 0.013661973178386688\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 2.4331908226013184 | KNN Loss: 2.412888526916504 | CLS Loss: 0.020302342250943184\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 2.438342332839966 | KNN Loss: 2.4174304008483887 | CLS Loss: 0.02091195620596409\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 2.4545767307281494 | KNN Loss: 2.4238579273223877 | CLS Loss: 0.03071880340576172\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 2.414280652999878 | KNN Loss: 2.3964807987213135 | CLS Loss: 0.01779991388320923\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 2.4564390182495117 | KNN Loss: 2.446226119995117 | CLS Loss: 0.010212852619588375\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 2.4290363788604736 | KNN Loss: 2.3774611949920654 | CLS Loss: 0.051575250923633575\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 2.421854019165039 | KNN Loss: 2.4126803874969482 | CLS Loss: 0.009173734113574028\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 2.4420602321624756 | KNN Loss: 2.4211928844451904 | CLS Loss: 0.020867442712187767\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 2.4517645835876465 | KNN Loss: 2.4262821674346924 | CLS Loss: 0.02548239380121231\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 2.4332923889160156 | KNN Loss: 2.427473783493042 | CLS Loss: 0.005818612407892942\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 2.4107890129089355 | KNN Loss: 2.3845205307006836 | CLS Loss: 0.026268571615219116\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 2.4601144790649414 | KNN Loss: 2.429358959197998 | CLS Loss: 0.030755508691072464\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 2.3994946479797363 | KNN Loss: 2.393627166748047 | CLS Loss: 0.0058674924075603485\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 2.4148311614990234 | KNN Loss: 2.374577283859253 | CLS Loss: 0.04025391489267349\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 2.420579671859741 | KNN Loss: 2.4057233333587646 | CLS Loss: 0.014856230467557907\n",
      "Epoch: 079, Loss: 2.4273, Train: 0.9929, Valid: 0.9852, Best: 0.9867\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 2.463857889175415 | KNN Loss: 2.4277517795562744 | CLS Loss: 0.03610621765255928\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 2.4720566272735596 | KNN Loss: 2.4670791625976562 | CLS Loss: 0.004977429751306772\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 2.4772026538848877 | KNN Loss: 2.4461734294891357 | CLS Loss: 0.031029261648654938\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 2.4199225902557373 | KNN Loss: 2.3938772678375244 | CLS Loss: 0.026045437902212143\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 2.405648946762085 | KNN Loss: 2.3979036808013916 | CLS Loss: 0.0077453488484025\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 2.4088566303253174 | KNN Loss: 2.38348650932312 | CLS Loss: 0.02537006326019764\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 2.3924663066864014 | KNN Loss: 2.367201566696167 | CLS Loss: 0.02526470646262169\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 2.4387035369873047 | KNN Loss: 2.4316742420196533 | CLS Loss: 0.007029266096651554\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 2.4193928241729736 | KNN Loss: 2.3886847496032715 | CLS Loss: 0.030708057805895805\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 2.409465789794922 | KNN Loss: 2.396921396255493 | CLS Loss: 0.012544331140816212\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 2.4186112880706787 | KNN Loss: 2.380492925643921 | CLS Loss: 0.03811844065785408\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 2.4212229251861572 | KNN Loss: 2.4083786010742188 | CLS Loss: 0.012844322249293327\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 2.42849063873291 | KNN Loss: 2.4201478958129883 | CLS Loss: 0.008342721499502659\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 2.4148805141448975 | KNN Loss: 2.3959319591522217 | CLS Loss: 0.018948586657643318\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 2.4129137992858887 | KNN Loss: 2.395125389099121 | CLS Loss: 0.017788508906960487\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 2.4068658351898193 | KNN Loss: 2.3859548568725586 | CLS Loss: 0.02091105282306671\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 2.4250125885009766 | KNN Loss: 2.407696485519409 | CLS Loss: 0.017316032201051712\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 2.4179227352142334 | KNN Loss: 2.4146506786346436 | CLS Loss: 0.003272129688411951\n",
      "Epoch: 080, Loss: 2.4279, Train: 0.9944, Valid: 0.9857, Best: 0.9867\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 2.4242541790008545 | KNN Loss: 2.4107747077941895 | CLS Loss: 0.01347955223172903\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 2.423513889312744 | KNN Loss: 2.4002838134765625 | CLS Loss: 0.023230092599987984\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 2.43753981590271 | KNN Loss: 2.41744327545166 | CLS Loss: 0.020096631720662117\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 2.439351797103882 | KNN Loss: 2.423398494720459 | CLS Loss: 0.015953265130519867\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 2.404721736907959 | KNN Loss: 2.3770854473114014 | CLS Loss: 0.027636276558041573\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 2.4229249954223633 | KNN Loss: 2.390876293182373 | CLS Loss: 0.032048746943473816\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 2.4060144424438477 | KNN Loss: 2.3905978202819824 | CLS Loss: 0.015416636131703854\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 2.4481594562530518 | KNN Loss: 2.4205851554870605 | CLS Loss: 0.02757418341934681\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 2.4155898094177246 | KNN Loss: 2.4031107425689697 | CLS Loss: 0.012479133903980255\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 2.465616226196289 | KNN Loss: 2.4068217277526855 | CLS Loss: 0.05879443138837814\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 2.435394048690796 | KNN Loss: 2.4255709648132324 | CLS Loss: 0.009823192842304707\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 2.437176465988159 | KNN Loss: 2.412214517593384 | CLS Loss: 0.024961955845355988\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 2.422083854675293 | KNN Loss: 2.418897867202759 | CLS Loss: 0.0031859194859862328\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 2.4320783615112305 | KNN Loss: 2.419640302658081 | CLS Loss: 0.012437941506505013\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 2.4295904636383057 | KNN Loss: 2.4116382598876953 | CLS Loss: 0.01795227825641632\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 2.4078433513641357 | KNN Loss: 2.391233444213867 | CLS Loss: 0.016609935089945793\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 2.420330286026001 | KNN Loss: 2.406031370162964 | CLS Loss: 0.014298822730779648\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 2.431641101837158 | KNN Loss: 2.4214417934417725 | CLS Loss: 0.010199405252933502\n",
      "Epoch: 081, Loss: 2.4265, Train: 0.9949, Valid: 0.9868, Best: 0.9868\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 2.4493939876556396 | KNN Loss: 2.401859998703003 | CLS Loss: 0.047534000128507614\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 2.434795618057251 | KNN Loss: 2.417527198791504 | CLS Loss: 0.017268329858779907\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 2.4365453720092773 | KNN Loss: 2.4103915691375732 | CLS Loss: 0.026153869926929474\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 2.4923927783966064 | KNN Loss: 2.471040725708008 | CLS Loss: 0.02135212905704975\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 2.4417619705200195 | KNN Loss: 2.411979913711548 | CLS Loss: 0.029782166704535484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 2.4492440223693848 | KNN Loss: 2.4388415813446045 | CLS Loss: 0.010402447544038296\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 2.4688706398010254 | KNN Loss: 2.4586684703826904 | CLS Loss: 0.010202163830399513\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 2.463597297668457 | KNN Loss: 2.4525861740112305 | CLS Loss: 0.011011175811290741\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 2.415379285812378 | KNN Loss: 2.375894069671631 | CLS Loss: 0.03948516771197319\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 2.419111728668213 | KNN Loss: 2.385976791381836 | CLS Loss: 0.033134832978248596\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 2.4012298583984375 | KNN Loss: 2.3946969509124756 | CLS Loss: 0.006532819475978613\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 2.432478904724121 | KNN Loss: 2.3923470973968506 | CLS Loss: 0.04013191908597946\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 2.382209300994873 | KNN Loss: 2.378948450088501 | CLS Loss: 0.003260921686887741\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 2.3974666595458984 | KNN Loss: 2.3760006427764893 | CLS Loss: 0.021465973928570747\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 2.4078116416931152 | KNN Loss: 2.382284641265869 | CLS Loss: 0.0255269818007946\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 2.381436586380005 | KNN Loss: 2.376091480255127 | CLS Loss: 0.005345196463167667\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 2.441145420074463 | KNN Loss: 2.4243004322052 | CLS Loss: 0.01684500090777874\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 2.4174158573150635 | KNN Loss: 2.4114909172058105 | CLS Loss: 0.005924996919929981\n",
      "Epoch: 082, Loss: 2.4261, Train: 0.9940, Valid: 0.9864, Best: 0.9868\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 2.3868985176086426 | KNN Loss: 2.372239351272583 | CLS Loss: 0.014659273438155651\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 2.4332175254821777 | KNN Loss: 2.40969181060791 | CLS Loss: 0.023525739088654518\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 2.456768274307251 | KNN Loss: 2.4243853092193604 | CLS Loss: 0.03238304704427719\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 2.41518235206604 | KNN Loss: 2.3866167068481445 | CLS Loss: 0.028565607964992523\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 2.431678295135498 | KNN Loss: 2.410055160522461 | CLS Loss: 0.02162306010723114\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 2.4501841068267822 | KNN Loss: 2.4314889907836914 | CLS Loss: 0.018695032224059105\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 2.442430019378662 | KNN Loss: 2.432474136352539 | CLS Loss: 0.00995589978992939\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 2.448720932006836 | KNN Loss: 2.4344658851623535 | CLS Loss: 0.014255020767450333\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 2.4173333644866943 | KNN Loss: 2.410019874572754 | CLS Loss: 0.007313522510230541\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 2.42250394821167 | KNN Loss: 2.4184069633483887 | CLS Loss: 0.0040968721732497215\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 2.4358396530151367 | KNN Loss: 2.422960042953491 | CLS Loss: 0.012879644520580769\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 2.407416820526123 | KNN Loss: 2.3795533180236816 | CLS Loss: 0.02786349132657051\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 2.4032368659973145 | KNN Loss: 2.393059730529785 | CLS Loss: 0.01017711777240038\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 2.4287283420562744 | KNN Loss: 2.4096195697784424 | CLS Loss: 0.019108697772026062\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 2.4158380031585693 | KNN Loss: 2.4069368839263916 | CLS Loss: 0.008901174180209637\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 2.4124410152435303 | KNN Loss: 2.4062893390655518 | CLS Loss: 0.0061517744325101376\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 2.450425863265991 | KNN Loss: 2.4422736167907715 | CLS Loss: 0.008152189664542675\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 2.480229139328003 | KNN Loss: 2.4574952125549316 | CLS Loss: 0.022733967751264572\n",
      "Epoch: 083, Loss: 2.4259, Train: 0.9951, Valid: 0.9864, Best: 0.9868\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 2.412813186645508 | KNN Loss: 2.3919241428375244 | CLS Loss: 0.02088898792862892\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 2.4288930892944336 | KNN Loss: 2.4181573390960693 | CLS Loss: 0.010735787451267242\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 2.4425487518310547 | KNN Loss: 2.428326368331909 | CLS Loss: 0.014222404919564724\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 2.4647860527038574 | KNN Loss: 2.4487030506134033 | CLS Loss: 0.01608297787606716\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 2.4355971813201904 | KNN Loss: 2.430009365081787 | CLS Loss: 0.0055877272970974445\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 2.4174747467041016 | KNN Loss: 2.4001073837280273 | CLS Loss: 0.01736743189394474\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 2.426222801208496 | KNN Loss: 2.4084813594818115 | CLS Loss: 0.017741544172167778\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 2.3838508129119873 | KNN Loss: 2.3640005588531494 | CLS Loss: 0.01985033042728901\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 2.4175822734832764 | KNN Loss: 2.40400767326355 | CLS Loss: 0.013574633747339249\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 2.454449415206909 | KNN Loss: 2.4419331550598145 | CLS Loss: 0.012516341172158718\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 2.4080772399902344 | KNN Loss: 2.392275094985962 | CLS Loss: 0.015802260488271713\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 2.4594829082489014 | KNN Loss: 2.4439895153045654 | CLS Loss: 0.015493465587496758\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 2.447160005569458 | KNN Loss: 2.431197166442871 | CLS Loss: 0.015962883830070496\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 2.4238455295562744 | KNN Loss: 2.3955466747283936 | CLS Loss: 0.028298960998654366\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 2.4226295948028564 | KNN Loss: 2.4100146293640137 | CLS Loss: 0.012614956125617027\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 2.4462006092071533 | KNN Loss: 2.4334113597869873 | CLS Loss: 0.012789283879101276\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 2.415708303451538 | KNN Loss: 2.378096342086792 | CLS Loss: 0.037612076848745346\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 2.473864793777466 | KNN Loss: 2.4468703269958496 | CLS Loss: 0.02699454128742218\n",
      "Epoch: 084, Loss: 2.4338, Train: 0.9953, Valid: 0.9860, Best: 0.9868\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 2.403575897216797 | KNN Loss: 2.392083168029785 | CLS Loss: 0.011492841877043247\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 2.430083751678467 | KNN Loss: 2.4116945266723633 | CLS Loss: 0.01838914304971695\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 2.394568920135498 | KNN Loss: 2.3841891288757324 | CLS Loss: 0.010379791259765625\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 2.390519142150879 | KNN Loss: 2.3701674938201904 | CLS Loss: 0.02035163715481758\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 2.394160270690918 | KNN Loss: 2.3789360523223877 | CLS Loss: 0.01522426400333643\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 2.444448947906494 | KNN Loss: 2.4347400665283203 | CLS Loss: 0.009708830155432224\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 2.4249982833862305 | KNN Loss: 2.4082024097442627 | CLS Loss: 0.01679578237235546\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 2.4414846897125244 | KNN Loss: 2.4266409873962402 | CLS Loss: 0.014843733981251717\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 2.438030958175659 | KNN Loss: 2.4308881759643555 | CLS Loss: 0.007142715621739626\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 2.390845537185669 | KNN Loss: 2.379204511642456 | CLS Loss: 0.011641106568276882\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 2.4277703762054443 | KNN Loss: 2.411407232284546 | CLS Loss: 0.016363177448511124\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 2.3785409927368164 | KNN Loss: 2.3606457710266113 | CLS Loss: 0.017895232886075974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 2.4342520236968994 | KNN Loss: 2.411630868911743 | CLS Loss: 0.02262107841670513\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 2.422337055206299 | KNN Loss: 2.3854331970214844 | CLS Loss: 0.036903850734233856\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 2.418377161026001 | KNN Loss: 2.4061927795410156 | CLS Loss: 0.01218440756201744\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 2.418635845184326 | KNN Loss: 2.3924341201782227 | CLS Loss: 0.026201780885457993\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 2.4250240325927734 | KNN Loss: 2.4066641330718994 | CLS Loss: 0.01835988275706768\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 2.446455717086792 | KNN Loss: 2.4265034198760986 | CLS Loss: 0.01995234563946724\n",
      "Epoch: 085, Loss: 2.4278, Train: 0.9949, Valid: 0.9858, Best: 0.9868\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 2.418454647064209 | KNN Loss: 2.409790277481079 | CLS Loss: 0.008664438501000404\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 2.4365193843841553 | KNN Loss: 2.41831374168396 | CLS Loss: 0.018205655738711357\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 2.424628973007202 | KNN Loss: 2.3997693061828613 | CLS Loss: 0.024859778583049774\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 2.4393115043640137 | KNN Loss: 2.4144413471221924 | CLS Loss: 0.02487027458846569\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 2.4389519691467285 | KNN Loss: 2.4111335277557373 | CLS Loss: 0.027818482369184494\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 2.417476177215576 | KNN Loss: 2.410374641418457 | CLS Loss: 0.007101587485522032\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 2.426421880722046 | KNN Loss: 2.4060802459716797 | CLS Loss: 0.020341718569397926\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 2.429872751235962 | KNN Loss: 2.425999164581299 | CLS Loss: 0.0038734993431717157\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 2.396148443222046 | KNN Loss: 2.385228395462036 | CLS Loss: 0.01092013344168663\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 2.4230761528015137 | KNN Loss: 2.408824920654297 | CLS Loss: 0.014251167885959148\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 2.462089776992798 | KNN Loss: 2.452375650405884 | CLS Loss: 0.009714019484817982\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 2.4203855991363525 | KNN Loss: 2.403576135635376 | CLS Loss: 0.01680951751768589\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 2.3881583213806152 | KNN Loss: 2.372910499572754 | CLS Loss: 0.015247717499732971\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 2.4153690338134766 | KNN Loss: 2.3889989852905273 | CLS Loss: 0.02637006901204586\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 2.425896644592285 | KNN Loss: 2.406289577484131 | CLS Loss: 0.01960710622370243\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 2.4241442680358887 | KNN Loss: 2.4091286659240723 | CLS Loss: 0.015015551820397377\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 2.4187698364257812 | KNN Loss: 2.4097049236297607 | CLS Loss: 0.009064898826181889\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 2.449474811553955 | KNN Loss: 2.439317464828491 | CLS Loss: 0.010157366283237934\n",
      "Epoch: 086, Loss: 2.4297, Train: 0.9933, Valid: 0.9844, Best: 0.9868\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 2.485520601272583 | KNN Loss: 2.4594080448150635 | CLS Loss: 0.026112494990229607\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 2.4640026092529297 | KNN Loss: 2.455209255218506 | CLS Loss: 0.008793411776423454\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 2.4343748092651367 | KNN Loss: 2.4089038372039795 | CLS Loss: 0.025471016764640808\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 2.4132001399993896 | KNN Loss: 2.4017274379730225 | CLS Loss: 0.01147276908159256\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 2.381560802459717 | KNN Loss: 2.375696897506714 | CLS Loss: 0.005863875616341829\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 2.4187510013580322 | KNN Loss: 2.39953875541687 | CLS Loss: 0.019212333485484123\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 2.4314191341400146 | KNN Loss: 2.4204728603363037 | CLS Loss: 0.010946357622742653\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 2.4411795139312744 | KNN Loss: 2.392598867416382 | CLS Loss: 0.04858054593205452\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 2.4321630001068115 | KNN Loss: 2.419875383377075 | CLS Loss: 0.012287663295865059\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 2.417719602584839 | KNN Loss: 2.401172637939453 | CLS Loss: 0.016546903178095818\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 2.409719467163086 | KNN Loss: 2.388190507888794 | CLS Loss: 0.021528903394937515\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 2.383378028869629 | KNN Loss: 2.358842134475708 | CLS Loss: 0.02453584223985672\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 2.427358865737915 | KNN Loss: 2.3948261737823486 | CLS Loss: 0.03253263980150223\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 2.455587863922119 | KNN Loss: 2.4133665561676025 | CLS Loss: 0.042221229523420334\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 2.421497106552124 | KNN Loss: 2.3823482990264893 | CLS Loss: 0.03914890065789223\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 2.404212474822998 | KNN Loss: 2.398617744445801 | CLS Loss: 0.0055946786887943745\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 2.4744532108306885 | KNN Loss: 2.4493656158447266 | CLS Loss: 0.02508755959570408\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 2.4188694953918457 | KNN Loss: 2.397836446762085 | CLS Loss: 0.02103300765156746\n",
      "Epoch: 087, Loss: 2.4293, Train: 0.9942, Valid: 0.9848, Best: 0.9868\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 2.389002799987793 | KNN Loss: 2.3758912086486816 | CLS Loss: 0.013111695647239685\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 2.4067447185516357 | KNN Loss: 2.388371467590332 | CLS Loss: 0.018373243510723114\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 2.3843908309936523 | KNN Loss: 2.375612497329712 | CLS Loss: 0.008778449147939682\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 2.4308297634124756 | KNN Loss: 2.41969895362854 | CLS Loss: 0.011130747385323048\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 2.4353652000427246 | KNN Loss: 2.414954662322998 | CLS Loss: 0.0204104483127594\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 2.3886821269989014 | KNN Loss: 2.379884719848633 | CLS Loss: 0.008797376416623592\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 2.3959312438964844 | KNN Loss: 2.377573013305664 | CLS Loss: 0.018358243629336357\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 2.3989319801330566 | KNN Loss: 2.387899160385132 | CLS Loss: 0.011032787151634693\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 2.441786766052246 | KNN Loss: 2.4164657592773438 | CLS Loss: 0.025321049615740776\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 2.4351236820220947 | KNN Loss: 2.4208877086639404 | CLS Loss: 0.014235997572541237\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 2.4519917964935303 | KNN Loss: 2.4259142875671387 | CLS Loss: 0.026077616959810257\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 2.4073712825775146 | KNN Loss: 2.3967697620391846 | CLS Loss: 0.010601628571748734\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 2.388624668121338 | KNN Loss: 2.3853800296783447 | CLS Loss: 0.003244734602048993\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 2.385565996170044 | KNN Loss: 2.3731744289398193 | CLS Loss: 0.012391645461320877\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 2.4145634174346924 | KNN Loss: 2.404343605041504 | CLS Loss: 0.010219914838671684\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 2.415847063064575 | KNN Loss: 2.3959953784942627 | CLS Loss: 0.01985178329050541\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 2.4255006313323975 | KNN Loss: 2.4041991233825684 | CLS Loss: 0.021301567554473877\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 2.410712718963623 | KNN Loss: 2.382460832595825 | CLS Loss: 0.028251973912119865\n",
      "Epoch: 088, Loss: 2.4239, Train: 0.9932, Valid: 0.9852, Best: 0.9868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 2.4605512619018555 | KNN Loss: 2.4267759323120117 | CLS Loss: 0.03377522528171539\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 2.4157261848449707 | KNN Loss: 2.3930156230926514 | CLS Loss: 0.022710641846060753\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 2.409142255783081 | KNN Loss: 2.394427537918091 | CLS Loss: 0.014714610762894154\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 2.4521121978759766 | KNN Loss: 2.440814733505249 | CLS Loss: 0.011297388933598995\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 2.4288036823272705 | KNN Loss: 2.4195895195007324 | CLS Loss: 0.009214275516569614\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 2.4774787425994873 | KNN Loss: 2.464404582977295 | CLS Loss: 0.013074223883450031\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 2.4256155490875244 | KNN Loss: 2.4093194007873535 | CLS Loss: 0.01629617251455784\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 2.41373872756958 | KNN Loss: 2.387627124786377 | CLS Loss: 0.026111576706171036\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 2.4169747829437256 | KNN Loss: 2.3885860443115234 | CLS Loss: 0.02838876098394394\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 2.4166743755340576 | KNN Loss: 2.4031643867492676 | CLS Loss: 0.013509941287338734\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 2.411957263946533 | KNN Loss: 2.3971266746520996 | CLS Loss: 0.014830607920885086\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 2.4154839515686035 | KNN Loss: 2.3988900184631348 | CLS Loss: 0.016593975946307182\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 2.4295694828033447 | KNN Loss: 2.414963483810425 | CLS Loss: 0.014606013894081116\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 2.4352800846099854 | KNN Loss: 2.4067156314849854 | CLS Loss: 0.028564538806676865\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 2.4008655548095703 | KNN Loss: 2.3932437896728516 | CLS Loss: 0.007621668744832277\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 2.423780918121338 | KNN Loss: 2.4138503074645996 | CLS Loss: 0.009930649772286415\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 2.4010565280914307 | KNN Loss: 2.3682701587677 | CLS Loss: 0.032786451280117035\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 2.450146436691284 | KNN Loss: 2.413163661956787 | CLS Loss: 0.03698276728391647\n",
      "Epoch: 089, Loss: 2.4261, Train: 0.9955, Valid: 0.9866, Best: 0.9868\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 2.436277151107788 | KNN Loss: 2.414665699005127 | CLS Loss: 0.021611373871564865\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 2.448225736618042 | KNN Loss: 2.4334511756896973 | CLS Loss: 0.014774498529732227\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 2.455449342727661 | KNN Loss: 2.430850028991699 | CLS Loss: 0.02459939569234848\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 2.4453675746917725 | KNN Loss: 2.431770086288452 | CLS Loss: 0.013597599230706692\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 2.4214537143707275 | KNN Loss: 2.4066693782806396 | CLS Loss: 0.014784290455281734\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 2.452345609664917 | KNN Loss: 2.4270849227905273 | CLS Loss: 0.025260699912905693\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 2.4053447246551514 | KNN Loss: 2.402984142303467 | CLS Loss: 0.0023605397436767817\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 2.448349714279175 | KNN Loss: 2.4267332553863525 | CLS Loss: 0.021616490557789803\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 2.388127326965332 | KNN Loss: 2.3711609840393066 | CLS Loss: 0.016966382041573524\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 2.4279956817626953 | KNN Loss: 2.424307346343994 | CLS Loss: 0.003688412019982934\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 2.4327125549316406 | KNN Loss: 2.407820463180542 | CLS Loss: 0.02489207684993744\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 2.4188385009765625 | KNN Loss: 2.39532208442688 | CLS Loss: 0.02351643331348896\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 2.4247896671295166 | KNN Loss: 2.408782482147217 | CLS Loss: 0.016007274389266968\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 2.4349963665008545 | KNN Loss: 2.3878350257873535 | CLS Loss: 0.04716140776872635\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 2.449065923690796 | KNN Loss: 2.424663782119751 | CLS Loss: 0.024402044713497162\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 2.404723644256592 | KNN Loss: 2.3943357467651367 | CLS Loss: 0.01038795243948698\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 2.4923789501190186 | KNN Loss: 2.454679250717163 | CLS Loss: 0.03769979625940323\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 2.415048122406006 | KNN Loss: 2.4008634090423584 | CLS Loss: 0.014184809289872646\n",
      "Epoch: 090, Loss: 2.4264, Train: 0.9945, Valid: 0.9853, Best: 0.9868\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 2.431771993637085 | KNN Loss: 2.421809673309326 | CLS Loss: 0.009962239302694798\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 2.4350805282592773 | KNN Loss: 2.4106178283691406 | CLS Loss: 0.024462657049298286\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 2.4005110263824463 | KNN Loss: 2.3700807094573975 | CLS Loss: 0.030430255457758904\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 2.3781869411468506 | KNN Loss: 2.359769344329834 | CLS Loss: 0.018417660146951675\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 2.4188570976257324 | KNN Loss: 2.392329454421997 | CLS Loss: 0.026527540758252144\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 2.4174184799194336 | KNN Loss: 2.403273582458496 | CLS Loss: 0.014144925400614738\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 2.4107422828674316 | KNN Loss: 2.3905434608459473 | CLS Loss: 0.02019878476858139\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 2.417534112930298 | KNN Loss: 2.4116971492767334 | CLS Loss: 0.005836863536387682\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 2.4738526344299316 | KNN Loss: 2.4399290084838867 | CLS Loss: 0.033923737704753876\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 2.4455766677856445 | KNN Loss: 2.422811508178711 | CLS Loss: 0.02276507206261158\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 2.42620587348938 | KNN Loss: 2.412315607070923 | CLS Loss: 0.013890240341424942\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 2.4471471309661865 | KNN Loss: 2.442282199859619 | CLS Loss: 0.004865017253905535\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 2.388862371444702 | KNN Loss: 2.363386392593384 | CLS Loss: 0.025475909933447838\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 2.400294542312622 | KNN Loss: 2.3981635570526123 | CLS Loss: 0.0021310909651219845\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 2.415863275527954 | KNN Loss: 2.4076809883117676 | CLS Loss: 0.008182370103895664\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 2.408967971801758 | KNN Loss: 2.3908987045288086 | CLS Loss: 0.01806928962469101\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 2.4750797748565674 | KNN Loss: 2.46661376953125 | CLS Loss: 0.008465909399092197\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 2.4349803924560547 | KNN Loss: 2.4107086658477783 | CLS Loss: 0.02427171729505062\n",
      "Epoch: 091, Loss: 2.4264, Train: 0.9948, Valid: 0.9861, Best: 0.9868\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 2.4111762046813965 | KNN Loss: 2.402876615524292 | CLS Loss: 0.008299472741782665\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 2.4274818897247314 | KNN Loss: 2.4194159507751465 | CLS Loss: 0.008065820671617985\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 2.436587333679199 | KNN Loss: 2.4029157161712646 | CLS Loss: 0.033671654760837555\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 2.427401542663574 | KNN Loss: 2.4048516750335693 | CLS Loss: 0.022549953311681747\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 2.4042582511901855 | KNN Loss: 2.3729002475738525 | CLS Loss: 0.03135791793465614\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 2.4222493171691895 | KNN Loss: 2.4110631942749023 | CLS Loss: 0.01118618343025446\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 2.436188220977783 | KNN Loss: 2.423689842224121 | CLS Loss: 0.012498417869210243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 2.427361249923706 | KNN Loss: 2.412095308303833 | CLS Loss: 0.015265850350260735\n",
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 2.4231443405151367 | KNN Loss: 2.3930857181549072 | CLS Loss: 0.030058644711971283\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 2.4359352588653564 | KNN Loss: 2.4269769191741943 | CLS Loss: 0.008958343416452408\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 2.4010519981384277 | KNN Loss: 2.3887932300567627 | CLS Loss: 0.012258786708116531\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 2.415271282196045 | KNN Loss: 2.399458408355713 | CLS Loss: 0.01581294648349285\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 2.4276633262634277 | KNN Loss: 2.4040791988372803 | CLS Loss: 0.02358406037092209\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 2.4201266765594482 | KNN Loss: 2.3990988731384277 | CLS Loss: 0.021027911454439163\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 2.4096932411193848 | KNN Loss: 2.393637180328369 | CLS Loss: 0.016056137159466743\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 2.4366238117218018 | KNN Loss: 2.4129438400268555 | CLS Loss: 0.023679859936237335\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 2.422471284866333 | KNN Loss: 2.4087889194488525 | CLS Loss: 0.013682285323739052\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 2.401674509048462 | KNN Loss: 2.3834311962127686 | CLS Loss: 0.01824343018233776\n",
      "Epoch: 092, Loss: 2.4256, Train: 0.9955, Valid: 0.9861, Best: 0.9868\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 2.4300475120544434 | KNN Loss: 2.400362968444824 | CLS Loss: 0.029684651643037796\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 2.4069058895111084 | KNN Loss: 2.4008846282958984 | CLS Loss: 0.0060211652889847755\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 2.4000279903411865 | KNN Loss: 2.3939149379730225 | CLS Loss: 0.006113163195550442\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 2.4598119258880615 | KNN Loss: 2.4402318000793457 | CLS Loss: 0.019580192863941193\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 2.430018663406372 | KNN Loss: 2.420703649520874 | CLS Loss: 0.009314930997788906\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 2.4581215381622314 | KNN Loss: 2.42661714553833 | CLS Loss: 0.03150428831577301\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 2.4183218479156494 | KNN Loss: 2.40586519241333 | CLS Loss: 0.0124567411839962\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 2.409764051437378 | KNN Loss: 2.3910837173461914 | CLS Loss: 0.01868041604757309\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 2.4246585369110107 | KNN Loss: 2.4200477600097656 | CLS Loss: 0.004610663279891014\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 2.45060396194458 | KNN Loss: 2.4384593963623047 | CLS Loss: 0.012144673615694046\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 2.427912712097168 | KNN Loss: 2.3925085067749023 | CLS Loss: 0.035404086112976074\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 2.4624593257904053 | KNN Loss: 2.4457147121429443 | CLS Loss: 0.01674453355371952\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 2.442039728164673 | KNN Loss: 2.43623685836792 | CLS Loss: 0.005802931264042854\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 2.4146759510040283 | KNN Loss: 2.3807079792022705 | CLS Loss: 0.0339680090546608\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 2.416271924972534 | KNN Loss: 2.393453359603882 | CLS Loss: 0.022818613797426224\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 2.430320978164673 | KNN Loss: 2.4091005325317383 | CLS Loss: 0.021220529451966286\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 2.415344715118408 | KNN Loss: 2.399146556854248 | CLS Loss: 0.016198208555579185\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 2.4350404739379883 | KNN Loss: 2.428544282913208 | CLS Loss: 0.00649611558765173\n",
      "Epoch: 093, Loss: 2.4280, Train: 0.9943, Valid: 0.9855, Best: 0.9868\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 2.4190664291381836 | KNN Loss: 2.4001505374908447 | CLS Loss: 0.018915921449661255\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 2.447974681854248 | KNN Loss: 2.426074981689453 | CLS Loss: 0.02189960889518261\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 2.4318552017211914 | KNN Loss: 2.4200222492218018 | CLS Loss: 0.011832967400550842\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 2.4232711791992188 | KNN Loss: 2.41398549079895 | CLS Loss: 0.0092856390401721\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 2.404674768447876 | KNN Loss: 2.4011056423187256 | CLS Loss: 0.003569240914657712\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 2.429197311401367 | KNN Loss: 2.410393238067627 | CLS Loss: 0.01880401186645031\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 2.4352641105651855 | KNN Loss: 2.426156997680664 | CLS Loss: 0.009107150137424469\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 2.4323320388793945 | KNN Loss: 2.42228102684021 | CLS Loss: 0.010051125660538673\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 2.4462006092071533 | KNN Loss: 2.418562889099121 | CLS Loss: 0.027637701481580734\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 2.425990104675293 | KNN Loss: 2.401423931121826 | CLS Loss: 0.02456609159708023\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 2.4137351512908936 | KNN Loss: 2.4096999168395996 | CLS Loss: 0.004035262856632471\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 2.442394495010376 | KNN Loss: 2.426088333129883 | CLS Loss: 0.01630624197423458\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 2.4131410121917725 | KNN Loss: 2.389996290206909 | CLS Loss: 0.02314482443034649\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 2.4141972064971924 | KNN Loss: 2.406735420227051 | CLS Loss: 0.007461853791028261\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 2.459294319152832 | KNN Loss: 2.428323268890381 | CLS Loss: 0.030971026048064232\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 2.4449422359466553 | KNN Loss: 2.405585289001465 | CLS Loss: 0.03935684636235237\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 2.4229819774627686 | KNN Loss: 2.4128170013427734 | CLS Loss: 0.010165058076381683\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 2.411208391189575 | KNN Loss: 2.405965566635132 | CLS Loss: 0.00524272071197629\n",
      "Epoch: 094, Loss: 2.4214, Train: 0.9956, Valid: 0.9867, Best: 0.9868\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 2.4284160137176514 | KNN Loss: 2.421821117401123 | CLS Loss: 0.006594961509108543\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 2.4452755451202393 | KNN Loss: 2.426823854446411 | CLS Loss: 0.01845180056989193\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 2.4394354820251465 | KNN Loss: 2.4189162254333496 | CLS Loss: 0.020519332960247993\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 2.440851926803589 | KNN Loss: 2.4244799613952637 | CLS Loss: 0.01637192629277706\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 2.454352855682373 | KNN Loss: 2.444643020629883 | CLS Loss: 0.009709798730909824\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 2.432345151901245 | KNN Loss: 2.4209957122802734 | CLS Loss: 0.01134948804974556\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 2.38289737701416 | KNN Loss: 2.378688335418701 | CLS Loss: 0.0042091235518455505\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 2.426640272140503 | KNN Loss: 2.381605863571167 | CLS Loss: 0.04503433778882027\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 2.4046623706817627 | KNN Loss: 2.398193120956421 | CLS Loss: 0.006469206418842077\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 2.4278533458709717 | KNN Loss: 2.420290470123291 | CLS Loss: 0.007562803570181131\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 2.4608824253082275 | KNN Loss: 2.4389054775238037 | CLS Loss: 0.021976998075842857\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 2.4404296875 | KNN Loss: 2.407630443572998 | CLS Loss: 0.03279928117990494\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 2.4299917221069336 | KNN Loss: 2.420973777770996 | CLS Loss: 0.009018046781420708\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 2.4408581256866455 | KNN Loss: 2.4192769527435303 | CLS Loss: 0.02158128283917904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 2.4244463443756104 | KNN Loss: 2.4045023918151855 | CLS Loss: 0.019944000989198685\n",
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 2.438995838165283 | KNN Loss: 2.427135944366455 | CLS Loss: 0.011859981343150139\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 2.460590362548828 | KNN Loss: 2.4392266273498535 | CLS Loss: 0.02136370725929737\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 2.4060490131378174 | KNN Loss: 2.393434762954712 | CLS Loss: 0.01261430699378252\n",
      "Epoch: 095, Loss: 2.4278, Train: 0.9958, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 2.404930830001831 | KNN Loss: 2.3953051567077637 | CLS Loss: 0.009625597856938839\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 2.406830310821533 | KNN Loss: 2.404090642929077 | CLS Loss: 0.002739636693149805\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 2.4484074115753174 | KNN Loss: 2.441992998123169 | CLS Loss: 0.0064143287017941475\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 2.432764768600464 | KNN Loss: 2.419916868209839 | CLS Loss: 0.01284794881939888\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 2.440033435821533 | KNN Loss: 2.415336847305298 | CLS Loss: 0.024696705862879753\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 2.4360320568084717 | KNN Loss: 2.4132134914398193 | CLS Loss: 0.022818611934781075\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 2.428001880645752 | KNN Loss: 2.4051673412323 | CLS Loss: 0.022834647446870804\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 2.4128458499908447 | KNN Loss: 2.3920035362243652 | CLS Loss: 0.02084233984351158\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 2.401334524154663 | KNN Loss: 2.3980634212493896 | CLS Loss: 0.00327113620005548\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 2.4418578147888184 | KNN Loss: 2.430274486541748 | CLS Loss: 0.011583264917135239\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 2.4418387413024902 | KNN Loss: 2.4171128273010254 | CLS Loss: 0.024725809693336487\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 2.423711061477661 | KNN Loss: 2.4086287021636963 | CLS Loss: 0.015082450583577156\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 2.436479330062866 | KNN Loss: 2.403149127960205 | CLS Loss: 0.03333015367388725\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 2.434286594390869 | KNN Loss: 2.410889148712158 | CLS Loss: 0.023397548124194145\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 2.46144962310791 | KNN Loss: 2.442188262939453 | CLS Loss: 0.019261348992586136\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 2.39945912361145 | KNN Loss: 2.379960060119629 | CLS Loss: 0.019499124959111214\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 2.4576358795166016 | KNN Loss: 2.437588930130005 | CLS Loss: 0.02004706859588623\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 2.472513198852539 | KNN Loss: 2.464028835296631 | CLS Loss: 0.00848432257771492\n",
      "Epoch: 096, Loss: 2.4203, Train: 0.9900, Valid: 0.9832, Best: 0.9873\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 2.544085741043091 | KNN Loss: 2.505868911743164 | CLS Loss: 0.03821677714586258\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 2.476515054702759 | KNN Loss: 2.466254949569702 | CLS Loss: 0.0102601433172822\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 2.4327869415283203 | KNN Loss: 2.418154001235962 | CLS Loss: 0.01463283970952034\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 2.3834474086761475 | KNN Loss: 2.3679163455963135 | CLS Loss: 0.015531040728092194\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 2.407229423522949 | KNN Loss: 2.3807032108306885 | CLS Loss: 0.026526130735874176\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 2.419711112976074 | KNN Loss: 2.412611246109009 | CLS Loss: 0.007099844980984926\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 2.440504550933838 | KNN Loss: 2.4256935119628906 | CLS Loss: 0.014811057597398758\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 2.4446377754211426 | KNN Loss: 2.431771993637085 | CLS Loss: 0.012865767814218998\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 2.4327499866485596 | KNN Loss: 2.4020087718963623 | CLS Loss: 0.030741287395358086\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 2.4452078342437744 | KNN Loss: 2.4042134284973145 | CLS Loss: 0.04099445417523384\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 2.463792324066162 | KNN Loss: 2.3996691703796387 | CLS Loss: 0.06412309408187866\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 2.432936668395996 | KNN Loss: 2.4190125465393066 | CLS Loss: 0.013924035243690014\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 2.4206905364990234 | KNN Loss: 2.3856067657470703 | CLS Loss: 0.03508378937840462\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 2.3885276317596436 | KNN Loss: 2.3632912635803223 | CLS Loss: 0.025236448273062706\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 2.4089064598083496 | KNN Loss: 2.391211986541748 | CLS Loss: 0.01769438572227955\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 2.4046971797943115 | KNN Loss: 2.3808510303497314 | CLS Loss: 0.023846186697483063\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 2.4394876956939697 | KNN Loss: 2.417742967605591 | CLS Loss: 0.02174476906657219\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 2.4293875694274902 | KNN Loss: 2.421491861343384 | CLS Loss: 0.007895739749073982\n",
      "Epoch: 097, Loss: 2.4281, Train: 0.9956, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 2.44459867477417 | KNN Loss: 2.4354159832000732 | CLS Loss: 0.009182574227452278\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 2.4360735416412354 | KNN Loss: 2.4212839603424072 | CLS Loss: 0.014789680019021034\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 2.433610677719116 | KNN Loss: 2.400413751602173 | CLS Loss: 0.03319697827100754\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 2.4170095920562744 | KNN Loss: 2.399392604827881 | CLS Loss: 0.01761694811284542\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 2.3969180583953857 | KNN Loss: 2.3844423294067383 | CLS Loss: 0.012475629337131977\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 2.4572155475616455 | KNN Loss: 2.44972562789917 | CLS Loss: 0.00748983770608902\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 2.419976234436035 | KNN Loss: 2.3991308212280273 | CLS Loss: 0.020845437422394753\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 2.4292430877685547 | KNN Loss: 2.414059638977051 | CLS Loss: 0.015183495357632637\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 2.4141910076141357 | KNN Loss: 2.4022092819213867 | CLS Loss: 0.011981610208749771\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 2.420943260192871 | KNN Loss: 2.417238235473633 | CLS Loss: 0.0037051304243505\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 2.4595632553100586 | KNN Loss: 2.454820156097412 | CLS Loss: 0.004743051249533892\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 2.3922297954559326 | KNN Loss: 2.375844717025757 | CLS Loss: 0.016384970396757126\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 2.3951148986816406 | KNN Loss: 2.388361692428589 | CLS Loss: 0.0067532360553741455\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 2.449249744415283 | KNN Loss: 2.416140556335449 | CLS Loss: 0.03310925513505936\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 2.4392294883728027 | KNN Loss: 2.415452003479004 | CLS Loss: 0.023777570575475693\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 2.4455935955047607 | KNN Loss: 2.4135260581970215 | CLS Loss: 0.03206750378012657\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 2.4086005687713623 | KNN Loss: 2.400627613067627 | CLS Loss: 0.00797293707728386\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 2.3847861289978027 | KNN Loss: 2.360090494155884 | CLS Loss: 0.024695677682757378\n",
      "Epoch: 098, Loss: 2.4255, Train: 0.9953, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 2.4343905448913574 | KNN Loss: 2.4213345050811768 | CLS Loss: 0.013055945746600628\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 2.4528448581695557 | KNN Loss: 2.4011542797088623 | CLS Loss: 0.05169060826301575\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 2.4257781505584717 | KNN Loss: 2.4192912578582764 | CLS Loss: 0.006486782804131508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 2.427884340286255 | KNN Loss: 2.402944326400757 | CLS Loss: 0.02493991330265999\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 2.4274613857269287 | KNN Loss: 2.395341634750366 | CLS Loss: 0.032119765877723694\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 2.3902907371520996 | KNN Loss: 2.382582187652588 | CLS Loss: 0.007708489894866943\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 2.4152441024780273 | KNN Loss: 2.3993537425994873 | CLS Loss: 0.015890317037701607\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 2.410616397857666 | KNN Loss: 2.4008688926696777 | CLS Loss: 0.00974738597869873\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 2.4133572578430176 | KNN Loss: 2.4091951847076416 | CLS Loss: 0.004162167198956013\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 2.4021308422088623 | KNN Loss: 2.3790841102600098 | CLS Loss: 0.023046741262078285\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 2.450831651687622 | KNN Loss: 2.410999298095703 | CLS Loss: 0.03983239829540253\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 2.419738531112671 | KNN Loss: 2.411705732345581 | CLS Loss: 0.008032844401896\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 2.4342539310455322 | KNN Loss: 2.417067050933838 | CLS Loss: 0.01718691736459732\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 2.3923473358154297 | KNN Loss: 2.3756606578826904 | CLS Loss: 0.016686566174030304\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 2.4385111331939697 | KNN Loss: 2.422813892364502 | CLS Loss: 0.015697333961725235\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 2.424875259399414 | KNN Loss: 2.409841299057007 | CLS Loss: 0.015033965930342674\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 2.452594757080078 | KNN Loss: 2.439124822616577 | CLS Loss: 0.013469910249114037\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 2.4145655632019043 | KNN Loss: 2.4072792530059814 | CLS Loss: 0.007286226376891136\n",
      "Epoch: 099, Loss: 2.4210, Train: 0.9955, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 2.429621696472168 | KNN Loss: 2.426081895828247 | CLS Loss: 0.0035397971514612436\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 2.4306671619415283 | KNN Loss: 2.422987937927246 | CLS Loss: 0.007679180707782507\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 2.44189190864563 | KNN Loss: 2.4220614433288574 | CLS Loss: 0.019830580800771713\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 2.423586368560791 | KNN Loss: 2.4035868644714355 | CLS Loss: 0.019999518990516663\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 2.436096668243408 | KNN Loss: 2.412484884262085 | CLS Loss: 0.02361181378364563\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 2.3924319744110107 | KNN Loss: 2.382809638977051 | CLS Loss: 0.00962237361818552\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 2.458573341369629 | KNN Loss: 2.4205260276794434 | CLS Loss: 0.03804737702012062\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 2.427318572998047 | KNN Loss: 2.398836374282837 | CLS Loss: 0.02848227135837078\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 2.4306178092956543 | KNN Loss: 2.4015414714813232 | CLS Loss: 0.02907644584774971\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 2.397242307662964 | KNN Loss: 2.3697919845581055 | CLS Loss: 0.027450433000922203\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 2.4343152046203613 | KNN Loss: 2.414311170578003 | CLS Loss: 0.020004142075777054\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 2.460536479949951 | KNN Loss: 2.446089744567871 | CLS Loss: 0.014446794986724854\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 2.4360599517822266 | KNN Loss: 2.414996862411499 | CLS Loss: 0.02106313221156597\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 2.451080560684204 | KNN Loss: 2.4323313236236572 | CLS Loss: 0.018749171867966652\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 2.429763078689575 | KNN Loss: 2.410116672515869 | CLS Loss: 0.01964637264609337\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 2.4007227420806885 | KNN Loss: 2.395416498184204 | CLS Loss: 0.005306259263306856\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 2.3760945796966553 | KNN Loss: 2.3628649711608887 | CLS Loss: 0.013229579664766788\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 2.4130477905273438 | KNN Loss: 2.3834798336029053 | CLS Loss: 0.029567988589406013\n",
      "Epoch: 100, Loss: 2.4245, Train: 0.9956, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 2.3984556198120117 | KNN Loss: 2.391223907470703 | CLS Loss: 0.007231610827147961\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 2.389538049697876 | KNN Loss: 2.383383274078369 | CLS Loss: 0.006154835224151611\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 2.3784797191619873 | KNN Loss: 2.3677279949188232 | CLS Loss: 0.010751689784228802\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 2.425755023956299 | KNN Loss: 2.422044038772583 | CLS Loss: 0.0037109176628291607\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 2.4191532135009766 | KNN Loss: 2.4028453826904297 | CLS Loss: 0.016307855024933815\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 2.3821303844451904 | KNN Loss: 2.378970146179199 | CLS Loss: 0.003160173073410988\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 2.424833059310913 | KNN Loss: 2.4159345626831055 | CLS Loss: 0.008898559026420116\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 2.423203229904175 | KNN Loss: 2.4199087619781494 | CLS Loss: 0.0032945529092103243\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 2.4377646446228027 | KNN Loss: 2.4249250888824463 | CLS Loss: 0.012839572504162788\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 2.409072160720825 | KNN Loss: 2.3926916122436523 | CLS Loss: 0.016380535438656807\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 2.4307048320770264 | KNN Loss: 2.406785488128662 | CLS Loss: 0.023919377475976944\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 2.4084935188293457 | KNN Loss: 2.401247501373291 | CLS Loss: 0.007246032822877169\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 2.4419188499450684 | KNN Loss: 2.431260824203491 | CLS Loss: 0.010658111423254013\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 2.448688507080078 | KNN Loss: 2.4177567958831787 | CLS Loss: 0.030931644141674042\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 2.424926280975342 | KNN Loss: 2.4127960205078125 | CLS Loss: 0.012130199931561947\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 2.446732521057129 | KNN Loss: 2.4138965606689453 | CLS Loss: 0.03283599391579628\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 2.424553871154785 | KNN Loss: 2.3870222568511963 | CLS Loss: 0.037531595677137375\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 2.416673183441162 | KNN Loss: 2.3964836597442627 | CLS Loss: 0.020189501345157623\n",
      "Epoch: 101, Loss: 2.4232, Train: 0.9949, Valid: 0.9857, Best: 0.9873\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 2.4113945960998535 | KNN Loss: 2.403475046157837 | CLS Loss: 0.00791944283992052\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 2.4125897884368896 | KNN Loss: 2.390549659729004 | CLS Loss: 0.022040102630853653\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 2.40710711479187 | KNN Loss: 2.389584541320801 | CLS Loss: 0.017522599548101425\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 2.4127137660980225 | KNN Loss: 2.408543586730957 | CLS Loss: 0.004170269705355167\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 2.4159188270568848 | KNN Loss: 2.407273054122925 | CLS Loss: 0.008645744994282722\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 2.4139795303344727 | KNN Loss: 2.380707263946533 | CLS Loss: 0.033272210508584976\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 2.4351282119750977 | KNN Loss: 2.4235668182373047 | CLS Loss: 0.01156146451830864\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 2.403287649154663 | KNN Loss: 2.394857883453369 | CLS Loss: 0.008429805748164654\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 2.4320666790008545 | KNN Loss: 2.4116663932800293 | CLS Loss: 0.02040017768740654\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 2.3970305919647217 | KNN Loss: 2.3647539615631104 | CLS Loss: 0.032276738435029984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 2.411527395248413 | KNN Loss: 2.4024436473846436 | CLS Loss: 0.009083799086511135\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 2.408468246459961 | KNN Loss: 2.392312526702881 | CLS Loss: 0.016155634075403214\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 2.4035086631774902 | KNN Loss: 2.396930456161499 | CLS Loss: 0.006578207481652498\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 2.4272241592407227 | KNN Loss: 2.400563955307007 | CLS Loss: 0.02666030265390873\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 2.428779125213623 | KNN Loss: 2.3815722465515137 | CLS Loss: 0.0472068265080452\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 2.4267849922180176 | KNN Loss: 2.4046990871429443 | CLS Loss: 0.022085899487137794\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 2.4326443672180176 | KNN Loss: 2.407682418823242 | CLS Loss: 0.02496200054883957\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 2.43111252784729 | KNN Loss: 2.402024030685425 | CLS Loss: 0.029088521376252174\n",
      "Epoch: 102, Loss: 2.4206, Train: 0.9927, Valid: 0.9853, Best: 0.9873\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 2.414903163909912 | KNN Loss: 2.4040586948394775 | CLS Loss: 0.01084447093307972\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 2.4842529296875 | KNN Loss: 2.450791597366333 | CLS Loss: 0.03346134349703789\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 2.4524290561676025 | KNN Loss: 2.4264650344848633 | CLS Loss: 0.025964127853512764\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 2.4386801719665527 | KNN Loss: 2.430241107940674 | CLS Loss: 0.00843916554003954\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 2.410377025604248 | KNN Loss: 2.4008660316467285 | CLS Loss: 0.009510939009487629\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 2.547943353652954 | KNN Loss: 2.5182056427001953 | CLS Loss: 0.029737770557403564\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 2.5137124061584473 | KNN Loss: 2.4874863624572754 | CLS Loss: 0.026226093992590904\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 2.4775798320770264 | KNN Loss: 2.451317071914673 | CLS Loss: 0.026262834668159485\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 2.4516592025756836 | KNN Loss: 2.4418628215789795 | CLS Loss: 0.009796303696930408\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 2.514106273651123 | KNN Loss: 2.499605894088745 | CLS Loss: 0.014500400051474571\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 2.459089994430542 | KNN Loss: 2.453104257583618 | CLS Loss: 0.005985824856907129\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 2.4386494159698486 | KNN Loss: 2.426978349685669 | CLS Loss: 0.011671045795083046\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 2.5408523082733154 | KNN Loss: 2.5312156677246094 | CLS Loss: 0.00963654275983572\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 2.4381725788116455 | KNN Loss: 2.4191155433654785 | CLS Loss: 0.019056981429457664\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 2.508176326751709 | KNN Loss: 2.4885647296905518 | CLS Loss: 0.01961163431406021\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 2.464107036590576 | KNN Loss: 2.43827223777771 | CLS Loss: 0.025834769010543823\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 2.4726574420928955 | KNN Loss: 2.4497592449188232 | CLS Loss: 0.02289816550910473\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 2.423398971557617 | KNN Loss: 2.4107258319854736 | CLS Loss: 0.0126730902120471\n",
      "Epoch: 103, Loss: 2.4611, Train: 0.9926, Valid: 0.9849, Best: 0.9873\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 2.431457757949829 | KNN Loss: 2.4135923385620117 | CLS Loss: 0.017865382134914398\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 2.4200291633605957 | KNN Loss: 2.4087767601013184 | CLS Loss: 0.011252288706600666\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 2.438645839691162 | KNN Loss: 2.4100515842437744 | CLS Loss: 0.02859433740377426\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 2.4455673694610596 | KNN Loss: 2.4276177883148193 | CLS Loss: 0.017949607223272324\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 2.4767682552337646 | KNN Loss: 2.4451866149902344 | CLS Loss: 0.03158175200223923\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 2.4292538166046143 | KNN Loss: 2.4153246879577637 | CLS Loss: 0.013929173350334167\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 2.4486281871795654 | KNN Loss: 2.4267830848693848 | CLS Loss: 0.021845178678631783\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 2.4395337104797363 | KNN Loss: 2.4258360862731934 | CLS Loss: 0.01369751151651144\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 2.4342732429504395 | KNN Loss: 2.408289909362793 | CLS Loss: 0.025983326137065887\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 2.411149263381958 | KNN Loss: 2.4030332565307617 | CLS Loss: 0.00811595655977726\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 2.4864134788513184 | KNN Loss: 2.478520154953003 | CLS Loss: 0.007893413305282593\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 2.470668315887451 | KNN Loss: 2.453636407852173 | CLS Loss: 0.017032025381922722\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 2.4113214015960693 | KNN Loss: 2.3833377361297607 | CLS Loss: 0.027983682230114937\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 2.419752836227417 | KNN Loss: 2.4006619453430176 | CLS Loss: 0.019090823829174042\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 2.415133476257324 | KNN Loss: 2.407106876373291 | CLS Loss: 0.00802649650722742\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 2.4755802154541016 | KNN Loss: 2.429884672164917 | CLS Loss: 0.04569559544324875\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 2.426363945007324 | KNN Loss: 2.4014391899108887 | CLS Loss: 0.024924669414758682\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 2.4555790424346924 | KNN Loss: 2.439452886581421 | CLS Loss: 0.016126088798046112\n",
      "Epoch: 104, Loss: 2.4434, Train: 0.9954, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 2.4080662727355957 | KNN Loss: 2.4036824703216553 | CLS Loss: 0.0043838974088430405\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 2.4019689559936523 | KNN Loss: 2.3957574367523193 | CLS Loss: 0.006211634259670973\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 2.4248979091644287 | KNN Loss: 2.41321063041687 | CLS Loss: 0.011687166057527065\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 2.41611385345459 | KNN Loss: 2.3918232917785645 | CLS Loss: 0.024290509521961212\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 2.4589812755584717 | KNN Loss: 2.440316677093506 | CLS Loss: 0.018664509057998657\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 2.4231553077697754 | KNN Loss: 2.407526731491089 | CLS Loss: 0.015628496184945107\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 2.4729464054107666 | KNN Loss: 2.4166526794433594 | CLS Loss: 0.05629361793398857\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 2.4131851196289062 | KNN Loss: 2.3938426971435547 | CLS Loss: 0.01934245601296425\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 2.4489479064941406 | KNN Loss: 2.4336390495300293 | CLS Loss: 0.015308908186852932\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 2.4391727447509766 | KNN Loss: 2.410153865814209 | CLS Loss: 0.029018772765994072\n",
      "Epoch 105 / 200 | iteration 100 / 171 | Total Loss: 2.4391674995422363 | KNN Loss: 2.4294400215148926 | CLS Loss: 0.009727424010634422\n",
      "Epoch 105 / 200 | iteration 110 / 171 | Total Loss: 2.447209596633911 | KNN Loss: 2.431478261947632 | CLS Loss: 0.015731263905763626\n",
      "Epoch 105 / 200 | iteration 120 / 171 | Total Loss: 2.424467086791992 | KNN Loss: 2.3940787315368652 | CLS Loss: 0.030388394370675087\n",
      "Epoch 105 / 200 | iteration 130 / 171 | Total Loss: 2.435821533203125 | KNN Loss: 2.3992562294006348 | CLS Loss: 0.03656518831849098\n",
      "Epoch 105 / 200 | iteration 140 / 171 | Total Loss: 2.4838898181915283 | KNN Loss: 2.464890718460083 | CLS Loss: 0.018999211490154266\n",
      "Epoch 105 / 200 | iteration 150 / 171 | Total Loss: 2.45978045463562 | KNN Loss: 2.4449007511138916 | CLS Loss: 0.014879734255373478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 / 200 | iteration 160 / 171 | Total Loss: 2.4155220985412598 | KNN Loss: 2.3995425701141357 | CLS Loss: 0.015979526564478874\n",
      "Epoch 105 / 200 | iteration 170 / 171 | Total Loss: 2.4406630992889404 | KNN Loss: 2.4181275367736816 | CLS Loss: 0.022535528987646103\n",
      "Epoch: 105, Loss: 2.4310, Train: 0.9942, Valid: 0.9847, Best: 0.9873\n",
      "Epoch 106 / 200 | iteration 0 / 171 | Total Loss: 2.4072766304016113 | KNN Loss: 2.4002904891967773 | CLS Loss: 0.006986184511333704\n",
      "Epoch 106 / 200 | iteration 10 / 171 | Total Loss: 2.4370627403259277 | KNN Loss: 2.4285566806793213 | CLS Loss: 0.008506151847541332\n",
      "Epoch 106 / 200 | iteration 20 / 171 | Total Loss: 2.4430904388427734 | KNN Loss: 2.417677640914917 | CLS Loss: 0.025412827730178833\n",
      "Epoch 106 / 200 | iteration 30 / 171 | Total Loss: 2.482295036315918 | KNN Loss: 2.452075719833374 | CLS Loss: 0.03021942265331745\n",
      "Epoch 106 / 200 | iteration 40 / 171 | Total Loss: 2.4652256965637207 | KNN Loss: 2.454318046569824 | CLS Loss: 0.010907769203186035\n",
      "Epoch 106 / 200 | iteration 50 / 171 | Total Loss: 2.4431607723236084 | KNN Loss: 2.4358978271484375 | CLS Loss: 0.007263001054525375\n",
      "Epoch 106 / 200 | iteration 60 / 171 | Total Loss: 2.4397261142730713 | KNN Loss: 2.437622308731079 | CLS Loss: 0.002103704260662198\n",
      "Epoch 106 / 200 | iteration 70 / 171 | Total Loss: 2.4153311252593994 | KNN Loss: 2.406844139099121 | CLS Loss: 0.008487014099955559\n",
      "Epoch 106 / 200 | iteration 80 / 171 | Total Loss: 2.4198756217956543 | KNN Loss: 2.408395528793335 | CLS Loss: 0.011480082757771015\n",
      "Epoch 106 / 200 | iteration 90 / 171 | Total Loss: 2.444148063659668 | KNN Loss: 2.4209752082824707 | CLS Loss: 0.02317274548113346\n",
      "Epoch 106 / 200 | iteration 100 / 171 | Total Loss: 2.4556140899658203 | KNN Loss: 2.4491560459136963 | CLS Loss: 0.0064581213518977165\n",
      "Epoch 106 / 200 | iteration 110 / 171 | Total Loss: 2.428955554962158 | KNN Loss: 2.4013161659240723 | CLS Loss: 0.027639275416731834\n",
      "Epoch 106 / 200 | iteration 120 / 171 | Total Loss: 2.415287494659424 | KNN Loss: 2.376612901687622 | CLS Loss: 0.0386744849383831\n",
      "Epoch 106 / 200 | iteration 130 / 171 | Total Loss: 2.4201648235321045 | KNN Loss: 2.4107816219329834 | CLS Loss: 0.009383304044604301\n",
      "Epoch 106 / 200 | iteration 140 / 171 | Total Loss: 2.44235897064209 | KNN Loss: 2.4246742725372314 | CLS Loss: 0.017684638500213623\n",
      "Epoch 106 / 200 | iteration 150 / 171 | Total Loss: 2.444354772567749 | KNN Loss: 2.418180465698242 | CLS Loss: 0.026174325495958328\n",
      "Epoch 106 / 200 | iteration 160 / 171 | Total Loss: 2.4507360458374023 | KNN Loss: 2.435962200164795 | CLS Loss: 0.014773753471672535\n",
      "Epoch 106 / 200 | iteration 170 / 171 | Total Loss: 2.3940651416778564 | KNN Loss: 2.383258104324341 | CLS Loss: 0.010807150043547153\n",
      "Epoch: 106, Loss: 2.4331, Train: 0.9942, Valid: 0.9854, Best: 0.9873\n",
      "Epoch 107 / 200 | iteration 0 / 171 | Total Loss: 2.4560232162475586 | KNN Loss: 2.3801517486572266 | CLS Loss: 0.07587146759033203\n",
      "Epoch 107 / 200 | iteration 10 / 171 | Total Loss: 2.4779486656188965 | KNN Loss: 2.445143222808838 | CLS Loss: 0.032805491238832474\n",
      "Epoch 107 / 200 | iteration 20 / 171 | Total Loss: 2.4322264194488525 | KNN Loss: 2.4158575534820557 | CLS Loss: 0.01636875607073307\n",
      "Epoch 107 / 200 | iteration 30 / 171 | Total Loss: 2.423487424850464 | KNN Loss: 2.411198616027832 | CLS Loss: 0.012288801372051239\n",
      "Epoch 107 / 200 | iteration 40 / 171 | Total Loss: 2.4565112590789795 | KNN Loss: 2.4372143745422363 | CLS Loss: 0.019296828657388687\n",
      "Epoch 107 / 200 | iteration 50 / 171 | Total Loss: 2.412398099899292 | KNN Loss: 2.4014663696289062 | CLS Loss: 0.010931846685707569\n",
      "Epoch 107 / 200 | iteration 60 / 171 | Total Loss: 2.457329034805298 | KNN Loss: 2.4394500255584717 | CLS Loss: 0.01787904091179371\n",
      "Epoch 107 / 200 | iteration 70 / 171 | Total Loss: 2.4376957416534424 | KNN Loss: 2.4184751510620117 | CLS Loss: 0.019220616668462753\n",
      "Epoch 107 / 200 | iteration 80 / 171 | Total Loss: 2.4408626556396484 | KNN Loss: 2.4349870681762695 | CLS Loss: 0.00587552459910512\n",
      "Epoch 107 / 200 | iteration 90 / 171 | Total Loss: 2.420609474182129 | KNN Loss: 2.4048752784729004 | CLS Loss: 0.015734273940324783\n",
      "Epoch 107 / 200 | iteration 100 / 171 | Total Loss: 2.454455852508545 | KNN Loss: 2.4303853511810303 | CLS Loss: 0.024070406332612038\n",
      "Epoch 107 / 200 | iteration 110 / 171 | Total Loss: 2.4628448486328125 | KNN Loss: 2.4444420337677 | CLS Loss: 0.01840282417833805\n",
      "Epoch 107 / 200 | iteration 120 / 171 | Total Loss: 2.4879674911499023 | KNN Loss: 2.458193778991699 | CLS Loss: 0.029773762449622154\n",
      "Epoch 107 / 200 | iteration 130 / 171 | Total Loss: 2.4975578784942627 | KNN Loss: 2.462531805038452 | CLS Loss: 0.03502611070871353\n",
      "Epoch 107 / 200 | iteration 140 / 171 | Total Loss: 2.4393839836120605 | KNN Loss: 2.4220805168151855 | CLS Loss: 0.01730356179177761\n",
      "Epoch 107 / 200 | iteration 150 / 171 | Total Loss: 2.448132038116455 | KNN Loss: 2.4365384578704834 | CLS Loss: 0.011593610048294067\n",
      "Epoch 107 / 200 | iteration 160 / 171 | Total Loss: 2.428873300552368 | KNN Loss: 2.4171388149261475 | CLS Loss: 0.01173449121415615\n",
      "Epoch 107 / 200 | iteration 170 / 171 | Total Loss: 2.397861957550049 | KNN Loss: 2.3815343379974365 | CLS Loss: 0.016327695921063423\n",
      "Epoch: 107, Loss: 2.4309, Train: 0.9961, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 108 / 200 | iteration 0 / 171 | Total Loss: 2.3839046955108643 | KNN Loss: 2.3684897422790527 | CLS Loss: 0.01541499886661768\n",
      "Epoch 108 / 200 | iteration 10 / 171 | Total Loss: 2.3804752826690674 | KNN Loss: 2.371854782104492 | CLS Loss: 0.008620403707027435\n",
      "Epoch 108 / 200 | iteration 20 / 171 | Total Loss: 2.4592125415802 | KNN Loss: 2.444917917251587 | CLS Loss: 0.014294601045548916\n",
      "Epoch 108 / 200 | iteration 30 / 171 | Total Loss: 2.430117607116699 | KNN Loss: 2.409909725189209 | CLS Loss: 0.020207932218909264\n",
      "Epoch 108 / 200 | iteration 40 / 171 | Total Loss: 2.4191548824310303 | KNN Loss: 2.415602207183838 | CLS Loss: 0.0035527769941836596\n",
      "Epoch 108 / 200 | iteration 50 / 171 | Total Loss: 2.4248480796813965 | KNN Loss: 2.408597707748413 | CLS Loss: 0.01625044457614422\n",
      "Epoch 108 / 200 | iteration 60 / 171 | Total Loss: 2.4101014137268066 | KNN Loss: 2.3907809257507324 | CLS Loss: 0.019320376217365265\n",
      "Epoch 108 / 200 | iteration 70 / 171 | Total Loss: 2.445366859436035 | KNN Loss: 2.435696840286255 | CLS Loss: 0.009670097380876541\n",
      "Epoch 108 / 200 | iteration 80 / 171 | Total Loss: 2.4188685417175293 | KNN Loss: 2.397420644760132 | CLS Loss: 0.02144795097410679\n",
      "Epoch 108 / 200 | iteration 90 / 171 | Total Loss: 2.413012742996216 | KNN Loss: 2.3974173069000244 | CLS Loss: 0.015595529228448868\n",
      "Epoch 108 / 200 | iteration 100 / 171 | Total Loss: 2.4166009426116943 | KNN Loss: 2.3980040550231934 | CLS Loss: 0.01859690062701702\n",
      "Epoch 108 / 200 | iteration 110 / 171 | Total Loss: 2.4025092124938965 | KNN Loss: 2.381239891052246 | CLS Loss: 0.021269211545586586\n",
      "Epoch 108 / 200 | iteration 120 / 171 | Total Loss: 2.462897777557373 | KNN Loss: 2.4537103176116943 | CLS Loss: 0.00918752420693636\n",
      "Epoch 108 / 200 | iteration 130 / 171 | Total Loss: 2.435019016265869 | KNN Loss: 2.388185501098633 | CLS Loss: 0.046833399683237076\n",
      "Epoch 108 / 200 | iteration 140 / 171 | Total Loss: 2.4329569339752197 | KNN Loss: 2.417527914047241 | CLS Loss: 0.015428907237946987\n",
      "Epoch 108 / 200 | iteration 150 / 171 | Total Loss: 2.439455032348633 | KNN Loss: 2.4103543758392334 | CLS Loss: 0.029100708663463593\n",
      "Epoch 108 / 200 | iteration 160 / 171 | Total Loss: 2.427060604095459 | KNN Loss: 2.4143855571746826 | CLS Loss: 0.012675103731453419\n",
      "Epoch 108 / 200 | iteration 170 / 171 | Total Loss: 2.4615745544433594 | KNN Loss: 2.42124080657959 | CLS Loss: 0.04033384099602699\n",
      "Epoch: 108, Loss: 2.4301, Train: 0.9950, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 109 / 200 | iteration 0 / 171 | Total Loss: 2.4498157501220703 | KNN Loss: 2.4343326091766357 | CLS Loss: 0.015483039431273937\n",
      "Epoch 109 / 200 | iteration 10 / 171 | Total Loss: 2.413161039352417 | KNN Loss: 2.409275531768799 | CLS Loss: 0.003885561367496848\n",
      "Epoch 109 / 200 | iteration 20 / 171 | Total Loss: 2.436572551727295 | KNN Loss: 2.4153826236724854 | CLS Loss: 0.021189941093325615\n",
      "Epoch 109 / 200 | iteration 30 / 171 | Total Loss: 2.392634153366089 | KNN Loss: 2.37715220451355 | CLS Loss: 0.015481949783861637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 / 200 | iteration 40 / 171 | Total Loss: 2.4329068660736084 | KNN Loss: 2.4146578311920166 | CLS Loss: 0.018248990178108215\n",
      "Epoch 109 / 200 | iteration 50 / 171 | Total Loss: 2.4329724311828613 | KNN Loss: 2.426724672317505 | CLS Loss: 0.006247641518712044\n",
      "Epoch 109 / 200 | iteration 60 / 171 | Total Loss: 2.4577348232269287 | KNN Loss: 2.4234988689422607 | CLS Loss: 0.034236036241054535\n",
      "Epoch 109 / 200 | iteration 70 / 171 | Total Loss: 2.435185670852661 | KNN Loss: 2.3980472087860107 | CLS Loss: 0.03713855519890785\n",
      "Epoch 109 / 200 | iteration 80 / 171 | Total Loss: 2.403531312942505 | KNN Loss: 2.3827927112579346 | CLS Loss: 0.02073850855231285\n",
      "Epoch 109 / 200 | iteration 90 / 171 | Total Loss: 2.4227259159088135 | KNN Loss: 2.412520408630371 | CLS Loss: 0.010205565020442009\n",
      "Epoch 109 / 200 | iteration 100 / 171 | Total Loss: 2.383897304534912 | KNN Loss: 2.370675802230835 | CLS Loss: 0.013221485540270805\n",
      "Epoch 109 / 200 | iteration 110 / 171 | Total Loss: 2.420781373977661 | KNN Loss: 2.407675266265869 | CLS Loss: 0.013106104917824268\n",
      "Epoch 109 / 200 | iteration 120 / 171 | Total Loss: 2.4236013889312744 | KNN Loss: 2.4148812294006348 | CLS Loss: 0.008720078505575657\n",
      "Epoch 109 / 200 | iteration 130 / 171 | Total Loss: 2.4271137714385986 | KNN Loss: 2.4026174545288086 | CLS Loss: 0.02449627034366131\n",
      "Epoch 109 / 200 | iteration 140 / 171 | Total Loss: 2.421152114868164 | KNN Loss: 2.4056310653686523 | CLS Loss: 0.015521068125963211\n",
      "Epoch 109 / 200 | iteration 150 / 171 | Total Loss: 2.4093949794769287 | KNN Loss: 2.4053492546081543 | CLS Loss: 0.004045738838613033\n",
      "Epoch 109 / 200 | iteration 160 / 171 | Total Loss: 2.457066297531128 | KNN Loss: 2.42718243598938 | CLS Loss: 0.02988395467400551\n",
      "Epoch 109 / 200 | iteration 170 / 171 | Total Loss: 2.4346137046813965 | KNN Loss: 2.411775588989258 | CLS Loss: 0.022838139906525612\n",
      "Epoch: 109, Loss: 2.4277, Train: 0.9957, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 110 / 200 | iteration 0 / 171 | Total Loss: 2.3970985412597656 | KNN Loss: 2.3738198280334473 | CLS Loss: 0.023278681561350822\n",
      "Epoch 110 / 200 | iteration 10 / 171 | Total Loss: 2.4199934005737305 | KNN Loss: 2.395594596862793 | CLS Loss: 0.024398870766162872\n",
      "Epoch 110 / 200 | iteration 20 / 171 | Total Loss: 2.4449644088745117 | KNN Loss: 2.4386560916900635 | CLS Loss: 0.006308337207883596\n",
      "Epoch 110 / 200 | iteration 30 / 171 | Total Loss: 2.424948215484619 | KNN Loss: 2.411325216293335 | CLS Loss: 0.013622897677123547\n",
      "Epoch 110 / 200 | iteration 40 / 171 | Total Loss: 2.463900566101074 | KNN Loss: 2.4390552043914795 | CLS Loss: 0.024845341220498085\n",
      "Epoch 110 / 200 | iteration 50 / 171 | Total Loss: 2.437169075012207 | KNN Loss: 2.4320437908172607 | CLS Loss: 0.00512529956176877\n",
      "Epoch 110 / 200 | iteration 60 / 171 | Total Loss: 2.4574668407440186 | KNN Loss: 2.4479048252105713 | CLS Loss: 0.009562131017446518\n",
      "Epoch 110 / 200 | iteration 70 / 171 | Total Loss: 2.4314754009246826 | KNN Loss: 2.4187088012695312 | CLS Loss: 0.01276669092476368\n",
      "Epoch 110 / 200 | iteration 80 / 171 | Total Loss: 2.447200298309326 | KNN Loss: 2.418973445892334 | CLS Loss: 0.028226753696799278\n",
      "Epoch 110 / 200 | iteration 90 / 171 | Total Loss: 2.422581434249878 | KNN Loss: 2.4079296588897705 | CLS Loss: 0.014651760458946228\n",
      "Epoch 110 / 200 | iteration 100 / 171 | Total Loss: 2.4195666313171387 | KNN Loss: 2.4023101329803467 | CLS Loss: 0.017256589606404305\n",
      "Epoch 110 / 200 | iteration 110 / 171 | Total Loss: 2.439336061477661 | KNN Loss: 2.406191349029541 | CLS Loss: 0.033144768327474594\n",
      "Epoch 110 / 200 | iteration 120 / 171 | Total Loss: 2.406034469604492 | KNN Loss: 2.394073247909546 | CLS Loss: 0.011961309239268303\n",
      "Epoch 110 / 200 | iteration 130 / 171 | Total Loss: 2.44488787651062 | KNN Loss: 2.4267780780792236 | CLS Loss: 0.018109705299139023\n",
      "Epoch 110 / 200 | iteration 140 / 171 | Total Loss: 2.4298408031463623 | KNN Loss: 2.409266710281372 | CLS Loss: 0.020574107766151428\n",
      "Epoch 110 / 200 | iteration 150 / 171 | Total Loss: 2.411694288253784 | KNN Loss: 2.4015262126922607 | CLS Loss: 0.010168076492846012\n",
      "Epoch 110 / 200 | iteration 160 / 171 | Total Loss: 2.4341557025909424 | KNN Loss: 2.4229671955108643 | CLS Loss: 0.011188480071723461\n",
      "Epoch 110 / 200 | iteration 170 / 171 | Total Loss: 2.4092671871185303 | KNN Loss: 2.374556541442871 | CLS Loss: 0.03471064195036888\n",
      "Epoch: 110, Loss: 2.4280, Train: 0.9947, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 111 / 200 | iteration 0 / 171 | Total Loss: 2.3966176509857178 | KNN Loss: 2.3872077465057373 | CLS Loss: 0.009409965947270393\n",
      "Epoch 111 / 200 | iteration 10 / 171 | Total Loss: 2.443070888519287 | KNN Loss: 2.4160070419311523 | CLS Loss: 0.027063732966780663\n",
      "Epoch 111 / 200 | iteration 20 / 171 | Total Loss: 2.4244515895843506 | KNN Loss: 2.4176018238067627 | CLS Loss: 0.006849766243249178\n",
      "Epoch 111 / 200 | iteration 30 / 171 | Total Loss: 2.426130533218384 | KNN Loss: 2.4214470386505127 | CLS Loss: 0.004683555103838444\n",
      "Epoch 111 / 200 | iteration 40 / 171 | Total Loss: 2.381685495376587 | KNN Loss: 2.370668649673462 | CLS Loss: 0.011016860604286194\n",
      "Epoch 111 / 200 | iteration 50 / 171 | Total Loss: 2.4087748527526855 | KNN Loss: 2.402782678604126 | CLS Loss: 0.005992178339511156\n",
      "Epoch 111 / 200 | iteration 60 / 171 | Total Loss: 2.406222343444824 | KNN Loss: 2.3775813579559326 | CLS Loss: 0.028640881180763245\n",
      "Epoch 111 / 200 | iteration 70 / 171 | Total Loss: 2.4427645206451416 | KNN Loss: 2.4156017303466797 | CLS Loss: 0.02716289833188057\n",
      "Epoch 111 / 200 | iteration 80 / 171 | Total Loss: 2.4212496280670166 | KNN Loss: 2.4026033878326416 | CLS Loss: 0.018646271899342537\n",
      "Epoch 111 / 200 | iteration 90 / 171 | Total Loss: 2.438535690307617 | KNN Loss: 2.408503293991089 | CLS Loss: 0.030032379552721977\n",
      "Epoch 111 / 200 | iteration 100 / 171 | Total Loss: 2.4265379905700684 | KNN Loss: 2.4031243324279785 | CLS Loss: 0.023413609713315964\n",
      "Epoch 111 / 200 | iteration 110 / 171 | Total Loss: 2.40728759765625 | KNN Loss: 2.3948163986206055 | CLS Loss: 0.012471146881580353\n",
      "Epoch 111 / 200 | iteration 120 / 171 | Total Loss: 2.4651622772216797 | KNN Loss: 2.450794219970703 | CLS Loss: 0.014368109405040741\n",
      "Epoch 111 / 200 | iteration 130 / 171 | Total Loss: 2.4336142539978027 | KNN Loss: 2.4202630519866943 | CLS Loss: 0.013351290486752987\n",
      "Epoch 111 / 200 | iteration 140 / 171 | Total Loss: 2.462766647338867 | KNN Loss: 2.438298463821411 | CLS Loss: 0.024468112736940384\n",
      "Epoch 111 / 200 | iteration 150 / 171 | Total Loss: 2.3900105953216553 | KNN Loss: 2.3801615238189697 | CLS Loss: 0.009849117137491703\n",
      "Epoch 111 / 200 | iteration 160 / 171 | Total Loss: 2.413806438446045 | KNN Loss: 2.400665760040283 | CLS Loss: 0.013140595518052578\n",
      "Epoch 111 / 200 | iteration 170 / 171 | Total Loss: 2.4004366397857666 | KNN Loss: 2.3807270526885986 | CLS Loss: 0.01970958150923252\n",
      "Epoch: 111, Loss: 2.4213, Train: 0.9958, Valid: 0.9864, Best: 0.9873\n",
      "Epoch 112 / 200 | iteration 0 / 171 | Total Loss: 2.4227211475372314 | KNN Loss: 2.415067195892334 | CLS Loss: 0.007654028479009867\n",
      "Epoch 112 / 200 | iteration 10 / 171 | Total Loss: 2.4249725341796875 | KNN Loss: 2.3895092010498047 | CLS Loss: 0.03546323627233505\n",
      "Epoch 112 / 200 | iteration 20 / 171 | Total Loss: 2.427940845489502 | KNN Loss: 2.4071993827819824 | CLS Loss: 0.020741350948810577\n",
      "Epoch 112 / 200 | iteration 30 / 171 | Total Loss: 2.3989875316619873 | KNN Loss: 2.3939902782440186 | CLS Loss: 0.004997244104743004\n",
      "Epoch 112 / 200 | iteration 40 / 171 | Total Loss: 2.4312870502471924 | KNN Loss: 2.4216952323913574 | CLS Loss: 0.009591898880898952\n",
      "Epoch 112 / 200 | iteration 50 / 171 | Total Loss: 2.4096262454986572 | KNN Loss: 2.3985111713409424 | CLS Loss: 0.011115006171166897\n",
      "Epoch 112 / 200 | iteration 60 / 171 | Total Loss: 2.444608688354492 | KNN Loss: 2.431225061416626 | CLS Loss: 0.013383546844124794\n",
      "Epoch 112 / 200 | iteration 70 / 171 | Total Loss: 2.460494041442871 | KNN Loss: 2.438147783279419 | CLS Loss: 0.022346211597323418\n",
      "Epoch 112 / 200 | iteration 80 / 171 | Total Loss: 2.4244306087493896 | KNN Loss: 2.4047114849090576 | CLS Loss: 0.019719036296010017\n",
      "Epoch 112 / 200 | iteration 90 / 171 | Total Loss: 2.4730048179626465 | KNN Loss: 2.456561326980591 | CLS Loss: 0.016443531960248947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 / 200 | iteration 100 / 171 | Total Loss: 2.4082491397857666 | KNN Loss: 2.3917176723480225 | CLS Loss: 0.01653146930038929\n",
      "Epoch 112 / 200 | iteration 110 / 171 | Total Loss: 2.4349284172058105 | KNN Loss: 2.414348840713501 | CLS Loss: 0.020579524338245392\n",
      "Epoch 112 / 200 | iteration 120 / 171 | Total Loss: 2.38258957862854 | KNN Loss: 2.3809475898742676 | CLS Loss: 0.0016420057509094477\n",
      "Epoch 112 / 200 | iteration 130 / 171 | Total Loss: 2.412882089614868 | KNN Loss: 2.3887999057769775 | CLS Loss: 0.024082284420728683\n",
      "Epoch 112 / 200 | iteration 140 / 171 | Total Loss: 2.453146457672119 | KNN Loss: 2.419658899307251 | CLS Loss: 0.03348749503493309\n",
      "Epoch 112 / 200 | iteration 150 / 171 | Total Loss: 2.4231884479522705 | KNN Loss: 2.4028847217559814 | CLS Loss: 0.0203036367893219\n",
      "Epoch 112 / 200 | iteration 160 / 171 | Total Loss: 2.4183382987976074 | KNN Loss: 2.4025518894195557 | CLS Loss: 0.01578647643327713\n",
      "Epoch 112 / 200 | iteration 170 / 171 | Total Loss: 2.4277119636535645 | KNN Loss: 2.37998628616333 | CLS Loss: 0.047725774347782135\n",
      "Epoch: 112, Loss: 2.4194, Train: 0.9953, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 113 / 200 | iteration 0 / 171 | Total Loss: 2.4117238521575928 | KNN Loss: 2.3950016498565674 | CLS Loss: 0.01672222837805748\n",
      "Epoch 113 / 200 | iteration 10 / 171 | Total Loss: 2.421736478805542 | KNN Loss: 2.4081456661224365 | CLS Loss: 0.013590714894235134\n",
      "Epoch 113 / 200 | iteration 20 / 171 | Total Loss: 2.397825241088867 | KNN Loss: 2.37033748626709 | CLS Loss: 0.027487827464938164\n",
      "Epoch 113 / 200 | iteration 30 / 171 | Total Loss: 2.379509687423706 | KNN Loss: 2.3705902099609375 | CLS Loss: 0.008919580839574337\n",
      "Epoch 113 / 200 | iteration 40 / 171 | Total Loss: 2.42610764503479 | KNN Loss: 2.4147913455963135 | CLS Loss: 0.011316182091832161\n",
      "Epoch 113 / 200 | iteration 50 / 171 | Total Loss: 2.374610185623169 | KNN Loss: 2.361802816390991 | CLS Loss: 0.012807322666049004\n",
      "Epoch 113 / 200 | iteration 60 / 171 | Total Loss: 2.4176316261291504 | KNN Loss: 2.413987159729004 | CLS Loss: 0.0036444789730012417\n",
      "Epoch 113 / 200 | iteration 70 / 171 | Total Loss: 2.418853759765625 | KNN Loss: 2.4032466411590576 | CLS Loss: 0.015607227571308613\n",
      "Epoch 113 / 200 | iteration 80 / 171 | Total Loss: 2.4041340351104736 | KNN Loss: 2.397336483001709 | CLS Loss: 0.006797485053539276\n",
      "Epoch 113 / 200 | iteration 90 / 171 | Total Loss: 2.433330774307251 | KNN Loss: 2.4149909019470215 | CLS Loss: 0.01833995431661606\n",
      "Epoch 113 / 200 | iteration 100 / 171 | Total Loss: 2.399930715560913 | KNN Loss: 2.383044958114624 | CLS Loss: 0.016885800287127495\n",
      "Epoch 113 / 200 | iteration 110 / 171 | Total Loss: 2.4629335403442383 | KNN Loss: 2.456331253051758 | CLS Loss: 0.0066022854298353195\n",
      "Epoch 113 / 200 | iteration 120 / 171 | Total Loss: 2.4029219150543213 | KNN Loss: 2.3957531452178955 | CLS Loss: 0.007168831303715706\n",
      "Epoch 113 / 200 | iteration 130 / 171 | Total Loss: 2.414665937423706 | KNN Loss: 2.3977084159851074 | CLS Loss: 0.01695748046040535\n",
      "Epoch 113 / 200 | iteration 140 / 171 | Total Loss: 2.4162209033966064 | KNN Loss: 2.3822240829467773 | CLS Loss: 0.03399691730737686\n",
      "Epoch 113 / 200 | iteration 150 / 171 | Total Loss: 2.470698118209839 | KNN Loss: 2.4406094551086426 | CLS Loss: 0.03008870594203472\n",
      "Epoch 113 / 200 | iteration 160 / 171 | Total Loss: 2.4385993480682373 | KNN Loss: 2.4223453998565674 | CLS Loss: 0.016253970563411713\n",
      "Epoch 113 / 200 | iteration 170 / 171 | Total Loss: 2.4379806518554688 | KNN Loss: 2.4228909015655518 | CLS Loss: 0.015089663676917553\n",
      "Epoch: 113, Loss: 2.4251, Train: 0.9945, Valid: 0.9851, Best: 0.9873\n",
      "Epoch 114 / 200 | iteration 0 / 171 | Total Loss: 2.489267349243164 | KNN Loss: 2.452364921569824 | CLS Loss: 0.036902520805597305\n",
      "Epoch 114 / 200 | iteration 10 / 171 | Total Loss: 2.3694190979003906 | KNN Loss: 2.3622324466705322 | CLS Loss: 0.007186702452600002\n",
      "Epoch 114 / 200 | iteration 20 / 171 | Total Loss: 2.3984286785125732 | KNN Loss: 2.375035524368286 | CLS Loss: 0.023393191397190094\n",
      "Epoch 114 / 200 | iteration 30 / 171 | Total Loss: 2.4346020221710205 | KNN Loss: 2.4057769775390625 | CLS Loss: 0.0288249421864748\n",
      "Epoch 114 / 200 | iteration 40 / 171 | Total Loss: 2.4363646507263184 | KNN Loss: 2.433425188064575 | CLS Loss: 0.0029394980520009995\n",
      "Epoch 114 / 200 | iteration 50 / 171 | Total Loss: 2.4076240062713623 | KNN Loss: 2.3972280025482178 | CLS Loss: 0.01039609033614397\n",
      "Epoch 114 / 200 | iteration 60 / 171 | Total Loss: 2.4084949493408203 | KNN Loss: 2.3871707916259766 | CLS Loss: 0.021324211731553078\n",
      "Epoch 114 / 200 | iteration 70 / 171 | Total Loss: 2.4442265033721924 | KNN Loss: 2.4241015911102295 | CLS Loss: 0.020125016570091248\n",
      "Epoch 114 / 200 | iteration 80 / 171 | Total Loss: 2.375917434692383 | KNN Loss: 2.369596004486084 | CLS Loss: 0.006321467459201813\n",
      "Epoch 114 / 200 | iteration 90 / 171 | Total Loss: 2.416212320327759 | KNN Loss: 2.4002811908721924 | CLS Loss: 0.015931177884340286\n",
      "Epoch 114 / 200 | iteration 100 / 171 | Total Loss: 2.4224722385406494 | KNN Loss: 2.41017746925354 | CLS Loss: 0.012294688262045383\n",
      "Epoch 114 / 200 | iteration 110 / 171 | Total Loss: 2.4457733631134033 | KNN Loss: 2.4200925827026367 | CLS Loss: 0.025680674239993095\n",
      "Epoch 114 / 200 | iteration 120 / 171 | Total Loss: 2.4106225967407227 | KNN Loss: 2.401484489440918 | CLS Loss: 0.00913799088448286\n",
      "Epoch 114 / 200 | iteration 130 / 171 | Total Loss: 2.4453048706054688 | KNN Loss: 2.3997809886932373 | CLS Loss: 0.04552377015352249\n",
      "Epoch 114 / 200 | iteration 140 / 171 | Total Loss: 2.438584566116333 | KNN Loss: 2.400451183319092 | CLS Loss: 0.038133345544338226\n",
      "Epoch 114 / 200 | iteration 150 / 171 | Total Loss: 2.401344060897827 | KNN Loss: 2.384366750717163 | CLS Loss: 0.016977248713374138\n",
      "Epoch 114 / 200 | iteration 160 / 171 | Total Loss: 2.4276928901672363 | KNN Loss: 2.4015166759490967 | CLS Loss: 0.02617619000375271\n",
      "Epoch 114 / 200 | iteration 170 / 171 | Total Loss: 2.4301810264587402 | KNN Loss: 2.4103474617004395 | CLS Loss: 0.019833682104945183\n",
      "Epoch: 114, Loss: 2.4263, Train: 0.9951, Valid: 0.9853, Best: 0.9873\n",
      "Epoch 115 / 200 | iteration 0 / 171 | Total Loss: 2.409752130508423 | KNN Loss: 2.404656171798706 | CLS Loss: 0.005095934495329857\n",
      "Epoch 115 / 200 | iteration 10 / 171 | Total Loss: 2.4225234985351562 | KNN Loss: 2.406071901321411 | CLS Loss: 0.016451489180326462\n",
      "Epoch 115 / 200 | iteration 20 / 171 | Total Loss: 2.3950791358947754 | KNN Loss: 2.3852529525756836 | CLS Loss: 0.009826155379414558\n",
      "Epoch 115 / 200 | iteration 30 / 171 | Total Loss: 2.421643018722534 | KNN Loss: 2.4123990535736084 | CLS Loss: 0.009244058281183243\n",
      "Epoch 115 / 200 | iteration 40 / 171 | Total Loss: 2.4445343017578125 | KNN Loss: 2.404170274734497 | CLS Loss: 0.04036414623260498\n",
      "Epoch 115 / 200 | iteration 50 / 171 | Total Loss: 2.4427883625030518 | KNN Loss: 2.4274466037750244 | CLS Loss: 0.015341785736382008\n",
      "Epoch 115 / 200 | iteration 60 / 171 | Total Loss: 2.4201459884643555 | KNN Loss: 2.4057881832122803 | CLS Loss: 0.01435788907110691\n",
      "Epoch 115 / 200 | iteration 70 / 171 | Total Loss: 2.438291072845459 | KNN Loss: 2.4325098991394043 | CLS Loss: 0.005781237035989761\n",
      "Epoch 115 / 200 | iteration 80 / 171 | Total Loss: 2.40191912651062 | KNN Loss: 2.3967511653900146 | CLS Loss: 0.005168067757040262\n",
      "Epoch 115 / 200 | iteration 90 / 171 | Total Loss: 2.4527084827423096 | KNN Loss: 2.415560245513916 | CLS Loss: 0.037148211151361465\n",
      "Epoch 115 / 200 | iteration 100 / 171 | Total Loss: 2.400440216064453 | KNN Loss: 2.38995623588562 | CLS Loss: 0.010483878664672375\n",
      "Epoch 115 / 200 | iteration 110 / 171 | Total Loss: 2.3998727798461914 | KNN Loss: 2.397047758102417 | CLS Loss: 0.0028249993920326233\n",
      "Epoch 115 / 200 | iteration 120 / 171 | Total Loss: 2.4259750843048096 | KNN Loss: 2.4033915996551514 | CLS Loss: 0.022583428770303726\n",
      "Epoch 115 / 200 | iteration 130 / 171 | Total Loss: 2.4346892833709717 | KNN Loss: 2.4123222827911377 | CLS Loss: 0.022366972640156746\n",
      "Epoch 115 / 200 | iteration 140 / 171 | Total Loss: 2.4194159507751465 | KNN Loss: 2.3913471698760986 | CLS Loss: 0.02806885540485382\n",
      "Epoch 115 / 200 | iteration 150 / 171 | Total Loss: 2.4175398349761963 | KNN Loss: 2.408912420272827 | CLS Loss: 0.008627357892692089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 / 200 | iteration 160 / 171 | Total Loss: 2.409503936767578 | KNN Loss: 2.3997392654418945 | CLS Loss: 0.00976472720503807\n",
      "Epoch 115 / 200 | iteration 170 / 171 | Total Loss: 2.4153614044189453 | KNN Loss: 2.403148889541626 | CLS Loss: 0.012212545610964298\n",
      "Epoch: 115, Loss: 2.4271, Train: 0.9960, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 116 / 200 | iteration 0 / 171 | Total Loss: 2.399867534637451 | KNN Loss: 2.394695997238159 | CLS Loss: 0.005171430762857199\n",
      "Epoch 116 / 200 | iteration 10 / 171 | Total Loss: 2.420572519302368 | KNN Loss: 2.4115099906921387 | CLS Loss: 0.009062465280294418\n",
      "Epoch 116 / 200 | iteration 20 / 171 | Total Loss: 2.3876309394836426 | KNN Loss: 2.3739027976989746 | CLS Loss: 0.013728126883506775\n",
      "Epoch 116 / 200 | iteration 30 / 171 | Total Loss: 2.449387788772583 | KNN Loss: 2.441389322280884 | CLS Loss: 0.007998385466635227\n",
      "Epoch 116 / 200 | iteration 40 / 171 | Total Loss: 2.408507823944092 | KNN Loss: 2.404376983642578 | CLS Loss: 0.004130837973207235\n",
      "Epoch 116 / 200 | iteration 50 / 171 | Total Loss: 2.453561544418335 | KNN Loss: 2.442523241043091 | CLS Loss: 0.011038261465728283\n",
      "Epoch 116 / 200 | iteration 60 / 171 | Total Loss: 2.3928840160369873 | KNN Loss: 2.3839709758758545 | CLS Loss: 0.008913133293390274\n",
      "Epoch 116 / 200 | iteration 70 / 171 | Total Loss: 2.4092533588409424 | KNN Loss: 2.389591693878174 | CLS Loss: 0.019661573693156242\n",
      "Epoch 116 / 200 | iteration 80 / 171 | Total Loss: 2.4505858421325684 | KNN Loss: 2.4131929874420166 | CLS Loss: 0.03739285096526146\n",
      "Epoch 116 / 200 | iteration 90 / 171 | Total Loss: 2.4606404304504395 | KNN Loss: 2.453575849533081 | CLS Loss: 0.00706455996260047\n",
      "Epoch 116 / 200 | iteration 100 / 171 | Total Loss: 2.3897202014923096 | KNN Loss: 2.380000114440918 | CLS Loss: 0.00972013920545578\n",
      "Epoch 116 / 200 | iteration 110 / 171 | Total Loss: 2.4163436889648438 | KNN Loss: 2.406320333480835 | CLS Loss: 0.010023273527622223\n",
      "Epoch 116 / 200 | iteration 120 / 171 | Total Loss: 2.4779186248779297 | KNN Loss: 2.417572021484375 | CLS Loss: 0.060346588492393494\n",
      "Epoch 116 / 200 | iteration 130 / 171 | Total Loss: 2.383648157119751 | KNN Loss: 2.3695831298828125 | CLS Loss: 0.014065035618841648\n",
      "Epoch 116 / 200 | iteration 140 / 171 | Total Loss: 2.457871437072754 | KNN Loss: 2.440534830093384 | CLS Loss: 0.017336679622530937\n",
      "Epoch 116 / 200 | iteration 150 / 171 | Total Loss: 2.4286415576934814 | KNN Loss: 2.4044313430786133 | CLS Loss: 0.024210125207901\n",
      "Epoch 116 / 200 | iteration 160 / 171 | Total Loss: 2.45396089553833 | KNN Loss: 2.428870439529419 | CLS Loss: 0.025090539827942848\n",
      "Epoch 116 / 200 | iteration 170 / 171 | Total Loss: 2.4396684169769287 | KNN Loss: 2.4327945709228516 | CLS Loss: 0.006873934995383024\n",
      "Epoch: 116, Loss: 2.4262, Train: 0.9947, Valid: 0.9860, Best: 0.9873\n",
      "Epoch 117 / 200 | iteration 0 / 171 | Total Loss: 2.4449081420898438 | KNN Loss: 2.4369888305664062 | CLS Loss: 0.007919281721115112\n",
      "Epoch 117 / 200 | iteration 10 / 171 | Total Loss: 2.4248557090759277 | KNN Loss: 2.4142165184020996 | CLS Loss: 0.01063927635550499\n",
      "Epoch 117 / 200 | iteration 20 / 171 | Total Loss: 2.418393135070801 | KNN Loss: 2.4065921306610107 | CLS Loss: 0.011800992302596569\n",
      "Epoch 117 / 200 | iteration 30 / 171 | Total Loss: 2.4129695892333984 | KNN Loss: 2.4000792503356934 | CLS Loss: 0.012890277430415154\n",
      "Epoch 117 / 200 | iteration 40 / 171 | Total Loss: 2.425255298614502 | KNN Loss: 2.406149387359619 | CLS Loss: 0.01910581812262535\n",
      "Epoch 117 / 200 | iteration 50 / 171 | Total Loss: 2.441404342651367 | KNN Loss: 2.400618553161621 | CLS Loss: 0.040785789489746094\n",
      "Epoch 117 / 200 | iteration 60 / 171 | Total Loss: 2.434770345687866 | KNN Loss: 2.421299934387207 | CLS Loss: 0.013470498844981194\n",
      "Epoch 117 / 200 | iteration 70 / 171 | Total Loss: 2.4120452404022217 | KNN Loss: 2.4021873474121094 | CLS Loss: 0.009857825934886932\n",
      "Epoch 117 / 200 | iteration 80 / 171 | Total Loss: 2.4144043922424316 | KNN Loss: 2.397320032119751 | CLS Loss: 0.017084429040551186\n",
      "Epoch 117 / 200 | iteration 90 / 171 | Total Loss: 2.4145920276641846 | KNN Loss: 2.4052233695983887 | CLS Loss: 0.00936855562031269\n",
      "Epoch 117 / 200 | iteration 100 / 171 | Total Loss: 2.4556610584259033 | KNN Loss: 2.4518635272979736 | CLS Loss: 0.003797593293711543\n",
      "Epoch 117 / 200 | iteration 110 / 171 | Total Loss: 2.4480462074279785 | KNN Loss: 2.4059078693389893 | CLS Loss: 0.04213837534189224\n",
      "Epoch 117 / 200 | iteration 120 / 171 | Total Loss: 2.4238173961639404 | KNN Loss: 2.397766590118408 | CLS Loss: 0.02605082280933857\n",
      "Epoch 117 / 200 | iteration 130 / 171 | Total Loss: 2.4222445487976074 | KNN Loss: 2.4199509620666504 | CLS Loss: 0.002293545054271817\n",
      "Epoch 117 / 200 | iteration 140 / 171 | Total Loss: 2.4095051288604736 | KNN Loss: 2.400973081588745 | CLS Loss: 0.008532143197953701\n",
      "Epoch 117 / 200 | iteration 150 / 171 | Total Loss: 2.4245481491088867 | KNN Loss: 2.4062912464141846 | CLS Loss: 0.018256986513733864\n",
      "Epoch 117 / 200 | iteration 160 / 171 | Total Loss: 2.4250543117523193 | KNN Loss: 2.4153332710266113 | CLS Loss: 0.009721004404127598\n",
      "Epoch 117 / 200 | iteration 170 / 171 | Total Loss: 2.39677357673645 | KNN Loss: 2.388145923614502 | CLS Loss: 0.008627763018012047\n",
      "Epoch: 117, Loss: 2.4231, Train: 0.9945, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 118 / 200 | iteration 0 / 171 | Total Loss: 2.4250576496124268 | KNN Loss: 2.420811891555786 | CLS Loss: 0.004245707765221596\n",
      "Epoch 118 / 200 | iteration 10 / 171 | Total Loss: 2.4217844009399414 | KNN Loss: 2.417858362197876 | CLS Loss: 0.0039259884506464005\n",
      "Epoch 118 / 200 | iteration 20 / 171 | Total Loss: 2.3893938064575195 | KNN Loss: 2.3833959102630615 | CLS Loss: 0.005997937172651291\n",
      "Epoch 118 / 200 | iteration 30 / 171 | Total Loss: 2.3822271823883057 | KNN Loss: 2.3674240112304688 | CLS Loss: 0.014803141355514526\n",
      "Epoch 118 / 200 | iteration 40 / 171 | Total Loss: 2.410064458847046 | KNN Loss: 2.3865859508514404 | CLS Loss: 0.023478562012314796\n",
      "Epoch 118 / 200 | iteration 50 / 171 | Total Loss: 2.4499197006225586 | KNN Loss: 2.426572561264038 | CLS Loss: 0.023347053676843643\n",
      "Epoch 118 / 200 | iteration 60 / 171 | Total Loss: 2.3920106887817383 | KNN Loss: 2.3830294609069824 | CLS Loss: 0.008981256745755672\n",
      "Epoch 118 / 200 | iteration 70 / 171 | Total Loss: 2.390083074569702 | KNN Loss: 2.3625309467315674 | CLS Loss: 0.02755209244787693\n",
      "Epoch 118 / 200 | iteration 80 / 171 | Total Loss: 2.4225916862487793 | KNN Loss: 2.40124773979187 | CLS Loss: 0.021343931555747986\n",
      "Epoch 118 / 200 | iteration 90 / 171 | Total Loss: 2.4429426193237305 | KNN Loss: 2.4217216968536377 | CLS Loss: 0.021220868453383446\n",
      "Epoch 118 / 200 | iteration 100 / 171 | Total Loss: 2.471036434173584 | KNN Loss: 2.451266288757324 | CLS Loss: 0.01977023296058178\n",
      "Epoch 118 / 200 | iteration 110 / 171 | Total Loss: 2.4483306407928467 | KNN Loss: 2.4388952255249023 | CLS Loss: 0.009435384534299374\n",
      "Epoch 118 / 200 | iteration 120 / 171 | Total Loss: 2.433999538421631 | KNN Loss: 2.4150962829589844 | CLS Loss: 0.018903374671936035\n",
      "Epoch 118 / 200 | iteration 130 / 171 | Total Loss: 2.4349524974823 | KNN Loss: 2.419308662414551 | CLS Loss: 0.01564388908445835\n",
      "Epoch 118 / 200 | iteration 140 / 171 | Total Loss: 2.420823335647583 | KNN Loss: 2.3973047733306885 | CLS Loss: 0.023518621921539307\n",
      "Epoch 118 / 200 | iteration 150 / 171 | Total Loss: 2.406919240951538 | KNN Loss: 2.366405725479126 | CLS Loss: 0.04051348939538002\n",
      "Epoch 118 / 200 | iteration 160 / 171 | Total Loss: 2.4622724056243896 | KNN Loss: 2.4385874271392822 | CLS Loss: 0.023685092106461525\n",
      "Epoch 118 / 200 | iteration 170 / 171 | Total Loss: 2.418513774871826 | KNN Loss: 2.4140090942382812 | CLS Loss: 0.004504628479480743\n",
      "Epoch: 118, Loss: 2.4305, Train: 0.9954, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 119 / 200 | iteration 0 / 171 | Total Loss: 2.404688835144043 | KNN Loss: 2.38836932182312 | CLS Loss: 0.016319533810019493\n",
      "Epoch 119 / 200 | iteration 10 / 171 | Total Loss: 2.435821056365967 | KNN Loss: 2.429530382156372 | CLS Loss: 0.006290696561336517\n",
      "Epoch 119 / 200 | iteration 20 / 171 | Total Loss: 2.404022216796875 | KNN Loss: 2.3691999912261963 | CLS Loss: 0.03482217714190483\n",
      "Epoch 119 / 200 | iteration 30 / 171 | Total Loss: 2.3858237266540527 | KNN Loss: 2.381410837173462 | CLS Loss: 0.004412943497300148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 / 200 | iteration 40 / 171 | Total Loss: 2.4057178497314453 | KNN Loss: 2.37969708442688 | CLS Loss: 0.026020776480436325\n",
      "Epoch 119 / 200 | iteration 50 / 171 | Total Loss: 2.421367883682251 | KNN Loss: 2.4002532958984375 | CLS Loss: 0.02111465483903885\n",
      "Epoch 119 / 200 | iteration 60 / 171 | Total Loss: 2.3934879302978516 | KNN Loss: 2.3834939002990723 | CLS Loss: 0.009994005784392357\n",
      "Epoch 119 / 200 | iteration 70 / 171 | Total Loss: 2.433379888534546 | KNN Loss: 2.4190707206726074 | CLS Loss: 0.014309154823422432\n",
      "Epoch 119 / 200 | iteration 80 / 171 | Total Loss: 2.419113874435425 | KNN Loss: 2.4131522178649902 | CLS Loss: 0.005961698479950428\n",
      "Epoch 119 / 200 | iteration 90 / 171 | Total Loss: 2.434375286102295 | KNN Loss: 2.4237418174743652 | CLS Loss: 0.010633576661348343\n",
      "Epoch 119 / 200 | iteration 100 / 171 | Total Loss: 2.459456205368042 | KNN Loss: 2.452127456665039 | CLS Loss: 0.007328852079808712\n",
      "Epoch 119 / 200 | iteration 110 / 171 | Total Loss: 2.425854206085205 | KNN Loss: 2.4052023887634277 | CLS Loss: 0.02065187506377697\n",
      "Epoch 119 / 200 | iteration 120 / 171 | Total Loss: 2.3832504749298096 | KNN Loss: 2.379133701324463 | CLS Loss: 0.004116766154766083\n",
      "Epoch 119 / 200 | iteration 130 / 171 | Total Loss: 2.4496591091156006 | KNN Loss: 2.424792766571045 | CLS Loss: 0.024866243824362755\n",
      "Epoch 119 / 200 | iteration 140 / 171 | Total Loss: 2.41403865814209 | KNN Loss: 2.3978986740112305 | CLS Loss: 0.016140099614858627\n",
      "Epoch 119 / 200 | iteration 150 / 171 | Total Loss: 2.418342351913452 | KNN Loss: 2.4070005416870117 | CLS Loss: 0.011341862380504608\n",
      "Epoch 119 / 200 | iteration 160 / 171 | Total Loss: 2.4544849395751953 | KNN Loss: 2.4421989917755127 | CLS Loss: 0.012285887263715267\n",
      "Epoch 119 / 200 | iteration 170 / 171 | Total Loss: 2.443145513534546 | KNN Loss: 2.4182217121124268 | CLS Loss: 0.024923857301473618\n",
      "Epoch: 119, Loss: 2.4295, Train: 0.9948, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 120 / 200 | iteration 0 / 171 | Total Loss: 2.39831805229187 | KNN Loss: 2.3842508792877197 | CLS Loss: 0.014067107811570168\n",
      "Epoch 120 / 200 | iteration 10 / 171 | Total Loss: 2.381743907928467 | KNN Loss: 2.3745529651641846 | CLS Loss: 0.007190860342234373\n",
      "Epoch 120 / 200 | iteration 20 / 171 | Total Loss: 2.4184675216674805 | KNN Loss: 2.4135732650756836 | CLS Loss: 0.0048942300491034985\n",
      "Epoch 120 / 200 | iteration 30 / 171 | Total Loss: 2.412236213684082 | KNN Loss: 2.3986122608184814 | CLS Loss: 0.013623837381601334\n",
      "Epoch 120 / 200 | iteration 40 / 171 | Total Loss: 2.42301082611084 | KNN Loss: 2.4040682315826416 | CLS Loss: 0.018942659720778465\n",
      "Epoch 120 / 200 | iteration 50 / 171 | Total Loss: 2.4774281978607178 | KNN Loss: 2.4457595348358154 | CLS Loss: 0.03166857361793518\n",
      "Epoch 120 / 200 | iteration 60 / 171 | Total Loss: 2.4434921741485596 | KNN Loss: 2.424548864364624 | CLS Loss: 0.01894332841038704\n",
      "Epoch 120 / 200 | iteration 70 / 171 | Total Loss: 2.5074896812438965 | KNN Loss: 2.477055311203003 | CLS Loss: 0.030434319749474525\n",
      "Epoch 120 / 200 | iteration 80 / 171 | Total Loss: 2.422851324081421 | KNN Loss: 2.4074819087982178 | CLS Loss: 0.015369310975074768\n",
      "Epoch 120 / 200 | iteration 90 / 171 | Total Loss: 2.432624101638794 | KNN Loss: 2.4210853576660156 | CLS Loss: 0.011538777500391006\n",
      "Epoch 120 / 200 | iteration 100 / 171 | Total Loss: 2.4155259132385254 | KNN Loss: 2.4045212268829346 | CLS Loss: 0.011004680767655373\n",
      "Epoch 120 / 200 | iteration 110 / 171 | Total Loss: 2.3994686603546143 | KNN Loss: 2.3840277194976807 | CLS Loss: 0.01544098649173975\n",
      "Epoch 120 / 200 | iteration 120 / 171 | Total Loss: 2.4172415733337402 | KNN Loss: 2.4028995037078857 | CLS Loss: 0.014342101290822029\n",
      "Epoch 120 / 200 | iteration 130 / 171 | Total Loss: 2.432542562484741 | KNN Loss: 2.412125825881958 | CLS Loss: 0.02041662484407425\n",
      "Epoch 120 / 200 | iteration 140 / 171 | Total Loss: 2.392688035964966 | KNN Loss: 2.3783562183380127 | CLS Loss: 0.014331787824630737\n",
      "Epoch 120 / 200 | iteration 150 / 171 | Total Loss: 2.452085018157959 | KNN Loss: 2.4274401664733887 | CLS Loss: 0.02464490570127964\n",
      "Epoch 120 / 200 | iteration 160 / 171 | Total Loss: 2.407169818878174 | KNN Loss: 2.396921396255493 | CLS Loss: 0.010248438455164433\n",
      "Epoch 120 / 200 | iteration 170 / 171 | Total Loss: 2.429140329360962 | KNN Loss: 2.4143564701080322 | CLS Loss: 0.014783746562898159\n",
      "Epoch: 120, Loss: 2.4260, Train: 0.9954, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 121 / 200 | iteration 0 / 171 | Total Loss: 2.426827907562256 | KNN Loss: 2.4100751876831055 | CLS Loss: 0.016752805560827255\n",
      "Epoch 121 / 200 | iteration 10 / 171 | Total Loss: 2.4178638458251953 | KNN Loss: 2.4093425273895264 | CLS Loss: 0.00852133333683014\n",
      "Epoch 121 / 200 | iteration 20 / 171 | Total Loss: 2.4023799896240234 | KNN Loss: 2.3702213764190674 | CLS Loss: 0.03215856850147247\n",
      "Epoch 121 / 200 | iteration 30 / 171 | Total Loss: 2.414078712463379 | KNN Loss: 2.386455535888672 | CLS Loss: 0.027623113244771957\n",
      "Epoch 121 / 200 | iteration 40 / 171 | Total Loss: 2.4417402744293213 | KNN Loss: 2.420474052429199 | CLS Loss: 0.021266255527734756\n",
      "Epoch 121 / 200 | iteration 50 / 171 | Total Loss: 2.4165256023406982 | KNN Loss: 2.402348279953003 | CLS Loss: 0.0141774145886302\n",
      "Epoch 121 / 200 | iteration 60 / 171 | Total Loss: 2.4441111087799072 | KNN Loss: 2.4312756061553955 | CLS Loss: 0.012835433706641197\n",
      "Epoch 121 / 200 | iteration 70 / 171 | Total Loss: 2.4030373096466064 | KNN Loss: 2.3893628120422363 | CLS Loss: 0.01367440726608038\n",
      "Epoch 121 / 200 | iteration 80 / 171 | Total Loss: 2.4085378646850586 | KNN Loss: 2.402338981628418 | CLS Loss: 0.006198869552463293\n",
      "Epoch 121 / 200 | iteration 90 / 171 | Total Loss: 2.42436146736145 | KNN Loss: 2.4026565551757812 | CLS Loss: 0.021704858168959618\n",
      "Epoch 121 / 200 | iteration 100 / 171 | Total Loss: 2.459470510482788 | KNN Loss: 2.4452569484710693 | CLS Loss: 0.014213543385267258\n",
      "Epoch 121 / 200 | iteration 110 / 171 | Total Loss: 2.404790163040161 | KNN Loss: 2.3949854373931885 | CLS Loss: 0.009804811328649521\n",
      "Epoch 121 / 200 | iteration 120 / 171 | Total Loss: 2.4022574424743652 | KNN Loss: 2.3941028118133545 | CLS Loss: 0.0081546101719141\n",
      "Epoch 121 / 200 | iteration 130 / 171 | Total Loss: 2.419158697128296 | KNN Loss: 2.410663366317749 | CLS Loss: 0.008495252579450607\n",
      "Epoch 121 / 200 | iteration 140 / 171 | Total Loss: 2.4069600105285645 | KNN Loss: 2.399271011352539 | CLS Loss: 0.0076889838092029095\n",
      "Epoch 121 / 200 | iteration 150 / 171 | Total Loss: 2.4384772777557373 | KNN Loss: 2.4273252487182617 | CLS Loss: 0.011152015067636967\n",
      "Epoch 121 / 200 | iteration 160 / 171 | Total Loss: 2.404426097869873 | KNN Loss: 2.383192539215088 | CLS Loss: 0.021233592182397842\n",
      "Epoch 121 / 200 | iteration 170 / 171 | Total Loss: 2.436228036880493 | KNN Loss: 2.403916835784912 | CLS Loss: 0.03231121227145195\n",
      "Epoch: 121, Loss: 2.4231, Train: 0.9951, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 122 / 200 | iteration 0 / 171 | Total Loss: 2.445429563522339 | KNN Loss: 2.438413381576538 | CLS Loss: 0.0070161763578653336\n",
      "Epoch 122 / 200 | iteration 10 / 171 | Total Loss: 2.36950421333313 | KNN Loss: 2.359820604324341 | CLS Loss: 0.009683599695563316\n",
      "Epoch 122 / 200 | iteration 20 / 171 | Total Loss: 2.438873291015625 | KNN Loss: 2.4050567150115967 | CLS Loss: 0.03381666541099548\n",
      "Epoch 122 / 200 | iteration 30 / 171 | Total Loss: 2.428492546081543 | KNN Loss: 2.414027452468872 | CLS Loss: 0.014465092681348324\n",
      "Epoch 122 / 200 | iteration 40 / 171 | Total Loss: 2.4746668338775635 | KNN Loss: 2.457171678543091 | CLS Loss: 0.017495140433311462\n",
      "Epoch 122 / 200 | iteration 50 / 171 | Total Loss: 2.422398090362549 | KNN Loss: 2.409930944442749 | CLS Loss: 0.012467162683606148\n",
      "Epoch 122 / 200 | iteration 60 / 171 | Total Loss: 2.3640618324279785 | KNN Loss: 2.3624703884124756 | CLS Loss: 0.0015914331888779998\n",
      "Epoch 122 / 200 | iteration 70 / 171 | Total Loss: 2.4512548446655273 | KNN Loss: 2.4188058376312256 | CLS Loss: 0.032448943704366684\n",
      "Epoch 122 / 200 | iteration 80 / 171 | Total Loss: 2.4287099838256836 | KNN Loss: 2.413050413131714 | CLS Loss: 0.015659598633646965\n",
      "Epoch 122 / 200 | iteration 90 / 171 | Total Loss: 2.4519853591918945 | KNN Loss: 2.4290733337402344 | CLS Loss: 0.0229120384901762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 / 200 | iteration 100 / 171 | Total Loss: 2.404557943344116 | KNN Loss: 2.397101640701294 | CLS Loss: 0.00745633477345109\n",
      "Epoch 122 / 200 | iteration 110 / 171 | Total Loss: 2.434159278869629 | KNN Loss: 2.408547878265381 | CLS Loss: 0.02561141364276409\n",
      "Epoch 122 / 200 | iteration 120 / 171 | Total Loss: 2.4244706630706787 | KNN Loss: 2.407862424850464 | CLS Loss: 0.016608137637376785\n",
      "Epoch 122 / 200 | iteration 130 / 171 | Total Loss: 2.382575750350952 | KNN Loss: 2.364762783050537 | CLS Loss: 0.01781296357512474\n",
      "Epoch 122 / 200 | iteration 140 / 171 | Total Loss: 2.4460153579711914 | KNN Loss: 2.4384233951568604 | CLS Loss: 0.0075920443050563335\n",
      "Epoch 122 / 200 | iteration 150 / 171 | Total Loss: 2.448647975921631 | KNN Loss: 2.421083688735962 | CLS Loss: 0.02756418101489544\n",
      "Epoch 122 / 200 | iteration 160 / 171 | Total Loss: 2.433551549911499 | KNN Loss: 2.4132750034332275 | CLS Loss: 0.020276609808206558\n",
      "Epoch 122 / 200 | iteration 170 / 171 | Total Loss: 2.438599109649658 | KNN Loss: 2.405972957611084 | CLS Loss: 0.032626040279865265\n",
      "Epoch: 122, Loss: 2.4251, Train: 0.9941, Valid: 0.9850, Best: 0.9873\n",
      "Epoch 123 / 200 | iteration 0 / 171 | Total Loss: 2.4285175800323486 | KNN Loss: 2.4110686779022217 | CLS Loss: 0.01744888350367546\n",
      "Epoch 123 / 200 | iteration 10 / 171 | Total Loss: 2.4425854682922363 | KNN Loss: 2.434072971343994 | CLS Loss: 0.008512585423886776\n",
      "Epoch 123 / 200 | iteration 20 / 171 | Total Loss: 2.371851682662964 | KNN Loss: 2.362506151199341 | CLS Loss: 0.009345493279397488\n",
      "Epoch 123 / 200 | iteration 30 / 171 | Total Loss: 2.3969502449035645 | KNN Loss: 2.3870649337768555 | CLS Loss: 0.009885219857096672\n",
      "Epoch 123 / 200 | iteration 40 / 171 | Total Loss: 2.4257609844207764 | KNN Loss: 2.4209399223327637 | CLS Loss: 0.004821162670850754\n",
      "Epoch 123 / 200 | iteration 50 / 171 | Total Loss: 2.4277710914611816 | KNN Loss: 2.4191555976867676 | CLS Loss: 0.008615379221737385\n",
      "Epoch 123 / 200 | iteration 60 / 171 | Total Loss: 2.3768765926361084 | KNN Loss: 2.3592631816864014 | CLS Loss: 0.01761346496641636\n",
      "Epoch 123 / 200 | iteration 70 / 171 | Total Loss: 2.410090923309326 | KNN Loss: 2.4030086994171143 | CLS Loss: 0.00708212424069643\n",
      "Epoch 123 / 200 | iteration 80 / 171 | Total Loss: 2.4012556076049805 | KNN Loss: 2.395021677017212 | CLS Loss: 0.006233874708414078\n",
      "Epoch 123 / 200 | iteration 90 / 171 | Total Loss: 2.4348843097686768 | KNN Loss: 2.405759572982788 | CLS Loss: 0.029124783352017403\n",
      "Epoch 123 / 200 | iteration 100 / 171 | Total Loss: 2.408133029937744 | KNN Loss: 2.386707305908203 | CLS Loss: 0.021425776183605194\n",
      "Epoch 123 / 200 | iteration 110 / 171 | Total Loss: 2.394066333770752 | KNN Loss: 2.384096622467041 | CLS Loss: 0.009969638660550117\n",
      "Epoch 123 / 200 | iteration 120 / 171 | Total Loss: 2.4649877548217773 | KNN Loss: 2.4452176094055176 | CLS Loss: 0.019770242273807526\n",
      "Epoch 123 / 200 | iteration 130 / 171 | Total Loss: 2.4157369136810303 | KNN Loss: 2.4033186435699463 | CLS Loss: 0.012418188154697418\n",
      "Epoch 123 / 200 | iteration 140 / 171 | Total Loss: 2.461475133895874 | KNN Loss: 2.4456088542938232 | CLS Loss: 0.015866367146372795\n",
      "Epoch 123 / 200 | iteration 150 / 171 | Total Loss: 2.3842642307281494 | KNN Loss: 2.3707773685455322 | CLS Loss: 0.013486960902810097\n",
      "Epoch 123 / 200 | iteration 160 / 171 | Total Loss: 2.408719539642334 | KNN Loss: 2.396394729614258 | CLS Loss: 0.012324904091656208\n",
      "Epoch 123 / 200 | iteration 170 / 171 | Total Loss: 2.4271435737609863 | KNN Loss: 2.417672872543335 | CLS Loss: 0.009470726363360882\n",
      "Epoch: 123, Loss: 2.4247, Train: 0.9954, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 124 / 200 | iteration 0 / 171 | Total Loss: 2.4138762950897217 | KNN Loss: 2.4041244983673096 | CLS Loss: 0.009751792065799236\n",
      "Epoch 124 / 200 | iteration 10 / 171 | Total Loss: 2.4151062965393066 | KNN Loss: 2.387906789779663 | CLS Loss: 0.02719947136938572\n",
      "Epoch 124 / 200 | iteration 20 / 171 | Total Loss: 2.417926788330078 | KNN Loss: 2.4135210514068604 | CLS Loss: 0.004405755549669266\n",
      "Epoch 124 / 200 | iteration 30 / 171 | Total Loss: 2.446185827255249 | KNN Loss: 2.423954725265503 | CLS Loss: 0.02223098836839199\n",
      "Epoch 124 / 200 | iteration 40 / 171 | Total Loss: 2.402085542678833 | KNN Loss: 2.393711805343628 | CLS Loss: 0.008373714983463287\n",
      "Epoch 124 / 200 | iteration 50 / 171 | Total Loss: 2.4225592613220215 | KNN Loss: 2.412688732147217 | CLS Loss: 0.009870599023997784\n",
      "Epoch 124 / 200 | iteration 60 / 171 | Total Loss: 2.4281554222106934 | KNN Loss: 2.4205234050750732 | CLS Loss: 0.0076320357620716095\n",
      "Epoch 124 / 200 | iteration 70 / 171 | Total Loss: 2.40370512008667 | KNN Loss: 2.3944151401519775 | CLS Loss: 0.00929000973701477\n",
      "Epoch 124 / 200 | iteration 80 / 171 | Total Loss: 2.423149585723877 | KNN Loss: 2.4198384284973145 | CLS Loss: 0.003311231965199113\n",
      "Epoch 124 / 200 | iteration 90 / 171 | Total Loss: 2.396543025970459 | KNN Loss: 2.3937861919403076 | CLS Loss: 0.002756843576207757\n",
      "Epoch 124 / 200 | iteration 100 / 171 | Total Loss: 2.4223217964172363 | KNN Loss: 2.396254777908325 | CLS Loss: 0.026066960766911507\n",
      "Epoch 124 / 200 | iteration 110 / 171 | Total Loss: 2.4048283100128174 | KNN Loss: 2.3981380462646484 | CLS Loss: 0.0066903624683618546\n",
      "Epoch 124 / 200 | iteration 120 / 171 | Total Loss: 2.412367582321167 | KNN Loss: 2.4043571949005127 | CLS Loss: 0.008010279387235641\n",
      "Epoch 124 / 200 | iteration 130 / 171 | Total Loss: 2.4488754272460938 | KNN Loss: 2.4286530017852783 | CLS Loss: 0.0202224962413311\n",
      "Epoch 124 / 200 | iteration 140 / 171 | Total Loss: 2.4089810848236084 | KNN Loss: 2.385948896408081 | CLS Loss: 0.023032160475850105\n",
      "Epoch 124 / 200 | iteration 150 / 171 | Total Loss: 2.4236528873443604 | KNN Loss: 2.4118998050689697 | CLS Loss: 0.011753080412745476\n",
      "Epoch 124 / 200 | iteration 160 / 171 | Total Loss: 2.3840267658233643 | KNN Loss: 2.3698556423187256 | CLS Loss: 0.014171037822961807\n",
      "Epoch 124 / 200 | iteration 170 / 171 | Total Loss: 2.4068589210510254 | KNN Loss: 2.393068313598633 | CLS Loss: 0.013790696859359741\n",
      "Epoch: 124, Loss: 2.4249, Train: 0.9956, Valid: 0.9856, Best: 0.9873\n",
      "Epoch 125 / 200 | iteration 0 / 171 | Total Loss: 2.4244608879089355 | KNN Loss: 2.3950300216674805 | CLS Loss: 0.029430916532874107\n",
      "Epoch 125 / 200 | iteration 10 / 171 | Total Loss: 2.423942804336548 | KNN Loss: 2.4200947284698486 | CLS Loss: 0.003847995540127158\n",
      "Epoch 125 / 200 | iteration 20 / 171 | Total Loss: 2.4627909660339355 | KNN Loss: 2.4333996772766113 | CLS Loss: 0.029391268268227577\n",
      "Epoch 125 / 200 | iteration 30 / 171 | Total Loss: 2.454655170440674 | KNN Loss: 2.4438672065734863 | CLS Loss: 0.01078790333122015\n",
      "Epoch 125 / 200 | iteration 40 / 171 | Total Loss: 2.438786506652832 | KNN Loss: 2.4109067916870117 | CLS Loss: 0.027879707515239716\n",
      "Epoch 125 / 200 | iteration 50 / 171 | Total Loss: 2.439256429672241 | KNN Loss: 2.432955741882324 | CLS Loss: 0.00630072271451354\n",
      "Epoch 125 / 200 | iteration 60 / 171 | Total Loss: 2.4141414165496826 | KNN Loss: 2.4029645919799805 | CLS Loss: 0.011176729574799538\n",
      "Epoch 125 / 200 | iteration 70 / 171 | Total Loss: 2.4081239700317383 | KNN Loss: 2.3916640281677246 | CLS Loss: 0.01645992323756218\n",
      "Epoch 125 / 200 | iteration 80 / 171 | Total Loss: 2.4317708015441895 | KNN Loss: 2.418344497680664 | CLS Loss: 0.013426307588815689\n",
      "Epoch 125 / 200 | iteration 90 / 171 | Total Loss: 2.476848840713501 | KNN Loss: 2.4604885578155518 | CLS Loss: 0.016360176727175713\n",
      "Epoch 125 / 200 | iteration 100 / 171 | Total Loss: 2.4145936965942383 | KNN Loss: 2.4055263996124268 | CLS Loss: 0.009067283011972904\n",
      "Epoch 125 / 200 | iteration 110 / 171 | Total Loss: 2.4257664680480957 | KNN Loss: 2.368063449859619 | CLS Loss: 0.05770307779312134\n",
      "Epoch 125 / 200 | iteration 120 / 171 | Total Loss: 2.419349431991577 | KNN Loss: 2.4026596546173096 | CLS Loss: 0.016689825803041458\n",
      "Epoch 125 / 200 | iteration 130 / 171 | Total Loss: 2.38748836517334 | KNN Loss: 2.3554134368896484 | CLS Loss: 0.03207503259181976\n",
      "Epoch 125 / 200 | iteration 140 / 171 | Total Loss: 2.3922619819641113 | KNN Loss: 2.3797225952148438 | CLS Loss: 0.012539436109364033\n",
      "Epoch 125 / 200 | iteration 150 / 171 | Total Loss: 2.397167444229126 | KNN Loss: 2.3692028522491455 | CLS Loss: 0.0279645174741745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 / 200 | iteration 160 / 171 | Total Loss: 2.4472408294677734 | KNN Loss: 2.4342398643493652 | CLS Loss: 0.01300099678337574\n",
      "Epoch 125 / 200 | iteration 170 / 171 | Total Loss: 2.43477201461792 | KNN Loss: 2.42405104637146 | CLS Loss: 0.010720849968492985\n",
      "Epoch: 125, Loss: 2.4259, Train: 0.9959, Valid: 0.9864, Best: 0.9873\n",
      "Epoch 126 / 200 | iteration 0 / 171 | Total Loss: 2.41845965385437 | KNN Loss: 2.414199113845825 | CLS Loss: 0.004260484594851732\n",
      "Epoch 126 / 200 | iteration 10 / 171 | Total Loss: 2.4278173446655273 | KNN Loss: 2.4222986698150635 | CLS Loss: 0.005518776830285788\n",
      "Epoch 126 / 200 | iteration 20 / 171 | Total Loss: 2.4058234691619873 | KNN Loss: 2.3878586292266846 | CLS Loss: 0.01796477474272251\n",
      "Epoch 126 / 200 | iteration 30 / 171 | Total Loss: 2.426086664199829 | KNN Loss: 2.400967836380005 | CLS Loss: 0.02511891908943653\n",
      "Epoch 126 / 200 | iteration 40 / 171 | Total Loss: 2.4320223331451416 | KNN Loss: 2.410773515701294 | CLS Loss: 0.021248819306492805\n",
      "Epoch 126 / 200 | iteration 50 / 171 | Total Loss: 2.4321396350860596 | KNN Loss: 2.411964178085327 | CLS Loss: 0.020175548270344734\n",
      "Epoch 126 / 200 | iteration 60 / 171 | Total Loss: 2.4311821460723877 | KNN Loss: 2.406343936920166 | CLS Loss: 0.02483811415731907\n",
      "Epoch 126 / 200 | iteration 70 / 171 | Total Loss: 2.3906805515289307 | KNN Loss: 2.3749938011169434 | CLS Loss: 0.015686681494116783\n",
      "Epoch 126 / 200 | iteration 80 / 171 | Total Loss: 2.406155586242676 | KNN Loss: 2.4006755352020264 | CLS Loss: 0.0054800729267299175\n",
      "Epoch 126 / 200 | iteration 90 / 171 | Total Loss: 2.4342103004455566 | KNN Loss: 2.4159693717956543 | CLS Loss: 0.01824103854596615\n",
      "Epoch 126 / 200 | iteration 100 / 171 | Total Loss: 2.4318532943725586 | KNN Loss: 2.4042253494262695 | CLS Loss: 0.027627920731902122\n",
      "Epoch 126 / 200 | iteration 110 / 171 | Total Loss: 2.428687810897827 | KNN Loss: 2.4239206314086914 | CLS Loss: 0.004767146427184343\n",
      "Epoch 126 / 200 | iteration 120 / 171 | Total Loss: 2.4229736328125 | KNN Loss: 2.4063327312469482 | CLS Loss: 0.016640791669487953\n",
      "Epoch 126 / 200 | iteration 130 / 171 | Total Loss: 2.4139671325683594 | KNN Loss: 2.3967764377593994 | CLS Loss: 0.017190760001540184\n",
      "Epoch 126 / 200 | iteration 140 / 171 | Total Loss: 2.386950731277466 | KNN Loss: 2.375802993774414 | CLS Loss: 0.011147784069180489\n",
      "Epoch 126 / 200 | iteration 150 / 171 | Total Loss: 2.3827056884765625 | KNN Loss: 2.3624370098114014 | CLS Loss: 0.020268647000193596\n",
      "Epoch 126 / 200 | iteration 160 / 171 | Total Loss: 2.402353525161743 | KNN Loss: 2.398493766784668 | CLS Loss: 0.0038597439415752888\n",
      "Epoch 126 / 200 | iteration 170 / 171 | Total Loss: 2.4035604000091553 | KNN Loss: 2.3830008506774902 | CLS Loss: 0.020559491589665413\n",
      "Epoch: 126, Loss: 2.4223, Train: 0.9959, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 127 / 200 | iteration 0 / 171 | Total Loss: 2.4038631916046143 | KNN Loss: 2.38334321975708 | CLS Loss: 0.020519964396953583\n",
      "Epoch 127 / 200 | iteration 10 / 171 | Total Loss: 2.3956573009490967 | KNN Loss: 2.388622760772705 | CLS Loss: 0.007034443784505129\n",
      "Epoch 127 / 200 | iteration 20 / 171 | Total Loss: 2.468088150024414 | KNN Loss: 2.438961982727051 | CLS Loss: 0.029126204550266266\n",
      "Epoch 127 / 200 | iteration 30 / 171 | Total Loss: 2.3911354541778564 | KNN Loss: 2.389322280883789 | CLS Loss: 0.0018132110126316547\n",
      "Epoch 127 / 200 | iteration 40 / 171 | Total Loss: 2.4426136016845703 | KNN Loss: 2.4402999877929688 | CLS Loss: 0.002313514705747366\n",
      "Epoch 127 / 200 | iteration 50 / 171 | Total Loss: 2.417548179626465 | KNN Loss: 2.3951761722564697 | CLS Loss: 0.02237210050225258\n",
      "Epoch 127 / 200 | iteration 60 / 171 | Total Loss: 2.4544711112976074 | KNN Loss: 2.4313979148864746 | CLS Loss: 0.023073244839906693\n",
      "Epoch 127 / 200 | iteration 70 / 171 | Total Loss: 2.417304515838623 | KNN Loss: 2.4066755771636963 | CLS Loss: 0.010628977790474892\n",
      "Epoch 127 / 200 | iteration 80 / 171 | Total Loss: 2.427429437637329 | KNN Loss: 2.4026925563812256 | CLS Loss: 0.024736911058425903\n",
      "Epoch 127 / 200 | iteration 90 / 171 | Total Loss: 2.4336283206939697 | KNN Loss: 2.4150590896606445 | CLS Loss: 0.01856912486255169\n",
      "Epoch 127 / 200 | iteration 100 / 171 | Total Loss: 2.4421913623809814 | KNN Loss: 2.426050901412964 | CLS Loss: 0.016140438616275787\n",
      "Epoch 127 / 200 | iteration 110 / 171 | Total Loss: 2.407663106918335 | KNN Loss: 2.402947187423706 | CLS Loss: 0.004716014955192804\n",
      "Epoch 127 / 200 | iteration 120 / 171 | Total Loss: 2.3933217525482178 | KNN Loss: 2.373244285583496 | CLS Loss: 0.020077385008335114\n",
      "Epoch 127 / 200 | iteration 130 / 171 | Total Loss: 2.461724281311035 | KNN Loss: 2.4490554332733154 | CLS Loss: 0.012668808922171593\n",
      "Epoch 127 / 200 | iteration 140 / 171 | Total Loss: 2.418480634689331 | KNN Loss: 2.41158390045166 | CLS Loss: 0.006896823178976774\n",
      "Epoch 127 / 200 | iteration 150 / 171 | Total Loss: 2.4447386264801025 | KNN Loss: 2.4299509525299072 | CLS Loss: 0.01478758454322815\n",
      "Epoch 127 / 200 | iteration 160 / 171 | Total Loss: 2.419881820678711 | KNN Loss: 2.4025986194610596 | CLS Loss: 0.01728328876197338\n",
      "Epoch 127 / 200 | iteration 170 / 171 | Total Loss: 2.429072856903076 | KNN Loss: 2.405487537384033 | CLS Loss: 0.02358539029955864\n",
      "Epoch: 127, Loss: 2.4239, Train: 0.9957, Valid: 0.9859, Best: 0.9873\n",
      "Epoch 128 / 200 | iteration 0 / 171 | Total Loss: 2.4242749214172363 | KNN Loss: 2.4007761478424072 | CLS Loss: 0.023498820140957832\n",
      "Epoch 128 / 200 | iteration 10 / 171 | Total Loss: 2.4027342796325684 | KNN Loss: 2.3813693523406982 | CLS Loss: 0.021364929154515266\n",
      "Epoch 128 / 200 | iteration 20 / 171 | Total Loss: 2.411416530609131 | KNN Loss: 2.3743412494659424 | CLS Loss: 0.037075337022542953\n",
      "Epoch 128 / 200 | iteration 30 / 171 | Total Loss: 2.471135377883911 | KNN Loss: 2.4550578594207764 | CLS Loss: 0.016077466309070587\n",
      "Epoch 128 / 200 | iteration 40 / 171 | Total Loss: 2.4086520671844482 | KNN Loss: 2.4019503593444824 | CLS Loss: 0.006701822858303785\n",
      "Epoch 128 / 200 | iteration 50 / 171 | Total Loss: 2.4714090824127197 | KNN Loss: 2.4534108638763428 | CLS Loss: 0.017998259514570236\n",
      "Epoch 128 / 200 | iteration 60 / 171 | Total Loss: 2.4376862049102783 | KNN Loss: 2.4268221855163574 | CLS Loss: 0.01086405012756586\n",
      "Epoch 128 / 200 | iteration 70 / 171 | Total Loss: 2.4189231395721436 | KNN Loss: 2.4093141555786133 | CLS Loss: 0.009608886204659939\n",
      "Epoch 128 / 200 | iteration 80 / 171 | Total Loss: 2.416959762573242 | KNN Loss: 2.413175106048584 | CLS Loss: 0.003784709144383669\n",
      "Epoch 128 / 200 | iteration 90 / 171 | Total Loss: 2.43107008934021 | KNN Loss: 2.4229531288146973 | CLS Loss: 0.008117073215544224\n",
      "Epoch 128 / 200 | iteration 100 / 171 | Total Loss: 2.374042272567749 | KNN Loss: 2.361585855484009 | CLS Loss: 0.012456499971449375\n",
      "Epoch 128 / 200 | iteration 110 / 171 | Total Loss: 2.433926820755005 | KNN Loss: 2.3965229988098145 | CLS Loss: 0.03740381821990013\n",
      "Epoch 128 / 200 | iteration 120 / 171 | Total Loss: 2.4053704738616943 | KNN Loss: 2.388241767883301 | CLS Loss: 0.017128797248005867\n",
      "Epoch 128 / 200 | iteration 130 / 171 | Total Loss: 2.433258295059204 | KNN Loss: 2.403920888900757 | CLS Loss: 0.029337508603930473\n",
      "Epoch 128 / 200 | iteration 140 / 171 | Total Loss: 2.4180243015289307 | KNN Loss: 2.392516851425171 | CLS Loss: 0.025507347658276558\n",
      "Epoch 128 / 200 | iteration 150 / 171 | Total Loss: 2.4074981212615967 | KNN Loss: 2.3974809646606445 | CLS Loss: 0.010017210617661476\n",
      "Epoch 128 / 200 | iteration 160 / 171 | Total Loss: 2.454373836517334 | KNN Loss: 2.447906732559204 | CLS Loss: 0.006467207334935665\n",
      "Epoch 128 / 200 | iteration 170 / 171 | Total Loss: 2.3652758598327637 | KNN Loss: 2.3559443950653076 | CLS Loss: 0.00933151226490736\n",
      "Epoch: 128, Loss: 2.4236, Train: 0.9956, Valid: 0.9867, Best: 0.9873\n",
      "Epoch 129 / 200 | iteration 0 / 171 | Total Loss: 2.4109230041503906 | KNN Loss: 2.377432107925415 | CLS Loss: 0.03349101543426514\n",
      "Epoch 129 / 200 | iteration 10 / 171 | Total Loss: 2.4127984046936035 | KNN Loss: 2.3943662643432617 | CLS Loss: 0.018432147800922394\n",
      "Epoch 129 / 200 | iteration 20 / 171 | Total Loss: 2.467247486114502 | KNN Loss: 2.462397575378418 | CLS Loss: 0.004849859979003668\n",
      "Epoch 129 / 200 | iteration 30 / 171 | Total Loss: 2.4351935386657715 | KNN Loss: 2.418609857559204 | CLS Loss: 0.01658366248011589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 / 200 | iteration 40 / 171 | Total Loss: 2.4978885650634766 | KNN Loss: 2.473923444747925 | CLS Loss: 0.02396516315639019\n",
      "Epoch 129 / 200 | iteration 50 / 171 | Total Loss: 2.4431567192077637 | KNN Loss: 2.4270777702331543 | CLS Loss: 0.016078844666481018\n",
      "Epoch 129 / 200 | iteration 60 / 171 | Total Loss: 2.4162588119506836 | KNN Loss: 2.410750389099121 | CLS Loss: 0.005508344154804945\n",
      "Epoch 129 / 200 | iteration 70 / 171 | Total Loss: 2.449242115020752 | KNN Loss: 2.4126551151275635 | CLS Loss: 0.036586880683898926\n",
      "Epoch 129 / 200 | iteration 80 / 171 | Total Loss: 2.426483154296875 | KNN Loss: 2.409296989440918 | CLS Loss: 0.01718609407544136\n",
      "Epoch 129 / 200 | iteration 90 / 171 | Total Loss: 2.5149950981140137 | KNN Loss: 2.4875359535217285 | CLS Loss: 0.02745908498764038\n",
      "Epoch 129 / 200 | iteration 100 / 171 | Total Loss: 2.4442625045776367 | KNN Loss: 2.419865131378174 | CLS Loss: 0.024397436529397964\n",
      "Epoch 129 / 200 | iteration 110 / 171 | Total Loss: 2.4199516773223877 | KNN Loss: 2.4017982482910156 | CLS Loss: 0.018153522163629532\n",
      "Epoch 129 / 200 | iteration 120 / 171 | Total Loss: 2.4027676582336426 | KNN Loss: 2.383110284805298 | CLS Loss: 0.01965726539492607\n",
      "Epoch 129 / 200 | iteration 130 / 171 | Total Loss: 2.41969895362854 | KNN Loss: 2.385472297668457 | CLS Loss: 0.03422676399350166\n",
      "Epoch 129 / 200 | iteration 140 / 171 | Total Loss: 2.426084041595459 | KNN Loss: 2.41990065574646 | CLS Loss: 0.006183268968015909\n",
      "Epoch 129 / 200 | iteration 150 / 171 | Total Loss: 2.4368221759796143 | KNN Loss: 2.4069228172302246 | CLS Loss: 0.029899412766098976\n",
      "Epoch 129 / 200 | iteration 160 / 171 | Total Loss: 2.4230055809020996 | KNN Loss: 2.4121897220611572 | CLS Loss: 0.01081587839871645\n",
      "Epoch 129 / 200 | iteration 170 / 171 | Total Loss: 2.4047157764434814 | KNN Loss: 2.3969807624816895 | CLS Loss: 0.007735022809356451\n",
      "Epoch: 129, Loss: 2.4260, Train: 0.9960, Valid: 0.9871, Best: 0.9873\n",
      "Epoch 130 / 200 | iteration 0 / 171 | Total Loss: 2.4144914150238037 | KNN Loss: 2.409311532974243 | CLS Loss: 0.005179962608963251\n",
      "Epoch 130 / 200 | iteration 10 / 171 | Total Loss: 2.400186538696289 | KNN Loss: 2.388335943222046 | CLS Loss: 0.011850683018565178\n",
      "Epoch 130 / 200 | iteration 20 / 171 | Total Loss: 2.423893451690674 | KNN Loss: 2.4188437461853027 | CLS Loss: 0.005049783270806074\n",
      "Epoch 130 / 200 | iteration 30 / 171 | Total Loss: 2.4307303428649902 | KNN Loss: 2.3950212001800537 | CLS Loss: 0.03570903465151787\n",
      "Epoch 130 / 200 | iteration 40 / 171 | Total Loss: 2.4401047229766846 | KNN Loss: 2.4289259910583496 | CLS Loss: 0.011178622022271156\n",
      "Epoch 130 / 200 | iteration 50 / 171 | Total Loss: 2.4859654903411865 | KNN Loss: 2.471222400665283 | CLS Loss: 0.014742984436452389\n",
      "Epoch 130 / 200 | iteration 60 / 171 | Total Loss: 2.4293596744537354 | KNN Loss: 2.4068081378936768 | CLS Loss: 0.022551540285348892\n",
      "Epoch 130 / 200 | iteration 70 / 171 | Total Loss: 2.445269823074341 | KNN Loss: 2.419952392578125 | CLS Loss: 0.025317495688796043\n",
      "Epoch 130 / 200 | iteration 80 / 171 | Total Loss: 2.4485254287719727 | KNN Loss: 2.438519239425659 | CLS Loss: 0.010006115771830082\n",
      "Epoch 130 / 200 | iteration 90 / 171 | Total Loss: 2.4362690448760986 | KNN Loss: 2.42741060256958 | CLS Loss: 0.008858324959874153\n",
      "Epoch 130 / 200 | iteration 100 / 171 | Total Loss: 2.4076743125915527 | KNN Loss: 2.3979506492614746 | CLS Loss: 0.009723687544465065\n",
      "Epoch 130 / 200 | iteration 110 / 171 | Total Loss: 2.4126501083374023 | KNN Loss: 2.392406702041626 | CLS Loss: 0.020243318751454353\n",
      "Epoch 130 / 200 | iteration 120 / 171 | Total Loss: 2.431204080581665 | KNN Loss: 2.4155757427215576 | CLS Loss: 0.015628309920430183\n",
      "Epoch 130 / 200 | iteration 130 / 171 | Total Loss: 2.4057111740112305 | KNN Loss: 2.392134428024292 | CLS Loss: 0.01357683353126049\n",
      "Epoch 130 / 200 | iteration 140 / 171 | Total Loss: 2.419401168823242 | KNN Loss: 2.404106616973877 | CLS Loss: 0.015294602140784264\n",
      "Epoch 130 / 200 | iteration 150 / 171 | Total Loss: 2.39925479888916 | KNN Loss: 2.3899085521698 | CLS Loss: 0.009346174076199532\n",
      "Epoch 130 / 200 | iteration 160 / 171 | Total Loss: 2.411771774291992 | KNN Loss: 2.3863909244537354 | CLS Loss: 0.025380847975611687\n",
      "Epoch 130 / 200 | iteration 170 / 171 | Total Loss: 2.4092421531677246 | KNN Loss: 2.382937431335449 | CLS Loss: 0.026304811239242554\n",
      "Epoch: 130, Loss: 2.4222, Train: 0.9960, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 131 / 200 | iteration 0 / 171 | Total Loss: 2.3977625370025635 | KNN Loss: 2.3925564289093018 | CLS Loss: 0.005206195171922445\n",
      "Epoch 131 / 200 | iteration 10 / 171 | Total Loss: 2.41410756111145 | KNN Loss: 2.411914587020874 | CLS Loss: 0.0021930066868662834\n",
      "Epoch 131 / 200 | iteration 20 / 171 | Total Loss: 2.4435999393463135 | KNN Loss: 2.417374849319458 | CLS Loss: 0.02622501365840435\n",
      "Epoch 131 / 200 | iteration 30 / 171 | Total Loss: 2.434399366378784 | KNN Loss: 2.4072272777557373 | CLS Loss: 0.02717219665646553\n",
      "Epoch 131 / 200 | iteration 40 / 171 | Total Loss: 2.496739149093628 | KNN Loss: 2.4797492027282715 | CLS Loss: 0.016989948228001595\n",
      "Epoch 131 / 200 | iteration 50 / 171 | Total Loss: 2.461176872253418 | KNN Loss: 2.451195240020752 | CLS Loss: 0.009981563314795494\n",
      "Epoch 131 / 200 | iteration 60 / 171 | Total Loss: 2.4098403453826904 | KNN Loss: 2.39277720451355 | CLS Loss: 0.017063170671463013\n",
      "Epoch 131 / 200 | iteration 70 / 171 | Total Loss: 2.4054617881774902 | KNN Loss: 2.3823254108428955 | CLS Loss: 0.023136407136917114\n",
      "Epoch 131 / 200 | iteration 80 / 171 | Total Loss: 2.3999972343444824 | KNN Loss: 2.3899693489074707 | CLS Loss: 0.010027795098721981\n",
      "Epoch 131 / 200 | iteration 90 / 171 | Total Loss: 2.395759105682373 | KNN Loss: 2.382422685623169 | CLS Loss: 0.013336408883333206\n",
      "Epoch 131 / 200 | iteration 100 / 171 | Total Loss: 2.422916889190674 | KNN Loss: 2.3999087810516357 | CLS Loss: 0.023008029907941818\n",
      "Epoch 131 / 200 | iteration 110 / 171 | Total Loss: 2.408082962036133 | KNN Loss: 2.3843369483947754 | CLS Loss: 0.023746127262711525\n",
      "Epoch 131 / 200 | iteration 120 / 171 | Total Loss: 2.3825228214263916 | KNN Loss: 2.3771374225616455 | CLS Loss: 0.00538535276427865\n",
      "Epoch 131 / 200 | iteration 130 / 171 | Total Loss: 2.4639415740966797 | KNN Loss: 2.4301812648773193 | CLS Loss: 0.0337601900100708\n",
      "Epoch 131 / 200 | iteration 140 / 171 | Total Loss: 2.4118924140930176 | KNN Loss: 2.397495746612549 | CLS Loss: 0.014396593905985355\n",
      "Epoch 131 / 200 | iteration 150 / 171 | Total Loss: 2.4214868545532227 | KNN Loss: 2.384492874145508 | CLS Loss: 0.036993879824876785\n",
      "Epoch 131 / 200 | iteration 160 / 171 | Total Loss: 2.4236862659454346 | KNN Loss: 2.406916379928589 | CLS Loss: 0.016769850626587868\n",
      "Epoch 131 / 200 | iteration 170 / 171 | Total Loss: 2.4180984497070312 | KNN Loss: 2.404102087020874 | CLS Loss: 0.013996291905641556\n",
      "Epoch: 131, Loss: 2.4200, Train: 0.9962, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 132 / 200 | iteration 0 / 171 | Total Loss: 2.532792806625366 | KNN Loss: 2.5044007301330566 | CLS Loss: 0.028392020612955093\n",
      "Epoch 132 / 200 | iteration 10 / 171 | Total Loss: 2.419640064239502 | KNN Loss: 2.406906843185425 | CLS Loss: 0.012733211740851402\n",
      "Epoch 132 / 200 | iteration 20 / 171 | Total Loss: 2.4234209060668945 | KNN Loss: 2.3901569843292236 | CLS Loss: 0.033263951539993286\n",
      "Epoch 132 / 200 | iteration 30 / 171 | Total Loss: 2.4317238330841064 | KNN Loss: 2.4185097217559814 | CLS Loss: 0.013214008882641792\n",
      "Epoch 132 / 200 | iteration 40 / 171 | Total Loss: 2.4263617992401123 | KNN Loss: 2.372095823287964 | CLS Loss: 0.05426587164402008\n",
      "Epoch 132 / 200 | iteration 50 / 171 | Total Loss: 2.4274208545684814 | KNN Loss: 2.416283130645752 | CLS Loss: 0.011137792840600014\n",
      "Epoch 132 / 200 | iteration 60 / 171 | Total Loss: 2.4337050914764404 | KNN Loss: 2.426058769226074 | CLS Loss: 0.007646376267075539\n",
      "Epoch 132 / 200 | iteration 70 / 171 | Total Loss: 2.401898145675659 | KNN Loss: 2.385288953781128 | CLS Loss: 0.016609203070402145\n",
      "Epoch 132 / 200 | iteration 80 / 171 | Total Loss: 2.4148483276367188 | KNN Loss: 2.3891983032226562 | CLS Loss: 0.025649908930063248\n",
      "Epoch 132 / 200 | iteration 90 / 171 | Total Loss: 2.426969051361084 | KNN Loss: 2.405008316040039 | CLS Loss: 0.021960798650979996\n",
      "Epoch 132 / 200 | iteration 100 / 171 | Total Loss: 2.399397611618042 | KNN Loss: 2.370964527130127 | CLS Loss: 0.028433164581656456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 / 200 | iteration 110 / 171 | Total Loss: 2.4730632305145264 | KNN Loss: 2.450782060623169 | CLS Loss: 0.022281277924776077\n",
      "Epoch 132 / 200 | iteration 120 / 171 | Total Loss: 2.4296774864196777 | KNN Loss: 2.4229705333709717 | CLS Loss: 0.006706861779093742\n",
      "Epoch 132 / 200 | iteration 130 / 171 | Total Loss: 2.4011168479919434 | KNN Loss: 2.395430564880371 | CLS Loss: 0.005686297547072172\n",
      "Epoch 132 / 200 | iteration 140 / 171 | Total Loss: 2.4600839614868164 | KNN Loss: 2.438626766204834 | CLS Loss: 0.021457141265273094\n",
      "Epoch 132 / 200 | iteration 150 / 171 | Total Loss: 2.4551262855529785 | KNN Loss: 2.444669485092163 | CLS Loss: 0.010456729680299759\n",
      "Epoch 132 / 200 | iteration 160 / 171 | Total Loss: 2.4455366134643555 | KNN Loss: 2.4281678199768066 | CLS Loss: 0.017368797212839127\n",
      "Epoch 132 / 200 | iteration 170 / 171 | Total Loss: 2.4402213096618652 | KNN Loss: 2.394592761993408 | CLS Loss: 0.045628540217876434\n",
      "Epoch: 132, Loss: 2.4229, Train: 0.9952, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 133 / 200 | iteration 0 / 171 | Total Loss: 2.4148733615875244 | KNN Loss: 2.4049742221832275 | CLS Loss: 0.009899045340716839\n",
      "Epoch 133 / 200 | iteration 10 / 171 | Total Loss: 2.4379637241363525 | KNN Loss: 2.418444871902466 | CLS Loss: 0.019518913701176643\n",
      "Epoch 133 / 200 | iteration 20 / 171 | Total Loss: 2.4313580989837646 | KNN Loss: 2.4102418422698975 | CLS Loss: 0.021116329357028008\n",
      "Epoch 133 / 200 | iteration 30 / 171 | Total Loss: 2.403665542602539 | KNN Loss: 2.394726514816284 | CLS Loss: 0.008938971906900406\n",
      "Epoch 133 / 200 | iteration 40 / 171 | Total Loss: 2.4032156467437744 | KNN Loss: 2.3943166732788086 | CLS Loss: 0.008899062871932983\n",
      "Epoch 133 / 200 | iteration 50 / 171 | Total Loss: 2.420860767364502 | KNN Loss: 2.4130172729492188 | CLS Loss: 0.007843499071896076\n",
      "Epoch 133 / 200 | iteration 60 / 171 | Total Loss: 2.447683811187744 | KNN Loss: 2.4332056045532227 | CLS Loss: 0.014478109776973724\n",
      "Epoch 133 / 200 | iteration 70 / 171 | Total Loss: 2.436579942703247 | KNN Loss: 2.417569875717163 | CLS Loss: 0.019010093063116074\n",
      "Epoch 133 / 200 | iteration 80 / 171 | Total Loss: 2.394730806350708 | KNN Loss: 2.380356550216675 | CLS Loss: 0.014374276623129845\n",
      "Epoch 133 / 200 | iteration 90 / 171 | Total Loss: 2.4121432304382324 | KNN Loss: 2.3954083919525146 | CLS Loss: 0.016734899953007698\n",
      "Epoch 133 / 200 | iteration 100 / 171 | Total Loss: 2.473914384841919 | KNN Loss: 2.4531726837158203 | CLS Loss: 0.020741701126098633\n",
      "Epoch 133 / 200 | iteration 110 / 171 | Total Loss: 2.4190690517425537 | KNN Loss: 2.3796186447143555 | CLS Loss: 0.03945043310523033\n",
      "Epoch 133 / 200 | iteration 120 / 171 | Total Loss: 2.4310860633850098 | KNN Loss: 2.397914409637451 | CLS Loss: 0.03317154198884964\n",
      "Epoch 133 / 200 | iteration 130 / 171 | Total Loss: 2.4437308311462402 | KNN Loss: 2.435856342315674 | CLS Loss: 0.007874424569308758\n",
      "Epoch 133 / 200 | iteration 140 / 171 | Total Loss: 2.4413323402404785 | KNN Loss: 2.4309866428375244 | CLS Loss: 0.010345708578824997\n",
      "Epoch 133 / 200 | iteration 150 / 171 | Total Loss: 2.4317421913146973 | KNN Loss: 2.4114413261413574 | CLS Loss: 0.02030077949166298\n",
      "Epoch 133 / 200 | iteration 160 / 171 | Total Loss: 2.433351755142212 | KNN Loss: 2.420261859893799 | CLS Loss: 0.013089984655380249\n",
      "Epoch 133 / 200 | iteration 170 / 171 | Total Loss: 2.4035184383392334 | KNN Loss: 2.3941397666931152 | CLS Loss: 0.009378693997859955\n",
      "Epoch: 133, Loss: 2.4242, Train: 0.9965, Valid: 0.9868, Best: 0.9873\n",
      "Epoch 134 / 200 | iteration 0 / 171 | Total Loss: 2.4008123874664307 | KNN Loss: 2.3955559730529785 | CLS Loss: 0.005256301257759333\n",
      "Epoch 134 / 200 | iteration 10 / 171 | Total Loss: 2.401292085647583 | KNN Loss: 2.394460678100586 | CLS Loss: 0.006831309292465448\n",
      "Epoch 134 / 200 | iteration 20 / 171 | Total Loss: 2.482426404953003 | KNN Loss: 2.4572160243988037 | CLS Loss: 0.025210445746779442\n",
      "Epoch 134 / 200 | iteration 30 / 171 | Total Loss: 2.3985633850097656 | KNN Loss: 2.3884904384613037 | CLS Loss: 0.01007300615310669\n",
      "Epoch 134 / 200 | iteration 40 / 171 | Total Loss: 2.4391777515411377 | KNN Loss: 2.4282588958740234 | CLS Loss: 0.010918807238340378\n",
      "Epoch 134 / 200 | iteration 50 / 171 | Total Loss: 2.4298200607299805 | KNN Loss: 2.39933705329895 | CLS Loss: 0.030483055859804153\n",
      "Epoch 134 / 200 | iteration 60 / 171 | Total Loss: 2.4222629070281982 | KNN Loss: 2.406574010848999 | CLS Loss: 0.01568889059126377\n",
      "Epoch 134 / 200 | iteration 70 / 171 | Total Loss: 2.426790237426758 | KNN Loss: 2.4059972763061523 | CLS Loss: 0.020792901515960693\n",
      "Epoch 134 / 200 | iteration 80 / 171 | Total Loss: 2.3882174491882324 | KNN Loss: 2.3826851844787598 | CLS Loss: 0.005532360170036554\n",
      "Epoch 134 / 200 | iteration 90 / 171 | Total Loss: 2.404242753982544 | KNN Loss: 2.395132303237915 | CLS Loss: 0.009110357612371445\n",
      "Epoch 134 / 200 | iteration 100 / 171 | Total Loss: 2.4296250343322754 | KNN Loss: 2.407782793045044 | CLS Loss: 0.021842192858457565\n",
      "Epoch 134 / 200 | iteration 110 / 171 | Total Loss: 2.416672706604004 | KNN Loss: 2.3902692794799805 | CLS Loss: 0.026403328403830528\n",
      "Epoch 134 / 200 | iteration 120 / 171 | Total Loss: 2.4423930644989014 | KNN Loss: 2.4273557662963867 | CLS Loss: 0.015037322416901588\n",
      "Epoch 134 / 200 | iteration 130 / 171 | Total Loss: 2.4152626991271973 | KNN Loss: 2.3923776149749756 | CLS Loss: 0.022885076701641083\n",
      "Epoch 134 / 200 | iteration 140 / 171 | Total Loss: 2.4096622467041016 | KNN Loss: 2.4032435417175293 | CLS Loss: 0.006418755743652582\n",
      "Epoch 134 / 200 | iteration 150 / 171 | Total Loss: 2.439885139465332 | KNN Loss: 2.428253650665283 | CLS Loss: 0.011631430126726627\n",
      "Epoch 134 / 200 | iteration 160 / 171 | Total Loss: 2.4089748859405518 | KNN Loss: 2.3992152214050293 | CLS Loss: 0.00975954718887806\n",
      "Epoch 134 / 200 | iteration 170 / 171 | Total Loss: 2.406874418258667 | KNN Loss: 2.4004454612731934 | CLS Loss: 0.006428953260183334\n",
      "Epoch: 134, Loss: 2.4221, Train: 0.9952, Valid: 0.9863, Best: 0.9873\n",
      "Epoch 135 / 200 | iteration 0 / 171 | Total Loss: 2.453812837600708 | KNN Loss: 2.4489784240722656 | CLS Loss: 0.004834509454667568\n",
      "Epoch 135 / 200 | iteration 10 / 171 | Total Loss: 2.445234537124634 | KNN Loss: 2.407219409942627 | CLS Loss: 0.038015205413103104\n",
      "Epoch 135 / 200 | iteration 20 / 171 | Total Loss: 2.4186344146728516 | KNN Loss: 2.402439832687378 | CLS Loss: 0.016194628551602364\n",
      "Epoch 135 / 200 | iteration 30 / 171 | Total Loss: 2.4456450939178467 | KNN Loss: 2.430845260620117 | CLS Loss: 0.014799915254116058\n",
      "Epoch 135 / 200 | iteration 40 / 171 | Total Loss: 2.3876044750213623 | KNN Loss: 2.3749401569366455 | CLS Loss: 0.012664314359426498\n",
      "Epoch 135 / 200 | iteration 50 / 171 | Total Loss: 2.450507164001465 | KNN Loss: 2.426039934158325 | CLS Loss: 0.024467289447784424\n",
      "Epoch 135 / 200 | iteration 60 / 171 | Total Loss: 2.435502767562866 | KNN Loss: 2.424663782119751 | CLS Loss: 0.01083907950669527\n",
      "Epoch 135 / 200 | iteration 70 / 171 | Total Loss: 2.4562385082244873 | KNN Loss: 2.437641143798828 | CLS Loss: 0.018597379326820374\n",
      "Epoch 135 / 200 | iteration 80 / 171 | Total Loss: 2.479557991027832 | KNN Loss: 2.4540038108825684 | CLS Loss: 0.02555428072810173\n",
      "Epoch 135 / 200 | iteration 90 / 171 | Total Loss: 2.4470365047454834 | KNN Loss: 2.4295730590820312 | CLS Loss: 0.017463454976677895\n",
      "Epoch 135 / 200 | iteration 100 / 171 | Total Loss: 2.4094960689544678 | KNN Loss: 2.403696298599243 | CLS Loss: 0.005799849983304739\n",
      "Epoch 135 / 200 | iteration 110 / 171 | Total Loss: 2.392808198928833 | KNN Loss: 2.3888769149780273 | CLS Loss: 0.003931334707885981\n",
      "Epoch 135 / 200 | iteration 120 / 171 | Total Loss: 2.397092819213867 | KNN Loss: 2.3833303451538086 | CLS Loss: 0.013762373477220535\n",
      "Epoch 135 / 200 | iteration 130 / 171 | Total Loss: 2.4563848972320557 | KNN Loss: 2.435814142227173 | CLS Loss: 0.02057076245546341\n",
      "Epoch 135 / 200 | iteration 140 / 171 | Total Loss: 2.3681838512420654 | KNN Loss: 2.3599958419799805 | CLS Loss: 0.008188122883439064\n",
      "Epoch 135 / 200 | iteration 150 / 171 | Total Loss: 2.4446680545806885 | KNN Loss: 2.4148964881896973 | CLS Loss: 0.02977149933576584\n",
      "Epoch 135 / 200 | iteration 160 / 171 | Total Loss: 2.4166359901428223 | KNN Loss: 2.397681713104248 | CLS Loss: 0.018954165279865265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 / 200 | iteration 170 / 171 | Total Loss: 2.425281286239624 | KNN Loss: 2.4159607887268066 | CLS Loss: 0.00932050496339798\n",
      "Epoch: 135, Loss: 2.4253, Train: 0.9958, Valid: 0.9858, Best: 0.9873\n",
      "Epoch 136 / 200 | iteration 0 / 171 | Total Loss: 2.4530434608459473 | KNN Loss: 2.4429354667663574 | CLS Loss: 0.010107909329235554\n",
      "Epoch 136 / 200 | iteration 10 / 171 | Total Loss: 2.4287827014923096 | KNN Loss: 2.413175582885742 | CLS Loss: 0.015607066452503204\n",
      "Epoch 136 / 200 | iteration 20 / 171 | Total Loss: 2.391200542449951 | KNN Loss: 2.388995885848999 | CLS Loss: 0.0022047085221856833\n",
      "Epoch 136 / 200 | iteration 30 / 171 | Total Loss: 2.443066358566284 | KNN Loss: 2.4274377822875977 | CLS Loss: 0.015628468245267868\n",
      "Epoch 136 / 200 | iteration 40 / 171 | Total Loss: 2.4120326042175293 | KNN Loss: 2.398960828781128 | CLS Loss: 0.013071807101368904\n",
      "Epoch 136 / 200 | iteration 50 / 171 | Total Loss: 2.4319143295288086 | KNN Loss: 2.416499614715576 | CLS Loss: 0.015414833091199398\n",
      "Epoch 136 / 200 | iteration 60 / 171 | Total Loss: 2.407212495803833 | KNN Loss: 2.404599905014038 | CLS Loss: 0.002612528158351779\n",
      "Epoch 136 / 200 | iteration 70 / 171 | Total Loss: 2.4322657585144043 | KNN Loss: 2.418229103088379 | CLS Loss: 0.014036568813025951\n",
      "Epoch 136 / 200 | iteration 80 / 171 | Total Loss: 2.46051025390625 | KNN Loss: 2.432227611541748 | CLS Loss: 0.028282655403017998\n",
      "Epoch 136 / 200 | iteration 90 / 171 | Total Loss: 2.470837354660034 | KNN Loss: 2.431938648223877 | CLS Loss: 0.03889859840273857\n",
      "Epoch 136 / 200 | iteration 100 / 171 | Total Loss: 2.4088034629821777 | KNN Loss: 2.3944787979125977 | CLS Loss: 0.014324606396257877\n",
      "Epoch 136 / 200 | iteration 110 / 171 | Total Loss: 2.4186341762542725 | KNN Loss: 2.4116740226745605 | CLS Loss: 0.006960182450711727\n",
      "Epoch 136 / 200 | iteration 120 / 171 | Total Loss: 2.428074836730957 | KNN Loss: 2.416386604309082 | CLS Loss: 0.011688175611197948\n",
      "Epoch 136 / 200 | iteration 130 / 171 | Total Loss: 2.4701690673828125 | KNN Loss: 2.46217942237854 | CLS Loss: 0.007989604957401752\n",
      "Epoch 136 / 200 | iteration 140 / 171 | Total Loss: 2.4166312217712402 | KNN Loss: 2.3941547870635986 | CLS Loss: 0.022476522251963615\n",
      "Epoch 136 / 200 | iteration 150 / 171 | Total Loss: 2.431074857711792 | KNN Loss: 2.4238553047180176 | CLS Loss: 0.007219587918370962\n",
      "Epoch 136 / 200 | iteration 160 / 171 | Total Loss: 2.463956356048584 | KNN Loss: 2.4490158557891846 | CLS Loss: 0.014940530061721802\n",
      "Epoch 136 / 200 | iteration 170 / 171 | Total Loss: 2.421468734741211 | KNN Loss: 2.4183480739593506 | CLS Loss: 0.0031205799896270037\n",
      "Epoch: 136, Loss: 2.4252, Train: 0.9958, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 137 / 200 | iteration 0 / 171 | Total Loss: 2.3795828819274902 | KNN Loss: 2.3667969703674316 | CLS Loss: 0.012786010280251503\n",
      "Epoch 137 / 200 | iteration 10 / 171 | Total Loss: 2.4059226512908936 | KNN Loss: 2.379142999649048 | CLS Loss: 0.02677956037223339\n",
      "Epoch 137 / 200 | iteration 20 / 171 | Total Loss: 2.4295709133148193 | KNN Loss: 2.418630599975586 | CLS Loss: 0.010940338484942913\n",
      "Epoch 137 / 200 | iteration 30 / 171 | Total Loss: 2.3881499767303467 | KNN Loss: 2.3821823596954346 | CLS Loss: 0.0059675597585737705\n",
      "Epoch 137 / 200 | iteration 40 / 171 | Total Loss: 2.379263401031494 | KNN Loss: 2.3639628887176514 | CLS Loss: 0.01530051976442337\n",
      "Epoch 137 / 200 | iteration 50 / 171 | Total Loss: 2.403663158416748 | KNN Loss: 2.388643741607666 | CLS Loss: 0.015019416809082031\n",
      "Epoch 137 / 200 | iteration 60 / 171 | Total Loss: 2.4113340377807617 | KNN Loss: 2.399066686630249 | CLS Loss: 0.012267441488802433\n",
      "Epoch 137 / 200 | iteration 70 / 171 | Total Loss: 2.4284069538116455 | KNN Loss: 2.3971636295318604 | CLS Loss: 0.031243417412042618\n",
      "Epoch 137 / 200 | iteration 80 / 171 | Total Loss: 2.3989992141723633 | KNN Loss: 2.3946163654327393 | CLS Loss: 0.004382739309221506\n",
      "Epoch 137 / 200 | iteration 90 / 171 | Total Loss: 2.3978843688964844 | KNN Loss: 2.3961524963378906 | CLS Loss: 0.0017319577746093273\n",
      "Epoch 137 / 200 | iteration 100 / 171 | Total Loss: 2.4366297721862793 | KNN Loss: 2.4158778190612793 | CLS Loss: 0.020752020180225372\n",
      "Epoch 137 / 200 | iteration 110 / 171 | Total Loss: 2.4351978302001953 | KNN Loss: 2.4127800464630127 | CLS Loss: 0.022417675703763962\n",
      "Epoch 137 / 200 | iteration 120 / 171 | Total Loss: 2.4896090030670166 | KNN Loss: 2.477452278137207 | CLS Loss: 0.012156695127487183\n",
      "Epoch 137 / 200 | iteration 130 / 171 | Total Loss: 2.429849863052368 | KNN Loss: 2.406731128692627 | CLS Loss: 0.023118672892451286\n",
      "Epoch 137 / 200 | iteration 140 / 171 | Total Loss: 2.4315805435180664 | KNN Loss: 2.429324150085449 | CLS Loss: 0.0022562772501260042\n",
      "Epoch 137 / 200 | iteration 150 / 171 | Total Loss: 2.4370946884155273 | KNN Loss: 2.426269769668579 | CLS Loss: 0.010825017467141151\n",
      "Epoch 137 / 200 | iteration 160 / 171 | Total Loss: 2.419051170349121 | KNN Loss: 2.414106845855713 | CLS Loss: 0.004944296553730965\n",
      "Epoch 137 / 200 | iteration 170 / 171 | Total Loss: 2.4301915168762207 | KNN Loss: 2.4127345085144043 | CLS Loss: 0.01745695248246193\n",
      "Epoch: 137, Loss: 2.4221, Train: 0.9966, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 138 / 200 | iteration 0 / 171 | Total Loss: 2.416937828063965 | KNN Loss: 2.408867359161377 | CLS Loss: 0.00807035993784666\n",
      "Epoch 138 / 200 | iteration 10 / 171 | Total Loss: 2.3969130516052246 | KNN Loss: 2.375504493713379 | CLS Loss: 0.021408511325716972\n",
      "Epoch 138 / 200 | iteration 20 / 171 | Total Loss: 2.482369899749756 | KNN Loss: 2.4627535343170166 | CLS Loss: 0.019616374745965004\n",
      "Epoch 138 / 200 | iteration 30 / 171 | Total Loss: 2.4282310009002686 | KNN Loss: 2.379302978515625 | CLS Loss: 0.04892792925238609\n",
      "Epoch 138 / 200 | iteration 40 / 171 | Total Loss: 2.409484386444092 | KNN Loss: 2.394993305206299 | CLS Loss: 0.014491090551018715\n",
      "Epoch 138 / 200 | iteration 50 / 171 | Total Loss: 2.401334047317505 | KNN Loss: 2.3732805252075195 | CLS Loss: 0.028053520247340202\n",
      "Epoch 138 / 200 | iteration 60 / 171 | Total Loss: 2.428243398666382 | KNN Loss: 2.403578042984009 | CLS Loss: 0.024665338918566704\n",
      "Epoch 138 / 200 | iteration 70 / 171 | Total Loss: 2.428837537765503 | KNN Loss: 2.4195051193237305 | CLS Loss: 0.009332484565675259\n",
      "Epoch 138 / 200 | iteration 80 / 171 | Total Loss: 2.4121434688568115 | KNN Loss: 2.4002017974853516 | CLS Loss: 0.011941574513912201\n",
      "Epoch 138 / 200 | iteration 90 / 171 | Total Loss: 2.466956377029419 | KNN Loss: 2.4274065494537354 | CLS Loss: 0.03954976052045822\n",
      "Epoch 138 / 200 | iteration 100 / 171 | Total Loss: 2.429495334625244 | KNN Loss: 2.424448013305664 | CLS Loss: 0.005047237034887075\n",
      "Epoch 138 / 200 | iteration 110 / 171 | Total Loss: 2.4259798526763916 | KNN Loss: 2.401440143585205 | CLS Loss: 0.024539604783058167\n",
      "Epoch 138 / 200 | iteration 120 / 171 | Total Loss: 2.443464994430542 | KNN Loss: 2.433382987976074 | CLS Loss: 0.010082080028951168\n",
      "Epoch 138 / 200 | iteration 130 / 171 | Total Loss: 2.4369277954101562 | KNN Loss: 2.417201042175293 | CLS Loss: 0.01972671039402485\n",
      "Epoch 138 / 200 | iteration 140 / 171 | Total Loss: 2.4263205528259277 | KNN Loss: 2.4187517166137695 | CLS Loss: 0.00756872771307826\n",
      "Epoch 138 / 200 | iteration 150 / 171 | Total Loss: 2.440007209777832 | KNN Loss: 2.413378953933716 | CLS Loss: 0.026628291234374046\n",
      "Epoch 138 / 200 | iteration 160 / 171 | Total Loss: 2.405318260192871 | KNN Loss: 2.3957512378692627 | CLS Loss: 0.009567087516188622\n",
      "Epoch 138 / 200 | iteration 170 / 171 | Total Loss: 2.457606315612793 | KNN Loss: 2.443042039871216 | CLS Loss: 0.014564160257577896\n",
      "Epoch: 138, Loss: 2.4239, Train: 0.9948, Valid: 0.9845, Best: 0.9873\n",
      "Epoch 139 / 200 | iteration 0 / 171 | Total Loss: 2.397348642349243 | KNN Loss: 2.3692519664764404 | CLS Loss: 0.02809658832848072\n",
      "Epoch 139 / 200 | iteration 10 / 171 | Total Loss: 2.4332165718078613 | KNN Loss: 2.4144749641418457 | CLS Loss: 0.01874166913330555\n",
      "Epoch 139 / 200 | iteration 20 / 171 | Total Loss: 2.4242959022521973 | KNN Loss: 2.4168636798858643 | CLS Loss: 0.007432257756590843\n",
      "Epoch 139 / 200 | iteration 30 / 171 | Total Loss: 2.42691969871521 | KNN Loss: 2.4178175926208496 | CLS Loss: 0.009102028794586658\n",
      "Epoch 139 / 200 | iteration 40 / 171 | Total Loss: 2.4553844928741455 | KNN Loss: 2.440164566040039 | CLS Loss: 0.015219933353364468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 / 200 | iteration 50 / 171 | Total Loss: 2.3725643157958984 | KNN Loss: 2.356304168701172 | CLS Loss: 0.016260169446468353\n",
      "Epoch 139 / 200 | iteration 60 / 171 | Total Loss: 2.3915722370147705 | KNN Loss: 2.382469415664673 | CLS Loss: 0.009102879092097282\n",
      "Epoch 139 / 200 | iteration 70 / 171 | Total Loss: 2.4216549396514893 | KNN Loss: 2.403608560562134 | CLS Loss: 0.018046371638774872\n",
      "Epoch 139 / 200 | iteration 80 / 171 | Total Loss: 2.45607590675354 | KNN Loss: 2.434978485107422 | CLS Loss: 0.02109731175005436\n",
      "Epoch 139 / 200 | iteration 90 / 171 | Total Loss: 2.379976749420166 | KNN Loss: 2.370692253112793 | CLS Loss: 0.00928457546979189\n",
      "Epoch 139 / 200 | iteration 100 / 171 | Total Loss: 2.4368975162506104 | KNN Loss: 2.419914484024048 | CLS Loss: 0.016983142122626305\n",
      "Epoch 139 / 200 | iteration 110 / 171 | Total Loss: 2.399829387664795 | KNN Loss: 2.3822567462921143 | CLS Loss: 0.01757262833416462\n",
      "Epoch 139 / 200 | iteration 120 / 171 | Total Loss: 2.405946969985962 | KNN Loss: 2.402219772338867 | CLS Loss: 0.003727314295247197\n",
      "Epoch 139 / 200 | iteration 130 / 171 | Total Loss: 2.416977643966675 | KNN Loss: 2.4067883491516113 | CLS Loss: 0.01018923707306385\n",
      "Epoch 139 / 200 | iteration 140 / 171 | Total Loss: 2.4117555618286133 | KNN Loss: 2.394235610961914 | CLS Loss: 0.017519958317279816\n",
      "Epoch 139 / 200 | iteration 150 / 171 | Total Loss: 2.402799367904663 | KNN Loss: 2.393172264099121 | CLS Loss: 0.009627044200897217\n",
      "Epoch 139 / 200 | iteration 160 / 171 | Total Loss: 2.3861355781555176 | KNN Loss: 2.382140874862671 | CLS Loss: 0.0039947759360075\n",
      "Epoch 139 / 200 | iteration 170 / 171 | Total Loss: 2.451026439666748 | KNN Loss: 2.4424753189086914 | CLS Loss: 0.008551006205379963\n",
      "Epoch: 139, Loss: 2.4181, Train: 0.9960, Valid: 0.9869, Best: 0.9873\n",
      "Epoch 140 / 200 | iteration 0 / 171 | Total Loss: 2.429959774017334 | KNN Loss: 2.408703088760376 | CLS Loss: 0.021256646141409874\n",
      "Epoch 140 / 200 | iteration 10 / 171 | Total Loss: 2.3796610832214355 | KNN Loss: 2.3645286560058594 | CLS Loss: 0.015132542699575424\n",
      "Epoch 140 / 200 | iteration 20 / 171 | Total Loss: 2.4366230964660645 | KNN Loss: 2.4351205825805664 | CLS Loss: 0.0015025869943201542\n",
      "Epoch 140 / 200 | iteration 30 / 171 | Total Loss: 2.4041051864624023 | KNN Loss: 2.3817715644836426 | CLS Loss: 0.02233361080288887\n",
      "Epoch 140 / 200 | iteration 40 / 171 | Total Loss: 2.4394543170928955 | KNN Loss: 2.415928602218628 | CLS Loss: 0.02352580986917019\n",
      "Epoch 140 / 200 | iteration 50 / 171 | Total Loss: 2.4200000762939453 | KNN Loss: 2.4166643619537354 | CLS Loss: 0.0033357180655002594\n",
      "Epoch 140 / 200 | iteration 60 / 171 | Total Loss: 2.38177490234375 | KNN Loss: 2.3629322052001953 | CLS Loss: 0.018842779099941254\n",
      "Epoch 140 / 200 | iteration 70 / 171 | Total Loss: 2.386375665664673 | KNN Loss: 2.369001626968384 | CLS Loss: 0.017374010756611824\n",
      "Epoch 140 / 200 | iteration 80 / 171 | Total Loss: 2.3868534564971924 | KNN Loss: 2.3818633556365967 | CLS Loss: 0.0049900789745152\n",
      "Epoch 140 / 200 | iteration 90 / 171 | Total Loss: 2.4180073738098145 | KNN Loss: 2.392960548400879 | CLS Loss: 0.025046855211257935\n",
      "Epoch 140 / 200 | iteration 100 / 171 | Total Loss: 2.4201245307922363 | KNN Loss: 2.4051172733306885 | CLS Loss: 0.015007339417934418\n",
      "Epoch 140 / 200 | iteration 110 / 171 | Total Loss: 2.3916234970092773 | KNN Loss: 2.3866002559661865 | CLS Loss: 0.005023190286010504\n",
      "Epoch 140 / 200 | iteration 120 / 171 | Total Loss: 2.4022839069366455 | KNN Loss: 2.393470287322998 | CLS Loss: 0.008813639171421528\n",
      "Epoch 140 / 200 | iteration 130 / 171 | Total Loss: 2.418700933456421 | KNN Loss: 2.406940221786499 | CLS Loss: 0.01176080945879221\n",
      "Epoch 140 / 200 | iteration 140 / 171 | Total Loss: 2.435011148452759 | KNN Loss: 2.403538227081299 | CLS Loss: 0.03147300332784653\n",
      "Epoch 140 / 200 | iteration 150 / 171 | Total Loss: 2.4761617183685303 | KNN Loss: 2.4446747303009033 | CLS Loss: 0.03148694336414337\n",
      "Epoch 140 / 200 | iteration 160 / 171 | Total Loss: 2.43929123878479 | KNN Loss: 2.3993728160858154 | CLS Loss: 0.03991837427020073\n",
      "Epoch 140 / 200 | iteration 170 / 171 | Total Loss: 2.3982386589050293 | KNN Loss: 2.3862366676330566 | CLS Loss: 0.01200187299400568\n",
      "Epoch: 140, Loss: 2.4218, Train: 0.9962, Valid: 0.9865, Best: 0.9873\n",
      "Epoch 141 / 200 | iteration 0 / 171 | Total Loss: 2.4265623092651367 | KNN Loss: 2.411555051803589 | CLS Loss: 0.015007296577095985\n",
      "Epoch 141 / 200 | iteration 10 / 171 | Total Loss: 2.44755482673645 | KNN Loss: 2.4079480171203613 | CLS Loss: 0.039606835693120956\n",
      "Epoch 141 / 200 | iteration 20 / 171 | Total Loss: 2.429473876953125 | KNN Loss: 2.4043402671813965 | CLS Loss: 0.025133708491921425\n",
      "Epoch 141 / 200 | iteration 30 / 171 | Total Loss: 2.4125161170959473 | KNN Loss: 2.408893346786499 | CLS Loss: 0.003622836899012327\n",
      "Epoch 141 / 200 | iteration 40 / 171 | Total Loss: 2.419248104095459 | KNN Loss: 2.397881269454956 | CLS Loss: 0.021366829052567482\n",
      "Epoch 141 / 200 | iteration 50 / 171 | Total Loss: 2.4334590435028076 | KNN Loss: 2.413785457611084 | CLS Loss: 0.01967354491353035\n",
      "Epoch 141 / 200 | iteration 60 / 171 | Total Loss: 2.3731119632720947 | KNN Loss: 2.362175464630127 | CLS Loss: 0.01093654427677393\n",
      "Epoch 141 / 200 | iteration 70 / 171 | Total Loss: 2.448434591293335 | KNN Loss: 2.438812255859375 | CLS Loss: 0.009622436948120594\n",
      "Epoch 141 / 200 | iteration 80 / 171 | Total Loss: 2.3920533657073975 | KNN Loss: 2.386589765548706 | CLS Loss: 0.0054634977132081985\n",
      "Epoch 141 / 200 | iteration 90 / 171 | Total Loss: 2.4030873775482178 | KNN Loss: 2.3909404277801514 | CLS Loss: 0.012146897614002228\n",
      "Epoch 141 / 200 | iteration 100 / 171 | Total Loss: 2.43631649017334 | KNN Loss: 2.379629135131836 | CLS Loss: 0.056687310338020325\n",
      "Epoch 141 / 200 | iteration 110 / 171 | Total Loss: 2.399970531463623 | KNN Loss: 2.392695903778076 | CLS Loss: 0.007274559698998928\n",
      "Epoch 141 / 200 | iteration 120 / 171 | Total Loss: 2.4150919914245605 | KNN Loss: 2.4043264389038086 | CLS Loss: 0.01076550967991352\n",
      "Epoch 141 / 200 | iteration 130 / 171 | Total Loss: 2.402362585067749 | KNN Loss: 2.3854005336761475 | CLS Loss: 0.016961947083473206\n",
      "Epoch 141 / 200 | iteration 140 / 171 | Total Loss: 2.401170253753662 | KNN Loss: 2.392465591430664 | CLS Loss: 0.008704704232513905\n",
      "Epoch 141 / 200 | iteration 150 / 171 | Total Loss: 2.393690347671509 | KNN Loss: 2.3828659057617188 | CLS Loss: 0.010824334807693958\n",
      "Epoch 141 / 200 | iteration 160 / 171 | Total Loss: 2.440178632736206 | KNN Loss: 2.4279091358184814 | CLS Loss: 0.012269420549273491\n",
      "Epoch 141 / 200 | iteration 170 / 171 | Total Loss: 2.4206645488739014 | KNN Loss: 2.416515588760376 | CLS Loss: 0.004149024374783039\n",
      "Epoch: 141, Loss: 2.4200, Train: 0.9956, Valid: 0.9861, Best: 0.9873\n",
      "Epoch 142 / 200 | iteration 0 / 171 | Total Loss: 2.451611042022705 | KNN Loss: 2.4354968070983887 | CLS Loss: 0.016114162281155586\n",
      "Epoch 142 / 200 | iteration 10 / 171 | Total Loss: 2.451129198074341 | KNN Loss: 2.420513153076172 | CLS Loss: 0.030616063624620438\n",
      "Epoch 142 / 200 | iteration 20 / 171 | Total Loss: 2.414578676223755 | KNN Loss: 2.40077805519104 | CLS Loss: 0.013800511136651039\n",
      "Epoch 142 / 200 | iteration 30 / 171 | Total Loss: 2.4476890563964844 | KNN Loss: 2.436180830001831 | CLS Loss: 0.011508326977491379\n",
      "Epoch 142 / 200 | iteration 40 / 171 | Total Loss: 2.4328386783599854 | KNN Loss: 2.427245855331421 | CLS Loss: 0.005592796951532364\n",
      "Epoch 142 / 200 | iteration 50 / 171 | Total Loss: 2.4199514389038086 | KNN Loss: 2.405292510986328 | CLS Loss: 0.014658884145319462\n",
      "Epoch 142 / 200 | iteration 60 / 171 | Total Loss: 2.429276466369629 | KNN Loss: 2.418039560317993 | CLS Loss: 0.011236998252570629\n",
      "Epoch 142 / 200 | iteration 70 / 171 | Total Loss: 2.450233221054077 | KNN Loss: 2.4081625938415527 | CLS Loss: 0.042070720344781876\n",
      "Epoch 142 / 200 | iteration 80 / 171 | Total Loss: 2.3835248947143555 | KNN Loss: 2.3679358959198 | CLS Loss: 0.015589039772748947\n",
      "Epoch 142 / 200 | iteration 90 / 171 | Total Loss: 2.4344656467437744 | KNN Loss: 2.4314229488372803 | CLS Loss: 0.0030426953453570604\n",
      "Epoch 142 / 200 | iteration 100 / 171 | Total Loss: 2.3925201892852783 | KNN Loss: 2.3894236087799072 | CLS Loss: 0.003096681321039796\n",
      "Epoch 142 / 200 | iteration 110 / 171 | Total Loss: 2.409945487976074 | KNN Loss: 2.3979129791259766 | CLS Loss: 0.012032520957291126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 / 200 | iteration 120 / 171 | Total Loss: 2.4305477142333984 | KNN Loss: 2.423388957977295 | CLS Loss: 0.007158856838941574\n",
      "Epoch 142 / 200 | iteration 130 / 171 | Total Loss: 2.4116644859313965 | KNN Loss: 2.401197910308838 | CLS Loss: 0.010466641746461391\n",
      "Epoch 142 / 200 | iteration 140 / 171 | Total Loss: 2.467960834503174 | KNN Loss: 2.4271717071533203 | CLS Loss: 0.04078923165798187\n",
      "Epoch 142 / 200 | iteration 150 / 171 | Total Loss: 2.437964677810669 | KNN Loss: 2.43249249458313 | CLS Loss: 0.005472262855619192\n",
      "Epoch 142 / 200 | iteration 160 / 171 | Total Loss: 2.385284662246704 | KNN Loss: 2.3762407302856445 | CLS Loss: 0.009043947793543339\n",
      "Epoch 142 / 200 | iteration 170 / 171 | Total Loss: 2.410123109817505 | KNN Loss: 2.4049603939056396 | CLS Loss: 0.005162746645510197\n",
      "Epoch: 142, Loss: 2.4237, Train: 0.9958, Valid: 0.9866, Best: 0.9873\n",
      "Epoch 143 / 200 | iteration 0 / 171 | Total Loss: 2.384040117263794 | KNN Loss: 2.3664634227752686 | CLS Loss: 0.017576776444911957\n",
      "Epoch 143 / 200 | iteration 10 / 171 | Total Loss: 2.4297728538513184 | KNN Loss: 2.408205270767212 | CLS Loss: 0.021567702293395996\n",
      "Epoch 143 / 200 | iteration 20 / 171 | Total Loss: 2.472604513168335 | KNN Loss: 2.44242262840271 | CLS Loss: 0.030181918293237686\n",
      "Epoch 143 / 200 | iteration 30 / 171 | Total Loss: 2.414426803588867 | KNN Loss: 2.402630567550659 | CLS Loss: 0.011796263046562672\n",
      "Epoch 143 / 200 | iteration 40 / 171 | Total Loss: 2.448169469833374 | KNN Loss: 2.4313807487487793 | CLS Loss: 0.016788650304079056\n",
      "Epoch 143 / 200 | iteration 50 / 171 | Total Loss: 2.47245192527771 | KNN Loss: 2.441678047180176 | CLS Loss: 0.030773859471082687\n",
      "Epoch 143 / 200 | iteration 60 / 171 | Total Loss: 2.437300443649292 | KNN Loss: 2.4314370155334473 | CLS Loss: 0.0058633191511034966\n",
      "Epoch 143 / 200 | iteration 70 / 171 | Total Loss: 2.4012088775634766 | KNN Loss: 2.365277051925659 | CLS Loss: 0.03593181073665619\n",
      "Epoch 143 / 200 | iteration 80 / 171 | Total Loss: 2.4394936561584473 | KNN Loss: 2.4260408878326416 | CLS Loss: 0.01345265842974186\n",
      "Epoch 143 / 200 | iteration 90 / 171 | Total Loss: 2.445190906524658 | KNN Loss: 2.441009521484375 | CLS Loss: 0.004181423224508762\n",
      "Epoch 143 / 200 | iteration 100 / 171 | Total Loss: 2.439819574356079 | KNN Loss: 2.4383633136749268 | CLS Loss: 0.001456245081499219\n",
      "Epoch 143 / 200 | iteration 110 / 171 | Total Loss: 2.3921735286712646 | KNN Loss: 2.3808438777923584 | CLS Loss: 0.011329617351293564\n",
      "Epoch 143 / 200 | iteration 120 / 171 | Total Loss: 2.424424886703491 | KNN Loss: 2.4149398803710938 | CLS Loss: 0.009484906680881977\n",
      "Epoch 143 / 200 | iteration 130 / 171 | Total Loss: 2.4129433631896973 | KNN Loss: 2.4022164344787598 | CLS Loss: 0.010726924054324627\n",
      "Epoch 143 / 200 | iteration 140 / 171 | Total Loss: 2.4203827381134033 | KNN Loss: 2.400089979171753 | CLS Loss: 0.020292816683650017\n",
      "Epoch 143 / 200 | iteration 150 / 171 | Total Loss: 2.4364476203918457 | KNN Loss: 2.4092705249786377 | CLS Loss: 0.02717721275985241\n",
      "Epoch 143 / 200 | iteration 160 / 171 | Total Loss: 2.400331974029541 | KNN Loss: 2.3916218280792236 | CLS Loss: 0.008710229769349098\n",
      "Epoch 143 / 200 | iteration 170 / 171 | Total Loss: 2.4033470153808594 | KNN Loss: 2.3765015602111816 | CLS Loss: 0.026845527812838554\n",
      "Epoch: 143, Loss: 2.4234, Train: 0.9944, Valid: 0.9842, Best: 0.9873\n",
      "Epoch 144 / 200 | iteration 0 / 171 | Total Loss: 2.4423024654388428 | KNN Loss: 2.415623664855957 | CLS Loss: 0.02667890675365925\n",
      "Epoch 144 / 200 | iteration 10 / 171 | Total Loss: 2.4077389240264893 | KNN Loss: 2.396369457244873 | CLS Loss: 0.011369354091584682\n",
      "Epoch 144 / 200 | iteration 20 / 171 | Total Loss: 2.4038045406341553 | KNN Loss: 2.3988308906555176 | CLS Loss: 0.0049736518412828445\n",
      "Epoch 144 / 200 | iteration 30 / 171 | Total Loss: 2.4572463035583496 | KNN Loss: 2.437126636505127 | CLS Loss: 0.020119640976190567\n",
      "Epoch 144 / 200 | iteration 40 / 171 | Total Loss: 2.489535331726074 | KNN Loss: 2.4607975482940674 | CLS Loss: 0.028737718239426613\n",
      "Epoch 144 / 200 | iteration 50 / 171 | Total Loss: 2.434354305267334 | KNN Loss: 2.4256958961486816 | CLS Loss: 0.008658415637910366\n",
      "Epoch 144 / 200 | iteration 60 / 171 | Total Loss: 2.394500970840454 | KNN Loss: 2.370915412902832 | CLS Loss: 0.023585615679621696\n",
      "Epoch 144 / 200 | iteration 70 / 171 | Total Loss: 2.4056451320648193 | KNN Loss: 2.395726203918457 | CLS Loss: 0.009918957017362118\n",
      "Epoch 144 / 200 | iteration 80 / 171 | Total Loss: 2.4257519245147705 | KNN Loss: 2.4226346015930176 | CLS Loss: 0.0031172800809144974\n",
      "Epoch 144 / 200 | iteration 90 / 171 | Total Loss: 2.4144411087036133 | KNN Loss: 2.4102799892425537 | CLS Loss: 0.00416106591001153\n",
      "Epoch 144 / 200 | iteration 100 / 171 | Total Loss: 2.519275426864624 | KNN Loss: 2.494919538497925 | CLS Loss: 0.02435578964650631\n",
      "Epoch 144 / 200 | iteration 110 / 171 | Total Loss: 2.3771402835845947 | KNN Loss: 2.370464563369751 | CLS Loss: 0.006675811484456062\n",
      "Epoch 144 / 200 | iteration 120 / 171 | Total Loss: 2.42822265625 | KNN Loss: 2.4144206047058105 | CLS Loss: 0.01380197610706091\n",
      "Epoch 144 / 200 | iteration 130 / 171 | Total Loss: 2.431912422180176 | KNN Loss: 2.406405210494995 | CLS Loss: 0.025507140904664993\n",
      "Epoch 144 / 200 | iteration 140 / 171 | Total Loss: 2.396554946899414 | KNN Loss: 2.383821725845337 | CLS Loss: 0.012733273208141327\n",
      "Epoch 144 / 200 | iteration 150 / 171 | Total Loss: 2.4216115474700928 | KNN Loss: 2.418276786804199 | CLS Loss: 0.003334697801619768\n",
      "Epoch 144 / 200 | iteration 160 / 171 | Total Loss: 2.4017274379730225 | KNN Loss: 2.38226056098938 | CLS Loss: 0.019466863945126534\n",
      "Epoch 144 / 200 | iteration 170 / 171 | Total Loss: 2.4476609230041504 | KNN Loss: 2.4296693801879883 | CLS Loss: 0.017991548404097557\n",
      "Epoch: 144, Loss: 2.4230, Train: 0.9939, Valid: 0.9850, Best: 0.9873\n",
      "Epoch 145 / 200 | iteration 0 / 171 | Total Loss: 2.4483399391174316 | KNN Loss: 2.423396348953247 | CLS Loss: 0.024943619966506958\n",
      "Epoch 145 / 200 | iteration 10 / 171 | Total Loss: 2.418341875076294 | KNN Loss: 2.4009552001953125 | CLS Loss: 0.017386602237820625\n",
      "Epoch 145 / 200 | iteration 20 / 171 | Total Loss: 2.4192111492156982 | KNN Loss: 2.3945810794830322 | CLS Loss: 0.024630095809698105\n",
      "Epoch 145 / 200 | iteration 30 / 171 | Total Loss: 2.431568145751953 | KNN Loss: 2.4005157947540283 | CLS Loss: 0.031052345409989357\n",
      "Epoch 145 / 200 | iteration 40 / 171 | Total Loss: 2.4295263290405273 | KNN Loss: 2.4182868003845215 | CLS Loss: 0.011239537037909031\n",
      "Epoch 145 / 200 | iteration 50 / 171 | Total Loss: 2.4021944999694824 | KNN Loss: 2.3895606994628906 | CLS Loss: 0.012633772566914558\n",
      "Epoch 145 / 200 | iteration 60 / 171 | Total Loss: 2.454296350479126 | KNN Loss: 2.4478206634521484 | CLS Loss: 0.006475761998444796\n",
      "Epoch 145 / 200 | iteration 70 / 171 | Total Loss: 2.400322675704956 | KNN Loss: 2.397078275680542 | CLS Loss: 0.0032443159725517035\n",
      "Epoch 145 / 200 | iteration 80 / 171 | Total Loss: 2.4669134616851807 | KNN Loss: 2.4519076347351074 | CLS Loss: 0.015005894936621189\n",
      "Epoch 145 / 200 | iteration 90 / 171 | Total Loss: 2.4500274658203125 | KNN Loss: 2.4312610626220703 | CLS Loss: 0.018766364082694054\n",
      "Epoch 145 / 200 | iteration 100 / 171 | Total Loss: 2.4045755863189697 | KNN Loss: 2.392491579055786 | CLS Loss: 0.012084049172699451\n",
      "Epoch 145 / 200 | iteration 110 / 171 | Total Loss: 2.4292690753936768 | KNN Loss: 2.4146242141723633 | CLS Loss: 0.014644775539636612\n",
      "Epoch 145 / 200 | iteration 120 / 171 | Total Loss: 2.4286932945251465 | KNN Loss: 2.4119391441345215 | CLS Loss: 0.016754260286688805\n",
      "Epoch 145 / 200 | iteration 130 / 171 | Total Loss: 2.455767869949341 | KNN Loss: 2.4416165351867676 | CLS Loss: 0.014151280745863914\n",
      "Epoch 145 / 200 | iteration 140 / 171 | Total Loss: 2.4594783782958984 | KNN Loss: 2.4324800968170166 | CLS Loss: 0.026998184621334076\n",
      "Epoch 145 / 200 | iteration 150 / 171 | Total Loss: 2.3915200233459473 | KNN Loss: 2.3827383518218994 | CLS Loss: 0.008781570941209793\n",
      "Epoch 145 / 200 | iteration 160 / 171 | Total Loss: 2.427396297454834 | KNN Loss: 2.4096126556396484 | CLS Loss: 0.01778368093073368\n",
      "Epoch 145 / 200 | iteration 170 / 171 | Total Loss: 2.4374067783355713 | KNN Loss: 2.394707679748535 | CLS Loss: 0.04269915819168091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145, Loss: 2.4251, Train: 0.9952, Valid: 0.9862, Best: 0.9873\n",
      "Epoch 146 / 200 | iteration 0 / 171 | Total Loss: 2.3937766551971436 | KNN Loss: 2.381634473800659 | CLS Loss: 0.012142088264226913\n",
      "Epoch 146 / 200 | iteration 10 / 171 | Total Loss: 2.401862859725952 | KNN Loss: 2.382481575012207 | CLS Loss: 0.01938120275735855\n",
      "Epoch 146 / 200 | iteration 20 / 171 | Total Loss: 2.3987979888916016 | KNN Loss: 2.3898544311523438 | CLS Loss: 0.00894360151141882\n",
      "Epoch 146 / 200 | iteration 30 / 171 | Total Loss: 2.3843867778778076 | KNN Loss: 2.3635029792785645 | CLS Loss: 0.02088373899459839\n",
      "Epoch 146 / 200 | iteration 40 / 171 | Total Loss: 2.4498534202575684 | KNN Loss: 2.4409682750701904 | CLS Loss: 0.008885029703378677\n",
      "Epoch 146 / 200 | iteration 50 / 171 | Total Loss: 2.379932165145874 | KNN Loss: 2.368635416030884 | CLS Loss: 0.011296837590634823\n",
      "Epoch 146 / 200 | iteration 60 / 171 | Total Loss: 2.3864927291870117 | KNN Loss: 2.370435953140259 | CLS Loss: 0.016056746244430542\n",
      "Epoch 146 / 200 | iteration 70 / 171 | Total Loss: 2.408601999282837 | KNN Loss: 2.3938252925872803 | CLS Loss: 0.014776659198105335\n",
      "Epoch 146 / 200 | iteration 80 / 171 | Total Loss: 2.460038185119629 | KNN Loss: 2.4501090049743652 | CLS Loss: 0.009929293766617775\n",
      "Epoch 146 / 200 | iteration 90 / 171 | Total Loss: 2.394923448562622 | KNN Loss: 2.3669233322143555 | CLS Loss: 0.02800007537007332\n",
      "Epoch 146 / 200 | iteration 100 / 171 | Total Loss: 2.4341530799865723 | KNN Loss: 2.4179370403289795 | CLS Loss: 0.01621602289378643\n",
      "Epoch 146 / 200 | iteration 110 / 171 | Total Loss: 2.4062340259552 | KNN Loss: 2.3875532150268555 | CLS Loss: 0.018680768087506294\n",
      "Epoch 146 / 200 | iteration 120 / 171 | Total Loss: 2.452552556991577 | KNN Loss: 2.4337503910064697 | CLS Loss: 0.018802180886268616\n",
      "Epoch 146 / 200 | iteration 130 / 171 | Total Loss: 2.4217121601104736 | KNN Loss: 2.414649486541748 | CLS Loss: 0.0070626623928546906\n",
      "Epoch 146 / 200 | iteration 140 / 171 | Total Loss: 2.4344139099121094 | KNN Loss: 2.3915863037109375 | CLS Loss: 0.04282749071717262\n",
      "Epoch 146 / 200 | iteration 150 / 171 | Total Loss: 2.4106733798980713 | KNN Loss: 2.387781858444214 | CLS Loss: 0.022891489788889885\n",
      "Epoch 146 / 200 | iteration 160 / 171 | Total Loss: 2.3782923221588135 | KNN Loss: 2.3677573204040527 | CLS Loss: 0.010534948669373989\n",
      "Epoch 146 / 200 | iteration 170 / 171 | Total Loss: 2.4595718383789062 | KNN Loss: 2.4342377185821533 | CLS Loss: 0.025334088131785393\n",
      "Epoch: 146, Loss: 2.4229, Train: 0.9958, Valid: 0.9870, Best: 0.9873\n",
      "Epoch 147 / 200 | iteration 0 / 171 | Total Loss: 2.400947332382202 | KNN Loss: 2.381645917892456 | CLS Loss: 0.019301310181617737\n",
      "Epoch 147 / 200 | iteration 10 / 171 | Total Loss: 2.430300712585449 | KNN Loss: 2.4225447177886963 | CLS Loss: 0.007755934726446867\n",
      "Epoch 147 / 200 | iteration 20 / 171 | Total Loss: 2.4032483100891113 | KNN Loss: 2.3899009227752686 | CLS Loss: 0.01334735844284296\n",
      "Epoch 147 / 200 | iteration 30 / 171 | Total Loss: 2.4652063846588135 | KNN Loss: 2.4410758018493652 | CLS Loss: 0.024130523204803467\n",
      "Epoch 147 / 200 | iteration 40 / 171 | Total Loss: 2.3939201831817627 | KNN Loss: 2.380460500717163 | CLS Loss: 0.013459780253469944\n",
      "Epoch 147 / 200 | iteration 50 / 171 | Total Loss: 2.4088730812072754 | KNN Loss: 2.401270866394043 | CLS Loss: 0.007602216210216284\n",
      "Epoch 147 / 200 | iteration 60 / 171 | Total Loss: 2.412104368209839 | KNN Loss: 2.394423484802246 | CLS Loss: 0.017680929973721504\n",
      "Epoch 147 / 200 | iteration 70 / 171 | Total Loss: 2.4575188159942627 | KNN Loss: 2.4203052520751953 | CLS Loss: 0.03721354529261589\n",
      "Epoch 147 / 200 | iteration 80 / 171 | Total Loss: 2.3901021480560303 | KNN Loss: 2.3829450607299805 | CLS Loss: 0.007157076615840197\n",
      "Epoch 147 / 200 | iteration 90 / 171 | Total Loss: 2.4434304237365723 | KNN Loss: 2.4341492652893066 | CLS Loss: 0.009281104430556297\n",
      "Epoch 147 / 200 | iteration 100 / 171 | Total Loss: 2.396130323410034 | KNN Loss: 2.3838067054748535 | CLS Loss: 0.012323658913373947\n",
      "Epoch 147 / 200 | iteration 110 / 171 | Total Loss: 2.407179594039917 | KNN Loss: 2.3903372287750244 | CLS Loss: 0.016842415556311607\n",
      "Epoch 147 / 200 | iteration 120 / 171 | Total Loss: 2.4100537300109863 | KNN Loss: 2.394667625427246 | CLS Loss: 0.015386157669126987\n",
      "Epoch 147 / 200 | iteration 130 / 171 | Total Loss: 2.4070606231689453 | KNN Loss: 2.387129306793213 | CLS Loss: 0.019931260496377945\n",
      "Epoch 147 / 200 | iteration 140 / 171 | Total Loss: 2.4068751335144043 | KNN Loss: 2.394747018814087 | CLS Loss: 0.012128208763897419\n",
      "Epoch 147 / 200 | iteration 150 / 171 | Total Loss: 2.3893675804138184 | KNN Loss: 2.3725666999816895 | CLS Loss: 0.016800813376903534\n",
      "Epoch 147 / 200 | iteration 160 / 171 | Total Loss: 2.424271583557129 | KNN Loss: 2.4193930625915527 | CLS Loss: 0.004878484643995762\n",
      "Epoch 147 / 200 | iteration 170 / 171 | Total Loss: 2.378089666366577 | KNN Loss: 2.365241289138794 | CLS Loss: 0.012848399579524994\n",
      "Epoch: 147, Loss: 2.4139, Train: 0.9972, Valid: 0.9877, Best: 0.9877\n",
      "Epoch 148 / 200 | iteration 0 / 171 | Total Loss: 2.4500162601470947 | KNN Loss: 2.448150634765625 | CLS Loss: 0.0018656603060662746\n",
      "Epoch 148 / 200 | iteration 10 / 171 | Total Loss: 2.4268531799316406 | KNN Loss: 2.4106624126434326 | CLS Loss: 0.01619076356291771\n",
      "Epoch 148 / 200 | iteration 20 / 171 | Total Loss: 2.4076976776123047 | KNN Loss: 2.3970954418182373 | CLS Loss: 0.010602164082229137\n",
      "Epoch 148 / 200 | iteration 30 / 171 | Total Loss: 2.3996634483337402 | KNN Loss: 2.3934895992279053 | CLS Loss: 0.0061739357188344\n",
      "Epoch 148 / 200 | iteration 40 / 171 | Total Loss: 2.410724639892578 | KNN Loss: 2.397484540939331 | CLS Loss: 0.01324016135185957\n",
      "Epoch 148 / 200 | iteration 50 / 171 | Total Loss: 2.4605319499969482 | KNN Loss: 2.4501450061798096 | CLS Loss: 0.010386939160525799\n",
      "Epoch 148 / 200 | iteration 60 / 171 | Total Loss: 2.4291367530822754 | KNN Loss: 2.4258995056152344 | CLS Loss: 0.0032373073045164347\n",
      "Epoch 148 / 200 | iteration 70 / 171 | Total Loss: 2.4247660636901855 | KNN Loss: 2.409433364868164 | CLS Loss: 0.015332640148699284\n",
      "Epoch 148 / 200 | iteration 80 / 171 | Total Loss: 2.4349849224090576 | KNN Loss: 2.4278533458709717 | CLS Loss: 0.007131480611860752\n",
      "Epoch 148 / 200 | iteration 90 / 171 | Total Loss: 2.41703462600708 | KNN Loss: 2.4135851860046387 | CLS Loss: 0.003449363401159644\n",
      "Epoch 148 / 200 | iteration 100 / 171 | Total Loss: 2.4270424842834473 | KNN Loss: 2.420588254928589 | CLS Loss: 0.006454321555793285\n",
      "Epoch 148 / 200 | iteration 110 / 171 | Total Loss: 2.3806605339050293 | KNN Loss: 2.3724286556243896 | CLS Loss: 0.008231837302446365\n",
      "Epoch 148 / 200 | iteration 120 / 171 | Total Loss: 2.4093356132507324 | KNN Loss: 2.3943331241607666 | CLS Loss: 0.015002585016191006\n",
      "Epoch 148 / 200 | iteration 130 / 171 | Total Loss: 2.394789457321167 | KNN Loss: 2.3884992599487305 | CLS Loss: 0.006290270481258631\n",
      "Epoch 148 / 200 | iteration 140 / 171 | Total Loss: 2.4116883277893066 | KNN Loss: 2.4074480533599854 | CLS Loss: 0.004240221343934536\n",
      "Epoch 148 / 200 | iteration 150 / 171 | Total Loss: 2.385639190673828 | KNN Loss: 2.3549485206604004 | CLS Loss: 0.030690710991621017\n",
      "Epoch 148 / 200 | iteration 160 / 171 | Total Loss: 2.397629976272583 | KNN Loss: 2.3913629055023193 | CLS Loss: 0.0062671834602952\n",
      "Epoch 148 / 200 | iteration 170 / 171 | Total Loss: 2.4257383346557617 | KNN Loss: 2.412287712097168 | CLS Loss: 0.013450656086206436\n",
      "Epoch: 148, Loss: 2.4160, Train: 0.9967, Valid: 0.9868, Best: 0.9877\n",
      "Epoch 149 / 200 | iteration 0 / 171 | Total Loss: 2.4032142162323 | KNN Loss: 2.3805274963378906 | CLS Loss: 0.022686654701828957\n",
      "Epoch 149 / 200 | iteration 10 / 171 | Total Loss: 2.4187428951263428 | KNN Loss: 2.408252000808716 | CLS Loss: 0.01049082912504673\n",
      "Epoch 149 / 200 | iteration 20 / 171 | Total Loss: 2.392385959625244 | KNN Loss: 2.3767147064208984 | CLS Loss: 0.015671268105506897\n",
      "Epoch 149 / 200 | iteration 30 / 171 | Total Loss: 2.4263219833374023 | KNN Loss: 2.418429374694824 | CLS Loss: 0.007892672903835773\n",
      "Epoch 149 / 200 | iteration 40 / 171 | Total Loss: 2.4455981254577637 | KNN Loss: 2.4329781532287598 | CLS Loss: 0.01261987630277872\n",
      "Epoch 149 / 200 | iteration 50 / 171 | Total Loss: 2.419070243835449 | KNN Loss: 2.4144928455352783 | CLS Loss: 0.004577465355396271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 / 200 | iteration 60 / 171 | Total Loss: 2.4352221488952637 | KNN Loss: 2.4212939739227295 | CLS Loss: 0.013928103260695934\n",
      "Epoch 149 / 200 | iteration 70 / 171 | Total Loss: 2.4316940307617188 | KNN Loss: 2.4191813468933105 | CLS Loss: 0.01251278631389141\n",
      "Epoch 149 / 200 | iteration 80 / 171 | Total Loss: 2.417574882507324 | KNN Loss: 2.41314435005188 | CLS Loss: 0.004430593457072973\n",
      "Epoch 149 / 200 | iteration 90 / 171 | Total Loss: 2.3880486488342285 | KNN Loss: 2.369636058807373 | CLS Loss: 0.018412502482533455\n",
      "Epoch 149 / 200 | iteration 100 / 171 | Total Loss: 2.401202917098999 | KNN Loss: 2.390273094177246 | CLS Loss: 0.010929832234978676\n",
      "Epoch 149 / 200 | iteration 110 / 171 | Total Loss: 2.4214134216308594 | KNN Loss: 2.4011754989624023 | CLS Loss: 0.0202378761023283\n",
      "Epoch 149 / 200 | iteration 120 / 171 | Total Loss: 2.406450033187866 | KNN Loss: 2.40173077583313 | CLS Loss: 0.004719339311122894\n",
      "Epoch 149 / 200 | iteration 130 / 171 | Total Loss: 2.4433255195617676 | KNN Loss: 2.4286344051361084 | CLS Loss: 0.014691031537950039\n",
      "Epoch 149 / 200 | iteration 140 / 171 | Total Loss: 2.3952605724334717 | KNN Loss: 2.38789439201355 | CLS Loss: 0.007366183679550886\n",
      "Epoch 149 / 200 | iteration 150 / 171 | Total Loss: 2.399397850036621 | KNN Loss: 2.372281551361084 | CLS Loss: 0.027116205543279648\n",
      "Epoch 149 / 200 | iteration 160 / 171 | Total Loss: 2.417459011077881 | KNN Loss: 2.3868541717529297 | CLS Loss: 0.030604759231209755\n",
      "Epoch 149 / 200 | iteration 170 / 171 | Total Loss: 2.4393088817596436 | KNN Loss: 2.4267287254333496 | CLS Loss: 0.012580200098454952\n",
      "Epoch: 149, Loss: 2.4204, Train: 0.9957, Valid: 0.9862, Best: 0.9877\n",
      "Epoch 150 / 200 | iteration 0 / 171 | Total Loss: 2.4209015369415283 | KNN Loss: 2.4075846672058105 | CLS Loss: 0.013316771946847439\n",
      "Epoch 150 / 200 | iteration 10 / 171 | Total Loss: 2.378441095352173 | KNN Loss: 2.376023054122925 | CLS Loss: 0.0024179499596357346\n",
      "Epoch 150 / 200 | iteration 20 / 171 | Total Loss: 2.396679639816284 | KNN Loss: 2.383300304412842 | CLS Loss: 0.01337928231805563\n",
      "Epoch 150 / 200 | iteration 30 / 171 | Total Loss: 2.4135823249816895 | KNN Loss: 2.39760160446167 | CLS Loss: 0.01598077453672886\n",
      "Epoch 150 / 200 | iteration 40 / 171 | Total Loss: 2.389336109161377 | KNN Loss: 2.375332832336426 | CLS Loss: 0.014003374613821507\n",
      "Epoch 150 / 200 | iteration 50 / 171 | Total Loss: 2.4095983505249023 | KNN Loss: 2.402491331100464 | CLS Loss: 0.007107105106115341\n",
      "Epoch 150 / 200 | iteration 60 / 171 | Total Loss: 2.3982183933258057 | KNN Loss: 2.389101028442383 | CLS Loss: 0.009117422625422478\n",
      "Epoch 150 / 200 | iteration 70 / 171 | Total Loss: 2.4640073776245117 | KNN Loss: 2.4537181854248047 | CLS Loss: 0.010289180092513561\n",
      "Epoch 150 / 200 | iteration 80 / 171 | Total Loss: 2.383546829223633 | KNN Loss: 2.379368543624878 | CLS Loss: 0.004178214352577925\n",
      "Epoch 150 / 200 | iteration 90 / 171 | Total Loss: 2.4334731101989746 | KNN Loss: 2.423673629760742 | CLS Loss: 0.009799388237297535\n",
      "Epoch 150 / 200 | iteration 100 / 171 | Total Loss: 2.4615390300750732 | KNN Loss: 2.4003405570983887 | CLS Loss: 0.06119850277900696\n",
      "Epoch 150 / 200 | iteration 110 / 171 | Total Loss: 2.396796941757202 | KNN Loss: 2.3857433795928955 | CLS Loss: 0.011053486727178097\n",
      "Epoch 150 / 200 | iteration 120 / 171 | Total Loss: 2.4572067260742188 | KNN Loss: 2.4384987354278564 | CLS Loss: 0.01870790682733059\n",
      "Epoch 150 / 200 | iteration 130 / 171 | Total Loss: 2.4474308490753174 | KNN Loss: 2.4241063594818115 | CLS Loss: 0.023324450477957726\n",
      "Epoch 150 / 200 | iteration 140 / 171 | Total Loss: 2.420795440673828 | KNN Loss: 2.397250175476074 | CLS Loss: 0.023545313626527786\n",
      "Epoch 150 / 200 | iteration 150 / 171 | Total Loss: 2.4615895748138428 | KNN Loss: 2.4445364475250244 | CLS Loss: 0.017053037881851196\n",
      "Epoch 150 / 200 | iteration 160 / 171 | Total Loss: 2.444150686264038 | KNN Loss: 2.4351956844329834 | CLS Loss: 0.008954890072345734\n",
      "Epoch 150 / 200 | iteration 170 / 171 | Total Loss: 2.407468318939209 | KNN Loss: 2.3921101093292236 | CLS Loss: 0.015358146280050278\n",
      "Epoch: 150, Loss: 2.4226, Train: 0.9942, Valid: 0.9847, Best: 0.9877\n",
      "Epoch 151 / 200 | iteration 0 / 171 | Total Loss: 2.400364398956299 | KNN Loss: 2.3843319416046143 | CLS Loss: 0.016032446175813675\n",
      "Epoch 151 / 200 | iteration 10 / 171 | Total Loss: 2.4277191162109375 | KNN Loss: 2.4012913703918457 | CLS Loss: 0.026427676901221275\n",
      "Epoch 151 / 200 | iteration 20 / 171 | Total Loss: 2.4561262130737305 | KNN Loss: 2.438933849334717 | CLS Loss: 0.01719232276082039\n",
      "Epoch 151 / 200 | iteration 30 / 171 | Total Loss: 2.4731273651123047 | KNN Loss: 2.439253807067871 | CLS Loss: 0.03387358412146568\n",
      "Epoch 151 / 200 | iteration 40 / 171 | Total Loss: 2.4188246726989746 | KNN Loss: 2.406231164932251 | CLS Loss: 0.012593616731464863\n",
      "Epoch 151 / 200 | iteration 50 / 171 | Total Loss: 2.4209377765655518 | KNN Loss: 2.406511068344116 | CLS Loss: 0.014426592737436295\n",
      "Epoch 151 / 200 | iteration 60 / 171 | Total Loss: 2.3994321823120117 | KNN Loss: 2.366518974304199 | CLS Loss: 0.032913241535425186\n",
      "Epoch 151 / 200 | iteration 70 / 171 | Total Loss: 2.437215566635132 | KNN Loss: 2.419504165649414 | CLS Loss: 0.017711473628878593\n",
      "Epoch 151 / 200 | iteration 80 / 171 | Total Loss: 2.4542076587677 | KNN Loss: 2.4087789058685303 | CLS Loss: 0.04542874917387962\n",
      "Epoch 151 / 200 | iteration 90 / 171 | Total Loss: 2.4553260803222656 | KNN Loss: 2.444368600845337 | CLS Loss: 0.010957424528896809\n",
      "Epoch 151 / 200 | iteration 100 / 171 | Total Loss: 2.4306459426879883 | KNN Loss: 2.417846202850342 | CLS Loss: 0.012799724005162716\n",
      "Epoch 151 / 200 | iteration 110 / 171 | Total Loss: 2.4097559452056885 | KNN Loss: 2.4044957160949707 | CLS Loss: 0.005260338541120291\n",
      "Epoch 151 / 200 | iteration 120 / 171 | Total Loss: 2.41685152053833 | KNN Loss: 2.411285638809204 | CLS Loss: 0.005565860774368048\n",
      "Epoch 151 / 200 | iteration 130 / 171 | Total Loss: 2.386403799057007 | KNN Loss: 2.367954969406128 | CLS Loss: 0.018448904156684875\n",
      "Epoch 151 / 200 | iteration 140 / 171 | Total Loss: 2.3966925144195557 | KNN Loss: 2.3904690742492676 | CLS Loss: 0.006223429460078478\n",
      "Epoch 151 / 200 | iteration 150 / 171 | Total Loss: 2.444486379623413 | KNN Loss: 2.4356720447540283 | CLS Loss: 0.008814376778900623\n",
      "Epoch 151 / 200 | iteration 160 / 171 | Total Loss: 2.4046883583068848 | KNN Loss: 2.398993492126465 | CLS Loss: 0.005694833118468523\n",
      "Epoch 151 / 200 | iteration 170 / 171 | Total Loss: 2.425468921661377 | KNN Loss: 2.398789882659912 | CLS Loss: 0.02667895331978798\n",
      "Epoch: 151, Loss: 2.4182, Train: 0.9962, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 152 / 200 | iteration 0 / 171 | Total Loss: 2.4535086154937744 | KNN Loss: 2.4489588737487793 | CLS Loss: 0.004549847915768623\n",
      "Epoch 152 / 200 | iteration 10 / 171 | Total Loss: 2.41434645652771 | KNN Loss: 2.4086482524871826 | CLS Loss: 0.005698179826140404\n",
      "Epoch 152 / 200 | iteration 20 / 171 | Total Loss: 2.4333269596099854 | KNN Loss: 2.4064645767211914 | CLS Loss: 0.02686232514679432\n",
      "Epoch 152 / 200 | iteration 30 / 171 | Total Loss: 2.4097073078155518 | KNN Loss: 2.4022421836853027 | CLS Loss: 0.007465093396604061\n",
      "Epoch 152 / 200 | iteration 40 / 171 | Total Loss: 2.455202579498291 | KNN Loss: 2.450956106185913 | CLS Loss: 0.004246535245329142\n",
      "Epoch 152 / 200 | iteration 50 / 171 | Total Loss: 2.4171926975250244 | KNN Loss: 2.407207489013672 | CLS Loss: 0.009985118173062801\n",
      "Epoch 152 / 200 | iteration 60 / 171 | Total Loss: 2.4000959396362305 | KNN Loss: 2.387791872024536 | CLS Loss: 0.012304116040468216\n",
      "Epoch 152 / 200 | iteration 70 / 171 | Total Loss: 2.3986406326293945 | KNN Loss: 2.391697406768799 | CLS Loss: 0.006943266373127699\n",
      "Epoch 152 / 200 | iteration 80 / 171 | Total Loss: 2.4221761226654053 | KNN Loss: 2.4198670387268066 | CLS Loss: 0.0023091945331543684\n",
      "Epoch 152 / 200 | iteration 90 / 171 | Total Loss: 2.4545602798461914 | KNN Loss: 2.436129570007324 | CLS Loss: 0.0184308011084795\n",
      "Epoch 152 / 200 | iteration 100 / 171 | Total Loss: 2.4161386489868164 | KNN Loss: 2.407395601272583 | CLS Loss: 0.00874309055507183\n",
      "Epoch 152 / 200 | iteration 110 / 171 | Total Loss: 2.397650718688965 | KNN Loss: 2.3878440856933594 | CLS Loss: 0.009806676767766476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 / 200 | iteration 120 / 171 | Total Loss: 2.3931679725646973 | KNN Loss: 2.3809800148010254 | CLS Loss: 0.012188032269477844\n",
      "Epoch 152 / 200 | iteration 130 / 171 | Total Loss: 2.4273054599761963 | KNN Loss: 2.4180350303649902 | CLS Loss: 0.0092704389244318\n",
      "Epoch 152 / 200 | iteration 140 / 171 | Total Loss: 2.4420692920684814 | KNN Loss: 2.415151596069336 | CLS Loss: 0.026917627081274986\n",
      "Epoch 152 / 200 | iteration 150 / 171 | Total Loss: 2.3985612392425537 | KNN Loss: 2.3767404556274414 | CLS Loss: 0.02182081714272499\n",
      "Epoch 152 / 200 | iteration 160 / 171 | Total Loss: 2.4378674030303955 | KNN Loss: 2.3955562114715576 | CLS Loss: 0.04231124371290207\n",
      "Epoch 152 / 200 | iteration 170 / 171 | Total Loss: 2.407341718673706 | KNN Loss: 2.400265693664551 | CLS Loss: 0.007075936067849398\n",
      "Epoch: 152, Loss: 2.4186, Train: 0.9960, Valid: 0.9860, Best: 0.9877\n",
      "Epoch 153 / 200 | iteration 0 / 171 | Total Loss: 2.383733034133911 | KNN Loss: 2.3741135597229004 | CLS Loss: 0.009619360789656639\n",
      "Epoch 153 / 200 | iteration 10 / 171 | Total Loss: 2.409511089324951 | KNN Loss: 2.4025795459747314 | CLS Loss: 0.006931561976671219\n",
      "Epoch 153 / 200 | iteration 20 / 171 | Total Loss: 2.4508183002471924 | KNN Loss: 2.428971529006958 | CLS Loss: 0.021846720948815346\n",
      "Epoch 153 / 200 | iteration 30 / 171 | Total Loss: 2.410339117050171 | KNN Loss: 2.400303363800049 | CLS Loss: 0.010035805404186249\n",
      "Epoch 153 / 200 | iteration 40 / 171 | Total Loss: 2.4067277908325195 | KNN Loss: 2.3991501331329346 | CLS Loss: 0.007577541749924421\n",
      "Epoch 153 / 200 | iteration 50 / 171 | Total Loss: 2.3845412731170654 | KNN Loss: 2.3795065879821777 | CLS Loss: 0.005034699570387602\n",
      "Epoch 153 / 200 | iteration 60 / 171 | Total Loss: 2.3972890377044678 | KNN Loss: 2.3869049549102783 | CLS Loss: 0.0103841507807374\n",
      "Epoch 153 / 200 | iteration 70 / 171 | Total Loss: 2.4024205207824707 | KNN Loss: 2.3789541721343994 | CLS Loss: 0.023466413840651512\n",
      "Epoch 153 / 200 | iteration 80 / 171 | Total Loss: 2.44376802444458 | KNN Loss: 2.4336564540863037 | CLS Loss: 0.010111636482179165\n",
      "Epoch 153 / 200 | iteration 90 / 171 | Total Loss: 2.429004669189453 | KNN Loss: 2.421318292617798 | CLS Loss: 0.007686380296945572\n",
      "Epoch 153 / 200 | iteration 100 / 171 | Total Loss: 2.413398027420044 | KNN Loss: 2.3817577362060547 | CLS Loss: 0.031640272587537766\n",
      "Epoch 153 / 200 | iteration 110 / 171 | Total Loss: 2.4031600952148438 | KNN Loss: 2.388878345489502 | CLS Loss: 0.014281630516052246\n",
      "Epoch 153 / 200 | iteration 120 / 171 | Total Loss: 2.416553258895874 | KNN Loss: 2.388425350189209 | CLS Loss: 0.02812792919576168\n",
      "Epoch 153 / 200 | iteration 130 / 171 | Total Loss: 2.382720470428467 | KNN Loss: 2.371140480041504 | CLS Loss: 0.011579927057027817\n",
      "Epoch 153 / 200 | iteration 140 / 171 | Total Loss: 2.456747531890869 | KNN Loss: 2.4410765171051025 | CLS Loss: 0.01567099615931511\n",
      "Epoch 153 / 200 | iteration 150 / 171 | Total Loss: 2.4301276206970215 | KNN Loss: 2.423426628112793 | CLS Loss: 0.006701034959405661\n",
      "Epoch 153 / 200 | iteration 160 / 171 | Total Loss: 2.414297103881836 | KNN Loss: 2.3824126720428467 | CLS Loss: 0.03188438341021538\n",
      "Epoch 153 / 200 | iteration 170 / 171 | Total Loss: 2.387873411178589 | KNN Loss: 2.3809101581573486 | CLS Loss: 0.006963309831917286\n",
      "Epoch: 153, Loss: 2.4165, Train: 0.9962, Valid: 0.9875, Best: 0.9877\n",
      "Epoch 154 / 200 | iteration 0 / 171 | Total Loss: 2.4147934913635254 | KNN Loss: 2.392620325088501 | CLS Loss: 0.022173257544636726\n",
      "Epoch 154 / 200 | iteration 10 / 171 | Total Loss: 2.422471761703491 | KNN Loss: 2.41770339012146 | CLS Loss: 0.004768442362546921\n",
      "Epoch 154 / 200 | iteration 20 / 171 | Total Loss: 2.402151584625244 | KNN Loss: 2.388592004776001 | CLS Loss: 0.01355952862650156\n",
      "Epoch 154 / 200 | iteration 30 / 171 | Total Loss: 2.397235870361328 | KNN Loss: 2.387385129928589 | CLS Loss: 0.009850647300481796\n",
      "Epoch 154 / 200 | iteration 40 / 171 | Total Loss: 2.4122791290283203 | KNN Loss: 2.399075984954834 | CLS Loss: 0.013203082606196404\n",
      "Epoch 154 / 200 | iteration 50 / 171 | Total Loss: 2.418710470199585 | KNN Loss: 2.411466360092163 | CLS Loss: 0.007244180887937546\n",
      "Epoch 154 / 200 | iteration 60 / 171 | Total Loss: 2.419252395629883 | KNN Loss: 2.3888866901397705 | CLS Loss: 0.030365820974111557\n",
      "Epoch 154 / 200 | iteration 70 / 171 | Total Loss: 2.4346888065338135 | KNN Loss: 2.4273860454559326 | CLS Loss: 0.007302666548639536\n",
      "Epoch 154 / 200 | iteration 80 / 171 | Total Loss: 2.416412830352783 | KNN Loss: 2.4050872325897217 | CLS Loss: 0.011325648054480553\n",
      "Epoch 154 / 200 | iteration 90 / 171 | Total Loss: 2.3855996131896973 | KNN Loss: 2.363173484802246 | CLS Loss: 0.0224261786788702\n",
      "Epoch 154 / 200 | iteration 100 / 171 | Total Loss: 2.3966827392578125 | KNN Loss: 2.3834030628204346 | CLS Loss: 0.013279608450829983\n",
      "Epoch 154 / 200 | iteration 110 / 171 | Total Loss: 2.4233953952789307 | KNN Loss: 2.4143171310424805 | CLS Loss: 0.009078227914869785\n",
      "Epoch 154 / 200 | iteration 120 / 171 | Total Loss: 2.4302244186401367 | KNN Loss: 2.422877073287964 | CLS Loss: 0.0073473271913826466\n",
      "Epoch 154 / 200 | iteration 130 / 171 | Total Loss: 2.4198286533355713 | KNN Loss: 2.4137167930603027 | CLS Loss: 0.00611191475763917\n",
      "Epoch 154 / 200 | iteration 140 / 171 | Total Loss: 2.440396308898926 | KNN Loss: 2.4257349967956543 | CLS Loss: 0.014661251567304134\n",
      "Epoch 154 / 200 | iteration 150 / 171 | Total Loss: 2.4167075157165527 | KNN Loss: 2.3954877853393555 | CLS Loss: 0.02121967077255249\n",
      "Epoch 154 / 200 | iteration 160 / 171 | Total Loss: 2.386552333831787 | KNN Loss: 2.3816092014312744 | CLS Loss: 0.004943189676851034\n",
      "Epoch 154 / 200 | iteration 170 / 171 | Total Loss: 2.406451463699341 | KNN Loss: 2.3938188552856445 | CLS Loss: 0.01263268943876028\n",
      "Epoch: 154, Loss: 2.4215, Train: 0.9960, Valid: 0.9855, Best: 0.9877\n",
      "Epoch 155 / 200 | iteration 0 / 171 | Total Loss: 2.4201502799987793 | KNN Loss: 2.4021220207214355 | CLS Loss: 0.018028350546956062\n",
      "Epoch 155 / 200 | iteration 10 / 171 | Total Loss: 2.465224504470825 | KNN Loss: 2.452955484390259 | CLS Loss: 0.012269086204469204\n",
      "Epoch 155 / 200 | iteration 20 / 171 | Total Loss: 2.432067394256592 | KNN Loss: 2.4250595569610596 | CLS Loss: 0.00700774323195219\n",
      "Epoch 155 / 200 | iteration 30 / 171 | Total Loss: 2.4012253284454346 | KNN Loss: 2.3858766555786133 | CLS Loss: 0.015348676592111588\n",
      "Epoch 155 / 200 | iteration 40 / 171 | Total Loss: 2.40175461769104 | KNN Loss: 2.391000747680664 | CLS Loss: 0.010753972455859184\n",
      "Epoch 155 / 200 | iteration 50 / 171 | Total Loss: 2.4412198066711426 | KNN Loss: 2.432356119155884 | CLS Loss: 0.008863628841936588\n",
      "Epoch 155 / 200 | iteration 60 / 171 | Total Loss: 2.4092347621917725 | KNN Loss: 2.3996620178222656 | CLS Loss: 0.00957263819873333\n",
      "Epoch 155 / 200 | iteration 70 / 171 | Total Loss: 2.3762524127960205 | KNN Loss: 2.371189832687378 | CLS Loss: 0.005062520038336515\n",
      "Epoch 155 / 200 | iteration 80 / 171 | Total Loss: 2.4117074012756348 | KNN Loss: 2.3876943588256836 | CLS Loss: 0.024012930691242218\n",
      "Epoch 155 / 200 | iteration 90 / 171 | Total Loss: 2.3798534870147705 | KNN Loss: 2.3614144325256348 | CLS Loss: 0.018438970670104027\n",
      "Epoch 155 / 200 | iteration 100 / 171 | Total Loss: 2.4300994873046875 | KNN Loss: 2.427069902420044 | CLS Loss: 0.003029683604836464\n",
      "Epoch 155 / 200 | iteration 110 / 171 | Total Loss: 2.3893470764160156 | KNN Loss: 2.380901575088501 | CLS Loss: 0.008445442654192448\n",
      "Epoch 155 / 200 | iteration 120 / 171 | Total Loss: 2.3818163871765137 | KNN Loss: 2.3795700073242188 | CLS Loss: 0.0022464885842055082\n",
      "Epoch 155 / 200 | iteration 130 / 171 | Total Loss: 2.386355400085449 | KNN Loss: 2.3809454441070557 | CLS Loss: 0.0054098740220069885\n",
      "Epoch 155 / 200 | iteration 140 / 171 | Total Loss: 2.4100208282470703 | KNN Loss: 2.4046125411987305 | CLS Loss: 0.005408213473856449\n",
      "Epoch 155 / 200 | iteration 150 / 171 | Total Loss: 2.4435367584228516 | KNN Loss: 2.4346511363983154 | CLS Loss: 0.008885512128472328\n",
      "Epoch 155 / 200 | iteration 160 / 171 | Total Loss: 2.443603038787842 | KNN Loss: 2.4208414554595947 | CLS Loss: 0.022761572152376175\n",
      "Epoch 155 / 200 | iteration 170 / 171 | Total Loss: 2.468698263168335 | KNN Loss: 2.4467241764068604 | CLS Loss: 0.021973975002765656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 155, Loss: 2.4190, Train: 0.9962, Valid: 0.9857, Best: 0.9877\n",
      "Epoch 156 / 200 | iteration 0 / 171 | Total Loss: 2.426699161529541 | KNN Loss: 2.403536796569824 | CLS Loss: 0.02316235564649105\n",
      "Epoch 156 / 200 | iteration 10 / 171 | Total Loss: 2.4227330684661865 | KNN Loss: 2.418480157852173 | CLS Loss: 0.004252924583852291\n",
      "Epoch 156 / 200 | iteration 20 / 171 | Total Loss: 2.418699264526367 | KNN Loss: 2.4063868522644043 | CLS Loss: 0.012312395498156548\n",
      "Epoch 156 / 200 | iteration 30 / 171 | Total Loss: 2.38853120803833 | KNN Loss: 2.374603748321533 | CLS Loss: 0.013927376829087734\n",
      "Epoch 156 / 200 | iteration 40 / 171 | Total Loss: 2.3793036937713623 | KNN Loss: 2.3694777488708496 | CLS Loss: 0.009826061315834522\n",
      "Epoch 156 / 200 | iteration 50 / 171 | Total Loss: 2.4142889976501465 | KNN Loss: 2.4078969955444336 | CLS Loss: 0.006392107345163822\n",
      "Epoch 156 / 200 | iteration 60 / 171 | Total Loss: 2.4464635848999023 | KNN Loss: 2.4304423332214355 | CLS Loss: 0.016021285206079483\n",
      "Epoch 156 / 200 | iteration 70 / 171 | Total Loss: 2.4271697998046875 | KNN Loss: 2.4191246032714844 | CLS Loss: 0.00804510060697794\n",
      "Epoch 156 / 200 | iteration 80 / 171 | Total Loss: 2.42214298248291 | KNN Loss: 2.4112377166748047 | CLS Loss: 0.010905294679105282\n",
      "Epoch 156 / 200 | iteration 90 / 171 | Total Loss: 2.413405656814575 | KNN Loss: 2.409946918487549 | CLS Loss: 0.0034586251713335514\n",
      "Epoch 156 / 200 | iteration 100 / 171 | Total Loss: 2.4751460552215576 | KNN Loss: 2.455610752105713 | CLS Loss: 0.01953539438545704\n",
      "Epoch 156 / 200 | iteration 110 / 171 | Total Loss: 2.4008047580718994 | KNN Loss: 2.3941996097564697 | CLS Loss: 0.006605234928429127\n",
      "Epoch 156 / 200 | iteration 120 / 171 | Total Loss: 2.4322540760040283 | KNN Loss: 2.407353639602661 | CLS Loss: 0.02490055002272129\n",
      "Epoch 156 / 200 | iteration 130 / 171 | Total Loss: 2.4183552265167236 | KNN Loss: 2.3978428840637207 | CLS Loss: 0.020512335002422333\n",
      "Epoch 156 / 200 | iteration 140 / 171 | Total Loss: 2.412543296813965 | KNN Loss: 2.4014945030212402 | CLS Loss: 0.0110488785430789\n",
      "Epoch 156 / 200 | iteration 150 / 171 | Total Loss: 2.445876359939575 | KNN Loss: 2.4404327869415283 | CLS Loss: 0.00544347520917654\n",
      "Epoch 156 / 200 | iteration 160 / 171 | Total Loss: 2.41496205329895 | KNN Loss: 2.408925771713257 | CLS Loss: 0.006036170292645693\n",
      "Epoch 156 / 200 | iteration 170 / 171 | Total Loss: 2.403674840927124 | KNN Loss: 2.4010086059570312 | CLS Loss: 0.0026661811862140894\n",
      "Epoch: 156, Loss: 2.4189, Train: 0.9961, Valid: 0.9867, Best: 0.9877\n",
      "Epoch 157 / 200 | iteration 0 / 171 | Total Loss: 2.4726643562316895 | KNN Loss: 2.434049129486084 | CLS Loss: 0.03861534595489502\n",
      "Epoch 157 / 200 | iteration 10 / 171 | Total Loss: 2.377678871154785 | KNN Loss: 2.368134021759033 | CLS Loss: 0.00954491924494505\n",
      "Epoch 157 / 200 | iteration 20 / 171 | Total Loss: 2.42974591255188 | KNN Loss: 2.4161548614501953 | CLS Loss: 0.013590946793556213\n",
      "Epoch 157 / 200 | iteration 30 / 171 | Total Loss: 2.4660212993621826 | KNN Loss: 2.4369826316833496 | CLS Loss: 0.029038729146122932\n",
      "Epoch 157 / 200 | iteration 40 / 171 | Total Loss: 2.4021899700164795 | KNN Loss: 2.3921706676483154 | CLS Loss: 0.010019255802035332\n",
      "Epoch 157 / 200 | iteration 50 / 171 | Total Loss: 2.383479356765747 | KNN Loss: 2.3590242862701416 | CLS Loss: 0.024455128237605095\n",
      "Epoch 157 / 200 | iteration 60 / 171 | Total Loss: 2.4244112968444824 | KNN Loss: 2.392573118209839 | CLS Loss: 0.031838174909353256\n",
      "Epoch 157 / 200 | iteration 70 / 171 | Total Loss: 2.420792579650879 | KNN Loss: 2.4039430618286133 | CLS Loss: 0.01684947870671749\n",
      "Epoch 157 / 200 | iteration 80 / 171 | Total Loss: 2.4459891319274902 | KNN Loss: 2.423494577407837 | CLS Loss: 0.022494517266750336\n",
      "Epoch 157 / 200 | iteration 90 / 171 | Total Loss: 2.4183919429779053 | KNN Loss: 2.4130687713623047 | CLS Loss: 0.005323105026036501\n",
      "Epoch 157 / 200 | iteration 100 / 171 | Total Loss: 2.433373212814331 | KNN Loss: 2.424856185913086 | CLS Loss: 0.008517083711922169\n",
      "Epoch 157 / 200 | iteration 110 / 171 | Total Loss: 2.4203479290008545 | KNN Loss: 2.404772996902466 | CLS Loss: 0.015574868768453598\n",
      "Epoch 157 / 200 | iteration 120 / 171 | Total Loss: 2.406156063079834 | KNN Loss: 2.39479660987854 | CLS Loss: 0.011359494179487228\n",
      "Epoch 157 / 200 | iteration 130 / 171 | Total Loss: 2.4038734436035156 | KNN Loss: 2.37876296043396 | CLS Loss: 0.025110533460974693\n",
      "Epoch 157 / 200 | iteration 140 / 171 | Total Loss: 2.409679651260376 | KNN Loss: 2.384843111038208 | CLS Loss: 0.02483656071126461\n",
      "Epoch 157 / 200 | iteration 150 / 171 | Total Loss: 2.458184003829956 | KNN Loss: 2.445802927017212 | CLS Loss: 0.012381092645227909\n",
      "Epoch 157 / 200 | iteration 160 / 171 | Total Loss: 2.452937602996826 | KNN Loss: 2.437976837158203 | CLS Loss: 0.014960759319365025\n",
      "Epoch 157 / 200 | iteration 170 / 171 | Total Loss: 2.42867374420166 | KNN Loss: 2.408303737640381 | CLS Loss: 0.02036989852786064\n",
      "Epoch: 157, Loss: 2.4188, Train: 0.9965, Valid: 0.9857, Best: 0.9877\n",
      "Epoch 158 / 200 | iteration 0 / 171 | Total Loss: 2.4614267349243164 | KNN Loss: 2.4502439498901367 | CLS Loss: 0.011182759888470173\n",
      "Epoch 158 / 200 | iteration 10 / 171 | Total Loss: 2.411059856414795 | KNN Loss: 2.4034078121185303 | CLS Loss: 0.0076519506983459\n",
      "Epoch 158 / 200 | iteration 20 / 171 | Total Loss: 2.4140632152557373 | KNN Loss: 2.4126484394073486 | CLS Loss: 0.0014146676985546947\n",
      "Epoch 158 / 200 | iteration 30 / 171 | Total Loss: 2.3931517601013184 | KNN Loss: 2.388319253921509 | CLS Loss: 0.004832463338971138\n",
      "Epoch 158 / 200 | iteration 40 / 171 | Total Loss: 2.440852403640747 | KNN Loss: 2.4219133853912354 | CLS Loss: 0.018938908353447914\n",
      "Epoch 158 / 200 | iteration 50 / 171 | Total Loss: 2.4030566215515137 | KNN Loss: 2.397153854370117 | CLS Loss: 0.0059027886018157005\n",
      "Epoch 158 / 200 | iteration 60 / 171 | Total Loss: 2.4394664764404297 | KNN Loss: 2.4135358333587646 | CLS Loss: 0.02593059465289116\n",
      "Epoch 158 / 200 | iteration 70 / 171 | Total Loss: 2.3773739337921143 | KNN Loss: 2.3650007247924805 | CLS Loss: 0.01237326581031084\n",
      "Epoch 158 / 200 | iteration 80 / 171 | Total Loss: 2.423917055130005 | KNN Loss: 2.4118311405181885 | CLS Loss: 0.01208591740578413\n",
      "Epoch 158 / 200 | iteration 90 / 171 | Total Loss: 2.4312522411346436 | KNN Loss: 2.417726755142212 | CLS Loss: 0.013525565154850483\n",
      "Epoch 158 / 200 | iteration 100 / 171 | Total Loss: 2.460042953491211 | KNN Loss: 2.4492766857147217 | CLS Loss: 0.010766354389488697\n",
      "Epoch 158 / 200 | iteration 110 / 171 | Total Loss: 2.4192416667938232 | KNN Loss: 2.4009509086608887 | CLS Loss: 0.018290776759386063\n",
      "Epoch 158 / 200 | iteration 120 / 171 | Total Loss: 2.390214681625366 | KNN Loss: 2.368774652481079 | CLS Loss: 0.021439986303448677\n",
      "Epoch 158 / 200 | iteration 130 / 171 | Total Loss: 2.4074771404266357 | KNN Loss: 2.394650936126709 | CLS Loss: 0.012826294638216496\n",
      "Epoch 158 / 200 | iteration 140 / 171 | Total Loss: 2.418659210205078 | KNN Loss: 2.3946104049682617 | CLS Loss: 0.02404877543449402\n",
      "Epoch 158 / 200 | iteration 150 / 171 | Total Loss: 2.4478061199188232 | KNN Loss: 2.43888521194458 | CLS Loss: 0.008920892141759396\n",
      "Epoch 158 / 200 | iteration 160 / 171 | Total Loss: 2.4849119186401367 | KNN Loss: 2.4565184116363525 | CLS Loss: 0.028393570333719254\n",
      "Epoch 158 / 200 | iteration 170 / 171 | Total Loss: 2.4210312366485596 | KNN Loss: 2.388439178466797 | CLS Loss: 0.03259212523698807\n",
      "Epoch: 158, Loss: 2.4225, Train: 0.9961, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 159 / 200 | iteration 0 / 171 | Total Loss: 2.4149844646453857 | KNN Loss: 2.402005672454834 | CLS Loss: 0.012978766113519669\n",
      "Epoch 159 / 200 | iteration 10 / 171 | Total Loss: 2.3954787254333496 | KNN Loss: 2.3828837871551514 | CLS Loss: 0.012594887986779213\n",
      "Epoch 159 / 200 | iteration 20 / 171 | Total Loss: 2.418203830718994 | KNN Loss: 2.4102330207824707 | CLS Loss: 0.007970823906362057\n",
      "Epoch 159 / 200 | iteration 30 / 171 | Total Loss: 2.4360852241516113 | KNN Loss: 2.425089120864868 | CLS Loss: 0.010996009223163128\n",
      "Epoch 159 / 200 | iteration 40 / 171 | Total Loss: 2.40317964553833 | KNN Loss: 2.392667293548584 | CLS Loss: 0.010512336157262325\n",
      "Epoch 159 / 200 | iteration 50 / 171 | Total Loss: 2.3978774547576904 | KNN Loss: 2.384279489517212 | CLS Loss: 0.013598029501736164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 / 200 | iteration 60 / 171 | Total Loss: 2.414212226867676 | KNN Loss: 2.407844066619873 | CLS Loss: 0.0063681709580123425\n",
      "Epoch 159 / 200 | iteration 70 / 171 | Total Loss: 2.42338228225708 | KNN Loss: 2.4188199043273926 | CLS Loss: 0.004562459886074066\n",
      "Epoch 159 / 200 | iteration 80 / 171 | Total Loss: 2.378603219985962 | KNN Loss: 2.372594118118286 | CLS Loss: 0.006009100470691919\n",
      "Epoch 159 / 200 | iteration 90 / 171 | Total Loss: 2.3845295906066895 | KNN Loss: 2.3780343532562256 | CLS Loss: 0.006495276000350714\n",
      "Epoch 159 / 200 | iteration 100 / 171 | Total Loss: 2.418332815170288 | KNN Loss: 2.392852306365967 | CLS Loss: 0.025480465963482857\n",
      "Epoch 159 / 200 | iteration 110 / 171 | Total Loss: 2.4543795585632324 | KNN Loss: 2.432668924331665 | CLS Loss: 0.02171061933040619\n",
      "Epoch 159 / 200 | iteration 120 / 171 | Total Loss: 2.422098159790039 | KNN Loss: 2.4148752689361572 | CLS Loss: 0.0072228508070111275\n",
      "Epoch 159 / 200 | iteration 130 / 171 | Total Loss: 2.429772138595581 | KNN Loss: 2.405184030532837 | CLS Loss: 0.024588221684098244\n",
      "Epoch 159 / 200 | iteration 140 / 171 | Total Loss: 2.4004628658294678 | KNN Loss: 2.390181541442871 | CLS Loss: 0.01028143335133791\n",
      "Epoch 159 / 200 | iteration 150 / 171 | Total Loss: 2.4235446453094482 | KNN Loss: 2.4103455543518066 | CLS Loss: 0.01319898571819067\n",
      "Epoch 159 / 200 | iteration 160 / 171 | Total Loss: 2.420807361602783 | KNN Loss: 2.4072062969207764 | CLS Loss: 0.013600998558104038\n",
      "Epoch 159 / 200 | iteration 170 / 171 | Total Loss: 2.3986730575561523 | KNN Loss: 2.386223793029785 | CLS Loss: 0.01244931761175394\n",
      "Epoch: 159, Loss: 2.4171, Train: 0.9964, Valid: 0.9860, Best: 0.9877\n",
      "Epoch 160 / 200 | iteration 0 / 171 | Total Loss: 2.427103042602539 | KNN Loss: 2.4175426959991455 | CLS Loss: 0.009560266509652138\n",
      "Epoch 160 / 200 | iteration 10 / 171 | Total Loss: 2.3678855895996094 | KNN Loss: 2.3647663593292236 | CLS Loss: 0.0031193094328045845\n",
      "Epoch 160 / 200 | iteration 20 / 171 | Total Loss: 2.392742395401001 | KNN Loss: 2.368105411529541 | CLS Loss: 0.024637077003717422\n",
      "Epoch 160 / 200 | iteration 30 / 171 | Total Loss: 2.425419569015503 | KNN Loss: 2.4075424671173096 | CLS Loss: 0.017877090722322464\n",
      "Epoch 160 / 200 | iteration 40 / 171 | Total Loss: 2.4562783241271973 | KNN Loss: 2.413317918777466 | CLS Loss: 0.042960312217473984\n",
      "Epoch 160 / 200 | iteration 50 / 171 | Total Loss: 2.437274217605591 | KNN Loss: 2.4176385402679443 | CLS Loss: 0.019635727629065514\n",
      "Epoch 160 / 200 | iteration 60 / 171 | Total Loss: 2.369349718093872 | KNN Loss: 2.3612382411956787 | CLS Loss: 0.008111553266644478\n",
      "Epoch 160 / 200 | iteration 70 / 171 | Total Loss: 2.423375368118286 | KNN Loss: 2.4021337032318115 | CLS Loss: 0.021241694688796997\n",
      "Epoch 160 / 200 | iteration 80 / 171 | Total Loss: 2.3976426124572754 | KNN Loss: 2.3773252964019775 | CLS Loss: 0.02031729556620121\n",
      "Epoch 160 / 200 | iteration 90 / 171 | Total Loss: 2.4418904781341553 | KNN Loss: 2.4363768100738525 | CLS Loss: 0.00551363080739975\n",
      "Epoch 160 / 200 | iteration 100 / 171 | Total Loss: 2.4238786697387695 | KNN Loss: 2.419142246246338 | CLS Loss: 0.00473649799823761\n",
      "Epoch 160 / 200 | iteration 110 / 171 | Total Loss: 2.4295296669006348 | KNN Loss: 2.4121997356414795 | CLS Loss: 0.017329998314380646\n",
      "Epoch 160 / 200 | iteration 120 / 171 | Total Loss: 2.419797897338867 | KNN Loss: 2.4072864055633545 | CLS Loss: 0.01251138374209404\n",
      "Epoch 160 / 200 | iteration 130 / 171 | Total Loss: 2.4176204204559326 | KNN Loss: 2.3992652893066406 | CLS Loss: 0.018355173990130424\n",
      "Epoch 160 / 200 | iteration 140 / 171 | Total Loss: 2.3749332427978516 | KNN Loss: 2.3706047534942627 | CLS Loss: 0.004328502342104912\n",
      "Epoch 160 / 200 | iteration 150 / 171 | Total Loss: 2.3765146732330322 | KNN Loss: 2.366774559020996 | CLS Loss: 0.00974018219858408\n",
      "Epoch 160 / 200 | iteration 160 / 171 | Total Loss: 2.391587972640991 | KNN Loss: 2.369023561477661 | CLS Loss: 0.022564388811588287\n",
      "Epoch 160 / 200 | iteration 170 / 171 | Total Loss: 2.4070725440979004 | KNN Loss: 2.3977808952331543 | CLS Loss: 0.009291640482842922\n",
      "Epoch: 160, Loss: 2.4166, Train: 0.9942, Valid: 0.9832, Best: 0.9877\n",
      "Epoch 161 / 200 | iteration 0 / 171 | Total Loss: 2.3769848346710205 | KNN Loss: 2.3545470237731934 | CLS Loss: 0.022437840700149536\n",
      "Epoch 161 / 200 | iteration 10 / 171 | Total Loss: 2.425623655319214 | KNN Loss: 2.4075522422790527 | CLS Loss: 0.018071413040161133\n",
      "Epoch 161 / 200 | iteration 20 / 171 | Total Loss: 2.4131548404693604 | KNN Loss: 2.3967056274414062 | CLS Loss: 0.016449211165308952\n",
      "Epoch 161 / 200 | iteration 30 / 171 | Total Loss: 2.436790704727173 | KNN Loss: 2.4289321899414062 | CLS Loss: 0.007858539931476116\n",
      "Epoch 161 / 200 | iteration 40 / 171 | Total Loss: 2.4108502864837646 | KNN Loss: 2.3951151371002197 | CLS Loss: 0.01573517732322216\n",
      "Epoch 161 / 200 | iteration 50 / 171 | Total Loss: 2.4242212772369385 | KNN Loss: 2.383653402328491 | CLS Loss: 0.04056775942444801\n",
      "Epoch 161 / 200 | iteration 60 / 171 | Total Loss: 2.4163248538970947 | KNN Loss: 2.404545783996582 | CLS Loss: 0.011779005639255047\n",
      "Epoch 161 / 200 | iteration 70 / 171 | Total Loss: 2.412684440612793 | KNN Loss: 2.3933842182159424 | CLS Loss: 0.019300341606140137\n",
      "Epoch 161 / 200 | iteration 80 / 171 | Total Loss: 2.395843029022217 | KNN Loss: 2.3780617713928223 | CLS Loss: 0.01778123900294304\n",
      "Epoch 161 / 200 | iteration 90 / 171 | Total Loss: 2.400165557861328 | KNN Loss: 2.3862195014953613 | CLS Loss: 0.013945979997515678\n",
      "Epoch 161 / 200 | iteration 100 / 171 | Total Loss: 2.4180381298065186 | KNN Loss: 2.4046106338500977 | CLS Loss: 0.01342750433832407\n",
      "Epoch 161 / 200 | iteration 110 / 171 | Total Loss: 2.398855686187744 | KNN Loss: 2.3947482109069824 | CLS Loss: 0.004107453860342503\n",
      "Epoch 161 / 200 | iteration 120 / 171 | Total Loss: 2.391474962234497 | KNN Loss: 2.3866024017333984 | CLS Loss: 0.0048725721426308155\n",
      "Epoch 161 / 200 | iteration 130 / 171 | Total Loss: 2.4205434322357178 | KNN Loss: 2.400143623352051 | CLS Loss: 0.020399771630764008\n",
      "Epoch 161 / 200 | iteration 140 / 171 | Total Loss: 2.4188179969787598 | KNN Loss: 2.4102964401245117 | CLS Loss: 0.008521616458892822\n",
      "Epoch 161 / 200 | iteration 150 / 171 | Total Loss: 2.430901288986206 | KNN Loss: 2.415658473968506 | CLS Loss: 0.01524271722882986\n",
      "Epoch 161 / 200 | iteration 160 / 171 | Total Loss: 2.4454267024993896 | KNN Loss: 2.441175937652588 | CLS Loss: 0.004250696394592524\n",
      "Epoch 161 / 200 | iteration 170 / 171 | Total Loss: 2.397879123687744 | KNN Loss: 2.3793389797210693 | CLS Loss: 0.018540160730481148\n",
      "Epoch: 161, Loss: 2.4177, Train: 0.9962, Valid: 0.9862, Best: 0.9877\n",
      "Epoch 162 / 200 | iteration 0 / 171 | Total Loss: 2.375190258026123 | KNN Loss: 2.373504400253296 | CLS Loss: 0.0016857770970091224\n",
      "Epoch 162 / 200 | iteration 10 / 171 | Total Loss: 2.371882200241089 | KNN Loss: 2.3700151443481445 | CLS Loss: 0.0018669760320335627\n",
      "Epoch 162 / 200 | iteration 20 / 171 | Total Loss: 2.4241273403167725 | KNN Loss: 2.3981378078460693 | CLS Loss: 0.025989443063735962\n",
      "Epoch 162 / 200 | iteration 30 / 171 | Total Loss: 2.4313759803771973 | KNN Loss: 2.416689872741699 | CLS Loss: 0.014686069451272488\n",
      "Epoch 162 / 200 | iteration 40 / 171 | Total Loss: 2.4276621341705322 | KNN Loss: 2.4227421283721924 | CLS Loss: 0.004919922910630703\n",
      "Epoch 162 / 200 | iteration 50 / 171 | Total Loss: 2.394543170928955 | KNN Loss: 2.3931422233581543 | CLS Loss: 0.0014010407030582428\n",
      "Epoch 162 / 200 | iteration 60 / 171 | Total Loss: 2.4334771633148193 | KNN Loss: 2.419435501098633 | CLS Loss: 0.014041643589735031\n",
      "Epoch 162 / 200 | iteration 70 / 171 | Total Loss: 2.384303331375122 | KNN Loss: 2.3765177726745605 | CLS Loss: 0.0077855284325778484\n",
      "Epoch 162 / 200 | iteration 80 / 171 | Total Loss: 2.400576114654541 | KNN Loss: 2.38258957862854 | CLS Loss: 0.017986563965678215\n",
      "Epoch 162 / 200 | iteration 90 / 171 | Total Loss: 2.400951385498047 | KNN Loss: 2.3672268390655518 | CLS Loss: 0.03372465819120407\n",
      "Epoch 162 / 200 | iteration 100 / 171 | Total Loss: 2.3751442432403564 | KNN Loss: 2.3721890449523926 | CLS Loss: 0.0029551463667303324\n",
      "Epoch 162 / 200 | iteration 110 / 171 | Total Loss: 2.4492454528808594 | KNN Loss: 2.438721179962158 | CLS Loss: 0.010524182580411434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 / 200 | iteration 120 / 171 | Total Loss: 2.438447952270508 | KNN Loss: 2.4200491905212402 | CLS Loss: 0.018398789688944817\n",
      "Epoch 162 / 200 | iteration 130 / 171 | Total Loss: 2.419670581817627 | KNN Loss: 2.3884103298187256 | CLS Loss: 0.031260184943675995\n",
      "Epoch 162 / 200 | iteration 140 / 171 | Total Loss: 2.4277660846710205 | KNN Loss: 2.4169833660125732 | CLS Loss: 0.010782704688608646\n",
      "Epoch 162 / 200 | iteration 150 / 171 | Total Loss: 2.3850669860839844 | KNN Loss: 2.374346971511841 | CLS Loss: 0.010719978250563145\n",
      "Epoch 162 / 200 | iteration 160 / 171 | Total Loss: 2.4704678058624268 | KNN Loss: 2.457977294921875 | CLS Loss: 0.012490605004131794\n",
      "Epoch 162 / 200 | iteration 170 / 171 | Total Loss: 2.3771064281463623 | KNN Loss: 2.3634033203125 | CLS Loss: 0.013702993281185627\n",
      "Epoch: 162, Loss: 2.4231, Train: 0.9961, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 163 / 200 | iteration 0 / 171 | Total Loss: 2.3837435245513916 | KNN Loss: 2.3719606399536133 | CLS Loss: 0.011782887391746044\n",
      "Epoch 163 / 200 | iteration 10 / 171 | Total Loss: 2.412668466567993 | KNN Loss: 2.405731439590454 | CLS Loss: 0.006937088444828987\n",
      "Epoch 163 / 200 | iteration 20 / 171 | Total Loss: 2.4027600288391113 | KNN Loss: 2.381706953048706 | CLS Loss: 0.021053113043308258\n",
      "Epoch 163 / 200 | iteration 30 / 171 | Total Loss: 2.412766695022583 | KNN Loss: 2.393665075302124 | CLS Loss: 0.019101526588201523\n",
      "Epoch 163 / 200 | iteration 40 / 171 | Total Loss: 2.4562368392944336 | KNN Loss: 2.4369382858276367 | CLS Loss: 0.019298439845442772\n",
      "Epoch 163 / 200 | iteration 50 / 171 | Total Loss: 2.4087767601013184 | KNN Loss: 2.391059398651123 | CLS Loss: 0.017717454582452774\n",
      "Epoch 163 / 200 | iteration 60 / 171 | Total Loss: 2.4541499614715576 | KNN Loss: 2.4298086166381836 | CLS Loss: 0.024341441690921783\n",
      "Epoch 163 / 200 | iteration 70 / 171 | Total Loss: 2.4178521633148193 | KNN Loss: 2.4077987670898438 | CLS Loss: 0.010053431615233421\n",
      "Epoch 163 / 200 | iteration 80 / 171 | Total Loss: 2.4563817977905273 | KNN Loss: 2.424417495727539 | CLS Loss: 0.031964272260665894\n",
      "Epoch 163 / 200 | iteration 90 / 171 | Total Loss: 2.4073143005371094 | KNN Loss: 2.3987584114074707 | CLS Loss: 0.008555907756090164\n",
      "Epoch 163 / 200 | iteration 100 / 171 | Total Loss: 2.4236338138580322 | KNN Loss: 2.417942523956299 | CLS Loss: 0.00569121353328228\n",
      "Epoch 163 / 200 | iteration 110 / 171 | Total Loss: 2.444965362548828 | KNN Loss: 2.4417927265167236 | CLS Loss: 0.0031725955195724964\n",
      "Epoch 163 / 200 | iteration 120 / 171 | Total Loss: 2.400514841079712 | KNN Loss: 2.394402027130127 | CLS Loss: 0.006112789269536734\n",
      "Epoch 163 / 200 | iteration 130 / 171 | Total Loss: 2.4489870071411133 | KNN Loss: 2.4182310104370117 | CLS Loss: 0.030756069347262383\n",
      "Epoch 163 / 200 | iteration 140 / 171 | Total Loss: 2.409104824066162 | KNN Loss: 2.4066309928894043 | CLS Loss: 0.00247389473952353\n",
      "Epoch 163 / 200 | iteration 150 / 171 | Total Loss: 2.4259414672851562 | KNN Loss: 2.403214454650879 | CLS Loss: 0.022727057337760925\n",
      "Epoch 163 / 200 | iteration 160 / 171 | Total Loss: 2.403386116027832 | KNN Loss: 2.387471914291382 | CLS Loss: 0.015914106741547585\n",
      "Epoch 163 / 200 | iteration 170 / 171 | Total Loss: 2.427854299545288 | KNN Loss: 2.4130122661590576 | CLS Loss: 0.014841926284134388\n",
      "Epoch: 163, Loss: 2.4184, Train: 0.9965, Valid: 0.9859, Best: 0.9877\n",
      "Epoch 164 / 200 | iteration 0 / 171 | Total Loss: 2.3997128009796143 | KNN Loss: 2.3821070194244385 | CLS Loss: 0.017605669796466827\n",
      "Epoch 164 / 200 | iteration 10 / 171 | Total Loss: 2.398149013519287 | KNN Loss: 2.3888490200042725 | CLS Loss: 0.009300006553530693\n",
      "Epoch 164 / 200 | iteration 20 / 171 | Total Loss: 2.405205488204956 | KNN Loss: 2.3976523876190186 | CLS Loss: 0.007553168572485447\n",
      "Epoch 164 / 200 | iteration 30 / 171 | Total Loss: 2.440579652786255 | KNN Loss: 2.4326281547546387 | CLS Loss: 0.00795156229287386\n",
      "Epoch 164 / 200 | iteration 40 / 171 | Total Loss: 2.4308102130889893 | KNN Loss: 2.402470111846924 | CLS Loss: 0.02834014594554901\n",
      "Epoch 164 / 200 | iteration 50 / 171 | Total Loss: 2.4179069995880127 | KNN Loss: 2.3890888690948486 | CLS Loss: 0.028818199411034584\n",
      "Epoch 164 / 200 | iteration 60 / 171 | Total Loss: 2.4034664630889893 | KNN Loss: 2.386601448059082 | CLS Loss: 0.016865041106939316\n",
      "Epoch 164 / 200 | iteration 70 / 171 | Total Loss: 2.4311203956604004 | KNN Loss: 2.4112017154693604 | CLS Loss: 0.01991862989962101\n",
      "Epoch 164 / 200 | iteration 80 / 171 | Total Loss: 2.4783802032470703 | KNN Loss: 2.4544260501861572 | CLS Loss: 0.023954151198267937\n",
      "Epoch 164 / 200 | iteration 90 / 171 | Total Loss: 2.443631410598755 | KNN Loss: 2.439762592315674 | CLS Loss: 0.0038687451742589474\n",
      "Epoch 164 / 200 | iteration 100 / 171 | Total Loss: 2.4102516174316406 | KNN Loss: 2.408693790435791 | CLS Loss: 0.001557838753797114\n",
      "Epoch 164 / 200 | iteration 110 / 171 | Total Loss: 2.4044229984283447 | KNN Loss: 2.3898401260375977 | CLS Loss: 0.014582893811166286\n",
      "Epoch 164 / 200 | iteration 120 / 171 | Total Loss: 2.4012997150421143 | KNN Loss: 2.387002468109131 | CLS Loss: 0.014297360554337502\n",
      "Epoch 164 / 200 | iteration 130 / 171 | Total Loss: 2.3801167011260986 | KNN Loss: 2.36034893989563 | CLS Loss: 0.019767723977565765\n",
      "Epoch 164 / 200 | iteration 140 / 171 | Total Loss: 2.4218766689300537 | KNN Loss: 2.3934972286224365 | CLS Loss: 0.02837951108813286\n",
      "Epoch 164 / 200 | iteration 150 / 171 | Total Loss: 2.449852705001831 | KNN Loss: 2.4120402336120605 | CLS Loss: 0.03781241551041603\n",
      "Epoch 164 / 200 | iteration 160 / 171 | Total Loss: 2.370161771774292 | KNN Loss: 2.364532470703125 | CLS Loss: 0.005629342049360275\n",
      "Epoch 164 / 200 | iteration 170 / 171 | Total Loss: 2.3921167850494385 | KNN Loss: 2.372945785522461 | CLS Loss: 0.0191709715873003\n",
      "Epoch: 164, Loss: 2.4209, Train: 0.9965, Valid: 0.9864, Best: 0.9877\n",
      "Epoch 165 / 200 | iteration 0 / 171 | Total Loss: 2.3878543376922607 | KNN Loss: 2.357805013656616 | CLS Loss: 0.030049243941903114\n",
      "Epoch 165 / 200 | iteration 10 / 171 | Total Loss: 2.42340087890625 | KNN Loss: 2.4208741188049316 | CLS Loss: 0.002526653930544853\n",
      "Epoch 165 / 200 | iteration 20 / 171 | Total Loss: 2.502858877182007 | KNN Loss: 2.493800163269043 | CLS Loss: 0.009058794006705284\n",
      "Epoch 165 / 200 | iteration 30 / 171 | Total Loss: 2.4064931869506836 | KNN Loss: 2.403745651245117 | CLS Loss: 0.0027474460657685995\n",
      "Epoch 165 / 200 | iteration 40 / 171 | Total Loss: 2.440187454223633 | KNN Loss: 2.4140918254852295 | CLS Loss: 0.02609565481543541\n",
      "Epoch 165 / 200 | iteration 50 / 171 | Total Loss: 2.420664072036743 | KNN Loss: 2.4072670936584473 | CLS Loss: 0.013396870344877243\n",
      "Epoch 165 / 200 | iteration 60 / 171 | Total Loss: 2.3843789100646973 | KNN Loss: 2.3805110454559326 | CLS Loss: 0.0038679034914821386\n",
      "Epoch 165 / 200 | iteration 70 / 171 | Total Loss: 2.3694448471069336 | KNN Loss: 2.366637945175171 | CLS Loss: 0.0028068663086742163\n",
      "Epoch 165 / 200 | iteration 80 / 171 | Total Loss: 2.4261207580566406 | KNN Loss: 2.4087352752685547 | CLS Loss: 0.017385371029376984\n",
      "Epoch 165 / 200 | iteration 90 / 171 | Total Loss: 2.4167189598083496 | KNN Loss: 2.397369384765625 | CLS Loss: 0.019349541515111923\n",
      "Epoch 165 / 200 | iteration 100 / 171 | Total Loss: 2.40777587890625 | KNN Loss: 2.4005274772644043 | CLS Loss: 0.007248349953442812\n",
      "Epoch 165 / 200 | iteration 110 / 171 | Total Loss: 2.424259662628174 | KNN Loss: 2.3989036083221436 | CLS Loss: 0.025356171652674675\n",
      "Epoch 165 / 200 | iteration 120 / 171 | Total Loss: 2.403383493423462 | KNN Loss: 2.3956658840179443 | CLS Loss: 0.00771765410900116\n",
      "Epoch 165 / 200 | iteration 130 / 171 | Total Loss: 2.4087109565734863 | KNN Loss: 2.3927204608917236 | CLS Loss: 0.01599055901169777\n",
      "Epoch 165 / 200 | iteration 140 / 171 | Total Loss: 2.460177183151245 | KNN Loss: 2.4561667442321777 | CLS Loss: 0.004010329023003578\n",
      "Epoch 165 / 200 | iteration 150 / 171 | Total Loss: 2.4601035118103027 | KNN Loss: 2.444944381713867 | CLS Loss: 0.01515902578830719\n",
      "Epoch 165 / 200 | iteration 160 / 171 | Total Loss: 2.427769660949707 | KNN Loss: 2.4039065837860107 | CLS Loss: 0.023863093927502632\n",
      "Epoch 165 / 200 | iteration 170 / 171 | Total Loss: 2.3794150352478027 | KNN Loss: 2.375993490219116 | CLS Loss: 0.0034216439817100763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165, Loss: 2.4173, Train: 0.9952, Valid: 0.9872, Best: 0.9877\n",
      "Epoch 166 / 200 | iteration 0 / 171 | Total Loss: 2.384030342102051 | KNN Loss: 2.3750882148742676 | CLS Loss: 0.008942064829170704\n",
      "Epoch 166 / 200 | iteration 10 / 171 | Total Loss: 2.412233352661133 | KNN Loss: 2.3902266025543213 | CLS Loss: 0.02200683020055294\n",
      "Epoch 166 / 200 | iteration 20 / 171 | Total Loss: 2.402087688446045 | KNN Loss: 2.399810552597046 | CLS Loss: 0.0022772469092160463\n",
      "Epoch 166 / 200 | iteration 30 / 171 | Total Loss: 2.4090025424957275 | KNN Loss: 2.399564504623413 | CLS Loss: 0.009438032284379005\n",
      "Epoch 166 / 200 | iteration 40 / 171 | Total Loss: 2.397714614868164 | KNN Loss: 2.393087148666382 | CLS Loss: 0.004627539776265621\n",
      "Epoch 166 / 200 | iteration 50 / 171 | Total Loss: 2.3911352157592773 | KNN Loss: 2.376361846923828 | CLS Loss: 0.01477347407490015\n",
      "Epoch 166 / 200 | iteration 60 / 171 | Total Loss: 2.506476640701294 | KNN Loss: 2.477640390396118 | CLS Loss: 0.028836244717240334\n",
      "Epoch 166 / 200 | iteration 70 / 171 | Total Loss: 2.430229425430298 | KNN Loss: 2.4250195026397705 | CLS Loss: 0.005209833383560181\n",
      "Epoch 166 / 200 | iteration 80 / 171 | Total Loss: 2.4178318977355957 | KNN Loss: 2.4139039516448975 | CLS Loss: 0.003928047604858875\n",
      "Epoch 166 / 200 | iteration 90 / 171 | Total Loss: 2.394913911819458 | KNN Loss: 2.382493019104004 | CLS Loss: 0.01242098119109869\n",
      "Epoch 166 / 200 | iteration 100 / 171 | Total Loss: 2.4732131958007812 | KNN Loss: 2.4514214992523193 | CLS Loss: 0.0217917300760746\n",
      "Epoch 166 / 200 | iteration 110 / 171 | Total Loss: 2.4280765056610107 | KNN Loss: 2.4165091514587402 | CLS Loss: 0.011567372828722\n",
      "Epoch 166 / 200 | iteration 120 / 171 | Total Loss: 2.4425649642944336 | KNN Loss: 2.4352550506591797 | CLS Loss: 0.007309804204851389\n",
      "Epoch 166 / 200 | iteration 130 / 171 | Total Loss: 2.4099555015563965 | KNN Loss: 2.4006571769714355 | CLS Loss: 0.00929822027683258\n",
      "Epoch 166 / 200 | iteration 140 / 171 | Total Loss: 2.4563276767730713 | KNN Loss: 2.428065538406372 | CLS Loss: 0.028262194246053696\n",
      "Epoch 166 / 200 | iteration 150 / 171 | Total Loss: 2.419858932495117 | KNN Loss: 2.4172027111053467 | CLS Loss: 0.002656226046383381\n",
      "Epoch 166 / 200 | iteration 160 / 171 | Total Loss: 2.4104957580566406 | KNN Loss: 2.390015125274658 | CLS Loss: 0.020480571314692497\n",
      "Epoch 166 / 200 | iteration 170 / 171 | Total Loss: 2.3979835510253906 | KNN Loss: 2.386784791946411 | CLS Loss: 0.011198874562978745\n",
      "Epoch: 166, Loss: 2.4202, Train: 0.9960, Valid: 0.9865, Best: 0.9877\n",
      "Epoch 167 / 200 | iteration 0 / 171 | Total Loss: 2.4021077156066895 | KNN Loss: 2.3983073234558105 | CLS Loss: 0.003800462232902646\n",
      "Epoch 167 / 200 | iteration 10 / 171 | Total Loss: 2.454477548599243 | KNN Loss: 2.4394421577453613 | CLS Loss: 0.015035438351333141\n",
      "Epoch 167 / 200 | iteration 20 / 171 | Total Loss: 2.4731197357177734 | KNN Loss: 2.4455223083496094 | CLS Loss: 0.027597393840551376\n",
      "Epoch 167 / 200 | iteration 30 / 171 | Total Loss: 2.388169050216675 | KNN Loss: 2.3780715465545654 | CLS Loss: 0.01009748037904501\n",
      "Epoch 167 / 200 | iteration 40 / 171 | Total Loss: 2.424319267272949 | KNN Loss: 2.4175169467926025 | CLS Loss: 0.006802298594266176\n",
      "Epoch 167 / 200 | iteration 50 / 171 | Total Loss: 2.4008545875549316 | KNN Loss: 2.390613317489624 | CLS Loss: 0.010241187177598476\n",
      "Epoch 167 / 200 | iteration 60 / 171 | Total Loss: 2.3939931392669678 | KNN Loss: 2.3901431560516357 | CLS Loss: 0.0038498963695019484\n",
      "Epoch 167 / 200 | iteration 70 / 171 | Total Loss: 2.4209349155426025 | KNN Loss: 2.414945125579834 | CLS Loss: 0.00598983746021986\n",
      "Epoch 167 / 200 | iteration 80 / 171 | Total Loss: 2.4106364250183105 | KNN Loss: 2.403660297393799 | CLS Loss: 0.006976075004786253\n",
      "Epoch 167 / 200 | iteration 90 / 171 | Total Loss: 2.421802520751953 | KNN Loss: 2.402369260787964 | CLS Loss: 0.01943323202431202\n",
      "Epoch 167 / 200 | iteration 100 / 171 | Total Loss: 2.428506851196289 | KNN Loss: 2.426711320877075 | CLS Loss: 0.0017955631483346224\n",
      "Epoch 167 / 200 | iteration 110 / 171 | Total Loss: 2.383171558380127 | KNN Loss: 2.3697662353515625 | CLS Loss: 0.01340539287775755\n",
      "Epoch 167 / 200 | iteration 120 / 171 | Total Loss: 2.4079203605651855 | KNN Loss: 2.4056036472320557 | CLS Loss: 0.002316800644621253\n",
      "Epoch 167 / 200 | iteration 130 / 171 | Total Loss: 2.3973076343536377 | KNN Loss: 2.37272572517395 | CLS Loss: 0.02458181418478489\n",
      "Epoch 167 / 200 | iteration 140 / 171 | Total Loss: 2.4168858528137207 | KNN Loss: 2.413844585418701 | CLS Loss: 0.0030412296764552593\n",
      "Epoch 167 / 200 | iteration 150 / 171 | Total Loss: 2.3764524459838867 | KNN Loss: 2.3679282665252686 | CLS Loss: 0.008524108678102493\n",
      "Epoch 167 / 200 | iteration 160 / 171 | Total Loss: 2.416011333465576 | KNN Loss: 2.4122586250305176 | CLS Loss: 0.0037526844535022974\n",
      "Epoch 167 / 200 | iteration 170 / 171 | Total Loss: 2.4540016651153564 | KNN Loss: 2.4396119117736816 | CLS Loss: 0.014389636926352978\n",
      "Epoch: 167, Loss: 2.4157, Train: 0.9960, Valid: 0.9862, Best: 0.9877\n",
      "Epoch 168 / 200 | iteration 0 / 171 | Total Loss: 2.442521572113037 | KNN Loss: 2.4388325214385986 | CLS Loss: 0.003689045552164316\n",
      "Epoch 168 / 200 | iteration 10 / 171 | Total Loss: 2.37524151802063 | KNN Loss: 2.3671951293945312 | CLS Loss: 0.008046437986195087\n",
      "Epoch 168 / 200 | iteration 20 / 171 | Total Loss: 2.4149792194366455 | KNN Loss: 2.407858371734619 | CLS Loss: 0.0071209208108484745\n",
      "Epoch 168 / 200 | iteration 30 / 171 | Total Loss: 2.392106533050537 | KNN Loss: 2.3805465698242188 | CLS Loss: 0.011560000479221344\n",
      "Epoch 168 / 200 | iteration 40 / 171 | Total Loss: 2.4093844890594482 | KNN Loss: 2.3855528831481934 | CLS Loss: 0.023831622675061226\n",
      "Epoch 168 / 200 | iteration 50 / 171 | Total Loss: 2.415130615234375 | KNN Loss: 2.402853488922119 | CLS Loss: 0.01227701734751463\n",
      "Epoch 168 / 200 | iteration 60 / 171 | Total Loss: 2.444162130355835 | KNN Loss: 2.440617799758911 | CLS Loss: 0.0035443753004074097\n",
      "Epoch 168 / 200 | iteration 70 / 171 | Total Loss: 2.4596736431121826 | KNN Loss: 2.4431259632110596 | CLS Loss: 0.016547780483961105\n",
      "Epoch 168 / 200 | iteration 80 / 171 | Total Loss: 2.3968701362609863 | KNN Loss: 2.3900699615478516 | CLS Loss: 0.006800167262554169\n",
      "Epoch 168 / 200 | iteration 90 / 171 | Total Loss: 2.382981061935425 | KNN Loss: 2.3550198078155518 | CLS Loss: 0.02796132303774357\n",
      "Epoch 168 / 200 | iteration 100 / 171 | Total Loss: 2.4119417667388916 | KNN Loss: 2.3973255157470703 | CLS Loss: 0.014616149477660656\n",
      "Epoch 168 / 200 | iteration 110 / 171 | Total Loss: 2.3752124309539795 | KNN Loss: 2.3556621074676514 | CLS Loss: 0.019550248980522156\n",
      "Epoch 168 / 200 | iteration 120 / 171 | Total Loss: 2.4577207565307617 | KNN Loss: 2.426483154296875 | CLS Loss: 0.031237641349434853\n",
      "Epoch 168 / 200 | iteration 130 / 171 | Total Loss: 2.3775534629821777 | KNN Loss: 2.360726833343506 | CLS Loss: 0.016826527193188667\n",
      "Epoch 168 / 200 | iteration 140 / 171 | Total Loss: 2.398143768310547 | KNN Loss: 2.388261318206787 | CLS Loss: 0.0098823681473732\n",
      "Epoch 168 / 200 | iteration 150 / 171 | Total Loss: 2.4056572914123535 | KNN Loss: 2.390448570251465 | CLS Loss: 0.015208675526082516\n",
      "Epoch 168 / 200 | iteration 160 / 171 | Total Loss: 2.4268746376037598 | KNN Loss: 2.410614013671875 | CLS Loss: 0.016260581091046333\n",
      "Epoch 168 / 200 | iteration 170 / 171 | Total Loss: 2.38602876663208 | KNN Loss: 2.365939140319824 | CLS Loss: 0.020089630037546158\n",
      "Epoch: 168, Loss: 2.4162, Train: 0.9974, Valid: 0.9872, Best: 0.9877\n",
      "Epoch 169 / 200 | iteration 0 / 171 | Total Loss: 2.3897931575775146 | KNN Loss: 2.385256767272949 | CLS Loss: 0.0045365034602582455\n",
      "Epoch 169 / 200 | iteration 10 / 171 | Total Loss: 2.4303088188171387 | KNN Loss: 2.4240238666534424 | CLS Loss: 0.0062849260866642\n",
      "Epoch 169 / 200 | iteration 20 / 171 | Total Loss: 2.3600046634674072 | KNN Loss: 2.3516628742218018 | CLS Loss: 0.008341829292476177\n",
      "Epoch 169 / 200 | iteration 30 / 171 | Total Loss: 2.423753023147583 | KNN Loss: 2.415876865386963 | CLS Loss: 0.007876054383814335\n",
      "Epoch 169 / 200 | iteration 40 / 171 | Total Loss: 2.4397082328796387 | KNN Loss: 2.4375879764556885 | CLS Loss: 0.0021202964708209038\n",
      "Epoch 169 / 200 | iteration 50 / 171 | Total Loss: 2.41190767288208 | KNN Loss: 2.380338191986084 | CLS Loss: 0.0315694659948349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 / 200 | iteration 60 / 171 | Total Loss: 2.4103851318359375 | KNN Loss: 2.3778553009033203 | CLS Loss: 0.03252982348203659\n",
      "Epoch 169 / 200 | iteration 70 / 171 | Total Loss: 2.4260482788085938 | KNN Loss: 2.4181010723114014 | CLS Loss: 0.007947313599288464\n",
      "Epoch 169 / 200 | iteration 80 / 171 | Total Loss: 2.4116547107696533 | KNN Loss: 2.4069337844848633 | CLS Loss: 0.0047210450284183025\n",
      "Epoch 169 / 200 | iteration 90 / 171 | Total Loss: 2.4077038764953613 | KNN Loss: 2.402024030685425 | CLS Loss: 0.005679942201822996\n",
      "Epoch 169 / 200 | iteration 100 / 171 | Total Loss: 2.414956569671631 | KNN Loss: 2.4110352993011475 | CLS Loss: 0.003921192605048418\n",
      "Epoch 169 / 200 | iteration 110 / 171 | Total Loss: 2.3735311031341553 | KNN Loss: 2.3605504035949707 | CLS Loss: 0.012980758212506771\n",
      "Epoch 169 / 200 | iteration 120 / 171 | Total Loss: 2.442890167236328 | KNN Loss: 2.41556453704834 | CLS Loss: 0.027325674891471863\n",
      "Epoch 169 / 200 | iteration 130 / 171 | Total Loss: 2.4164586067199707 | KNN Loss: 2.4060018062591553 | CLS Loss: 0.010456813499331474\n",
      "Epoch 169 / 200 | iteration 140 / 171 | Total Loss: 2.463973045349121 | KNN Loss: 2.459181547164917 | CLS Loss: 0.0047915019094944\n",
      "Epoch 169 / 200 | iteration 150 / 171 | Total Loss: 2.4459400177001953 | KNN Loss: 2.4136440753936768 | CLS Loss: 0.03229605033993721\n",
      "Epoch 169 / 200 | iteration 160 / 171 | Total Loss: 2.439927577972412 | KNN Loss: 2.4338088035583496 | CLS Loss: 0.006118872668594122\n",
      "Epoch 169 / 200 | iteration 170 / 171 | Total Loss: 2.434030771255493 | KNN Loss: 2.4265758991241455 | CLS Loss: 0.007454756647348404\n",
      "Epoch: 169, Loss: 2.4182, Train: 0.9965, Valid: 0.9867, Best: 0.9877\n",
      "Epoch 170 / 200 | iteration 0 / 171 | Total Loss: 2.4291563034057617 | KNN Loss: 2.414647340774536 | CLS Loss: 0.014509040862321854\n",
      "Epoch 170 / 200 | iteration 10 / 171 | Total Loss: 2.451275110244751 | KNN Loss: 2.4449410438537598 | CLS Loss: 0.006334059871733189\n",
      "Epoch 170 / 200 | iteration 20 / 171 | Total Loss: 2.3890299797058105 | KNN Loss: 2.382911443710327 | CLS Loss: 0.006118470802903175\n",
      "Epoch 170 / 200 | iteration 30 / 171 | Total Loss: 2.387277126312256 | KNN Loss: 2.367305278778076 | CLS Loss: 0.019971938803792\n",
      "Epoch 170 / 200 | iteration 40 / 171 | Total Loss: 2.4063851833343506 | KNN Loss: 2.3897109031677246 | CLS Loss: 0.016674255952239037\n",
      "Epoch 170 / 200 | iteration 50 / 171 | Total Loss: 2.393763542175293 | KNN Loss: 2.3770768642425537 | CLS Loss: 0.016686711460351944\n",
      "Epoch 170 / 200 | iteration 60 / 171 | Total Loss: 2.3844149112701416 | KNN Loss: 2.3711397647857666 | CLS Loss: 0.013275130651891232\n",
      "Epoch 170 / 200 | iteration 70 / 171 | Total Loss: 2.416013717651367 | KNN Loss: 2.3992793560028076 | CLS Loss: 0.01673431321978569\n",
      "Epoch 170 / 200 | iteration 80 / 171 | Total Loss: 2.4143667221069336 | KNN Loss: 2.4050846099853516 | CLS Loss: 0.009282168000936508\n",
      "Epoch 170 / 200 | iteration 90 / 171 | Total Loss: 2.420886993408203 | KNN Loss: 2.4135775566101074 | CLS Loss: 0.007309347856789827\n",
      "Epoch 170 / 200 | iteration 100 / 171 | Total Loss: 2.4262187480926514 | KNN Loss: 2.412161111831665 | CLS Loss: 0.014057643711566925\n",
      "Epoch 170 / 200 | iteration 110 / 171 | Total Loss: 2.406315326690674 | KNN Loss: 2.3980250358581543 | CLS Loss: 0.008290278725326061\n",
      "Epoch 170 / 200 | iteration 120 / 171 | Total Loss: 2.385483741760254 | KNN Loss: 2.3757283687591553 | CLS Loss: 0.009755264036357403\n",
      "Epoch 170 / 200 | iteration 130 / 171 | Total Loss: 2.4186551570892334 | KNN Loss: 2.4047658443450928 | CLS Loss: 0.013889425434172153\n",
      "Epoch 170 / 200 | iteration 140 / 171 | Total Loss: 2.3968045711517334 | KNN Loss: 2.3876841068267822 | CLS Loss: 0.009120414964854717\n",
      "Epoch 170 / 200 | iteration 150 / 171 | Total Loss: 2.382216453552246 | KNN Loss: 2.3619678020477295 | CLS Loss: 0.020248545333743095\n",
      "Epoch 170 / 200 | iteration 160 / 171 | Total Loss: 2.396904468536377 | KNN Loss: 2.3911309242248535 | CLS Loss: 0.005773605313152075\n",
      "Epoch 170 / 200 | iteration 170 / 171 | Total Loss: 2.3929474353790283 | KNN Loss: 2.38559627532959 | CLS Loss: 0.007351268082857132\n",
      "Epoch: 170, Loss: 2.4168, Train: 0.9962, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 171 / 200 | iteration 0 / 171 | Total Loss: 2.4116148948669434 | KNN Loss: 2.3984715938568115 | CLS Loss: 0.013143183663487434\n",
      "Epoch 171 / 200 | iteration 10 / 171 | Total Loss: 2.4158525466918945 | KNN Loss: 2.4100847244262695 | CLS Loss: 0.0057679153978824615\n",
      "Epoch 171 / 200 | iteration 20 / 171 | Total Loss: 2.3998513221740723 | KNN Loss: 2.392000913619995 | CLS Loss: 0.007850369438529015\n",
      "Epoch 171 / 200 | iteration 30 / 171 | Total Loss: 2.4040775299072266 | KNN Loss: 2.3838183879852295 | CLS Loss: 0.020259052515029907\n",
      "Epoch 171 / 200 | iteration 40 / 171 | Total Loss: 2.408521890640259 | KNN Loss: 2.380361795425415 | CLS Loss: 0.028160154819488525\n",
      "Epoch 171 / 200 | iteration 50 / 171 | Total Loss: 2.4078245162963867 | KNN Loss: 2.4035658836364746 | CLS Loss: 0.00425869831815362\n",
      "Epoch 171 / 200 | iteration 60 / 171 | Total Loss: 2.460946798324585 | KNN Loss: 2.447822332382202 | CLS Loss: 0.013124436140060425\n",
      "Epoch 171 / 200 | iteration 70 / 171 | Total Loss: 2.438565731048584 | KNN Loss: 2.416931629180908 | CLS Loss: 0.021634088829159737\n",
      "Epoch 171 / 200 | iteration 80 / 171 | Total Loss: 2.3814704418182373 | KNN Loss: 2.36993408203125 | CLS Loss: 0.011536461301147938\n",
      "Epoch 171 / 200 | iteration 90 / 171 | Total Loss: 2.3853495121002197 | KNN Loss: 2.379206657409668 | CLS Loss: 0.006142968777567148\n",
      "Epoch 171 / 200 | iteration 100 / 171 | Total Loss: 2.416055917739868 | KNN Loss: 2.402707576751709 | CLS Loss: 0.013348248787224293\n",
      "Epoch 171 / 200 | iteration 110 / 171 | Total Loss: 2.4311420917510986 | KNN Loss: 2.4218807220458984 | CLS Loss: 0.009261371567845345\n",
      "Epoch 171 / 200 | iteration 120 / 171 | Total Loss: 2.415686845779419 | KNN Loss: 2.3920066356658936 | CLS Loss: 0.023680102080106735\n",
      "Epoch 171 / 200 | iteration 130 / 171 | Total Loss: 2.4712820053100586 | KNN Loss: 2.436462163925171 | CLS Loss: 0.03481991961598396\n",
      "Epoch 171 / 200 | iteration 140 / 171 | Total Loss: 2.4336631298065186 | KNN Loss: 2.4233975410461426 | CLS Loss: 0.010265486314892769\n",
      "Epoch 171 / 200 | iteration 150 / 171 | Total Loss: 2.4065680503845215 | KNN Loss: 2.398555278778076 | CLS Loss: 0.008012832142412663\n",
      "Epoch 171 / 200 | iteration 160 / 171 | Total Loss: 2.424755096435547 | KNN Loss: 2.410048246383667 | CLS Loss: 0.01470684353262186\n",
      "Epoch 171 / 200 | iteration 170 / 171 | Total Loss: 2.434654712677002 | KNN Loss: 2.4199397563934326 | CLS Loss: 0.014714986085891724\n",
      "Epoch: 171, Loss: 2.4180, Train: 0.9964, Valid: 0.9861, Best: 0.9877\n",
      "Epoch 172 / 200 | iteration 0 / 171 | Total Loss: 2.3867945671081543 | KNN Loss: 2.3767244815826416 | CLS Loss: 0.010070167481899261\n",
      "Epoch 172 / 200 | iteration 10 / 171 | Total Loss: 2.405454158782959 | KNN Loss: 2.398955821990967 | CLS Loss: 0.00649836054071784\n",
      "Epoch 172 / 200 | iteration 20 / 171 | Total Loss: 2.412515163421631 | KNN Loss: 2.4063730239868164 | CLS Loss: 0.0061421263962984085\n",
      "Epoch 172 / 200 | iteration 30 / 171 | Total Loss: 2.3895254135131836 | KNN Loss: 2.3856215476989746 | CLS Loss: 0.0039039470721036196\n",
      "Epoch 172 / 200 | iteration 40 / 171 | Total Loss: 2.4249486923217773 | KNN Loss: 2.4212121963500977 | CLS Loss: 0.003736397484317422\n",
      "Epoch 172 / 200 | iteration 50 / 171 | Total Loss: 2.3976693153381348 | KNN Loss: 2.382098913192749 | CLS Loss: 0.01557028666138649\n",
      "Epoch 172 / 200 | iteration 60 / 171 | Total Loss: 2.4149603843688965 | KNN Loss: 2.406346559524536 | CLS Loss: 0.008613893762230873\n",
      "Epoch 172 / 200 | iteration 70 / 171 | Total Loss: 2.3701066970825195 | KNN Loss: 2.3604283332824707 | CLS Loss: 0.009678392671048641\n",
      "Epoch 172 / 200 | iteration 80 / 171 | Total Loss: 2.418329954147339 | KNN Loss: 2.4129607677459717 | CLS Loss: 0.005369246006011963\n",
      "Epoch 172 / 200 | iteration 90 / 171 | Total Loss: 2.3718583583831787 | KNN Loss: 2.370304584503174 | CLS Loss: 0.0015538098523393273\n",
      "Epoch 172 / 200 | iteration 100 / 171 | Total Loss: 2.441798686981201 | KNN Loss: 2.425950050354004 | CLS Loss: 0.015848642215132713\n",
      "Epoch 172 / 200 | iteration 110 / 171 | Total Loss: 2.379800319671631 | KNN Loss: 2.371738910675049 | CLS Loss: 0.008061356842517853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 / 200 | iteration 120 / 171 | Total Loss: 2.4437978267669678 | KNN Loss: 2.432168483734131 | CLS Loss: 0.011629343964159489\n",
      "Epoch 172 / 200 | iteration 130 / 171 | Total Loss: 2.4632632732391357 | KNN Loss: 2.4509127140045166 | CLS Loss: 0.012350494042038918\n",
      "Epoch 172 / 200 | iteration 140 / 171 | Total Loss: 2.4422378540039062 | KNN Loss: 2.4264841079711914 | CLS Loss: 0.015753639861941338\n",
      "Epoch 172 / 200 | iteration 150 / 171 | Total Loss: 2.392085313796997 | KNN Loss: 2.367666482925415 | CLS Loss: 0.024418821558356285\n",
      "Epoch 172 / 200 | iteration 160 / 171 | Total Loss: 2.3966619968414307 | KNN Loss: 2.374375343322754 | CLS Loss: 0.022286580875515938\n",
      "Epoch 172 / 200 | iteration 170 / 171 | Total Loss: 2.4043161869049072 | KNN Loss: 2.399260997772217 | CLS Loss: 0.005055295769125223\n",
      "Epoch: 172, Loss: 2.4163, Train: 0.9966, Valid: 0.9866, Best: 0.9877\n",
      "Epoch 173 / 200 | iteration 0 / 171 | Total Loss: 2.4368276596069336 | KNN Loss: 2.4200804233551025 | CLS Loss: 0.016747314482927322\n",
      "Epoch 173 / 200 | iteration 10 / 171 | Total Loss: 2.386075496673584 | KNN Loss: 2.3837335109710693 | CLS Loss: 0.0023419256322085857\n",
      "Epoch 173 / 200 | iteration 20 / 171 | Total Loss: 2.439239740371704 | KNN Loss: 2.4205706119537354 | CLS Loss: 0.018669215962290764\n",
      "Epoch 173 / 200 | iteration 30 / 171 | Total Loss: 2.431279182434082 | KNN Loss: 2.420672655105591 | CLS Loss: 0.010606580413877964\n",
      "Epoch 173 / 200 | iteration 40 / 171 | Total Loss: 2.403021812438965 | KNN Loss: 2.3990437984466553 | CLS Loss: 0.003978081978857517\n",
      "Epoch 173 / 200 | iteration 50 / 171 | Total Loss: 2.4056389331817627 | KNN Loss: 2.3975141048431396 | CLS Loss: 0.008124754764139652\n",
      "Epoch 173 / 200 | iteration 60 / 171 | Total Loss: 2.430838108062744 | KNN Loss: 2.4231767654418945 | CLS Loss: 0.0076613700948655605\n",
      "Epoch 173 / 200 | iteration 70 / 171 | Total Loss: 2.394991159439087 | KNN Loss: 2.3868088722229004 | CLS Loss: 0.008182402700185776\n",
      "Epoch 173 / 200 | iteration 80 / 171 | Total Loss: 2.429516077041626 | KNN Loss: 2.4214887619018555 | CLS Loss: 0.008027341216802597\n",
      "Epoch 173 / 200 | iteration 90 / 171 | Total Loss: 2.44022274017334 | KNN Loss: 2.420747756958008 | CLS Loss: 0.019474953413009644\n",
      "Epoch 173 / 200 | iteration 100 / 171 | Total Loss: 2.4401915073394775 | KNN Loss: 2.411043882369995 | CLS Loss: 0.02914763055741787\n",
      "Epoch 173 / 200 | iteration 110 / 171 | Total Loss: 2.387420415878296 | KNN Loss: 2.3863718509674072 | CLS Loss: 0.0010486628161743283\n",
      "Epoch 173 / 200 | iteration 120 / 171 | Total Loss: 2.4617695808410645 | KNN Loss: 2.454634428024292 | CLS Loss: 0.007135190535336733\n",
      "Epoch 173 / 200 | iteration 130 / 171 | Total Loss: 2.456380605697632 | KNN Loss: 2.4492194652557373 | CLS Loss: 0.007161230780184269\n",
      "Epoch 173 / 200 | iteration 140 / 171 | Total Loss: 2.3847603797912598 | KNN Loss: 2.3798904418945312 | CLS Loss: 0.004869939759373665\n",
      "Epoch 173 / 200 | iteration 150 / 171 | Total Loss: 2.388537883758545 | KNN Loss: 2.376922607421875 | CLS Loss: 0.011615336872637272\n",
      "Epoch 173 / 200 | iteration 160 / 171 | Total Loss: 2.405837297439575 | KNN Loss: 2.39247465133667 | CLS Loss: 0.01336276438087225\n",
      "Epoch 173 / 200 | iteration 170 / 171 | Total Loss: 2.4029016494750977 | KNN Loss: 2.3994579315185547 | CLS Loss: 0.0034436522983014584\n",
      "Epoch: 173, Loss: 2.4190, Train: 0.9970, Valid: 0.9866, Best: 0.9877\n",
      "Epoch 174 / 200 | iteration 0 / 171 | Total Loss: 2.3864147663116455 | KNN Loss: 2.3846189975738525 | CLS Loss: 0.0017957090167328715\n",
      "Epoch 174 / 200 | iteration 10 / 171 | Total Loss: 2.424905300140381 | KNN Loss: 2.3932077884674072 | CLS Loss: 0.03169746696949005\n",
      "Epoch 174 / 200 | iteration 20 / 171 | Total Loss: 2.3939993381500244 | KNN Loss: 2.384087085723877 | CLS Loss: 0.009912309236824512\n",
      "Epoch 174 / 200 | iteration 30 / 171 | Total Loss: 2.4574246406555176 | KNN Loss: 2.453779935836792 | CLS Loss: 0.003644742304459214\n",
      "Epoch 174 / 200 | iteration 40 / 171 | Total Loss: 2.424478769302368 | KNN Loss: 2.417111396789551 | CLS Loss: 0.007367304060608149\n",
      "Epoch 174 / 200 | iteration 50 / 171 | Total Loss: 2.4280009269714355 | KNN Loss: 2.40431547164917 | CLS Loss: 0.023685527965426445\n",
      "Epoch 174 / 200 | iteration 60 / 171 | Total Loss: 2.4147567749023438 | KNN Loss: 2.399327039718628 | CLS Loss: 0.015429779887199402\n",
      "Epoch 174 / 200 | iteration 70 / 171 | Total Loss: 2.4163596630096436 | KNN Loss: 2.409031629562378 | CLS Loss: 0.007327964995056391\n",
      "Epoch 174 / 200 | iteration 80 / 171 | Total Loss: 2.3807380199432373 | KNN Loss: 2.366349458694458 | CLS Loss: 0.014388671144843102\n",
      "Epoch 174 / 200 | iteration 90 / 171 | Total Loss: 2.4248297214508057 | KNN Loss: 2.4226090908050537 | CLS Loss: 0.0022205584682524204\n",
      "Epoch 174 / 200 | iteration 100 / 171 | Total Loss: 2.405714750289917 | KNN Loss: 2.402798652648926 | CLS Loss: 0.002916159573942423\n",
      "Epoch 174 / 200 | iteration 110 / 171 | Total Loss: 2.3951051235198975 | KNN Loss: 2.387967824935913 | CLS Loss: 0.007137325592339039\n",
      "Epoch 174 / 200 | iteration 120 / 171 | Total Loss: 2.417572259902954 | KNN Loss: 2.405120372772217 | CLS Loss: 0.012451870366930962\n",
      "Epoch 174 / 200 | iteration 130 / 171 | Total Loss: 2.3932430744171143 | KNN Loss: 2.3765597343444824 | CLS Loss: 0.01668342389166355\n",
      "Epoch 174 / 200 | iteration 140 / 171 | Total Loss: 2.419982671737671 | KNN Loss: 2.390336275100708 | CLS Loss: 0.029646392911672592\n",
      "Epoch 174 / 200 | iteration 150 / 171 | Total Loss: 2.394087553024292 | KNN Loss: 2.3929526805877686 | CLS Loss: 0.0011348873376846313\n",
      "Epoch 174 / 200 | iteration 160 / 171 | Total Loss: 2.3949763774871826 | KNN Loss: 2.386284351348877 | CLS Loss: 0.008691996335983276\n",
      "Epoch 174 / 200 | iteration 170 / 171 | Total Loss: 2.4451894760131836 | KNN Loss: 2.424384832382202 | CLS Loss: 0.020804710686206818\n",
      "Epoch: 174, Loss: 2.4178, Train: 0.9949, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 175 / 200 | iteration 0 / 171 | Total Loss: 2.418231725692749 | KNN Loss: 2.402076482772827 | CLS Loss: 0.016155334189534187\n",
      "Epoch 175 / 200 | iteration 10 / 171 | Total Loss: 2.422186851501465 | KNN Loss: 2.3973798751831055 | CLS Loss: 0.024807080626487732\n",
      "Epoch 175 / 200 | iteration 20 / 171 | Total Loss: 2.44051456451416 | KNN Loss: 2.4215753078460693 | CLS Loss: 0.01893918216228485\n",
      "Epoch 175 / 200 | iteration 30 / 171 | Total Loss: 2.396773338317871 | KNN Loss: 2.39005184173584 | CLS Loss: 0.006721521727740765\n",
      "Epoch 175 / 200 | iteration 40 / 171 | Total Loss: 2.4223761558532715 | KNN Loss: 2.407562017440796 | CLS Loss: 0.014814070425927639\n",
      "Epoch 175 / 200 | iteration 50 / 171 | Total Loss: 2.4408326148986816 | KNN Loss: 2.435662269592285 | CLS Loss: 0.005170397460460663\n",
      "Epoch 175 / 200 | iteration 60 / 171 | Total Loss: 2.391700267791748 | KNN Loss: 2.3867626190185547 | CLS Loss: 0.004937556106597185\n",
      "Epoch 175 / 200 | iteration 70 / 171 | Total Loss: 2.414653778076172 | KNN Loss: 2.4088733196258545 | CLS Loss: 0.005780496168881655\n",
      "Epoch 175 / 200 | iteration 80 / 171 | Total Loss: 2.381356954574585 | KNN Loss: 2.3650949001312256 | CLS Loss: 0.016262007877230644\n",
      "Epoch 175 / 200 | iteration 90 / 171 | Total Loss: 2.3986737728118896 | KNN Loss: 2.39479660987854 | CLS Loss: 0.0038771876133978367\n",
      "Epoch 175 / 200 | iteration 100 / 171 | Total Loss: 2.429514169692993 | KNN Loss: 2.404015064239502 | CLS Loss: 0.02549910545349121\n",
      "Epoch 175 / 200 | iteration 110 / 171 | Total Loss: 2.3994288444519043 | KNN Loss: 2.3775739669799805 | CLS Loss: 0.021854937076568604\n",
      "Epoch 175 / 200 | iteration 120 / 171 | Total Loss: 2.4009621143341064 | KNN Loss: 2.3788578510284424 | CLS Loss: 0.022104356437921524\n",
      "Epoch 175 / 200 | iteration 130 / 171 | Total Loss: 2.4034883975982666 | KNN Loss: 2.384824752807617 | CLS Loss: 0.01866375282406807\n",
      "Epoch 175 / 200 | iteration 140 / 171 | Total Loss: 2.3967363834381104 | KNN Loss: 2.3876049518585205 | CLS Loss: 0.00913134217262268\n",
      "Epoch 175 / 200 | iteration 150 / 171 | Total Loss: 2.4746782779693604 | KNN Loss: 2.464470386505127 | CLS Loss: 0.01020786166191101\n",
      "Epoch 175 / 200 | iteration 160 / 171 | Total Loss: 2.415574789047241 | KNN Loss: 2.3957431316375732 | CLS Loss: 0.019831618294119835\n",
      "Epoch 175 / 200 | iteration 170 / 171 | Total Loss: 2.3698935508728027 | KNN Loss: 2.34694766998291 | CLS Loss: 0.022945770993828773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175, Loss: 2.4176, Train: 0.9962, Valid: 0.9868, Best: 0.9877\n",
      "Epoch 176 / 200 | iteration 0 / 171 | Total Loss: 2.3878118991851807 | KNN Loss: 2.385547161102295 | CLS Loss: 0.0022646316792815924\n",
      "Epoch 176 / 200 | iteration 10 / 171 | Total Loss: 2.389198064804077 | KNN Loss: 2.3673198223114014 | CLS Loss: 0.021878231316804886\n",
      "Epoch 176 / 200 | iteration 20 / 171 | Total Loss: 2.408796787261963 | KNN Loss: 2.3899219036102295 | CLS Loss: 0.01887483336031437\n",
      "Epoch 176 / 200 | iteration 30 / 171 | Total Loss: 2.4296250343322754 | KNN Loss: 2.417938709259033 | CLS Loss: 0.011686262674629688\n",
      "Epoch 176 / 200 | iteration 40 / 171 | Total Loss: 2.3954977989196777 | KNN Loss: 2.3905324935913086 | CLS Loss: 0.0049652280285954475\n",
      "Epoch 176 / 200 | iteration 50 / 171 | Total Loss: 2.396230697631836 | KNN Loss: 2.3734073638916016 | CLS Loss: 0.02282334864139557\n",
      "Epoch 176 / 200 | iteration 60 / 171 | Total Loss: 2.411369562149048 | KNN Loss: 2.401437520980835 | CLS Loss: 0.009932056069374084\n",
      "Epoch 176 / 200 | iteration 70 / 171 | Total Loss: 2.425590991973877 | KNN Loss: 2.419511318206787 | CLS Loss: 0.006079734768718481\n",
      "Epoch 176 / 200 | iteration 80 / 171 | Total Loss: 2.4383022785186768 | KNN Loss: 2.4294815063476562 | CLS Loss: 0.008820746093988419\n",
      "Epoch 176 / 200 | iteration 90 / 171 | Total Loss: 2.416588068008423 | KNN Loss: 2.4044642448425293 | CLS Loss: 0.012123898603022099\n",
      "Epoch 176 / 200 | iteration 100 / 171 | Total Loss: 2.410125255584717 | KNN Loss: 2.396411895751953 | CLS Loss: 0.013713446445763111\n",
      "Epoch 176 / 200 | iteration 110 / 171 | Total Loss: 2.415053606033325 | KNN Loss: 2.3803153038024902 | CLS Loss: 0.03473839908838272\n",
      "Epoch 176 / 200 | iteration 120 / 171 | Total Loss: 2.456761598587036 | KNN Loss: 2.4310126304626465 | CLS Loss: 0.025748876854777336\n",
      "Epoch 176 / 200 | iteration 130 / 171 | Total Loss: 2.4277451038360596 | KNN Loss: 2.4108433723449707 | CLS Loss: 0.016901841387152672\n",
      "Epoch 176 / 200 | iteration 140 / 171 | Total Loss: 2.468576192855835 | KNN Loss: 2.445119619369507 | CLS Loss: 0.02345646359026432\n",
      "Epoch 176 / 200 | iteration 150 / 171 | Total Loss: 2.429246425628662 | KNN Loss: 2.4115071296691895 | CLS Loss: 0.017739256843924522\n",
      "Epoch 176 / 200 | iteration 160 / 171 | Total Loss: 2.443148374557495 | KNN Loss: 2.427713394165039 | CLS Loss: 0.015434878878295422\n",
      "Epoch 176 / 200 | iteration 170 / 171 | Total Loss: 2.4140536785125732 | KNN Loss: 2.391190767288208 | CLS Loss: 0.02286289818584919\n",
      "Epoch: 176, Loss: 2.4159, Train: 0.9961, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 177 / 200 | iteration 0 / 171 | Total Loss: 2.3981149196624756 | KNN Loss: 2.386265277862549 | CLS Loss: 0.011849748902022839\n",
      "Epoch 177 / 200 | iteration 10 / 171 | Total Loss: 2.4132347106933594 | KNN Loss: 2.406792640686035 | CLS Loss: 0.0064419908449053764\n",
      "Epoch 177 / 200 | iteration 20 / 171 | Total Loss: 2.41868257522583 | KNN Loss: 2.403336763381958 | CLS Loss: 0.015345818363130093\n",
      "Epoch 177 / 200 | iteration 30 / 171 | Total Loss: 2.406038284301758 | KNN Loss: 2.3987185955047607 | CLS Loss: 0.00731965946033597\n",
      "Epoch 177 / 200 | iteration 40 / 171 | Total Loss: 2.397813081741333 | KNN Loss: 2.393961191177368 | CLS Loss: 0.003851926187053323\n",
      "Epoch 177 / 200 | iteration 50 / 171 | Total Loss: 2.370112419128418 | KNN Loss: 2.368152618408203 | CLS Loss: 0.0019597329664975405\n",
      "Epoch 177 / 200 | iteration 60 / 171 | Total Loss: 2.452208995819092 | KNN Loss: 2.4403512477874756 | CLS Loss: 0.011857690289616585\n",
      "Epoch 177 / 200 | iteration 70 / 171 | Total Loss: 2.4084877967834473 | KNN Loss: 2.396435260772705 | CLS Loss: 0.012052454985678196\n",
      "Epoch 177 / 200 | iteration 80 / 171 | Total Loss: 2.397428512573242 | KNN Loss: 2.3886642456054688 | CLS Loss: 0.008764385245740414\n",
      "Epoch 177 / 200 | iteration 90 / 171 | Total Loss: 2.43290376663208 | KNN Loss: 2.4219727516174316 | CLS Loss: 0.010930977761745453\n",
      "Epoch 177 / 200 | iteration 100 / 171 | Total Loss: 2.372727632522583 | KNN Loss: 2.3674654960632324 | CLS Loss: 0.005262142512947321\n",
      "Epoch 177 / 200 | iteration 110 / 171 | Total Loss: 2.4082324504852295 | KNN Loss: 2.3864693641662598 | CLS Loss: 0.02176300808787346\n",
      "Epoch 177 / 200 | iteration 120 / 171 | Total Loss: 2.42079496383667 | KNN Loss: 2.4031198024749756 | CLS Loss: 0.0176751296967268\n",
      "Epoch 177 / 200 | iteration 130 / 171 | Total Loss: 2.4512243270874023 | KNN Loss: 2.4405906200408936 | CLS Loss: 0.010633648373186588\n",
      "Epoch 177 / 200 | iteration 140 / 171 | Total Loss: 2.4227852821350098 | KNN Loss: 2.3993282318115234 | CLS Loss: 0.023457009345293045\n",
      "Epoch 177 / 200 | iteration 150 / 171 | Total Loss: 2.394512414932251 | KNN Loss: 2.3759353160858154 | CLS Loss: 0.018577048555016518\n",
      "Epoch 177 / 200 | iteration 160 / 171 | Total Loss: 2.4186742305755615 | KNN Loss: 2.388502836227417 | CLS Loss: 0.0301714688539505\n",
      "Epoch 177 / 200 | iteration 170 / 171 | Total Loss: 2.3831875324249268 | KNN Loss: 2.3731956481933594 | CLS Loss: 0.009991997852921486\n",
      "Epoch: 177, Loss: 2.4178, Train: 0.9946, Valid: 0.9860, Best: 0.9877\n",
      "Epoch 178 / 200 | iteration 0 / 171 | Total Loss: 2.400182008743286 | KNN Loss: 2.380293846130371 | CLS Loss: 0.019888078793883324\n",
      "Epoch 178 / 200 | iteration 10 / 171 | Total Loss: 2.4447200298309326 | KNN Loss: 2.4414584636688232 | CLS Loss: 0.003261486766859889\n",
      "Epoch 178 / 200 | iteration 20 / 171 | Total Loss: 2.4620163440704346 | KNN Loss: 2.439023494720459 | CLS Loss: 0.022992853075265884\n",
      "Epoch 178 / 200 | iteration 30 / 171 | Total Loss: 2.445765256881714 | KNN Loss: 2.433370590209961 | CLS Loss: 0.01239464245736599\n",
      "Epoch 178 / 200 | iteration 40 / 171 | Total Loss: 2.436518430709839 | KNN Loss: 2.428596019744873 | CLS Loss: 0.007922306656837463\n",
      "Epoch 178 / 200 | iteration 50 / 171 | Total Loss: 2.424452304840088 | KNN Loss: 2.420253276824951 | CLS Loss: 0.004199131857603788\n",
      "Epoch 178 / 200 | iteration 60 / 171 | Total Loss: 2.3985233306884766 | KNN Loss: 2.3834972381591797 | CLS Loss: 0.015026146546006203\n",
      "Epoch 178 / 200 | iteration 70 / 171 | Total Loss: 2.43239426612854 | KNN Loss: 2.416126012802124 | CLS Loss: 0.01626827009022236\n",
      "Epoch 178 / 200 | iteration 80 / 171 | Total Loss: 2.421332359313965 | KNN Loss: 2.4155266284942627 | CLS Loss: 0.005805758759379387\n",
      "Epoch 178 / 200 | iteration 90 / 171 | Total Loss: 2.422945737838745 | KNN Loss: 2.408094644546509 | CLS Loss: 0.01485111378133297\n",
      "Epoch 178 / 200 | iteration 100 / 171 | Total Loss: 2.3969991207122803 | KNN Loss: 2.3919434547424316 | CLS Loss: 0.005055633839219809\n",
      "Epoch 178 / 200 | iteration 110 / 171 | Total Loss: 2.4147047996520996 | KNN Loss: 2.3977408409118652 | CLS Loss: 0.016963863745331764\n",
      "Epoch 178 / 200 | iteration 120 / 171 | Total Loss: 2.4348363876342773 | KNN Loss: 2.406388759613037 | CLS Loss: 0.028447706252336502\n",
      "Epoch 178 / 200 | iteration 130 / 171 | Total Loss: 2.4277520179748535 | KNN Loss: 2.42094349861145 | CLS Loss: 0.006808405742049217\n",
      "Epoch 178 / 200 | iteration 140 / 171 | Total Loss: 2.43337082862854 | KNN Loss: 2.403899908065796 | CLS Loss: 0.0294710211455822\n",
      "Epoch 178 / 200 | iteration 150 / 171 | Total Loss: 2.379185438156128 | KNN Loss: 2.372978687286377 | CLS Loss: 0.006206856109201908\n",
      "Epoch 178 / 200 | iteration 160 / 171 | Total Loss: 2.430220127105713 | KNN Loss: 2.4262888431549072 | CLS Loss: 0.003931173589080572\n",
      "Epoch 178 / 200 | iteration 170 / 171 | Total Loss: 2.4166104793548584 | KNN Loss: 2.3915092945098877 | CLS Loss: 0.02510112337768078\n",
      "Epoch: 178, Loss: 2.4235, Train: 0.9960, Valid: 0.9861, Best: 0.9877\n",
      "Epoch 179 / 200 | iteration 0 / 171 | Total Loss: 2.399040937423706 | KNN Loss: 2.3925743103027344 | CLS Loss: 0.006466517224907875\n",
      "Epoch 179 / 200 | iteration 10 / 171 | Total Loss: 2.438286781311035 | KNN Loss: 2.4248430728912354 | CLS Loss: 0.013443661853671074\n",
      "Epoch 179 / 200 | iteration 20 / 171 | Total Loss: 2.4137778282165527 | KNN Loss: 2.405402183532715 | CLS Loss: 0.008375604636967182\n",
      "Epoch 179 / 200 | iteration 30 / 171 | Total Loss: 2.4055988788604736 | KNN Loss: 2.394007682800293 | CLS Loss: 0.011591168120503426\n",
      "Epoch 179 / 200 | iteration 40 / 171 | Total Loss: 2.4198062419891357 | KNN Loss: 2.410208225250244 | CLS Loss: 0.00959801860153675\n",
      "Epoch 179 / 200 | iteration 50 / 171 | Total Loss: 2.4068057537078857 | KNN Loss: 2.3864388465881348 | CLS Loss: 0.02036689594388008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 / 200 | iteration 60 / 171 | Total Loss: 2.429917812347412 | KNN Loss: 2.4188618659973145 | CLS Loss: 0.0110558420419693\n",
      "Epoch 179 / 200 | iteration 70 / 171 | Total Loss: 2.400336742401123 | KNN Loss: 2.3888142108917236 | CLS Loss: 0.011522614397108555\n",
      "Epoch 179 / 200 | iteration 80 / 171 | Total Loss: 2.4450461864471436 | KNN Loss: 2.439887762069702 | CLS Loss: 0.005158418323844671\n",
      "Epoch 179 / 200 | iteration 90 / 171 | Total Loss: 2.4267995357513428 | KNN Loss: 2.398348808288574 | CLS Loss: 0.028450623154640198\n",
      "Epoch 179 / 200 | iteration 100 / 171 | Total Loss: 2.433804750442505 | KNN Loss: 2.4274840354919434 | CLS Loss: 0.006320657674223185\n",
      "Epoch 179 / 200 | iteration 110 / 171 | Total Loss: 2.377309560775757 | KNN Loss: 2.3728644847869873 | CLS Loss: 0.004445097874850035\n",
      "Epoch 179 / 200 | iteration 120 / 171 | Total Loss: 2.389059066772461 | KNN Loss: 2.381943464279175 | CLS Loss: 0.007115675136446953\n",
      "Epoch 179 / 200 | iteration 130 / 171 | Total Loss: 2.4329144954681396 | KNN Loss: 2.431259870529175 | CLS Loss: 0.0016546157421544194\n",
      "Epoch 179 / 200 | iteration 140 / 171 | Total Loss: 2.390263080596924 | KNN Loss: 2.383014678955078 | CLS Loss: 0.007248427253216505\n",
      "Epoch 179 / 200 | iteration 150 / 171 | Total Loss: 2.4175546169281006 | KNN Loss: 2.396658420562744 | CLS Loss: 0.020896250382065773\n",
      "Epoch 179 / 200 | iteration 160 / 171 | Total Loss: 2.46384859085083 | KNN Loss: 2.446669340133667 | CLS Loss: 0.017179250717163086\n",
      "Epoch 179 / 200 | iteration 170 / 171 | Total Loss: 2.397279977798462 | KNN Loss: 2.39064621925354 | CLS Loss: 0.006633721757680178\n",
      "Epoch: 179, Loss: 2.4241, Train: 0.9969, Valid: 0.9870, Best: 0.9877\n",
      "Epoch 180 / 200 | iteration 0 / 171 | Total Loss: 2.403561592102051 | KNN Loss: 2.3908379077911377 | CLS Loss: 0.012723736464977264\n",
      "Epoch 180 / 200 | iteration 10 / 171 | Total Loss: 2.396306037902832 | KNN Loss: 2.386056661605835 | CLS Loss: 0.01024936605244875\n",
      "Epoch 180 / 200 | iteration 20 / 171 | Total Loss: 2.3846664428710938 | KNN Loss: 2.3822760581970215 | CLS Loss: 0.0023904158733785152\n",
      "Epoch 180 / 200 | iteration 30 / 171 | Total Loss: 2.3979928493499756 | KNN Loss: 2.388108968734741 | CLS Loss: 0.00988396443426609\n",
      "Epoch 180 / 200 | iteration 40 / 171 | Total Loss: 2.4344794750213623 | KNN Loss: 2.4319777488708496 | CLS Loss: 0.002501735230907798\n",
      "Epoch 180 / 200 | iteration 50 / 171 | Total Loss: 2.40193772315979 | KNN Loss: 2.385068893432617 | CLS Loss: 0.016868924722075462\n",
      "Epoch 180 / 200 | iteration 60 / 171 | Total Loss: 2.4876010417938232 | KNN Loss: 2.4759862422943115 | CLS Loss: 0.011614907532930374\n",
      "Epoch 180 / 200 | iteration 70 / 171 | Total Loss: 2.396690845489502 | KNN Loss: 2.384636402130127 | CLS Loss: 0.012054541148245335\n",
      "Epoch 180 / 200 | iteration 80 / 171 | Total Loss: 2.4922375679016113 | KNN Loss: 2.4801247119903564 | CLS Loss: 0.012112881988286972\n",
      "Epoch 180 / 200 | iteration 90 / 171 | Total Loss: 2.4035189151763916 | KNN Loss: 2.388554573059082 | CLS Loss: 0.014964419417083263\n",
      "Epoch 180 / 200 | iteration 100 / 171 | Total Loss: 2.4460062980651855 | KNN Loss: 2.438782215118408 | CLS Loss: 0.007223974447697401\n",
      "Epoch 180 / 200 | iteration 110 / 171 | Total Loss: 2.447514772415161 | KNN Loss: 2.4257826805114746 | CLS Loss: 0.02173217199742794\n",
      "Epoch 180 / 200 | iteration 120 / 171 | Total Loss: 2.408698081970215 | KNN Loss: 2.401370048522949 | CLS Loss: 0.007328060921281576\n",
      "Epoch 180 / 200 | iteration 130 / 171 | Total Loss: 2.4139413833618164 | KNN Loss: 2.4076523780822754 | CLS Loss: 0.006289078388363123\n",
      "Epoch 180 / 200 | iteration 140 / 171 | Total Loss: 2.386348009109497 | KNN Loss: 2.3748981952667236 | CLS Loss: 0.011449783109128475\n",
      "Epoch 180 / 200 | iteration 150 / 171 | Total Loss: 2.4489426612854004 | KNN Loss: 2.441499948501587 | CLS Loss: 0.007442729081958532\n",
      "Epoch 180 / 200 | iteration 160 / 171 | Total Loss: 2.4141957759857178 | KNN Loss: 2.4023044109344482 | CLS Loss: 0.011891474947333336\n",
      "Epoch 180 / 200 | iteration 170 / 171 | Total Loss: 2.4637794494628906 | KNN Loss: 2.424363374710083 | CLS Loss: 0.03941619396209717\n",
      "Epoch: 180, Loss: 2.4211, Train: 0.9942, Valid: 0.9832, Best: 0.9877\n",
      "Epoch 181 / 200 | iteration 0 / 171 | Total Loss: 2.408747434616089 | KNN Loss: 2.378497362136841 | CLS Loss: 0.030250078067183495\n",
      "Epoch 181 / 200 | iteration 10 / 171 | Total Loss: 2.4618849754333496 | KNN Loss: 2.435163974761963 | CLS Loss: 0.026721036061644554\n",
      "Epoch 181 / 200 | iteration 20 / 171 | Total Loss: 2.433602809906006 | KNN Loss: 2.431509256362915 | CLS Loss: 0.0020936245564371347\n",
      "Epoch 181 / 200 | iteration 30 / 171 | Total Loss: 2.3913676738739014 | KNN Loss: 2.380971908569336 | CLS Loss: 0.010395738296210766\n",
      "Epoch 181 / 200 | iteration 40 / 171 | Total Loss: 2.425384283065796 | KNN Loss: 2.399568557739258 | CLS Loss: 0.025815626606345177\n",
      "Epoch 181 / 200 | iteration 50 / 171 | Total Loss: 2.453299045562744 | KNN Loss: 2.428102493286133 | CLS Loss: 0.025196585804224014\n",
      "Epoch 181 / 200 | iteration 60 / 171 | Total Loss: 2.4428646564483643 | KNN Loss: 2.422708034515381 | CLS Loss: 0.02015666663646698\n",
      "Epoch 181 / 200 | iteration 70 / 171 | Total Loss: 2.409745693206787 | KNN Loss: 2.404108762741089 | CLS Loss: 0.00563697749748826\n",
      "Epoch 181 / 200 | iteration 80 / 171 | Total Loss: 2.4391603469848633 | KNN Loss: 2.426614761352539 | CLS Loss: 0.012545466423034668\n",
      "Epoch 181 / 200 | iteration 90 / 171 | Total Loss: 2.4170005321502686 | KNN Loss: 2.408562660217285 | CLS Loss: 0.008437938056886196\n",
      "Epoch 181 / 200 | iteration 100 / 171 | Total Loss: 2.4542055130004883 | KNN Loss: 2.441988229751587 | CLS Loss: 0.012217182666063309\n",
      "Epoch 181 / 200 | iteration 110 / 171 | Total Loss: 2.442927360534668 | KNN Loss: 2.412930488586426 | CLS Loss: 0.029996925964951515\n",
      "Epoch 181 / 200 | iteration 120 / 171 | Total Loss: 2.456162214279175 | KNN Loss: 2.4420392513275146 | CLS Loss: 0.014122920110821724\n",
      "Epoch 181 / 200 | iteration 130 / 171 | Total Loss: 2.452867031097412 | KNN Loss: 2.424617290496826 | CLS Loss: 0.028249653056263924\n",
      "Epoch 181 / 200 | iteration 140 / 171 | Total Loss: 2.4216549396514893 | KNN Loss: 2.391057252883911 | CLS Loss: 0.030597755685448647\n",
      "Epoch 181 / 200 | iteration 150 / 171 | Total Loss: 2.480128765106201 | KNN Loss: 2.4441964626312256 | CLS Loss: 0.03593228757381439\n",
      "Epoch 181 / 200 | iteration 160 / 171 | Total Loss: 2.4244651794433594 | KNN Loss: 2.411315679550171 | CLS Loss: 0.013149494305253029\n",
      "Epoch 181 / 200 | iteration 170 / 171 | Total Loss: 2.403240203857422 | KNN Loss: 2.3760526180267334 | CLS Loss: 0.027187634259462357\n",
      "Epoch: 181, Loss: 2.4257, Train: 0.9958, Valid: 0.9869, Best: 0.9877\n",
      "Epoch 182 / 200 | iteration 0 / 171 | Total Loss: 2.430288314819336 | KNN Loss: 2.427553653717041 | CLS Loss: 0.0027346403803676367\n",
      "Epoch 182 / 200 | iteration 10 / 171 | Total Loss: 2.4425203800201416 | KNN Loss: 2.426440477371216 | CLS Loss: 0.016079934313893318\n",
      "Epoch 182 / 200 | iteration 20 / 171 | Total Loss: 2.4394497871398926 | KNN Loss: 2.4263241291046143 | CLS Loss: 0.013125636614859104\n",
      "Epoch 182 / 200 | iteration 30 / 171 | Total Loss: 2.4207777976989746 | KNN Loss: 2.4105496406555176 | CLS Loss: 0.01022819709032774\n",
      "Epoch 182 / 200 | iteration 40 / 171 | Total Loss: 2.4390201568603516 | KNN Loss: 2.4191548824310303 | CLS Loss: 0.019865188747644424\n",
      "Epoch 182 / 200 | iteration 50 / 171 | Total Loss: 2.440755844116211 | KNN Loss: 2.424767017364502 | CLS Loss: 0.015988729894161224\n",
      "Epoch 182 / 200 | iteration 60 / 171 | Total Loss: 2.443946361541748 | KNN Loss: 2.43506121635437 | CLS Loss: 0.008885236456990242\n",
      "Epoch 182 / 200 | iteration 70 / 171 | Total Loss: 2.4064786434173584 | KNN Loss: 2.3992197513580322 | CLS Loss: 0.007258986588567495\n",
      "Epoch 182 / 200 | iteration 80 / 171 | Total Loss: 2.402925491333008 | KNN Loss: 2.4002716541290283 | CLS Loss: 0.0026539003010839224\n",
      "Epoch 182 / 200 | iteration 90 / 171 | Total Loss: 2.4251692295074463 | KNN Loss: 2.4132235050201416 | CLS Loss: 0.011945675127208233\n",
      "Epoch 182 / 200 | iteration 100 / 171 | Total Loss: 2.434347152709961 | KNN Loss: 2.418111801147461 | CLS Loss: 0.01623525656759739\n",
      "Epoch 182 / 200 | iteration 110 / 171 | Total Loss: 2.4307355880737305 | KNN Loss: 2.421591281890869 | CLS Loss: 0.009144255891442299\n",
      "Epoch 182 / 200 | iteration 120 / 171 | Total Loss: 2.474048376083374 | KNN Loss: 2.4579718112945557 | CLS Loss: 0.016076477244496346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 / 200 | iteration 130 / 171 | Total Loss: 2.4116954803466797 | KNN Loss: 2.389427900314331 | CLS Loss: 0.022267693653702736\n",
      "Epoch 182 / 200 | iteration 140 / 171 | Total Loss: 2.3778882026672363 | KNN Loss: 2.3729352951049805 | CLS Loss: 0.004952860996127129\n",
      "Epoch 182 / 200 | iteration 150 / 171 | Total Loss: 2.405331611633301 | KNN Loss: 2.4006457328796387 | CLS Loss: 0.00468584056943655\n",
      "Epoch 182 / 200 | iteration 160 / 171 | Total Loss: 2.41795015335083 | KNN Loss: 2.3957574367523193 | CLS Loss: 0.02219267003238201\n",
      "Epoch 182 / 200 | iteration 170 / 171 | Total Loss: 2.408967971801758 | KNN Loss: 2.3834261894226074 | CLS Loss: 0.025541871786117554\n",
      "Epoch: 182, Loss: 2.4184, Train: 0.9966, Valid: 0.9853, Best: 0.9877\n",
      "Epoch 183 / 200 | iteration 0 / 171 | Total Loss: 2.4108808040618896 | KNN Loss: 2.4074294567108154 | CLS Loss: 0.003451260272413492\n",
      "Epoch 183 / 200 | iteration 10 / 171 | Total Loss: 2.414402484893799 | KNN Loss: 2.406243324279785 | CLS Loss: 0.008159051649272442\n",
      "Epoch 183 / 200 | iteration 20 / 171 | Total Loss: 2.3846254348754883 | KNN Loss: 2.376086711883545 | CLS Loss: 0.008538833819329739\n",
      "Epoch 183 / 200 | iteration 30 / 171 | Total Loss: 2.416243076324463 | KNN Loss: 2.398916482925415 | CLS Loss: 0.0173265989869833\n",
      "Epoch 183 / 200 | iteration 40 / 171 | Total Loss: 2.448631525039673 | KNN Loss: 2.423833131790161 | CLS Loss: 0.024798495694994926\n",
      "Epoch 183 / 200 | iteration 50 / 171 | Total Loss: 2.414585828781128 | KNN Loss: 2.4097800254821777 | CLS Loss: 0.0048056915402412415\n",
      "Epoch 183 / 200 | iteration 60 / 171 | Total Loss: 2.4338719844818115 | KNN Loss: 2.4275918006896973 | CLS Loss: 0.006280244328081608\n",
      "Epoch 183 / 200 | iteration 70 / 171 | Total Loss: 2.392096519470215 | KNN Loss: 2.3879711627960205 | CLS Loss: 0.004125415347516537\n",
      "Epoch 183 / 200 | iteration 80 / 171 | Total Loss: 2.4420957565307617 | KNN Loss: 2.435441732406616 | CLS Loss: 0.006653912831097841\n",
      "Epoch 183 / 200 | iteration 90 / 171 | Total Loss: 2.455260753631592 | KNN Loss: 2.4468131065368652 | CLS Loss: 0.008447748608887196\n",
      "Epoch 183 / 200 | iteration 100 / 171 | Total Loss: 2.441086769104004 | KNN Loss: 2.4303250312805176 | CLS Loss: 0.010761757381260395\n",
      "Epoch 183 / 200 | iteration 110 / 171 | Total Loss: 2.407726526260376 | KNN Loss: 2.4057514667510986 | CLS Loss: 0.0019750373903661966\n",
      "Epoch 183 / 200 | iteration 120 / 171 | Total Loss: 2.392019271850586 | KNN Loss: 2.3729965686798096 | CLS Loss: 0.019022788852453232\n",
      "Epoch 183 / 200 | iteration 130 / 171 | Total Loss: 2.4156274795532227 | KNN Loss: 2.39931583404541 | CLS Loss: 0.016311580315232277\n",
      "Epoch 183 / 200 | iteration 140 / 171 | Total Loss: 2.3873493671417236 | KNN Loss: 2.3754520416259766 | CLS Loss: 0.01189742423593998\n",
      "Epoch 183 / 200 | iteration 150 / 171 | Total Loss: 2.3741884231567383 | KNN Loss: 2.3612804412841797 | CLS Loss: 0.01290789246559143\n",
      "Epoch 183 / 200 | iteration 160 / 171 | Total Loss: 2.4421586990356445 | KNN Loss: 2.424107789993286 | CLS Loss: 0.018050864338874817\n",
      "Epoch 183 / 200 | iteration 170 / 171 | Total Loss: 2.383545398712158 | KNN Loss: 2.3591160774230957 | CLS Loss: 0.024429289624094963\n",
      "Epoch: 183, Loss: 2.4137, Train: 0.9975, Valid: 0.9862, Best: 0.9877\n",
      "Epoch 184 / 200 | iteration 0 / 171 | Total Loss: 2.4155540466308594 | KNN Loss: 2.4045116901397705 | CLS Loss: 0.011042417027056217\n",
      "Epoch 184 / 200 | iteration 10 / 171 | Total Loss: 2.422630548477173 | KNN Loss: 2.415212869644165 | CLS Loss: 0.007417621556669474\n",
      "Epoch 184 / 200 | iteration 20 / 171 | Total Loss: 2.4556124210357666 | KNN Loss: 2.440117835998535 | CLS Loss: 0.01549453940242529\n",
      "Epoch 184 / 200 | iteration 30 / 171 | Total Loss: 2.4259495735168457 | KNN Loss: 2.413717031478882 | CLS Loss: 0.012232531793415546\n",
      "Epoch 184 / 200 | iteration 40 / 171 | Total Loss: 2.46071720123291 | KNN Loss: 2.4582996368408203 | CLS Loss: 0.0024176116567105055\n",
      "Epoch 184 / 200 | iteration 50 / 171 | Total Loss: 2.435041904449463 | KNN Loss: 2.4295806884765625 | CLS Loss: 0.005461250431835651\n",
      "Epoch 184 / 200 | iteration 60 / 171 | Total Loss: 2.4288289546966553 | KNN Loss: 2.4088921546936035 | CLS Loss: 0.019936786964535713\n",
      "Epoch 184 / 200 | iteration 70 / 171 | Total Loss: 2.45816707611084 | KNN Loss: 2.4518234729766846 | CLS Loss: 0.006343708839267492\n",
      "Epoch 184 / 200 | iteration 80 / 171 | Total Loss: 2.450334310531616 | KNN Loss: 2.446976661682129 | CLS Loss: 0.0033576111309230328\n",
      "Epoch 184 / 200 | iteration 90 / 171 | Total Loss: 2.430459499359131 | KNN Loss: 2.409590482711792 | CLS Loss: 0.020869050174951553\n",
      "Epoch 184 / 200 | iteration 100 / 171 | Total Loss: 2.3973934650421143 | KNN Loss: 2.377148151397705 | CLS Loss: 0.02024541236460209\n",
      "Epoch 184 / 200 | iteration 110 / 171 | Total Loss: 2.454594612121582 | KNN Loss: 2.4492087364196777 | CLS Loss: 0.005385911092162132\n",
      "Epoch 184 / 200 | iteration 120 / 171 | Total Loss: 2.4051506519317627 | KNN Loss: 2.3752245903015137 | CLS Loss: 0.029926016926765442\n",
      "Epoch 184 / 200 | iteration 130 / 171 | Total Loss: 2.3956196308135986 | KNN Loss: 2.382591724395752 | CLS Loss: 0.013027934357523918\n",
      "Epoch 184 / 200 | iteration 140 / 171 | Total Loss: 2.375885009765625 | KNN Loss: 2.3541948795318604 | CLS Loss: 0.021690087392926216\n",
      "Epoch 184 / 200 | iteration 150 / 171 | Total Loss: 2.4395997524261475 | KNN Loss: 2.417952060699463 | CLS Loss: 0.021647579967975616\n",
      "Epoch 184 / 200 | iteration 160 / 171 | Total Loss: 2.4262611865997314 | KNN Loss: 2.414304256439209 | CLS Loss: 0.011956813745200634\n",
      "Epoch 184 / 200 | iteration 170 / 171 | Total Loss: 2.4040873050689697 | KNN Loss: 2.398930072784424 | CLS Loss: 0.005157328676432371\n",
      "Epoch: 184, Loss: 2.4203, Train: 0.9973, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 185 / 200 | iteration 0 / 171 | Total Loss: 2.389270544052124 | KNN Loss: 2.3763720989227295 | CLS Loss: 0.012898443266749382\n",
      "Epoch 185 / 200 | iteration 10 / 171 | Total Loss: 2.3933496475219727 | KNN Loss: 2.388345241546631 | CLS Loss: 0.005004468373954296\n",
      "Epoch 185 / 200 | iteration 20 / 171 | Total Loss: 2.3751094341278076 | KNN Loss: 2.362757921218872 | CLS Loss: 0.012351473793387413\n",
      "Epoch 185 / 200 | iteration 30 / 171 | Total Loss: 2.432781219482422 | KNN Loss: 2.413769006729126 | CLS Loss: 0.019012123346328735\n",
      "Epoch 185 / 200 | iteration 40 / 171 | Total Loss: 2.3871259689331055 | KNN Loss: 2.379030704498291 | CLS Loss: 0.00809532217681408\n",
      "Epoch 185 / 200 | iteration 50 / 171 | Total Loss: 2.4248833656311035 | KNN Loss: 2.4156792163848877 | CLS Loss: 0.009204250760376453\n",
      "Epoch 185 / 200 | iteration 60 / 171 | Total Loss: 2.3749332427978516 | KNN Loss: 2.37249493598938 | CLS Loss: 0.0024383822456002235\n",
      "Epoch 185 / 200 | iteration 70 / 171 | Total Loss: 2.414720058441162 | KNN Loss: 2.4088103771209717 | CLS Loss: 0.0059096841141581535\n",
      "Epoch 185 / 200 | iteration 80 / 171 | Total Loss: 2.4112653732299805 | KNN Loss: 2.406369209289551 | CLS Loss: 0.004896095488220453\n",
      "Epoch 185 / 200 | iteration 90 / 171 | Total Loss: 2.3898298740386963 | KNN Loss: 2.3825080394744873 | CLS Loss: 0.007321721874177456\n",
      "Epoch 185 / 200 | iteration 100 / 171 | Total Loss: 2.410334587097168 | KNN Loss: 2.3996574878692627 | CLS Loss: 0.010677196085453033\n",
      "Epoch 185 / 200 | iteration 110 / 171 | Total Loss: 2.438446044921875 | KNN Loss: 2.4262444972991943 | CLS Loss: 0.012201651930809021\n",
      "Epoch 185 / 200 | iteration 120 / 171 | Total Loss: 2.423696517944336 | KNN Loss: 2.417881488800049 | CLS Loss: 0.005815071985125542\n",
      "Epoch 185 / 200 | iteration 130 / 171 | Total Loss: 2.42281174659729 | KNN Loss: 2.408669948577881 | CLS Loss: 0.014141829684376717\n",
      "Epoch 185 / 200 | iteration 140 / 171 | Total Loss: 2.38101863861084 | KNN Loss: 2.3745479583740234 | CLS Loss: 0.006470625288784504\n",
      "Epoch 185 / 200 | iteration 150 / 171 | Total Loss: 2.4381752014160156 | KNN Loss: 2.4268181324005127 | CLS Loss: 0.01135716401040554\n",
      "Epoch 185 / 200 | iteration 160 / 171 | Total Loss: 2.428529977798462 | KNN Loss: 2.4070935249328613 | CLS Loss: 0.021436501294374466\n",
      "Epoch 185 / 200 | iteration 170 / 171 | Total Loss: 2.4207913875579834 | KNN Loss: 2.3891818523406982 | CLS Loss: 0.031609419733285904\n",
      "Epoch: 185, Loss: 2.4113, Train: 0.9969, Valid: 0.9869, Best: 0.9877\n",
      "Epoch 186 / 200 | iteration 0 / 171 | Total Loss: 2.399135112762451 | KNN Loss: 2.392652988433838 | CLS Loss: 0.0064821671694517136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186 / 200 | iteration 10 / 171 | Total Loss: 2.423741102218628 | KNN Loss: 2.4106104373931885 | CLS Loss: 0.01313056517392397\n",
      "Epoch 186 / 200 | iteration 20 / 171 | Total Loss: 2.4519309997558594 | KNN Loss: 2.440330982208252 | CLS Loss: 0.011600104160606861\n",
      "Epoch 186 / 200 | iteration 30 / 171 | Total Loss: 2.422361373901367 | KNN Loss: 2.4131765365600586 | CLS Loss: 0.009184829890727997\n",
      "Epoch 186 / 200 | iteration 40 / 171 | Total Loss: 2.4058241844177246 | KNN Loss: 2.3885395526885986 | CLS Loss: 0.017284715548157692\n",
      "Epoch 186 / 200 | iteration 50 / 171 | Total Loss: 2.423069953918457 | KNN Loss: 2.4066174030303955 | CLS Loss: 0.016452541574835777\n",
      "Epoch 186 / 200 | iteration 60 / 171 | Total Loss: 2.419846534729004 | KNN Loss: 2.39336895942688 | CLS Loss: 0.02647750824689865\n",
      "Epoch 186 / 200 | iteration 70 / 171 | Total Loss: 2.4381065368652344 | KNN Loss: 2.4240856170654297 | CLS Loss: 0.014020973816514015\n",
      "Epoch 186 / 200 | iteration 80 / 171 | Total Loss: 2.3900530338287354 | KNN Loss: 2.3859291076660156 | CLS Loss: 0.004123878665268421\n",
      "Epoch 186 / 200 | iteration 90 / 171 | Total Loss: 2.459850788116455 | KNN Loss: 2.4320738315582275 | CLS Loss: 0.02777685411274433\n",
      "Epoch 186 / 200 | iteration 100 / 171 | Total Loss: 2.410142660140991 | KNN Loss: 2.378081798553467 | CLS Loss: 0.03206096589565277\n",
      "Epoch 186 / 200 | iteration 110 / 171 | Total Loss: 2.4248440265655518 | KNN Loss: 2.408935070037842 | CLS Loss: 0.01590885780751705\n",
      "Epoch 186 / 200 | iteration 120 / 171 | Total Loss: 2.406802177429199 | KNN Loss: 2.388765573501587 | CLS Loss: 0.018036527559161186\n",
      "Epoch 186 / 200 | iteration 130 / 171 | Total Loss: 2.440960645675659 | KNN Loss: 2.421299934387207 | CLS Loss: 0.019660761579871178\n",
      "Epoch 186 / 200 | iteration 140 / 171 | Total Loss: 2.4060733318328857 | KNN Loss: 2.390634059906006 | CLS Loss: 0.015439368784427643\n",
      "Epoch 186 / 200 | iteration 150 / 171 | Total Loss: 2.4262144565582275 | KNN Loss: 2.422884941101074 | CLS Loss: 0.0033294910099357367\n",
      "Epoch 186 / 200 | iteration 160 / 171 | Total Loss: 2.395003080368042 | KNN Loss: 2.381582498550415 | CLS Loss: 0.013420624658465385\n",
      "Epoch 186 / 200 | iteration 170 / 171 | Total Loss: 2.396909475326538 | KNN Loss: 2.3695552349090576 | CLS Loss: 0.027354339137673378\n",
      "Epoch: 186, Loss: 2.4182, Train: 0.9956, Valid: 0.9857, Best: 0.9877\n",
      "Epoch 187 / 200 | iteration 0 / 171 | Total Loss: 2.3877668380737305 | KNN Loss: 2.370257616043091 | CLS Loss: 0.017509285360574722\n",
      "Epoch 187 / 200 | iteration 10 / 171 | Total Loss: 2.4197566509246826 | KNN Loss: 2.3915202617645264 | CLS Loss: 0.02823643945157528\n",
      "Epoch 187 / 200 | iteration 20 / 171 | Total Loss: 2.371692180633545 | KNN Loss: 2.35614275932312 | CLS Loss: 0.015549526549875736\n",
      "Epoch 187 / 200 | iteration 30 / 171 | Total Loss: 2.448941230773926 | KNN Loss: 2.4364778995513916 | CLS Loss: 0.01246334332972765\n",
      "Epoch 187 / 200 | iteration 40 / 171 | Total Loss: 2.457975387573242 | KNN Loss: 2.440706253051758 | CLS Loss: 0.01726904883980751\n",
      "Epoch 187 / 200 | iteration 50 / 171 | Total Loss: 2.4062514305114746 | KNN Loss: 2.401707887649536 | CLS Loss: 0.004543655086308718\n",
      "Epoch 187 / 200 | iteration 60 / 171 | Total Loss: 2.41055965423584 | KNN Loss: 2.4002315998077393 | CLS Loss: 0.010328060947358608\n",
      "Epoch 187 / 200 | iteration 70 / 171 | Total Loss: 2.450439691543579 | KNN Loss: 2.4404730796813965 | CLS Loss: 0.009966579265892506\n",
      "Epoch 187 / 200 | iteration 80 / 171 | Total Loss: 2.414139986038208 | KNN Loss: 2.4122745990753174 | CLS Loss: 0.0018654981395229697\n",
      "Epoch 187 / 200 | iteration 90 / 171 | Total Loss: 2.3804197311401367 | KNN Loss: 2.374849319458008 | CLS Loss: 0.005570471752434969\n",
      "Epoch 187 / 200 | iteration 100 / 171 | Total Loss: 2.406764507293701 | KNN Loss: 2.397770881652832 | CLS Loss: 0.0089937224984169\n",
      "Epoch 187 / 200 | iteration 110 / 171 | Total Loss: 2.4104862213134766 | KNN Loss: 2.4017722606658936 | CLS Loss: 0.008713861927390099\n",
      "Epoch 187 / 200 | iteration 120 / 171 | Total Loss: 2.4227304458618164 | KNN Loss: 2.4091951847076416 | CLS Loss: 0.013535154983401299\n",
      "Epoch 187 / 200 | iteration 130 / 171 | Total Loss: 2.4831714630126953 | KNN Loss: 2.468907117843628 | CLS Loss: 0.014264257624745369\n",
      "Epoch 187 / 200 | iteration 140 / 171 | Total Loss: 2.438444137573242 | KNN Loss: 2.4246017932891846 | CLS Loss: 0.01384238712489605\n",
      "Epoch 187 / 200 | iteration 150 / 171 | Total Loss: 2.418567657470703 | KNN Loss: 2.410560369491577 | CLS Loss: 0.008007307536900043\n",
      "Epoch 187 / 200 | iteration 160 / 171 | Total Loss: 2.4157233238220215 | KNN Loss: 2.3927924633026123 | CLS Loss: 0.022930866107344627\n",
      "Epoch 187 / 200 | iteration 170 / 171 | Total Loss: 2.3822460174560547 | KNN Loss: 2.377117156982422 | CLS Loss: 0.005128844175487757\n",
      "Epoch: 187, Loss: 2.4151, Train: 0.9965, Valid: 0.9868, Best: 0.9877\n",
      "Epoch 188 / 200 | iteration 0 / 171 | Total Loss: 2.403780937194824 | KNN Loss: 2.382969617843628 | CLS Loss: 0.02081143483519554\n",
      "Epoch 188 / 200 | iteration 10 / 171 | Total Loss: 2.446537494659424 | KNN Loss: 2.4316763877868652 | CLS Loss: 0.014861210249364376\n",
      "Epoch 188 / 200 | iteration 20 / 171 | Total Loss: 2.434858798980713 | KNN Loss: 2.4230384826660156 | CLS Loss: 0.011820286512374878\n",
      "Epoch 188 / 200 | iteration 30 / 171 | Total Loss: 2.4528515338897705 | KNN Loss: 2.4428839683532715 | CLS Loss: 0.009967480786144733\n",
      "Epoch 188 / 200 | iteration 40 / 171 | Total Loss: 2.4002468585968018 | KNN Loss: 2.3961381912231445 | CLS Loss: 0.004108561668545008\n",
      "Epoch 188 / 200 | iteration 50 / 171 | Total Loss: 2.4076497554779053 | KNN Loss: 2.401392936706543 | CLS Loss: 0.006256898865103722\n",
      "Epoch 188 / 200 | iteration 60 / 171 | Total Loss: 2.472714424133301 | KNN Loss: 2.454720973968506 | CLS Loss: 0.017993388697504997\n",
      "Epoch 188 / 200 | iteration 70 / 171 | Total Loss: 2.4349632263183594 | KNN Loss: 2.405182123184204 | CLS Loss: 0.029781095683574677\n",
      "Epoch 188 / 200 | iteration 80 / 171 | Total Loss: 2.4030470848083496 | KNN Loss: 2.399570941925049 | CLS Loss: 0.0034760464914143085\n",
      "Epoch 188 / 200 | iteration 90 / 171 | Total Loss: 2.423572540283203 | KNN Loss: 2.413804769515991 | CLS Loss: 0.009767863899469376\n",
      "Epoch 188 / 200 | iteration 100 / 171 | Total Loss: 2.4513533115386963 | KNN Loss: 2.4283804893493652 | CLS Loss: 0.022972915321588516\n",
      "Epoch 188 / 200 | iteration 110 / 171 | Total Loss: 2.440669059753418 | KNN Loss: 2.439854621887207 | CLS Loss: 0.000814510858617723\n",
      "Epoch 188 / 200 | iteration 120 / 171 | Total Loss: 2.4222140312194824 | KNN Loss: 2.4125685691833496 | CLS Loss: 0.009645531885325909\n",
      "Epoch 188 / 200 | iteration 130 / 171 | Total Loss: 2.4489779472351074 | KNN Loss: 2.4314939975738525 | CLS Loss: 0.017483962699770927\n",
      "Epoch 188 / 200 | iteration 140 / 171 | Total Loss: 2.423672914505005 | KNN Loss: 2.3946163654327393 | CLS Loss: 0.029056604951620102\n",
      "Epoch 188 / 200 | iteration 150 / 171 | Total Loss: 2.4280741214752197 | KNN Loss: 2.4071288108825684 | CLS Loss: 0.020945308730006218\n",
      "Epoch 188 / 200 | iteration 160 / 171 | Total Loss: 2.4382338523864746 | KNN Loss: 2.4134552478790283 | CLS Loss: 0.02477863058447838\n",
      "Epoch 188 / 200 | iteration 170 / 171 | Total Loss: 2.4283945560455322 | KNN Loss: 2.4108834266662598 | CLS Loss: 0.01751110702753067\n",
      "Epoch: 188, Loss: 2.4214, Train: 0.9967, Valid: 0.9867, Best: 0.9877\n",
      "Epoch 189 / 200 | iteration 0 / 171 | Total Loss: 2.4041683673858643 | KNN Loss: 2.3937323093414307 | CLS Loss: 0.010435965843498707\n",
      "Epoch 189 / 200 | iteration 10 / 171 | Total Loss: 2.4144773483276367 | KNN Loss: 2.4071974754333496 | CLS Loss: 0.007279831916093826\n",
      "Epoch 189 / 200 | iteration 20 / 171 | Total Loss: 2.4216256141662598 | KNN Loss: 2.4129793643951416 | CLS Loss: 0.008646286092698574\n",
      "Epoch 189 / 200 | iteration 30 / 171 | Total Loss: 2.433816909790039 | KNN Loss: 2.3998305797576904 | CLS Loss: 0.033986277878284454\n",
      "Epoch 189 / 200 | iteration 40 / 171 | Total Loss: 2.4414429664611816 | KNN Loss: 2.4182510375976562 | CLS Loss: 0.02319202572107315\n",
      "Epoch 189 / 200 | iteration 50 / 171 | Total Loss: 2.4562041759490967 | KNN Loss: 2.445462942123413 | CLS Loss: 0.010741184465587139\n",
      "Epoch 189 / 200 | iteration 60 / 171 | Total Loss: 2.3934097290039062 | KNN Loss: 2.3867976665496826 | CLS Loss: 0.0066119530238211155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 / 200 | iteration 70 / 171 | Total Loss: 2.4003379344940186 | KNN Loss: 2.3877363204956055 | CLS Loss: 0.012601522728800774\n",
      "Epoch 189 / 200 | iteration 80 / 171 | Total Loss: 2.4133224487304688 | KNN Loss: 2.3927459716796875 | CLS Loss: 0.020576534792780876\n",
      "Epoch 189 / 200 | iteration 90 / 171 | Total Loss: 2.3987808227539062 | KNN Loss: 2.3797974586486816 | CLS Loss: 0.01898333989083767\n",
      "Epoch 189 / 200 | iteration 100 / 171 | Total Loss: 2.445039987564087 | KNN Loss: 2.4145350456237793 | CLS Loss: 0.03050500713288784\n",
      "Epoch 189 / 200 | iteration 110 / 171 | Total Loss: 2.433316230773926 | KNN Loss: 2.419560670852661 | CLS Loss: 0.013755575753748417\n",
      "Epoch 189 / 200 | iteration 120 / 171 | Total Loss: 2.501502275466919 | KNN Loss: 2.4793009757995605 | CLS Loss: 0.02220122143626213\n",
      "Epoch 189 / 200 | iteration 130 / 171 | Total Loss: 2.442021608352661 | KNN Loss: 2.430443525314331 | CLS Loss: 0.011578013189136982\n",
      "Epoch 189 / 200 | iteration 140 / 171 | Total Loss: 2.4157562255859375 | KNN Loss: 2.392899751663208 | CLS Loss: 0.022856401279568672\n",
      "Epoch 189 / 200 | iteration 150 / 171 | Total Loss: 2.3975439071655273 | KNN Loss: 2.3930559158325195 | CLS Loss: 0.004488086793571711\n",
      "Epoch 189 / 200 | iteration 160 / 171 | Total Loss: 2.407175302505493 | KNN Loss: 2.3882646560668945 | CLS Loss: 0.018910575658082962\n",
      "Epoch 189 / 200 | iteration 170 / 171 | Total Loss: 2.4210169315338135 | KNN Loss: 2.4076240062713623 | CLS Loss: 0.013392866589128971\n",
      "Epoch: 189, Loss: 2.4178, Train: 0.9965, Valid: 0.9869, Best: 0.9877\n",
      "Epoch 190 / 200 | iteration 0 / 171 | Total Loss: 2.3979172706604004 | KNN Loss: 2.387011766433716 | CLS Loss: 0.010905423201620579\n",
      "Epoch 190 / 200 | iteration 10 / 171 | Total Loss: 2.377469539642334 | KNN Loss: 2.3737287521362305 | CLS Loss: 0.0037408361677080393\n",
      "Epoch 190 / 200 | iteration 20 / 171 | Total Loss: 2.4615252017974854 | KNN Loss: 2.4541196823120117 | CLS Loss: 0.007405428681522608\n",
      "Epoch 190 / 200 | iteration 30 / 171 | Total Loss: 2.4285542964935303 | KNN Loss: 2.4191009998321533 | CLS Loss: 0.00945320911705494\n",
      "Epoch 190 / 200 | iteration 40 / 171 | Total Loss: 2.3936526775360107 | KNN Loss: 2.3901660442352295 | CLS Loss: 0.0034866926725953817\n",
      "Epoch 190 / 200 | iteration 50 / 171 | Total Loss: 2.4118757247924805 | KNN Loss: 2.406329393386841 | CLS Loss: 0.00554634677246213\n",
      "Epoch 190 / 200 | iteration 60 / 171 | Total Loss: 2.4287357330322266 | KNN Loss: 2.4223697185516357 | CLS Loss: 0.006365939509123564\n",
      "Epoch 190 / 200 | iteration 70 / 171 | Total Loss: 2.407785654067993 | KNN Loss: 2.3775856494903564 | CLS Loss: 0.030199943110346794\n",
      "Epoch 190 / 200 | iteration 80 / 171 | Total Loss: 2.4255588054656982 | KNN Loss: 2.399768829345703 | CLS Loss: 0.02579009160399437\n",
      "Epoch 190 / 200 | iteration 90 / 171 | Total Loss: 2.3766961097717285 | KNN Loss: 2.365523099899292 | CLS Loss: 0.011173100210726261\n",
      "Epoch 190 / 200 | iteration 100 / 171 | Total Loss: 2.4142022132873535 | KNN Loss: 2.3952651023864746 | CLS Loss: 0.018937090411782265\n",
      "Epoch 190 / 200 | iteration 110 / 171 | Total Loss: 2.4075376987457275 | KNN Loss: 2.4067981243133545 | CLS Loss: 0.0007395113934762776\n",
      "Epoch 190 / 200 | iteration 120 / 171 | Total Loss: 2.4036340713500977 | KNN Loss: 2.398451089859009 | CLS Loss: 0.005182925146073103\n",
      "Epoch 190 / 200 | iteration 130 / 171 | Total Loss: 2.3393194675445557 | KNN Loss: 2.3350651264190674 | CLS Loss: 0.004254388157278299\n",
      "Epoch 190 / 200 | iteration 140 / 171 | Total Loss: 2.392509698867798 | KNN Loss: 2.3914709091186523 | CLS Loss: 0.0010387868387624621\n",
      "Epoch 190 / 200 | iteration 150 / 171 | Total Loss: 2.399080753326416 | KNN Loss: 2.39328932762146 | CLS Loss: 0.0057913875207304955\n",
      "Epoch 190 / 200 | iteration 160 / 171 | Total Loss: 2.506230592727661 | KNN Loss: 2.4748830795288086 | CLS Loss: 0.03134753927588463\n",
      "Epoch 190 / 200 | iteration 170 / 171 | Total Loss: 2.388855218887329 | KNN Loss: 2.385986804962158 | CLS Loss: 0.0028683424461632967\n",
      "Epoch: 190, Loss: 2.4134, Train: 0.9970, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 191 / 200 | iteration 0 / 171 | Total Loss: 2.42777681350708 | KNN Loss: 2.4251861572265625 | CLS Loss: 0.002590563613921404\n",
      "Epoch 191 / 200 | iteration 10 / 171 | Total Loss: 2.4355053901672363 | KNN Loss: 2.4137399196624756 | CLS Loss: 0.02176557667553425\n",
      "Epoch 191 / 200 | iteration 20 / 171 | Total Loss: 2.39634370803833 | KNN Loss: 2.3869924545288086 | CLS Loss: 0.009351334534585476\n",
      "Epoch 191 / 200 | iteration 30 / 171 | Total Loss: 2.4186787605285645 | KNN Loss: 2.4130027294158936 | CLS Loss: 0.0056760977022349834\n",
      "Epoch 191 / 200 | iteration 40 / 171 | Total Loss: 2.469451427459717 | KNN Loss: 2.461787700653076 | CLS Loss: 0.0076637109741568565\n",
      "Epoch 191 / 200 | iteration 50 / 171 | Total Loss: 2.3742637634277344 | KNN Loss: 2.3588969707489014 | CLS Loss: 0.01536688394844532\n",
      "Epoch 191 / 200 | iteration 60 / 171 | Total Loss: 2.405235767364502 | KNN Loss: 2.3935952186584473 | CLS Loss: 0.01164055336266756\n",
      "Epoch 191 / 200 | iteration 70 / 171 | Total Loss: 2.4026455879211426 | KNN Loss: 2.393105983734131 | CLS Loss: 0.009539546445012093\n",
      "Epoch 191 / 200 | iteration 80 / 171 | Total Loss: 2.428330659866333 | KNN Loss: 2.414431571960449 | CLS Loss: 0.013899060897529125\n",
      "Epoch 191 / 200 | iteration 90 / 171 | Total Loss: 2.4455838203430176 | KNN Loss: 2.4232711791992188 | CLS Loss: 0.02231263741850853\n",
      "Epoch 191 / 200 | iteration 100 / 171 | Total Loss: 2.414844036102295 | KNN Loss: 2.3944008350372314 | CLS Loss: 0.020443294197320938\n",
      "Epoch 191 / 200 | iteration 110 / 171 | Total Loss: 2.4082460403442383 | KNN Loss: 2.4026060104370117 | CLS Loss: 0.0056399134919047356\n",
      "Epoch 191 / 200 | iteration 120 / 171 | Total Loss: 2.4594454765319824 | KNN Loss: 2.448397159576416 | CLS Loss: 0.011048410087823868\n",
      "Epoch 191 / 200 | iteration 130 / 171 | Total Loss: 2.4524524211883545 | KNN Loss: 2.447624921798706 | CLS Loss: 0.004827598575502634\n",
      "Epoch 191 / 200 | iteration 140 / 171 | Total Loss: 2.4435884952545166 | KNN Loss: 2.4296014308929443 | CLS Loss: 0.013987087644636631\n",
      "Epoch 191 / 200 | iteration 150 / 171 | Total Loss: 2.4048993587493896 | KNN Loss: 2.38867449760437 | CLS Loss: 0.01622486673295498\n",
      "Epoch 191 / 200 | iteration 160 / 171 | Total Loss: 2.40364933013916 | KNN Loss: 2.387613296508789 | CLS Loss: 0.01603601686656475\n",
      "Epoch 191 / 200 | iteration 170 / 171 | Total Loss: 2.422374725341797 | KNN Loss: 2.411867141723633 | CLS Loss: 0.010507465340197086\n",
      "Epoch: 191, Loss: 2.4191, Train: 0.9954, Valid: 0.9872, Best: 0.9877\n",
      "Epoch 192 / 200 | iteration 0 / 171 | Total Loss: 2.428368330001831 | KNN Loss: 2.4151854515075684 | CLS Loss: 0.013182842172682285\n",
      "Epoch 192 / 200 | iteration 10 / 171 | Total Loss: 2.4489834308624268 | KNN Loss: 2.4462170600891113 | CLS Loss: 0.0027663393411785364\n",
      "Epoch 192 / 200 | iteration 20 / 171 | Total Loss: 2.4123451709747314 | KNN Loss: 2.4022409915924072 | CLS Loss: 0.010104107670485973\n",
      "Epoch 192 / 200 | iteration 30 / 171 | Total Loss: 2.4156696796417236 | KNN Loss: 2.4104080200195312 | CLS Loss: 0.0052617271430790424\n",
      "Epoch 192 / 200 | iteration 40 / 171 | Total Loss: 2.409899950027466 | KNN Loss: 2.4051249027252197 | CLS Loss: 0.004775110632181168\n",
      "Epoch 192 / 200 | iteration 50 / 171 | Total Loss: 2.436814785003662 | KNN Loss: 2.42911958694458 | CLS Loss: 0.007695249281823635\n",
      "Epoch 192 / 200 | iteration 60 / 171 | Total Loss: 2.436147689819336 | KNN Loss: 2.416109800338745 | CLS Loss: 0.020037831738591194\n",
      "Epoch 192 / 200 | iteration 70 / 171 | Total Loss: 2.4429426193237305 | KNN Loss: 2.4229483604431152 | CLS Loss: 0.019994376227259636\n",
      "Epoch 192 / 200 | iteration 80 / 171 | Total Loss: 2.4099576473236084 | KNN Loss: 2.398880958557129 | CLS Loss: 0.011076699011027813\n",
      "Epoch 192 / 200 | iteration 90 / 171 | Total Loss: 2.4127981662750244 | KNN Loss: 2.4004933834075928 | CLS Loss: 0.012304846197366714\n",
      "Epoch 192 / 200 | iteration 100 / 171 | Total Loss: 2.380441904067993 | KNN Loss: 2.3649473190307617 | CLS Loss: 0.01549452543258667\n",
      "Epoch 192 / 200 | iteration 110 / 171 | Total Loss: 2.4217042922973633 | KNN Loss: 2.3918190002441406 | CLS Loss: 0.029885243624448776\n",
      "Epoch 192 / 200 | iteration 120 / 171 | Total Loss: 2.471482992172241 | KNN Loss: 2.448399782180786 | CLS Loss: 0.023083101958036423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 / 200 | iteration 130 / 171 | Total Loss: 2.4154891967773438 | KNN Loss: 2.40907883644104 | CLS Loss: 0.0064102946780622005\n",
      "Epoch 192 / 200 | iteration 140 / 171 | Total Loss: 2.41257643699646 | KNN Loss: 2.407850503921509 | CLS Loss: 0.004725826904177666\n",
      "Epoch 192 / 200 | iteration 150 / 171 | Total Loss: 2.377790689468384 | KNN Loss: 2.354823589324951 | CLS Loss: 0.02296704612672329\n",
      "Epoch 192 / 200 | iteration 160 / 171 | Total Loss: 2.392366647720337 | KNN Loss: 2.384329080581665 | CLS Loss: 0.008037499152123928\n",
      "Epoch 192 / 200 | iteration 170 / 171 | Total Loss: 2.438843250274658 | KNN Loss: 2.4248478412628174 | CLS Loss: 0.01399534847587347\n",
      "Epoch: 192, Loss: 2.4226, Train: 0.9970, Valid: 0.9871, Best: 0.9877\n",
      "Epoch 193 / 200 | iteration 0 / 171 | Total Loss: 2.4052398204803467 | KNN Loss: 2.3996529579162598 | CLS Loss: 0.005586802028119564\n",
      "Epoch 193 / 200 | iteration 10 / 171 | Total Loss: 2.400081157684326 | KNN Loss: 2.3848702907562256 | CLS Loss: 0.015210882760584354\n",
      "Epoch 193 / 200 | iteration 20 / 171 | Total Loss: 2.4111316204071045 | KNN Loss: 2.404465436935425 | CLS Loss: 0.00666611734777689\n",
      "Epoch 193 / 200 | iteration 30 / 171 | Total Loss: 2.4296178817749023 | KNN Loss: 2.385745048522949 | CLS Loss: 0.04387276619672775\n",
      "Epoch 193 / 200 | iteration 40 / 171 | Total Loss: 2.4643075466156006 | KNN Loss: 2.4360404014587402 | CLS Loss: 0.02826705574989319\n",
      "Epoch 193 / 200 | iteration 50 / 171 | Total Loss: 2.4318785667419434 | KNN Loss: 2.426034688949585 | CLS Loss: 0.005843938793987036\n",
      "Epoch 193 / 200 | iteration 60 / 171 | Total Loss: 2.3931920528411865 | KNN Loss: 2.3858208656311035 | CLS Loss: 0.007371249608695507\n",
      "Epoch 193 / 200 | iteration 70 / 171 | Total Loss: 2.420933723449707 | KNN Loss: 2.3976495265960693 | CLS Loss: 0.02328408509492874\n",
      "Epoch 193 / 200 | iteration 80 / 171 | Total Loss: 2.447230100631714 | KNN Loss: 2.43733286857605 | CLS Loss: 0.009897208772599697\n",
      "Epoch 193 / 200 | iteration 90 / 171 | Total Loss: 2.3976523876190186 | KNN Loss: 2.388824224472046 | CLS Loss: 0.00882810726761818\n",
      "Epoch 193 / 200 | iteration 100 / 171 | Total Loss: 2.3695240020751953 | KNN Loss: 2.3678104877471924 | CLS Loss: 0.0017134726513177156\n",
      "Epoch 193 / 200 | iteration 110 / 171 | Total Loss: 2.414457321166992 | KNN Loss: 2.4063642024993896 | CLS Loss: 0.008093020878732204\n",
      "Epoch 193 / 200 | iteration 120 / 171 | Total Loss: 2.4099514484405518 | KNN Loss: 2.405482769012451 | CLS Loss: 0.004468702245503664\n",
      "Epoch 193 / 200 | iteration 130 / 171 | Total Loss: 2.410417079925537 | KNN Loss: 2.4044764041900635 | CLS Loss: 0.005940676666796207\n",
      "Epoch 193 / 200 | iteration 140 / 171 | Total Loss: 2.378802537918091 | KNN Loss: 2.365464687347412 | CLS Loss: 0.013337918557226658\n",
      "Epoch 193 / 200 | iteration 150 / 171 | Total Loss: 2.4039082527160645 | KNN Loss: 2.3948347568511963 | CLS Loss: 0.009073590859770775\n",
      "Epoch 193 / 200 | iteration 160 / 171 | Total Loss: 2.3891921043395996 | KNN Loss: 2.3844406604766846 | CLS Loss: 0.004751547239720821\n",
      "Epoch 193 / 200 | iteration 170 / 171 | Total Loss: 2.430304527282715 | KNN Loss: 2.4110159873962402 | CLS Loss: 0.01928865723311901\n",
      "Epoch: 193, Loss: 2.4222, Train: 0.9951, Valid: 0.9852, Best: 0.9877\n",
      "Epoch 194 / 200 | iteration 0 / 171 | Total Loss: 2.435669183731079 | KNN Loss: 2.4269189834594727 | CLS Loss: 0.008750270120799541\n",
      "Epoch 194 / 200 | iteration 10 / 171 | Total Loss: 2.3998613357543945 | KNN Loss: 2.3804659843444824 | CLS Loss: 0.019395291805267334\n",
      "Epoch 194 / 200 | iteration 20 / 171 | Total Loss: 2.3648576736450195 | KNN Loss: 2.3569562435150146 | CLS Loss: 0.007901319302618504\n",
      "Epoch 194 / 200 | iteration 30 / 171 | Total Loss: 2.422518491744995 | KNN Loss: 2.3978190422058105 | CLS Loss: 0.02469935081899166\n",
      "Epoch 194 / 200 | iteration 40 / 171 | Total Loss: 2.4255597591400146 | KNN Loss: 2.4034016132354736 | CLS Loss: 0.022158082574605942\n",
      "Epoch 194 / 200 | iteration 50 / 171 | Total Loss: 2.383424758911133 | KNN Loss: 2.375004768371582 | CLS Loss: 0.008419928140938282\n",
      "Epoch 194 / 200 | iteration 60 / 171 | Total Loss: 2.3998754024505615 | KNN Loss: 2.3874034881591797 | CLS Loss: 0.012472023256123066\n",
      "Epoch 194 / 200 | iteration 70 / 171 | Total Loss: 2.4256811141967773 | KNN Loss: 2.4209604263305664 | CLS Loss: 0.004720666911453009\n",
      "Epoch 194 / 200 | iteration 80 / 171 | Total Loss: 2.4303317070007324 | KNN Loss: 2.3961236476898193 | CLS Loss: 0.034208010882139206\n",
      "Epoch 194 / 200 | iteration 90 / 171 | Total Loss: 2.46882700920105 | KNN Loss: 2.451711416244507 | CLS Loss: 0.017115594819188118\n",
      "Epoch 194 / 200 | iteration 100 / 171 | Total Loss: 2.465564250946045 | KNN Loss: 2.4604105949401855 | CLS Loss: 0.005153566598892212\n",
      "Epoch 194 / 200 | iteration 110 / 171 | Total Loss: 2.4006705284118652 | KNN Loss: 2.388485908508301 | CLS Loss: 0.01218472234904766\n",
      "Epoch 194 / 200 | iteration 120 / 171 | Total Loss: 2.3652355670928955 | KNN Loss: 2.362305164337158 | CLS Loss: 0.002930333837866783\n",
      "Epoch 194 / 200 | iteration 130 / 171 | Total Loss: 2.4209601879119873 | KNN Loss: 2.4171571731567383 | CLS Loss: 0.003803097642958164\n",
      "Epoch 194 / 200 | iteration 140 / 171 | Total Loss: 2.4137566089630127 | KNN Loss: 2.3995110988616943 | CLS Loss: 0.014245457015931606\n",
      "Epoch 194 / 200 | iteration 150 / 171 | Total Loss: 2.4410083293914795 | KNN Loss: 2.4254114627838135 | CLS Loss: 0.015596919693052769\n",
      "Epoch 194 / 200 | iteration 160 / 171 | Total Loss: 2.416663885116577 | KNN Loss: 2.4112343788146973 | CLS Loss: 0.005429534707218409\n",
      "Epoch 194 / 200 | iteration 170 / 171 | Total Loss: 2.41772198677063 | KNN Loss: 2.3765406608581543 | CLS Loss: 0.041181255131959915\n",
      "Epoch: 194, Loss: 2.4145, Train: 0.9967, Valid: 0.9863, Best: 0.9877\n",
      "Epoch 195 / 200 | iteration 0 / 171 | Total Loss: 2.420670747756958 | KNN Loss: 2.408273935317993 | CLS Loss: 0.012396769598126411\n",
      "Epoch 195 / 200 | iteration 10 / 171 | Total Loss: 2.442457675933838 | KNN Loss: 2.4304144382476807 | CLS Loss: 0.012043296359479427\n",
      "Epoch 195 / 200 | iteration 20 / 171 | Total Loss: 2.382833957672119 | KNN Loss: 2.374854326248169 | CLS Loss: 0.007979689165949821\n",
      "Epoch 195 / 200 | iteration 30 / 171 | Total Loss: 2.3873493671417236 | KNN Loss: 2.3856258392333984 | CLS Loss: 0.0017236105632036924\n",
      "Epoch 195 / 200 | iteration 40 / 171 | Total Loss: 2.428014039993286 | KNN Loss: 2.4247121810913086 | CLS Loss: 0.003301935037598014\n",
      "Epoch 195 / 200 | iteration 50 / 171 | Total Loss: 2.408973217010498 | KNN Loss: 2.3860621452331543 | CLS Loss: 0.02291117236018181\n",
      "Epoch 195 / 200 | iteration 60 / 171 | Total Loss: 2.418449878692627 | KNN Loss: 2.405543327331543 | CLS Loss: 0.012906570918858051\n",
      "Epoch 195 / 200 | iteration 70 / 171 | Total Loss: 2.424685478210449 | KNN Loss: 2.4128568172454834 | CLS Loss: 0.011828642338514328\n",
      "Epoch 195 / 200 | iteration 80 / 171 | Total Loss: 2.4664759635925293 | KNN Loss: 2.433899402618408 | CLS Loss: 0.03257645294070244\n",
      "Epoch 195 / 200 | iteration 90 / 171 | Total Loss: 2.4432692527770996 | KNN Loss: 2.4190924167633057 | CLS Loss: 0.0241768229752779\n",
      "Epoch 195 / 200 | iteration 100 / 171 | Total Loss: 2.4244329929351807 | KNN Loss: 2.405015230178833 | CLS Loss: 0.019417699426412582\n",
      "Epoch 195 / 200 | iteration 110 / 171 | Total Loss: 2.423212766647339 | KNN Loss: 2.401674747467041 | CLS Loss: 0.021538009867072105\n",
      "Epoch 195 / 200 | iteration 120 / 171 | Total Loss: 2.4138717651367188 | KNN Loss: 2.4036476612091064 | CLS Loss: 0.010224019177258015\n",
      "Epoch 195 / 200 | iteration 130 / 171 | Total Loss: 2.4243788719177246 | KNN Loss: 2.4128971099853516 | CLS Loss: 0.011481751687824726\n",
      "Epoch 195 / 200 | iteration 140 / 171 | Total Loss: 2.4175848960876465 | KNN Loss: 2.40458607673645 | CLS Loss: 0.012998891994357109\n",
      "Epoch 195 / 200 | iteration 150 / 171 | Total Loss: 2.4555845260620117 | KNN Loss: 2.4533064365386963 | CLS Loss: 0.0022780299186706543\n",
      "Epoch 195 / 200 | iteration 160 / 171 | Total Loss: 2.3968327045440674 | KNN Loss: 2.391775131225586 | CLS Loss: 0.005057656206190586\n",
      "Epoch 195 / 200 | iteration 170 / 171 | Total Loss: 2.4130117893218994 | KNN Loss: 2.4086358547210693 | CLS Loss: 0.004375827964395285\n",
      "Epoch: 195, Loss: 2.4133, Train: 0.9973, Valid: 0.9870, Best: 0.9877\n",
      "Epoch 196 / 200 | iteration 0 / 171 | Total Loss: 2.452728271484375 | KNN Loss: 2.449944019317627 | CLS Loss: 0.0027842670679092407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196 / 200 | iteration 10 / 171 | Total Loss: 2.3891751766204834 | KNN Loss: 2.378584623336792 | CLS Loss: 0.010590544901788235\n",
      "Epoch 196 / 200 | iteration 20 / 171 | Total Loss: 2.4515790939331055 | KNN Loss: 2.446146011352539 | CLS Loss: 0.005433198995888233\n",
      "Epoch 196 / 200 | iteration 30 / 171 | Total Loss: 2.3746628761291504 | KNN Loss: 2.368917942047119 | CLS Loss: 0.005744998808950186\n",
      "Epoch 196 / 200 | iteration 40 / 171 | Total Loss: 2.405022621154785 | KNN Loss: 2.3930423259735107 | CLS Loss: 0.011980370618402958\n",
      "Epoch 196 / 200 | iteration 50 / 171 | Total Loss: 2.385594129562378 | KNN Loss: 2.36598801612854 | CLS Loss: 0.01960601843893528\n",
      "Epoch 196 / 200 | iteration 60 / 171 | Total Loss: 2.4038076400756836 | KNN Loss: 2.398301362991333 | CLS Loss: 0.005506326910108328\n",
      "Epoch 196 / 200 | iteration 70 / 171 | Total Loss: 2.469566822052002 | KNN Loss: 2.4619991779327393 | CLS Loss: 0.00756765715777874\n",
      "Epoch 196 / 200 | iteration 80 / 171 | Total Loss: 2.375807523727417 | KNN Loss: 2.3699071407318115 | CLS Loss: 0.0059003885835409164\n",
      "Epoch 196 / 200 | iteration 90 / 171 | Total Loss: 2.414120674133301 | KNN Loss: 2.4114370346069336 | CLS Loss: 0.002683723345398903\n",
      "Epoch 196 / 200 | iteration 100 / 171 | Total Loss: 2.398583173751831 | KNN Loss: 2.3860363960266113 | CLS Loss: 0.012546693906188011\n",
      "Epoch 196 / 200 | iteration 110 / 171 | Total Loss: 2.3835198879241943 | KNN Loss: 2.367032289505005 | CLS Loss: 0.016487659886479378\n",
      "Epoch 196 / 200 | iteration 120 / 171 | Total Loss: 2.4147729873657227 | KNN Loss: 2.398380994796753 | CLS Loss: 0.016392076388001442\n",
      "Epoch 196 / 200 | iteration 130 / 171 | Total Loss: 2.432436466217041 | KNN Loss: 2.4300222396850586 | CLS Loss: 0.0024142854381352663\n",
      "Epoch 196 / 200 | iteration 140 / 171 | Total Loss: 2.414562463760376 | KNN Loss: 2.397034168243408 | CLS Loss: 0.017528370022773743\n",
      "Epoch 196 / 200 | iteration 150 / 171 | Total Loss: 2.4184794425964355 | KNN Loss: 2.3963394165039062 | CLS Loss: 0.022139977663755417\n",
      "Epoch 196 / 200 | iteration 160 / 171 | Total Loss: 2.387258291244507 | KNN Loss: 2.3800196647644043 | CLS Loss: 0.007238680962473154\n",
      "Epoch 196 / 200 | iteration 170 / 171 | Total Loss: 2.3820912837982178 | KNN Loss: 2.3760316371917725 | CLS Loss: 0.00605975603684783\n",
      "Epoch: 196, Loss: 2.4145, Train: 0.9967, Valid: 0.9859, Best: 0.9877\n",
      "Epoch 197 / 200 | iteration 0 / 171 | Total Loss: 2.4123570919036865 | KNN Loss: 2.399005651473999 | CLS Loss: 0.013351420871913433\n",
      "Epoch 197 / 200 | iteration 10 / 171 | Total Loss: 2.4052865505218506 | KNN Loss: 2.400083541870117 | CLS Loss: 0.0052030012011528015\n",
      "Epoch 197 / 200 | iteration 20 / 171 | Total Loss: 2.4110262393951416 | KNN Loss: 2.390432834625244 | CLS Loss: 0.020593339577317238\n",
      "Epoch 197 / 200 | iteration 30 / 171 | Total Loss: 2.4258835315704346 | KNN Loss: 2.4170303344726562 | CLS Loss: 0.008853251114487648\n",
      "Epoch 197 / 200 | iteration 40 / 171 | Total Loss: 2.4499571323394775 | KNN Loss: 2.4453258514404297 | CLS Loss: 0.004631307441741228\n",
      "Epoch 197 / 200 | iteration 50 / 171 | Total Loss: 2.4107162952423096 | KNN Loss: 2.401789665222168 | CLS Loss: 0.008926683105528355\n",
      "Epoch 197 / 200 | iteration 60 / 171 | Total Loss: 2.3974695205688477 | KNN Loss: 2.378376007080078 | CLS Loss: 0.019093450158834457\n",
      "Epoch 197 / 200 | iteration 70 / 171 | Total Loss: 2.418123483657837 | KNN Loss: 2.413804531097412 | CLS Loss: 0.004318845458328724\n",
      "Epoch 197 / 200 | iteration 80 / 171 | Total Loss: 2.415539503097534 | KNN Loss: 2.411694049835205 | CLS Loss: 0.0038454646710306406\n",
      "Epoch 197 / 200 | iteration 90 / 171 | Total Loss: 2.424530506134033 | KNN Loss: 2.4038383960723877 | CLS Loss: 0.02069205977022648\n",
      "Epoch 197 / 200 | iteration 100 / 171 | Total Loss: 2.3704402446746826 | KNN Loss: 2.3586173057556152 | CLS Loss: 0.01182283740490675\n",
      "Epoch 197 / 200 | iteration 110 / 171 | Total Loss: 2.39346981048584 | KNN Loss: 2.377976179122925 | CLS Loss: 0.015493638813495636\n",
      "Epoch 197 / 200 | iteration 120 / 171 | Total Loss: 2.424785614013672 | KNN Loss: 2.3978943824768066 | CLS Loss: 0.026891279965639114\n",
      "Epoch 197 / 200 | iteration 130 / 171 | Total Loss: 2.4130213260650635 | KNN Loss: 2.4042863845825195 | CLS Loss: 0.008734862320125103\n",
      "Epoch 197 / 200 | iteration 140 / 171 | Total Loss: 2.420877456665039 | KNN Loss: 2.3913934230804443 | CLS Loss: 0.029483957216143608\n",
      "Epoch 197 / 200 | iteration 150 / 171 | Total Loss: 2.426182985305786 | KNN Loss: 2.4093053340911865 | CLS Loss: 0.01687769591808319\n",
      "Epoch 197 / 200 | iteration 160 / 171 | Total Loss: 2.3869893550872803 | KNN Loss: 2.3735079765319824 | CLS Loss: 0.013481492176651955\n",
      "Epoch 197 / 200 | iteration 170 / 171 | Total Loss: 2.4808402061462402 | KNN Loss: 2.468829393386841 | CLS Loss: 0.0120108462870121\n",
      "Epoch: 197, Loss: 2.4117, Train: 0.9962, Valid: 0.9859, Best: 0.9877\n",
      "Epoch 198 / 200 | iteration 0 / 171 | Total Loss: 2.4275834560394287 | KNN Loss: 2.4184045791625977 | CLS Loss: 0.009178848937153816\n",
      "Epoch 198 / 200 | iteration 10 / 171 | Total Loss: 2.4095048904418945 | KNN Loss: 2.408630609512329 | CLS Loss: 0.0008742978097870946\n",
      "Epoch 198 / 200 | iteration 20 / 171 | Total Loss: 2.4479658603668213 | KNN Loss: 2.4374542236328125 | CLS Loss: 0.010511699132621288\n",
      "Epoch 198 / 200 | iteration 30 / 171 | Total Loss: 2.4620983600616455 | KNN Loss: 2.4412574768066406 | CLS Loss: 0.020840926095843315\n",
      "Epoch 198 / 200 | iteration 40 / 171 | Total Loss: 2.3881211280822754 | KNN Loss: 2.379943370819092 | CLS Loss: 0.008177798241376877\n",
      "Epoch 198 / 200 | iteration 50 / 171 | Total Loss: 2.456796884536743 | KNN Loss: 2.429572105407715 | CLS Loss: 0.027224790304899216\n",
      "Epoch 198 / 200 | iteration 60 / 171 | Total Loss: 2.4116103649139404 | KNN Loss: 2.400526523590088 | CLS Loss: 0.011083747260272503\n",
      "Epoch 198 / 200 | iteration 70 / 171 | Total Loss: 2.405360460281372 | KNN Loss: 2.3976457118988037 | CLS Loss: 0.007714645005762577\n",
      "Epoch 198 / 200 | iteration 80 / 171 | Total Loss: 2.3826141357421875 | KNN Loss: 2.3795101642608643 | CLS Loss: 0.003103869268670678\n",
      "Epoch 198 / 200 | iteration 90 / 171 | Total Loss: 2.4532251358032227 | KNN Loss: 2.4315247535705566 | CLS Loss: 0.021700343117117882\n",
      "Epoch 198 / 200 | iteration 100 / 171 | Total Loss: 2.423051357269287 | KNN Loss: 2.3869242668151855 | CLS Loss: 0.03612716495990753\n",
      "Epoch 198 / 200 | iteration 110 / 171 | Total Loss: 2.4574427604675293 | KNN Loss: 2.44197940826416 | CLS Loss: 0.015463433228433132\n",
      "Epoch 198 / 200 | iteration 120 / 171 | Total Loss: 2.4271209239959717 | KNN Loss: 2.4224581718444824 | CLS Loss: 0.004662779159843922\n",
      "Epoch 198 / 200 | iteration 130 / 171 | Total Loss: 2.485931873321533 | KNN Loss: 2.464179754257202 | CLS Loss: 0.021752070635557175\n",
      "Epoch 198 / 200 | iteration 140 / 171 | Total Loss: 2.3897979259490967 | KNN Loss: 2.3825623989105225 | CLS Loss: 0.00723551819100976\n",
      "Epoch 198 / 200 | iteration 150 / 171 | Total Loss: 2.4114065170288086 | KNN Loss: 2.3969857692718506 | CLS Loss: 0.014420853927731514\n",
      "Epoch 198 / 200 | iteration 160 / 171 | Total Loss: 2.4214067459106445 | KNN Loss: 2.4057493209838867 | CLS Loss: 0.01565742865204811\n",
      "Epoch 198 / 200 | iteration 170 / 171 | Total Loss: 2.3883299827575684 | KNN Loss: 2.380739450454712 | CLS Loss: 0.007590595632791519\n",
      "Epoch: 198, Loss: 2.4184, Train: 0.9966, Valid: 0.9858, Best: 0.9877\n",
      "Epoch 199 / 200 | iteration 0 / 171 | Total Loss: 2.402127981185913 | KNN Loss: 2.3974709510803223 | CLS Loss: 0.004657061770558357\n",
      "Epoch 199 / 200 | iteration 10 / 171 | Total Loss: 2.4321951866149902 | KNN Loss: 2.413456678390503 | CLS Loss: 0.01873856410384178\n",
      "Epoch 199 / 200 | iteration 20 / 171 | Total Loss: 2.4391980171203613 | KNN Loss: 2.422168731689453 | CLS Loss: 0.017029307782649994\n",
      "Epoch 199 / 200 | iteration 30 / 171 | Total Loss: 2.4190053939819336 | KNN Loss: 2.3980600833892822 | CLS Loss: 0.02094540186226368\n",
      "Epoch 199 / 200 | iteration 40 / 171 | Total Loss: 2.4007880687713623 | KNN Loss: 2.3989901542663574 | CLS Loss: 0.0017979220720008016\n",
      "Epoch 199 / 200 | iteration 50 / 171 | Total Loss: 2.3984029293060303 | KNN Loss: 2.384309768676758 | CLS Loss: 0.014093104749917984\n",
      "Epoch 199 / 200 | iteration 60 / 171 | Total Loss: 2.4375035762786865 | KNN Loss: 2.4253926277160645 | CLS Loss: 0.012110964395105839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 / 200 | iteration 70 / 171 | Total Loss: 2.4101948738098145 | KNN Loss: 2.392791748046875 | CLS Loss: 0.017403146252036095\n",
      "Epoch 199 / 200 | iteration 80 / 171 | Total Loss: 2.3714137077331543 | KNN Loss: 2.3656351566314697 | CLS Loss: 0.0057786256074905396\n",
      "Epoch 199 / 200 | iteration 90 / 171 | Total Loss: 2.4124298095703125 | KNN Loss: 2.402292251586914 | CLS Loss: 0.010137462988495827\n",
      "Epoch 199 / 200 | iteration 100 / 171 | Total Loss: 2.4406585693359375 | KNN Loss: 2.4180727005004883 | CLS Loss: 0.022585898637771606\n",
      "Epoch 199 / 200 | iteration 110 / 171 | Total Loss: 2.4331226348876953 | KNN Loss: 2.419377326965332 | CLS Loss: 0.013745265081524849\n",
      "Epoch 199 / 200 | iteration 120 / 171 | Total Loss: 2.4068851470947266 | KNN Loss: 2.3972902297973633 | CLS Loss: 0.009594847448170185\n",
      "Epoch 199 / 200 | iteration 130 / 171 | Total Loss: 2.4206607341766357 | KNN Loss: 2.404902935028076 | CLS Loss: 0.015757769346237183\n",
      "Epoch 199 / 200 | iteration 140 / 171 | Total Loss: 2.427826404571533 | KNN Loss: 2.4267988204956055 | CLS Loss: 0.0010274866363033652\n",
      "Epoch 199 / 200 | iteration 150 / 171 | Total Loss: 2.3670318126678467 | KNN Loss: 2.3551859855651855 | CLS Loss: 0.011845821514725685\n",
      "Epoch 199 / 200 | iteration 160 / 171 | Total Loss: 2.434751272201538 | KNN Loss: 2.412503480911255 | CLS Loss: 0.02224777080118656\n",
      "Epoch 199 / 200 | iteration 170 / 171 | Total Loss: 2.389347553253174 | KNN Loss: 2.364154100418091 | CLS Loss: 0.025193415582180023\n",
      "Epoch: 199, Loss: 2.4159, Train: 0.9967, Valid: 0.9865, Best: 0.9877\n",
      "Epoch 200 / 200 | iteration 0 / 171 | Total Loss: 2.3865418434143066 | KNN Loss: 2.3766798973083496 | CLS Loss: 0.009862041100859642\n",
      "Epoch 200 / 200 | iteration 10 / 171 | Total Loss: 2.4188735485076904 | KNN Loss: 2.4080281257629395 | CLS Loss: 0.010845525190234184\n",
      "Epoch 200 / 200 | iteration 20 / 171 | Total Loss: 2.412583351135254 | KNN Loss: 2.4094815254211426 | CLS Loss: 0.0031018592417240143\n",
      "Epoch 200 / 200 | iteration 30 / 171 | Total Loss: 2.416841506958008 | KNN Loss: 2.400900363922119 | CLS Loss: 0.015941089019179344\n",
      "Epoch 200 / 200 | iteration 40 / 171 | Total Loss: 2.450923442840576 | KNN Loss: 2.4301917552948 | CLS Loss: 0.020731603726744652\n",
      "Epoch 200 / 200 | iteration 50 / 171 | Total Loss: 2.4137706756591797 | KNN Loss: 2.4114036560058594 | CLS Loss: 0.0023670836817473173\n",
      "Epoch 200 / 200 | iteration 60 / 171 | Total Loss: 2.4234135150909424 | KNN Loss: 2.415436029434204 | CLS Loss: 0.007977589964866638\n",
      "Epoch 200 / 200 | iteration 70 / 171 | Total Loss: 2.3799121379852295 | KNN Loss: 2.377826452255249 | CLS Loss: 0.002085748128592968\n",
      "Epoch 200 / 200 | iteration 80 / 171 | Total Loss: 2.4030401706695557 | KNN Loss: 2.39898943901062 | CLS Loss: 0.004050831310451031\n",
      "Epoch 200 / 200 | iteration 90 / 171 | Total Loss: 2.3882434368133545 | KNN Loss: 2.3849127292633057 | CLS Loss: 0.003330701496452093\n",
      "Epoch 200 / 200 | iteration 100 / 171 | Total Loss: 2.3759448528289795 | KNN Loss: 2.366374969482422 | CLS Loss: 0.009569786489009857\n",
      "Epoch 200 / 200 | iteration 110 / 171 | Total Loss: 2.4558019638061523 | KNN Loss: 2.417879104614258 | CLS Loss: 0.03792290389537811\n",
      "Epoch 200 / 200 | iteration 120 / 171 | Total Loss: 2.4330966472625732 | KNN Loss: 2.4174299240112305 | CLS Loss: 0.015666622668504715\n",
      "Epoch 200 / 200 | iteration 130 / 171 | Total Loss: 2.429271936416626 | KNN Loss: 2.4103446006774902 | CLS Loss: 0.018927376717329025\n",
      "Epoch 200 / 200 | iteration 140 / 171 | Total Loss: 2.4341201782226562 | KNN Loss: 2.421322822570801 | CLS Loss: 0.012797444127500057\n",
      "Epoch 200 / 200 | iteration 150 / 171 | Total Loss: 2.399066209793091 | KNN Loss: 2.3926260471343994 | CLS Loss: 0.006440135184675455\n",
      "Epoch 200 / 200 | iteration 160 / 171 | Total Loss: 2.4174811840057373 | KNN Loss: 2.4041943550109863 | CLS Loss: 0.013286726549267769\n",
      "Epoch 200 / 200 | iteration 170 / 171 | Total Loss: 2.476212978363037 | KNN Loss: 2.4430315494537354 | CLS Loss: 0.03318147361278534\n",
      "Epoch: 200, Loss: 2.4199, Train: 0.9960, Valid: 0.9856, Best: 0.9877\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9856, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ce5bc37604444c9553a139754ef849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2112ea197dd438398de79326adbbf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6696592b8a465590571695b6eff041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3450b29e3d4716bcfc31aa1b81e250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c27914d7184060baefd2475e34f3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.9099629984925311\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9edd1f58ba4c8882696da8ff36cc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "Epoch: 00 | Batch: 000 / 039 | Total loss: 3.270 | Reg loss: 0.007 | Tree loss: 3.270 | Accuracy: 0.046875 | 0.091 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 01 | Batch: 000 / 039 | Total loss: 3.193 | Reg loss: 0.005 | Tree loss: 3.193 | Accuracy: 0.136719 | 0.063 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 02 | Batch: 000 / 039 | Total loss: 3.135 | Reg loss: 0.008 | Tree loss: 3.135 | Accuracy: 0.146484 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 03 | Batch: 000 / 039 | Total loss: 3.090 | Reg loss: 0.010 | Tree loss: 3.090 | Accuracy: 0.158203 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 04 | Batch: 000 / 039 | Total loss: 3.084 | Reg loss: 0.012 | Tree loss: 3.084 | Accuracy: 0.126953 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 05 | Batch: 000 / 039 | Total loss: 3.034 | Reg loss: 0.013 | Tree loss: 3.034 | Accuracy: 0.169922 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 06 | Batch: 000 / 039 | Total loss: 3.005 | Reg loss: 0.014 | Tree loss: 3.005 | Accuracy: 0.164062 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 07 | Batch: 000 / 039 | Total loss: 2.972 | Reg loss: 0.014 | Tree loss: 2.972 | Accuracy: 0.214844 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 08 | Batch: 000 / 039 | Total loss: 2.952 | Reg loss: 0.015 | Tree loss: 2.952 | Accuracy: 0.224609 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 09 | Batch: 000 / 039 | Total loss: 2.919 | Reg loss: 0.016 | Tree loss: 2.919 | Accuracy: 0.240234 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 10 | Batch: 000 / 039 | Total loss: 2.901 | Reg loss: 0.016 | Tree loss: 2.901 | Accuracy: 0.273438 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 11 | Batch: 000 / 039 | Total loss: 2.938 | Reg loss: 0.016 | Tree loss: 2.938 | Accuracy: 0.236328 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 12 | Batch: 000 / 039 | Total loss: 2.881 | Reg loss: 0.017 | Tree loss: 2.881 | Accuracy: 0.248047 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 13 | Batch: 000 / 039 | Total loss: 2.895 | Reg loss: 0.017 | Tree loss: 2.895 | Accuracy: 0.242188 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 14 | Batch: 000 / 039 | Total loss: 2.844 | Reg loss: 0.017 | Tree loss: 2.844 | Accuracy: 0.269531 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 15 | Batch: 000 / 039 | Total loss: 2.832 | Reg loss: 0.018 | Tree loss: 2.832 | Accuracy: 0.257812 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 16 | Batch: 000 / 039 | Total loss: 2.824 | Reg loss: 0.018 | Tree loss: 2.824 | Accuracy: 0.244141 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 17 | Batch: 000 / 039 | Total loss: 2.769 | Reg loss: 0.019 | Tree loss: 2.769 | Accuracy: 0.292969 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 18 | Batch: 000 / 039 | Total loss: 2.846 | Reg loss: 0.019 | Tree loss: 2.846 | Accuracy: 0.236328 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 19 | Batch: 000 / 039 | Total loss: 2.794 | Reg loss: 0.019 | Tree loss: 2.794 | Accuracy: 0.265625 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 20 | Batch: 000 / 039 | Total loss: 2.798 | Reg loss: 0.020 | Tree loss: 2.798 | Accuracy: 0.242188 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 21 | Batch: 000 / 039 | Total loss: 2.701 | Reg loss: 0.020 | Tree loss: 2.701 | Accuracy: 0.320312 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 22 | Batch: 000 / 039 | Total loss: 2.794 | Reg loss: 0.021 | Tree loss: 2.794 | Accuracy: 0.232422 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 23 | Batch: 000 / 039 | Total loss: 2.732 | Reg loss: 0.021 | Tree loss: 2.732 | Accuracy: 0.279297 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 24 | Batch: 000 / 039 | Total loss: 2.734 | Reg loss: 0.021 | Tree loss: 2.734 | Accuracy: 0.271484 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 25 | Batch: 000 / 039 | Total loss: 2.690 | Reg loss: 0.022 | Tree loss: 2.690 | Accuracy: 0.294922 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 26 | Batch: 000 / 039 | Total loss: 2.697 | Reg loss: 0.022 | Tree loss: 2.697 | Accuracy: 0.275391 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 27 | Batch: 000 / 039 | Total loss: 2.709 | Reg loss: 0.022 | Tree loss: 2.709 | Accuracy: 0.236328 | 0.062 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 28 | Batch: 000 / 039 | Total loss: 2.743 | Reg loss: 0.023 | Tree loss: 2.743 | Accuracy: 0.216797 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 29 | Batch: 000 / 039 | Total loss: 2.686 | Reg loss: 0.023 | Tree loss: 2.686 | Accuracy: 0.267578 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 30 | Batch: 000 / 039 | Total loss: 2.647 | Reg loss: 0.023 | Tree loss: 2.647 | Accuracy: 0.304688 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 31 | Batch: 000 / 039 | Total loss: 2.642 | Reg loss: 0.023 | Tree loss: 2.642 | Accuracy: 0.296875 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 32 | Batch: 000 / 039 | Total loss: 2.720 | Reg loss: 0.023 | Tree loss: 2.720 | Accuracy: 0.261719 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 33 | Batch: 000 / 039 | Total loss: 2.622 | Reg loss: 0.023 | Tree loss: 2.622 | Accuracy: 0.326172 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 34 | Batch: 000 / 039 | Total loss: 2.693 | Reg loss: 0.024 | Tree loss: 2.693 | Accuracy: 0.253906 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 35 | Batch: 000 / 039 | Total loss: 2.607 | Reg loss: 0.024 | Tree loss: 2.607 | Accuracy: 0.294922 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 36 | Batch: 000 / 039 | Total loss: 2.656 | Reg loss: 0.024 | Tree loss: 2.656 | Accuracy: 0.259766 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 37 | Batch: 000 / 039 | Total loss: 2.510 | Reg loss: 0.024 | Tree loss: 2.510 | Accuracy: 0.351562 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 38 | Batch: 000 / 039 | Total loss: 2.547 | Reg loss: 0.024 | Tree loss: 2.547 | Accuracy: 0.285156 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 39 | Batch: 000 / 039 | Total loss: 2.601 | Reg loss: 0.024 | Tree loss: 2.601 | Accuracy: 0.283203 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 40 | Batch: 000 / 039 | Total loss: 2.451 | Reg loss: 0.024 | Tree loss: 2.451 | Accuracy: 0.365234 | 0.062 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 41 | Batch: 000 / 039 | Total loss: 2.479 | Reg loss: 0.024 | Tree loss: 2.479 | Accuracy: 0.302734 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 42 | Batch: 000 / 039 | Total loss: 2.498 | Reg loss: 0.024 | Tree loss: 2.498 | Accuracy: 0.294922 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 43 | Batch: 000 / 039 | Total loss: 2.505 | Reg loss: 0.024 | Tree loss: 2.505 | Accuracy: 0.298828 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 44 | Batch: 000 / 039 | Total loss: 2.541 | Reg loss: 0.024 | Tree loss: 2.541 | Accuracy: 0.265625 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 45 | Batch: 000 / 039 | Total loss: 2.540 | Reg loss: 0.024 | Tree loss: 2.540 | Accuracy: 0.269531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 46 | Batch: 000 / 039 | Total loss: 2.456 | Reg loss: 0.024 | Tree loss: 2.456 | Accuracy: 0.289062 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 47 | Batch: 000 / 039 | Total loss: 2.510 | Reg loss: 0.024 | Tree loss: 2.510 | Accuracy: 0.271484 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 48 | Batch: 000 / 039 | Total loss: 2.508 | Reg loss: 0.024 | Tree loss: 2.508 | Accuracy: 0.273438 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 49 | Batch: 000 / 039 | Total loss: 2.583 | Reg loss: 0.024 | Tree loss: 2.583 | Accuracy: 0.240234 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 50 | Batch: 000 / 039 | Total loss: 2.544 | Reg loss: 0.024 | Tree loss: 2.544 | Accuracy: 0.244141 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 51 | Batch: 000 / 039 | Total loss: 2.448 | Reg loss: 0.024 | Tree loss: 2.448 | Accuracy: 0.292969 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 52 | Batch: 000 / 039 | Total loss: 2.447 | Reg loss: 0.024 | Tree loss: 2.447 | Accuracy: 0.287109 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 53 | Batch: 000 / 039 | Total loss: 2.514 | Reg loss: 0.024 | Tree loss: 2.514 | Accuracy: 0.285156 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 54 | Batch: 000 / 039 | Total loss: 2.528 | Reg loss: 0.024 | Tree loss: 2.528 | Accuracy: 0.271484 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 55 | Batch: 000 / 039 | Total loss: 2.494 | Reg loss: 0.024 | Tree loss: 2.494 | Accuracy: 0.267578 | 0.058 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 56 | Batch: 000 / 039 | Total loss: 2.454 | Reg loss: 0.024 | Tree loss: 2.454 | Accuracy: 0.283203 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 57 | Batch: 000 / 039 | Total loss: 2.436 | Reg loss: 0.024 | Tree loss: 2.436 | Accuracy: 0.296875 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 58 | Batch: 000 / 039 | Total loss: 2.474 | Reg loss: 0.024 | Tree loss: 2.474 | Accuracy: 0.285156 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 59 | Batch: 000 / 039 | Total loss: 2.448 | Reg loss: 0.024 | Tree loss: 2.448 | Accuracy: 0.271484 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 60 | Batch: 000 / 039 | Total loss: 2.418 | Reg loss: 0.024 | Tree loss: 2.418 | Accuracy: 0.285156 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 61 | Batch: 000 / 039 | Total loss: 2.506 | Reg loss: 0.024 | Tree loss: 2.506 | Accuracy: 0.275391 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 62 | Batch: 000 / 039 | Total loss: 2.433 | Reg loss: 0.024 | Tree loss: 2.433 | Accuracy: 0.285156 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 63 | Batch: 000 / 039 | Total loss: 2.405 | Reg loss: 0.024 | Tree loss: 2.405 | Accuracy: 0.300781 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 64 | Batch: 000 / 039 | Total loss: 2.465 | Reg loss: 0.024 | Tree loss: 2.465 | Accuracy: 0.283203 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 65 | Batch: 000 / 039 | Total loss: 2.445 | Reg loss: 0.024 | Tree loss: 2.445 | Accuracy: 0.273438 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 66 | Batch: 000 / 039 | Total loss: 2.396 | Reg loss: 0.024 | Tree loss: 2.396 | Accuracy: 0.310547 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 67 | Batch: 000 / 039 | Total loss: 2.571 | Reg loss: 0.024 | Tree loss: 2.571 | Accuracy: 0.253906 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 68 | Batch: 000 / 039 | Total loss: 2.364 | Reg loss: 0.024 | Tree loss: 2.364 | Accuracy: 0.283203 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 69 | Batch: 000 / 039 | Total loss: 2.515 | Reg loss: 0.024 | Tree loss: 2.515 | Accuracy: 0.251953 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 70 | Batch: 000 / 039 | Total loss: 2.448 | Reg loss: 0.024 | Tree loss: 2.448 | Accuracy: 0.289062 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 71 | Batch: 000 / 039 | Total loss: 2.413 | Reg loss: 0.024 | Tree loss: 2.413 | Accuracy: 0.265625 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 72 | Batch: 000 / 039 | Total loss: 2.431 | Reg loss: 0.024 | Tree loss: 2.431 | Accuracy: 0.271484 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 73 | Batch: 000 / 039 | Total loss: 2.420 | Reg loss: 0.025 | Tree loss: 2.420 | Accuracy: 0.302734 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 74 | Batch: 000 / 039 | Total loss: 2.438 | Reg loss: 0.025 | Tree loss: 2.438 | Accuracy: 0.298828 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 75 | Batch: 000 / 039 | Total loss: 2.458 | Reg loss: 0.025 | Tree loss: 2.458 | Accuracy: 0.279297 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 76 | Batch: 000 / 039 | Total loss: 2.391 | Reg loss: 0.025 | Tree loss: 2.391 | Accuracy: 0.335938 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 77 | Batch: 000 / 039 | Total loss: 2.391 | Reg loss: 0.025 | Tree loss: 2.391 | Accuracy: 0.314453 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 78 | Batch: 000 / 039 | Total loss: 2.467 | Reg loss: 0.025 | Tree loss: 2.467 | Accuracy: 0.291016 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 79 | Batch: 000 / 039 | Total loss: 2.443 | Reg loss: 0.025 | Tree loss: 2.443 | Accuracy: 0.283203 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 80 | Batch: 000 / 039 | Total loss: 2.410 | Reg loss: 0.025 | Tree loss: 2.410 | Accuracy: 0.306641 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 81 | Batch: 000 / 039 | Total loss: 2.446 | Reg loss: 0.025 | Tree loss: 2.446 | Accuracy: 0.306641 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 82 | Batch: 000 / 039 | Total loss: 2.431 | Reg loss: 0.025 | Tree loss: 2.431 | Accuracy: 0.296875 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 83 | Batch: 000 / 039 | Total loss: 2.401 | Reg loss: 0.025 | Tree loss: 2.401 | Accuracy: 0.310547 | 0.054 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 84 | Batch: 000 / 039 | Total loss: 2.435 | Reg loss: 0.025 | Tree loss: 2.435 | Accuracy: 0.294922 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 85 | Batch: 000 / 039 | Total loss: 2.439 | Reg loss: 0.025 | Tree loss: 2.439 | Accuracy: 0.300781 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 86 | Batch: 000 / 039 | Total loss: 2.442 | Reg loss: 0.025 | Tree loss: 2.442 | Accuracy: 0.302734 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 87 | Batch: 000 / 039 | Total loss: 2.369 | Reg loss: 0.025 | Tree loss: 2.369 | Accuracy: 0.289062 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 88 | Batch: 000 / 039 | Total loss: 2.421 | Reg loss: 0.025 | Tree loss: 2.421 | Accuracy: 0.304688 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 89 | Batch: 000 / 039 | Total loss: 2.467 | Reg loss: 0.025 | Tree loss: 2.467 | Accuracy: 0.320312 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 90 | Batch: 000 / 039 | Total loss: 2.494 | Reg loss: 0.025 | Tree loss: 2.494 | Accuracy: 0.251953 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 91 | Batch: 000 / 039 | Total loss: 2.438 | Reg loss: 0.025 | Tree loss: 2.438 | Accuracy: 0.322266 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 92 | Batch: 000 / 039 | Total loss: 2.462 | Reg loss: 0.025 | Tree loss: 2.462 | Accuracy: 0.308594 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 93 | Batch: 000 / 039 | Total loss: 2.432 | Reg loss: 0.025 | Tree loss: 2.432 | Accuracy: 0.310547 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 94 | Batch: 000 / 039 | Total loss: 2.385 | Reg loss: 0.025 | Tree loss: 2.385 | Accuracy: 0.292969 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 95 | Batch: 000 / 039 | Total loss: 2.349 | Reg loss: 0.025 | Tree loss: 2.349 | Accuracy: 0.318359 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 96 | Batch: 000 / 039 | Total loss: 2.448 | Reg loss: 0.025 | Tree loss: 2.448 | Accuracy: 0.294922 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 97 | Batch: 000 / 039 | Total loss: 2.428 | Reg loss: 0.025 | Tree loss: 2.428 | Accuracy: 0.304688 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 98 | Batch: 000 / 039 | Total loss: 2.380 | Reg loss: 0.025 | Tree loss: 2.380 | Accuracy: 0.320312 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 99 | Batch: 000 / 039 | Total loss: 2.420 | Reg loss: 0.025 | Tree loss: 2.420 | Accuracy: 0.279297 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 100 | Batch: 000 / 039 | Total loss: 2.444 | Reg loss: 0.025 | Tree loss: 2.444 | Accuracy: 0.296875 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 101 | Batch: 000 / 039 | Total loss: 2.427 | Reg loss: 0.025 | Tree loss: 2.427 | Accuracy: 0.281250 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 102 | Batch: 000 / 039 | Total loss: 2.412 | Reg loss: 0.025 | Tree loss: 2.412 | Accuracy: 0.277344 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 103 | Batch: 000 / 039 | Total loss: 2.420 | Reg loss: 0.025 | Tree loss: 2.420 | Accuracy: 0.253906 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 104 | Batch: 000 / 039 | Total loss: 2.427 | Reg loss: 0.025 | Tree loss: 2.427 | Accuracy: 0.302734 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 105 | Batch: 000 / 039 | Total loss: 2.392 | Reg loss: 0.025 | Tree loss: 2.392 | Accuracy: 0.302734 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 106 | Batch: 000 / 039 | Total loss: 2.283 | Reg loss: 0.025 | Tree loss: 2.283 | Accuracy: 0.310547 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 107 | Batch: 000 / 039 | Total loss: 2.358 | Reg loss: 0.025 | Tree loss: 2.358 | Accuracy: 0.330078 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 108 | Batch: 000 / 039 | Total loss: 2.430 | Reg loss: 0.025 | Tree loss: 2.430 | Accuracy: 0.287109 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 109 | Batch: 000 / 039 | Total loss: 2.396 | Reg loss: 0.025 | Tree loss: 2.396 | Accuracy: 0.291016 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 110 | Batch: 000 / 039 | Total loss: 2.385 | Reg loss: 0.025 | Tree loss: 2.385 | Accuracy: 0.296875 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 111 | Batch: 000 / 039 | Total loss: 2.360 | Reg loss: 0.025 | Tree loss: 2.360 | Accuracy: 0.310547 | 0.052 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 112 | Batch: 000 / 039 | Total loss: 2.385 | Reg loss: 0.025 | Tree loss: 2.385 | Accuracy: 0.294922 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 113 | Batch: 000 / 039 | Total loss: 2.428 | Reg loss: 0.025 | Tree loss: 2.428 | Accuracy: 0.300781 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 114 | Batch: 000 / 039 | Total loss: 2.449 | Reg loss: 0.025 | Tree loss: 2.449 | Accuracy: 0.273438 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 115 | Batch: 000 / 039 | Total loss: 2.388 | Reg loss: 0.025 | Tree loss: 2.388 | Accuracy: 0.308594 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 116 | Batch: 000 / 039 | Total loss: 2.418 | Reg loss: 0.025 | Tree loss: 2.418 | Accuracy: 0.287109 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 117 | Batch: 000 / 039 | Total loss: 2.428 | Reg loss: 0.025 | Tree loss: 2.428 | Accuracy: 0.273438 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 118 | Batch: 000 / 039 | Total loss: 2.403 | Reg loss: 0.025 | Tree loss: 2.403 | Accuracy: 0.304688 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 119 | Batch: 000 / 039 | Total loss: 2.431 | Reg loss: 0.025 | Tree loss: 2.431 | Accuracy: 0.271484 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 120 | Batch: 000 / 039 | Total loss: 2.353 | Reg loss: 0.025 | Tree loss: 2.353 | Accuracy: 0.304688 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 121 | Batch: 000 / 039 | Total loss: 2.431 | Reg loss: 0.025 | Tree loss: 2.431 | Accuracy: 0.267578 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 122 | Batch: 000 / 039 | Total loss: 2.387 | Reg loss: 0.025 | Tree loss: 2.387 | Accuracy: 0.314453 | 0.052 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 123 | Batch: 000 / 039 | Total loss: 2.354 | Reg loss: 0.025 | Tree loss: 2.354 | Accuracy: 0.312500 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 124 | Batch: 000 / 039 | Total loss: 2.296 | Reg loss: 0.025 | Tree loss: 2.296 | Accuracy: 0.314453 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 125 | Batch: 000 / 039 | Total loss: 2.336 | Reg loss: 0.025 | Tree loss: 2.336 | Accuracy: 0.296875 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 126 | Batch: 000 / 039 | Total loss: 2.376 | Reg loss: 0.025 | Tree loss: 2.376 | Accuracy: 0.291016 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 127 | Batch: 000 / 039 | Total loss: 2.417 | Reg loss: 0.025 | Tree loss: 2.417 | Accuracy: 0.289062 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 128 | Batch: 000 / 039 | Total loss: 2.370 | Reg loss: 0.025 | Tree loss: 2.370 | Accuracy: 0.312500 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 129 | Batch: 000 / 039 | Total loss: 2.399 | Reg loss: 0.025 | Tree loss: 2.399 | Accuracy: 0.312500 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 130 | Batch: 000 / 039 | Total loss: 2.465 | Reg loss: 0.025 | Tree loss: 2.465 | Accuracy: 0.294922 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 131 | Batch: 000 / 039 | Total loss: 2.386 | Reg loss: 0.025 | Tree loss: 2.386 | Accuracy: 0.316406 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 132 | Batch: 000 / 039 | Total loss: 2.349 | Reg loss: 0.025 | Tree loss: 2.349 | Accuracy: 0.294922 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 133 | Batch: 000 / 039 | Total loss: 2.298 | Reg loss: 0.025 | Tree loss: 2.298 | Accuracy: 0.332031 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 134 | Batch: 000 / 039 | Total loss: 2.343 | Reg loss: 0.025 | Tree loss: 2.343 | Accuracy: 0.326172 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 135 | Batch: 000 / 039 | Total loss: 2.300 | Reg loss: 0.025 | Tree loss: 2.300 | Accuracy: 0.330078 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 136 | Batch: 000 / 039 | Total loss: 2.370 | Reg loss: 0.025 | Tree loss: 2.370 | Accuracy: 0.310547 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 137 | Batch: 000 / 039 | Total loss: 2.390 | Reg loss: 0.025 | Tree loss: 2.390 | Accuracy: 0.294922 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 138 | Batch: 000 / 039 | Total loss: 2.389 | Reg loss: 0.025 | Tree loss: 2.389 | Accuracy: 0.275391 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 139 | Batch: 000 / 039 | Total loss: 2.406 | Reg loss: 0.025 | Tree loss: 2.406 | Accuracy: 0.291016 | 0.053 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 140 | Batch: 000 / 039 | Total loss: 2.385 | Reg loss: 0.025 | Tree loss: 2.385 | Accuracy: 0.328125 | 0.053 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 141 | Batch: 000 / 039 | Total loss: 2.248 | Reg loss: 0.025 | Tree loss: 2.248 | Accuracy: 0.353516 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 142 | Batch: 000 / 039 | Total loss: 2.353 | Reg loss: 0.025 | Tree loss: 2.353 | Accuracy: 0.310547 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 143 | Batch: 000 / 039 | Total loss: 2.352 | Reg loss: 0.025 | Tree loss: 2.352 | Accuracy: 0.318359 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 144 | Batch: 000 / 039 | Total loss: 2.318 | Reg loss: 0.025 | Tree loss: 2.318 | Accuracy: 0.314453 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 145 | Batch: 000 / 039 | Total loss: 2.349 | Reg loss: 0.025 | Tree loss: 2.349 | Accuracy: 0.296875 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 146 | Batch: 000 / 039 | Total loss: 2.278 | Reg loss: 0.025 | Tree loss: 2.278 | Accuracy: 0.341797 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 147 | Batch: 000 / 039 | Total loss: 2.407 | Reg loss: 0.025 | Tree loss: 2.407 | Accuracy: 0.291016 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 148 | Batch: 000 / 039 | Total loss: 2.296 | Reg loss: 0.025 | Tree loss: 2.296 | Accuracy: 0.310547 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 149 | Batch: 000 / 039 | Total loss: 2.317 | Reg loss: 0.025 | Tree loss: 2.317 | Accuracy: 0.312500 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 150 | Batch: 000 / 039 | Total loss: 2.322 | Reg loss: 0.025 | Tree loss: 2.322 | Accuracy: 0.306641 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 151 | Batch: 000 / 039 | Total loss: 2.332 | Reg loss: 0.025 | Tree loss: 2.332 | Accuracy: 0.298828 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 152 | Batch: 000 / 039 | Total loss: 2.294 | Reg loss: 0.025 | Tree loss: 2.294 | Accuracy: 0.302734 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 153 | Batch: 000 / 039 | Total loss: 2.354 | Reg loss: 0.025 | Tree loss: 2.354 | Accuracy: 0.292969 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 154 | Batch: 000 / 039 | Total loss: 2.287 | Reg loss: 0.025 | Tree loss: 2.287 | Accuracy: 0.322266 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 155 | Batch: 000 / 039 | Total loss: 2.391 | Reg loss: 0.025 | Tree loss: 2.391 | Accuracy: 0.298828 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 156 | Batch: 000 / 039 | Total loss: 2.267 | Reg loss: 0.025 | Tree loss: 2.267 | Accuracy: 0.337891 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 157 | Batch: 000 / 039 | Total loss: 2.270 | Reg loss: 0.025 | Tree loss: 2.270 | Accuracy: 0.312500 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 158 | Batch: 000 / 039 | Total loss: 2.319 | Reg loss: 0.025 | Tree loss: 2.319 | Accuracy: 0.324219 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 159 | Batch: 000 / 039 | Total loss: 2.295 | Reg loss: 0.025 | Tree loss: 2.295 | Accuracy: 0.314453 | 0.054 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 160 | Batch: 000 / 039 | Total loss: 2.351 | Reg loss: 0.025 | Tree loss: 2.351 | Accuracy: 0.300781 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 161 | Batch: 000 / 039 | Total loss: 2.382 | Reg loss: 0.025 | Tree loss: 2.382 | Accuracy: 0.308594 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 162 | Batch: 000 / 039 | Total loss: 2.361 | Reg loss: 0.025 | Tree loss: 2.361 | Accuracy: 0.281250 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 163 | Batch: 000 / 039 | Total loss: 2.301 | Reg loss: 0.025 | Tree loss: 2.301 | Accuracy: 0.333984 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 164 | Batch: 000 / 039 | Total loss: 2.214 | Reg loss: 0.025 | Tree loss: 2.214 | Accuracy: 0.369141 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 165 | Batch: 000 / 039 | Total loss: 2.216 | Reg loss: 0.025 | Tree loss: 2.216 | Accuracy: 0.333984 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 166 | Batch: 000 / 039 | Total loss: 2.238 | Reg loss: 0.026 | Tree loss: 2.238 | Accuracy: 0.341797 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 167 | Batch: 000 / 039 | Total loss: 2.260 | Reg loss: 0.026 | Tree loss: 2.260 | Accuracy: 0.312500 | 0.055 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 168 | Batch: 000 / 039 | Total loss: 2.284 | Reg loss: 0.026 | Tree loss: 2.284 | Accuracy: 0.322266 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 169 | Batch: 000 / 039 | Total loss: 2.292 | Reg loss: 0.026 | Tree loss: 2.292 | Accuracy: 0.337891 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 170 | Batch: 000 / 039 | Total loss: 2.302 | Reg loss: 0.026 | Tree loss: 2.302 | Accuracy: 0.310547 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 171 | Batch: 000 / 039 | Total loss: 2.273 | Reg loss: 0.026 | Tree loss: 2.273 | Accuracy: 0.339844 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 172 | Batch: 000 / 039 | Total loss: 2.279 | Reg loss: 0.026 | Tree loss: 2.279 | Accuracy: 0.318359 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 173 | Batch: 000 / 039 | Total loss: 2.289 | Reg loss: 0.026 | Tree loss: 2.289 | Accuracy: 0.310547 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 174 | Batch: 000 / 039 | Total loss: 2.278 | Reg loss: 0.026 | Tree loss: 2.278 | Accuracy: 0.355469 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 175 | Batch: 000 / 039 | Total loss: 2.246 | Reg loss: 0.026 | Tree loss: 2.246 | Accuracy: 0.347656 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 176 | Batch: 000 / 039 | Total loss: 2.321 | Reg loss: 0.026 | Tree loss: 2.321 | Accuracy: 0.324219 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 177 | Batch: 000 / 039 | Total loss: 2.154 | Reg loss: 0.026 | Tree loss: 2.154 | Accuracy: 0.341797 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 178 | Batch: 000 / 039 | Total loss: 2.212 | Reg loss: 0.026 | Tree loss: 2.212 | Accuracy: 0.335938 | 0.055 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 179 | Batch: 000 / 039 | Total loss: 2.197 | Reg loss: 0.026 | Tree loss: 2.197 | Accuracy: 0.349609 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 180 | Batch: 000 / 039 | Total loss: 2.306 | Reg loss: 0.026 | Tree loss: 2.306 | Accuracy: 0.333984 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 181 | Batch: 000 / 039 | Total loss: 2.246 | Reg loss: 0.026 | Tree loss: 2.246 | Accuracy: 0.343750 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 182 | Batch: 000 / 039 | Total loss: 2.279 | Reg loss: 0.026 | Tree loss: 2.279 | Accuracy: 0.373047 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 183 | Batch: 000 / 039 | Total loss: 2.272 | Reg loss: 0.026 | Tree loss: 2.272 | Accuracy: 0.347656 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 184 | Batch: 000 / 039 | Total loss: 2.220 | Reg loss: 0.026 | Tree loss: 2.220 | Accuracy: 0.337891 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 185 | Batch: 000 / 039 | Total loss: 2.267 | Reg loss: 0.026 | Tree loss: 2.267 | Accuracy: 0.335938 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 186 | Batch: 000 / 039 | Total loss: 2.209 | Reg loss: 0.026 | Tree loss: 2.209 | Accuracy: 0.380859 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 187 | Batch: 000 / 039 | Total loss: 2.283 | Reg loss: 0.026 | Tree loss: 2.283 | Accuracy: 0.322266 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 188 | Batch: 000 / 039 | Total loss: 2.306 | Reg loss: 0.026 | Tree loss: 2.306 | Accuracy: 0.304688 | 0.056 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 189 | Batch: 000 / 039 | Total loss: 2.257 | Reg loss: 0.026 | Tree loss: 2.257 | Accuracy: 0.361328 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 190 | Batch: 000 / 039 | Total loss: 2.257 | Reg loss: 0.026 | Tree loss: 2.257 | Accuracy: 0.326172 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 191 | Batch: 000 / 039 | Total loss: 2.205 | Reg loss: 0.026 | Tree loss: 2.205 | Accuracy: 0.367188 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 192 | Batch: 000 / 039 | Total loss: 2.231 | Reg loss: 0.027 | Tree loss: 2.231 | Accuracy: 0.310547 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 193 | Batch: 000 / 039 | Total loss: 2.242 | Reg loss: 0.027 | Tree loss: 2.242 | Accuracy: 0.330078 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 194 | Batch: 000 / 039 | Total loss: 2.244 | Reg loss: 0.027 | Tree loss: 2.244 | Accuracy: 0.335938 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 195 | Batch: 000 / 039 | Total loss: 2.257 | Reg loss: 0.027 | Tree loss: 2.257 | Accuracy: 0.357422 | 0.057 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 196 | Batch: 000 / 039 | Total loss: 2.238 | Reg loss: 0.027 | Tree loss: 2.238 | Accuracy: 0.320312 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 197 | Batch: 000 / 039 | Total loss: 2.220 | Reg loss: 0.027 | Tree loss: 2.220 | Accuracy: 0.310547 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 198 | Batch: 000 / 039 | Total loss: 2.280 | Reg loss: 0.027 | Tree loss: 2.280 | Accuracy: 0.318359 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 199 | Batch: 000 / 039 | Total loss: 2.233 | Reg loss: 0.027 | Tree loss: 2.233 | Accuracy: 0.341797 | 0.057 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 200 | Batch: 000 / 039 | Total loss: 2.175 | Reg loss: 0.027 | Tree loss: 2.175 | Accuracy: 0.376953 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 201 | Batch: 000 / 039 | Total loss: 2.194 | Reg loss: 0.027 | Tree loss: 2.194 | Accuracy: 0.337891 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 202 | Batch: 000 / 039 | Total loss: 2.264 | Reg loss: 0.027 | Tree loss: 2.264 | Accuracy: 0.330078 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 203 | Batch: 000 / 039 | Total loss: 2.231 | Reg loss: 0.027 | Tree loss: 2.231 | Accuracy: 0.330078 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 204 | Batch: 000 / 039 | Total loss: 2.183 | Reg loss: 0.027 | Tree loss: 2.183 | Accuracy: 0.373047 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 205 | Batch: 000 / 039 | Total loss: 2.183 | Reg loss: 0.027 | Tree loss: 2.183 | Accuracy: 0.363281 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 206 | Batch: 000 / 039 | Total loss: 2.218 | Reg loss: 0.027 | Tree loss: 2.218 | Accuracy: 0.378906 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 207 | Batch: 000 / 039 | Total loss: 2.209 | Reg loss: 0.027 | Tree loss: 2.209 | Accuracy: 0.373047 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 208 | Batch: 000 / 039 | Total loss: 2.172 | Reg loss: 0.027 | Tree loss: 2.172 | Accuracy: 0.353516 | 0.058 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 209 | Batch: 000 / 039 | Total loss: 2.283 | Reg loss: 0.027 | Tree loss: 2.283 | Accuracy: 0.347656 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 210 | Batch: 000 / 039 | Total loss: 2.128 | Reg loss: 0.027 | Tree loss: 2.128 | Accuracy: 0.404297 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 211 | Batch: 000 / 039 | Total loss: 2.211 | Reg loss: 0.027 | Tree loss: 2.211 | Accuracy: 0.328125 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 212 | Batch: 000 / 039 | Total loss: 2.265 | Reg loss: 0.027 | Tree loss: 2.265 | Accuracy: 0.322266 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 213 | Batch: 000 / 039 | Total loss: 2.207 | Reg loss: 0.027 | Tree loss: 2.207 | Accuracy: 0.339844 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 214 | Batch: 000 / 039 | Total loss: 2.246 | Reg loss: 0.027 | Tree loss: 2.246 | Accuracy: 0.347656 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 215 | Batch: 000 / 039 | Total loss: 2.219 | Reg loss: 0.027 | Tree loss: 2.219 | Accuracy: 0.349609 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 216 | Batch: 000 / 039 | Total loss: 2.201 | Reg loss: 0.027 | Tree loss: 2.201 | Accuracy: 0.339844 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 217 | Batch: 000 / 039 | Total loss: 2.203 | Reg loss: 0.027 | Tree loss: 2.203 | Accuracy: 0.341797 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 218 | Batch: 000 / 039 | Total loss: 2.236 | Reg loss: 0.027 | Tree loss: 2.236 | Accuracy: 0.351562 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 219 | Batch: 000 / 039 | Total loss: 2.195 | Reg loss: 0.028 | Tree loss: 2.195 | Accuracy: 0.361328 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 220 | Batch: 000 / 039 | Total loss: 2.197 | Reg loss: 0.028 | Tree loss: 2.197 | Accuracy: 0.371094 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 221 | Batch: 000 / 039 | Total loss: 2.283 | Reg loss: 0.028 | Tree loss: 2.283 | Accuracy: 0.349609 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 222 | Batch: 000 / 039 | Total loss: 2.245 | Reg loss: 0.028 | Tree loss: 2.245 | Accuracy: 0.353516 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 223 | Batch: 000 / 039 | Total loss: 2.201 | Reg loss: 0.028 | Tree loss: 2.201 | Accuracy: 0.378906 | 0.059 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 224 | Batch: 000 / 039 | Total loss: 2.154 | Reg loss: 0.028 | Tree loss: 2.154 | Accuracy: 0.400391 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 225 | Batch: 000 / 039 | Total loss: 2.203 | Reg loss: 0.028 | Tree loss: 2.203 | Accuracy: 0.345703 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 226 | Batch: 000 / 039 | Total loss: 2.206 | Reg loss: 0.028 | Tree loss: 2.206 | Accuracy: 0.357422 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 227 | Batch: 000 / 039 | Total loss: 2.234 | Reg loss: 0.028 | Tree loss: 2.234 | Accuracy: 0.373047 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 228 | Batch: 000 / 039 | Total loss: 2.135 | Reg loss: 0.028 | Tree loss: 2.135 | Accuracy: 0.390625 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 229 | Batch: 000 / 039 | Total loss: 2.127 | Reg loss: 0.028 | Tree loss: 2.127 | Accuracy: 0.400391 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 230 | Batch: 000 / 039 | Total loss: 2.187 | Reg loss: 0.028 | Tree loss: 2.187 | Accuracy: 0.369141 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 231 | Batch: 000 / 039 | Total loss: 2.209 | Reg loss: 0.028 | Tree loss: 2.209 | Accuracy: 0.373047 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 232 | Batch: 000 / 039 | Total loss: 2.162 | Reg loss: 0.028 | Tree loss: 2.162 | Accuracy: 0.390625 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 233 | Batch: 000 / 039 | Total loss: 2.174 | Reg loss: 0.028 | Tree loss: 2.174 | Accuracy: 0.378906 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 234 | Batch: 000 / 039 | Total loss: 2.179 | Reg loss: 0.028 | Tree loss: 2.179 | Accuracy: 0.376953 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 235 | Batch: 000 / 039 | Total loss: 2.196 | Reg loss: 0.028 | Tree loss: 2.196 | Accuracy: 0.361328 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 236 | Batch: 000 / 039 | Total loss: 2.127 | Reg loss: 0.028 | Tree loss: 2.127 | Accuracy: 0.386719 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 237 | Batch: 000 / 039 | Total loss: 2.215 | Reg loss: 0.028 | Tree loss: 2.215 | Accuracy: 0.347656 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 238 | Batch: 000 / 039 | Total loss: 2.216 | Reg loss: 0.028 | Tree loss: 2.216 | Accuracy: 0.369141 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 239 | Batch: 000 / 039 | Total loss: 2.181 | Reg loss: 0.028 | Tree loss: 2.181 | Accuracy: 0.345703 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 240 | Batch: 000 / 039 | Total loss: 2.163 | Reg loss: 0.028 | Tree loss: 2.163 | Accuracy: 0.375000 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 241 | Batch: 000 / 039 | Total loss: 2.172 | Reg loss: 0.028 | Tree loss: 2.172 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 242 | Batch: 000 / 039 | Total loss: 2.244 | Reg loss: 0.028 | Tree loss: 2.244 | Accuracy: 0.345703 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 243 | Batch: 000 / 039 | Total loss: 2.152 | Reg loss: 0.028 | Tree loss: 2.152 | Accuracy: 0.400391 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 244 | Batch: 000 / 039 | Total loss: 2.157 | Reg loss: 0.028 | Tree loss: 2.157 | Accuracy: 0.367188 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 245 | Batch: 000 / 039 | Total loss: 2.106 | Reg loss: 0.028 | Tree loss: 2.106 | Accuracy: 0.408203 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 246 | Batch: 000 / 039 | Total loss: 2.186 | Reg loss: 0.028 | Tree loss: 2.186 | Accuracy: 0.349609 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 247 | Batch: 000 / 039 | Total loss: 2.141 | Reg loss: 0.028 | Tree loss: 2.141 | Accuracy: 0.412109 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 248 | Batch: 000 / 039 | Total loss: 2.228 | Reg loss: 0.028 | Tree loss: 2.228 | Accuracy: 0.371094 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 249 | Batch: 000 / 039 | Total loss: 2.208 | Reg loss: 0.028 | Tree loss: 2.208 | Accuracy: 0.380859 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 250 | Batch: 000 / 039 | Total loss: 2.145 | Reg loss: 0.028 | Tree loss: 2.145 | Accuracy: 0.373047 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 251 | Batch: 000 / 039 | Total loss: 2.056 | Reg loss: 0.028 | Tree loss: 2.056 | Accuracy: 0.445312 | 0.06 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 252 | Batch: 000 / 039 | Total loss: 2.203 | Reg loss: 0.028 | Tree loss: 2.203 | Accuracy: 0.363281 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 253 | Batch: 000 / 039 | Total loss: 2.111 | Reg loss: 0.028 | Tree loss: 2.111 | Accuracy: 0.390625 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 254 | Batch: 000 / 039 | Total loss: 2.272 | Reg loss: 0.028 | Tree loss: 2.272 | Accuracy: 0.322266 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 255 | Batch: 000 / 039 | Total loss: 2.135 | Reg loss: 0.028 | Tree loss: 2.135 | Accuracy: 0.388672 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 256 | Batch: 000 / 039 | Total loss: 2.064 | Reg loss: 0.028 | Tree loss: 2.064 | Accuracy: 0.419922 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 257 | Batch: 000 / 039 | Total loss: 2.181 | Reg loss: 0.028 | Tree loss: 2.181 | Accuracy: 0.400391 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 258 | Batch: 000 / 039 | Total loss: 2.083 | Reg loss: 0.028 | Tree loss: 2.083 | Accuracy: 0.419922 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 259 | Batch: 000 / 039 | Total loss: 2.156 | Reg loss: 0.028 | Tree loss: 2.156 | Accuracy: 0.361328 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 260 | Batch: 000 / 039 | Total loss: 2.130 | Reg loss: 0.028 | Tree loss: 2.130 | Accuracy: 0.396484 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 261 | Batch: 000 / 039 | Total loss: 2.099 | Reg loss: 0.028 | Tree loss: 2.099 | Accuracy: 0.400391 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 262 | Batch: 000 / 039 | Total loss: 2.142 | Reg loss: 0.028 | Tree loss: 2.142 | Accuracy: 0.388672 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 263 | Batch: 000 / 039 | Total loss: 2.143 | Reg loss: 0.028 | Tree loss: 2.143 | Accuracy: 0.390625 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 264 | Batch: 000 / 039 | Total loss: 2.174 | Reg loss: 0.028 | Tree loss: 2.174 | Accuracy: 0.392578 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 265 | Batch: 000 / 039 | Total loss: 2.112 | Reg loss: 0.028 | Tree loss: 2.112 | Accuracy: 0.414062 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 266 | Batch: 000 / 039 | Total loss: 2.133 | Reg loss: 0.028 | Tree loss: 2.133 | Accuracy: 0.396484 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 267 | Batch: 000 / 039 | Total loss: 2.186 | Reg loss: 0.028 | Tree loss: 2.186 | Accuracy: 0.365234 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 268 | Batch: 000 / 039 | Total loss: 2.173 | Reg loss: 0.028 | Tree loss: 2.173 | Accuracy: 0.371094 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 269 | Batch: 000 / 039 | Total loss: 2.189 | Reg loss: 0.028 | Tree loss: 2.189 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 270 | Batch: 000 / 039 | Total loss: 2.133 | Reg loss: 0.028 | Tree loss: 2.133 | Accuracy: 0.404297 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 271 | Batch: 000 / 039 | Total loss: 2.209 | Reg loss: 0.028 | Tree loss: 2.209 | Accuracy: 0.371094 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 272 | Batch: 000 / 039 | Total loss: 2.105 | Reg loss: 0.028 | Tree loss: 2.105 | Accuracy: 0.398438 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 273 | Batch: 000 / 039 | Total loss: 2.148 | Reg loss: 0.028 | Tree loss: 2.148 | Accuracy: 0.380859 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 274 | Batch: 000 / 039 | Total loss: 2.144 | Reg loss: 0.028 | Tree loss: 2.144 | Accuracy: 0.408203 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 275 | Batch: 000 / 039 | Total loss: 2.166 | Reg loss: 0.028 | Tree loss: 2.166 | Accuracy: 0.388672 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 276 | Batch: 000 / 039 | Total loss: 2.170 | Reg loss: 0.028 | Tree loss: 2.170 | Accuracy: 0.376953 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 277 | Batch: 000 / 039 | Total loss: 2.064 | Reg loss: 0.028 | Tree loss: 2.064 | Accuracy: 0.406250 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 278 | Batch: 000 / 039 | Total loss: 2.185 | Reg loss: 0.028 | Tree loss: 2.185 | Accuracy: 0.380859 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 279 | Batch: 000 / 039 | Total loss: 2.070 | Reg loss: 0.028 | Tree loss: 2.070 | Accuracy: 0.458984 | 0.06 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 280 | Batch: 000 / 039 | Total loss: 2.139 | Reg loss: 0.028 | Tree loss: 2.139 | Accuracy: 0.396484 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 281 | Batch: 000 / 039 | Total loss: 2.096 | Reg loss: 0.028 | Tree loss: 2.096 | Accuracy: 0.400391 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 282 | Batch: 000 / 039 | Total loss: 2.188 | Reg loss: 0.028 | Tree loss: 2.188 | Accuracy: 0.373047 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 283 | Batch: 000 / 039 | Total loss: 2.121 | Reg loss: 0.028 | Tree loss: 2.121 | Accuracy: 0.378906 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 284 | Batch: 000 / 039 | Total loss: 2.226 | Reg loss: 0.028 | Tree loss: 2.226 | Accuracy: 0.353516 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 285 | Batch: 000 / 039 | Total loss: 2.166 | Reg loss: 0.028 | Tree loss: 2.166 | Accuracy: 0.390625 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 286 | Batch: 000 / 039 | Total loss: 2.123 | Reg loss: 0.028 | Tree loss: 2.123 | Accuracy: 0.382812 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 287 | Batch: 000 / 039 | Total loss: 2.149 | Reg loss: 0.028 | Tree loss: 2.149 | Accuracy: 0.404297 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 288 | Batch: 000 / 039 | Total loss: 2.111 | Reg loss: 0.028 | Tree loss: 2.111 | Accuracy: 0.406250 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 289 | Batch: 000 / 039 | Total loss: 2.062 | Reg loss: 0.027 | Tree loss: 2.062 | Accuracy: 0.433594 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 290 | Batch: 000 / 039 | Total loss: 2.158 | Reg loss: 0.028 | Tree loss: 2.158 | Accuracy: 0.417969 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 291 | Batch: 000 / 039 | Total loss: 2.144 | Reg loss: 0.027 | Tree loss: 2.144 | Accuracy: 0.398438 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 292 | Batch: 000 / 039 | Total loss: 2.196 | Reg loss: 0.027 | Tree loss: 2.196 | Accuracy: 0.367188 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 293 | Batch: 000 / 039 | Total loss: 2.149 | Reg loss: 0.027 | Tree loss: 2.149 | Accuracy: 0.375000 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 294 | Batch: 000 / 039 | Total loss: 2.088 | Reg loss: 0.027 | Tree loss: 2.088 | Accuracy: 0.396484 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 295 | Batch: 000 / 039 | Total loss: 2.109 | Reg loss: 0.027 | Tree loss: 2.109 | Accuracy: 0.392578 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 296 | Batch: 000 / 039 | Total loss: 2.148 | Reg loss: 0.027 | Tree loss: 2.148 | Accuracy: 0.380859 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 297 | Batch: 000 / 039 | Total loss: 2.085 | Reg loss: 0.027 | Tree loss: 2.085 | Accuracy: 0.416016 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 298 | Batch: 000 / 039 | Total loss: 2.127 | Reg loss: 0.027 | Tree loss: 2.127 | Accuracy: 0.396484 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 299 | Batch: 000 / 039 | Total loss: 2.136 | Reg loss: 0.027 | Tree loss: 2.136 | Accuracy: 0.406250 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 300 | Batch: 000 / 039 | Total loss: 2.093 | Reg loss: 0.027 | Tree loss: 2.093 | Accuracy: 0.406250 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 301 | Batch: 000 / 039 | Total loss: 2.186 | Reg loss: 0.027 | Tree loss: 2.186 | Accuracy: 0.359375 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 302 | Batch: 000 / 039 | Total loss: 2.094 | Reg loss: 0.027 | Tree loss: 2.094 | Accuracy: 0.414062 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 303 | Batch: 000 / 039 | Total loss: 2.107 | Reg loss: 0.027 | Tree loss: 2.107 | Accuracy: 0.441406 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 304 | Batch: 000 / 039 | Total loss: 2.125 | Reg loss: 0.027 | Tree loss: 2.125 | Accuracy: 0.357422 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 305 | Batch: 000 / 039 | Total loss: 2.180 | Reg loss: 0.027 | Tree loss: 2.180 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 306 | Batch: 000 / 039 | Total loss: 2.108 | Reg loss: 0.027 | Tree loss: 2.108 | Accuracy: 0.404297 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 307 | Batch: 000 / 039 | Total loss: 2.124 | Reg loss: 0.027 | Tree loss: 2.124 | Accuracy: 0.402344 | 0.06 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 308 | Batch: 000 / 039 | Total loss: 2.106 | Reg loss: 0.027 | Tree loss: 2.106 | Accuracy: 0.400391 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 309 | Batch: 000 / 039 | Total loss: 2.086 | Reg loss: 0.027 | Tree loss: 2.086 | Accuracy: 0.431641 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 310 | Batch: 000 / 039 | Total loss: 2.049 | Reg loss: 0.027 | Tree loss: 2.049 | Accuracy: 0.417969 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 311 | Batch: 000 / 039 | Total loss: 2.114 | Reg loss: 0.027 | Tree loss: 2.114 | Accuracy: 0.388672 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 312 | Batch: 000 / 039 | Total loss: 2.151 | Reg loss: 0.027 | Tree loss: 2.151 | Accuracy: 0.421875 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 313 | Batch: 000 / 039 | Total loss: 2.139 | Reg loss: 0.027 | Tree loss: 2.139 | Accuracy: 0.404297 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 314 | Batch: 000 / 039 | Total loss: 2.138 | Reg loss: 0.027 | Tree loss: 2.138 | Accuracy: 0.408203 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 315 | Batch: 000 / 039 | Total loss: 2.089 | Reg loss: 0.027 | Tree loss: 2.089 | Accuracy: 0.423828 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 316 | Batch: 000 / 039 | Total loss: 2.089 | Reg loss: 0.027 | Tree loss: 2.089 | Accuracy: 0.427734 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 317 | Batch: 000 / 039 | Total loss: 2.177 | Reg loss: 0.027 | Tree loss: 2.177 | Accuracy: 0.400391 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 318 | Batch: 000 / 039 | Total loss: 2.097 | Reg loss: 0.027 | Tree loss: 2.097 | Accuracy: 0.392578 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 319 | Batch: 000 / 039 | Total loss: 2.033 | Reg loss: 0.027 | Tree loss: 2.033 | Accuracy: 0.416016 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 320 | Batch: 000 / 039 | Total loss: 2.118 | Reg loss: 0.027 | Tree loss: 2.118 | Accuracy: 0.406250 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 321 | Batch: 000 / 039 | Total loss: 2.128 | Reg loss: 0.027 | Tree loss: 2.128 | Accuracy: 0.376953 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 322 | Batch: 000 / 039 | Total loss: 2.132 | Reg loss: 0.027 | Tree loss: 2.132 | Accuracy: 0.402344 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 323 | Batch: 000 / 039 | Total loss: 2.137 | Reg loss: 0.027 | Tree loss: 2.137 | Accuracy: 0.412109 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 324 | Batch: 000 / 039 | Total loss: 2.147 | Reg loss: 0.027 | Tree loss: 2.147 | Accuracy: 0.392578 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 325 | Batch: 000 / 039 | Total loss: 2.102 | Reg loss: 0.027 | Tree loss: 2.102 | Accuracy: 0.414062 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 326 | Batch: 000 / 039 | Total loss: 2.184 | Reg loss: 0.027 | Tree loss: 2.184 | Accuracy: 0.390625 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 327 | Batch: 000 / 039 | Total loss: 2.052 | Reg loss: 0.027 | Tree loss: 2.052 | Accuracy: 0.433594 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 328 | Batch: 000 / 039 | Total loss: 2.137 | Reg loss: 0.027 | Tree loss: 2.137 | Accuracy: 0.421875 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 329 | Batch: 000 / 039 | Total loss: 2.068 | Reg loss: 0.027 | Tree loss: 2.068 | Accuracy: 0.429688 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 330 | Batch: 000 / 039 | Total loss: 2.108 | Reg loss: 0.027 | Tree loss: 2.108 | Accuracy: 0.396484 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 331 | Batch: 000 / 039 | Total loss: 2.147 | Reg loss: 0.027 | Tree loss: 2.147 | Accuracy: 0.365234 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 332 | Batch: 000 / 039 | Total loss: 2.062 | Reg loss: 0.027 | Tree loss: 2.062 | Accuracy: 0.412109 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 333 | Batch: 000 / 039 | Total loss: 2.143 | Reg loss: 0.027 | Tree loss: 2.143 | Accuracy: 0.386719 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 334 | Batch: 000 / 039 | Total loss: 2.129 | Reg loss: 0.027 | Tree loss: 2.129 | Accuracy: 0.400391 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 335 | Batch: 000 / 039 | Total loss: 2.131 | Reg loss: 0.027 | Tree loss: 2.131 | Accuracy: 0.388672 | 0.06 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 336 | Batch: 000 / 039 | Total loss: 2.083 | Reg loss: 0.027 | Tree loss: 2.083 | Accuracy: 0.423828 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 337 | Batch: 000 / 039 | Total loss: 2.132 | Reg loss: 0.027 | Tree loss: 2.132 | Accuracy: 0.414062 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 338 | Batch: 000 / 039 | Total loss: 2.030 | Reg loss: 0.027 | Tree loss: 2.030 | Accuracy: 0.472656 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 339 | Batch: 000 / 039 | Total loss: 2.043 | Reg loss: 0.027 | Tree loss: 2.043 | Accuracy: 0.455078 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 340 | Batch: 000 / 039 | Total loss: 2.102 | Reg loss: 0.027 | Tree loss: 2.102 | Accuracy: 0.410156 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 341 | Batch: 000 / 039 | Total loss: 2.032 | Reg loss: 0.027 | Tree loss: 2.032 | Accuracy: 0.435547 | 0.061 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 342 | Batch: 000 / 039 | Total loss: 2.156 | Reg loss: 0.027 | Tree loss: 2.156 | Accuracy: 0.404297 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 343 | Batch: 000 / 039 | Total loss: 2.115 | Reg loss: 0.027 | Tree loss: 2.115 | Accuracy: 0.400391 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 344 | Batch: 000 / 039 | Total loss: 2.079 | Reg loss: 0.027 | Tree loss: 2.079 | Accuracy: 0.408203 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 345 | Batch: 000 / 039 | Total loss: 2.139 | Reg loss: 0.027 | Tree loss: 2.139 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 346 | Batch: 000 / 039 | Total loss: 2.158 | Reg loss: 0.027 | Tree loss: 2.158 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 347 | Batch: 000 / 039 | Total loss: 2.186 | Reg loss: 0.027 | Tree loss: 2.186 | Accuracy: 0.386719 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 348 | Batch: 000 / 039 | Total loss: 2.101 | Reg loss: 0.027 | Tree loss: 2.101 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 349 | Batch: 000 / 039 | Total loss: 2.099 | Reg loss: 0.027 | Tree loss: 2.099 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 350 | Batch: 000 / 039 | Total loss: 2.194 | Reg loss: 0.027 | Tree loss: 2.194 | Accuracy: 0.367188 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 351 | Batch: 000 / 039 | Total loss: 2.141 | Reg loss: 0.027 | Tree loss: 2.141 | Accuracy: 0.396484 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 352 | Batch: 000 / 039 | Total loss: 2.110 | Reg loss: 0.027 | Tree loss: 2.110 | Accuracy: 0.419922 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 353 | Batch: 000 / 039 | Total loss: 2.036 | Reg loss: 0.027 | Tree loss: 2.036 | Accuracy: 0.439453 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 354 | Batch: 000 / 039 | Total loss: 1.983 | Reg loss: 0.027 | Tree loss: 1.983 | Accuracy: 0.453125 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 355 | Batch: 000 / 039 | Total loss: 2.080 | Reg loss: 0.027 | Tree loss: 2.080 | Accuracy: 0.402344 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 356 | Batch: 000 / 039 | Total loss: 2.073 | Reg loss: 0.027 | Tree loss: 2.073 | Accuracy: 0.380859 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 357 | Batch: 000 / 039 | Total loss: 2.112 | Reg loss: 0.027 | Tree loss: 2.112 | Accuracy: 0.404297 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 358 | Batch: 000 / 039 | Total loss: 2.060 | Reg loss: 0.027 | Tree loss: 2.060 | Accuracy: 0.423828 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 359 | Batch: 000 / 039 | Total loss: 2.122 | Reg loss: 0.027 | Tree loss: 2.122 | Accuracy: 0.380859 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 360 | Batch: 000 / 039 | Total loss: 2.164 | Reg loss: 0.027 | Tree loss: 2.164 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 361 | Batch: 000 / 039 | Total loss: 2.114 | Reg loss: 0.027 | Tree loss: 2.114 | Accuracy: 0.410156 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 362 | Batch: 000 / 039 | Total loss: 2.109 | Reg loss: 0.027 | Tree loss: 2.109 | Accuracy: 0.427734 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 363 | Batch: 000 / 039 | Total loss: 2.052 | Reg loss: 0.027 | Tree loss: 2.052 | Accuracy: 0.453125 | 0.06 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 364 | Batch: 000 / 039 | Total loss: 2.151 | Reg loss: 0.027 | Tree loss: 2.151 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 365 | Batch: 000 / 039 | Total loss: 2.134 | Reg loss: 0.027 | Tree loss: 2.134 | Accuracy: 0.392578 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 366 | Batch: 000 / 039 | Total loss: 2.060 | Reg loss: 0.027 | Tree loss: 2.060 | Accuracy: 0.431641 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 367 | Batch: 000 / 039 | Total loss: 2.081 | Reg loss: 0.027 | Tree loss: 2.081 | Accuracy: 0.390625 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 368 | Batch: 000 / 039 | Total loss: 2.049 | Reg loss: 0.027 | Tree loss: 2.049 | Accuracy: 0.429688 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 369 | Batch: 000 / 039 | Total loss: 2.192 | Reg loss: 0.027 | Tree loss: 2.192 | Accuracy: 0.382812 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 370 | Batch: 000 / 039 | Total loss: 2.119 | Reg loss: 0.027 | Tree loss: 2.119 | Accuracy: 0.414062 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 371 | Batch: 000 / 039 | Total loss: 2.111 | Reg loss: 0.027 | Tree loss: 2.111 | Accuracy: 0.414062 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 372 | Batch: 000 / 039 | Total loss: 2.118 | Reg loss: 0.027 | Tree loss: 2.118 | Accuracy: 0.394531 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 373 | Batch: 000 / 039 | Total loss: 2.185 | Reg loss: 0.027 | Tree loss: 2.185 | Accuracy: 0.355469 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 374 | Batch: 000 / 039 | Total loss: 2.139 | Reg loss: 0.027 | Tree loss: 2.139 | Accuracy: 0.402344 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 375 | Batch: 000 / 039 | Total loss: 2.064 | Reg loss: 0.027 | Tree loss: 2.064 | Accuracy: 0.414062 | 0.06 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 376 | Batch: 000 / 039 | Total loss: 2.100 | Reg loss: 0.027 | Tree loss: 2.100 | Accuracy: 0.410156 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 377 | Batch: 000 / 039 | Total loss: 2.110 | Reg loss: 0.027 | Tree loss: 2.110 | Accuracy: 0.417969 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 378 | Batch: 000 / 039 | Total loss: 2.113 | Reg loss: 0.027 | Tree loss: 2.113 | Accuracy: 0.408203 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 379 | Batch: 000 / 039 | Total loss: 2.203 | Reg loss: 0.027 | Tree loss: 2.203 | Accuracy: 0.351562 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 380 | Batch: 000 / 039 | Total loss: 2.116 | Reg loss: 0.027 | Tree loss: 2.116 | Accuracy: 0.400391 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 381 | Batch: 000 / 039 | Total loss: 2.056 | Reg loss: 0.027 | Tree loss: 2.056 | Accuracy: 0.427734 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 382 | Batch: 000 / 039 | Total loss: 2.103 | Reg loss: 0.027 | Tree loss: 2.103 | Accuracy: 0.400391 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 383 | Batch: 000 / 039 | Total loss: 2.119 | Reg loss: 0.027 | Tree loss: 2.119 | Accuracy: 0.392578 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 384 | Batch: 000 / 039 | Total loss: 2.122 | Reg loss: 0.027 | Tree loss: 2.122 | Accuracy: 0.392578 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 385 | Batch: 000 / 039 | Total loss: 2.114 | Reg loss: 0.027 | Tree loss: 2.114 | Accuracy: 0.447266 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 386 | Batch: 000 / 039 | Total loss: 2.100 | Reg loss: 0.027 | Tree loss: 2.100 | Accuracy: 0.412109 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 387 | Batch: 000 / 039 | Total loss: 2.101 | Reg loss: 0.027 | Tree loss: 2.101 | Accuracy: 0.406250 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 388 | Batch: 000 / 039 | Total loss: 2.032 | Reg loss: 0.027 | Tree loss: 2.032 | Accuracy: 0.449219 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 389 | Batch: 000 / 039 | Total loss: 2.158 | Reg loss: 0.027 | Tree loss: 2.158 | Accuracy: 0.380859 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 390 | Batch: 000 / 039 | Total loss: 2.090 | Reg loss: 0.027 | Tree loss: 2.090 | Accuracy: 0.427734 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 391 | Batch: 000 / 039 | Total loss: 2.161 | Reg loss: 0.027 | Tree loss: 2.161 | Accuracy: 0.375000 | 0.059 sec/iter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 392 | Batch: 000 / 039 | Total loss: 2.094 | Reg loss: 0.027 | Tree loss: 2.094 | Accuracy: 0.423828 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 393 | Batch: 000 / 039 | Total loss: 2.139 | Reg loss: 0.027 | Tree loss: 2.139 | Accuracy: 0.408203 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 394 | Batch: 000 / 039 | Total loss: 2.114 | Reg loss: 0.027 | Tree loss: 2.114 | Accuracy: 0.417969 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 395 | Batch: 000 / 039 | Total loss: 2.120 | Reg loss: 0.027 | Tree loss: 2.120 | Accuracy: 0.390625 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 396 | Batch: 000 / 039 | Total loss: 2.149 | Reg loss: 0.027 | Tree loss: 2.149 | Accuracy: 0.396484 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 397 | Batch: 000 / 039 | Total loss: 2.046 | Reg loss: 0.027 | Tree loss: 2.046 | Accuracy: 0.406250 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 398 | Batch: 000 / 039 | Total loss: 2.166 | Reg loss: 0.027 | Tree loss: 2.166 | Accuracy: 0.369141 | 0.059 sec/iter\n",
      "Average sparseness: 0.984042553191489\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "Epoch: 399 | Batch: 000 / 039 | Total loss: 2.166 | Reg loss: 0.027 | Tree loss: 2.166 | Accuracy: 0.404297 | 0.059 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34fb5beaa194d16a7d13261d15908a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286f6ce5b53f40978c8ee47ccc7b0116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a54e9fb58048bf99af0e09d7e53b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb77865ceb6d42a0b4f7f7ca22fe903a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 5.222222222222222\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "254\n",
      "============== Pattern 2 ==============\n",
      "335\n",
      "============== Pattern 3 ==============\n",
      "1302\n",
      "============== Pattern 4 ==============\n",
      "1420\n",
      "============== Pattern 5 ==============\n",
      "============== Pattern 6 ==============\n",
      "626\n",
      "============== Pattern 7 ==============\n",
      "2427\n",
      "============== Pattern 8 ==============\n",
      "============== Pattern 9 ==============\n",
      "5248\n",
      "============== Pattern 10 ==============\n",
      "5396\n",
      "============== Pattern 11 ==============\n",
      "============== Pattern 12 ==============\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "526\n",
      "============== Pattern 16 ==============\n",
      "2386\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "Average comprehensibility: 28.333333333333332\n",
      "std comprehensibility: 8.034647195462632\n",
      "var comprehensibility: 64.55555555555556\n",
      "minimum comprehensibility: 4\n",
      "maximum comprehensibility: 34\n"
     ]
    }
   ],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
