{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 64\n",
    "tree_depth = 10\n",
    "batch_size = 512\n",
    "device = 'cpu'\n",
    "train_data_path = r'<>/mitbih_train.csv'  # replace <> with the correct path of the dataset\n",
    "test_data_path = r'<>/mitbih_test.csv'  # replace <> with the correct path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.611621379852295 | KNN Loss: 5.851576805114746 | CLS Loss: 1.7600445747375488\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 5.5411458015441895 | KNN Loss: 4.718804836273193 | CLS Loss: 0.8223410844802856\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 5.31278133392334 | KNN Loss: 4.556290626525879 | CLS Loss: 0.7564908266067505\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 5.130352973937988 | KNN Loss: 4.530723571777344 | CLS Loss: 0.5996293425559998\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 5.090763092041016 | KNN Loss: 4.479553699493408 | CLS Loss: 0.6112095713615417\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 5.027774810791016 | KNN Loss: 4.468639850616455 | CLS Loss: 0.5591350793838501\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 4.985223770141602 | KNN Loss: 4.48076868057251 | CLS Loss: 0.504455029964447\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 4.821516990661621 | KNN Loss: 4.4435038566589355 | CLS Loss: 0.3780133128166199\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 4.962495803833008 | KNN Loss: 4.435650825500488 | CLS Loss: 0.5268449783325195\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 4.769200801849365 | KNN Loss: 4.427261829376221 | CLS Loss: 0.3419388234615326\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 4.81560754776001 | KNN Loss: 4.373869895935059 | CLS Loss: 0.441737562417984\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 4.890377044677734 | KNN Loss: 4.434360027313232 | CLS Loss: 0.4560171365737915\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 4.88572359085083 | KNN Loss: 4.46038818359375 | CLS Loss: 0.42533546686172485\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 4.759463787078857 | KNN Loss: 4.39281702041626 | CLS Loss: 0.36664676666259766\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 4.750181674957275 | KNN Loss: 4.397143363952637 | CLS Loss: 0.3530382812023163\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 4.71118688583374 | KNN Loss: 4.366084098815918 | CLS Loss: 0.3451026380062103\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 4.622550010681152 | KNN Loss: 4.367143630981445 | CLS Loss: 0.25540629029273987\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 4.627360820770264 | KNN Loss: 4.353684425354004 | CLS Loss: 0.2736765742301941\n",
      "Epoch: 001, Loss: 5.0068, Train: 0.8971, Valid: 0.8964, Best: 0.8964\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 4.683085918426514 | KNN Loss: 4.390021800994873 | CLS Loss: 0.2930639386177063\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 4.704441070556641 | KNN Loss: 4.3702263832092285 | CLS Loss: 0.334214448928833\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 4.711410999298096 | KNN Loss: 4.354302406311035 | CLS Loss: 0.35710880160331726\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 4.735871315002441 | KNN Loss: 4.402227878570557 | CLS Loss: 0.3336436152458191\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 4.664397716522217 | KNN Loss: 4.3772125244140625 | CLS Loss: 0.28718528151512146\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 4.616510391235352 | KNN Loss: 4.344912052154541 | CLS Loss: 0.27159830927848816\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 4.70134973526001 | KNN Loss: 4.402566909790039 | CLS Loss: 0.2987828254699707\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 4.607325077056885 | KNN Loss: 4.327444076538086 | CLS Loss: 0.27988097071647644\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 4.67618465423584 | KNN Loss: 4.3903398513793945 | CLS Loss: 0.28584468364715576\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 4.60722541809082 | KNN Loss: 4.323575019836426 | CLS Loss: 0.2836504876613617\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 4.616159439086914 | KNN Loss: 4.394768238067627 | CLS Loss: 0.22139114141464233\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 4.680885314941406 | KNN Loss: 4.396765232086182 | CLS Loss: 0.2841198742389679\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 4.627459526062012 | KNN Loss: 4.394988059997559 | CLS Loss: 0.2324712574481964\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 4.59425687789917 | KNN Loss: 4.357606887817383 | CLS Loss: 0.23665006458759308\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 4.631478786468506 | KNN Loss: 4.3893046379089355 | CLS Loss: 0.24217422306537628\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 4.583636283874512 | KNN Loss: 4.3567609786987305 | CLS Loss: 0.22687509655952454\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 4.569571495056152 | KNN Loss: 4.370149612426758 | CLS Loss: 0.19942200183868408\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 4.5013203620910645 | KNN Loss: 4.351070404052734 | CLS Loss: 0.15025003254413605\n",
      "Epoch: 002, Loss: 4.6327, Train: 0.9546, Valid: 0.9531, Best: 0.9531\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 4.549570083618164 | KNN Loss: 4.358043670654297 | CLS Loss: 0.19152624905109406\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 4.496596336364746 | KNN Loss: 4.306181907653809 | CLS Loss: 0.1904146522283554\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 4.516887664794922 | KNN Loss: 4.324154376983643 | CLS Loss: 0.1927330493927002\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 4.516783237457275 | KNN Loss: 4.343451499938965 | CLS Loss: 0.17333151400089264\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 4.525296211242676 | KNN Loss: 4.325151443481445 | CLS Loss: 0.20014460384845734\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 4.5818939208984375 | KNN Loss: 4.320244789123535 | CLS Loss: 0.26164910197257996\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 4.495112895965576 | KNN Loss: 4.302645206451416 | CLS Loss: 0.19246774911880493\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 4.504261016845703 | KNN Loss: 4.294912815093994 | CLS Loss: 0.2093483954668045\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 4.497007846832275 | KNN Loss: 4.3255085945129395 | CLS Loss: 0.1714993417263031\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 4.4519829750061035 | KNN Loss: 4.261115550994873 | CLS Loss: 0.190867617726326\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 4.48825740814209 | KNN Loss: 4.3149094581604 | CLS Loss: 0.17334812879562378\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 4.511963844299316 | KNN Loss: 4.351291656494141 | CLS Loss: 0.16067209839820862\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 4.405401706695557 | KNN Loss: 4.294224739074707 | CLS Loss: 0.11117717623710632\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 4.418338298797607 | KNN Loss: 4.295818328857422 | CLS Loss: 0.12252001464366913\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 4.3820977210998535 | KNN Loss: 4.2910027503967285 | CLS Loss: 0.09109502285718918\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 4.44710111618042 | KNN Loss: 4.3017072677612305 | CLS Loss: 0.14539368450641632\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 4.4210968017578125 | KNN Loss: 4.284690856933594 | CLS Loss: 0.1364057958126068\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 4.359096050262451 | KNN Loss: 4.260099411010742 | CLS Loss: 0.09899664670228958\n",
      "Epoch: 003, Loss: 4.4798, Train: 0.9663, Valid: 0.9636, Best: 0.9636\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 4.41619348526001 | KNN Loss: 4.308671951293945 | CLS Loss: 0.10752169042825699\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 4.424130439758301 | KNN Loss: 4.283978462219238 | CLS Loss: 0.14015193283557892\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 4.376442909240723 | KNN Loss: 4.280007362365723 | CLS Loss: 0.09643537551164627\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 4.37608003616333 | KNN Loss: 4.226426124572754 | CLS Loss: 0.14965389668941498\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 4.441482067108154 | KNN Loss: 4.300647735595703 | CLS Loss: 0.1408344954252243\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 4.399204730987549 | KNN Loss: 4.268701553344727 | CLS Loss: 0.1305031180381775\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 4.4777913093566895 | KNN Loss: 4.312614917755127 | CLS Loss: 0.1651764214038849\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 4.373706817626953 | KNN Loss: 4.278258323669434 | CLS Loss: 0.09544871747493744\n",
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 4.4478607177734375 | KNN Loss: 4.313466548919678 | CLS Loss: 0.13439403474330902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 4.386694431304932 | KNN Loss: 4.247145175933838 | CLS Loss: 0.1395494043827057\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 4.374841690063477 | KNN Loss: 4.246660232543945 | CLS Loss: 0.12818162143230438\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 4.411810874938965 | KNN Loss: 4.282763481140137 | CLS Loss: 0.12904725968837738\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 4.402511119842529 | KNN Loss: 4.281371116638184 | CLS Loss: 0.12113998830318451\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 4.4582953453063965 | KNN Loss: 4.3242268562316895 | CLS Loss: 0.13406848907470703\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 4.4174981117248535 | KNN Loss: 4.270980358123779 | CLS Loss: 0.14651760458946228\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 4.4136857986450195 | KNN Loss: 4.308887958526611 | CLS Loss: 0.10479802638292313\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 4.330372333526611 | KNN Loss: 4.249135971069336 | CLS Loss: 0.08123648166656494\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 4.35697603225708 | KNN Loss: 4.256400108337402 | CLS Loss: 0.10057610273361206\n",
      "Epoch: 004, Loss: 4.4131, Train: 0.9721, Valid: 0.9703, Best: 0.9703\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 4.3515095710754395 | KNN Loss: 4.258777141571045 | CLS Loss: 0.09273229539394379\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 4.354401588439941 | KNN Loss: 4.2752180099487305 | CLS Loss: 0.07918364554643631\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 4.443954944610596 | KNN Loss: 4.309277057647705 | CLS Loss: 0.13467787206172943\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 4.365910530090332 | KNN Loss: 4.258974075317383 | CLS Loss: 0.10693636536598206\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 4.358325004577637 | KNN Loss: 4.224021911621094 | CLS Loss: 0.13430291414260864\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 4.355473041534424 | KNN Loss: 4.252901554107666 | CLS Loss: 0.10257133096456528\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 4.352200984954834 | KNN Loss: 4.249208927154541 | CLS Loss: 0.10299217700958252\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 4.393860340118408 | KNN Loss: 4.287680149078369 | CLS Loss: 0.10618020594120026\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 4.377012729644775 | KNN Loss: 4.2691731452941895 | CLS Loss: 0.10783946514129639\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 4.360005855560303 | KNN Loss: 4.234751224517822 | CLS Loss: 0.12525449693202972\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 4.382213115692139 | KNN Loss: 4.271281719207764 | CLS Loss: 0.1109314039349556\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 4.355181694030762 | KNN Loss: 4.251408100128174 | CLS Loss: 0.10377345234155655\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 4.421258449554443 | KNN Loss: 4.296829700469971 | CLS Loss: 0.12442896515130997\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 4.369630336761475 | KNN Loss: 4.263290882110596 | CLS Loss: 0.10633958131074905\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 4.335392475128174 | KNN Loss: 4.245337963104248 | CLS Loss: 0.09005448967218399\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 4.3757004737854 | KNN Loss: 4.281091690063477 | CLS Loss: 0.09460890293121338\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 4.373769760131836 | KNN Loss: 4.2742109298706055 | CLS Loss: 0.09955883026123047\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 4.312808990478516 | KNN Loss: 4.217874050140381 | CLS Loss: 0.09493516385555267\n",
      "Epoch: 005, Loss: 4.3653, Train: 0.9764, Valid: 0.9743, Best: 0.9743\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 4.349104404449463 | KNN Loss: 4.252679347991943 | CLS Loss: 0.09642523527145386\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 4.330130577087402 | KNN Loss: 4.261727809906006 | CLS Loss: 0.06840299069881439\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 4.402382850646973 | KNN Loss: 4.296156406402588 | CLS Loss: 0.10622657090425491\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 4.324352741241455 | KNN Loss: 4.193814754486084 | CLS Loss: 0.1305379867553711\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 4.368525981903076 | KNN Loss: 4.278532981872559 | CLS Loss: 0.08999299257993698\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 4.3328423500061035 | KNN Loss: 4.249400615692139 | CLS Loss: 0.08344161510467529\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 4.3402814865112305 | KNN Loss: 4.259179592132568 | CLS Loss: 0.08110203593969345\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 4.372375011444092 | KNN Loss: 4.287220478057861 | CLS Loss: 0.08515476435422897\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 4.3537917137146 | KNN Loss: 4.249115467071533 | CLS Loss: 0.10467617958784103\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 4.3255157470703125 | KNN Loss: 4.23876428604126 | CLS Loss: 0.08675165474414825\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 4.387969970703125 | KNN Loss: 4.289342880249023 | CLS Loss: 0.09862715005874634\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 4.357921600341797 | KNN Loss: 4.2846903800964355 | CLS Loss: 0.07323145866394043\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 4.3260416984558105 | KNN Loss: 4.245081424713135 | CLS Loss: 0.08096031844615936\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 4.335010528564453 | KNN Loss: 4.220292568206787 | CLS Loss: 0.1147179901599884\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 4.377788066864014 | KNN Loss: 4.234306812286377 | CLS Loss: 0.14348119497299194\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 4.3240156173706055 | KNN Loss: 4.221759796142578 | CLS Loss: 0.10225564241409302\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 4.311607837677002 | KNN Loss: 4.213702201843262 | CLS Loss: 0.09790543466806412\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 4.343178749084473 | KNN Loss: 4.260725498199463 | CLS Loss: 0.08245312422513962\n",
      "Epoch: 006, Loss: 4.3461, Train: 0.9762, Valid: 0.9725, Best: 0.9743\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 4.306669235229492 | KNN Loss: 4.220757007598877 | CLS Loss: 0.08591241389513016\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 4.322779178619385 | KNN Loss: 4.202329158782959 | CLS Loss: 0.12045001983642578\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 4.33075475692749 | KNN Loss: 4.25063419342041 | CLS Loss: 0.08012060075998306\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 4.308619022369385 | KNN Loss: 4.219819068908691 | CLS Loss: 0.0888001099228859\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 4.291591167449951 | KNN Loss: 4.241945743560791 | CLS Loss: 0.049645405262708664\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 4.384220123291016 | KNN Loss: 4.27213191986084 | CLS Loss: 0.1120881512761116\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 4.314243316650391 | KNN Loss: 4.2309184074401855 | CLS Loss: 0.08332492411136627\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 4.335052967071533 | KNN Loss: 4.231462001800537 | CLS Loss: 0.10359074175357819\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 4.324377059936523 | KNN Loss: 4.2544121742248535 | CLS Loss: 0.06996487081050873\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 4.340202331542969 | KNN Loss: 4.250120639801025 | CLS Loss: 0.09008172154426575\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 4.339155197143555 | KNN Loss: 4.233553886413574 | CLS Loss: 0.10560149699449539\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 4.282501220703125 | KNN Loss: 4.2101545333862305 | CLS Loss: 0.07234656065702438\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 4.313683032989502 | KNN Loss: 4.228367805480957 | CLS Loss: 0.08531540632247925\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 4.291323184967041 | KNN Loss: 4.205726623535156 | CLS Loss: 0.08559642732143402\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 4.307826995849609 | KNN Loss: 4.226057052612305 | CLS Loss: 0.0817699059844017\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 4.341269016265869 | KNN Loss: 4.254546642303467 | CLS Loss: 0.08672234416007996\n",
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 4.334161281585693 | KNN Loss: 4.228261947631836 | CLS Loss: 0.105899378657341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 4.397749900817871 | KNN Loss: 4.290170669555664 | CLS Loss: 0.10757926106452942\n",
      "Epoch: 007, Loss: 4.3257, Train: 0.9791, Valid: 0.9756, Best: 0.9756\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 4.312385082244873 | KNN Loss: 4.230754852294922 | CLS Loss: 0.08163004368543625\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 4.3073225021362305 | KNN Loss: 4.232346534729004 | CLS Loss: 0.07497601956129074\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 4.376765727996826 | KNN Loss: 4.256069183349609 | CLS Loss: 0.12069671601057053\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 4.250857830047607 | KNN Loss: 4.192142486572266 | CLS Loss: 0.0587153285741806\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 4.308696269989014 | KNN Loss: 4.215068340301514 | CLS Loss: 0.09362789988517761\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 4.2926836013793945 | KNN Loss: 4.228835582733154 | CLS Loss: 0.06384791433811188\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 4.323232650756836 | KNN Loss: 4.249416828155518 | CLS Loss: 0.0738159641623497\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 4.31165075302124 | KNN Loss: 4.218843936920166 | CLS Loss: 0.09280704706907272\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 4.336077690124512 | KNN Loss: 4.2572760581970215 | CLS Loss: 0.0788017138838768\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 4.292585849761963 | KNN Loss: 4.2071533203125 | CLS Loss: 0.08543244749307632\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 4.283128261566162 | KNN Loss: 4.206029415130615 | CLS Loss: 0.07709892094135284\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 4.342762470245361 | KNN Loss: 4.270188808441162 | CLS Loss: 0.07257366925477982\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 4.342081069946289 | KNN Loss: 4.233212471008301 | CLS Loss: 0.10886857658624649\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 4.283926010131836 | KNN Loss: 4.217048168182373 | CLS Loss: 0.06687802821397781\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 4.357478141784668 | KNN Loss: 4.255409240722656 | CLS Loss: 0.10206908732652664\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 4.314809322357178 | KNN Loss: 4.227506637573242 | CLS Loss: 0.08730251342058182\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 4.332649230957031 | KNN Loss: 4.2308573722839355 | CLS Loss: 0.10179197788238525\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 4.338685512542725 | KNN Loss: 4.250058650970459 | CLS Loss: 0.08862666040658951\n",
      "Epoch: 008, Loss: 4.3125, Train: 0.9780, Valid: 0.9750, Best: 0.9756\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 4.249859809875488 | KNN Loss: 4.178689479827881 | CLS Loss: 0.07117033749818802\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 4.307625770568848 | KNN Loss: 4.22252893447876 | CLS Loss: 0.08509689569473267\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 4.227181911468506 | KNN Loss: 4.17432975769043 | CLS Loss: 0.05285220965743065\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 4.311478137969971 | KNN Loss: 4.230576992034912 | CLS Loss: 0.08090097457170486\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 4.343900680541992 | KNN Loss: 4.222944736480713 | CLS Loss: 0.12095598131418228\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 4.309298992156982 | KNN Loss: 4.2324347496032715 | CLS Loss: 0.07686445116996765\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 4.333393096923828 | KNN Loss: 4.240538120269775 | CLS Loss: 0.09285487979650497\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 4.298548698425293 | KNN Loss: 4.266607761383057 | CLS Loss: 0.03194096311926842\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 4.321589469909668 | KNN Loss: 4.194812774658203 | CLS Loss: 0.12677672505378723\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 4.2999982833862305 | KNN Loss: 4.2596306800842285 | CLS Loss: 0.040367648005485535\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 4.281786918640137 | KNN Loss: 4.212344169616699 | CLS Loss: 0.06944295763969421\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 4.35133695602417 | KNN Loss: 4.24182653427124 | CLS Loss: 0.10951025784015656\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 4.329930305480957 | KNN Loss: 4.268156051635742 | CLS Loss: 0.061774320900440216\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 4.305808067321777 | KNN Loss: 4.2092719078063965 | CLS Loss: 0.09653592109680176\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 4.272549629211426 | KNN Loss: 4.219031810760498 | CLS Loss: 0.05351792648434639\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 4.280515193939209 | KNN Loss: 4.199438571929932 | CLS Loss: 0.08107685297727585\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 4.255158424377441 | KNN Loss: 4.1739654541015625 | CLS Loss: 0.08119307458400726\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 4.325014114379883 | KNN Loss: 4.2350239753723145 | CLS Loss: 0.08999019861221313\n",
      "Epoch: 009, Loss: 4.3113, Train: 0.9808, Valid: 0.9769, Best: 0.9769\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 4.358110427856445 | KNN Loss: 4.26383638381958 | CLS Loss: 0.0942738950252533\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 4.304518699645996 | KNN Loss: 4.250286102294922 | CLS Loss: 0.0542323961853981\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 4.320633888244629 | KNN Loss: 4.209327697753906 | CLS Loss: 0.11130641400814056\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 4.284289836883545 | KNN Loss: 4.2117600440979 | CLS Loss: 0.07252970337867737\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 4.342254161834717 | KNN Loss: 4.269453048706055 | CLS Loss: 0.07280097156763077\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 4.2837138175964355 | KNN Loss: 4.22555685043335 | CLS Loss: 0.05815674364566803\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 4.271778106689453 | KNN Loss: 4.220707893371582 | CLS Loss: 0.05107037350535393\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 4.298710346221924 | KNN Loss: 4.193081378936768 | CLS Loss: 0.10562904179096222\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 4.31454610824585 | KNN Loss: 4.22811222076416 | CLS Loss: 0.08643410354852676\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 4.310686111450195 | KNN Loss: 4.220549583435059 | CLS Loss: 0.09013664722442627\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 4.287454605102539 | KNN Loss: 4.212466716766357 | CLS Loss: 0.07498812675476074\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 4.325830459594727 | KNN Loss: 4.254579067230225 | CLS Loss: 0.07125159353017807\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 4.276435375213623 | KNN Loss: 4.208069324493408 | CLS Loss: 0.06836584955453873\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 4.280700206756592 | KNN Loss: 4.232442855834961 | CLS Loss: 0.048257552087306976\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 4.315670967102051 | KNN Loss: 4.217471599578857 | CLS Loss: 0.09819957613945007\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 4.252084732055664 | KNN Loss: 4.20953369140625 | CLS Loss: 0.04255085811018944\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 4.315456390380859 | KNN Loss: 4.241064071655273 | CLS Loss: 0.0743923932313919\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 4.275904655456543 | KNN Loss: 4.198632717132568 | CLS Loss: 0.0772717222571373\n",
      "Epoch: 010, Loss: 4.2942, Train: 0.9826, Valid: 0.9788, Best: 0.9788\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 4.308160781860352 | KNN Loss: 4.243295192718506 | CLS Loss: 0.06486540287733078\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 4.299249172210693 | KNN Loss: 4.201204299926758 | CLS Loss: 0.0980449691414833\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 4.335267066955566 | KNN Loss: 4.239528656005859 | CLS Loss: 0.09573838114738464\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 4.290850639343262 | KNN Loss: 4.205672740936279 | CLS Loss: 0.08517807722091675\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 4.259593486785889 | KNN Loss: 4.204894542694092 | CLS Loss: 0.05469892919063568\n",
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 4.270247459411621 | KNN Loss: 4.198846817016602 | CLS Loss: 0.07140065729618073\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 4.296922206878662 | KNN Loss: 4.233614444732666 | CLS Loss: 0.06330766528844833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 4.251927375793457 | KNN Loss: 4.207891941070557 | CLS Loss: 0.044035378843545914\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 4.266667366027832 | KNN Loss: 4.218547344207764 | CLS Loss: 0.048120222985744476\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 4.2895026206970215 | KNN Loss: 4.229923248291016 | CLS Loss: 0.05957914888858795\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 4.284947395324707 | KNN Loss: 4.229155540466309 | CLS Loss: 0.05579190328717232\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 4.2707695960998535 | KNN Loss: 4.1840410232543945 | CLS Loss: 0.08672859519720078\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 4.274397373199463 | KNN Loss: 4.226527690887451 | CLS Loss: 0.04786955937743187\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 4.230456829071045 | KNN Loss: 4.206214427947998 | CLS Loss: 0.024242430925369263\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 4.3067755699157715 | KNN Loss: 4.2267656326293945 | CLS Loss: 0.08001016080379486\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 4.270424842834473 | KNN Loss: 4.209024906158447 | CLS Loss: 0.061399996280670166\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 4.250519275665283 | KNN Loss: 4.2033562660217285 | CLS Loss: 0.047163039445877075\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 4.277907848358154 | KNN Loss: 4.175974369049072 | CLS Loss: 0.10193344205617905\n",
      "Epoch: 011, Loss: 4.2826, Train: 0.9840, Valid: 0.9797, Best: 0.9797\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 4.2733893394470215 | KNN Loss: 4.187991142272949 | CLS Loss: 0.08539809286594391\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 4.275954723358154 | KNN Loss: 4.223459243774414 | CLS Loss: 0.052495453506708145\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 4.293971538543701 | KNN Loss: 4.213913440704346 | CLS Loss: 0.080058254301548\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 4.256170749664307 | KNN Loss: 4.205733776092529 | CLS Loss: 0.050436798483133316\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 4.286611080169678 | KNN Loss: 4.180328845977783 | CLS Loss: 0.1062823161482811\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 4.292690753936768 | KNN Loss: 4.172397613525391 | CLS Loss: 0.12029313296079636\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 4.276611804962158 | KNN Loss: 4.218868255615234 | CLS Loss: 0.05774374306201935\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 4.243494033813477 | KNN Loss: 4.207220077514648 | CLS Loss: 0.0362740121781826\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 4.308536052703857 | KNN Loss: 4.219239234924316 | CLS Loss: 0.08929695188999176\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 4.257411479949951 | KNN Loss: 4.215643882751465 | CLS Loss: 0.04176761582493782\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 4.373981952667236 | KNN Loss: 4.252976417541504 | CLS Loss: 0.12100552022457123\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 4.252340316772461 | KNN Loss: 4.162806034088135 | CLS Loss: 0.08953414857387543\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 4.286644458770752 | KNN Loss: 4.223544120788574 | CLS Loss: 0.06310044974088669\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 4.344040393829346 | KNN Loss: 4.231080532073975 | CLS Loss: 0.11295998841524124\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 4.31449556350708 | KNN Loss: 4.278981685638428 | CLS Loss: 0.035513702780008316\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 4.296776294708252 | KNN Loss: 4.23402738571167 | CLS Loss: 0.06274901330471039\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 4.222854137420654 | KNN Loss: 4.171102046966553 | CLS Loss: 0.05175212025642395\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 4.288519382476807 | KNN Loss: 4.2177019119262695 | CLS Loss: 0.07081738114356995\n",
      "Epoch: 012, Loss: 4.2759, Train: 0.9854, Valid: 0.9811, Best: 0.9811\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 4.237201690673828 | KNN Loss: 4.174461364746094 | CLS Loss: 0.06274028867483139\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 4.238681793212891 | KNN Loss: 4.1915669441223145 | CLS Loss: 0.04711495712399483\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 4.281309604644775 | KNN Loss: 4.232873439788818 | CLS Loss: 0.04843619465827942\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 4.25327730178833 | KNN Loss: 4.216115951538086 | CLS Loss: 0.03716152533888817\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 4.307283878326416 | KNN Loss: 4.2559943199157715 | CLS Loss: 0.051289770752191544\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 4.251346111297607 | KNN Loss: 4.2108917236328125 | CLS Loss: 0.04045458137989044\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 4.227444171905518 | KNN Loss: 4.201801776885986 | CLS Loss: 0.025642184540629387\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 4.244142055511475 | KNN Loss: 4.179067134857178 | CLS Loss: 0.06507512181997299\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 4.232262134552002 | KNN Loss: 4.176147937774658 | CLS Loss: 0.05611412599682808\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 4.298109531402588 | KNN Loss: 4.1994805335998535 | CLS Loss: 0.09862880408763885\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 4.237475872039795 | KNN Loss: 4.191085338592529 | CLS Loss: 0.04639063775539398\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 4.3029046058654785 | KNN Loss: 4.228585243225098 | CLS Loss: 0.07431920617818832\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 4.293213844299316 | KNN Loss: 4.237031936645508 | CLS Loss: 0.05618182197213173\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 4.337301731109619 | KNN Loss: 4.264865875244141 | CLS Loss: 0.07243570685386658\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 4.2767181396484375 | KNN Loss: 4.199021816253662 | CLS Loss: 0.07769620418548584\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 4.232604503631592 | KNN Loss: 4.199129581451416 | CLS Loss: 0.033475007861852646\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 4.228484153747559 | KNN Loss: 4.199090480804443 | CLS Loss: 0.029393622651696205\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 4.206731796264648 | KNN Loss: 4.178916931152344 | CLS Loss: 0.02781476266682148\n",
      "Epoch: 013, Loss: 4.2689, Train: 0.9852, Valid: 0.9812, Best: 0.9812\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 4.265677452087402 | KNN Loss: 4.1829118728637695 | CLS Loss: 0.08276534080505371\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 4.254848957061768 | KNN Loss: 4.180025100708008 | CLS Loss: 0.0748240202665329\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 4.299544811248779 | KNN Loss: 4.230672836303711 | CLS Loss: 0.06887191534042358\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 4.286202907562256 | KNN Loss: 4.219621181488037 | CLS Loss: 0.06658149510622025\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 4.322986125946045 | KNN Loss: 4.251223564147949 | CLS Loss: 0.07176259905099869\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 4.22105073928833 | KNN Loss: 4.1893630027771 | CLS Loss: 0.03168755769729614\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 4.267758846282959 | KNN Loss: 4.217201232910156 | CLS Loss: 0.05055765435099602\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 4.230079650878906 | KNN Loss: 4.176714897155762 | CLS Loss: 0.05336495116353035\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 4.290803909301758 | KNN Loss: 4.226348876953125 | CLS Loss: 0.06445486843585968\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 4.273728370666504 | KNN Loss: 4.212497234344482 | CLS Loss: 0.06123122572898865\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 4.293529033660889 | KNN Loss: 4.21659517288208 | CLS Loss: 0.07693378627300262\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 4.2422075271606445 | KNN Loss: 4.18757963180542 | CLS Loss: 0.05462774634361267\n",
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 4.296651363372803 | KNN Loss: 4.203375816345215 | CLS Loss: 0.09327568113803864\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 4.266418933868408 | KNN Loss: 4.211954593658447 | CLS Loss: 0.05446454510092735\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 4.232828140258789 | KNN Loss: 4.221839904785156 | CLS Loss: 0.01098803523927927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 4.281956672668457 | KNN Loss: 4.200355529785156 | CLS Loss: 0.08160095661878586\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 4.22836971282959 | KNN Loss: 4.184549331665039 | CLS Loss: 0.043820470571517944\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 4.241146087646484 | KNN Loss: 4.2008819580078125 | CLS Loss: 0.04026389122009277\n",
      "Epoch: 014, Loss: 4.2620, Train: 0.9862, Valid: 0.9815, Best: 0.9815\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 4.280323505401611 | KNN Loss: 4.223146438598633 | CLS Loss: 0.057177189737558365\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 4.249734878540039 | KNN Loss: 4.201269149780273 | CLS Loss: 0.048465877771377563\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 4.280198574066162 | KNN Loss: 4.216894626617432 | CLS Loss: 0.06330376863479614\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 4.236361980438232 | KNN Loss: 4.186278343200684 | CLS Loss: 0.050083499401807785\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 4.185341835021973 | KNN Loss: 4.137538433074951 | CLS Loss: 0.04780350625514984\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 4.257046699523926 | KNN Loss: 4.205088138580322 | CLS Loss: 0.051958613097667694\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 4.24329137802124 | KNN Loss: 4.207573890686035 | CLS Loss: 0.035717494785785675\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 4.226019859313965 | KNN Loss: 4.166895389556885 | CLS Loss: 0.059124525636434555\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 4.238317966461182 | KNN Loss: 4.208288192749023 | CLS Loss: 0.03002992644906044\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 4.239238739013672 | KNN Loss: 4.196324825286865 | CLS Loss: 0.042914122343063354\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 4.240777492523193 | KNN Loss: 4.175308704376221 | CLS Loss: 0.0654686987400055\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 4.219423294067383 | KNN Loss: 4.170022964477539 | CLS Loss: 0.04940023645758629\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 4.284239768981934 | KNN Loss: 4.222855567932129 | CLS Loss: 0.061384040862321854\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 4.26997709274292 | KNN Loss: 4.199350357055664 | CLS Loss: 0.07062659412622452\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 4.285110950469971 | KNN Loss: 4.218565464019775 | CLS Loss: 0.06654532253742218\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 4.251786708831787 | KNN Loss: 4.190793991088867 | CLS Loss: 0.06099279969930649\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 4.207783222198486 | KNN Loss: 4.177453994750977 | CLS Loss: 0.03032936528325081\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 4.272474765777588 | KNN Loss: 4.229244232177734 | CLS Loss: 0.04323076829314232\n",
      "Epoch: 015, Loss: 4.2566, Train: 0.9870, Valid: 0.9824, Best: 0.9824\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 4.251777172088623 | KNN Loss: 4.215699195861816 | CLS Loss: 0.03607778623700142\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 4.237686634063721 | KNN Loss: 4.1970601081848145 | CLS Loss: 0.040626395493745804\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 4.241903305053711 | KNN Loss: 4.215868949890137 | CLS Loss: 0.026034492999315262\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 4.288908958435059 | KNN Loss: 4.2113542556762695 | CLS Loss: 0.07755474746227264\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 4.231616497039795 | KNN Loss: 4.201464653015137 | CLS Loss: 0.030151931568980217\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 4.2672295570373535 | KNN Loss: 4.1916680335998535 | CLS Loss: 0.07556149363517761\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 4.274068355560303 | KNN Loss: 4.209775924682617 | CLS Loss: 0.06429241597652435\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 4.271853446960449 | KNN Loss: 4.212925434112549 | CLS Loss: 0.058928001672029495\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 4.198179721832275 | KNN Loss: 4.168003082275391 | CLS Loss: 0.03017650917172432\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 4.270309925079346 | KNN Loss: 4.224460601806641 | CLS Loss: 0.04584934934973717\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 4.234199047088623 | KNN Loss: 4.170767307281494 | CLS Loss: 0.06343171745538712\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 4.315767765045166 | KNN Loss: 4.252278804779053 | CLS Loss: 0.06348896771669388\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 4.2483978271484375 | KNN Loss: 4.206203460693359 | CLS Loss: 0.04219432175159454\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 4.19281005859375 | KNN Loss: 4.162719249725342 | CLS Loss: 0.030090900138020515\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 4.22520112991333 | KNN Loss: 4.190517902374268 | CLS Loss: 0.03468310087919235\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 4.233469009399414 | KNN Loss: 4.175803184509277 | CLS Loss: 0.057665593922138214\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 4.2389349937438965 | KNN Loss: 4.186534881591797 | CLS Loss: 0.05240010842680931\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 4.242326736450195 | KNN Loss: 4.175107002258301 | CLS Loss: 0.06721964478492737\n",
      "Epoch: 016, Loss: 4.2530, Train: 0.9880, Valid: 0.9832, Best: 0.9832\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 4.241049289703369 | KNN Loss: 4.182159900665283 | CLS Loss: 0.058889612555503845\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 4.225570201873779 | KNN Loss: 4.182565212249756 | CLS Loss: 0.04300522431731224\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 4.247630596160889 | KNN Loss: 4.204816818237305 | CLS Loss: 0.042813852429389954\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 4.259002685546875 | KNN Loss: 4.192216396331787 | CLS Loss: 0.06678616255521774\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 4.244196891784668 | KNN Loss: 4.200846195220947 | CLS Loss: 0.04335060343146324\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 4.273814678192139 | KNN Loss: 4.186703205108643 | CLS Loss: 0.08711150288581848\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 4.287201404571533 | KNN Loss: 4.21101713180542 | CLS Loss: 0.07618433982133865\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 4.248358249664307 | KNN Loss: 4.18728494644165 | CLS Loss: 0.061073485761880875\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 4.236809730529785 | KNN Loss: 4.184266090393066 | CLS Loss: 0.05254356935620308\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 4.274263381958008 | KNN Loss: 4.186175346374512 | CLS Loss: 0.08808813244104385\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 4.2645721435546875 | KNN Loss: 4.2111053466796875 | CLS Loss: 0.053466737270355225\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 4.293703079223633 | KNN Loss: 4.2062087059021 | CLS Loss: 0.0874943733215332\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 4.248506546020508 | KNN Loss: 4.21951150894165 | CLS Loss: 0.028995268046855927\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 4.2131028175354 | KNN Loss: 4.181978225708008 | CLS Loss: 0.03112439252436161\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 4.2159857749938965 | KNN Loss: 4.1842122077941895 | CLS Loss: 0.031773630529642105\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 4.256143093109131 | KNN Loss: 4.192991256713867 | CLS Loss: 0.06315205991268158\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 4.253147125244141 | KNN Loss: 4.219510555267334 | CLS Loss: 0.03363671153783798\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 4.227325916290283 | KNN Loss: 4.165421485900879 | CLS Loss: 0.061904311180114746\n",
      "Epoch: 017, Loss: 4.2470, Train: 0.9881, Valid: 0.9831, Best: 0.9832\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 4.262733459472656 | KNN Loss: 4.1669087409973145 | CLS Loss: 0.0958249494433403\n",
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 4.221471309661865 | KNN Loss: 4.181858539581299 | CLS Loss: 0.039612848311662674\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 4.234887599945068 | KNN Loss: 4.1705403327941895 | CLS Loss: 0.06434742361307144\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 4.239408016204834 | KNN Loss: 4.196161270141602 | CLS Loss: 0.04324676841497421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 4.221866607666016 | KNN Loss: 4.176784038543701 | CLS Loss: 0.045082446187734604\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 4.240352630615234 | KNN Loss: 4.170080661773682 | CLS Loss: 0.07027196884155273\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 4.244841575622559 | KNN Loss: 4.174323081970215 | CLS Loss: 0.07051845639944077\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 4.205639839172363 | KNN Loss: 4.166610240936279 | CLS Loss: 0.03902976214885712\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 4.27803897857666 | KNN Loss: 4.193373203277588 | CLS Loss: 0.08466577529907227\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 4.326822280883789 | KNN Loss: 4.255382061004639 | CLS Loss: 0.07144034653902054\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 4.2749223709106445 | KNN Loss: 4.216742038726807 | CLS Loss: 0.058180514723062515\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 4.212435722351074 | KNN Loss: 4.16302490234375 | CLS Loss: 0.049410734325647354\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 4.237663269042969 | KNN Loss: 4.19282865524292 | CLS Loss: 0.04483455792069435\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 4.301581382751465 | KNN Loss: 4.239055156707764 | CLS Loss: 0.06252607703208923\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 4.208593368530273 | KNN Loss: 4.18662691116333 | CLS Loss: 0.02196628972887993\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 4.203534126281738 | KNN Loss: 4.146488189697266 | CLS Loss: 0.05704597383737564\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 4.225095748901367 | KNN Loss: 4.162949562072754 | CLS Loss: 0.06214601919054985\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 4.2526774406433105 | KNN Loss: 4.191262722015381 | CLS Loss: 0.061414532363414764\n",
      "Epoch: 018, Loss: 4.2437, Train: 0.9876, Valid: 0.9832, Best: 0.9832\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 4.273997783660889 | KNN Loss: 4.2222371101379395 | CLS Loss: 0.051760751754045486\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 4.239907741546631 | KNN Loss: 4.205995082855225 | CLS Loss: 0.033912889659404755\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 4.220357418060303 | KNN Loss: 4.178022861480713 | CLS Loss: 0.042334526777267456\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 4.22669792175293 | KNN Loss: 4.187380790710449 | CLS Loss: 0.03931720554828644\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 4.23773717880249 | KNN Loss: 4.203018665313721 | CLS Loss: 0.034718431532382965\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 4.1967315673828125 | KNN Loss: 4.160373687744141 | CLS Loss: 0.03635803982615471\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 4.203675746917725 | KNN Loss: 4.173589706420898 | CLS Loss: 0.030085859820246696\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 4.210849285125732 | KNN Loss: 4.1902666091918945 | CLS Loss: 0.020582888275384903\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 4.223211765289307 | KNN Loss: 4.172610282897949 | CLS Loss: 0.0506012849509716\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 4.260248184204102 | KNN Loss: 4.217975616455078 | CLS Loss: 0.042272765189409256\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 4.219169616699219 | KNN Loss: 4.181570053100586 | CLS Loss: 0.037599366158246994\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 4.206498146057129 | KNN Loss: 4.17378044128418 | CLS Loss: 0.03271759673953056\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 4.206852912902832 | KNN Loss: 4.182109832763672 | CLS Loss: 0.024743128567934036\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 4.222068786621094 | KNN Loss: 4.163333415985107 | CLS Loss: 0.0587352029979229\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 4.267151832580566 | KNN Loss: 4.2041473388671875 | CLS Loss: 0.06300473213195801\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 4.222689628601074 | KNN Loss: 4.185440540313721 | CLS Loss: 0.03724892437458038\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 4.26152229309082 | KNN Loss: 4.198799133300781 | CLS Loss: 0.06272325664758682\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 4.227569103240967 | KNN Loss: 4.1778693199157715 | CLS Loss: 0.04969997704029083\n",
      "Epoch: 019, Loss: 4.2347, Train: 0.9887, Valid: 0.9831, Best: 0.9832\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 4.188701152801514 | KNN Loss: 4.161196708679199 | CLS Loss: 0.027504585683345795\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 4.261476516723633 | KNN Loss: 4.216015815734863 | CLS Loss: 0.045460570603609085\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 4.216848373413086 | KNN Loss: 4.1668901443481445 | CLS Loss: 0.04995808005332947\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 4.234890460968018 | KNN Loss: 4.183827877044678 | CLS Loss: 0.051062777638435364\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 4.21536111831665 | KNN Loss: 4.161759853363037 | CLS Loss: 0.053601425141096115\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 4.247998237609863 | KNN Loss: 4.206161022186279 | CLS Loss: 0.04183714836835861\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 4.2290496826171875 | KNN Loss: 4.190214157104492 | CLS Loss: 0.03883569687604904\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 4.2222580909729 | KNN Loss: 4.18748140335083 | CLS Loss: 0.03477657213807106\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 4.2091217041015625 | KNN Loss: 4.179431438446045 | CLS Loss: 0.029690289869904518\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 4.28180456161499 | KNN Loss: 4.239589214324951 | CLS Loss: 0.04221551492810249\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 4.213773727416992 | KNN Loss: 4.157088756561279 | CLS Loss: 0.056685078889131546\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 4.273961067199707 | KNN Loss: 4.2261834144592285 | CLS Loss: 0.04777764156460762\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 4.2939252853393555 | KNN Loss: 4.208548545837402 | CLS Loss: 0.08537674695253372\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 4.219393730163574 | KNN Loss: 4.186666011810303 | CLS Loss: 0.03272760286927223\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 4.259698867797852 | KNN Loss: 4.224438190460205 | CLS Loss: 0.03526059538125992\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 4.219211578369141 | KNN Loss: 4.160623073577881 | CLS Loss: 0.05858873575925827\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 4.280232906341553 | KNN Loss: 4.197350025177002 | CLS Loss: 0.08288294076919556\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 4.269714832305908 | KNN Loss: 4.225518226623535 | CLS Loss: 0.044196657836437225\n",
      "Epoch: 020, Loss: 4.2346, Train: 0.9860, Valid: 0.9810, Best: 0.9832\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 4.296511173248291 | KNN Loss: 4.233304023742676 | CLS Loss: 0.06320713460445404\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 4.2149858474731445 | KNN Loss: 4.171863555908203 | CLS Loss: 0.04312210530042648\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 4.248507499694824 | KNN Loss: 4.208264350891113 | CLS Loss: 0.040243279188871384\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 4.243800163269043 | KNN Loss: 4.179701805114746 | CLS Loss: 0.06409823894500732\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 4.280942916870117 | KNN Loss: 4.216348171234131 | CLS Loss: 0.0645945593714714\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 4.261185646057129 | KNN Loss: 4.205315113067627 | CLS Loss: 0.05587049946188927\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 4.30715274810791 | KNN Loss: 4.225643157958984 | CLS Loss: 0.08150967210531235\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 4.220312118530273 | KNN Loss: 4.204966068267822 | CLS Loss: 0.01534584816545248\n",
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 4.249849796295166 | KNN Loss: 4.175313949584961 | CLS Loss: 0.07453568279743195\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 4.226910591125488 | KNN Loss: 4.196876049041748 | CLS Loss: 0.030034659430384636\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 4.249350070953369 | KNN Loss: 4.228160381317139 | CLS Loss: 0.02118959091603756\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 4.1834635734558105 | KNN Loss: 4.170332908630371 | CLS Loss: 0.01313081756234169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 4.198505401611328 | KNN Loss: 4.171528339385986 | CLS Loss: 0.026977157220244408\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 4.295622825622559 | KNN Loss: 4.226320743560791 | CLS Loss: 0.06930216401815414\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 4.1923346519470215 | KNN Loss: 4.14118766784668 | CLS Loss: 0.05114692822098732\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 4.224180698394775 | KNN Loss: 4.167666435241699 | CLS Loss: 0.05651447921991348\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 4.245595932006836 | KNN Loss: 4.19228458404541 | CLS Loss: 0.05331148952245712\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 4.250962257385254 | KNN Loss: 4.175938606262207 | CLS Loss: 0.07502368092536926\n",
      "Epoch: 021, Loss: 4.2320, Train: 0.9897, Valid: 0.9838, Best: 0.9838\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 4.24685001373291 | KNN Loss: 4.210028171539307 | CLS Loss: 0.0368216298520565\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 4.236832618713379 | KNN Loss: 4.213662624359131 | CLS Loss: 0.0231699850410223\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 4.232785224914551 | KNN Loss: 4.183803081512451 | CLS Loss: 0.048982057720422745\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 4.235447883605957 | KNN Loss: 4.162500381469727 | CLS Loss: 0.07294750213623047\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 4.186985492706299 | KNN Loss: 4.168638706207275 | CLS Loss: 0.018346698954701424\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 4.236748695373535 | KNN Loss: 4.176616191864014 | CLS Loss: 0.06013239547610283\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 4.2274956703186035 | KNN Loss: 4.169964790344238 | CLS Loss: 0.057531073689460754\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 4.248729705810547 | KNN Loss: 4.193167209625244 | CLS Loss: 0.05556256324052811\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 4.2270121574401855 | KNN Loss: 4.187851905822754 | CLS Loss: 0.0391603522002697\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 4.279877185821533 | KNN Loss: 4.221189975738525 | CLS Loss: 0.058686982840299606\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 4.352473258972168 | KNN Loss: 4.301459789276123 | CLS Loss: 0.05101349204778671\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 4.221818447113037 | KNN Loss: 4.200440406799316 | CLS Loss: 0.021377932280302048\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 4.237703323364258 | KNN Loss: 4.195769786834717 | CLS Loss: 0.041933462023735046\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 4.2278056144714355 | KNN Loss: 4.196526527404785 | CLS Loss: 0.03127927705645561\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 4.23772668838501 | KNN Loss: 4.19066858291626 | CLS Loss: 0.04705798625946045\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 4.213578224182129 | KNN Loss: 4.187962532043457 | CLS Loss: 0.02561572939157486\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 4.244609355926514 | KNN Loss: 4.178666114807129 | CLS Loss: 0.065943144261837\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 4.2231831550598145 | KNN Loss: 4.189247131347656 | CLS Loss: 0.03393607586622238\n",
      "Epoch: 022, Loss: 4.2291, Train: 0.9893, Valid: 0.9834, Best: 0.9838\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 4.323641300201416 | KNN Loss: 4.265620231628418 | CLS Loss: 0.05802127718925476\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 4.2240681648254395 | KNN Loss: 4.199798583984375 | CLS Loss: 0.024269750341773033\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 4.210278511047363 | KNN Loss: 4.176487922668457 | CLS Loss: 0.03379039093852043\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 4.190398216247559 | KNN Loss: 4.165598392486572 | CLS Loss: 0.024799836799502373\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 4.207177639007568 | KNN Loss: 4.171557426452637 | CLS Loss: 0.03562001511454582\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 4.22210168838501 | KNN Loss: 4.169947624206543 | CLS Loss: 0.052153848111629486\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 4.2067670822143555 | KNN Loss: 4.189717769622803 | CLS Loss: 0.017049076035618782\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 4.241161346435547 | KNN Loss: 4.197403430938721 | CLS Loss: 0.04375814273953438\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 4.234671115875244 | KNN Loss: 4.201156139373779 | CLS Loss: 0.033514924347400665\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 4.23552131652832 | KNN Loss: 4.20051383972168 | CLS Loss: 0.035007648169994354\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 4.251245021820068 | KNN Loss: 4.1889495849609375 | CLS Loss: 0.062295328825712204\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 4.225820064544678 | KNN Loss: 4.182252883911133 | CLS Loss: 0.043567195534706116\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 4.2678093910217285 | KNN Loss: 4.21424674987793 | CLS Loss: 0.05356249958276749\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 4.259462356567383 | KNN Loss: 4.186505317687988 | CLS Loss: 0.07295722514390945\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 4.197099208831787 | KNN Loss: 4.153034210205078 | CLS Loss: 0.04406481981277466\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 4.218016624450684 | KNN Loss: 4.181380271911621 | CLS Loss: 0.03663618117570877\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 4.207948684692383 | KNN Loss: 4.185697555541992 | CLS Loss: 0.022250914946198463\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 4.253428936004639 | KNN Loss: 4.2022705078125 | CLS Loss: 0.05115845426917076\n",
      "Epoch: 023, Loss: 4.2274, Train: 0.9857, Valid: 0.9812, Best: 0.9838\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 4.257145404815674 | KNN Loss: 4.229267120361328 | CLS Loss: 0.027878189459443092\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 4.231892108917236 | KNN Loss: 4.2071919441223145 | CLS Loss: 0.024700382724404335\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 4.286207675933838 | KNN Loss: 4.227760314941406 | CLS Loss: 0.05844726413488388\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 4.229696273803711 | KNN Loss: 4.1900153160095215 | CLS Loss: 0.03968111053109169\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 4.251073837280273 | KNN Loss: 4.211881160736084 | CLS Loss: 0.0391928032040596\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 4.229167461395264 | KNN Loss: 4.171506881713867 | CLS Loss: 0.05766076222062111\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 4.2543625831604 | KNN Loss: 4.211513996124268 | CLS Loss: 0.04284876957535744\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 4.249794006347656 | KNN Loss: 4.2097320556640625 | CLS Loss: 0.04006216302514076\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 4.181328773498535 | KNN Loss: 4.165200233459473 | CLS Loss: 0.01612846553325653\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 4.219970703125 | KNN Loss: 4.188943862915039 | CLS Loss: 0.031027046963572502\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 4.223066806793213 | KNN Loss: 4.161508560180664 | CLS Loss: 0.06155817210674286\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 4.238779067993164 | KNN Loss: 4.220753192901611 | CLS Loss: 0.018025832250714302\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 4.210534572601318 | KNN Loss: 4.167564392089844 | CLS Loss: 0.04297010600566864\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 4.253790378570557 | KNN Loss: 4.214515686035156 | CLS Loss: 0.03927477449178696\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 4.225485801696777 | KNN Loss: 4.182851314544678 | CLS Loss: 0.04263469949364662\n",
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 4.257262706756592 | KNN Loss: 4.187010288238525 | CLS Loss: 0.0702521950006485\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 4.236072540283203 | KNN Loss: 4.180423259735107 | CLS Loss: 0.055649206042289734\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 4.2282185554504395 | KNN Loss: 4.197331428527832 | CLS Loss: 0.03088713064789772\n",
      "Epoch: 024, Loss: 4.2231, Train: 0.9902, Valid: 0.9850, Best: 0.9850\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 4.300751209259033 | KNN Loss: 4.250121116638184 | CLS Loss: 0.050630275160074234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 4.202946186065674 | KNN Loss: 4.176621913909912 | CLS Loss: 0.02632424794137478\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 4.242764949798584 | KNN Loss: 4.215856552124023 | CLS Loss: 0.026908554136753082\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 4.211588382720947 | KNN Loss: 4.167508602142334 | CLS Loss: 0.04407999664545059\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 4.235064506530762 | KNN Loss: 4.2154541015625 | CLS Loss: 0.019610607996582985\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 4.226382255554199 | KNN Loss: 4.202508449554443 | CLS Loss: 0.023873774334788322\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 4.229248046875 | KNN Loss: 4.195174217224121 | CLS Loss: 0.034073878079652786\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 4.186060905456543 | KNN Loss: 4.170558452606201 | CLS Loss: 0.015502363443374634\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 4.224132061004639 | KNN Loss: 4.188500881195068 | CLS Loss: 0.03563130274415016\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 4.201879024505615 | KNN Loss: 4.171874523162842 | CLS Loss: 0.030004305765032768\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 4.204826354980469 | KNN Loss: 4.179573059082031 | CLS Loss: 0.025253180414438248\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 4.229029655456543 | KNN Loss: 4.195340633392334 | CLS Loss: 0.03368920087814331\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 4.2412590980529785 | KNN Loss: 4.205001354217529 | CLS Loss: 0.036257822066545486\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 4.232707500457764 | KNN Loss: 4.196142196655273 | CLS Loss: 0.03656526282429695\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 4.268868446350098 | KNN Loss: 4.19320821762085 | CLS Loss: 0.07566019147634506\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 4.227687358856201 | KNN Loss: 4.192444324493408 | CLS Loss: 0.03524291142821312\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 4.246272563934326 | KNN Loss: 4.211271286010742 | CLS Loss: 0.03500130772590637\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 4.233168601989746 | KNN Loss: 4.202218055725098 | CLS Loss: 0.030950432643294334\n",
      "Epoch: 025, Loss: 4.2212, Train: 0.9905, Valid: 0.9847, Best: 0.9850\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 4.208252429962158 | KNN Loss: 4.178907871246338 | CLS Loss: 0.029344329610466957\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 4.252871513366699 | KNN Loss: 4.227711200714111 | CLS Loss: 0.025160228833556175\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 4.236800193786621 | KNN Loss: 4.196334362030029 | CLS Loss: 0.040465619415044785\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 4.2619218826293945 | KNN Loss: 4.173634052276611 | CLS Loss: 0.08828774094581604\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 4.200020790100098 | KNN Loss: 4.157025337219238 | CLS Loss: 0.04299543797969818\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 4.220124244689941 | KNN Loss: 4.176963806152344 | CLS Loss: 0.04316030442714691\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 4.247594833374023 | KNN Loss: 4.1830973625183105 | CLS Loss: 0.06449740380048752\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 4.228375434875488 | KNN Loss: 4.188487529754639 | CLS Loss: 0.03988797590136528\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 4.183353900909424 | KNN Loss: 4.16323184967041 | CLS Loss: 0.020121967419981956\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 4.175565242767334 | KNN Loss: 4.130683422088623 | CLS Loss: 0.04488179832696915\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 4.257769584655762 | KNN Loss: 4.219921588897705 | CLS Loss: 0.03784821555018425\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 4.2298502922058105 | KNN Loss: 4.183871269226074 | CLS Loss: 0.045979246497154236\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 4.256424427032471 | KNN Loss: 4.162392616271973 | CLS Loss: 0.09403157979249954\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 4.223240375518799 | KNN Loss: 4.194116592407227 | CLS Loss: 0.029123647138476372\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 4.239980697631836 | KNN Loss: 4.216374397277832 | CLS Loss: 0.0236063189804554\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 4.236643314361572 | KNN Loss: 4.161734580993652 | CLS Loss: 0.07490874826908112\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 4.226322174072266 | KNN Loss: 4.19940185546875 | CLS Loss: 0.026920385658740997\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 4.230653762817383 | KNN Loss: 4.1767120361328125 | CLS Loss: 0.05394183099269867\n",
      "Epoch: 026, Loss: 4.2196, Train: 0.9905, Valid: 0.9850, Best: 0.9850\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 4.202981472015381 | KNN Loss: 4.188827037811279 | CLS Loss: 0.014154409989714622\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 4.200031757354736 | KNN Loss: 4.179958343505859 | CLS Loss: 0.02007337287068367\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 4.207995891571045 | KNN Loss: 4.169827938079834 | CLS Loss: 0.038167815655469894\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 4.173311710357666 | KNN Loss: 4.147429943084717 | CLS Loss: 0.025881977751851082\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 4.212060451507568 | KNN Loss: 4.193070888519287 | CLS Loss: 0.018989378586411476\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 4.205695629119873 | KNN Loss: 4.174075603485107 | CLS Loss: 0.03161981329321861\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 4.207702159881592 | KNN Loss: 4.170009136199951 | CLS Loss: 0.03769318386912346\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 4.236933708190918 | KNN Loss: 4.181440353393555 | CLS Loss: 0.05549337714910507\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 4.243890285491943 | KNN Loss: 4.200485706329346 | CLS Loss: 0.043404653668403625\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 4.177535057067871 | KNN Loss: 4.159399509429932 | CLS Loss: 0.018135374411940575\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 4.218988418579102 | KNN Loss: 4.168257236480713 | CLS Loss: 0.05073118209838867\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 4.249279499053955 | KNN Loss: 4.210541248321533 | CLS Loss: 0.038738101720809937\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 4.215430736541748 | KNN Loss: 4.1870551109313965 | CLS Loss: 0.028375744819641113\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 4.238575458526611 | KNN Loss: 4.174663543701172 | CLS Loss: 0.06391182541847229\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 4.223959445953369 | KNN Loss: 4.200953483581543 | CLS Loss: 0.023006008937954903\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 4.193004131317139 | KNN Loss: 4.168036460876465 | CLS Loss: 0.024967482313513756\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 4.193055629730225 | KNN Loss: 4.1589837074279785 | CLS Loss: 0.034072015434503555\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 4.222817420959473 | KNN Loss: 4.189310073852539 | CLS Loss: 0.03350735455751419\n",
      "Epoch: 027, Loss: 4.2141, Train: 0.9881, Valid: 0.9833, Best: 0.9850\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 4.251881122589111 | KNN Loss: 4.154987335205078 | CLS Loss: 0.0968937799334526\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 4.206928253173828 | KNN Loss: 4.169734001159668 | CLS Loss: 0.03719434514641762\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 4.196657180786133 | KNN Loss: 4.178948879241943 | CLS Loss: 0.017708083614706993\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 4.245734214782715 | KNN Loss: 4.202457427978516 | CLS Loss: 0.04327663406729698\n",
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 4.233858585357666 | KNN Loss: 4.187812805175781 | CLS Loss: 0.04604560136795044\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 4.217915058135986 | KNN Loss: 4.205377101898193 | CLS Loss: 0.012538110837340355\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 4.208097457885742 | KNN Loss: 4.165261745452881 | CLS Loss: 0.04283594712615013\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 4.239024639129639 | KNN Loss: 4.208186149597168 | CLS Loss: 0.030838608741760254\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 4.207152843475342 | KNN Loss: 4.18855619430542 | CLS Loss: 0.018596600741147995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 4.209473609924316 | KNN Loss: 4.193514823913574 | CLS Loss: 0.01595856063067913\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 4.179968357086182 | KNN Loss: 4.150774955749512 | CLS Loss: 0.0291933324187994\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 4.2003173828125 | KNN Loss: 4.181091785430908 | CLS Loss: 0.019225429743528366\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 4.22584867477417 | KNN Loss: 4.196103572845459 | CLS Loss: 0.02974509634077549\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 4.169257640838623 | KNN Loss: 4.151370525360107 | CLS Loss: 0.01788724772632122\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 4.220255374908447 | KNN Loss: 4.201069355010986 | CLS Loss: 0.019185852259397507\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 4.1873908042907715 | KNN Loss: 4.162753105163574 | CLS Loss: 0.024637851864099503\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 4.215841770172119 | KNN Loss: 4.157540798187256 | CLS Loss: 0.058300986886024475\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 4.2105913162231445 | KNN Loss: 4.159876823425293 | CLS Loss: 0.05071450024843216\n",
      "Epoch: 028, Loss: 4.2171, Train: 0.9901, Valid: 0.9834, Best: 0.9850\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 4.205582141876221 | KNN Loss: 4.179770469665527 | CLS Loss: 0.02581186778843403\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 4.2138190269470215 | KNN Loss: 4.18989896774292 | CLS Loss: 0.023920278996229172\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 4.198971271514893 | KNN Loss: 4.170001983642578 | CLS Loss: 0.028969254344701767\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 4.233598709106445 | KNN Loss: 4.190777778625488 | CLS Loss: 0.04282079637050629\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 4.215651988983154 | KNN Loss: 4.177119731903076 | CLS Loss: 0.03853224217891693\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 4.182628154754639 | KNN Loss: 4.152052879333496 | CLS Loss: 0.03057505004107952\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 4.182260990142822 | KNN Loss: 4.153875350952148 | CLS Loss: 0.028385566547513008\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 4.227201461791992 | KNN Loss: 4.197703838348389 | CLS Loss: 0.029497714713215828\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 4.184136390686035 | KNN Loss: 4.148022174835205 | CLS Loss: 0.03611436486244202\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 4.167131423950195 | KNN Loss: 4.135968208312988 | CLS Loss: 0.03116323985159397\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 4.20049524307251 | KNN Loss: 4.158863067626953 | CLS Loss: 0.04163200035691261\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 4.18428897857666 | KNN Loss: 4.156381130218506 | CLS Loss: 0.027907876297831535\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 4.218837261199951 | KNN Loss: 4.156819820404053 | CLS Loss: 0.062017496675252914\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 4.198689937591553 | KNN Loss: 4.16175651550293 | CLS Loss: 0.03693331778049469\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 4.204031467437744 | KNN Loss: 4.167754650115967 | CLS Loss: 0.03627660498023033\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 4.226085662841797 | KNN Loss: 4.187394618988037 | CLS Loss: 0.03869100287556648\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 4.21645975112915 | KNN Loss: 4.182627201080322 | CLS Loss: 0.03383273258805275\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 4.238203525543213 | KNN Loss: 4.202685832977295 | CLS Loss: 0.03551766648888588\n",
      "Epoch: 029, Loss: 4.2127, Train: 0.9883, Valid: 0.9817, Best: 0.9850\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 4.207712650299072 | KNN Loss: 4.170894622802734 | CLS Loss: 0.036818116903305054\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 4.216554641723633 | KNN Loss: 4.1980485916137695 | CLS Loss: 0.01850602962076664\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 4.2685089111328125 | KNN Loss: 4.220195770263672 | CLS Loss: 0.04831291362643242\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 4.197725772857666 | KNN Loss: 4.162194728851318 | CLS Loss: 0.035530898720026016\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 4.253762245178223 | KNN Loss: 4.189345836639404 | CLS Loss: 0.06441635638475418\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 4.183525085449219 | KNN Loss: 4.161103248596191 | CLS Loss: 0.022421838715672493\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 4.191165447235107 | KNN Loss: 4.165438175201416 | CLS Loss: 0.025727372616529465\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 4.217404842376709 | KNN Loss: 4.182776927947998 | CLS Loss: 0.03462785854935646\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 4.20691442489624 | KNN Loss: 4.167412281036377 | CLS Loss: 0.03950216993689537\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 4.203005790710449 | KNN Loss: 4.164884567260742 | CLS Loss: 0.03812112659215927\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 4.200686931610107 | KNN Loss: 4.172731876373291 | CLS Loss: 0.02795487269759178\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 4.208101749420166 | KNN Loss: 4.169541358947754 | CLS Loss: 0.03856022283434868\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 4.187061309814453 | KNN Loss: 4.176856517791748 | CLS Loss: 0.010204905644059181\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 4.210409641265869 | KNN Loss: 4.160393238067627 | CLS Loss: 0.05001626908779144\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 4.210031509399414 | KNN Loss: 4.13908576965332 | CLS Loss: 0.07094556838274002\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 4.213003635406494 | KNN Loss: 4.185710430145264 | CLS Loss: 0.02729317732155323\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 4.227376937866211 | KNN Loss: 4.199620246887207 | CLS Loss: 0.027756929397583008\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 4.162716388702393 | KNN Loss: 4.143095970153809 | CLS Loss: 0.019620316103100777\n",
      "Epoch: 030, Loss: 4.2127, Train: 0.9894, Valid: 0.9835, Best: 0.9850\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 4.226527214050293 | KNN Loss: 4.193382740020752 | CLS Loss: 0.033144254237413406\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 4.218294620513916 | KNN Loss: 4.1649169921875 | CLS Loss: 0.05337744578719139\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 4.244544982910156 | KNN Loss: 4.19761323928833 | CLS Loss: 0.04693165421485901\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 4.216897010803223 | KNN Loss: 4.179903030395508 | CLS Loss: 0.036993950605392456\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 4.195969581604004 | KNN Loss: 4.182640075683594 | CLS Loss: 0.01332932896912098\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 4.210035800933838 | KNN Loss: 4.186201095581055 | CLS Loss: 0.023834699764847755\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 4.22126579284668 | KNN Loss: 4.191532135009766 | CLS Loss: 0.029733439907431602\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 4.211670398712158 | KNN Loss: 4.18247127532959 | CLS Loss: 0.029199175536632538\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 4.2011823654174805 | KNN Loss: 4.181560039520264 | CLS Loss: 0.01962253637611866\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 4.192404270172119 | KNN Loss: 4.164776802062988 | CLS Loss: 0.027627604082226753\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 4.2140960693359375 | KNN Loss: 4.193599700927734 | CLS Loss: 0.020496154204010963\n",
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 4.1670823097229 | KNN Loss: 4.144357681274414 | CLS Loss: 0.022724699229002\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 4.180881977081299 | KNN Loss: 4.166299343109131 | CLS Loss: 0.014582809060811996\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 4.186559677124023 | KNN Loss: 4.149843215942383 | CLS Loss: 0.03671630844473839\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 4.2153801918029785 | KNN Loss: 4.186079502105713 | CLS Loss: 0.029300881549715996\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 4.208784103393555 | KNN Loss: 4.16823673248291 | CLS Loss: 0.04054743051528931\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 4.225322723388672 | KNN Loss: 4.164670944213867 | CLS Loss: 0.06065189093351364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 4.329753875732422 | KNN Loss: 4.283032417297363 | CLS Loss: 0.046721626073122025\n",
      "Epoch: 031, Loss: 4.2095, Train: 0.9917, Valid: 0.9859, Best: 0.9859\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 4.196259498596191 | KNN Loss: 4.168260097503662 | CLS Loss: 0.027999596670269966\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 4.195666790008545 | KNN Loss: 4.160972595214844 | CLS Loss: 0.03469400480389595\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 4.257388591766357 | KNN Loss: 4.225433826446533 | CLS Loss: 0.03195473924279213\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 4.1703410148620605 | KNN Loss: 4.151196002960205 | CLS Loss: 0.019144900143146515\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 4.197514533996582 | KNN Loss: 4.166368007659912 | CLS Loss: 0.031146572902798653\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 4.257805824279785 | KNN Loss: 4.229037284851074 | CLS Loss: 0.028768394142389297\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 4.20948600769043 | KNN Loss: 4.159315586090088 | CLS Loss: 0.050170205533504486\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 4.244595050811768 | KNN Loss: 4.175167560577393 | CLS Loss: 0.06942746788263321\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 4.22314453125 | KNN Loss: 4.176767826080322 | CLS Loss: 0.04637691006064415\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 4.227962970733643 | KNN Loss: 4.191269397735596 | CLS Loss: 0.03669357672333717\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 4.216277599334717 | KNN Loss: 4.186899185180664 | CLS Loss: 0.029378270730376244\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 4.249639511108398 | KNN Loss: 4.192479610443115 | CLS Loss: 0.05715974420309067\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 4.223719120025635 | KNN Loss: 4.2083001136779785 | CLS Loss: 0.01541909109801054\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 4.214383125305176 | KNN Loss: 4.17168664932251 | CLS Loss: 0.04269633814692497\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 4.21417236328125 | KNN Loss: 4.186168670654297 | CLS Loss: 0.028003722429275513\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 4.179113388061523 | KNN Loss: 4.171813488006592 | CLS Loss: 0.007299821823835373\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 4.178885459899902 | KNN Loss: 4.152227878570557 | CLS Loss: 0.02665743976831436\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 4.260081768035889 | KNN Loss: 4.198729991912842 | CLS Loss: 0.06135178357362747\n",
      "Epoch: 032, Loss: 4.2039, Train: 0.9920, Valid: 0.9841, Best: 0.9859\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 4.199434280395508 | KNN Loss: 4.183392524719238 | CLS Loss: 0.016041897237300873\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 4.326676368713379 | KNN Loss: 4.291006088256836 | CLS Loss: 0.03567024692893028\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 4.180402755737305 | KNN Loss: 4.153284072875977 | CLS Loss: 0.027118735015392303\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 4.20268440246582 | KNN Loss: 4.179962635040283 | CLS Loss: 0.022721683606505394\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 4.222461700439453 | KNN Loss: 4.196151256561279 | CLS Loss: 0.026310443878173828\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 4.188792705535889 | KNN Loss: 4.176612854003906 | CLS Loss: 0.012179844081401825\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 4.175234794616699 | KNN Loss: 4.1564154624938965 | CLS Loss: 0.018819529563188553\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 4.198714733123779 | KNN Loss: 4.169827461242676 | CLS Loss: 0.0288873091340065\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 4.202184200286865 | KNN Loss: 4.16209077835083 | CLS Loss: 0.040093354880809784\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 4.2054338455200195 | KNN Loss: 4.169381618499756 | CLS Loss: 0.03605243191123009\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 4.198323726654053 | KNN Loss: 4.157900810241699 | CLS Loss: 0.040422774851322174\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 4.176490783691406 | KNN Loss: 4.153853416442871 | CLS Loss: 0.022637195885181427\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 4.16418981552124 | KNN Loss: 4.149779319763184 | CLS Loss: 0.014410726726055145\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 4.2142653465271 | KNN Loss: 4.183844089508057 | CLS Loss: 0.030421370640397072\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 4.1833930015563965 | KNN Loss: 4.118697643280029 | CLS Loss: 0.06469518691301346\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 4.1890482902526855 | KNN Loss: 4.170482158660889 | CLS Loss: 0.018566256389021873\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 4.208889961242676 | KNN Loss: 4.174243927001953 | CLS Loss: 0.03464619070291519\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 4.243976593017578 | KNN Loss: 4.181643486022949 | CLS Loss: 0.06233318895101547\n",
      "Epoch: 033, Loss: 4.2042, Train: 0.9919, Valid: 0.9856, Best: 0.9859\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 4.1869940757751465 | KNN Loss: 4.1737494468688965 | CLS Loss: 0.013244854286313057\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 4.2187089920043945 | KNN Loss: 4.186726093292236 | CLS Loss: 0.031982846558094025\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 4.251999855041504 | KNN Loss: 4.202631950378418 | CLS Loss: 0.049367763102054596\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 4.208032131195068 | KNN Loss: 4.170454502105713 | CLS Loss: 0.03757768124341965\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 4.166416645050049 | KNN Loss: 4.152011394500732 | CLS Loss: 0.014405209571123123\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 4.2917304039001465 | KNN Loss: 4.2410569190979 | CLS Loss: 0.0506734773516655\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 4.1925177574157715 | KNN Loss: 4.147940635681152 | CLS Loss: 0.04457704350352287\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 4.213338375091553 | KNN Loss: 4.178029537200928 | CLS Loss: 0.03530864790081978\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 4.234768867492676 | KNN Loss: 4.207516193389893 | CLS Loss: 0.02725282311439514\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 4.194431304931641 | KNN Loss: 4.169121265411377 | CLS Loss: 0.025310274213552475\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 4.196520805358887 | KNN Loss: 4.174310684204102 | CLS Loss: 0.022210121154785156\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 4.19771671295166 | KNN Loss: 4.1746039390563965 | CLS Loss: 0.023112749680876732\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 4.218380928039551 | KNN Loss: 4.196413993835449 | CLS Loss: 0.02196679078042507\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 4.225767135620117 | KNN Loss: 4.182492733001709 | CLS Loss: 0.04327429085969925\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 4.17851448059082 | KNN Loss: 4.152927875518799 | CLS Loss: 0.025586701929569244\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 4.222080230712891 | KNN Loss: 4.195292949676514 | CLS Loss: 0.02678743191063404\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 4.214441776275635 | KNN Loss: 4.185629844665527 | CLS Loss: 0.02881176955997944\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 4.211446762084961 | KNN Loss: 4.180908203125 | CLS Loss: 0.03053879179060459\n",
      "Epoch: 034, Loss: 4.2062, Train: 0.9904, Valid: 0.9848, Best: 0.9859\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 4.17361307144165 | KNN Loss: 4.150991916656494 | CLS Loss: 0.022621162235736847\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 4.2064595222473145 | KNN Loss: 4.191291332244873 | CLS Loss: 0.015167981386184692\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 4.2236504554748535 | KNN Loss: 4.186737060546875 | CLS Loss: 0.03691323474049568\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 4.15232515335083 | KNN Loss: 4.124707221984863 | CLS Loss: 0.02761794626712799\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 4.177517890930176 | KNN Loss: 4.155157566070557 | CLS Loss: 0.02236013300716877\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 4.239657878875732 | KNN Loss: 4.196384906768799 | CLS Loss: 0.04327281564474106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 4.223788261413574 | KNN Loss: 4.2151007652282715 | CLS Loss: 0.008687641471624374\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 4.207919597625732 | KNN Loss: 4.192777633666992 | CLS Loss: 0.015141968615353107\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 4.206507682800293 | KNN Loss: 4.170849800109863 | CLS Loss: 0.0356581024825573\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 4.210572242736816 | KNN Loss: 4.16250467300415 | CLS Loss: 0.048067398369312286\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 4.238564491271973 | KNN Loss: 4.198464393615723 | CLS Loss: 0.04010014608502388\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 4.197249889373779 | KNN Loss: 4.1406731605529785 | CLS Loss: 0.056576717644929886\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 4.21688985824585 | KNN Loss: 4.1817851066589355 | CLS Loss: 0.03510491922497749\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 4.194021701812744 | KNN Loss: 4.167507171630859 | CLS Loss: 0.02651454135775566\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 4.184946537017822 | KNN Loss: 4.158712863922119 | CLS Loss: 0.02623387612402439\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 4.197311878204346 | KNN Loss: 4.166391849517822 | CLS Loss: 0.03092026524245739\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 4.250921726226807 | KNN Loss: 4.203566074371338 | CLS Loss: 0.04735563322901726\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 4.211367130279541 | KNN Loss: 4.182878017425537 | CLS Loss: 0.028488950803875923\n",
      "Epoch: 035, Loss: 4.2051, Train: 0.9922, Valid: 0.9861, Best: 0.9861\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 4.183648109436035 | KNN Loss: 4.1647629737854 | CLS Loss: 0.018885048106312752\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 4.20271110534668 | KNN Loss: 4.1823039054870605 | CLS Loss: 0.02040722593665123\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 4.229568958282471 | KNN Loss: 4.207824230194092 | CLS Loss: 0.02174472063779831\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 4.191853046417236 | KNN Loss: 4.180057048797607 | CLS Loss: 0.011795860715210438\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 4.18019962310791 | KNN Loss: 4.155332565307617 | CLS Loss: 0.024867108091711998\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 4.254946708679199 | KNN Loss: 4.23508358001709 | CLS Loss: 0.019863294437527657\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 4.17201566696167 | KNN Loss: 4.157705783843994 | CLS Loss: 0.014309882186353207\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 4.208271503448486 | KNN Loss: 4.175615310668945 | CLS Loss: 0.032656293362379074\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 4.185764312744141 | KNN Loss: 4.166688442230225 | CLS Loss: 0.01907607913017273\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 4.186232089996338 | KNN Loss: 4.1523942947387695 | CLS Loss: 0.03383766487240791\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 4.21359395980835 | KNN Loss: 4.170626640319824 | CLS Loss: 0.04296746104955673\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 4.216860294342041 | KNN Loss: 4.193998336791992 | CLS Loss: 0.0228619072586298\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 4.191025257110596 | KNN Loss: 4.165510654449463 | CLS Loss: 0.025514479726552963\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 4.170805931091309 | KNN Loss: 4.149497032165527 | CLS Loss: 0.02130870148539543\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 4.219455718994141 | KNN Loss: 4.181881904602051 | CLS Loss: 0.037573881447315216\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 4.184988975524902 | KNN Loss: 4.156844139099121 | CLS Loss: 0.02814486436545849\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 4.241368293762207 | KNN Loss: 4.201836109161377 | CLS Loss: 0.03953207656741142\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 4.186117172241211 | KNN Loss: 4.152383804321289 | CLS Loss: 0.03373324126005173\n",
      "Epoch: 036, Loss: 4.2015, Train: 0.9937, Valid: 0.9874, Best: 0.9874\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 4.183770179748535 | KNN Loss: 4.141592025756836 | CLS Loss: 0.04217829555273056\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 4.200047492980957 | KNN Loss: 4.1771979331970215 | CLS Loss: 0.022849587723612785\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 4.165772438049316 | KNN Loss: 4.147139072418213 | CLS Loss: 0.01863349787890911\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 4.213773727416992 | KNN Loss: 4.197368621826172 | CLS Loss: 0.016405196860432625\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 4.209843635559082 | KNN Loss: 4.168201446533203 | CLS Loss: 0.04164227843284607\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 4.164056301116943 | KNN Loss: 4.153348922729492 | CLS Loss: 0.010707531124353409\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 4.181524753570557 | KNN Loss: 4.148200035095215 | CLS Loss: 0.03332476317882538\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 4.186825752258301 | KNN Loss: 4.171228885650635 | CLS Loss: 0.015596817247569561\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 4.209330081939697 | KNN Loss: 4.183549404144287 | CLS Loss: 0.02578083798289299\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 4.207168102264404 | KNN Loss: 4.177034854888916 | CLS Loss: 0.03013336844742298\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 4.205604076385498 | KNN Loss: 4.166276454925537 | CLS Loss: 0.039327558130025864\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 4.185580253601074 | KNN Loss: 4.158043384552002 | CLS Loss: 0.027536652982234955\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 4.222586631774902 | KNN Loss: 4.179271697998047 | CLS Loss: 0.04331478103995323\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 4.177099704742432 | KNN Loss: 4.150550365447998 | CLS Loss: 0.026549432426691055\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 4.184478759765625 | KNN Loss: 4.13828706741333 | CLS Loss: 0.04619162529706955\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 4.181650161743164 | KNN Loss: 4.167285442352295 | CLS Loss: 0.01436475571244955\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 4.191153526306152 | KNN Loss: 4.176620960235596 | CLS Loss: 0.014532500877976418\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 4.199465751647949 | KNN Loss: 4.175990581512451 | CLS Loss: 0.023475121706724167\n",
      "Epoch: 037, Loss: 4.1976, Train: 0.9932, Valid: 0.9862, Best: 0.9874\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 4.188904762268066 | KNN Loss: 4.17287015914917 | CLS Loss: 0.016034450381994247\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 4.172491550445557 | KNN Loss: 4.165638446807861 | CLS Loss: 0.006853153929114342\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 4.258539199829102 | KNN Loss: 4.22285270690918 | CLS Loss: 0.035686589777469635\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 4.202335834503174 | KNN Loss: 4.164937496185303 | CLS Loss: 0.03739844262599945\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 4.224356651306152 | KNN Loss: 4.196683883666992 | CLS Loss: 0.027672747150063515\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 4.194956302642822 | KNN Loss: 4.177819728851318 | CLS Loss: 0.0171363465487957\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 4.193274021148682 | KNN Loss: 4.173184871673584 | CLS Loss: 0.02008906565606594\n",
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 4.20384407043457 | KNN Loss: 4.184961318969727 | CLS Loss: 0.018882671371102333\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 4.225533485412598 | KNN Loss: 4.209751129150391 | CLS Loss: 0.015782158821821213\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 4.239010810852051 | KNN Loss: 4.203271865844727 | CLS Loss: 0.035738859325647354\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 4.1817474365234375 | KNN Loss: 4.166694641113281 | CLS Loss: 0.015052634291350842\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 4.162269592285156 | KNN Loss: 4.1492486000061035 | CLS Loss: 0.013020926155149937\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 4.2317914962768555 | KNN Loss: 4.209975242614746 | CLS Loss: 0.021816087886691093\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 4.239351749420166 | KNN Loss: 4.190367221832275 | CLS Loss: 0.048984672874212265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 4.200791835784912 | KNN Loss: 4.183178901672363 | CLS Loss: 0.01761278137564659\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 4.150178909301758 | KNN Loss: 4.14164924621582 | CLS Loss: 0.008529637940227985\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 4.218690395355225 | KNN Loss: 4.183375358581543 | CLS Loss: 0.035315223038196564\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 4.195539951324463 | KNN Loss: 4.17203950881958 | CLS Loss: 0.02350040338933468\n",
      "Epoch: 038, Loss: 4.2027, Train: 0.9932, Valid: 0.9866, Best: 0.9874\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 4.191890239715576 | KNN Loss: 4.1646599769592285 | CLS Loss: 0.027230199426412582\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 4.1915082931518555 | KNN Loss: 4.167344570159912 | CLS Loss: 0.024163732305169106\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 4.181209564208984 | KNN Loss: 4.139123916625977 | CLS Loss: 0.04208579286932945\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 4.19404411315918 | KNN Loss: 4.183140754699707 | CLS Loss: 0.010903420858085155\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 4.199063301086426 | KNN Loss: 4.156778812408447 | CLS Loss: 0.042284514755010605\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 4.192230224609375 | KNN Loss: 4.16907262802124 | CLS Loss: 0.02315782941877842\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 4.1793646812438965 | KNN Loss: 4.153552532196045 | CLS Loss: 0.025812042877078056\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 4.196081638336182 | KNN Loss: 4.164597034454346 | CLS Loss: 0.03148447349667549\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 4.225795745849609 | KNN Loss: 4.19313907623291 | CLS Loss: 0.03265680372714996\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 4.1969451904296875 | KNN Loss: 4.169310569763184 | CLS Loss: 0.027634575963020325\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 4.208872318267822 | KNN Loss: 4.175897121429443 | CLS Loss: 0.032975126057863235\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 4.236124515533447 | KNN Loss: 4.2019734382629395 | CLS Loss: 0.034151069819927216\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 4.207346439361572 | KNN Loss: 4.170554161071777 | CLS Loss: 0.0367923341691494\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 4.2124786376953125 | KNN Loss: 4.19223165512085 | CLS Loss: 0.0202468354254961\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 4.20864200592041 | KNN Loss: 4.182802677154541 | CLS Loss: 0.025839442387223244\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 4.190722942352295 | KNN Loss: 4.164234161376953 | CLS Loss: 0.026488689705729485\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 4.175756454467773 | KNN Loss: 4.147383213043213 | CLS Loss: 0.028373336419463158\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 4.1777849197387695 | KNN Loss: 4.1540327072143555 | CLS Loss: 0.023751985281705856\n",
      "Epoch: 039, Loss: 4.1964, Train: 0.9934, Valid: 0.9859, Best: 0.9874\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 4.1436357498168945 | KNN Loss: 4.128977298736572 | CLS Loss: 0.014658324420452118\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 4.199892044067383 | KNN Loss: 4.163130760192871 | CLS Loss: 0.03676144406199455\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 4.2075347900390625 | KNN Loss: 4.189644813537598 | CLS Loss: 0.017890116199851036\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 4.17490816116333 | KNN Loss: 4.144166469573975 | CLS Loss: 0.030741563066840172\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 4.181044101715088 | KNN Loss: 4.148616790771484 | CLS Loss: 0.03242712840437889\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 4.206074237823486 | KNN Loss: 4.172534465789795 | CLS Loss: 0.033539850264787674\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 4.210631370544434 | KNN Loss: 4.188525199890137 | CLS Loss: 0.022106243297457695\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 4.181333541870117 | KNN Loss: 4.166149139404297 | CLS Loss: 0.015184296295046806\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 4.156819820404053 | KNN Loss: 4.127686977386475 | CLS Loss: 0.029132872819900513\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 4.194730281829834 | KNN Loss: 4.161116600036621 | CLS Loss: 0.033613722771406174\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 4.2209625244140625 | KNN Loss: 4.16785192489624 | CLS Loss: 0.05311071127653122\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 4.171606540679932 | KNN Loss: 4.162848472595215 | CLS Loss: 0.00875792745500803\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 4.180533409118652 | KNN Loss: 4.16591739654541 | CLS Loss: 0.014615959487855434\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 4.204082489013672 | KNN Loss: 4.170252323150635 | CLS Loss: 0.03383009135723114\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 4.19972562789917 | KNN Loss: 4.178908824920654 | CLS Loss: 0.020816920325160027\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 4.254515171051025 | KNN Loss: 4.214663028717041 | CLS Loss: 0.039852093905210495\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 4.191533088684082 | KNN Loss: 4.156299114227295 | CLS Loss: 0.03523395210504532\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 4.202976226806641 | KNN Loss: 4.176896095275879 | CLS Loss: 0.026080172508955002\n",
      "Epoch: 040, Loss: 4.1961, Train: 0.9943, Valid: 0.9874, Best: 0.9874\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 4.18966817855835 | KNN Loss: 4.178823947906494 | CLS Loss: 0.010844242759048939\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 4.2561235427856445 | KNN Loss: 4.200412273406982 | CLS Loss: 0.055711500346660614\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 4.191339492797852 | KNN Loss: 4.158323287963867 | CLS Loss: 0.03301640972495079\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 4.2019805908203125 | KNN Loss: 4.1712799072265625 | CLS Loss: 0.030700452625751495\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 4.163071632385254 | KNN Loss: 4.15730619430542 | CLS Loss: 0.005765371024608612\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 4.186089515686035 | KNN Loss: 4.161707878112793 | CLS Loss: 0.024381736293435097\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 4.180217266082764 | KNN Loss: 4.172797679901123 | CLS Loss: 0.007419386878609657\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 4.186035633087158 | KNN Loss: 4.145012378692627 | CLS Loss: 0.04102345556020737\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 4.157608509063721 | KNN Loss: 4.146487236022949 | CLS Loss: 0.011121315881609917\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 4.174901485443115 | KNN Loss: 4.162556171417236 | CLS Loss: 0.012345398776233196\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 4.173089981079102 | KNN Loss: 4.157299995422363 | CLS Loss: 0.015789978206157684\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 4.18773078918457 | KNN Loss: 4.1791300773620605 | CLS Loss: 0.00860093254595995\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 4.177802085876465 | KNN Loss: 4.152766704559326 | CLS Loss: 0.02503545954823494\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 4.220815658569336 | KNN Loss: 4.1878204345703125 | CLS Loss: 0.032995209097862244\n",
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 4.183104991912842 | KNN Loss: 4.173354625701904 | CLS Loss: 0.009750206023454666\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 4.1762189865112305 | KNN Loss: 4.167057037353516 | CLS Loss: 0.009161757305264473\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 4.199661731719971 | KNN Loss: 4.170319080352783 | CLS Loss: 0.029342418536543846\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 4.208954334259033 | KNN Loss: 4.191122531890869 | CLS Loss: 0.017831912264227867\n",
      "Epoch: 041, Loss: 4.1935, Train: 0.9938, Valid: 0.9861, Best: 0.9874\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 4.195897579193115 | KNN Loss: 4.170982837677002 | CLS Loss: 0.024914514273405075\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 4.228219509124756 | KNN Loss: 4.208702087402344 | CLS Loss: 0.019517309963703156\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 4.197302341461182 | KNN Loss: 4.181134223937988 | CLS Loss: 0.016168344765901566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 4.242067337036133 | KNN Loss: 4.20757532119751 | CLS Loss: 0.03449203446507454\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 4.190289497375488 | KNN Loss: 4.175161361694336 | CLS Loss: 0.015128017403185368\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 4.1797590255737305 | KNN Loss: 4.159085750579834 | CLS Loss: 0.02067323960363865\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 4.178226947784424 | KNN Loss: 4.153156757354736 | CLS Loss: 0.025070106610655785\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 4.206882476806641 | KNN Loss: 4.193690776824951 | CLS Loss: 0.013191461563110352\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 4.233734130859375 | KNN Loss: 4.177765369415283 | CLS Loss: 0.055968642234802246\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 4.192840576171875 | KNN Loss: 4.185133934020996 | CLS Loss: 0.007706467993557453\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 4.163606643676758 | KNN Loss: 4.147533416748047 | CLS Loss: 0.01607326976954937\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 4.216840744018555 | KNN Loss: 4.187213897705078 | CLS Loss: 0.029626738280057907\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 4.190186500549316 | KNN Loss: 4.172354221343994 | CLS Loss: 0.017832303419709206\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 4.15639066696167 | KNN Loss: 4.141798496246338 | CLS Loss: 0.014592359773814678\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 4.250637531280518 | KNN Loss: 4.214955806732178 | CLS Loss: 0.03568149730563164\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 4.2348456382751465 | KNN Loss: 4.22025728225708 | CLS Loss: 0.014588292688131332\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 4.191473484039307 | KNN Loss: 4.164899826049805 | CLS Loss: 0.02657342702150345\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 4.2467498779296875 | KNN Loss: 4.21764612197876 | CLS Loss: 0.029103541746735573\n",
      "Epoch: 042, Loss: 4.1997, Train: 0.9944, Valid: 0.9863, Best: 0.9874\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 4.190060615539551 | KNN Loss: 4.18404483795166 | CLS Loss: 0.0060159373097121716\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 4.17519474029541 | KNN Loss: 4.168488502502441 | CLS Loss: 0.006706008221954107\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 4.176655292510986 | KNN Loss: 4.142439842224121 | CLS Loss: 0.03421556577086449\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 4.173459053039551 | KNN Loss: 4.157557487487793 | CLS Loss: 0.01590171456336975\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 4.16008996963501 | KNN Loss: 4.152947425842285 | CLS Loss: 0.007142350543290377\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 4.22986364364624 | KNN Loss: 4.2070488929748535 | CLS Loss: 0.0228146780282259\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 4.195462226867676 | KNN Loss: 4.1613640785217285 | CLS Loss: 0.03409794345498085\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 4.229061603546143 | KNN Loss: 4.196499347686768 | CLS Loss: 0.03256229683756828\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 4.15568208694458 | KNN Loss: 4.1412858963012695 | CLS Loss: 0.014395974576473236\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 4.163449287414551 | KNN Loss: 4.133548259735107 | CLS Loss: 0.029900917783379555\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 4.2273268699646 | KNN Loss: 4.203578472137451 | CLS Loss: 0.023748241364955902\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 4.215432643890381 | KNN Loss: 4.198245048522949 | CLS Loss: 0.017187362536787987\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 4.183982849121094 | KNN Loss: 4.173239707946777 | CLS Loss: 0.010743034072220325\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 4.187333106994629 | KNN Loss: 4.156457901000977 | CLS Loss: 0.03087514452636242\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 4.151092529296875 | KNN Loss: 4.143496990203857 | CLS Loss: 0.007595683913677931\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 4.137833595275879 | KNN Loss: 4.1303486824035645 | CLS Loss: 0.0074849557131528854\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 4.1956353187561035 | KNN Loss: 4.190033912658691 | CLS Loss: 0.00560134369879961\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 4.239409446716309 | KNN Loss: 4.199875831604004 | CLS Loss: 0.03953360393643379\n",
      "Epoch: 043, Loss: 4.1926, Train: 0.9930, Valid: 0.9852, Best: 0.9874\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 4.245894908905029 | KNN Loss: 4.22343635559082 | CLS Loss: 0.022458570078015327\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 4.196207046508789 | KNN Loss: 4.153012752532959 | CLS Loss: 0.04319408908486366\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 4.208074569702148 | KNN Loss: 4.174381732940674 | CLS Loss: 0.03369272127747536\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 4.152968406677246 | KNN Loss: 4.133387088775635 | CLS Loss: 0.019581377506256104\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 4.2286272048950195 | KNN Loss: 4.179519176483154 | CLS Loss: 0.049108151346445084\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 4.228535175323486 | KNN Loss: 4.1965742111206055 | CLS Loss: 0.03196078538894653\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 4.185732841491699 | KNN Loss: 4.163305759429932 | CLS Loss: 0.0224272720515728\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 4.233497142791748 | KNN Loss: 4.209667205810547 | CLS Loss: 0.02382982335984707\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 4.193265914916992 | KNN Loss: 4.147871971130371 | CLS Loss: 0.04539377987384796\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 4.217704772949219 | KNN Loss: 4.194022178649902 | CLS Loss: 0.023682482540607452\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 4.219790458679199 | KNN Loss: 4.180690765380859 | CLS Loss: 0.039099644869565964\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 4.158914089202881 | KNN Loss: 4.144839763641357 | CLS Loss: 0.014074137434363365\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 4.208470344543457 | KNN Loss: 4.188637733459473 | CLS Loss: 0.019832618534564972\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 4.2095417976379395 | KNN Loss: 4.201622486114502 | CLS Loss: 0.007919191382825375\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 4.220319747924805 | KNN Loss: 4.189720630645752 | CLS Loss: 0.030599022284150124\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 4.150704860687256 | KNN Loss: 4.132816791534424 | CLS Loss: 0.017887895926833153\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 4.216136455535889 | KNN Loss: 4.199043273925781 | CLS Loss: 0.017093274742364883\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 4.174187660217285 | KNN Loss: 4.157965183258057 | CLS Loss: 0.016222650185227394\n",
      "Epoch: 044, Loss: 4.1995, Train: 0.9948, Valid: 0.9870, Best: 0.9874\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 4.187546253204346 | KNN Loss: 4.17525577545166 | CLS Loss: 0.012290715239942074\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 4.199981212615967 | KNN Loss: 4.18187141418457 | CLS Loss: 0.018109973520040512\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 4.165927410125732 | KNN Loss: 4.139098167419434 | CLS Loss: 0.0268291886895895\n",
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 4.158348560333252 | KNN Loss: 4.143991947174072 | CLS Loss: 0.014356445521116257\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 4.183733940124512 | KNN Loss: 4.159152507781982 | CLS Loss: 0.024581613019108772\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 4.198427200317383 | KNN Loss: 4.186887264251709 | CLS Loss: 0.011539933271706104\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 4.1778244972229 | KNN Loss: 4.139993190765381 | CLS Loss: 0.037831347435712814\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 4.184152126312256 | KNN Loss: 4.162842273712158 | CLS Loss: 0.021309876814484596\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 4.218075752258301 | KNN Loss: 4.187122821807861 | CLS Loss: 0.03095307946205139\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 4.17252254486084 | KNN Loss: 4.158955097198486 | CLS Loss: 0.013567614369094372\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 4.218477249145508 | KNN Loss: 4.191317558288574 | CLS Loss: 0.027159467339515686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 4.192473888397217 | KNN Loss: 4.160407543182373 | CLS Loss: 0.032066185027360916\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 4.1660895347595215 | KNN Loss: 4.140162944793701 | CLS Loss: 0.025926820933818817\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 4.177515029907227 | KNN Loss: 4.141493320465088 | CLS Loss: 0.036021821200847626\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 4.1983418464660645 | KNN Loss: 4.179731369018555 | CLS Loss: 0.018610574305057526\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 4.187421798706055 | KNN Loss: 4.176373481750488 | CLS Loss: 0.011048156768083572\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 4.149960041046143 | KNN Loss: 4.128811359405518 | CLS Loss: 0.021148812025785446\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 4.187256336212158 | KNN Loss: 4.165436744689941 | CLS Loss: 0.021819591522216797\n",
      "Epoch: 045, Loss: 4.1894, Train: 0.9941, Valid: 0.9860, Best: 0.9874\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 4.152374744415283 | KNN Loss: 4.113925933837891 | CLS Loss: 0.038448989391326904\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 4.1711530685424805 | KNN Loss: 4.159395694732666 | CLS Loss: 0.011757365427911282\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 4.201780796051025 | KNN Loss: 4.17592191696167 | CLS Loss: 0.025858644396066666\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 4.2003607749938965 | KNN Loss: 4.184431552886963 | CLS Loss: 0.01592908427119255\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 4.181546688079834 | KNN Loss: 4.155612945556641 | CLS Loss: 0.025933925062417984\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 4.173142433166504 | KNN Loss: 4.162381172180176 | CLS Loss: 0.010761446319520473\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 4.193977355957031 | KNN Loss: 4.157688140869141 | CLS Loss: 0.03628945350646973\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 4.1801981925964355 | KNN Loss: 4.1522417068481445 | CLS Loss: 0.027956563979387283\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 4.180285930633545 | KNN Loss: 4.175792217254639 | CLS Loss: 0.004493765067309141\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 4.228222846984863 | KNN Loss: 4.198762893676758 | CLS Loss: 0.02945985645055771\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 4.174558639526367 | KNN Loss: 4.16103458404541 | CLS Loss: 0.01352427527308464\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 4.184021949768066 | KNN Loss: 4.1741623878479 | CLS Loss: 0.009859396144747734\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 4.243346214294434 | KNN Loss: 4.196993350982666 | CLS Loss: 0.046352777630090714\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 4.182132720947266 | KNN Loss: 4.161544322967529 | CLS Loss: 0.02058842033147812\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 4.196131229400635 | KNN Loss: 4.178798198699951 | CLS Loss: 0.01733294688165188\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 4.207376956939697 | KNN Loss: 4.19334602355957 | CLS Loss: 0.014031060971319675\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 4.193978786468506 | KNN Loss: 4.160330772399902 | CLS Loss: 0.03364790976047516\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 4.196044921875 | KNN Loss: 4.149953365325928 | CLS Loss: 0.046091753989458084\n",
      "Epoch: 046, Loss: 4.1931, Train: 0.9939, Valid: 0.9867, Best: 0.9874\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 4.1810078620910645 | KNN Loss: 4.162217617034912 | CLS Loss: 0.018790021538734436\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 4.228856086730957 | KNN Loss: 4.207444667816162 | CLS Loss: 0.02141159400343895\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 4.248965263366699 | KNN Loss: 4.228144645690918 | CLS Loss: 0.02082083746790886\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 4.2409348487854 | KNN Loss: 4.19645881652832 | CLS Loss: 0.04447624459862709\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 4.172566890716553 | KNN Loss: 4.16497278213501 | CLS Loss: 0.007594241760671139\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 4.187604904174805 | KNN Loss: 4.153920650482178 | CLS Loss: 0.033684324473142624\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 4.209803581237793 | KNN Loss: 4.181846618652344 | CLS Loss: 0.027957012876868248\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 4.176416397094727 | KNN Loss: 4.146399974822998 | CLS Loss: 0.030016381293535233\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 4.202521324157715 | KNN Loss: 4.178560256958008 | CLS Loss: 0.02396085485816002\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 4.185574054718018 | KNN Loss: 4.164276123046875 | CLS Loss: 0.0212978757917881\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 4.1712117195129395 | KNN Loss: 4.139713287353516 | CLS Loss: 0.03149852901697159\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 4.2207112312316895 | KNN Loss: 4.1970953941345215 | CLS Loss: 0.02361604943871498\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 4.179868221282959 | KNN Loss: 4.169764995574951 | CLS Loss: 0.010103345848619938\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 4.189239978790283 | KNN Loss: 4.173023700714111 | CLS Loss: 0.016216399148106575\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 4.211465358734131 | KNN Loss: 4.17667293548584 | CLS Loss: 0.03479264676570892\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 4.19673490524292 | KNN Loss: 4.165948867797852 | CLS Loss: 0.03078615479171276\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 4.191194534301758 | KNN Loss: 4.1842756271362305 | CLS Loss: 0.006918805185705423\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 4.188316345214844 | KNN Loss: 4.178752899169922 | CLS Loss: 0.009563545696437359\n",
      "Epoch: 047, Loss: 4.1936, Train: 0.9932, Valid: 0.9856, Best: 0.9874\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 4.20849609375 | KNN Loss: 4.167925834655762 | CLS Loss: 0.0405704528093338\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 4.194446563720703 | KNN Loss: 4.183436870574951 | CLS Loss: 0.011009810492396355\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 4.198657035827637 | KNN Loss: 4.1845173835754395 | CLS Loss: 0.01413947343826294\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 4.198078155517578 | KNN Loss: 4.155421733856201 | CLS Loss: 0.042656395584344864\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 4.171942710876465 | KNN Loss: 4.165530204772949 | CLS Loss: 0.006412445101886988\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 4.181673526763916 | KNN Loss: 4.173917293548584 | CLS Loss: 0.0077562290243804455\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 4.189501762390137 | KNN Loss: 4.1761627197265625 | CLS Loss: 0.013338836841285229\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 4.205620765686035 | KNN Loss: 4.180326461791992 | CLS Loss: 0.025294316932559013\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 4.18942403793335 | KNN Loss: 4.175647735595703 | CLS Loss: 0.013776306062936783\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 4.210158348083496 | KNN Loss: 4.187727451324463 | CLS Loss: 0.02243092656135559\n",
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 4.149898529052734 | KNN Loss: 4.145320415496826 | CLS Loss: 0.004578327294439077\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 4.185749053955078 | KNN Loss: 4.1757025718688965 | CLS Loss: 0.010046363808214664\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 4.177646636962891 | KNN Loss: 4.17354154586792 | CLS Loss: 0.0041052293963730335\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 4.170279502868652 | KNN Loss: 4.157881736755371 | CLS Loss: 0.012397723272442818\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 4.142782211303711 | KNN Loss: 4.136840343475342 | CLS Loss: 0.005941672250628471\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 4.155729293823242 | KNN Loss: 4.1455230712890625 | CLS Loss: 0.010206068865954876\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 4.1945672035217285 | KNN Loss: 4.178823471069336 | CLS Loss: 0.015743577852845192\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 4.180670261383057 | KNN Loss: 4.16383695602417 | CLS Loss: 0.016833391040563583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 048, Loss: 4.1907, Train: 0.9950, Valid: 0.9879, Best: 0.9879\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 4.163189888000488 | KNN Loss: 4.160344123840332 | CLS Loss: 0.002845947165042162\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 4.2866668701171875 | KNN Loss: 4.2625346183776855 | CLS Loss: 0.024132052436470985\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 4.204080104827881 | KNN Loss: 4.172611236572266 | CLS Loss: 0.031468715518713\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 4.177768230438232 | KNN Loss: 4.155491352081299 | CLS Loss: 0.02227671816945076\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 4.18756628036499 | KNN Loss: 4.157102584838867 | CLS Loss: 0.030463803559541702\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 4.2115559577941895 | KNN Loss: 4.168483734130859 | CLS Loss: 0.04307224228978157\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 4.175419330596924 | KNN Loss: 4.1609063148498535 | CLS Loss: 0.014512856490910053\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 4.197321891784668 | KNN Loss: 4.178562164306641 | CLS Loss: 0.018759610131382942\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 4.168222904205322 | KNN Loss: 4.15365743637085 | CLS Loss: 0.014565289951860905\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 4.174947261810303 | KNN Loss: 4.152265548706055 | CLS Loss: 0.02268173359334469\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 4.179720878601074 | KNN Loss: 4.167015552520752 | CLS Loss: 0.012705517001450062\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 4.196966171264648 | KNN Loss: 4.192944049835205 | CLS Loss: 0.004022036213427782\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 4.147075653076172 | KNN Loss: 4.131864547729492 | CLS Loss: 0.015211106278002262\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 4.2096428871154785 | KNN Loss: 4.190805435180664 | CLS Loss: 0.018837498500943184\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 4.16729736328125 | KNN Loss: 4.152009010314941 | CLS Loss: 0.015288428403437138\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 4.1929030418396 | KNN Loss: 4.16909646987915 | CLS Loss: 0.02380673959851265\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 4.256644248962402 | KNN Loss: 4.223598003387451 | CLS Loss: 0.03304602578282356\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 4.249293804168701 | KNN Loss: 4.230764865875244 | CLS Loss: 0.018529042601585388\n",
      "Epoch: 049, Loss: 4.1873, Train: 0.9934, Valid: 0.9863, Best: 0.9879\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 4.166144371032715 | KNN Loss: 4.151632308959961 | CLS Loss: 0.014512255787849426\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 4.201415538787842 | KNN Loss: 4.186613082885742 | CLS Loss: 0.01480224821716547\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 4.164320945739746 | KNN Loss: 4.159572124481201 | CLS Loss: 0.004748890642076731\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 4.175463676452637 | KNN Loss: 4.161165714263916 | CLS Loss: 0.014298090711236\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 4.205219745635986 | KNN Loss: 4.188925266265869 | CLS Loss: 0.016294611617922783\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 4.158480644226074 | KNN Loss: 4.149875640869141 | CLS Loss: 0.008605034090578556\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 4.15903377532959 | KNN Loss: 4.132640838623047 | CLS Loss: 0.02639310248196125\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 4.209638595581055 | KNN Loss: 4.181829929351807 | CLS Loss: 0.02780867926776409\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 4.199491500854492 | KNN Loss: 4.178363800048828 | CLS Loss: 0.02112753316760063\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 4.2203474044799805 | KNN Loss: 4.174924850463867 | CLS Loss: 0.0454225018620491\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 4.18569803237915 | KNN Loss: 4.182580947875977 | CLS Loss: 0.0031170067377388477\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 4.1819000244140625 | KNN Loss: 4.169220447540283 | CLS Loss: 0.012679420411586761\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 4.175338268280029 | KNN Loss: 4.153205871582031 | CLS Loss: 0.022132374346256256\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 4.202076435089111 | KNN Loss: 4.164821147918701 | CLS Loss: 0.03725528344511986\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 4.238256931304932 | KNN Loss: 4.204583644866943 | CLS Loss: 0.03367330878973007\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 4.185307502746582 | KNN Loss: 4.160575866699219 | CLS Loss: 0.024731609970331192\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 4.1787848472595215 | KNN Loss: 4.164816856384277 | CLS Loss: 0.013968060724437237\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 4.163534164428711 | KNN Loss: 4.156924724578857 | CLS Loss: 0.0066095818765461445\n",
      "Epoch: 050, Loss: 4.1841, Train: 0.9944, Valid: 0.9867, Best: 0.9879\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 4.201714515686035 | KNN Loss: 4.173877716064453 | CLS Loss: 0.02783701941370964\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 4.2541584968566895 | KNN Loss: 4.212317943572998 | CLS Loss: 0.04184042662382126\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 4.179852485656738 | KNN Loss: 4.172332286834717 | CLS Loss: 0.0075201066210865974\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 4.2083282470703125 | KNN Loss: 4.1919660568237305 | CLS Loss: 0.016362033784389496\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 4.147115707397461 | KNN Loss: 4.144021987915039 | CLS Loss: 0.0030937278643250465\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 4.193595886230469 | KNN Loss: 4.182469844818115 | CLS Loss: 0.011125973425805569\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 4.188407897949219 | KNN Loss: 4.182486534118652 | CLS Loss: 0.005921263713389635\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 4.18960428237915 | KNN Loss: 4.177198886871338 | CLS Loss: 0.01240541972219944\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 4.174911022186279 | KNN Loss: 4.144558429718018 | CLS Loss: 0.030352694913744926\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 4.172999858856201 | KNN Loss: 4.161128997802734 | CLS Loss: 0.011870933696627617\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 4.174712181091309 | KNN Loss: 4.163503646850586 | CLS Loss: 0.011208639480173588\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 4.167496681213379 | KNN Loss: 4.165184497833252 | CLS Loss: 0.0023120027035474777\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 4.146081447601318 | KNN Loss: 4.133423328399658 | CLS Loss: 0.012658141553401947\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 4.161506175994873 | KNN Loss: 4.14951753616333 | CLS Loss: 0.011988661251962185\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 4.159714221954346 | KNN Loss: 4.149970531463623 | CLS Loss: 0.009743845090270042\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 4.180567741394043 | KNN Loss: 4.160369873046875 | CLS Loss: 0.02019786462187767\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 4.230477333068848 | KNN Loss: 4.200753211975098 | CLS Loss: 0.02972433902323246\n",
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 4.190188884735107 | KNN Loss: 4.1845479011535645 | CLS Loss: 0.005640968680381775\n",
      "Epoch: 051, Loss: 4.1847, Train: 0.9948, Valid: 0.9868, Best: 0.9879\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 4.170533180236816 | KNN Loss: 4.1514177322387695 | CLS Loss: 0.01911562867462635\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 4.143402576446533 | KNN Loss: 4.139865875244141 | CLS Loss: 0.0035365670919418335\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 4.1929779052734375 | KNN Loss: 4.170145034790039 | CLS Loss: 0.022832944989204407\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 4.194648265838623 | KNN Loss: 4.171138286590576 | CLS Loss: 0.023510076105594635\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 4.187668800354004 | KNN Loss: 4.157467365264893 | CLS Loss: 0.030201654881238937\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 4.15844202041626 | KNN Loss: 4.15342378616333 | CLS Loss: 0.005018323194235563\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 4.226425647735596 | KNN Loss: 4.1934919357299805 | CLS Loss: 0.03293367102742195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 4.197727680206299 | KNN Loss: 4.181432247161865 | CLS Loss: 0.016295595094561577\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 4.183227062225342 | KNN Loss: 4.17805814743042 | CLS Loss: 0.005169024225324392\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 4.170871734619141 | KNN Loss: 4.148606777191162 | CLS Loss: 0.022264782339334488\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 4.15255069732666 | KNN Loss: 4.133375644683838 | CLS Loss: 0.019175026565790176\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 4.185458660125732 | KNN Loss: 4.17549467086792 | CLS Loss: 0.009963990189135075\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 4.177595138549805 | KNN Loss: 4.153993606567383 | CLS Loss: 0.023601680994033813\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 4.218579292297363 | KNN Loss: 4.176449775695801 | CLS Loss: 0.042129743844270706\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 4.171987533569336 | KNN Loss: 4.159819602966309 | CLS Loss: 0.012168051674962044\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 4.161737442016602 | KNN Loss: 4.152797698974609 | CLS Loss: 0.008939554914832115\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 4.191661834716797 | KNN Loss: 4.14843225479126 | CLS Loss: 0.04322964325547218\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 4.22640323638916 | KNN Loss: 4.205777168273926 | CLS Loss: 0.020626042038202286\n",
      "Epoch: 052, Loss: 4.1846, Train: 0.9915, Valid: 0.9841, Best: 0.9879\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 4.198457717895508 | KNN Loss: 4.1591596603393555 | CLS Loss: 0.03929783031344414\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 4.192314147949219 | KNN Loss: 4.1835198402404785 | CLS Loss: 0.008794459514319897\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 4.173971176147461 | KNN Loss: 4.141645908355713 | CLS Loss: 0.03232535347342491\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 4.14367151260376 | KNN Loss: 4.136600494384766 | CLS Loss: 0.007071177940815687\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 4.162705898284912 | KNN Loss: 4.151925563812256 | CLS Loss: 0.01078032050281763\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 4.185308933258057 | KNN Loss: 4.165715217590332 | CLS Loss: 0.019593877717852592\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 4.157016277313232 | KNN Loss: 4.144031047821045 | CLS Loss: 0.01298534870147705\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 4.142202854156494 | KNN Loss: 4.130797863006592 | CLS Loss: 0.01140514574944973\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 4.202754974365234 | KNN Loss: 4.1856608390808105 | CLS Loss: 0.017093930393457413\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 4.147915840148926 | KNN Loss: 4.1380462646484375 | CLS Loss: 0.009869375266134739\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 4.24186372756958 | KNN Loss: 4.186001300811768 | CLS Loss: 0.05586247146129608\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 4.207179546356201 | KNN Loss: 4.182607650756836 | CLS Loss: 0.024572016671299934\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 4.181131362915039 | KNN Loss: 4.146085739135742 | CLS Loss: 0.03504543378949165\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 4.187066078186035 | KNN Loss: 4.156020641326904 | CLS Loss: 0.03104529343545437\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 4.15701961517334 | KNN Loss: 4.143773078918457 | CLS Loss: 0.013246512971818447\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 4.18688440322876 | KNN Loss: 4.180174827575684 | CLS Loss: 0.006709595210850239\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 4.161318778991699 | KNN Loss: 4.1474833488464355 | CLS Loss: 0.013835449703037739\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 4.1723432540893555 | KNN Loss: 4.158663749694824 | CLS Loss: 0.013679307885468006\n",
      "Epoch: 053, Loss: 4.1828, Train: 0.9955, Valid: 0.9872, Best: 0.9879\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 4.164789199829102 | KNN Loss: 4.152031898498535 | CLS Loss: 0.012757535092532635\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 4.16298246383667 | KNN Loss: 4.136585712432861 | CLS Loss: 0.026396609842777252\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 4.195633888244629 | KNN Loss: 4.169285774230957 | CLS Loss: 0.026347901672124863\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 4.1832146644592285 | KNN Loss: 4.17404317855835 | CLS Loss: 0.009171546436846256\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 4.193742752075195 | KNN Loss: 4.175182342529297 | CLS Loss: 0.018560195341706276\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 4.182219505310059 | KNN Loss: 4.171514511108398 | CLS Loss: 0.010704978369176388\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 4.164927005767822 | KNN Loss: 4.154233932495117 | CLS Loss: 0.010692846029996872\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 4.1796698570251465 | KNN Loss: 4.145874977111816 | CLS Loss: 0.03379478305578232\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 4.170319557189941 | KNN Loss: 4.167366981506348 | CLS Loss: 0.0029524206183850765\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 4.196499824523926 | KNN Loss: 4.181569576263428 | CLS Loss: 0.014930084347724915\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 4.193883895874023 | KNN Loss: 4.173069477081299 | CLS Loss: 0.020814377814531326\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 4.206416606903076 | KNN Loss: 4.195710182189941 | CLS Loss: 0.010706447064876556\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 4.163939952850342 | KNN Loss: 4.133701324462891 | CLS Loss: 0.03023861162364483\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 4.2239155769348145 | KNN Loss: 4.203760147094727 | CLS Loss: 0.020155491307377815\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 4.220485210418701 | KNN Loss: 4.176624298095703 | CLS Loss: 0.04386068880558014\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 4.166382789611816 | KNN Loss: 4.158744812011719 | CLS Loss: 0.0076377857476472855\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 4.161260604858398 | KNN Loss: 4.1571879386901855 | CLS Loss: 0.004072831943631172\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 4.169722557067871 | KNN Loss: 4.150811672210693 | CLS Loss: 0.018910983577370644\n",
      "Epoch: 054, Loss: 4.1823, Train: 0.9951, Valid: 0.9867, Best: 0.9879\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 4.170969009399414 | KNN Loss: 4.158548831939697 | CLS Loss: 0.012420072220265865\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 4.184762001037598 | KNN Loss: 4.174417972564697 | CLS Loss: 0.010344218462705612\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 4.132965564727783 | KNN Loss: 4.128021717071533 | CLS Loss: 0.004943888168781996\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 4.195703506469727 | KNN Loss: 4.188354969024658 | CLS Loss: 0.007348363287746906\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 4.146317005157471 | KNN Loss: 4.1230340003967285 | CLS Loss: 0.02328324131667614\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 4.1742658615112305 | KNN Loss: 4.153871536254883 | CLS Loss: 0.020394310355186462\n",
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 4.182819843292236 | KNN Loss: 4.159493923187256 | CLS Loss: 0.02332586981356144\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 4.160623073577881 | KNN Loss: 4.154711723327637 | CLS Loss: 0.005911512766033411\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 4.244514465332031 | KNN Loss: 4.213730812072754 | CLS Loss: 0.030783792957663536\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 4.205426216125488 | KNN Loss: 4.169192314147949 | CLS Loss: 0.03623369708657265\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 4.198314666748047 | KNN Loss: 4.18131160736084 | CLS Loss: 0.017003247514367104\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 4.220404148101807 | KNN Loss: 4.205493450164795 | CLS Loss: 0.0149107426404953\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 4.177445888519287 | KNN Loss: 4.171693325042725 | CLS Loss: 0.005752719938755035\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 4.193484306335449 | KNN Loss: 4.175325870513916 | CLS Loss: 0.018158648163080215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 4.197900772094727 | KNN Loss: 4.166614055633545 | CLS Loss: 0.03128694370388985\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 4.180901527404785 | KNN Loss: 4.161993503570557 | CLS Loss: 0.018908172845840454\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 4.196558475494385 | KNN Loss: 4.165285587310791 | CLS Loss: 0.03127269074320793\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 4.185582637786865 | KNN Loss: 4.162908554077148 | CLS Loss: 0.02267426624894142\n",
      "Epoch: 055, Loss: 4.1812, Train: 0.9953, Valid: 0.9866, Best: 0.9879\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 4.168360233306885 | KNN Loss: 4.162323474884033 | CLS Loss: 0.006036869715899229\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 4.1695098876953125 | KNN Loss: 4.158447742462158 | CLS Loss: 0.011062183417379856\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 4.168417930603027 | KNN Loss: 4.160828590393066 | CLS Loss: 0.007589166518300772\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 4.188268184661865 | KNN Loss: 4.178426265716553 | CLS Loss: 0.009841802529990673\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 4.1788530349731445 | KNN Loss: 4.15773344039917 | CLS Loss: 0.02111957035958767\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 4.1942315101623535 | KNN Loss: 4.170901775360107 | CLS Loss: 0.02332969568669796\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 4.206594944000244 | KNN Loss: 4.193497657775879 | CLS Loss: 0.013097519986331463\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 4.172707557678223 | KNN Loss: 4.149807929992676 | CLS Loss: 0.022899683564901352\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 4.19113826751709 | KNN Loss: 4.168753623962402 | CLS Loss: 0.022384483367204666\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 4.18285608291626 | KNN Loss: 4.167800426483154 | CLS Loss: 0.015055439434945583\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 4.167683124542236 | KNN Loss: 4.155278205871582 | CLS Loss: 0.012404982931911945\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 4.184299945831299 | KNN Loss: 4.156184673309326 | CLS Loss: 0.02811523526906967\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 4.159926414489746 | KNN Loss: 4.146512031555176 | CLS Loss: 0.013414314948022366\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 4.182971954345703 | KNN Loss: 4.167156219482422 | CLS Loss: 0.015815837308764458\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 4.193105697631836 | KNN Loss: 4.165619373321533 | CLS Loss: 0.02748609147965908\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 4.168335914611816 | KNN Loss: 4.154263973236084 | CLS Loss: 0.014071895740926266\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 4.2019195556640625 | KNN Loss: 4.170051097869873 | CLS Loss: 0.03186823055148125\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 4.216889381408691 | KNN Loss: 4.186391830444336 | CLS Loss: 0.030497657135128975\n",
      "Epoch: 056, Loss: 4.1866, Train: 0.9960, Valid: 0.9876, Best: 0.9879\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 4.17483377456665 | KNN Loss: 4.168944358825684 | CLS Loss: 0.005889503285288811\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 4.151230335235596 | KNN Loss: 4.146012783050537 | CLS Loss: 0.0052176001481711864\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 4.201686859130859 | KNN Loss: 4.199420928955078 | CLS Loss: 0.0022657294757664204\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 4.206174373626709 | KNN Loss: 4.1915059089660645 | CLS Loss: 0.014668666757643223\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 4.19728946685791 | KNN Loss: 4.1665215492248535 | CLS Loss: 0.030767910182476044\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 4.180059909820557 | KNN Loss: 4.174118518829346 | CLS Loss: 0.005941462703049183\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 4.193140983581543 | KNN Loss: 4.178147792816162 | CLS Loss: 0.014993163757026196\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 4.1730732917785645 | KNN Loss: 4.161705017089844 | CLS Loss: 0.011368483304977417\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 4.197641372680664 | KNN Loss: 4.166079998016357 | CLS Loss: 0.03156120702624321\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 4.188053131103516 | KNN Loss: 4.171475410461426 | CLS Loss: 0.016577592119574547\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 4.163137912750244 | KNN Loss: 4.155949115753174 | CLS Loss: 0.007188716437667608\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 4.153277397155762 | KNN Loss: 4.145432472229004 | CLS Loss: 0.00784486997872591\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 4.15078067779541 | KNN Loss: 4.1472296714782715 | CLS Loss: 0.003550988622009754\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 4.205069065093994 | KNN Loss: 4.176292419433594 | CLS Loss: 0.02877642959356308\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 4.183730125427246 | KNN Loss: 4.163395881652832 | CLS Loss: 0.020334098488092422\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 4.144663333892822 | KNN Loss: 4.120355606079102 | CLS Loss: 0.024307897314429283\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 4.2353925704956055 | KNN Loss: 4.17922830581665 | CLS Loss: 0.05616408959031105\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 4.190025329589844 | KNN Loss: 4.158937454223633 | CLS Loss: 0.031087802723050117\n",
      "Epoch: 057, Loss: 4.1799, Train: 0.9956, Valid: 0.9870, Best: 0.9879\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 4.1693620681762695 | KNN Loss: 4.16542387008667 | CLS Loss: 0.003938323352485895\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 4.209836006164551 | KNN Loss: 4.180052280426025 | CLS Loss: 0.029783770442008972\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 4.190300941467285 | KNN Loss: 4.171943664550781 | CLS Loss: 0.018357394263148308\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 4.2374796867370605 | KNN Loss: 4.162878036499023 | CLS Loss: 0.07460187375545502\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 4.211075305938721 | KNN Loss: 4.194072246551514 | CLS Loss: 0.017003251239657402\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 4.180953025817871 | KNN Loss: 4.1630401611328125 | CLS Loss: 0.01791275665163994\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 4.171546936035156 | KNN Loss: 4.1459784507751465 | CLS Loss: 0.025568263605237007\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 4.152580738067627 | KNN Loss: 4.146090030670166 | CLS Loss: 0.006490616127848625\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 4.195610046386719 | KNN Loss: 4.172053813934326 | CLS Loss: 0.023556284606456757\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 4.179668426513672 | KNN Loss: 4.158783435821533 | CLS Loss: 0.020885096862912178\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 4.242191314697266 | KNN Loss: 4.210935115814209 | CLS Loss: 0.031256068497896194\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 4.1758222579956055 | KNN Loss: 4.147269248962402 | CLS Loss: 0.028553146868944168\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 4.195730686187744 | KNN Loss: 4.180099010467529 | CLS Loss: 0.015631569549441338\n",
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 4.207084655761719 | KNN Loss: 4.185862064361572 | CLS Loss: 0.021222813054919243\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 4.1838579177856445 | KNN Loss: 4.1730546951293945 | CLS Loss: 0.010803014039993286\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 4.162992477416992 | KNN Loss: 4.125635623931885 | CLS Loss: 0.03735673427581787\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 4.204719543457031 | KNN Loss: 4.186535358428955 | CLS Loss: 0.018184058368206024\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 4.193722724914551 | KNN Loss: 4.163538932800293 | CLS Loss: 0.030183879658579826\n",
      "Epoch: 058, Loss: 4.1840, Train: 0.9948, Valid: 0.9857, Best: 0.9879\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 4.166998863220215 | KNN Loss: 4.1405463218688965 | CLS Loss: 0.026452310383319855\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 4.159529209136963 | KNN Loss: 4.144011974334717 | CLS Loss: 0.015517215244472027\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 4.146531105041504 | KNN Loss: 4.133096694946289 | CLS Loss: 0.013434600085020065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 4.235450267791748 | KNN Loss: 4.224225997924805 | CLS Loss: 0.011224178597331047\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 4.189977169036865 | KNN Loss: 4.181004047393799 | CLS Loss: 0.008973284624516964\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 4.2686333656311035 | KNN Loss: 4.242259502410889 | CLS Loss: 0.026374027132987976\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 4.149801254272461 | KNN Loss: 4.1427435874938965 | CLS Loss: 0.007057898677885532\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 4.195149898529053 | KNN Loss: 4.171325206756592 | CLS Loss: 0.023824622854590416\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 4.235574245452881 | KNN Loss: 4.228626728057861 | CLS Loss: 0.00694735161960125\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 4.159236431121826 | KNN Loss: 4.141646862030029 | CLS Loss: 0.017589615657925606\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 4.204322814941406 | KNN Loss: 4.195101261138916 | CLS Loss: 0.00922140572220087\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 4.171535968780518 | KNN Loss: 4.141229152679443 | CLS Loss: 0.030306659638881683\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 4.165847301483154 | KNN Loss: 4.156506538391113 | CLS Loss: 0.009340869262814522\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 4.185445785522461 | KNN Loss: 4.175044536590576 | CLS Loss: 0.010401195846498013\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 4.168553352355957 | KNN Loss: 4.147294998168945 | CLS Loss: 0.021258478984236717\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 4.215836048126221 | KNN Loss: 4.178964614868164 | CLS Loss: 0.036871664226055145\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 4.209287166595459 | KNN Loss: 4.179990768432617 | CLS Loss: 0.029296567663550377\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 4.1817193031311035 | KNN Loss: 4.17130184173584 | CLS Loss: 0.010417564772069454\n",
      "Epoch: 059, Loss: 4.1829, Train: 0.9955, Valid: 0.9870, Best: 0.9879\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 4.169187068939209 | KNN Loss: 4.136969089508057 | CLS Loss: 0.032218076288700104\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 4.132063865661621 | KNN Loss: 4.1270246505737305 | CLS Loss: 0.005039255600422621\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 4.235256671905518 | KNN Loss: 4.2136688232421875 | CLS Loss: 0.02158772386610508\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 4.176461219787598 | KNN Loss: 4.157541275024414 | CLS Loss: 0.018920108675956726\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 4.171559810638428 | KNN Loss: 4.1626176834106445 | CLS Loss: 0.008942135609686375\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 4.162036418914795 | KNN Loss: 4.158834934234619 | CLS Loss: 0.003201568964868784\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 4.146846771240234 | KNN Loss: 4.131287097930908 | CLS Loss: 0.01555949728935957\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 4.176368236541748 | KNN Loss: 4.164567470550537 | CLS Loss: 0.01180066354572773\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 4.189706325531006 | KNN Loss: 4.178088188171387 | CLS Loss: 0.011618091724812984\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 4.211684226989746 | KNN Loss: 4.197152137756348 | CLS Loss: 0.014532172121107578\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 4.1636576652526855 | KNN Loss: 4.159360408782959 | CLS Loss: 0.0042974017560482025\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 4.2022013664245605 | KNN Loss: 4.1846513748168945 | CLS Loss: 0.01755000650882721\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 4.204962730407715 | KNN Loss: 4.189757347106934 | CLS Loss: 0.015205197036266327\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 4.1927337646484375 | KNN Loss: 4.154670715332031 | CLS Loss: 0.038063131272792816\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 4.158835411071777 | KNN Loss: 4.134130954742432 | CLS Loss: 0.024704614654183388\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 4.234512805938721 | KNN Loss: 4.209253311157227 | CLS Loss: 0.025259273126721382\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 4.167957305908203 | KNN Loss: 4.147794723510742 | CLS Loss: 0.020162709057331085\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 4.193023681640625 | KNN Loss: 4.166621685028076 | CLS Loss: 0.0264021847397089\n",
      "Epoch: 060, Loss: 4.1810, Train: 0.9937, Valid: 0.9844, Best: 0.9879\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 4.199336528778076 | KNN Loss: 4.178484916687012 | CLS Loss: 0.020851651206612587\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 4.1577253341674805 | KNN Loss: 4.145476341247559 | CLS Loss: 0.012248801998794079\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 4.201461315155029 | KNN Loss: 4.184706211090088 | CLS Loss: 0.016755107790231705\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 4.176918029785156 | KNN Loss: 4.16215705871582 | CLS Loss: 0.014760940335690975\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 4.182790279388428 | KNN Loss: 4.149914264678955 | CLS Loss: 0.03287617489695549\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 4.161318778991699 | KNN Loss: 4.157345294952393 | CLS Loss: 0.003973640035837889\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 4.139970779418945 | KNN Loss: 4.119128704071045 | CLS Loss: 0.02084195986390114\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 4.17912483215332 | KNN Loss: 4.159255504608154 | CLS Loss: 0.01986934430897236\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 4.214445114135742 | KNN Loss: 4.192777156829834 | CLS Loss: 0.021667957305908203\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 4.142159461975098 | KNN Loss: 4.127037525177002 | CLS Loss: 0.015121985226869583\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 4.186108112335205 | KNN Loss: 4.177020072937012 | CLS Loss: 0.009088222868740559\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 4.157104969024658 | KNN Loss: 4.133533000946045 | CLS Loss: 0.023571886122226715\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 4.2103471755981445 | KNN Loss: 4.188990592956543 | CLS Loss: 0.021356552839279175\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 4.2635498046875 | KNN Loss: 4.251709938049316 | CLS Loss: 0.011839909479022026\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 4.207583427429199 | KNN Loss: 4.198441028594971 | CLS Loss: 0.009142483584582806\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 4.226620197296143 | KNN Loss: 4.199398040771484 | CLS Loss: 0.02722223661839962\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 4.1950507164001465 | KNN Loss: 4.179428577423096 | CLS Loss: 0.015621989965438843\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 4.182200908660889 | KNN Loss: 4.162265777587891 | CLS Loss: 0.019934991374611855\n",
      "Epoch: 061, Loss: 4.1783, Train: 0.9930, Valid: 0.9839, Best: 0.9879\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 4.166769027709961 | KNN Loss: 4.14617395401001 | CLS Loss: 0.02059483714401722\n",
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 4.164035320281982 | KNN Loss: 4.159564018249512 | CLS Loss: 0.004471453372389078\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 4.169483184814453 | KNN Loss: 4.1575517654418945 | CLS Loss: 0.011931582354009151\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 4.158999919891357 | KNN Loss: 4.153131008148193 | CLS Loss: 0.005868787877261639\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 4.159240245819092 | KNN Loss: 4.152321815490723 | CLS Loss: 0.006918198894709349\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 4.165303707122803 | KNN Loss: 4.146073341369629 | CLS Loss: 0.019230471923947334\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 4.181704044342041 | KNN Loss: 4.143202781677246 | CLS Loss: 0.0385010652244091\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 4.174558162689209 | KNN Loss: 4.1475300788879395 | CLS Loss: 0.02702825702726841\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 4.183938503265381 | KNN Loss: 4.174031734466553 | CLS Loss: 0.009906594641506672\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 4.183776378631592 | KNN Loss: 4.170397758483887 | CLS Loss: 0.013378633186221123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 4.20235538482666 | KNN Loss: 4.177860736846924 | CLS Loss: 0.024494634941220284\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 4.153744220733643 | KNN Loss: 4.148408889770508 | CLS Loss: 0.005335189867764711\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 4.176042556762695 | KNN Loss: 4.166662216186523 | CLS Loss: 0.009380178526043892\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 4.2133307456970215 | KNN Loss: 4.1831183433532715 | CLS Loss: 0.030212225392460823\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 4.197668075561523 | KNN Loss: 4.183560848236084 | CLS Loss: 0.014107326976954937\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 4.1816301345825195 | KNN Loss: 4.1582489013671875 | CLS Loss: 0.023381469771265984\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 4.152663230895996 | KNN Loss: 4.140800476074219 | CLS Loss: 0.011862615123391151\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 4.2052083015441895 | KNN Loss: 4.179224014282227 | CLS Loss: 0.025984199717640877\n",
      "Epoch: 062, Loss: 4.1790, Train: 0.9962, Valid: 0.9871, Best: 0.9879\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 4.190238952636719 | KNN Loss: 4.170583248138428 | CLS Loss: 0.019655602052807808\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 4.157100200653076 | KNN Loss: 4.136534214019775 | CLS Loss: 0.02056586742401123\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 4.179802417755127 | KNN Loss: 4.1677937507629395 | CLS Loss: 0.01200860645622015\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 4.174951076507568 | KNN Loss: 4.153615951538086 | CLS Loss: 0.021334946155548096\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 4.151266574859619 | KNN Loss: 4.141604900360107 | CLS Loss: 0.009661771357059479\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 4.1827473640441895 | KNN Loss: 4.152549743652344 | CLS Loss: 0.03019748441874981\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 4.153167724609375 | KNN Loss: 4.136858940124512 | CLS Loss: 0.016308989375829697\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 4.149814128875732 | KNN Loss: 4.135646820068359 | CLS Loss: 0.01416739821434021\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 4.154163837432861 | KNN Loss: 4.143771171569824 | CLS Loss: 0.01039262767881155\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 4.116539001464844 | KNN Loss: 4.114347457885742 | CLS Loss: 0.0021917130798101425\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 4.1730828285217285 | KNN Loss: 4.155306816101074 | CLS Loss: 0.017775848507881165\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 4.216407775878906 | KNN Loss: 4.186183452606201 | CLS Loss: 0.030224185436964035\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 4.15983772277832 | KNN Loss: 4.151977062225342 | CLS Loss: 0.007860648445785046\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 4.195429801940918 | KNN Loss: 4.172580242156982 | CLS Loss: 0.0228495541960001\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 4.144266128540039 | KNN Loss: 4.1352458000183105 | CLS Loss: 0.009020119905471802\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 4.179348468780518 | KNN Loss: 4.155653476715088 | CLS Loss: 0.023694874718785286\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 4.185988426208496 | KNN Loss: 4.159749984741211 | CLS Loss: 0.02623850665986538\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 4.158080101013184 | KNN Loss: 4.148691654205322 | CLS Loss: 0.009388607926666737\n",
      "Epoch: 063, Loss: 4.1710, Train: 0.9959, Valid: 0.9858, Best: 0.9879\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 4.174429893493652 | KNN Loss: 4.161178112030029 | CLS Loss: 0.01325155422091484\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 4.163647174835205 | KNN Loss: 4.15295934677124 | CLS Loss: 0.010687977075576782\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 4.178771495819092 | KNN Loss: 4.168242454528809 | CLS Loss: 0.010529125109314919\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 4.191271781921387 | KNN Loss: 4.1833367347717285 | CLS Loss: 0.007934829220175743\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 4.132258892059326 | KNN Loss: 4.1195387840271 | CLS Loss: 0.012720228172838688\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 4.200666904449463 | KNN Loss: 4.1604461669921875 | CLS Loss: 0.04022052884101868\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 4.159411907196045 | KNN Loss: 4.156297206878662 | CLS Loss: 0.0031146095134317875\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 4.190613269805908 | KNN Loss: 4.187180519104004 | CLS Loss: 0.00343274581246078\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 4.169785976409912 | KNN Loss: 4.1620659828186035 | CLS Loss: 0.007720071356743574\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 4.149916172027588 | KNN Loss: 4.126101970672607 | CLS Loss: 0.02381431683897972\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 4.158755779266357 | KNN Loss: 4.14715576171875 | CLS Loss: 0.011599984019994736\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 4.176358699798584 | KNN Loss: 4.169495582580566 | CLS Loss: 0.00686316704377532\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 4.196305751800537 | KNN Loss: 4.159143447875977 | CLS Loss: 0.037162166088819504\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 4.180665493011475 | KNN Loss: 4.16555118560791 | CLS Loss: 0.015114111825823784\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 4.166365623474121 | KNN Loss: 4.148561000823975 | CLS Loss: 0.017804455012083054\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 4.187809944152832 | KNN Loss: 4.164581298828125 | CLS Loss: 0.023228783160448074\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 4.194508075714111 | KNN Loss: 4.172916889190674 | CLS Loss: 0.02159123122692108\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 4.187851905822754 | KNN Loss: 4.160478591918945 | CLS Loss: 0.02737327106297016\n",
      "Epoch: 064, Loss: 4.1721, Train: 0.9960, Valid: 0.9865, Best: 0.9879\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 4.174482345581055 | KNN Loss: 4.160491466522217 | CLS Loss: 0.013990762643516064\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 4.165686130523682 | KNN Loss: 4.156645774841309 | CLS Loss: 0.009040138684213161\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 4.186513423919678 | KNN Loss: 4.169123649597168 | CLS Loss: 0.017389684915542603\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 4.210727691650391 | KNN Loss: 4.183605194091797 | CLS Loss: 0.027122467756271362\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 4.144776344299316 | KNN Loss: 4.115780830383301 | CLS Loss: 0.02899535931646824\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 4.1562066078186035 | KNN Loss: 4.148160457611084 | CLS Loss: 0.008046241477131844\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 4.211493015289307 | KNN Loss: 4.196728706359863 | CLS Loss: 0.014764453284442425\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 4.158834934234619 | KNN Loss: 4.152988910675049 | CLS Loss: 0.005845964886248112\n",
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 4.196225166320801 | KNN Loss: 4.1540422439575195 | CLS Loss: 0.04218296334147453\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 4.161036968231201 | KNN Loss: 4.151515960693359 | CLS Loss: 0.009521101601421833\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 4.159393310546875 | KNN Loss: 4.146321773529053 | CLS Loss: 0.013071538880467415\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 4.217535018920898 | KNN Loss: 4.196287631988525 | CLS Loss: 0.02124715968966484\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 4.214343547821045 | KNN Loss: 4.190556049346924 | CLS Loss: 0.023787356913089752\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 4.20728063583374 | KNN Loss: 4.183588027954102 | CLS Loss: 0.02369271032512188\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 4.1492791175842285 | KNN Loss: 4.146113872528076 | CLS Loss: 0.0031650662422180176\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 4.1761651039123535 | KNN Loss: 4.156399250030518 | CLS Loss: 0.019765906035900116\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 4.181726455688477 | KNN Loss: 4.173740863800049 | CLS Loss: 0.007985481061041355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 4.169375896453857 | KNN Loss: 4.127748489379883 | CLS Loss: 0.041627321392297745\n",
      "Epoch: 065, Loss: 4.1843, Train: 0.9954, Valid: 0.9860, Best: 0.9879\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 4.190199851989746 | KNN Loss: 4.179450511932373 | CLS Loss: 0.010749546810984612\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 4.161864280700684 | KNN Loss: 4.119619369506836 | CLS Loss: 0.04224475100636482\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 4.153781890869141 | KNN Loss: 4.14592170715332 | CLS Loss: 0.007860290817916393\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 4.176140308380127 | KNN Loss: 4.16296911239624 | CLS Loss: 0.013171353377401829\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 4.151883602142334 | KNN Loss: 4.1373162269592285 | CLS Loss: 0.014567478559911251\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 4.145975112915039 | KNN Loss: 4.138625144958496 | CLS Loss: 0.007349858991801739\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 4.153185844421387 | KNN Loss: 4.139832496643066 | CLS Loss: 0.01335345022380352\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 4.196847915649414 | KNN Loss: 4.179057598114014 | CLS Loss: 0.01779051683843136\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 4.160300254821777 | KNN Loss: 4.144303798675537 | CLS Loss: 0.01599626988172531\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 4.176937580108643 | KNN Loss: 4.165998935699463 | CLS Loss: 0.010938452556729317\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 4.209447860717773 | KNN Loss: 4.1944732666015625 | CLS Loss: 0.0149745624512434\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 4.173050403594971 | KNN Loss: 4.160722732543945 | CLS Loss: 0.012327681295573711\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 4.188682556152344 | KNN Loss: 4.160111427307129 | CLS Loss: 0.028571201488375664\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 4.187994003295898 | KNN Loss: 4.17365837097168 | CLS Loss: 0.014335457235574722\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 4.191879749298096 | KNN Loss: 4.172183513641357 | CLS Loss: 0.019696436822414398\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 4.168583393096924 | KNN Loss: 4.158904075622559 | CLS Loss: 0.009679296985268593\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 4.188111305236816 | KNN Loss: 4.179360866546631 | CLS Loss: 0.00875064916908741\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 4.140234470367432 | KNN Loss: 4.125245571136475 | CLS Loss: 0.0149890948086977\n",
      "Epoch: 066, Loss: 4.1761, Train: 0.9941, Valid: 0.9854, Best: 0.9879\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 4.153891086578369 | KNN Loss: 4.144060134887695 | CLS Loss: 0.009831095114350319\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 4.181248188018799 | KNN Loss: 4.17238712310791 | CLS Loss: 0.008860979229211807\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 4.193974018096924 | KNN Loss: 4.185308456420898 | CLS Loss: 0.008665431290864944\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 4.1836323738098145 | KNN Loss: 4.163985729217529 | CLS Loss: 0.01964658312499523\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 4.165143966674805 | KNN Loss: 4.158982276916504 | CLS Loss: 0.006161477882415056\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 4.17227029800415 | KNN Loss: 4.166926860809326 | CLS Loss: 0.005343309137970209\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 4.169253826141357 | KNN Loss: 4.164489269256592 | CLS Loss: 0.0047644954174757\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 4.162191867828369 | KNN Loss: 4.144258499145508 | CLS Loss: 0.017933251336216927\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 4.144898414611816 | KNN Loss: 4.135195255279541 | CLS Loss: 0.009703307412564754\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 4.183154582977295 | KNN Loss: 4.1720757484436035 | CLS Loss: 0.011078717187047005\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 4.1651129722595215 | KNN Loss: 4.13932991027832 | CLS Loss: 0.02578299306333065\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 4.136587619781494 | KNN Loss: 4.1189961433410645 | CLS Loss: 0.017591582611203194\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 4.168467998504639 | KNN Loss: 4.164417743682861 | CLS Loss: 0.00405025202780962\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 4.134628772735596 | KNN Loss: 4.119854927062988 | CLS Loss: 0.014773745089769363\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 4.262957572937012 | KNN Loss: 4.223674774169922 | CLS Loss: 0.039282768964767456\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 4.142125606536865 | KNN Loss: 4.11647367477417 | CLS Loss: 0.025651752948760986\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 4.210969924926758 | KNN Loss: 4.17178201675415 | CLS Loss: 0.039187848567962646\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 4.17847204208374 | KNN Loss: 4.160007476806641 | CLS Loss: 0.018464671447873116\n",
      "Epoch: 067, Loss: 4.1744, Train: 0.9962, Valid: 0.9872, Best: 0.9879\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 4.168150424957275 | KNN Loss: 4.157182693481445 | CLS Loss: 0.010967527516186237\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 4.141295909881592 | KNN Loss: 4.13730001449585 | CLS Loss: 0.0039956774562597275\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 4.191760540008545 | KNN Loss: 4.165517330169678 | CLS Loss: 0.026243234053254128\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 4.185739517211914 | KNN Loss: 4.163616180419922 | CLS Loss: 0.022123413160443306\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 4.182145595550537 | KNN Loss: 4.14823055267334 | CLS Loss: 0.033915042877197266\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 4.1667799949646 | KNN Loss: 4.151928901672363 | CLS Loss: 0.014851237647235394\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 4.1611247062683105 | KNN Loss: 4.140763282775879 | CLS Loss: 0.020361604169011116\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 4.200231075286865 | KNN Loss: 4.185633659362793 | CLS Loss: 0.014597645029425621\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 4.190516471862793 | KNN Loss: 4.171223163604736 | CLS Loss: 0.01929347775876522\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 4.189722061157227 | KNN Loss: 4.170147895812988 | CLS Loss: 0.019574007019400597\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 4.1593523025512695 | KNN Loss: 4.148040771484375 | CLS Loss: 0.011311622336506844\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 4.139098644256592 | KNN Loss: 4.135462760925293 | CLS Loss: 0.003635925240814686\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 4.191365718841553 | KNN Loss: 4.176218509674072 | CLS Loss: 0.015146985650062561\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 4.166832447052002 | KNN Loss: 4.149090766906738 | CLS Loss: 0.017741909250617027\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 4.241714000701904 | KNN Loss: 4.202401161193848 | CLS Loss: 0.03931276127696037\n",
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 4.237244606018066 | KNN Loss: 4.213376045227051 | CLS Loss: 0.023868616670370102\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 4.168545722961426 | KNN Loss: 4.152872562408447 | CLS Loss: 0.01567295379936695\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 4.207673072814941 | KNN Loss: 4.179661750793457 | CLS Loss: 0.028011193498969078\n",
      "Epoch: 068, Loss: 4.1748, Train: 0.9954, Valid: 0.9854, Best: 0.9879\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 4.172018051147461 | KNN Loss: 4.160053730010986 | CLS Loss: 0.011964456178247929\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 4.180371284484863 | KNN Loss: 4.15910005569458 | CLS Loss: 0.021271316334605217\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 4.186203956604004 | KNN Loss: 4.171526908874512 | CLS Loss: 0.014677214436233044\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 4.20202112197876 | KNN Loss: 4.165897846221924 | CLS Loss: 0.03612349182367325\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 4.157233238220215 | KNN Loss: 4.140317916870117 | CLS Loss: 0.01691514067351818\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 4.1659016609191895 | KNN Loss: 4.149544715881348 | CLS Loss: 0.016357101500034332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 4.210141181945801 | KNN Loss: 4.1895246505737305 | CLS Loss: 0.020616691559553146\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 4.157844543457031 | KNN Loss: 4.152379035949707 | CLS Loss: 0.005465322639793158\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 4.168301105499268 | KNN Loss: 4.15464973449707 | CLS Loss: 0.013651560992002487\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 4.1590681076049805 | KNN Loss: 4.123043060302734 | CLS Loss: 0.03602497652173042\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 4.204143524169922 | KNN Loss: 4.197665691375732 | CLS Loss: 0.006477800663560629\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 4.153521537780762 | KNN Loss: 4.14231538772583 | CLS Loss: 0.011206322349607944\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 4.212551593780518 | KNN Loss: 4.192112922668457 | CLS Loss: 0.020438862964510918\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 4.154801845550537 | KNN Loss: 4.14512300491333 | CLS Loss: 0.009678752161562443\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 4.130462646484375 | KNN Loss: 4.122326850891113 | CLS Loss: 0.008135568350553513\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 4.140646934509277 | KNN Loss: 4.136366844177246 | CLS Loss: 0.004279999528080225\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 4.1566481590271 | KNN Loss: 4.135730743408203 | CLS Loss: 0.02091747149825096\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 4.163527011871338 | KNN Loss: 4.1357855796813965 | CLS Loss: 0.027741437777876854\n",
      "Epoch: 069, Loss: 4.1738, Train: 0.9949, Valid: 0.9859, Best: 0.9879\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 4.200224876403809 | KNN Loss: 4.152271747589111 | CLS Loss: 0.04795313626527786\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 4.14972448348999 | KNN Loss: 4.142385482788086 | CLS Loss: 0.007339188829064369\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 4.185648441314697 | KNN Loss: 4.170581817626953 | CLS Loss: 0.015066802501678467\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 4.160106658935547 | KNN Loss: 4.1481804847717285 | CLS Loss: 0.011926081962883472\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 4.166261196136475 | KNN Loss: 4.159762382507324 | CLS Loss: 0.006498710252344608\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 4.1512579917907715 | KNN Loss: 4.136489391326904 | CLS Loss: 0.014768547378480434\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 4.139639854431152 | KNN Loss: 4.122788429260254 | CLS Loss: 0.01685134507715702\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 4.154481410980225 | KNN Loss: 4.138946533203125 | CLS Loss: 0.015535006299614906\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 4.1434855461120605 | KNN Loss: 4.137441158294678 | CLS Loss: 0.006044188980013132\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 4.157260417938232 | KNN Loss: 4.153357982635498 | CLS Loss: 0.0039023298304528\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 4.200249671936035 | KNN Loss: 4.190846920013428 | CLS Loss: 0.00940267089754343\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 4.161863803863525 | KNN Loss: 4.1495208740234375 | CLS Loss: 0.01234291773289442\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 4.218705177307129 | KNN Loss: 4.201956272125244 | CLS Loss: 0.01674891635775566\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 4.166188716888428 | KNN Loss: 4.161272048950195 | CLS Loss: 0.004916612524539232\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 4.118710994720459 | KNN Loss: 4.112528324127197 | CLS Loss: 0.006182692013680935\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 4.197552680969238 | KNN Loss: 4.169270038604736 | CLS Loss: 0.028282860293984413\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 4.141222953796387 | KNN Loss: 4.123939514160156 | CLS Loss: 0.017283540219068527\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 4.156313419342041 | KNN Loss: 4.1505446434021 | CLS Loss: 0.00576878571882844\n",
      "Epoch: 070, Loss: 4.1758, Train: 0.9958, Valid: 0.9852, Best: 0.9879\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 4.183419704437256 | KNN Loss: 4.167299270629883 | CLS Loss: 0.016120515763759613\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 4.168100833892822 | KNN Loss: 4.152245044708252 | CLS Loss: 0.01585601456463337\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 4.186123847961426 | KNN Loss: 4.170924186706543 | CLS Loss: 0.01519955787807703\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 4.193212985992432 | KNN Loss: 4.181746482849121 | CLS Loss: 0.011466474272310734\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 4.164710998535156 | KNN Loss: 4.13902473449707 | CLS Loss: 0.025686290115118027\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 4.165677070617676 | KNN Loss: 4.144674777984619 | CLS Loss: 0.021002309396862984\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 4.150388240814209 | KNN Loss: 4.147979736328125 | CLS Loss: 0.0024083966854959726\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 4.191042423248291 | KNN Loss: 4.187692642211914 | CLS Loss: 0.003349826904013753\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 4.184231758117676 | KNN Loss: 4.1438727378845215 | CLS Loss: 0.04035921022295952\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 4.1365251541137695 | KNN Loss: 4.135318279266357 | CLS Loss: 0.0012070077937096357\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 4.109709739685059 | KNN Loss: 4.1075310707092285 | CLS Loss: 0.002178802154958248\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 4.127838134765625 | KNN Loss: 4.1182966232299805 | CLS Loss: 0.009541431441903114\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 4.142761707305908 | KNN Loss: 4.136081218719482 | CLS Loss: 0.006680319085717201\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 4.163671016693115 | KNN Loss: 4.151532173156738 | CLS Loss: 0.012138746678829193\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 4.155771732330322 | KNN Loss: 4.144376277923584 | CLS Loss: 0.011395418085157871\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 4.178151607513428 | KNN Loss: 4.1667609214782715 | CLS Loss: 0.011390747502446175\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 4.1704792976379395 | KNN Loss: 4.137762069702148 | CLS Loss: 0.03271736204624176\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 4.209425449371338 | KNN Loss: 4.2015156745910645 | CLS Loss: 0.007909920066595078\n",
      "Epoch: 071, Loss: 4.1733, Train: 0.9965, Valid: 0.9865, Best: 0.9879\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 4.166958808898926 | KNN Loss: 4.150291442871094 | CLS Loss: 0.016667569056153297\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 4.155543804168701 | KNN Loss: 4.149727821350098 | CLS Loss: 0.005815980024635792\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 4.155252933502197 | KNN Loss: 4.1400837898254395 | CLS Loss: 0.015169045887887478\n",
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 4.147768974304199 | KNN Loss: 4.136476993560791 | CLS Loss: 0.011291854083538055\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 4.187305450439453 | KNN Loss: 4.1605224609375 | CLS Loss: 0.026783086359500885\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 4.193909645080566 | KNN Loss: 4.159708499908447 | CLS Loss: 0.03420129418373108\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 4.160111904144287 | KNN Loss: 4.1420979499816895 | CLS Loss: 0.01801394298672676\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 4.138360023498535 | KNN Loss: 4.134037017822266 | CLS Loss: 0.004323190078139305\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 4.173306465148926 | KNN Loss: 4.157431602478027 | CLS Loss: 0.015875093638896942\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 4.1557745933532715 | KNN Loss: 4.14619255065918 | CLS Loss: 0.009581963531672955\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 4.200768947601318 | KNN Loss: 4.175060272216797 | CLS Loss: 0.025708474218845367\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 4.163899898529053 | KNN Loss: 4.151801586151123 | CLS Loss: 0.012098228558897972\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 4.146642684936523 | KNN Loss: 4.136980056762695 | CLS Loss: 0.009662642143666744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 4.1536078453063965 | KNN Loss: 4.136358737945557 | CLS Loss: 0.017249252647161484\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 4.202422618865967 | KNN Loss: 4.176987648010254 | CLS Loss: 0.025435088202357292\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 4.134022235870361 | KNN Loss: 4.112412929534912 | CLS Loss: 0.021609248593449593\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 4.159771919250488 | KNN Loss: 4.128117561340332 | CLS Loss: 0.031654298305511475\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 4.199166297912598 | KNN Loss: 4.157289028167725 | CLS Loss: 0.041877347975969315\n",
      "Epoch: 072, Loss: 4.1673, Train: 0.9959, Valid: 0.9864, Best: 0.9879\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 4.168333053588867 | KNN Loss: 4.157445907592773 | CLS Loss: 0.010887343436479568\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 4.177974224090576 | KNN Loss: 4.144679546356201 | CLS Loss: 0.03329487517476082\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 4.152538776397705 | KNN Loss: 4.12861967086792 | CLS Loss: 0.023919064551591873\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 4.17022705078125 | KNN Loss: 4.155529975891113 | CLS Loss: 0.01469698641449213\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 4.164912700653076 | KNN Loss: 4.1522440910339355 | CLS Loss: 0.012668570503592491\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 4.195864677429199 | KNN Loss: 4.182601451873779 | CLS Loss: 0.013263392262160778\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 4.231499671936035 | KNN Loss: 4.19675350189209 | CLS Loss: 0.03474610671401024\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 4.162115097045898 | KNN Loss: 4.1567864418029785 | CLS Loss: 0.005328711122274399\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 4.148151874542236 | KNN Loss: 4.132305145263672 | CLS Loss: 0.01584681309759617\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 4.145304203033447 | KNN Loss: 4.124144554138184 | CLS Loss: 0.021159494295716286\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 4.142246246337891 | KNN Loss: 4.136628150939941 | CLS Loss: 0.005617961287498474\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 4.16274356842041 | KNN Loss: 4.148073673248291 | CLS Loss: 0.014670077711343765\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 4.162296772003174 | KNN Loss: 4.144716262817383 | CLS Loss: 0.017580389976501465\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 4.185571670532227 | KNN Loss: 4.1762237548828125 | CLS Loss: 0.009348059073090553\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 4.14683723449707 | KNN Loss: 4.125338077545166 | CLS Loss: 0.02149932272732258\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 4.201865196228027 | KNN Loss: 4.187023639678955 | CLS Loss: 0.014841518364846706\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 4.208678722381592 | KNN Loss: 4.1643147468566895 | CLS Loss: 0.04436386749148369\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 4.168557643890381 | KNN Loss: 4.160325527191162 | CLS Loss: 0.008232232183218002\n",
      "Epoch: 073, Loss: 4.1734, Train: 0.9969, Valid: 0.9875, Best: 0.9879\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 4.170618534088135 | KNN Loss: 4.168285846710205 | CLS Loss: 0.00233290484175086\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 4.1675944328308105 | KNN Loss: 4.164111137390137 | CLS Loss: 0.003483304288238287\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 4.195002555847168 | KNN Loss: 4.178001880645752 | CLS Loss: 0.017000608146190643\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 4.1901960372924805 | KNN Loss: 4.1665239334106445 | CLS Loss: 0.02367204986512661\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 4.156962871551514 | KNN Loss: 4.153348445892334 | CLS Loss: 0.0036142379976809025\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 4.16892671585083 | KNN Loss: 4.158187389373779 | CLS Loss: 0.010739254765212536\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 4.157793045043945 | KNN Loss: 4.14702844619751 | CLS Loss: 0.010764522477984428\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 4.176476955413818 | KNN Loss: 4.163330078125 | CLS Loss: 0.01314685121178627\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 4.149954319000244 | KNN Loss: 4.14586067199707 | CLS Loss: 0.004093443509191275\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 4.162469863891602 | KNN Loss: 4.14892578125 | CLS Loss: 0.0135438721626997\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 4.165441989898682 | KNN Loss: 4.143609046936035 | CLS Loss: 0.021833015605807304\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 4.1949567794799805 | KNN Loss: 4.180844306945801 | CLS Loss: 0.014112546108663082\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 4.145415306091309 | KNN Loss: 4.141049861907959 | CLS Loss: 0.004365366417914629\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 4.184791088104248 | KNN Loss: 4.172708988189697 | CLS Loss: 0.01208189781755209\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 4.179998874664307 | KNN Loss: 4.169057846069336 | CLS Loss: 0.01094105839729309\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 4.231296539306641 | KNN Loss: 4.2107343673706055 | CLS Loss: 0.02056216262280941\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 4.169803619384766 | KNN Loss: 4.163014888763428 | CLS Loss: 0.006788685917854309\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 4.154026508331299 | KNN Loss: 4.145356178283691 | CLS Loss: 0.008670158684253693\n",
      "Epoch: 074, Loss: 4.1726, Train: 0.9965, Valid: 0.9863, Best: 0.9879\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 4.17123556137085 | KNN Loss: 4.168968677520752 | CLS Loss: 0.0022669306490570307\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 4.134329319000244 | KNN Loss: 4.1297197341918945 | CLS Loss: 0.004609482828527689\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 4.160750389099121 | KNN Loss: 4.151144504547119 | CLS Loss: 0.009606058709323406\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 4.148805618286133 | KNN Loss: 4.131011009216309 | CLS Loss: 0.017794489860534668\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 4.1580281257629395 | KNN Loss: 4.148262977600098 | CLS Loss: 0.009765314869582653\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 4.148098945617676 | KNN Loss: 4.14528751373291 | CLS Loss: 0.00281143537722528\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 4.199125289916992 | KNN Loss: 4.174484729766846 | CLS Loss: 0.02464076317846775\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 4.184597015380859 | KNN Loss: 4.15928840637207 | CLS Loss: 0.02530837431550026\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 4.16483736038208 | KNN Loss: 4.145424842834473 | CLS Loss: 0.019412748515605927\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 4.157209873199463 | KNN Loss: 4.138908863067627 | CLS Loss: 0.018301041796803474\n",
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 4.167760848999023 | KNN Loss: 4.157495021820068 | CLS Loss: 0.010266020894050598\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 4.14120626449585 | KNN Loss: 4.134914875030518 | CLS Loss: 0.006291504018008709\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 4.141491889953613 | KNN Loss: 4.139387607574463 | CLS Loss: 0.0021044528111815453\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 4.125027656555176 | KNN Loss: 4.122936725616455 | CLS Loss: 0.0020910436287522316\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 4.146514892578125 | KNN Loss: 4.124019145965576 | CLS Loss: 0.02249598503112793\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 4.133212089538574 | KNN Loss: 4.128412246704102 | CLS Loss: 0.004800079390406609\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 4.13100528717041 | KNN Loss: 4.124330997467041 | CLS Loss: 0.006674421951174736\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 4.151988506317139 | KNN Loss: 4.129643440246582 | CLS Loss: 0.022345073521137238\n",
      "Epoch: 075, Loss: 4.1674, Train: 0.9970, Valid: 0.9870, Best: 0.9879\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 4.1883225440979 | KNN Loss: 4.177039623260498 | CLS Loss: 0.011282880790531635\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 4.171929836273193 | KNN Loss: 4.16988468170166 | CLS Loss: 0.002044917782768607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 4.139902591705322 | KNN Loss: 4.133307456970215 | CLS Loss: 0.006595138926059008\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 4.160104751586914 | KNN Loss: 4.153448581695557 | CLS Loss: 0.006656260695308447\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 4.169928073883057 | KNN Loss: 4.166134357452393 | CLS Loss: 0.003793500829488039\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 4.214899063110352 | KNN Loss: 4.194516181945801 | CLS Loss: 0.020383082330226898\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 4.175389289855957 | KNN Loss: 4.13417387008667 | CLS Loss: 0.04121527820825577\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 4.181911945343018 | KNN Loss: 4.163629531860352 | CLS Loss: 0.018282609060406685\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 4.220448970794678 | KNN Loss: 4.213099002838135 | CLS Loss: 0.007349777966737747\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 4.17477560043335 | KNN Loss: 4.142029285430908 | CLS Loss: 0.03274625912308693\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 4.160727024078369 | KNN Loss: 4.144954204559326 | CLS Loss: 0.015772642567753792\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 4.155226230621338 | KNN Loss: 4.149102210998535 | CLS Loss: 0.006123827304691076\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 4.1441216468811035 | KNN Loss: 4.1378397941589355 | CLS Loss: 0.006281910929828882\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 4.179782867431641 | KNN Loss: 4.164569854736328 | CLS Loss: 0.0152128292247653\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 4.135275363922119 | KNN Loss: 4.1307902336120605 | CLS Loss: 0.004485162906348705\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 4.175705909729004 | KNN Loss: 4.160754203796387 | CLS Loss: 0.014951505698263645\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 4.152036666870117 | KNN Loss: 4.146306037902832 | CLS Loss: 0.0057308366522192955\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 4.142935276031494 | KNN Loss: 4.1296772956848145 | CLS Loss: 0.013258208520710468\n",
      "Epoch: 076, Loss: 4.1709, Train: 0.9964, Valid: 0.9865, Best: 0.9879\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 4.209147930145264 | KNN Loss: 4.181509971618652 | CLS Loss: 0.027638103812932968\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 4.211592674255371 | KNN Loss: 4.188405513763428 | CLS Loss: 0.023186977952718735\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 4.210581302642822 | KNN Loss: 4.203814506530762 | CLS Loss: 0.006766697857528925\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 4.152246475219727 | KNN Loss: 4.138723373413086 | CLS Loss: 0.013522916473448277\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 4.140444278717041 | KNN Loss: 4.133055210113525 | CLS Loss: 0.007388983387500048\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 4.148515701293945 | KNN Loss: 4.139591693878174 | CLS Loss: 0.008924195542931557\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 4.17471170425415 | KNN Loss: 4.1695237159729 | CLS Loss: 0.005187969654798508\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 4.180834770202637 | KNN Loss: 4.169583797454834 | CLS Loss: 0.011250956915318966\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 4.173503398895264 | KNN Loss: 4.1641459465026855 | CLS Loss: 0.009357452392578125\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 4.1753716468811035 | KNN Loss: 4.166479110717773 | CLS Loss: 0.00889238715171814\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 4.174908638000488 | KNN Loss: 4.16942024230957 | CLS Loss: 0.005488466005772352\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 4.165213584899902 | KNN Loss: 4.1262969970703125 | CLS Loss: 0.0389166921377182\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 4.1479268074035645 | KNN Loss: 4.122241497039795 | CLS Loss: 0.025685176253318787\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 4.170785903930664 | KNN Loss: 4.150999069213867 | CLS Loss: 0.019786600023508072\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 4.165356636047363 | KNN Loss: 4.144731044769287 | CLS Loss: 0.02062579244375229\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 4.212255954742432 | KNN Loss: 4.189756393432617 | CLS Loss: 0.022499511018395424\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 4.176309585571289 | KNN Loss: 4.158290863037109 | CLS Loss: 0.018018562346696854\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 4.145867347717285 | KNN Loss: 4.141417026519775 | CLS Loss: 0.004450553562492132\n",
      "Epoch: 077, Loss: 4.1643, Train: 0.9968, Valid: 0.9866, Best: 0.9879\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 4.186110496520996 | KNN Loss: 4.183841705322266 | CLS Loss: 0.0022685572039335966\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 4.1997456550598145 | KNN Loss: 4.1890387535095215 | CLS Loss: 0.010706856846809387\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 4.153231143951416 | KNN Loss: 4.1460089683532715 | CLS Loss: 0.007222371641546488\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 4.165196895599365 | KNN Loss: 4.1539506912231445 | CLS Loss: 0.011246183887124062\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 4.191638469696045 | KNN Loss: 4.180700778961182 | CLS Loss: 0.010937887243926525\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 4.136800289154053 | KNN Loss: 4.128035068511963 | CLS Loss: 0.008765042759478092\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 4.131282806396484 | KNN Loss: 4.122028827667236 | CLS Loss: 0.00925376545637846\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 4.16178560256958 | KNN Loss: 4.150846481323242 | CLS Loss: 0.010938913561403751\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 4.146693229675293 | KNN Loss: 4.137415409088135 | CLS Loss: 0.009277974255383015\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 4.177886009216309 | KNN Loss: 4.158134460449219 | CLS Loss: 0.01975172944366932\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 4.127556324005127 | KNN Loss: 4.115273952484131 | CLS Loss: 0.012282527051866055\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 4.1742353439331055 | KNN Loss: 4.161543369293213 | CLS Loss: 0.012691808864474297\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 4.163328170776367 | KNN Loss: 4.145707130432129 | CLS Loss: 0.01762082614004612\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 4.152032852172852 | KNN Loss: 4.146857738494873 | CLS Loss: 0.005174908321350813\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 4.189422130584717 | KNN Loss: 4.179757595062256 | CLS Loss: 0.009664589539170265\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 4.150547504425049 | KNN Loss: 4.14747953414917 | CLS Loss: 0.0030681791249662638\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 4.177781581878662 | KNN Loss: 4.170444011688232 | CLS Loss: 0.007337658666074276\n",
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 4.173734188079834 | KNN Loss: 4.16166353225708 | CLS Loss: 0.012070630677044392\n",
      "Epoch: 078, Loss: 4.1673, Train: 0.9961, Valid: 0.9868, Best: 0.9879\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 4.21673583984375 | KNN Loss: 4.168617248535156 | CLS Loss: 0.04811852425336838\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 4.149686813354492 | KNN Loss: 4.116891384124756 | CLS Loss: 0.03279564902186394\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 4.137314319610596 | KNN Loss: 4.1307220458984375 | CLS Loss: 0.006592407822608948\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 4.178112983703613 | KNN Loss: 4.160836219787598 | CLS Loss: 0.017276981845498085\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 4.249947547912598 | KNN Loss: 4.228599548339844 | CLS Loss: 0.021348068490624428\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 4.162543296813965 | KNN Loss: 4.153893947601318 | CLS Loss: 0.008649316616356373\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 4.1600871086120605 | KNN Loss: 4.148547172546387 | CLS Loss: 0.011539755389094353\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 4.150734901428223 | KNN Loss: 4.144252300262451 | CLS Loss: 0.006482718512415886\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 4.1732378005981445 | KNN Loss: 4.16208553314209 | CLS Loss: 0.011152317747473717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 4.150318622589111 | KNN Loss: 4.1280107498168945 | CLS Loss: 0.022307857871055603\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 4.149371147155762 | KNN Loss: 4.111486911773682 | CLS Loss: 0.03788416460156441\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 4.168167591094971 | KNN Loss: 4.155006408691406 | CLS Loss: 0.013161257840692997\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 4.1702680587768555 | KNN Loss: 4.153422832489014 | CLS Loss: 0.01684541627764702\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 4.148903846740723 | KNN Loss: 4.144194602966309 | CLS Loss: 0.004709448665380478\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 4.147111415863037 | KNN Loss: 4.144194602966309 | CLS Loss: 0.0029165949672460556\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 4.185890197753906 | KNN Loss: 4.164979934692383 | CLS Loss: 0.02091006375849247\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 4.15160608291626 | KNN Loss: 4.147890090942383 | CLS Loss: 0.0037160853389650583\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 4.177070617675781 | KNN Loss: 4.158070087432861 | CLS Loss: 0.019000550732016563\n",
      "Epoch: 079, Loss: 4.1693, Train: 0.9970, Valid: 0.9871, Best: 0.9879\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 4.120707988739014 | KNN Loss: 4.1115241050720215 | CLS Loss: 0.009183712303638458\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 4.156937599182129 | KNN Loss: 4.146639347076416 | CLS Loss: 0.010298133827745914\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 4.14015007019043 | KNN Loss: 4.136428356170654 | CLS Loss: 0.0037217848002910614\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 4.137357711791992 | KNN Loss: 4.131190299987793 | CLS Loss: 0.006167436018586159\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 4.143463134765625 | KNN Loss: 4.138689994812012 | CLS Loss: 0.004773149266839027\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 4.162199974060059 | KNN Loss: 4.1511149406433105 | CLS Loss: 0.01108505018055439\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 4.133815288543701 | KNN Loss: 4.128820419311523 | CLS Loss: 0.004994732793420553\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 4.189973831176758 | KNN Loss: 4.143054485321045 | CLS Loss: 0.04691915586590767\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 4.1692705154418945 | KNN Loss: 4.143016815185547 | CLS Loss: 0.026253627613186836\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 4.162978649139404 | KNN Loss: 4.157121181488037 | CLS Loss: 0.005857246927917004\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 4.132791996002197 | KNN Loss: 4.130706310272217 | CLS Loss: 0.002085922285914421\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 4.210391521453857 | KNN Loss: 4.20415735244751 | CLS Loss: 0.0062343161553144455\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 4.143452167510986 | KNN Loss: 4.138308048248291 | CLS Loss: 0.0051442659460008144\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 4.1756391525268555 | KNN Loss: 4.169600963592529 | CLS Loss: 0.0060380082577466965\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 4.170793533325195 | KNN Loss: 4.163676738739014 | CLS Loss: 0.007116826716810465\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 4.226772785186768 | KNN Loss: 4.21004581451416 | CLS Loss: 0.01672716811299324\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 4.153738021850586 | KNN Loss: 4.148993492126465 | CLS Loss: 0.004744329024106264\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 4.1725664138793945 | KNN Loss: 4.159774303436279 | CLS Loss: 0.012791909277439117\n",
      "Epoch: 080, Loss: 4.1696, Train: 0.9968, Valid: 0.9871, Best: 0.9879\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 4.149935722351074 | KNN Loss: 4.1470746994018555 | CLS Loss: 0.0028611032757908106\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 4.1595916748046875 | KNN Loss: 4.139975070953369 | CLS Loss: 0.01961655542254448\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 4.159154415130615 | KNN Loss: 4.132288932800293 | CLS Loss: 0.026865661144256592\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 4.14607048034668 | KNN Loss: 4.143898010253906 | CLS Loss: 0.002172676846385002\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 4.1607866287231445 | KNN Loss: 4.146515369415283 | CLS Loss: 0.01427149772644043\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 4.182055950164795 | KNN Loss: 4.168576240539551 | CLS Loss: 0.013479640707373619\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 4.133335590362549 | KNN Loss: 4.129578590393066 | CLS Loss: 0.003757000667974353\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 4.153635025024414 | KNN Loss: 4.146335601806641 | CLS Loss: 0.0072992462664842606\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 4.14136266708374 | KNN Loss: 4.124279022216797 | CLS Loss: 0.017083868384361267\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 4.198592662811279 | KNN Loss: 4.1722540855407715 | CLS Loss: 0.02633863128721714\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 4.114683628082275 | KNN Loss: 4.113121509552002 | CLS Loss: 0.0015618999022990465\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 4.1329474449157715 | KNN Loss: 4.131863117218018 | CLS Loss: 0.0010845583165064454\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 4.139889240264893 | KNN Loss: 4.130472660064697 | CLS Loss: 0.009416679851710796\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 4.169414520263672 | KNN Loss: 4.151433944702148 | CLS Loss: 0.01798056811094284\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 4.169967174530029 | KNN Loss: 4.168298721313477 | CLS Loss: 0.0016686179442331195\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 4.155743598937988 | KNN Loss: 4.151806831359863 | CLS Loss: 0.003936850931495428\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 4.140624046325684 | KNN Loss: 4.136883735656738 | CLS Loss: 0.003740261774510145\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 4.141406536102295 | KNN Loss: 4.126391887664795 | CLS Loss: 0.015014532953500748\n",
      "Epoch: 081, Loss: 4.1593, Train: 0.9972, Valid: 0.9870, Best: 0.9879\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 4.166951656341553 | KNN Loss: 4.137716293334961 | CLS Loss: 0.029235266149044037\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 4.1663994789123535 | KNN Loss: 4.156808853149414 | CLS Loss: 0.00959045346826315\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 4.187583923339844 | KNN Loss: 4.163565635681152 | CLS Loss: 0.024018272757530212\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 4.1564130783081055 | KNN Loss: 4.150327682495117 | CLS Loss: 0.006085592322051525\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 4.208553314208984 | KNN Loss: 4.191498279571533 | CLS Loss: 0.017055051401257515\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 4.173995494842529 | KNN Loss: 4.165194988250732 | CLS Loss: 0.008800442330539227\n",
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 4.183166027069092 | KNN Loss: 4.17466926574707 | CLS Loss: 0.008496694266796112\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 4.180261611938477 | KNN Loss: 4.161372661590576 | CLS Loss: 0.018889162689447403\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 4.1563801765441895 | KNN Loss: 4.151548862457275 | CLS Loss: 0.004831132013350725\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 4.215283393859863 | KNN Loss: 4.182375431060791 | CLS Loss: 0.032907914370298386\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 4.184925556182861 | KNN Loss: 4.155735969543457 | CLS Loss: 0.0291894618421793\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 4.207489013671875 | KNN Loss: 4.181462287902832 | CLS Loss: 0.026026753708720207\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 4.1673150062561035 | KNN Loss: 4.153326511383057 | CLS Loss: 0.013988464139401913\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 4.192151069641113 | KNN Loss: 4.175893783569336 | CLS Loss: 0.016257448121905327\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 4.182432174682617 | KNN Loss: 4.150132179260254 | CLS Loss: 0.03229999914765358\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 4.172510623931885 | KNN Loss: 4.14851713180542 | CLS Loss: 0.023993410170078278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 4.130731582641602 | KNN Loss: 4.118416786193848 | CLS Loss: 0.012314657680690289\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 4.144529342651367 | KNN Loss: 4.137655735015869 | CLS Loss: 0.006873531267046928\n",
      "Epoch: 082, Loss: 4.1675, Train: 0.9973, Valid: 0.9870, Best: 0.9879\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 4.1322736740112305 | KNN Loss: 4.130181312561035 | CLS Loss: 0.0020925994031131268\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 4.155758857727051 | KNN Loss: 4.1355695724487305 | CLS Loss: 0.020189112052321434\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 4.145876884460449 | KNN Loss: 4.139819622039795 | CLS Loss: 0.006057152524590492\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 4.153669834136963 | KNN Loss: 4.14516544342041 | CLS Loss: 0.008504399098455906\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 4.1693220138549805 | KNN Loss: 4.161662578582764 | CLS Loss: 0.007659585680812597\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 4.161977291107178 | KNN Loss: 4.145055770874023 | CLS Loss: 0.016921447589993477\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 4.1506571769714355 | KNN Loss: 4.142712593078613 | CLS Loss: 0.007944722659885883\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 4.148398399353027 | KNN Loss: 4.144848346710205 | CLS Loss: 0.003549815621227026\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 4.167059898376465 | KNN Loss: 4.147659778594971 | CLS Loss: 0.01939992606639862\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 4.14995813369751 | KNN Loss: 4.1463623046875 | CLS Loss: 0.003595606656745076\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 4.166243076324463 | KNN Loss: 4.160608768463135 | CLS Loss: 0.005634239874780178\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 4.1778154373168945 | KNN Loss: 4.150366306304932 | CLS Loss: 0.027449244633316994\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 4.135131359100342 | KNN Loss: 4.129284858703613 | CLS Loss: 0.005846456158906221\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 4.162299156188965 | KNN Loss: 4.143559455871582 | CLS Loss: 0.018739521503448486\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 4.172401428222656 | KNN Loss: 4.156742095947266 | CLS Loss: 0.015659283846616745\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 4.19076681137085 | KNN Loss: 4.178808689117432 | CLS Loss: 0.011958065442740917\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 4.145256996154785 | KNN Loss: 4.125624179840088 | CLS Loss: 0.019632715731859207\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 4.1652727127075195 | KNN Loss: 4.146274566650391 | CLS Loss: 0.018998196348547935\n",
      "Epoch: 083, Loss: 4.1647, Train: 0.9975, Valid: 0.9860, Best: 0.9879\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 4.145755290985107 | KNN Loss: 4.136224746704102 | CLS Loss: 0.00953046977519989\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 4.196009635925293 | KNN Loss: 4.184475421905518 | CLS Loss: 0.011534258723258972\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 4.165652275085449 | KNN Loss: 4.153112888336182 | CLS Loss: 0.012539179064333439\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 4.161588668823242 | KNN Loss: 4.160219192504883 | CLS Loss: 0.001369472942315042\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 4.144314289093018 | KNN Loss: 4.133658409118652 | CLS Loss: 0.010656028054654598\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 4.158811569213867 | KNN Loss: 4.147738933563232 | CLS Loss: 0.011072586290538311\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 4.172208786010742 | KNN Loss: 4.170915603637695 | CLS Loss: 0.0012932501267641783\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 4.195885181427002 | KNN Loss: 4.183093070983887 | CLS Loss: 0.012792247347533703\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 4.197932720184326 | KNN Loss: 4.158603668212891 | CLS Loss: 0.039329253137111664\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 4.176729202270508 | KNN Loss: 4.133175373077393 | CLS Loss: 0.04355386272072792\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 4.1798624992370605 | KNN Loss: 4.174591541290283 | CLS Loss: 0.005271057598292828\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 4.143138885498047 | KNN Loss: 4.140902519226074 | CLS Loss: 0.00223649968393147\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 4.163908958435059 | KNN Loss: 4.139671325683594 | CLS Loss: 0.02423764020204544\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 4.161184310913086 | KNN Loss: 4.145728588104248 | CLS Loss: 0.015455509535968304\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 4.170077323913574 | KNN Loss: 4.152039527893066 | CLS Loss: 0.018037846311926842\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 4.157212734222412 | KNN Loss: 4.154377460479736 | CLS Loss: 0.002835477003827691\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 4.148680686950684 | KNN Loss: 4.138387203216553 | CLS Loss: 0.010293371975421906\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 4.144075393676758 | KNN Loss: 4.139698028564453 | CLS Loss: 0.004377318080514669\n",
      "Epoch: 084, Loss: 4.1654, Train: 0.9971, Valid: 0.9874, Best: 0.9879\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 4.203874588012695 | KNN Loss: 4.183375835418701 | CLS Loss: 0.0204988531768322\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 4.1569905281066895 | KNN Loss: 4.131967067718506 | CLS Loss: 0.025023406371474266\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 4.179149627685547 | KNN Loss: 4.17453145980835 | CLS Loss: 0.004618313163518906\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 4.190093517303467 | KNN Loss: 4.176571846008301 | CLS Loss: 0.013521451503038406\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 4.136215686798096 | KNN Loss: 4.133932590484619 | CLS Loss: 0.0022831198293715715\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 4.136681079864502 | KNN Loss: 4.128942966461182 | CLS Loss: 0.007738130167126656\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 4.166155815124512 | KNN Loss: 4.163410663604736 | CLS Loss: 0.0027453473303467035\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 4.15750789642334 | KNN Loss: 4.14782190322876 | CLS Loss: 0.009686125442385674\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 4.219732761383057 | KNN Loss: 4.193963527679443 | CLS Loss: 0.025769423693418503\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 4.160788059234619 | KNN Loss: 4.151415824890137 | CLS Loss: 0.009372180327773094\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 4.142316818237305 | KNN Loss: 4.128961086273193 | CLS Loss: 0.013355731032788754\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 4.195347785949707 | KNN Loss: 4.171957015991211 | CLS Loss: 0.023390993475914\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 4.171669006347656 | KNN Loss: 4.1642913818359375 | CLS Loss: 0.007377646863460541\n",
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 4.14922571182251 | KNN Loss: 4.126001834869385 | CLS Loss: 0.023223835974931717\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 4.199242115020752 | KNN Loss: 4.155672073364258 | CLS Loss: 0.04357026144862175\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 4.15444278717041 | KNN Loss: 4.137174606323242 | CLS Loss: 0.01726839691400528\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 4.21252965927124 | KNN Loss: 4.178105354309082 | CLS Loss: 0.03442423790693283\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 4.143770217895508 | KNN Loss: 4.128103256225586 | CLS Loss: 0.015667054802179337\n",
      "Epoch: 085, Loss: 4.1660, Train: 0.9969, Valid: 0.9870, Best: 0.9879\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 4.162867069244385 | KNN Loss: 4.142017841339111 | CLS Loss: 0.02084912359714508\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 4.1626176834106445 | KNN Loss: 4.156752109527588 | CLS Loss: 0.005865765735507011\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 4.146495819091797 | KNN Loss: 4.144079685211182 | CLS Loss: 0.0024163685739040375\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 4.143457889556885 | KNN Loss: 4.132513523101807 | CLS Loss: 0.010944447480142117\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 4.1585493087768555 | KNN Loss: 4.1557793617248535 | CLS Loss: 0.0027698567137122154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 4.142706394195557 | KNN Loss: 4.13645601272583 | CLS Loss: 0.006250463426113129\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 4.159805774688721 | KNN Loss: 4.154379844665527 | CLS Loss: 0.005426023155450821\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 4.187921047210693 | KNN Loss: 4.169433116912842 | CLS Loss: 0.018488062545657158\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 4.153057098388672 | KNN Loss: 4.150600433349609 | CLS Loss: 0.0024564729537814856\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 4.174063682556152 | KNN Loss: 4.159762859344482 | CLS Loss: 0.014300926588475704\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 4.151689052581787 | KNN Loss: 4.1401824951171875 | CLS Loss: 0.011506634764373302\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 4.157598972320557 | KNN Loss: 4.133328914642334 | CLS Loss: 0.024270083755254745\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 4.167727947235107 | KNN Loss: 4.134260654449463 | CLS Loss: 0.03346714377403259\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 4.20455265045166 | KNN Loss: 4.191552639007568 | CLS Loss: 0.012999782338738441\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 4.170073986053467 | KNN Loss: 4.154629230499268 | CLS Loss: 0.015444743447005749\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 4.135196208953857 | KNN Loss: 4.1195597648620605 | CLS Loss: 0.015636634081602097\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 4.12544584274292 | KNN Loss: 4.121260643005371 | CLS Loss: 0.004185011610388756\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 4.115316390991211 | KNN Loss: 4.111745357513428 | CLS Loss: 0.003570939414203167\n",
      "Epoch: 086, Loss: 4.1615, Train: 0.9959, Valid: 0.9861, Best: 0.9879\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 4.173326015472412 | KNN Loss: 4.168959140777588 | CLS Loss: 0.004366803914308548\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 4.190835952758789 | KNN Loss: 4.1697282791137695 | CLS Loss: 0.021107671782374382\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 4.137772083282471 | KNN Loss: 4.131989479064941 | CLS Loss: 0.005782507825642824\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 4.166809558868408 | KNN Loss: 4.165116786956787 | CLS Loss: 0.0016927309334278107\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 4.2124924659729 | KNN Loss: 4.199084758758545 | CLS Loss: 0.013407674618065357\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 4.154611110687256 | KNN Loss: 4.146117687225342 | CLS Loss: 0.008493221364915371\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 4.1594414710998535 | KNN Loss: 4.150639533996582 | CLS Loss: 0.008801862597465515\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 4.144231796264648 | KNN Loss: 4.132163047790527 | CLS Loss: 0.012068898417055607\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 4.141133785247803 | KNN Loss: 4.129591941833496 | CLS Loss: 0.011541720479726791\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 4.136823654174805 | KNN Loss: 4.133370399475098 | CLS Loss: 0.0034532463178038597\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 4.138745307922363 | KNN Loss: 4.133535385131836 | CLS Loss: 0.005210020113736391\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 4.154595375061035 | KNN Loss: 4.141251564025879 | CLS Loss: 0.01334358099848032\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 4.1312971115112305 | KNN Loss: 4.119436740875244 | CLS Loss: 0.01186053641140461\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 4.172486305236816 | KNN Loss: 4.160508155822754 | CLS Loss: 0.011978305876255035\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 4.156893730163574 | KNN Loss: 4.155961990356445 | CLS Loss: 0.0009319412638433278\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 4.189807415008545 | KNN Loss: 4.164794921875 | CLS Loss: 0.025012724101543427\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 4.171689510345459 | KNN Loss: 4.154768466949463 | CLS Loss: 0.01692109741270542\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 4.125112533569336 | KNN Loss: 4.117456436157227 | CLS Loss: 0.007656075060367584\n",
      "Epoch: 087, Loss: 4.1635, Train: 0.9972, Valid: 0.9866, Best: 0.9879\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 4.16166877746582 | KNN Loss: 4.15151309967041 | CLS Loss: 0.01015580352395773\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 4.1748480796813965 | KNN Loss: 4.1597981452941895 | CLS Loss: 0.015050094574689865\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 4.16450309753418 | KNN Loss: 4.1564741134643555 | CLS Loss: 0.008028930984437466\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 4.132439136505127 | KNN Loss: 4.127047538757324 | CLS Loss: 0.005391586571931839\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 4.158811092376709 | KNN Loss: 4.141420364379883 | CLS Loss: 0.017390938475728035\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 4.118610858917236 | KNN Loss: 4.115157604217529 | CLS Loss: 0.003453376004472375\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 4.17511510848999 | KNN Loss: 4.1489152908325195 | CLS Loss: 0.026199588552117348\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 4.176992893218994 | KNN Loss: 4.170745849609375 | CLS Loss: 0.006247237790375948\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 4.156864643096924 | KNN Loss: 4.146714687347412 | CLS Loss: 0.010149811394512653\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 4.141328811645508 | KNN Loss: 4.139312267303467 | CLS Loss: 0.002016410231590271\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 4.133386611938477 | KNN Loss: 4.1273016929626465 | CLS Loss: 0.006084683816879988\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 4.151271820068359 | KNN Loss: 4.1402812004089355 | CLS Loss: 0.010990624316036701\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 4.232020378112793 | KNN Loss: 4.215433597564697 | CLS Loss: 0.01658657379448414\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 4.172654151916504 | KNN Loss: 4.1603312492370605 | CLS Loss: 0.012322671711444855\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 4.125352382659912 | KNN Loss: 4.1184468269348145 | CLS Loss: 0.006905748508870602\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 4.201642036437988 | KNN Loss: 4.155681610107422 | CLS Loss: 0.04596060886979103\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 4.163650989532471 | KNN Loss: 4.144145965576172 | CLS Loss: 0.019504955038428307\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 4.188533306121826 | KNN Loss: 4.178659915924072 | CLS Loss: 0.009873447008430958\n",
      "Epoch: 088, Loss: 4.1611, Train: 0.9968, Valid: 0.9868, Best: 0.9879\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 4.1892409324646 | KNN Loss: 4.181926250457764 | CLS Loss: 0.007314622867852449\n",
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 4.133538246154785 | KNN Loss: 4.119625091552734 | CLS Loss: 0.01391295250505209\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 4.1571245193481445 | KNN Loss: 4.124781608581543 | CLS Loss: 0.03234294056892395\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 4.145397663116455 | KNN Loss: 4.14255428314209 | CLS Loss: 0.0028435022104531527\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 4.118698596954346 | KNN Loss: 4.118017196655273 | CLS Loss: 0.0006811633938923478\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 4.154799461364746 | KNN Loss: 4.144309043884277 | CLS Loss: 0.01049048826098442\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 4.126584529876709 | KNN Loss: 4.117075443267822 | CLS Loss: 0.009509223513305187\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 4.147281646728516 | KNN Loss: 4.136213302612305 | CLS Loss: 0.011068413034081459\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 4.170632362365723 | KNN Loss: 4.149847507476807 | CLS Loss: 0.020784905180335045\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 4.130183219909668 | KNN Loss: 4.12199592590332 | CLS Loss: 0.008187237195670605\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 4.258794784545898 | KNN Loss: 4.254072666168213 | CLS Loss: 0.004722163546830416\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 4.164901256561279 | KNN Loss: 4.142176628112793 | CLS Loss: 0.02272455208003521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 4.14461088180542 | KNN Loss: 4.140966892242432 | CLS Loss: 0.003643893403932452\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 4.188840389251709 | KNN Loss: 4.163620471954346 | CLS Loss: 0.02521994151175022\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 4.14785099029541 | KNN Loss: 4.139376163482666 | CLS Loss: 0.008474699221551418\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 4.1736555099487305 | KNN Loss: 4.167597770690918 | CLS Loss: 0.006057725753635168\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 4.142537593841553 | KNN Loss: 4.139855861663818 | CLS Loss: 0.0026817191392183304\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 4.176389217376709 | KNN Loss: 4.148622512817383 | CLS Loss: 0.027766840532422066\n",
      "Epoch: 089, Loss: 4.1597, Train: 0.9971, Valid: 0.9867, Best: 0.9879\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 4.143197059631348 | KNN Loss: 4.127331733703613 | CLS Loss: 0.015865514054894447\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 4.140321254730225 | KNN Loss: 4.138340950012207 | CLS Loss: 0.001980189001187682\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 4.146912574768066 | KNN Loss: 4.135579586029053 | CLS Loss: 0.011332943104207516\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 4.148201942443848 | KNN Loss: 4.143104076385498 | CLS Loss: 0.005097746383398771\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 4.197629451751709 | KNN Loss: 4.182682514190674 | CLS Loss: 0.014947020448744297\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 4.191153049468994 | KNN Loss: 4.1750078201293945 | CLS Loss: 0.016144996508955956\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 4.179138660430908 | KNN Loss: 4.159801006317139 | CLS Loss: 0.01933751069009304\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 4.145627975463867 | KNN Loss: 4.130234718322754 | CLS Loss: 0.015393087640404701\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 4.158130645751953 | KNN Loss: 4.153202056884766 | CLS Loss: 0.004928646143525839\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 4.2153544425964355 | KNN Loss: 4.203341960906982 | CLS Loss: 0.012012271210551262\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 4.203300476074219 | KNN Loss: 4.18225622177124 | CLS Loss: 0.021044427528977394\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 4.153199195861816 | KNN Loss: 4.122603893280029 | CLS Loss: 0.030595170333981514\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 4.160090446472168 | KNN Loss: 4.152579307556152 | CLS Loss: 0.007510948460549116\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 4.11404275894165 | KNN Loss: 4.112443923950195 | CLS Loss: 0.0015989819075912237\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 4.150932312011719 | KNN Loss: 4.131697654724121 | CLS Loss: 0.01923481561243534\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 4.1109113693237305 | KNN Loss: 4.1093573570251465 | CLS Loss: 0.001553975511342287\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 4.1813459396362305 | KNN Loss: 4.165533542633057 | CLS Loss: 0.015812629833817482\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 4.139346599578857 | KNN Loss: 4.131025314331055 | CLS Loss: 0.008321368135511875\n",
      "Epoch: 090, Loss: 4.1590, Train: 0.9975, Valid: 0.9877, Best: 0.9879\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 4.143752098083496 | KNN Loss: 4.142079830169678 | CLS Loss: 0.0016720399726182222\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 4.240360260009766 | KNN Loss: 4.226041793823242 | CLS Loss: 0.014318646863102913\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 4.163869380950928 | KNN Loss: 4.151257038116455 | CLS Loss: 0.012612391263246536\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 4.188812255859375 | KNN Loss: 4.1787824630737305 | CLS Loss: 0.01002966146916151\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 4.161622047424316 | KNN Loss: 4.151215553283691 | CLS Loss: 0.01040666550397873\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 4.180050849914551 | KNN Loss: 4.14909029006958 | CLS Loss: 0.030960625037550926\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 4.169342517852783 | KNN Loss: 4.15510892868042 | CLS Loss: 0.014233614318072796\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 4.187343597412109 | KNN Loss: 4.170681953430176 | CLS Loss: 0.016661711037158966\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 4.130605220794678 | KNN Loss: 4.116742134094238 | CLS Loss: 0.01386291440576315\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 4.247783660888672 | KNN Loss: 4.187047004699707 | CLS Loss: 0.06073654443025589\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 4.142603397369385 | KNN Loss: 4.131036758422852 | CLS Loss: 0.011566491797566414\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 4.167499542236328 | KNN Loss: 4.163552761077881 | CLS Loss: 0.0039465525187551975\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 4.186273097991943 | KNN Loss: 4.1690216064453125 | CLS Loss: 0.01725170388817787\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 4.132123947143555 | KNN Loss: 4.1265411376953125 | CLS Loss: 0.00558282807469368\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 4.190596103668213 | KNN Loss: 4.160425662994385 | CLS Loss: 0.030170446261763573\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dfa1649219a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#     print(f\"Loss: {loss} =============================\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-7ccbd69308b5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9865)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd5a9296646497495cb92eb5d899e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f8294e49a0427b87866ac9cf96630c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7124d58201564252b8cc8d332ef7d8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1413390b39648d89cdfed820c5b0df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b813f750db9c4be4b8ebc41bfb10d50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.9410716732903933\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99657048f84497381693493049e60b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "layer 7: 0.0\n",
      "layer 8: 0.0\n",
      "Epoch: 00 | Batch: 000 / 041 | Total loss: 1.587 | Reg loss: 0.012 | Tree loss: 1.587 | Accuracy: 0.691406 | 1.298 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 01 | Batch: 000 / 041 | Total loss: 1.455 | Reg loss: 0.005 | Tree loss: 1.455 | Accuracy: 0.677734 | 2.015 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 02 | Batch: 000 / 041 | Total loss: 1.377 | Reg loss: 0.008 | Tree loss: 1.377 | Accuracy: 0.679688 | 1.851 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 03 | Batch: 000 / 041 | Total loss: 1.296 | Reg loss: 0.010 | Tree loss: 1.296 | Accuracy: 0.689453 | 1.813 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 04 | Batch: 000 / 041 | Total loss: 1.209 | Reg loss: 0.012 | Tree loss: 1.209 | Accuracy: 0.710938 | 1.847 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 05 | Batch: 000 / 041 | Total loss: 1.157 | Reg loss: 0.013 | Tree loss: 1.157 | Accuracy: 0.673828 | 1.83 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 06 | Batch: 000 / 041 | Total loss: 1.086 | Reg loss: 0.015 | Tree loss: 1.086 | Accuracy: 0.689453 | 1.824 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 07 | Batch: 000 / 041 | Total loss: 0.995 | Reg loss: 0.016 | Tree loss: 0.995 | Accuracy: 0.714844 | 1.869 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 08 | Batch: 000 / 041 | Total loss: 1.002 | Reg loss: 0.016 | Tree loss: 1.002 | Accuracy: 0.673828 | 1.88 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 09 | Batch: 000 / 041 | Total loss: 0.955 | Reg loss: 0.017 | Tree loss: 0.955 | Accuracy: 0.701172 | 1.882 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 10 | Batch: 000 / 041 | Total loss: 0.948 | Reg loss: 0.018 | Tree loss: 0.948 | Accuracy: 0.689453 | 1.9 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 11 | Batch: 000 / 041 | Total loss: 0.878 | Reg loss: 0.018 | Tree loss: 0.878 | Accuracy: 0.705078 | 1.883 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 12 | Batch: 000 / 041 | Total loss: 0.826 | Reg loss: 0.019 | Tree loss: 0.826 | Accuracy: 0.744141 | 1.869 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 13 | Batch: 000 / 041 | Total loss: 0.808 | Reg loss: 0.019 | Tree loss: 0.808 | Accuracy: 0.732422 | 1.888 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 14 | Batch: 000 / 041 | Total loss: 0.862 | Reg loss: 0.019 | Tree loss: 0.862 | Accuracy: 0.705078 | 1.88 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 15 | Batch: 000 / 041 | Total loss: 0.845 | Reg loss: 0.019 | Tree loss: 0.845 | Accuracy: 0.712891 | 1.883 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 16 | Batch: 000 / 041 | Total loss: 0.827 | Reg loss: 0.020 | Tree loss: 0.827 | Accuracy: 0.708984 | 1.873 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 17 | Batch: 000 / 041 | Total loss: 0.796 | Reg loss: 0.020 | Tree loss: 0.796 | Accuracy: 0.714844 | 1.876 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 18 | Batch: 000 / 041 | Total loss: 0.799 | Reg loss: 0.020 | Tree loss: 0.799 | Accuracy: 0.740234 | 1.868 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 19 | Batch: 000 / 041 | Total loss: 0.880 | Reg loss: 0.020 | Tree loss: 0.880 | Accuracy: 0.703125 | 1.861 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Batch: 000 / 041 | Total loss: 0.872 | Reg loss: 0.021 | Tree loss: 0.872 | Accuracy: 0.695312 | 1.863 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 21 | Batch: 000 / 041 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.708984 | 1.864 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 22 | Batch: 000 / 041 | Total loss: 0.850 | Reg loss: 0.021 | Tree loss: 0.850 | Accuracy: 0.705078 | 1.863 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 23 | Batch: 000 / 041 | Total loss: 0.830 | Reg loss: 0.021 | Tree loss: 0.830 | Accuracy: 0.722656 | 1.855 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 24 | Batch: 000 / 041 | Total loss: 0.838 | Reg loss: 0.021 | Tree loss: 0.838 | Accuracy: 0.734375 | 1.837 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 25 | Batch: 000 / 041 | Total loss: 0.839 | Reg loss: 0.021 | Tree loss: 0.839 | Accuracy: 0.710938 | 1.827 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 26 | Batch: 000 / 041 | Total loss: 0.744 | Reg loss: 0.021 | Tree loss: 0.744 | Accuracy: 0.751953 | 1.827 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 27 | Batch: 000 / 041 | Total loss: 0.865 | Reg loss: 0.021 | Tree loss: 0.865 | Accuracy: 0.703125 | 1.821 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 28 | Batch: 000 / 041 | Total loss: 0.877 | Reg loss: 0.022 | Tree loss: 0.877 | Accuracy: 0.691406 | 1.821 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 29 | Batch: 000 / 041 | Total loss: 0.837 | Reg loss: 0.022 | Tree loss: 0.837 | Accuracy: 0.710938 | 1.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 30 | Batch: 000 / 041 | Total loss: 0.870 | Reg loss: 0.022 | Tree loss: 0.870 | Accuracy: 0.701172 | 1.81 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 31 | Batch: 000 / 041 | Total loss: 0.820 | Reg loss: 0.022 | Tree loss: 0.820 | Accuracy: 0.699219 | 1.815 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 32 | Batch: 000 / 041 | Total loss: 0.923 | Reg loss: 0.022 | Tree loss: 0.923 | Accuracy: 0.681641 | 1.812 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 33 | Batch: 000 / 041 | Total loss: 0.898 | Reg loss: 0.022 | Tree loss: 0.898 | Accuracy: 0.693359 | 1.811 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 34 | Batch: 000 / 041 | Total loss: 0.916 | Reg loss: 0.022 | Tree loss: 0.916 | Accuracy: 0.697266 | 1.812 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 35 | Batch: 000 / 041 | Total loss: 0.817 | Reg loss: 0.022 | Tree loss: 0.817 | Accuracy: 0.716797 | 1.816 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 36 | Batch: 000 / 041 | Total loss: 0.814 | Reg loss: 0.022 | Tree loss: 0.814 | Accuracy: 0.722656 | 1.823 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 37 | Batch: 000 / 041 | Total loss: 0.825 | Reg loss: 0.022 | Tree loss: 0.825 | Accuracy: 0.718750 | 1.832 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 38 | Batch: 000 / 041 | Total loss: 0.880 | Reg loss: 0.022 | Tree loss: 0.880 | Accuracy: 0.695312 | 1.85 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 39 | Batch: 000 / 041 | Total loss: 0.866 | Reg loss: 0.023 | Tree loss: 0.866 | Accuracy: 0.712891 | 1.853 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Batch: 000 / 041 | Total loss: 0.840 | Reg loss: 0.023 | Tree loss: 0.840 | Accuracy: 0.708984 | 1.853 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 41 | Batch: 000 / 041 | Total loss: 0.921 | Reg loss: 0.023 | Tree loss: 0.921 | Accuracy: 0.681641 | 1.854 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 42 | Batch: 000 / 041 | Total loss: 0.921 | Reg loss: 0.023 | Tree loss: 0.921 | Accuracy: 0.691406 | 1.852 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 43 | Batch: 000 / 041 | Total loss: 0.923 | Reg loss: 0.023 | Tree loss: 0.923 | Accuracy: 0.675781 | 1.852 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 44 | Batch: 000 / 041 | Total loss: 0.794 | Reg loss: 0.023 | Tree loss: 0.794 | Accuracy: 0.738281 | 1.845 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 45 | Batch: 000 / 041 | Total loss: 0.861 | Reg loss: 0.023 | Tree loss: 0.861 | Accuracy: 0.720703 | 1.841 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 46 | Batch: 000 / 041 | Total loss: 0.783 | Reg loss: 0.023 | Tree loss: 0.783 | Accuracy: 0.728516 | 1.84 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 47 | Batch: 000 / 041 | Total loss: 0.862 | Reg loss: 0.023 | Tree loss: 0.862 | Accuracy: 0.697266 | 1.843 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 48 | Batch: 000 / 041 | Total loss: 0.792 | Reg loss: 0.023 | Tree loss: 0.792 | Accuracy: 0.726562 | 1.848 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 49 | Batch: 000 / 041 | Total loss: 0.751 | Reg loss: 0.023 | Tree loss: 0.751 | Accuracy: 0.734375 | 1.849 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 50 | Batch: 000 / 041 | Total loss: 0.820 | Reg loss: 0.023 | Tree loss: 0.820 | Accuracy: 0.720703 | 1.848 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 51 | Batch: 000 / 041 | Total loss: 0.778 | Reg loss: 0.023 | Tree loss: 0.778 | Accuracy: 0.736328 | 1.846 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 52 | Batch: 000 / 041 | Total loss: 0.836 | Reg loss: 0.023 | Tree loss: 0.836 | Accuracy: 0.712891 | 1.845 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 53 | Batch: 000 / 041 | Total loss: 0.900 | Reg loss: 0.023 | Tree loss: 0.900 | Accuracy: 0.685547 | 1.844 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 54 | Batch: 000 / 041 | Total loss: 0.793 | Reg loss: 0.023 | Tree loss: 0.793 | Accuracy: 0.722656 | 1.841 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 55 | Batch: 000 / 041 | Total loss: 0.859 | Reg loss: 0.024 | Tree loss: 0.859 | Accuracy: 0.695312 | 1.842 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 56 | Batch: 000 / 041 | Total loss: 0.891 | Reg loss: 0.024 | Tree loss: 0.891 | Accuracy: 0.679688 | 1.847 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 57 | Batch: 000 / 041 | Total loss: 0.755 | Reg loss: 0.024 | Tree loss: 0.755 | Accuracy: 0.736328 | 1.846 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 58 | Batch: 000 / 041 | Total loss: 0.800 | Reg loss: 0.024 | Tree loss: 0.800 | Accuracy: 0.714844 | 1.854 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 59 | Batch: 000 / 041 | Total loss: 0.843 | Reg loss: 0.024 | Tree loss: 0.843 | Accuracy: 0.695312 | 1.851 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 | Batch: 000 / 041 | Total loss: 0.710 | Reg loss: 0.024 | Tree loss: 0.710 | Accuracy: 0.748047 | 1.85 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 61 | Batch: 000 / 041 | Total loss: 0.805 | Reg loss: 0.024 | Tree loss: 0.805 | Accuracy: 0.708984 | 1.853 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 62 | Batch: 000 / 041 | Total loss: 0.702 | Reg loss: 0.024 | Tree loss: 0.702 | Accuracy: 0.740234 | 1.856 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 63 | Batch: 000 / 041 | Total loss: 0.887 | Reg loss: 0.024 | Tree loss: 0.887 | Accuracy: 0.675781 | 1.86 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 64 | Batch: 000 / 041 | Total loss: 0.757 | Reg loss: 0.024 | Tree loss: 0.757 | Accuracy: 0.716797 | 1.862 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 65 | Batch: 000 / 041 | Total loss: 0.812 | Reg loss: 0.024 | Tree loss: 0.812 | Accuracy: 0.724609 | 1.865 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 66 | Batch: 000 / 041 | Total loss: 0.850 | Reg loss: 0.024 | Tree loss: 0.850 | Accuracy: 0.693359 | 1.867 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 67 | Batch: 000 / 041 | Total loss: 0.829 | Reg loss: 0.024 | Tree loss: 0.829 | Accuracy: 0.685547 | 1.872 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 68 | Batch: 000 / 041 | Total loss: 0.778 | Reg loss: 0.024 | Tree loss: 0.778 | Accuracy: 0.726562 | 1.871 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 69 | Batch: 000 / 041 | Total loss: 0.700 | Reg loss: 0.024 | Tree loss: 0.700 | Accuracy: 0.750000 | 1.868 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 70 | Batch: 000 / 041 | Total loss: 0.724 | Reg loss: 0.024 | Tree loss: 0.724 | Accuracy: 0.744141 | 1.869 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 71 | Batch: 000 / 041 | Total loss: 0.753 | Reg loss: 0.024 | Tree loss: 0.753 | Accuracy: 0.750000 | 1.868 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 72 | Batch: 000 / 041 | Total loss: 0.795 | Reg loss: 0.024 | Tree loss: 0.795 | Accuracy: 0.685547 | 1.87 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 73 | Batch: 000 / 041 | Total loss: 0.783 | Reg loss: 0.024 | Tree loss: 0.783 | Accuracy: 0.710938 | 1.87 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 74 | Batch: 000 / 041 | Total loss: 0.778 | Reg loss: 0.024 | Tree loss: 0.778 | Accuracy: 0.716797 | 1.87 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 75 | Batch: 000 / 041 | Total loss: 0.864 | Reg loss: 0.024 | Tree loss: 0.864 | Accuracy: 0.673828 | 1.874 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 76 | Batch: 000 / 041 | Total loss: 0.779 | Reg loss: 0.024 | Tree loss: 0.779 | Accuracy: 0.707031 | 1.875 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 77 | Batch: 000 / 041 | Total loss: 0.790 | Reg loss: 0.024 | Tree loss: 0.790 | Accuracy: 0.691406 | 1.873 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 78 | Batch: 000 / 041 | Total loss: 0.740 | Reg loss: 0.024 | Tree loss: 0.740 | Accuracy: 0.707031 | 1.873 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 79 | Batch: 000 / 041 | Total loss: 0.757 | Reg loss: 0.024 | Tree loss: 0.757 | Accuracy: 0.710938 | 1.876 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 | Batch: 000 / 041 | Total loss: 0.671 | Reg loss: 0.024 | Tree loss: 0.671 | Accuracy: 0.765625 | 1.878 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 81 | Batch: 000 / 041 | Total loss: 0.725 | Reg loss: 0.024 | Tree loss: 0.725 | Accuracy: 0.730469 | 1.878 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 82 | Batch: 000 / 041 | Total loss: 0.717 | Reg loss: 0.024 | Tree loss: 0.717 | Accuracy: 0.736328 | 1.881 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 83 | Batch: 000 / 041 | Total loss: 0.699 | Reg loss: 0.024 | Tree loss: 0.699 | Accuracy: 0.740234 | 1.885 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 84 | Batch: 000 / 041 | Total loss: 0.752 | Reg loss: 0.024 | Tree loss: 0.752 | Accuracy: 0.705078 | 1.883 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 85 | Batch: 000 / 041 | Total loss: 0.799 | Reg loss: 0.024 | Tree loss: 0.799 | Accuracy: 0.703125 | 1.882 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 86 | Batch: 000 / 041 | Total loss: 0.760 | Reg loss: 0.024 | Tree loss: 0.760 | Accuracy: 0.716797 | 1.882 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 87 | Batch: 000 / 041 | Total loss: 0.824 | Reg loss: 0.024 | Tree loss: 0.824 | Accuracy: 0.681641 | 1.883 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 88 | Batch: 000 / 041 | Total loss: 0.706 | Reg loss: 0.024 | Tree loss: 0.706 | Accuracy: 0.742188 | 1.882 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 89 | Batch: 000 / 041 | Total loss: 0.770 | Reg loss: 0.024 | Tree loss: 0.770 | Accuracy: 0.728516 | 1.884 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 90 | Batch: 000 / 041 | Total loss: 0.714 | Reg loss: 0.024 | Tree loss: 0.714 | Accuracy: 0.746094 | 1.881 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 91 | Batch: 000 / 041 | Total loss: 0.658 | Reg loss: 0.024 | Tree loss: 0.658 | Accuracy: 0.773438 | 1.879 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 92 | Batch: 000 / 041 | Total loss: 0.830 | Reg loss: 0.025 | Tree loss: 0.830 | Accuracy: 0.701172 | 1.879 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 93 | Batch: 000 / 041 | Total loss: 0.792 | Reg loss: 0.025 | Tree loss: 0.792 | Accuracy: 0.685547 | 1.879 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 94 | Batch: 000 / 041 | Total loss: 0.768 | Reg loss: 0.025 | Tree loss: 0.768 | Accuracy: 0.710938 | 1.886 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 95 | Batch: 000 / 041 | Total loss: 0.807 | Reg loss: 0.025 | Tree loss: 0.807 | Accuracy: 0.691406 | 1.886 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 96 | Batch: 000 / 041 | Total loss: 0.736 | Reg loss: 0.025 | Tree loss: 0.736 | Accuracy: 0.724609 | 1.887 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 97 | Batch: 000 / 041 | Total loss: 0.777 | Reg loss: 0.025 | Tree loss: 0.777 | Accuracy: 0.701172 | 1.888 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 98 | Batch: 000 / 041 | Total loss: 0.769 | Reg loss: 0.025 | Tree loss: 0.769 | Accuracy: 0.701172 | 1.888 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 99 | Batch: 000 / 041 | Total loss: 0.807 | Reg loss: 0.025 | Tree loss: 0.807 | Accuracy: 0.693359 | 1.888 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Batch: 000 / 041 | Total loss: 0.789 | Reg loss: 0.025 | Tree loss: 0.789 | Accuracy: 0.726562 | 1.89 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 101 | Batch: 000 / 041 | Total loss: 0.755 | Reg loss: 0.025 | Tree loss: 0.755 | Accuracy: 0.705078 | 1.888 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 102 | Batch: 000 / 041 | Total loss: 0.692 | Reg loss: 0.025 | Tree loss: 0.692 | Accuracy: 0.714844 | 1.89 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 103 | Batch: 000 / 041 | Total loss: 0.793 | Reg loss: 0.025 | Tree loss: 0.793 | Accuracy: 0.703125 | 1.888 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 104 | Batch: 000 / 041 | Total loss: 0.755 | Reg loss: 0.025 | Tree loss: 0.755 | Accuracy: 0.710938 | 1.889 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 105 | Batch: 000 / 041 | Total loss: 0.743 | Reg loss: 0.025 | Tree loss: 0.743 | Accuracy: 0.714844 | 1.885 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 106 | Batch: 000 / 041 | Total loss: 0.850 | Reg loss: 0.025 | Tree loss: 0.850 | Accuracy: 0.675781 | 1.885 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 107 | Batch: 000 / 041 | Total loss: 0.657 | Reg loss: 0.025 | Tree loss: 0.657 | Accuracy: 0.763672 | 1.885 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 108 | Batch: 000 / 041 | Total loss: 0.698 | Reg loss: 0.025 | Tree loss: 0.698 | Accuracy: 0.734375 | 1.886 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 109 | Batch: 000 / 041 | Total loss: 0.739 | Reg loss: 0.025 | Tree loss: 0.739 | Accuracy: 0.734375 | 1.887 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 110 | Batch: 000 / 041 | Total loss: 0.771 | Reg loss: 0.025 | Tree loss: 0.771 | Accuracy: 0.712891 | 1.887 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 111 | Batch: 000 / 041 | Total loss: 0.648 | Reg loss: 0.025 | Tree loss: 0.648 | Accuracy: 0.787109 | 1.89 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 112 | Batch: 000 / 041 | Total loss: 0.775 | Reg loss: 0.025 | Tree loss: 0.775 | Accuracy: 0.718750 | 1.891 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 113 | Batch: 000 / 041 | Total loss: 0.680 | Reg loss: 0.025 | Tree loss: 0.680 | Accuracy: 0.744141 | 1.891 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 114 | Batch: 000 / 041 | Total loss: 0.791 | Reg loss: 0.025 | Tree loss: 0.791 | Accuracy: 0.705078 | 1.892 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 115 | Batch: 000 / 041 | Total loss: 0.800 | Reg loss: 0.025 | Tree loss: 0.800 | Accuracy: 0.708984 | 1.893 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 116 | Batch: 000 / 041 | Total loss: 0.761 | Reg loss: 0.025 | Tree loss: 0.761 | Accuracy: 0.710938 | 1.894 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 117 | Batch: 000 / 041 | Total loss: 0.722 | Reg loss: 0.025 | Tree loss: 0.722 | Accuracy: 0.738281 | 1.895 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 118 | Batch: 000 / 041 | Total loss: 0.707 | Reg loss: 0.025 | Tree loss: 0.707 | Accuracy: 0.742188 | 1.896 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 119 | Batch: 000 / 041 | Total loss: 0.759 | Reg loss: 0.025 | Tree loss: 0.759 | Accuracy: 0.716797 | 1.896 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120 | Batch: 000 / 041 | Total loss: 0.700 | Reg loss: 0.025 | Tree loss: 0.700 | Accuracy: 0.742188 | 1.894 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 121 | Batch: 000 / 041 | Total loss: 0.782 | Reg loss: 0.025 | Tree loss: 0.782 | Accuracy: 0.693359 | 1.894 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 122 | Batch: 000 / 041 | Total loss: 0.832 | Reg loss: 0.025 | Tree loss: 0.832 | Accuracy: 0.673828 | 1.897 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 123 | Batch: 000 / 041 | Total loss: 0.712 | Reg loss: 0.025 | Tree loss: 0.712 | Accuracy: 0.730469 | 1.896 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 124 | Batch: 000 / 041 | Total loss: 0.664 | Reg loss: 0.025 | Tree loss: 0.664 | Accuracy: 0.755859 | 1.897 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 125 | Batch: 000 / 041 | Total loss: 0.807 | Reg loss: 0.025 | Tree loss: 0.807 | Accuracy: 0.679688 | 1.899 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "layer 7: 0.9840425531914895\n",
      "layer 8: 0.9840425531914895\n",
      "Epoch: 126 | Batch: 000 / 041 | Total loss: 0.710 | Reg loss: 0.025 | Tree loss: 0.710 | Accuracy: 0.722656 | 1.898 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
