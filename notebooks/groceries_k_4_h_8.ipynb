{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.market_basket_dataset import MarketBasketDataset, BinaryEncodingTransform, RemoveItemsTransform\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "tree_depth = 8\n",
    "device = 'cuda'\n",
    "dataset_path = r\"/mnt/qnap/ekosman/Groceries_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the market basket dataset and use one-hot encoding for items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MarketBasketDataset(dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(dataset.n_items, 50, 4).train().to(device)\n",
    "epochs = 500\n",
    "lr = 5e-3\n",
    "batch_size = 512\n",
    "log_every = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform = torchvision.transforms.Compose([\n",
    "    RemoveItemsTransform(p=0.5),\n",
    "    BinaryEncodingTransform(mapping=dataset.items_to_idx),\n",
    "]\n",
    ")\n",
    "dataset.target_transform = torchvision.transforms.Compose([\n",
    "    BinaryEncodingTransform(mapping=dataset.items_to_idx),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 500 | iteration 0 / 30 | Total Loss: 2.0072975158691406 | KNN Loss: 6.227202892303467 | BCE Loss: 2.0072975158691406\n",
      "Epoch 0 / 500 | iteration 5 / 30 | Total Loss: 1.9876428842544556 | KNN Loss: 6.2271728515625 | BCE Loss: 1.9876428842544556\n",
      "Epoch 0 / 500 | iteration 10 / 30 | Total Loss: 1.9654991626739502 | KNN Loss: 6.227078914642334 | BCE Loss: 1.9654991626739502\n",
      "Epoch 0 / 500 | iteration 15 / 30 | Total Loss: 2.007986545562744 | KNN Loss: 6.227046489715576 | BCE Loss: 2.007986545562744\n",
      "Epoch 0 / 500 | iteration 20 / 30 | Total Loss: 1.93807053565979 | KNN Loss: 6.227117538452148 | BCE Loss: 1.93807053565979\n",
      "Epoch 0 / 500 | iteration 25 / 30 | Total Loss: 1.890448808670044 | KNN Loss: 6.2272539138793945 | BCE Loss: 1.890448808670044\n",
      "Epoch 1 / 500 | iteration 0 / 30 | Total Loss: 1.8803540468215942 | KNN Loss: 6.227087020874023 | BCE Loss: 1.8803540468215942\n",
      "Epoch 1 / 500 | iteration 5 / 30 | Total Loss: 1.8928595781326294 | KNN Loss: 6.227339267730713 | BCE Loss: 1.8928595781326294\n",
      "Epoch 1 / 500 | iteration 10 / 30 | Total Loss: 1.9279311895370483 | KNN Loss: 6.2269816398620605 | BCE Loss: 1.9279311895370483\n",
      "Epoch 1 / 500 | iteration 15 / 30 | Total Loss: 1.9131510257720947 | KNN Loss: 6.227376937866211 | BCE Loss: 1.9131510257720947\n",
      "Epoch 1 / 500 | iteration 20 / 30 | Total Loss: 1.920452356338501 | KNN Loss: 6.227065563201904 | BCE Loss: 1.920452356338501\n",
      "Epoch 1 / 500 | iteration 25 / 30 | Total Loss: 1.8713029623031616 | KNN Loss: 6.226813316345215 | BCE Loss: 1.8713029623031616\n",
      "Epoch 2 / 500 | iteration 0 / 30 | Total Loss: 1.8674829006195068 | KNN Loss: 6.227560043334961 | BCE Loss: 1.8674829006195068\n",
      "Epoch 2 / 500 | iteration 5 / 30 | Total Loss: 1.951974630355835 | KNN Loss: 6.227015972137451 | BCE Loss: 1.951974630355835\n",
      "Epoch 2 / 500 | iteration 10 / 30 | Total Loss: 1.8323527574539185 | KNN Loss: 6.227171897888184 | BCE Loss: 1.8323527574539185\n",
      "Epoch 2 / 500 | iteration 15 / 30 | Total Loss: 1.837967872619629 | KNN Loss: 6.22722053527832 | BCE Loss: 1.837967872619629\n",
      "Epoch 2 / 500 | iteration 20 / 30 | Total Loss: 1.9158254861831665 | KNN Loss: 6.227051734924316 | BCE Loss: 1.9158254861831665\n",
      "Epoch 2 / 500 | iteration 25 / 30 | Total Loss: 1.8671890497207642 | KNN Loss: 6.227386951446533 | BCE Loss: 1.8671890497207642\n",
      "Epoch 3 / 500 | iteration 0 / 30 | Total Loss: 1.8259891271591187 | KNN Loss: 6.22734260559082 | BCE Loss: 1.8259891271591187\n",
      "Epoch 3 / 500 | iteration 5 / 30 | Total Loss: 1.8334109783172607 | KNN Loss: 6.227197647094727 | BCE Loss: 1.8334109783172607\n",
      "Epoch 3 / 500 | iteration 10 / 30 | Total Loss: 1.7991198301315308 | KNN Loss: 6.227426528930664 | BCE Loss: 1.7991198301315308\n",
      "Epoch 3 / 500 | iteration 15 / 30 | Total Loss: 1.78706693649292 | KNN Loss: 6.227574825286865 | BCE Loss: 1.78706693649292\n",
      "Epoch 3 / 500 | iteration 20 / 30 | Total Loss: 1.7806060314178467 | KNN Loss: 6.227184772491455 | BCE Loss: 1.7806060314178467\n",
      "Epoch 3 / 500 | iteration 25 / 30 | Total Loss: 1.7946438789367676 | KNN Loss: 6.227509498596191 | BCE Loss: 1.7946438789367676\n",
      "Epoch 4 / 500 | iteration 0 / 30 | Total Loss: 1.7668921947479248 | KNN Loss: 6.227322578430176 | BCE Loss: 1.7668921947479248\n",
      "Epoch 4 / 500 | iteration 5 / 30 | Total Loss: 1.8093594312667847 | KNN Loss: 6.22744083404541 | BCE Loss: 1.8093594312667847\n",
      "Epoch 4 / 500 | iteration 10 / 30 | Total Loss: 1.8043646812438965 | KNN Loss: 6.22756290435791 | BCE Loss: 1.8043646812438965\n",
      "Epoch 4 / 500 | iteration 15 / 30 | Total Loss: 1.7402982711791992 | KNN Loss: 6.2272539138793945 | BCE Loss: 1.7402982711791992\n",
      "Epoch 4 / 500 | iteration 20 / 30 | Total Loss: 1.7459204196929932 | KNN Loss: 6.227455139160156 | BCE Loss: 1.7459204196929932\n",
      "Epoch 4 / 500 | iteration 25 / 30 | Total Loss: 1.7670910358428955 | KNN Loss: 6.227315425872803 | BCE Loss: 1.7670910358428955\n",
      "Epoch 5 / 500 | iteration 0 / 30 | Total Loss: 1.78486967086792 | KNN Loss: 6.22726583480835 | BCE Loss: 1.78486967086792\n",
      "Epoch 5 / 500 | iteration 5 / 30 | Total Loss: 1.6985795497894287 | KNN Loss: 6.227466106414795 | BCE Loss: 1.6985795497894287\n",
      "Epoch 5 / 500 | iteration 10 / 30 | Total Loss: 1.6994080543518066 | KNN Loss: 6.227291584014893 | BCE Loss: 1.6994080543518066\n",
      "Epoch 5 / 500 | iteration 15 / 30 | Total Loss: 1.6631381511688232 | KNN Loss: 6.227690696716309 | BCE Loss: 1.6631381511688232\n",
      "Epoch 5 / 500 | iteration 20 / 30 | Total Loss: 1.6799129247665405 | KNN Loss: 6.226943492889404 | BCE Loss: 1.6799129247665405\n",
      "Epoch 5 / 500 | iteration 25 / 30 | Total Loss: 1.6894451379776 | KNN Loss: 6.227537631988525 | BCE Loss: 1.6894451379776\n",
      "Epoch 6 / 500 | iteration 0 / 30 | Total Loss: 1.6292095184326172 | KNN Loss: 6.227575778961182 | BCE Loss: 1.6292095184326172\n",
      "Epoch 6 / 500 | iteration 5 / 30 | Total Loss: 1.6212515830993652 | KNN Loss: 6.227260112762451 | BCE Loss: 1.6212515830993652\n",
      "Epoch 6 / 500 | iteration 10 / 30 | Total Loss: 1.6052213907241821 | KNN Loss: 6.227388381958008 | BCE Loss: 1.6052213907241821\n",
      "Epoch 6 / 500 | iteration 15 / 30 | Total Loss: 1.6274425983428955 | KNN Loss: 6.227214813232422 | BCE Loss: 1.6274425983428955\n",
      "Epoch 6 / 500 | iteration 20 / 30 | Total Loss: 1.595390796661377 | KNN Loss: 6.227156162261963 | BCE Loss: 1.595390796661377\n",
      "Epoch 6 / 500 | iteration 25 / 30 | Total Loss: 1.6219635009765625 | KNN Loss: 6.227537155151367 | BCE Loss: 1.6219635009765625\n",
      "Epoch 7 / 500 | iteration 0 / 30 | Total Loss: 1.5423827171325684 | KNN Loss: 6.227426528930664 | BCE Loss: 1.5423827171325684\n",
      "Epoch 7 / 500 | iteration 5 / 30 | Total Loss: 1.5581085681915283 | KNN Loss: 6.227252960205078 | BCE Loss: 1.5581085681915283\n",
      "Epoch 7 / 500 | iteration 10 / 30 | Total Loss: 1.5679948329925537 | KNN Loss: 6.226894378662109 | BCE Loss: 1.5679948329925537\n",
      "Epoch 7 / 500 | iteration 15 / 30 | Total Loss: 1.5525177717208862 | KNN Loss: 6.2272629737854 | BCE Loss: 1.5525177717208862\n",
      "Epoch 7 / 500 | iteration 20 / 30 | Total Loss: 1.4871267080307007 | KNN Loss: 6.22756290435791 | BCE Loss: 1.4871267080307007\n",
      "Epoch 7 / 500 | iteration 25 / 30 | Total Loss: 1.4134743213653564 | KNN Loss: 6.227331161499023 | BCE Loss: 1.4134743213653564\n",
      "Epoch 8 / 500 | iteration 0 / 30 | Total Loss: 1.4380173683166504 | KNN Loss: 6.227142333984375 | BCE Loss: 1.4380173683166504\n",
      "Epoch 8 / 500 | iteration 5 / 30 | Total Loss: 1.4486987590789795 | KNN Loss: 6.2275390625 | BCE Loss: 1.4486987590789795\n",
      "Epoch 8 / 500 | iteration 10 / 30 | Total Loss: 1.4050698280334473 | KNN Loss: 6.227156162261963 | BCE Loss: 1.4050698280334473\n",
      "Epoch 8 / 500 | iteration 15 / 30 | Total Loss: 1.3618204593658447 | KNN Loss: 6.227344036102295 | BCE Loss: 1.3618204593658447\n",
      "Epoch 8 / 500 | iteration 20 / 30 | Total Loss: 1.3761111497879028 | KNN Loss: 6.227101802825928 | BCE Loss: 1.3761111497879028\n",
      "Epoch 8 / 500 | iteration 25 / 30 | Total Loss: 1.3294579982757568 | KNN Loss: 6.2271809577941895 | BCE Loss: 1.3294579982757568\n",
      "Epoch 9 / 500 | iteration 0 / 30 | Total Loss: 1.3364813327789307 | KNN Loss: 6.227288246154785 | BCE Loss: 1.3364813327789307\n",
      "Epoch 9 / 500 | iteration 5 / 30 | Total Loss: 1.3331321477890015 | KNN Loss: 6.227150917053223 | BCE Loss: 1.3331321477890015\n",
      "Epoch 9 / 500 | iteration 10 / 30 | Total Loss: 1.2640169858932495 | KNN Loss: 6.227417469024658 | BCE Loss: 1.2640169858932495\n",
      "Epoch 9 / 500 | iteration 15 / 30 | Total Loss: 1.2630014419555664 | KNN Loss: 6.227130889892578 | BCE Loss: 1.2630014419555664\n",
      "Epoch 9 / 500 | iteration 20 / 30 | Total Loss: 1.2425496578216553 | KNN Loss: 6.227311611175537 | BCE Loss: 1.2425496578216553\n",
      "Epoch 9 / 500 | iteration 25 / 30 | Total Loss: 1.2363955974578857 | KNN Loss: 6.227275371551514 | BCE Loss: 1.2363955974578857\n",
      "Epoch 10 / 500 | iteration 0 / 30 | Total Loss: 1.2117455005645752 | KNN Loss: 6.227212429046631 | BCE Loss: 1.2117455005645752\n",
      "Epoch 10 / 500 | iteration 5 / 30 | Total Loss: 1.2164537906646729 | KNN Loss: 6.227364540100098 | BCE Loss: 1.2164537906646729\n",
      "Epoch 10 / 500 | iteration 10 / 30 | Total Loss: 1.1659166812896729 | KNN Loss: 6.227121829986572 | BCE Loss: 1.1659166812896729\n",
      "Epoch 10 / 500 | iteration 15 / 30 | Total Loss: 1.1739202737808228 | KNN Loss: 6.2273640632629395 | BCE Loss: 1.1739202737808228\n",
      "Epoch 10 / 500 | iteration 20 / 30 | Total Loss: 1.1707115173339844 | KNN Loss: 6.22708797454834 | BCE Loss: 1.1707115173339844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 500 | iteration 25 / 30 | Total Loss: 1.1139508485794067 | KNN Loss: 6.227087020874023 | BCE Loss: 1.1139508485794067\n",
      "Epoch 11 / 500 | iteration 0 / 30 | Total Loss: 1.1409372091293335 | KNN Loss: 6.227234840393066 | BCE Loss: 1.1409372091293335\n",
      "Epoch 11 / 500 | iteration 5 / 30 | Total Loss: 1.1305830478668213 | KNN Loss: 6.227318286895752 | BCE Loss: 1.1305830478668213\n",
      "Epoch 11 / 500 | iteration 10 / 30 | Total Loss: 1.154988408088684 | KNN Loss: 6.227245807647705 | BCE Loss: 1.154988408088684\n",
      "Epoch 11 / 500 | iteration 15 / 30 | Total Loss: 1.1592546701431274 | KNN Loss: 6.227466106414795 | BCE Loss: 1.1592546701431274\n",
      "Epoch 11 / 500 | iteration 20 / 30 | Total Loss: 1.1000138521194458 | KNN Loss: 6.227219104766846 | BCE Loss: 1.1000138521194458\n",
      "Epoch 11 / 500 | iteration 25 / 30 | Total Loss: 1.1004137992858887 | KNN Loss: 6.227105617523193 | BCE Loss: 1.1004137992858887\n",
      "Epoch 12 / 500 | iteration 0 / 30 | Total Loss: 1.113079309463501 | KNN Loss: 6.2272515296936035 | BCE Loss: 1.113079309463501\n",
      "Epoch 12 / 500 | iteration 5 / 30 | Total Loss: 1.099510908126831 | KNN Loss: 6.227197647094727 | BCE Loss: 1.099510908126831\n",
      "Epoch 12 / 500 | iteration 10 / 30 | Total Loss: 1.094502568244934 | KNN Loss: 6.227360725402832 | BCE Loss: 1.094502568244934\n",
      "Epoch 12 / 500 | iteration 15 / 30 | Total Loss: 1.117936611175537 | KNN Loss: 6.227011203765869 | BCE Loss: 1.117936611175537\n",
      "Epoch 12 / 500 | iteration 20 / 30 | Total Loss: 1.092836618423462 | KNN Loss: 6.227142810821533 | BCE Loss: 1.092836618423462\n",
      "Epoch 12 / 500 | iteration 25 / 30 | Total Loss: 1.0690537691116333 | KNN Loss: 6.227219581604004 | BCE Loss: 1.0690537691116333\n",
      "Epoch 13 / 500 | iteration 0 / 30 | Total Loss: 1.0761337280273438 | KNN Loss: 6.227194786071777 | BCE Loss: 1.0761337280273438\n",
      "Epoch 13 / 500 | iteration 5 / 30 | Total Loss: 1.102136254310608 | KNN Loss: 6.227153778076172 | BCE Loss: 1.102136254310608\n",
      "Epoch 13 / 500 | iteration 10 / 30 | Total Loss: 1.0651780366897583 | KNN Loss: 6.227173328399658 | BCE Loss: 1.0651780366897583\n",
      "Epoch 13 / 500 | iteration 15 / 30 | Total Loss: 1.0893375873565674 | KNN Loss: 6.227299690246582 | BCE Loss: 1.0893375873565674\n",
      "Epoch 13 / 500 | iteration 20 / 30 | Total Loss: 1.0708520412445068 | KNN Loss: 6.226966381072998 | BCE Loss: 1.0708520412445068\n",
      "Epoch 13 / 500 | iteration 25 / 30 | Total Loss: 1.075128197669983 | KNN Loss: 6.227333068847656 | BCE Loss: 1.075128197669983\n",
      "Epoch 14 / 500 | iteration 0 / 30 | Total Loss: 1.0694478750228882 | KNN Loss: 6.227081298828125 | BCE Loss: 1.0694478750228882\n",
      "Epoch 14 / 500 | iteration 5 / 30 | Total Loss: 1.09965181350708 | KNN Loss: 6.2269415855407715 | BCE Loss: 1.09965181350708\n",
      "Epoch 14 / 500 | iteration 10 / 30 | Total Loss: 1.0646356344223022 | KNN Loss: 6.227559566497803 | BCE Loss: 1.0646356344223022\n",
      "Epoch 14 / 500 | iteration 15 / 30 | Total Loss: 1.070942997932434 | KNN Loss: 6.226960182189941 | BCE Loss: 1.070942997932434\n",
      "Epoch 14 / 500 | iteration 20 / 30 | Total Loss: 1.0465295314788818 | KNN Loss: 6.227396488189697 | BCE Loss: 1.0465295314788818\n",
      "Epoch 14 / 500 | iteration 25 / 30 | Total Loss: 1.0758044719696045 | KNN Loss: 6.227169513702393 | BCE Loss: 1.0758044719696045\n",
      "Epoch 15 / 500 | iteration 0 / 30 | Total Loss: 1.0710742473602295 | KNN Loss: 6.2273077964782715 | BCE Loss: 1.0710742473602295\n",
      "Epoch 15 / 500 | iteration 5 / 30 | Total Loss: 1.0731728076934814 | KNN Loss: 6.227287769317627 | BCE Loss: 1.0731728076934814\n",
      "Epoch 15 / 500 | iteration 10 / 30 | Total Loss: 1.1047565937042236 | KNN Loss: 6.227416038513184 | BCE Loss: 1.1047565937042236\n",
      "Epoch 15 / 500 | iteration 15 / 30 | Total Loss: 1.064823865890503 | KNN Loss: 6.226998805999756 | BCE Loss: 1.064823865890503\n",
      "Epoch 15 / 500 | iteration 20 / 30 | Total Loss: 1.0520963668823242 | KNN Loss: 6.227282524108887 | BCE Loss: 1.0520963668823242\n",
      "Epoch 15 / 500 | iteration 25 / 30 | Total Loss: 1.0800156593322754 | KNN Loss: 6.226945877075195 | BCE Loss: 1.0800156593322754\n",
      "Epoch 16 / 500 | iteration 0 / 30 | Total Loss: 1.1004297733306885 | KNN Loss: 6.22722864151001 | BCE Loss: 1.1004297733306885\n",
      "Epoch 16 / 500 | iteration 5 / 30 | Total Loss: 1.0728416442871094 | KNN Loss: 6.2273664474487305 | BCE Loss: 1.0728416442871094\n",
      "Epoch 16 / 500 | iteration 10 / 30 | Total Loss: 1.0848114490509033 | KNN Loss: 6.22705602645874 | BCE Loss: 1.0848114490509033\n",
      "Epoch 16 / 500 | iteration 15 / 30 | Total Loss: 1.0436933040618896 | KNN Loss: 6.227268695831299 | BCE Loss: 1.0436933040618896\n",
      "Epoch 16 / 500 | iteration 20 / 30 | Total Loss: 1.0872122049331665 | KNN Loss: 6.227033615112305 | BCE Loss: 1.0872122049331665\n",
      "Epoch 16 / 500 | iteration 25 / 30 | Total Loss: 1.0939916372299194 | KNN Loss: 6.22719669342041 | BCE Loss: 1.0939916372299194\n",
      "Epoch 17 / 500 | iteration 0 / 30 | Total Loss: 1.0584146976470947 | KNN Loss: 6.227232933044434 | BCE Loss: 1.0584146976470947\n",
      "Epoch 17 / 500 | iteration 5 / 30 | Total Loss: 1.0742652416229248 | KNN Loss: 6.227290153503418 | BCE Loss: 1.0742652416229248\n",
      "Epoch 17 / 500 | iteration 10 / 30 | Total Loss: 1.0585764646530151 | KNN Loss: 6.227041721343994 | BCE Loss: 1.0585764646530151\n",
      "Epoch 17 / 500 | iteration 15 / 30 | Total Loss: 1.0668545961380005 | KNN Loss: 6.227237701416016 | BCE Loss: 1.0668545961380005\n",
      "Epoch 17 / 500 | iteration 20 / 30 | Total Loss: 1.0544313192367554 | KNN Loss: 6.227160453796387 | BCE Loss: 1.0544313192367554\n",
      "Epoch 17 / 500 | iteration 25 / 30 | Total Loss: 1.0571690797805786 | KNN Loss: 6.227261066436768 | BCE Loss: 1.0571690797805786\n",
      "Epoch 18 / 500 | iteration 0 / 30 | Total Loss: 1.0640697479248047 | KNN Loss: 6.2268548011779785 | BCE Loss: 1.0640697479248047\n",
      "Epoch 18 / 500 | iteration 5 / 30 | Total Loss: 1.0819826126098633 | KNN Loss: 6.227278709411621 | BCE Loss: 1.0819826126098633\n",
      "Epoch 18 / 500 | iteration 10 / 30 | Total Loss: 1.0584118366241455 | KNN Loss: 6.227349281311035 | BCE Loss: 1.0584118366241455\n",
      "Epoch 18 / 500 | iteration 15 / 30 | Total Loss: 1.069514513015747 | KNN Loss: 6.226939678192139 | BCE Loss: 1.069514513015747\n",
      "Epoch 18 / 500 | iteration 20 / 30 | Total Loss: 1.0692332983016968 | KNN Loss: 6.22726583480835 | BCE Loss: 1.0692332983016968\n",
      "Epoch 18 / 500 | iteration 25 / 30 | Total Loss: 1.081209421157837 | KNN Loss: 6.227200031280518 | BCE Loss: 1.081209421157837\n",
      "Epoch 19 / 500 | iteration 0 / 30 | Total Loss: 1.0533652305603027 | KNN Loss: 6.2273736000061035 | BCE Loss: 1.0533652305603027\n",
      "Epoch 19 / 500 | iteration 5 / 30 | Total Loss: 1.0600316524505615 | KNN Loss: 6.227207183837891 | BCE Loss: 1.0600316524505615\n",
      "Epoch 19 / 500 | iteration 10 / 30 | Total Loss: 1.0502915382385254 | KNN Loss: 6.227065563201904 | BCE Loss: 1.0502915382385254\n",
      "Epoch 19 / 500 | iteration 15 / 30 | Total Loss: 1.0492711067199707 | KNN Loss: 6.22733736038208 | BCE Loss: 1.0492711067199707\n",
      "Epoch 19 / 500 | iteration 20 / 30 | Total Loss: 1.0532389879226685 | KNN Loss: 6.227294921875 | BCE Loss: 1.0532389879226685\n",
      "Epoch 19 / 500 | iteration 25 / 30 | Total Loss: 1.0715737342834473 | KNN Loss: 6.2272820472717285 | BCE Loss: 1.0715737342834473\n",
      "Epoch 20 / 500 | iteration 0 / 30 | Total Loss: 1.0461571216583252 | KNN Loss: 6.2271833419799805 | BCE Loss: 1.0461571216583252\n",
      "Epoch 20 / 500 | iteration 5 / 30 | Total Loss: 1.0686933994293213 | KNN Loss: 6.227097511291504 | BCE Loss: 1.0686933994293213\n",
      "Epoch 20 / 500 | iteration 10 / 30 | Total Loss: 1.0812104940414429 | KNN Loss: 6.227056980133057 | BCE Loss: 1.0812104940414429\n",
      "Epoch 20 / 500 | iteration 15 / 30 | Total Loss: 1.065738320350647 | KNN Loss: 6.2269978523254395 | BCE Loss: 1.065738320350647\n",
      "Epoch 20 / 500 | iteration 20 / 30 | Total Loss: 1.0769383907318115 | KNN Loss: 6.227359294891357 | BCE Loss: 1.0769383907318115\n",
      "Epoch 20 / 500 | iteration 25 / 30 | Total Loss: 1.0327868461608887 | KNN Loss: 6.227197647094727 | BCE Loss: 1.0327868461608887\n",
      "Epoch 21 / 500 | iteration 0 / 30 | Total Loss: 1.0710031986236572 | KNN Loss: 6.227322101593018 | BCE Loss: 1.0710031986236572\n",
      "Epoch 21 / 500 | iteration 5 / 30 | Total Loss: 1.0476746559143066 | KNN Loss: 6.227035045623779 | BCE Loss: 1.0476746559143066\n",
      "Epoch 21 / 500 | iteration 10 / 30 | Total Loss: 1.0931363105773926 | KNN Loss: 6.227320194244385 | BCE Loss: 1.0931363105773926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 500 | iteration 15 / 30 | Total Loss: 1.0572924613952637 | KNN Loss: 6.226929664611816 | BCE Loss: 1.0572924613952637\n",
      "Epoch 21 / 500 | iteration 20 / 30 | Total Loss: 1.0835916996002197 | KNN Loss: 6.226919174194336 | BCE Loss: 1.0835916996002197\n",
      "Epoch 21 / 500 | iteration 25 / 30 | Total Loss: 1.0618128776550293 | KNN Loss: 6.227316379547119 | BCE Loss: 1.0618128776550293\n",
      "Epoch 22 / 500 | iteration 0 / 30 | Total Loss: 1.0492719411849976 | KNN Loss: 6.227105617523193 | BCE Loss: 1.0492719411849976\n",
      "Epoch 22 / 500 | iteration 5 / 30 | Total Loss: 1.0456345081329346 | KNN Loss: 6.227390289306641 | BCE Loss: 1.0456345081329346\n",
      "Epoch 22 / 500 | iteration 10 / 30 | Total Loss: 1.0723578929901123 | KNN Loss: 6.227113723754883 | BCE Loss: 1.0723578929901123\n",
      "Epoch 22 / 500 | iteration 15 / 30 | Total Loss: 1.0711735486984253 | KNN Loss: 6.227255821228027 | BCE Loss: 1.0711735486984253\n",
      "Epoch 22 / 500 | iteration 20 / 30 | Total Loss: 1.0376567840576172 | KNN Loss: 6.227641582489014 | BCE Loss: 1.0376567840576172\n",
      "Epoch 22 / 500 | iteration 25 / 30 | Total Loss: 1.0728274583816528 | KNN Loss: 6.227144718170166 | BCE Loss: 1.0728274583816528\n",
      "Epoch 23 / 500 | iteration 0 / 30 | Total Loss: 1.0569398403167725 | KNN Loss: 6.2271952629089355 | BCE Loss: 1.0569398403167725\n",
      "Epoch 23 / 500 | iteration 5 / 30 | Total Loss: 1.0489578247070312 | KNN Loss: 6.227183818817139 | BCE Loss: 1.0489578247070312\n",
      "Epoch 23 / 500 | iteration 10 / 30 | Total Loss: 1.0513203144073486 | KNN Loss: 6.227170467376709 | BCE Loss: 1.0513203144073486\n",
      "Epoch 23 / 500 | iteration 15 / 30 | Total Loss: 1.052133321762085 | KNN Loss: 6.227080345153809 | BCE Loss: 1.052133321762085\n",
      "Epoch 23 / 500 | iteration 20 / 30 | Total Loss: 1.0696985721588135 | KNN Loss: 6.227010250091553 | BCE Loss: 1.0696985721588135\n",
      "Epoch 23 / 500 | iteration 25 / 30 | Total Loss: 1.0393497943878174 | KNN Loss: 6.2272725105285645 | BCE Loss: 1.0393497943878174\n",
      "Epoch 24 / 500 | iteration 0 / 30 | Total Loss: 1.0473448038101196 | KNN Loss: 6.227097988128662 | BCE Loss: 1.0473448038101196\n",
      "Epoch 24 / 500 | iteration 5 / 30 | Total Loss: 1.1022660732269287 | KNN Loss: 6.227070331573486 | BCE Loss: 1.1022660732269287\n",
      "Epoch 24 / 500 | iteration 10 / 30 | Total Loss: 1.0602449178695679 | KNN Loss: 6.227283000946045 | BCE Loss: 1.0602449178695679\n",
      "Epoch 24 / 500 | iteration 15 / 30 | Total Loss: 1.0432004928588867 | KNN Loss: 6.227056980133057 | BCE Loss: 1.0432004928588867\n",
      "Epoch 24 / 500 | iteration 20 / 30 | Total Loss: 1.0703939199447632 | KNN Loss: 6.2272419929504395 | BCE Loss: 1.0703939199447632\n",
      "Epoch 24 / 500 | iteration 25 / 30 | Total Loss: 1.0738632678985596 | KNN Loss: 6.227090835571289 | BCE Loss: 1.0738632678985596\n",
      "Epoch 25 / 500 | iteration 0 / 30 | Total Loss: 1.057237148284912 | KNN Loss: 6.227197647094727 | BCE Loss: 1.057237148284912\n",
      "Epoch 25 / 500 | iteration 5 / 30 | Total Loss: 1.06264066696167 | KNN Loss: 6.227230072021484 | BCE Loss: 1.06264066696167\n",
      "Epoch 25 / 500 | iteration 10 / 30 | Total Loss: 1.0661723613739014 | KNN Loss: 6.227274417877197 | BCE Loss: 1.0661723613739014\n",
      "Epoch 25 / 500 | iteration 15 / 30 | Total Loss: 1.0477612018585205 | KNN Loss: 6.227230548858643 | BCE Loss: 1.0477612018585205\n",
      "Epoch 25 / 500 | iteration 20 / 30 | Total Loss: 1.0686606168746948 | KNN Loss: 6.22718620300293 | BCE Loss: 1.0686606168746948\n",
      "Epoch 25 / 500 | iteration 25 / 30 | Total Loss: 1.0362786054611206 | KNN Loss: 6.227163314819336 | BCE Loss: 1.0362786054611206\n",
      "Epoch 26 / 500 | iteration 0 / 30 | Total Loss: 1.0366051197052002 | KNN Loss: 6.227172374725342 | BCE Loss: 1.0366051197052002\n",
      "Epoch 26 / 500 | iteration 5 / 30 | Total Loss: 1.1119393110275269 | KNN Loss: 6.227102756500244 | BCE Loss: 1.1119393110275269\n",
      "Epoch 26 / 500 | iteration 10 / 30 | Total Loss: 1.0321542024612427 | KNN Loss: 6.227035999298096 | BCE Loss: 1.0321542024612427\n",
      "Epoch 26 / 500 | iteration 15 / 30 | Total Loss: 1.065976858139038 | KNN Loss: 6.227334976196289 | BCE Loss: 1.065976858139038\n",
      "Epoch 26 / 500 | iteration 20 / 30 | Total Loss: 1.0784918069839478 | KNN Loss: 6.227299690246582 | BCE Loss: 1.0784918069839478\n",
      "Epoch 26 / 500 | iteration 25 / 30 | Total Loss: 1.0462825298309326 | KNN Loss: 6.2269606590271 | BCE Loss: 1.0462825298309326\n",
      "Epoch 27 / 500 | iteration 0 / 30 | Total Loss: 1.038642406463623 | KNN Loss: 6.227237224578857 | BCE Loss: 1.038642406463623\n",
      "Epoch 27 / 500 | iteration 5 / 30 | Total Loss: 1.0535168647766113 | KNN Loss: 6.227141857147217 | BCE Loss: 1.0535168647766113\n",
      "Epoch 27 / 500 | iteration 10 / 30 | Total Loss: 1.0667921304702759 | KNN Loss: 6.226684093475342 | BCE Loss: 1.0667921304702759\n",
      "Epoch 27 / 500 | iteration 15 / 30 | Total Loss: 1.095996379852295 | KNN Loss: 6.227099418640137 | BCE Loss: 1.095996379852295\n",
      "Epoch 27 / 500 | iteration 20 / 30 | Total Loss: 1.017096996307373 | KNN Loss: 6.227092266082764 | BCE Loss: 1.017096996307373\n",
      "Epoch 27 / 500 | iteration 25 / 30 | Total Loss: 1.0278570652008057 | KNN Loss: 6.2271504402160645 | BCE Loss: 1.0278570652008057\n",
      "Epoch 28 / 500 | iteration 0 / 30 | Total Loss: 1.0528005361557007 | KNN Loss: 6.2272210121154785 | BCE Loss: 1.0528005361557007\n",
      "Epoch 28 / 500 | iteration 5 / 30 | Total Loss: 1.0378667116165161 | KNN Loss: 6.226932048797607 | BCE Loss: 1.0378667116165161\n",
      "Epoch 28 / 500 | iteration 10 / 30 | Total Loss: 1.054060459136963 | KNN Loss: 6.227315425872803 | BCE Loss: 1.054060459136963\n",
      "Epoch 28 / 500 | iteration 15 / 30 | Total Loss: 1.0681928396224976 | KNN Loss: 6.227281093597412 | BCE Loss: 1.0681928396224976\n",
      "Epoch 28 / 500 | iteration 20 / 30 | Total Loss: 1.0698134899139404 | KNN Loss: 6.227112770080566 | BCE Loss: 1.0698134899139404\n",
      "Epoch 28 / 500 | iteration 25 / 30 | Total Loss: 1.0595349073410034 | KNN Loss: 6.227209091186523 | BCE Loss: 1.0595349073410034\n",
      "Epoch 29 / 500 | iteration 0 / 30 | Total Loss: 1.0369782447814941 | KNN Loss: 6.227065563201904 | BCE Loss: 1.0369782447814941\n",
      "Epoch 29 / 500 | iteration 5 / 30 | Total Loss: 1.0860708951950073 | KNN Loss: 6.226713180541992 | BCE Loss: 1.0860708951950073\n",
      "Epoch 29 / 500 | iteration 10 / 30 | Total Loss: 1.0813825130462646 | KNN Loss: 6.227345943450928 | BCE Loss: 1.0813825130462646\n",
      "Epoch 29 / 500 | iteration 15 / 30 | Total Loss: 1.0590474605560303 | KNN Loss: 6.227394104003906 | BCE Loss: 1.0590474605560303\n",
      "Epoch 29 / 500 | iteration 20 / 30 | Total Loss: 1.054333209991455 | KNN Loss: 6.226950168609619 | BCE Loss: 1.054333209991455\n",
      "Epoch 29 / 500 | iteration 25 / 30 | Total Loss: 1.0769368410110474 | KNN Loss: 6.226968288421631 | BCE Loss: 1.0769368410110474\n",
      "Epoch 30 / 500 | iteration 0 / 30 | Total Loss: 1.0405213832855225 | KNN Loss: 6.227229118347168 | BCE Loss: 1.0405213832855225\n",
      "Epoch 30 / 500 | iteration 5 / 30 | Total Loss: 1.0720093250274658 | KNN Loss: 6.227300643920898 | BCE Loss: 1.0720093250274658\n",
      "Epoch 30 / 500 | iteration 10 / 30 | Total Loss: 1.041276216506958 | KNN Loss: 6.227001190185547 | BCE Loss: 1.041276216506958\n",
      "Epoch 30 / 500 | iteration 15 / 30 | Total Loss: 1.0489697456359863 | KNN Loss: 6.227018356323242 | BCE Loss: 1.0489697456359863\n",
      "Epoch 30 / 500 | iteration 20 / 30 | Total Loss: 1.0631437301635742 | KNN Loss: 6.227205276489258 | BCE Loss: 1.0631437301635742\n",
      "Epoch 30 / 500 | iteration 25 / 30 | Total Loss: 1.0363304615020752 | KNN Loss: 6.226994514465332 | BCE Loss: 1.0363304615020752\n",
      "Epoch 31 / 500 | iteration 0 / 30 | Total Loss: 1.0317540168762207 | KNN Loss: 6.2269206047058105 | BCE Loss: 1.0317540168762207\n",
      "Epoch 31 / 500 | iteration 5 / 30 | Total Loss: 1.0599420070648193 | KNN Loss: 6.226914405822754 | BCE Loss: 1.0599420070648193\n",
      "Epoch 31 / 500 | iteration 10 / 30 | Total Loss: 1.0610020160675049 | KNN Loss: 6.22720193862915 | BCE Loss: 1.0610020160675049\n",
      "Epoch 31 / 500 | iteration 15 / 30 | Total Loss: 1.066009283065796 | KNN Loss: 6.227110862731934 | BCE Loss: 1.066009283065796\n",
      "Epoch 31 / 500 | iteration 20 / 30 | Total Loss: 1.0370218753814697 | KNN Loss: 6.227220058441162 | BCE Loss: 1.0370218753814697\n",
      "Epoch 31 / 500 | iteration 25 / 30 | Total Loss: 1.0307891368865967 | KNN Loss: 6.227143287658691 | BCE Loss: 1.0307891368865967\n",
      "Epoch 32 / 500 | iteration 0 / 30 | Total Loss: 1.0083013772964478 | KNN Loss: 6.226855754852295 | BCE Loss: 1.0083013772964478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 / 500 | iteration 5 / 30 | Total Loss: 1.0753090381622314 | KNN Loss: 6.227157115936279 | BCE Loss: 1.0753090381622314\n",
      "Epoch 32 / 500 | iteration 10 / 30 | Total Loss: 1.029982089996338 | KNN Loss: 6.227000713348389 | BCE Loss: 1.029982089996338\n",
      "Epoch 32 / 500 | iteration 15 / 30 | Total Loss: 1.0515832901000977 | KNN Loss: 6.227030277252197 | BCE Loss: 1.0515832901000977\n",
      "Epoch 32 / 500 | iteration 20 / 30 | Total Loss: 1.0583832263946533 | KNN Loss: 6.2273454666137695 | BCE Loss: 1.0583832263946533\n",
      "Epoch 32 / 500 | iteration 25 / 30 | Total Loss: 1.0431360006332397 | KNN Loss: 6.22691535949707 | BCE Loss: 1.0431360006332397\n",
      "Epoch 33 / 500 | iteration 0 / 30 | Total Loss: 1.018707513809204 | KNN Loss: 6.227166652679443 | BCE Loss: 1.018707513809204\n",
      "Epoch 33 / 500 | iteration 5 / 30 | Total Loss: 1.0483719110488892 | KNN Loss: 6.227583885192871 | BCE Loss: 1.0483719110488892\n",
      "Epoch 33 / 500 | iteration 10 / 30 | Total Loss: 1.065049171447754 | KNN Loss: 6.227123737335205 | BCE Loss: 1.065049171447754\n",
      "Epoch 33 / 500 | iteration 15 / 30 | Total Loss: 1.0607037544250488 | KNN Loss: 6.227336883544922 | BCE Loss: 1.0607037544250488\n",
      "Epoch 33 / 500 | iteration 20 / 30 | Total Loss: 1.0816688537597656 | KNN Loss: 6.226951599121094 | BCE Loss: 1.0816688537597656\n",
      "Epoch 33 / 500 | iteration 25 / 30 | Total Loss: 1.0360355377197266 | KNN Loss: 6.227311134338379 | BCE Loss: 1.0360355377197266\n",
      "Epoch 34 / 500 | iteration 0 / 30 | Total Loss: 1.0549043416976929 | KNN Loss: 6.227358341217041 | BCE Loss: 1.0549043416976929\n",
      "Epoch 34 / 500 | iteration 5 / 30 | Total Loss: 1.0465126037597656 | KNN Loss: 6.2271857261657715 | BCE Loss: 1.0465126037597656\n",
      "Epoch 34 / 500 | iteration 10 / 30 | Total Loss: 1.0638598203659058 | KNN Loss: 6.226828575134277 | BCE Loss: 1.0638598203659058\n",
      "Epoch 34 / 500 | iteration 15 / 30 | Total Loss: 1.046058177947998 | KNN Loss: 6.227012634277344 | BCE Loss: 1.046058177947998\n",
      "Epoch 34 / 500 | iteration 20 / 30 | Total Loss: 1.047953486442566 | KNN Loss: 6.227190971374512 | BCE Loss: 1.047953486442566\n",
      "Epoch 34 / 500 | iteration 25 / 30 | Total Loss: 1.0668506622314453 | KNN Loss: 6.227134704589844 | BCE Loss: 1.0668506622314453\n",
      "Epoch 35 / 500 | iteration 0 / 30 | Total Loss: 1.0849294662475586 | KNN Loss: 6.227022647857666 | BCE Loss: 1.0849294662475586\n",
      "Epoch 35 / 500 | iteration 5 / 30 | Total Loss: 1.033530831336975 | KNN Loss: 6.227003574371338 | BCE Loss: 1.033530831336975\n",
      "Epoch 35 / 500 | iteration 10 / 30 | Total Loss: 1.0475574731826782 | KNN Loss: 6.22721529006958 | BCE Loss: 1.0475574731826782\n",
      "Epoch 35 / 500 | iteration 15 / 30 | Total Loss: 1.059783935546875 | KNN Loss: 6.227067947387695 | BCE Loss: 1.059783935546875\n",
      "Epoch 35 / 500 | iteration 20 / 30 | Total Loss: 1.0620338916778564 | KNN Loss: 6.226998329162598 | BCE Loss: 1.0620338916778564\n",
      "Epoch 35 / 500 | iteration 25 / 30 | Total Loss: 1.036048412322998 | KNN Loss: 6.226738929748535 | BCE Loss: 1.036048412322998\n",
      "Epoch 36 / 500 | iteration 0 / 30 | Total Loss: 1.0791220664978027 | KNN Loss: 6.227319240570068 | BCE Loss: 1.0791220664978027\n",
      "Epoch 36 / 500 | iteration 5 / 30 | Total Loss: 1.0549312829971313 | KNN Loss: 6.2269673347473145 | BCE Loss: 1.0549312829971313\n",
      "Epoch 36 / 500 | iteration 10 / 30 | Total Loss: 1.0435633659362793 | KNN Loss: 6.227189540863037 | BCE Loss: 1.0435633659362793\n",
      "Epoch 36 / 500 | iteration 15 / 30 | Total Loss: 1.022755742073059 | KNN Loss: 6.226571559906006 | BCE Loss: 1.022755742073059\n",
      "Epoch 36 / 500 | iteration 20 / 30 | Total Loss: 1.0572313070297241 | KNN Loss: 6.22732400894165 | BCE Loss: 1.0572313070297241\n",
      "Epoch 36 / 500 | iteration 25 / 30 | Total Loss: 1.0767686367034912 | KNN Loss: 6.227097034454346 | BCE Loss: 1.0767686367034912\n",
      "Epoch 37 / 500 | iteration 0 / 30 | Total Loss: 1.0495564937591553 | KNN Loss: 6.227166175842285 | BCE Loss: 1.0495564937591553\n",
      "Epoch 37 / 500 | iteration 5 / 30 | Total Loss: 1.0660285949707031 | KNN Loss: 6.227077484130859 | BCE Loss: 1.0660285949707031\n",
      "Epoch 37 / 500 | iteration 10 / 30 | Total Loss: 1.0585688352584839 | KNN Loss: 6.226852893829346 | BCE Loss: 1.0585688352584839\n",
      "Epoch 37 / 500 | iteration 15 / 30 | Total Loss: 1.0215660333633423 | KNN Loss: 6.227066993713379 | BCE Loss: 1.0215660333633423\n",
      "Epoch 37 / 500 | iteration 20 / 30 | Total Loss: 1.0421817302703857 | KNN Loss: 6.227044582366943 | BCE Loss: 1.0421817302703857\n",
      "Epoch 37 / 500 | iteration 25 / 30 | Total Loss: 1.0489270687103271 | KNN Loss: 6.227213382720947 | BCE Loss: 1.0489270687103271\n",
      "Epoch 38 / 500 | iteration 0 / 30 | Total Loss: 1.087721586227417 | KNN Loss: 6.226884365081787 | BCE Loss: 1.087721586227417\n",
      "Epoch 38 / 500 | iteration 5 / 30 | Total Loss: 1.0510386228561401 | KNN Loss: 6.2271037101745605 | BCE Loss: 1.0510386228561401\n",
      "Epoch 38 / 500 | iteration 10 / 30 | Total Loss: 1.0310767889022827 | KNN Loss: 6.227136135101318 | BCE Loss: 1.0310767889022827\n",
      "Epoch 38 / 500 | iteration 15 / 30 | Total Loss: 1.0648622512817383 | KNN Loss: 6.227080821990967 | BCE Loss: 1.0648622512817383\n",
      "Epoch 38 / 500 | iteration 20 / 30 | Total Loss: 1.0552663803100586 | KNN Loss: 6.226994514465332 | BCE Loss: 1.0552663803100586\n",
      "Epoch 38 / 500 | iteration 25 / 30 | Total Loss: 1.049645185470581 | KNN Loss: 6.227175712585449 | BCE Loss: 1.049645185470581\n",
      "Epoch 39 / 500 | iteration 0 / 30 | Total Loss: 1.0292694568634033 | KNN Loss: 6.227216720581055 | BCE Loss: 1.0292694568634033\n",
      "Epoch 39 / 500 | iteration 5 / 30 | Total Loss: 1.0504422187805176 | KNN Loss: 6.226824760437012 | BCE Loss: 1.0504422187805176\n",
      "Epoch 39 / 500 | iteration 10 / 30 | Total Loss: 1.046095371246338 | KNN Loss: 6.227321147918701 | BCE Loss: 1.046095371246338\n",
      "Epoch 39 / 500 | iteration 15 / 30 | Total Loss: 1.0424444675445557 | KNN Loss: 6.227369785308838 | BCE Loss: 1.0424444675445557\n",
      "Epoch 39 / 500 | iteration 20 / 30 | Total Loss: 1.0281063318252563 | KNN Loss: 6.227382659912109 | BCE Loss: 1.0281063318252563\n",
      "Epoch 39 / 500 | iteration 25 / 30 | Total Loss: 1.0775599479675293 | KNN Loss: 6.227022647857666 | BCE Loss: 1.0775599479675293\n",
      "Epoch 40 / 500 | iteration 0 / 30 | Total Loss: 1.0538318157196045 | KNN Loss: 6.226846218109131 | BCE Loss: 1.0538318157196045\n",
      "Epoch 40 / 500 | iteration 5 / 30 | Total Loss: 1.070797324180603 | KNN Loss: 6.2270989418029785 | BCE Loss: 1.070797324180603\n",
      "Epoch 40 / 500 | iteration 10 / 30 | Total Loss: 1.010857105255127 | KNN Loss: 6.227120399475098 | BCE Loss: 1.010857105255127\n",
      "Epoch 40 / 500 | iteration 15 / 30 | Total Loss: 1.0575261116027832 | KNN Loss: 6.2270827293396 | BCE Loss: 1.0575261116027832\n",
      "Epoch 40 / 500 | iteration 20 / 30 | Total Loss: 1.0494710206985474 | KNN Loss: 6.227209568023682 | BCE Loss: 1.0494710206985474\n",
      "Epoch 40 / 500 | iteration 25 / 30 | Total Loss: 1.0514179468154907 | KNN Loss: 6.227209091186523 | BCE Loss: 1.0514179468154907\n",
      "Epoch 41 / 500 | iteration 0 / 30 | Total Loss: 1.0465785264968872 | KNN Loss: 6.226948261260986 | BCE Loss: 1.0465785264968872\n",
      "Epoch 41 / 500 | iteration 5 / 30 | Total Loss: 1.043962001800537 | KNN Loss: 6.227153778076172 | BCE Loss: 1.043962001800537\n",
      "Epoch 41 / 500 | iteration 10 / 30 | Total Loss: 1.0307834148406982 | KNN Loss: 6.227332592010498 | BCE Loss: 1.0307834148406982\n",
      "Epoch 41 / 500 | iteration 15 / 30 | Total Loss: 1.0652575492858887 | KNN Loss: 6.226783275604248 | BCE Loss: 1.0652575492858887\n",
      "Epoch 41 / 500 | iteration 20 / 30 | Total Loss: 1.035479187965393 | KNN Loss: 6.226900100708008 | BCE Loss: 1.035479187965393\n",
      "Epoch 41 / 500 | iteration 25 / 30 | Total Loss: 1.0642861127853394 | KNN Loss: 6.2272844314575195 | BCE Loss: 1.0642861127853394\n",
      "Epoch 42 / 500 | iteration 0 / 30 | Total Loss: 1.067747712135315 | KNN Loss: 6.227095603942871 | BCE Loss: 1.067747712135315\n",
      "Epoch 42 / 500 | iteration 5 / 30 | Total Loss: 1.0566072463989258 | KNN Loss: 6.227270126342773 | BCE Loss: 1.0566072463989258\n",
      "Epoch 42 / 500 | iteration 10 / 30 | Total Loss: 1.0592912435531616 | KNN Loss: 6.227013111114502 | BCE Loss: 1.0592912435531616\n",
      "Epoch 42 / 500 | iteration 15 / 30 | Total Loss: 1.03972327709198 | KNN Loss: 6.22702169418335 | BCE Loss: 1.03972327709198\n",
      "Epoch 42 / 500 | iteration 20 / 30 | Total Loss: 1.0661479234695435 | KNN Loss: 6.227182865142822 | BCE Loss: 1.0661479234695435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 500 | iteration 25 / 30 | Total Loss: 1.0463571548461914 | KNN Loss: 6.22697114944458 | BCE Loss: 1.0463571548461914\n",
      "Epoch 43 / 500 | iteration 0 / 30 | Total Loss: 1.0512670278549194 | KNN Loss: 6.227015495300293 | BCE Loss: 1.0512670278549194\n",
      "Epoch 43 / 500 | iteration 5 / 30 | Total Loss: 1.04410719871521 | KNN Loss: 6.226932048797607 | BCE Loss: 1.04410719871521\n",
      "Epoch 43 / 500 | iteration 10 / 30 | Total Loss: 1.048304557800293 | KNN Loss: 6.226841449737549 | BCE Loss: 1.048304557800293\n",
      "Epoch 43 / 500 | iteration 15 / 30 | Total Loss: 1.0363131761550903 | KNN Loss: 6.22735071182251 | BCE Loss: 1.0363131761550903\n",
      "Epoch 43 / 500 | iteration 20 / 30 | Total Loss: 1.0411527156829834 | KNN Loss: 6.226919174194336 | BCE Loss: 1.0411527156829834\n",
      "Epoch 43 / 500 | iteration 25 / 30 | Total Loss: 1.091540813446045 | KNN Loss: 6.227146625518799 | BCE Loss: 1.091540813446045\n",
      "Epoch 44 / 500 | iteration 0 / 30 | Total Loss: 1.0506095886230469 | KNN Loss: 6.22714900970459 | BCE Loss: 1.0506095886230469\n",
      "Epoch 44 / 500 | iteration 5 / 30 | Total Loss: 1.0656366348266602 | KNN Loss: 6.226894378662109 | BCE Loss: 1.0656366348266602\n",
      "Epoch 44 / 500 | iteration 10 / 30 | Total Loss: 1.0445711612701416 | KNN Loss: 6.227187633514404 | BCE Loss: 1.0445711612701416\n",
      "Epoch 44 / 500 | iteration 15 / 30 | Total Loss: 1.0404815673828125 | KNN Loss: 6.226840972900391 | BCE Loss: 1.0404815673828125\n",
      "Epoch 44 / 500 | iteration 20 / 30 | Total Loss: 1.0740118026733398 | KNN Loss: 6.227071285247803 | BCE Loss: 1.0740118026733398\n",
      "Epoch 44 / 500 | iteration 25 / 30 | Total Loss: 1.021604061126709 | KNN Loss: 6.227185249328613 | BCE Loss: 1.021604061126709\n",
      "Epoch 45 / 500 | iteration 0 / 30 | Total Loss: 1.0314550399780273 | KNN Loss: 6.227177619934082 | BCE Loss: 1.0314550399780273\n",
      "Epoch 45 / 500 | iteration 5 / 30 | Total Loss: 1.0653613805770874 | KNN Loss: 6.227150917053223 | BCE Loss: 1.0653613805770874\n",
      "Epoch 45 / 500 | iteration 10 / 30 | Total Loss: 1.0827569961547852 | KNN Loss: 6.226877689361572 | BCE Loss: 1.0827569961547852\n",
      "Epoch 45 / 500 | iteration 15 / 30 | Total Loss: 1.0412449836730957 | KNN Loss: 6.2272162437438965 | BCE Loss: 1.0412449836730957\n",
      "Epoch 45 / 500 | iteration 20 / 30 | Total Loss: 1.044980525970459 | KNN Loss: 6.226830005645752 | BCE Loss: 1.044980525970459\n",
      "Epoch 45 / 500 | iteration 25 / 30 | Total Loss: 1.0713214874267578 | KNN Loss: 6.227201461791992 | BCE Loss: 1.0713214874267578\n",
      "Epoch 46 / 500 | iteration 0 / 30 | Total Loss: 1.047629475593567 | KNN Loss: 6.227020740509033 | BCE Loss: 1.047629475593567\n",
      "Epoch 46 / 500 | iteration 5 / 30 | Total Loss: 1.0429561138153076 | KNN Loss: 6.22706413269043 | BCE Loss: 1.0429561138153076\n",
      "Epoch 46 / 500 | iteration 10 / 30 | Total Loss: 1.0371406078338623 | KNN Loss: 6.226822376251221 | BCE Loss: 1.0371406078338623\n",
      "Epoch 46 / 500 | iteration 15 / 30 | Total Loss: 1.027015209197998 | KNN Loss: 6.227103233337402 | BCE Loss: 1.027015209197998\n",
      "Epoch 46 / 500 | iteration 20 / 30 | Total Loss: 1.075881004333496 | KNN Loss: 6.227274417877197 | BCE Loss: 1.075881004333496\n",
      "Epoch 46 / 500 | iteration 25 / 30 | Total Loss: 1.0374150276184082 | KNN Loss: 6.226931571960449 | BCE Loss: 1.0374150276184082\n",
      "Epoch 47 / 500 | iteration 0 / 30 | Total Loss: 1.0399174690246582 | KNN Loss: 6.226896286010742 | BCE Loss: 1.0399174690246582\n",
      "Epoch 47 / 500 | iteration 5 / 30 | Total Loss: 1.0593388080596924 | KNN Loss: 6.227141857147217 | BCE Loss: 1.0593388080596924\n",
      "Epoch 47 / 500 | iteration 10 / 30 | Total Loss: 1.041120171546936 | KNN Loss: 6.227063179016113 | BCE Loss: 1.041120171546936\n",
      "Epoch 47 / 500 | iteration 15 / 30 | Total Loss: 1.0429307222366333 | KNN Loss: 6.226883888244629 | BCE Loss: 1.0429307222366333\n",
      "Epoch 47 / 500 | iteration 20 / 30 | Total Loss: 1.0759165287017822 | KNN Loss: 6.227407455444336 | BCE Loss: 1.0759165287017822\n",
      "Epoch 47 / 500 | iteration 25 / 30 | Total Loss: 1.0598938465118408 | KNN Loss: 6.22714900970459 | BCE Loss: 1.0598938465118408\n",
      "Epoch 48 / 500 | iteration 0 / 30 | Total Loss: 1.078322172164917 | KNN Loss: 6.22730016708374 | BCE Loss: 1.078322172164917\n",
      "Epoch 48 / 500 | iteration 5 / 30 | Total Loss: 1.06124746799469 | KNN Loss: 6.226952075958252 | BCE Loss: 1.06124746799469\n",
      "Epoch 48 / 500 | iteration 10 / 30 | Total Loss: 1.0471405982971191 | KNN Loss: 6.22721529006958 | BCE Loss: 1.0471405982971191\n",
      "Epoch 48 / 500 | iteration 15 / 30 | Total Loss: 1.0506031513214111 | KNN Loss: 6.226865291595459 | BCE Loss: 1.0506031513214111\n",
      "Epoch 48 / 500 | iteration 20 / 30 | Total Loss: 1.0187278985977173 | KNN Loss: 6.227176189422607 | BCE Loss: 1.0187278985977173\n",
      "Epoch 48 / 500 | iteration 25 / 30 | Total Loss: 1.0476391315460205 | KNN Loss: 6.227288246154785 | BCE Loss: 1.0476391315460205\n",
      "Epoch 49 / 500 | iteration 0 / 30 | Total Loss: 1.0540189743041992 | KNN Loss: 6.227134704589844 | BCE Loss: 1.0540189743041992\n",
      "Epoch 49 / 500 | iteration 5 / 30 | Total Loss: 1.0480365753173828 | KNN Loss: 6.227022647857666 | BCE Loss: 1.0480365753173828\n",
      "Epoch 49 / 500 | iteration 10 / 30 | Total Loss: 1.0567805767059326 | KNN Loss: 6.226980209350586 | BCE Loss: 1.0567805767059326\n",
      "Epoch 49 / 500 | iteration 15 / 30 | Total Loss: 1.037968397140503 | KNN Loss: 6.226883888244629 | BCE Loss: 1.037968397140503\n",
      "Epoch 49 / 500 | iteration 20 / 30 | Total Loss: 1.0169553756713867 | KNN Loss: 6.226826190948486 | BCE Loss: 1.0169553756713867\n",
      "Epoch 49 / 500 | iteration 25 / 30 | Total Loss: 1.064497470855713 | KNN Loss: 6.226799964904785 | BCE Loss: 1.064497470855713\n",
      "Epoch 50 / 500 | iteration 0 / 30 | Total Loss: 1.0416066646575928 | KNN Loss: 6.227145671844482 | BCE Loss: 1.0416066646575928\n",
      "Epoch 50 / 500 | iteration 5 / 30 | Total Loss: 1.0205891132354736 | KNN Loss: 6.226944923400879 | BCE Loss: 1.0205891132354736\n",
      "Epoch 50 / 500 | iteration 10 / 30 | Total Loss: 1.0815715789794922 | KNN Loss: 6.226933479309082 | BCE Loss: 1.0815715789794922\n",
      "Epoch 50 / 500 | iteration 15 / 30 | Total Loss: 1.0486270189285278 | KNN Loss: 6.226747989654541 | BCE Loss: 1.0486270189285278\n",
      "Epoch 50 / 500 | iteration 20 / 30 | Total Loss: 1.0214924812316895 | KNN Loss: 6.227243900299072 | BCE Loss: 1.0214924812316895\n",
      "Epoch 50 / 500 | iteration 25 / 30 | Total Loss: 1.045417308807373 | KNN Loss: 6.226789951324463 | BCE Loss: 1.045417308807373\n",
      "Epoch 51 / 500 | iteration 0 / 30 | Total Loss: 1.074570655822754 | KNN Loss: 6.227043628692627 | BCE Loss: 1.074570655822754\n",
      "Epoch 51 / 500 | iteration 5 / 30 | Total Loss: 1.060409426689148 | KNN Loss: 6.227187633514404 | BCE Loss: 1.060409426689148\n",
      "Epoch 51 / 500 | iteration 10 / 30 | Total Loss: 1.051432728767395 | KNN Loss: 6.227088451385498 | BCE Loss: 1.051432728767395\n",
      "Epoch 51 / 500 | iteration 15 / 30 | Total Loss: 1.0362064838409424 | KNN Loss: 6.2270827293396 | BCE Loss: 1.0362064838409424\n",
      "Epoch 51 / 500 | iteration 20 / 30 | Total Loss: 1.0372953414916992 | KNN Loss: 6.2267537117004395 | BCE Loss: 1.0372953414916992\n",
      "Epoch 51 / 500 | iteration 25 / 30 | Total Loss: 1.0482609272003174 | KNN Loss: 6.227085590362549 | BCE Loss: 1.0482609272003174\n",
      "Epoch 52 / 500 | iteration 0 / 30 | Total Loss: 1.0675989389419556 | KNN Loss: 6.227144718170166 | BCE Loss: 1.0675989389419556\n",
      "Epoch 52 / 500 | iteration 5 / 30 | Total Loss: 1.0252265930175781 | KNN Loss: 6.227255821228027 | BCE Loss: 1.0252265930175781\n",
      "Epoch 52 / 500 | iteration 10 / 30 | Total Loss: 1.040438175201416 | KNN Loss: 6.227011680603027 | BCE Loss: 1.040438175201416\n",
      "Epoch 52 / 500 | iteration 15 / 30 | Total Loss: 1.0788748264312744 | KNN Loss: 6.227207660675049 | BCE Loss: 1.0788748264312744\n",
      "Epoch 52 / 500 | iteration 20 / 30 | Total Loss: 1.0708364248275757 | KNN Loss: 6.227088928222656 | BCE Loss: 1.0708364248275757\n",
      "Epoch 52 / 500 | iteration 25 / 30 | Total Loss: 1.0537219047546387 | KNN Loss: 6.226958274841309 | BCE Loss: 1.0537219047546387\n",
      "Epoch 53 / 500 | iteration 0 / 30 | Total Loss: 1.0310918092727661 | KNN Loss: 6.226840972900391 | BCE Loss: 1.0310918092727661\n",
      "Epoch 53 / 500 | iteration 5 / 30 | Total Loss: 1.044142723083496 | KNN Loss: 6.226910591125488 | BCE Loss: 1.044142723083496\n",
      "Epoch 53 / 500 | iteration 10 / 30 | Total Loss: 1.0431363582611084 | KNN Loss: 6.226961135864258 | BCE Loss: 1.0431363582611084\n",
      "Epoch 53 / 500 | iteration 15 / 30 | Total Loss: 1.039466381072998 | KNN Loss: 6.226747989654541 | BCE Loss: 1.039466381072998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 / 500 | iteration 20 / 30 | Total Loss: 1.0615265369415283 | KNN Loss: 6.227290153503418 | BCE Loss: 1.0615265369415283\n",
      "Epoch 53 / 500 | iteration 25 / 30 | Total Loss: 1.0531423091888428 | KNN Loss: 6.227272033691406 | BCE Loss: 1.0531423091888428\n",
      "Epoch 54 / 500 | iteration 0 / 30 | Total Loss: 1.0578547716140747 | KNN Loss: 6.227115631103516 | BCE Loss: 1.0578547716140747\n",
      "Epoch 54 / 500 | iteration 5 / 30 | Total Loss: 1.0479074716567993 | KNN Loss: 6.227134704589844 | BCE Loss: 1.0479074716567993\n",
      "Epoch 54 / 500 | iteration 10 / 30 | Total Loss: 1.0590124130249023 | KNN Loss: 6.227303981781006 | BCE Loss: 1.0590124130249023\n",
      "Epoch 54 / 500 | iteration 15 / 30 | Total Loss: 1.05381441116333 | KNN Loss: 6.226988315582275 | BCE Loss: 1.05381441116333\n",
      "Epoch 54 / 500 | iteration 20 / 30 | Total Loss: 1.0622897148132324 | KNN Loss: 6.226889133453369 | BCE Loss: 1.0622897148132324\n",
      "Epoch 54 / 500 | iteration 25 / 30 | Total Loss: 1.0240764617919922 | KNN Loss: 6.2272491455078125 | BCE Loss: 1.0240764617919922\n",
      "Epoch    55: reducing learning rate of group 0 to 3.5000e-03.\n",
      "Epoch 55 / 500 | iteration 0 / 30 | Total Loss: 1.0345683097839355 | KNN Loss: 6.226553916931152 | BCE Loss: 1.0345683097839355\n",
      "Epoch 55 / 500 | iteration 5 / 30 | Total Loss: 1.033366084098816 | KNN Loss: 6.227179050445557 | BCE Loss: 1.033366084098816\n",
      "Epoch 55 / 500 | iteration 10 / 30 | Total Loss: 1.0543110370635986 | KNN Loss: 6.227033615112305 | BCE Loss: 1.0543110370635986\n",
      "Epoch 55 / 500 | iteration 15 / 30 | Total Loss: 1.058429479598999 | KNN Loss: 6.227193355560303 | BCE Loss: 1.058429479598999\n",
      "Epoch 55 / 500 | iteration 20 / 30 | Total Loss: 1.0619990825653076 | KNN Loss: 6.226960182189941 | BCE Loss: 1.0619990825653076\n",
      "Epoch 55 / 500 | iteration 25 / 30 | Total Loss: 1.0317039489746094 | KNN Loss: 6.227176666259766 | BCE Loss: 1.0317039489746094\n",
      "Epoch 56 / 500 | iteration 0 / 30 | Total Loss: 1.026155710220337 | KNN Loss: 6.227139949798584 | BCE Loss: 1.026155710220337\n",
      "Epoch 56 / 500 | iteration 5 / 30 | Total Loss: 1.0497950315475464 | KNN Loss: 6.226903915405273 | BCE Loss: 1.0497950315475464\n",
      "Epoch 56 / 500 | iteration 10 / 30 | Total Loss: 1.0709813833236694 | KNN Loss: 6.2269206047058105 | BCE Loss: 1.0709813833236694\n",
      "Epoch 56 / 500 | iteration 15 / 30 | Total Loss: 1.0456218719482422 | KNN Loss: 6.227182388305664 | BCE Loss: 1.0456218719482422\n",
      "Epoch 56 / 500 | iteration 20 / 30 | Total Loss: 1.0398430824279785 | KNN Loss: 6.227057456970215 | BCE Loss: 1.0398430824279785\n",
      "Epoch 56 / 500 | iteration 25 / 30 | Total Loss: 1.0516842603683472 | KNN Loss: 6.227311134338379 | BCE Loss: 1.0516842603683472\n",
      "Epoch 57 / 500 | iteration 0 / 30 | Total Loss: 1.042203426361084 | KNN Loss: 6.22699499130249 | BCE Loss: 1.042203426361084\n",
      "Epoch 57 / 500 | iteration 5 / 30 | Total Loss: 1.0447344779968262 | KNN Loss: 6.226694583892822 | BCE Loss: 1.0447344779968262\n",
      "Epoch 57 / 500 | iteration 10 / 30 | Total Loss: 1.0411921739578247 | KNN Loss: 6.227070331573486 | BCE Loss: 1.0411921739578247\n",
      "Epoch 57 / 500 | iteration 15 / 30 | Total Loss: 1.0491573810577393 | KNN Loss: 6.227214813232422 | BCE Loss: 1.0491573810577393\n",
      "Epoch 57 / 500 | iteration 20 / 30 | Total Loss: 1.0135513544082642 | KNN Loss: 6.2267866134643555 | BCE Loss: 1.0135513544082642\n",
      "Epoch 57 / 500 | iteration 25 / 30 | Total Loss: 1.066875696182251 | KNN Loss: 6.22714376449585 | BCE Loss: 1.066875696182251\n",
      "Epoch 58 / 500 | iteration 0 / 30 | Total Loss: 1.033097743988037 | KNN Loss: 6.227138042449951 | BCE Loss: 1.033097743988037\n",
      "Epoch 58 / 500 | iteration 5 / 30 | Total Loss: 1.042495608329773 | KNN Loss: 6.227091312408447 | BCE Loss: 1.042495608329773\n",
      "Epoch 58 / 500 | iteration 10 / 30 | Total Loss: 1.0461803674697876 | KNN Loss: 6.227015018463135 | BCE Loss: 1.0461803674697876\n",
      "Epoch 58 / 500 | iteration 15 / 30 | Total Loss: 1.046010971069336 | KNN Loss: 6.226993560791016 | BCE Loss: 1.046010971069336\n",
      "Epoch 58 / 500 | iteration 20 / 30 | Total Loss: 1.0526902675628662 | KNN Loss: 6.22712516784668 | BCE Loss: 1.0526902675628662\n",
      "Epoch 58 / 500 | iteration 25 / 30 | Total Loss: 1.031822919845581 | KNN Loss: 6.22725248336792 | BCE Loss: 1.031822919845581\n",
      "Epoch 59 / 500 | iteration 0 / 30 | Total Loss: 1.037670373916626 | KNN Loss: 6.2270684242248535 | BCE Loss: 1.037670373916626\n",
      "Epoch 59 / 500 | iteration 5 / 30 | Total Loss: 1.0469516515731812 | KNN Loss: 6.227309703826904 | BCE Loss: 1.0469516515731812\n",
      "Epoch 59 / 500 | iteration 10 / 30 | Total Loss: 1.0542473793029785 | KNN Loss: 6.227207660675049 | BCE Loss: 1.0542473793029785\n",
      "Epoch 59 / 500 | iteration 15 / 30 | Total Loss: 1.0628345012664795 | KNN Loss: 6.226944446563721 | BCE Loss: 1.0628345012664795\n",
      "Epoch 59 / 500 | iteration 20 / 30 | Total Loss: 1.0699381828308105 | KNN Loss: 6.22688102722168 | BCE Loss: 1.0699381828308105\n",
      "Epoch 59 / 500 | iteration 25 / 30 | Total Loss: 1.0632593631744385 | KNN Loss: 6.227025508880615 | BCE Loss: 1.0632593631744385\n",
      "Epoch 60 / 500 | iteration 0 / 30 | Total Loss: 1.0443387031555176 | KNN Loss: 6.227198123931885 | BCE Loss: 1.0443387031555176\n",
      "Epoch 60 / 500 | iteration 5 / 30 | Total Loss: 1.0598459243774414 | KNN Loss: 6.227068901062012 | BCE Loss: 1.0598459243774414\n",
      "Epoch 60 / 500 | iteration 10 / 30 | Total Loss: 1.0491145849227905 | KNN Loss: 6.227298736572266 | BCE Loss: 1.0491145849227905\n",
      "Epoch 60 / 500 | iteration 15 / 30 | Total Loss: 1.0444464683532715 | KNN Loss: 6.2269287109375 | BCE Loss: 1.0444464683532715\n",
      "Epoch 60 / 500 | iteration 20 / 30 | Total Loss: 1.0851430892944336 | KNN Loss: 6.2272257804870605 | BCE Loss: 1.0851430892944336\n",
      "Epoch 60 / 500 | iteration 25 / 30 | Total Loss: 1.074493169784546 | KNN Loss: 6.226787567138672 | BCE Loss: 1.074493169784546\n",
      "Epoch 61 / 500 | iteration 0 / 30 | Total Loss: 1.0258054733276367 | KNN Loss: 6.227087020874023 | BCE Loss: 1.0258054733276367\n",
      "Epoch 61 / 500 | iteration 5 / 30 | Total Loss: 1.0738062858581543 | KNN Loss: 6.227341175079346 | BCE Loss: 1.0738062858581543\n",
      "Epoch 61 / 500 | iteration 10 / 30 | Total Loss: 1.0447834730148315 | KNN Loss: 6.226919174194336 | BCE Loss: 1.0447834730148315\n",
      "Epoch 61 / 500 | iteration 15 / 30 | Total Loss: 1.0243840217590332 | KNN Loss: 6.2271647453308105 | BCE Loss: 1.0243840217590332\n",
      "Epoch 61 / 500 | iteration 20 / 30 | Total Loss: 1.091943621635437 | KNN Loss: 6.22697114944458 | BCE Loss: 1.091943621635437\n",
      "Epoch 61 / 500 | iteration 25 / 30 | Total Loss: 1.0564875602722168 | KNN Loss: 6.226588249206543 | BCE Loss: 1.0564875602722168\n",
      "Epoch 62 / 500 | iteration 0 / 30 | Total Loss: 1.0617300271987915 | KNN Loss: 6.227014541625977 | BCE Loss: 1.0617300271987915\n",
      "Epoch 62 / 500 | iteration 5 / 30 | Total Loss: 1.078087568283081 | KNN Loss: 6.226916790008545 | BCE Loss: 1.078087568283081\n",
      "Epoch 62 / 500 | iteration 10 / 30 | Total Loss: 1.0630604028701782 | KNN Loss: 6.227244853973389 | BCE Loss: 1.0630604028701782\n",
      "Epoch 62 / 500 | iteration 15 / 30 | Total Loss: 1.0476789474487305 | KNN Loss: 6.227012634277344 | BCE Loss: 1.0476789474487305\n",
      "Epoch 62 / 500 | iteration 20 / 30 | Total Loss: 1.0259225368499756 | KNN Loss: 6.226904392242432 | BCE Loss: 1.0259225368499756\n",
      "Epoch 62 / 500 | iteration 25 / 30 | Total Loss: 1.0580224990844727 | KNN Loss: 6.227371692657471 | BCE Loss: 1.0580224990844727\n",
      "Epoch 63 / 500 | iteration 0 / 30 | Total Loss: 1.0563220977783203 | KNN Loss: 6.2270026206970215 | BCE Loss: 1.0563220977783203\n",
      "Epoch 63 / 500 | iteration 5 / 30 | Total Loss: 1.0299818515777588 | KNN Loss: 6.2268781661987305 | BCE Loss: 1.0299818515777588\n",
      "Epoch 63 / 500 | iteration 10 / 30 | Total Loss: 1.04800546169281 | KNN Loss: 6.227014064788818 | BCE Loss: 1.04800546169281\n",
      "Epoch 63 / 500 | iteration 15 / 30 | Total Loss: 1.0351213216781616 | KNN Loss: 6.227156639099121 | BCE Loss: 1.0351213216781616\n",
      "Epoch 63 / 500 | iteration 20 / 30 | Total Loss: 1.0586822032928467 | KNN Loss: 6.226883888244629 | BCE Loss: 1.0586822032928467\n",
      "Epoch 63 / 500 | iteration 25 / 30 | Total Loss: 1.046029806137085 | KNN Loss: 6.2268829345703125 | BCE Loss: 1.046029806137085\n",
      "Epoch 64 / 500 | iteration 0 / 30 | Total Loss: 1.0647966861724854 | KNN Loss: 6.2271342277526855 | BCE Loss: 1.0647966861724854\n",
      "Epoch 64 / 500 | iteration 5 / 30 | Total Loss: 1.0604302883148193 | KNN Loss: 6.227200984954834 | BCE Loss: 1.0604302883148193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 / 500 | iteration 10 / 30 | Total Loss: 1.0658824443817139 | KNN Loss: 6.227335453033447 | BCE Loss: 1.0658824443817139\n",
      "Epoch 64 / 500 | iteration 15 / 30 | Total Loss: 1.0483509302139282 | KNN Loss: 6.227010250091553 | BCE Loss: 1.0483509302139282\n",
      "Epoch 64 / 500 | iteration 20 / 30 | Total Loss: 1.0740257501602173 | KNN Loss: 6.22695779800415 | BCE Loss: 1.0740257501602173\n",
      "Epoch 64 / 500 | iteration 25 / 30 | Total Loss: 1.026416301727295 | KNN Loss: 6.22708797454834 | BCE Loss: 1.026416301727295\n",
      "Epoch 65 / 500 | iteration 0 / 30 | Total Loss: 1.071574330329895 | KNN Loss: 6.226841926574707 | BCE Loss: 1.071574330329895\n",
      "Epoch 65 / 500 | iteration 5 / 30 | Total Loss: 1.0505361557006836 | KNN Loss: 6.226873874664307 | BCE Loss: 1.0505361557006836\n",
      "Epoch 65 / 500 | iteration 10 / 30 | Total Loss: 1.0773199796676636 | KNN Loss: 6.227167129516602 | BCE Loss: 1.0773199796676636\n",
      "Epoch 65 / 500 | iteration 15 / 30 | Total Loss: 1.0297532081604004 | KNN Loss: 6.2273783683776855 | BCE Loss: 1.0297532081604004\n",
      "Epoch 65 / 500 | iteration 20 / 30 | Total Loss: 1.0295374393463135 | KNN Loss: 6.22703742980957 | BCE Loss: 1.0295374393463135\n",
      "Epoch 65 / 500 | iteration 25 / 30 | Total Loss: 1.0322719812393188 | KNN Loss: 6.2270612716674805 | BCE Loss: 1.0322719812393188\n",
      "Epoch 66 / 500 | iteration 0 / 30 | Total Loss: 1.0634701251983643 | KNN Loss: 6.227134704589844 | BCE Loss: 1.0634701251983643\n",
      "Epoch 66 / 500 | iteration 5 / 30 | Total Loss: 1.049088716506958 | KNN Loss: 6.226751327514648 | BCE Loss: 1.049088716506958\n",
      "Epoch 66 / 500 | iteration 10 / 30 | Total Loss: 1.0526429414749146 | KNN Loss: 6.226864814758301 | BCE Loss: 1.0526429414749146\n",
      "Epoch 66 / 500 | iteration 15 / 30 | Total Loss: 1.032959222793579 | KNN Loss: 6.22710657119751 | BCE Loss: 1.032959222793579\n",
      "Epoch 66 / 500 | iteration 20 / 30 | Total Loss: 1.0601366758346558 | KNN Loss: 6.226934909820557 | BCE Loss: 1.0601366758346558\n",
      "Epoch 66 / 500 | iteration 25 / 30 | Total Loss: 1.045621395111084 | KNN Loss: 6.227028846740723 | BCE Loss: 1.045621395111084\n",
      "Epoch    67: reducing learning rate of group 0 to 2.4500e-03.\n",
      "Epoch 67 / 500 | iteration 0 / 30 | Total Loss: 1.0534613132476807 | KNN Loss: 6.2268266677856445 | BCE Loss: 1.0534613132476807\n",
      "Epoch 67 / 500 | iteration 5 / 30 | Total Loss: 1.0390641689300537 | KNN Loss: 6.226860046386719 | BCE Loss: 1.0390641689300537\n",
      "Epoch 67 / 500 | iteration 10 / 30 | Total Loss: 1.0485517978668213 | KNN Loss: 6.226994037628174 | BCE Loss: 1.0485517978668213\n",
      "Epoch 67 / 500 | iteration 15 / 30 | Total Loss: 1.0179197788238525 | KNN Loss: 6.2272515296936035 | BCE Loss: 1.0179197788238525\n",
      "Epoch 67 / 500 | iteration 20 / 30 | Total Loss: 1.040165662765503 | KNN Loss: 6.226980686187744 | BCE Loss: 1.040165662765503\n",
      "Epoch 67 / 500 | iteration 25 / 30 | Total Loss: 1.0551071166992188 | KNN Loss: 6.227266311645508 | BCE Loss: 1.0551071166992188\n",
      "Epoch 68 / 500 | iteration 0 / 30 | Total Loss: 1.059417963027954 | KNN Loss: 6.227044582366943 | BCE Loss: 1.059417963027954\n",
      "Epoch 68 / 500 | iteration 5 / 30 | Total Loss: 1.0741325616836548 | KNN Loss: 6.226719379425049 | BCE Loss: 1.0741325616836548\n",
      "Epoch 68 / 500 | iteration 10 / 30 | Total Loss: 1.0696618556976318 | KNN Loss: 6.226952075958252 | BCE Loss: 1.0696618556976318\n",
      "Epoch 68 / 500 | iteration 15 / 30 | Total Loss: 1.0957791805267334 | KNN Loss: 6.226846694946289 | BCE Loss: 1.0957791805267334\n",
      "Epoch 68 / 500 | iteration 20 / 30 | Total Loss: 1.0684905052185059 | KNN Loss: 6.227071762084961 | BCE Loss: 1.0684905052185059\n",
      "Epoch 68 / 500 | iteration 25 / 30 | Total Loss: 1.0663992166519165 | KNN Loss: 6.227050304412842 | BCE Loss: 1.0663992166519165\n",
      "Epoch 69 / 500 | iteration 0 / 30 | Total Loss: 1.0754139423370361 | KNN Loss: 6.226944446563721 | BCE Loss: 1.0754139423370361\n",
      "Epoch 69 / 500 | iteration 5 / 30 | Total Loss: 1.0592665672302246 | KNN Loss: 6.226937770843506 | BCE Loss: 1.0592665672302246\n",
      "Epoch 69 / 500 | iteration 10 / 30 | Total Loss: 1.022161602973938 | KNN Loss: 6.2267231941223145 | BCE Loss: 1.022161602973938\n",
      "Epoch 69 / 500 | iteration 15 / 30 | Total Loss: 1.0536422729492188 | KNN Loss: 6.226893424987793 | BCE Loss: 1.0536422729492188\n",
      "Epoch 69 / 500 | iteration 20 / 30 | Total Loss: 1.0185174942016602 | KNN Loss: 6.226898670196533 | BCE Loss: 1.0185174942016602\n",
      "Epoch 69 / 500 | iteration 25 / 30 | Total Loss: 1.0687751770019531 | KNN Loss: 6.2269368171691895 | BCE Loss: 1.0687751770019531\n",
      "Epoch 70 / 500 | iteration 0 / 30 | Total Loss: 1.059412956237793 | KNN Loss: 6.227241039276123 | BCE Loss: 1.059412956237793\n",
      "Epoch 70 / 500 | iteration 5 / 30 | Total Loss: 1.0289628505706787 | KNN Loss: 6.226982116699219 | BCE Loss: 1.0289628505706787\n",
      "Epoch 70 / 500 | iteration 10 / 30 | Total Loss: 1.0290940999984741 | KNN Loss: 6.227123737335205 | BCE Loss: 1.0290940999984741\n",
      "Epoch 70 / 500 | iteration 15 / 30 | Total Loss: 1.045356035232544 | KNN Loss: 6.226954460144043 | BCE Loss: 1.045356035232544\n",
      "Epoch 70 / 500 | iteration 20 / 30 | Total Loss: 1.0744553804397583 | KNN Loss: 6.227102279663086 | BCE Loss: 1.0744553804397583\n",
      "Epoch 70 / 500 | iteration 25 / 30 | Total Loss: 1.0299217700958252 | KNN Loss: 6.227200508117676 | BCE Loss: 1.0299217700958252\n",
      "Epoch 71 / 500 | iteration 0 / 30 | Total Loss: 1.042860746383667 | KNN Loss: 6.227451324462891 | BCE Loss: 1.042860746383667\n",
      "Epoch 71 / 500 | iteration 5 / 30 | Total Loss: 1.0594276189804077 | KNN Loss: 6.227099895477295 | BCE Loss: 1.0594276189804077\n",
      "Epoch 71 / 500 | iteration 10 / 30 | Total Loss: 1.065793752670288 | KNN Loss: 6.2271409034729 | BCE Loss: 1.065793752670288\n",
      "Epoch 71 / 500 | iteration 15 / 30 | Total Loss: 1.0657466650009155 | KNN Loss: 6.226945400238037 | BCE Loss: 1.0657466650009155\n",
      "Epoch 71 / 500 | iteration 20 / 30 | Total Loss: 1.0596895217895508 | KNN Loss: 6.227239608764648 | BCE Loss: 1.0596895217895508\n",
      "Epoch 71 / 500 | iteration 25 / 30 | Total Loss: 1.0577585697174072 | KNN Loss: 6.227133274078369 | BCE Loss: 1.0577585697174072\n",
      "Epoch 72 / 500 | iteration 0 / 30 | Total Loss: 1.008824348449707 | KNN Loss: 6.227042198181152 | BCE Loss: 1.008824348449707\n",
      "Epoch 72 / 500 | iteration 5 / 30 | Total Loss: 1.0442781448364258 | KNN Loss: 6.226963043212891 | BCE Loss: 1.0442781448364258\n",
      "Epoch 72 / 500 | iteration 10 / 30 | Total Loss: 1.0645339488983154 | KNN Loss: 6.2271504402160645 | BCE Loss: 1.0645339488983154\n",
      "Epoch 72 / 500 | iteration 15 / 30 | Total Loss: 1.071094274520874 | KNN Loss: 6.226919174194336 | BCE Loss: 1.071094274520874\n",
      "Epoch 72 / 500 | iteration 20 / 30 | Total Loss: 1.0418965816497803 | KNN Loss: 6.227260112762451 | BCE Loss: 1.0418965816497803\n",
      "Epoch 72 / 500 | iteration 25 / 30 | Total Loss: 1.0389456748962402 | KNN Loss: 6.226776599884033 | BCE Loss: 1.0389456748962402\n",
      "Epoch 73 / 500 | iteration 0 / 30 | Total Loss: 1.0494110584259033 | KNN Loss: 6.226729869842529 | BCE Loss: 1.0494110584259033\n",
      "Epoch 73 / 500 | iteration 5 / 30 | Total Loss: 1.052253246307373 | KNN Loss: 6.226836204528809 | BCE Loss: 1.052253246307373\n",
      "Epoch 73 / 500 | iteration 10 / 30 | Total Loss: 1.054158091545105 | KNN Loss: 6.22676944732666 | BCE Loss: 1.054158091545105\n",
      "Epoch 73 / 500 | iteration 15 / 30 | Total Loss: 1.0814287662506104 | KNN Loss: 6.226789951324463 | BCE Loss: 1.0814287662506104\n",
      "Epoch 73 / 500 | iteration 20 / 30 | Total Loss: 1.0202287435531616 | KNN Loss: 6.226696968078613 | BCE Loss: 1.0202287435531616\n",
      "Epoch 73 / 500 | iteration 25 / 30 | Total Loss: 1.0263981819152832 | KNN Loss: 6.226919651031494 | BCE Loss: 1.0263981819152832\n",
      "Epoch 74 / 500 | iteration 0 / 30 | Total Loss: 1.059779167175293 | KNN Loss: 6.22689962387085 | BCE Loss: 1.059779167175293\n",
      "Epoch 74 / 500 | iteration 5 / 30 | Total Loss: 1.0425143241882324 | KNN Loss: 6.227089881896973 | BCE Loss: 1.0425143241882324\n",
      "Epoch 74 / 500 | iteration 10 / 30 | Total Loss: 1.0692559480667114 | KNN Loss: 6.227035999298096 | BCE Loss: 1.0692559480667114\n",
      "Epoch 74 / 500 | iteration 15 / 30 | Total Loss: 1.0311628580093384 | KNN Loss: 6.226726055145264 | BCE Loss: 1.0311628580093384\n",
      "Epoch 74 / 500 | iteration 20 / 30 | Total Loss: 1.0830519199371338 | KNN Loss: 6.227269172668457 | BCE Loss: 1.0830519199371338\n",
      "Epoch 74 / 500 | iteration 25 / 30 | Total Loss: 1.0536729097366333 | KNN Loss: 6.226978778839111 | BCE Loss: 1.0536729097366333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 500 | iteration 0 / 30 | Total Loss: 1.058895468711853 | KNN Loss: 6.226919651031494 | BCE Loss: 1.058895468711853\n",
      "Epoch 75 / 500 | iteration 5 / 30 | Total Loss: 1.0337564945220947 | KNN Loss: 6.226998805999756 | BCE Loss: 1.0337564945220947\n",
      "Epoch 75 / 500 | iteration 10 / 30 | Total Loss: 1.0652885437011719 | KNN Loss: 6.227047443389893 | BCE Loss: 1.0652885437011719\n",
      "Epoch 75 / 500 | iteration 15 / 30 | Total Loss: 1.0697295665740967 | KNN Loss: 6.226920127868652 | BCE Loss: 1.0697295665740967\n",
      "Epoch 75 / 500 | iteration 20 / 30 | Total Loss: 1.0246686935424805 | KNN Loss: 6.2267889976501465 | BCE Loss: 1.0246686935424805\n",
      "Epoch 75 / 500 | iteration 25 / 30 | Total Loss: 1.080754280090332 | KNN Loss: 6.227147102355957 | BCE Loss: 1.080754280090332\n",
      "Epoch 76 / 500 | iteration 0 / 30 | Total Loss: 1.0415258407592773 | KNN Loss: 6.226583957672119 | BCE Loss: 1.0415258407592773\n",
      "Epoch 76 / 500 | iteration 5 / 30 | Total Loss: 1.0682053565979004 | KNN Loss: 6.227074146270752 | BCE Loss: 1.0682053565979004\n",
      "Epoch 76 / 500 | iteration 10 / 30 | Total Loss: 1.0695527791976929 | KNN Loss: 6.227076530456543 | BCE Loss: 1.0695527791976929\n",
      "Epoch 76 / 500 | iteration 15 / 30 | Total Loss: 1.061144232749939 | KNN Loss: 6.227031707763672 | BCE Loss: 1.061144232749939\n",
      "Epoch 76 / 500 | iteration 20 / 30 | Total Loss: 1.0467991828918457 | KNN Loss: 6.227080345153809 | BCE Loss: 1.0467991828918457\n",
      "Epoch 76 / 500 | iteration 25 / 30 | Total Loss: 1.0736950635910034 | KNN Loss: 6.227069854736328 | BCE Loss: 1.0736950635910034\n",
      "Epoch 77 / 500 | iteration 0 / 30 | Total Loss: 1.0401709079742432 | KNN Loss: 6.226874351501465 | BCE Loss: 1.0401709079742432\n",
      "Epoch 77 / 500 | iteration 5 / 30 | Total Loss: 1.0376383066177368 | KNN Loss: 6.227094650268555 | BCE Loss: 1.0376383066177368\n",
      "Epoch 77 / 500 | iteration 10 / 30 | Total Loss: 1.046295166015625 | KNN Loss: 6.226916313171387 | BCE Loss: 1.046295166015625\n",
      "Epoch 77 / 500 | iteration 15 / 30 | Total Loss: 1.0461251735687256 | KNN Loss: 6.2270307540893555 | BCE Loss: 1.0461251735687256\n",
      "Epoch 77 / 500 | iteration 20 / 30 | Total Loss: 1.064371109008789 | KNN Loss: 6.226998329162598 | BCE Loss: 1.064371109008789\n",
      "Epoch 77 / 500 | iteration 25 / 30 | Total Loss: 1.0448276996612549 | KNN Loss: 6.226794719696045 | BCE Loss: 1.0448276996612549\n",
      "Epoch    78: reducing learning rate of group 0 to 1.7150e-03.\n",
      "Epoch 78 / 500 | iteration 0 / 30 | Total Loss: 1.0639958381652832 | KNN Loss: 6.226922988891602 | BCE Loss: 1.0639958381652832\n",
      "Epoch 78 / 500 | iteration 5 / 30 | Total Loss: 1.0548582077026367 | KNN Loss: 6.22706413269043 | BCE Loss: 1.0548582077026367\n",
      "Epoch 78 / 500 | iteration 10 / 30 | Total Loss: 1.0279009342193604 | KNN Loss: 6.226898193359375 | BCE Loss: 1.0279009342193604\n",
      "Epoch 78 / 500 | iteration 15 / 30 | Total Loss: 1.059556007385254 | KNN Loss: 6.22681188583374 | BCE Loss: 1.059556007385254\n",
      "Epoch 78 / 500 | iteration 20 / 30 | Total Loss: 1.059983253479004 | KNN Loss: 6.227014064788818 | BCE Loss: 1.059983253479004\n",
      "Epoch 78 / 500 | iteration 25 / 30 | Total Loss: 1.0597940683364868 | KNN Loss: 6.226797580718994 | BCE Loss: 1.0597940683364868\n",
      "Epoch 79 / 500 | iteration 0 / 30 | Total Loss: 1.0564908981323242 | KNN Loss: 6.226930618286133 | BCE Loss: 1.0564908981323242\n",
      "Epoch 79 / 500 | iteration 5 / 30 | Total Loss: 1.062089204788208 | KNN Loss: 6.22691535949707 | BCE Loss: 1.062089204788208\n",
      "Epoch 79 / 500 | iteration 10 / 30 | Total Loss: 1.0392696857452393 | KNN Loss: 6.226988792419434 | BCE Loss: 1.0392696857452393\n",
      "Epoch 79 / 500 | iteration 15 / 30 | Total Loss: 1.0535433292388916 | KNN Loss: 6.226986408233643 | BCE Loss: 1.0535433292388916\n",
      "Epoch 79 / 500 | iteration 20 / 30 | Total Loss: 1.044999599456787 | KNN Loss: 6.226908206939697 | BCE Loss: 1.044999599456787\n",
      "Epoch 79 / 500 | iteration 25 / 30 | Total Loss: 1.062838077545166 | KNN Loss: 6.227081775665283 | BCE Loss: 1.062838077545166\n",
      "Epoch 80 / 500 | iteration 0 / 30 | Total Loss: 1.0462257862091064 | KNN Loss: 6.226866245269775 | BCE Loss: 1.0462257862091064\n",
      "Epoch 80 / 500 | iteration 5 / 30 | Total Loss: 1.052435278892517 | KNN Loss: 6.226987361907959 | BCE Loss: 1.052435278892517\n",
      "Epoch 80 / 500 | iteration 10 / 30 | Total Loss: 1.052392840385437 | KNN Loss: 6.227070331573486 | BCE Loss: 1.052392840385437\n",
      "Epoch 80 / 500 | iteration 15 / 30 | Total Loss: 1.057611107826233 | KNN Loss: 6.226888179779053 | BCE Loss: 1.057611107826233\n",
      "Epoch 80 / 500 | iteration 20 / 30 | Total Loss: 1.0730233192443848 | KNN Loss: 6.227049827575684 | BCE Loss: 1.0730233192443848\n",
      "Epoch 80 / 500 | iteration 25 / 30 | Total Loss: 1.0619968175888062 | KNN Loss: 6.227074146270752 | BCE Loss: 1.0619968175888062\n",
      "Epoch 81 / 500 | iteration 0 / 30 | Total Loss: 1.0553038120269775 | KNN Loss: 6.226836681365967 | BCE Loss: 1.0553038120269775\n",
      "Epoch 81 / 500 | iteration 5 / 30 | Total Loss: 1.0458999872207642 | KNN Loss: 6.22684907913208 | BCE Loss: 1.0458999872207642\n",
      "Epoch 81 / 500 | iteration 10 / 30 | Total Loss: 1.0564630031585693 | KNN Loss: 6.226840019226074 | BCE Loss: 1.0564630031585693\n",
      "Epoch 81 / 500 | iteration 15 / 30 | Total Loss: 1.0491116046905518 | KNN Loss: 6.226787090301514 | BCE Loss: 1.0491116046905518\n",
      "Epoch 81 / 500 | iteration 20 / 30 | Total Loss: 1.0702691078186035 | KNN Loss: 6.227062702178955 | BCE Loss: 1.0702691078186035\n",
      "Epoch 81 / 500 | iteration 25 / 30 | Total Loss: 1.0180604457855225 | KNN Loss: 6.226621150970459 | BCE Loss: 1.0180604457855225\n",
      "Epoch 82 / 500 | iteration 0 / 30 | Total Loss: 1.0221400260925293 | KNN Loss: 6.226516246795654 | BCE Loss: 1.0221400260925293\n",
      "Epoch 82 / 500 | iteration 5 / 30 | Total Loss: 1.0326980352401733 | KNN Loss: 6.226995468139648 | BCE Loss: 1.0326980352401733\n",
      "Epoch 82 / 500 | iteration 10 / 30 | Total Loss: 1.0640535354614258 | KNN Loss: 6.2270050048828125 | BCE Loss: 1.0640535354614258\n",
      "Epoch 82 / 500 | iteration 15 / 30 | Total Loss: 1.034425973892212 | KNN Loss: 6.2271904945373535 | BCE Loss: 1.034425973892212\n",
      "Epoch 82 / 500 | iteration 20 / 30 | Total Loss: 1.0400984287261963 | KNN Loss: 6.226842880249023 | BCE Loss: 1.0400984287261963\n",
      "Epoch 82 / 500 | iteration 25 / 30 | Total Loss: 1.043539047241211 | KNN Loss: 6.226511478424072 | BCE Loss: 1.043539047241211\n",
      "Epoch 83 / 500 | iteration 0 / 30 | Total Loss: 1.0381399393081665 | KNN Loss: 6.226934909820557 | BCE Loss: 1.0381399393081665\n",
      "Epoch 83 / 500 | iteration 5 / 30 | Total Loss: 1.0567944049835205 | KNN Loss: 6.227008819580078 | BCE Loss: 1.0567944049835205\n",
      "Epoch 83 / 500 | iteration 10 / 30 | Total Loss: 1.0715259313583374 | KNN Loss: 6.227170944213867 | BCE Loss: 1.0715259313583374\n",
      "Epoch 83 / 500 | iteration 15 / 30 | Total Loss: 1.0736510753631592 | KNN Loss: 6.226858615875244 | BCE Loss: 1.0736510753631592\n",
      "Epoch 83 / 500 | iteration 20 / 30 | Total Loss: 1.0652542114257812 | KNN Loss: 6.2265729904174805 | BCE Loss: 1.0652542114257812\n",
      "Epoch 83 / 500 | iteration 25 / 30 | Total Loss: 1.0650601387023926 | KNN Loss: 6.2271904945373535 | BCE Loss: 1.0650601387023926\n",
      "Epoch 84 / 500 | iteration 0 / 30 | Total Loss: 1.0476701259613037 | KNN Loss: 6.227085590362549 | BCE Loss: 1.0476701259613037\n",
      "Epoch 84 / 500 | iteration 5 / 30 | Total Loss: 1.0585153102874756 | KNN Loss: 6.226754188537598 | BCE Loss: 1.0585153102874756\n",
      "Epoch 84 / 500 | iteration 10 / 30 | Total Loss: 1.0478394031524658 | KNN Loss: 6.226929664611816 | BCE Loss: 1.0478394031524658\n",
      "Epoch 84 / 500 | iteration 15 / 30 | Total Loss: 1.051274299621582 | KNN Loss: 6.2268877029418945 | BCE Loss: 1.051274299621582\n",
      "Epoch 84 / 500 | iteration 20 / 30 | Total Loss: 1.0579694509506226 | KNN Loss: 6.226973533630371 | BCE Loss: 1.0579694509506226\n",
      "Epoch 84 / 500 | iteration 25 / 30 | Total Loss: 1.0273137092590332 | KNN Loss: 6.227052211761475 | BCE Loss: 1.0273137092590332\n",
      "Epoch 85 / 500 | iteration 0 / 30 | Total Loss: 1.0373902320861816 | KNN Loss: 6.226844787597656 | BCE Loss: 1.0373902320861816\n",
      "Epoch 85 / 500 | iteration 5 / 30 | Total Loss: 1.0603423118591309 | KNN Loss: 6.226949691772461 | BCE Loss: 1.0603423118591309\n",
      "Epoch 85 / 500 | iteration 10 / 30 | Total Loss: 1.0325267314910889 | KNN Loss: 6.227061748504639 | BCE Loss: 1.0325267314910889\n",
      "Epoch 85 / 500 | iteration 15 / 30 | Total Loss: 1.0225470066070557 | KNN Loss: 6.227085590362549 | BCE Loss: 1.0225470066070557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 500 | iteration 20 / 30 | Total Loss: 1.0773146152496338 | KNN Loss: 6.226704120635986 | BCE Loss: 1.0773146152496338\n",
      "Epoch 85 / 500 | iteration 25 / 30 | Total Loss: 1.0384821891784668 | KNN Loss: 6.226852893829346 | BCE Loss: 1.0384821891784668\n",
      "Epoch 86 / 500 | iteration 0 / 30 | Total Loss: 1.066483974456787 | KNN Loss: 6.226875305175781 | BCE Loss: 1.066483974456787\n",
      "Epoch 86 / 500 | iteration 5 / 30 | Total Loss: 1.0413341522216797 | KNN Loss: 6.227021217346191 | BCE Loss: 1.0413341522216797\n",
      "Epoch 86 / 500 | iteration 10 / 30 | Total Loss: 1.0411936044692993 | KNN Loss: 6.22705602645874 | BCE Loss: 1.0411936044692993\n",
      "Epoch 86 / 500 | iteration 15 / 30 | Total Loss: 1.084040641784668 | KNN Loss: 6.227148056030273 | BCE Loss: 1.084040641784668\n",
      "Epoch 86 / 500 | iteration 20 / 30 | Total Loss: 1.0611236095428467 | KNN Loss: 6.2269768714904785 | BCE Loss: 1.0611236095428467\n",
      "Epoch 86 / 500 | iteration 25 / 30 | Total Loss: 1.0695083141326904 | KNN Loss: 6.227015495300293 | BCE Loss: 1.0695083141326904\n",
      "Epoch 87 / 500 | iteration 0 / 30 | Total Loss: 1.043183445930481 | KNN Loss: 6.226894378662109 | BCE Loss: 1.043183445930481\n",
      "Epoch 87 / 500 | iteration 5 / 30 | Total Loss: 1.089017391204834 | KNN Loss: 6.226900577545166 | BCE Loss: 1.089017391204834\n",
      "Epoch 87 / 500 | iteration 10 / 30 | Total Loss: 1.0673415660858154 | KNN Loss: 6.226630210876465 | BCE Loss: 1.0673415660858154\n",
      "Epoch 87 / 500 | iteration 15 / 30 | Total Loss: 1.058902382850647 | KNN Loss: 6.226495265960693 | BCE Loss: 1.058902382850647\n",
      "Epoch 87 / 500 | iteration 20 / 30 | Total Loss: 1.0425264835357666 | KNN Loss: 6.226678848266602 | BCE Loss: 1.0425264835357666\n",
      "Epoch 87 / 500 | iteration 25 / 30 | Total Loss: 1.0113742351531982 | KNN Loss: 6.22713565826416 | BCE Loss: 1.0113742351531982\n",
      "Epoch 88 / 500 | iteration 0 / 30 | Total Loss: 1.0745165348052979 | KNN Loss: 6.227095603942871 | BCE Loss: 1.0745165348052979\n",
      "Epoch 88 / 500 | iteration 5 / 30 | Total Loss: 1.0618035793304443 | KNN Loss: 6.226681232452393 | BCE Loss: 1.0618035793304443\n",
      "Epoch 88 / 500 | iteration 10 / 30 | Total Loss: 1.0349822044372559 | KNN Loss: 6.226724624633789 | BCE Loss: 1.0349822044372559\n",
      "Epoch 88 / 500 | iteration 15 / 30 | Total Loss: 1.0288798809051514 | KNN Loss: 6.226816654205322 | BCE Loss: 1.0288798809051514\n",
      "Epoch 88 / 500 | iteration 20 / 30 | Total Loss: 1.0358902215957642 | KNN Loss: 6.2271318435668945 | BCE Loss: 1.0358902215957642\n",
      "Epoch 88 / 500 | iteration 25 / 30 | Total Loss: 1.0600178241729736 | KNN Loss: 6.226719856262207 | BCE Loss: 1.0600178241729736\n",
      "Epoch 89 / 500 | iteration 0 / 30 | Total Loss: 1.0166664123535156 | KNN Loss: 6.226627349853516 | BCE Loss: 1.0166664123535156\n",
      "Epoch 89 / 500 | iteration 5 / 30 | Total Loss: 1.0371415615081787 | KNN Loss: 6.2268595695495605 | BCE Loss: 1.0371415615081787\n",
      "Epoch 89 / 500 | iteration 10 / 30 | Total Loss: 1.0347919464111328 | KNN Loss: 6.227256774902344 | BCE Loss: 1.0347919464111328\n",
      "Epoch 89 / 500 | iteration 15 / 30 | Total Loss: 1.0482752323150635 | KNN Loss: 6.227129936218262 | BCE Loss: 1.0482752323150635\n",
      "Epoch 89 / 500 | iteration 20 / 30 | Total Loss: 1.0593624114990234 | KNN Loss: 6.226992607116699 | BCE Loss: 1.0593624114990234\n",
      "Epoch 89 / 500 | iteration 25 / 30 | Total Loss: 1.0652278661727905 | KNN Loss: 6.226921081542969 | BCE Loss: 1.0652278661727905\n",
      "Epoch 90 / 500 | iteration 0 / 30 | Total Loss: 1.0494534969329834 | KNN Loss: 6.227118492126465 | BCE Loss: 1.0494534969329834\n",
      "Epoch 90 / 500 | iteration 5 / 30 | Total Loss: 1.050907015800476 | KNN Loss: 6.226667404174805 | BCE Loss: 1.050907015800476\n",
      "Epoch 90 / 500 | iteration 10 / 30 | Total Loss: 1.029900074005127 | KNN Loss: 6.226857662200928 | BCE Loss: 1.029900074005127\n",
      "Epoch 90 / 500 | iteration 15 / 30 | Total Loss: 1.0649242401123047 | KNN Loss: 6.226937770843506 | BCE Loss: 1.0649242401123047\n",
      "Epoch 90 / 500 | iteration 20 / 30 | Total Loss: 1.0337841510772705 | KNN Loss: 6.227034568786621 | BCE Loss: 1.0337841510772705\n",
      "Epoch 90 / 500 | iteration 25 / 30 | Total Loss: 1.061861515045166 | KNN Loss: 6.2269415855407715 | BCE Loss: 1.061861515045166\n",
      "Epoch 91 / 500 | iteration 0 / 30 | Total Loss: 1.0588171482086182 | KNN Loss: 6.226621627807617 | BCE Loss: 1.0588171482086182\n",
      "Epoch 91 / 500 | iteration 5 / 30 | Total Loss: 1.0724496841430664 | KNN Loss: 6.226861000061035 | BCE Loss: 1.0724496841430664\n",
      "Epoch 91 / 500 | iteration 10 / 30 | Total Loss: 1.0606943368911743 | KNN Loss: 6.227421283721924 | BCE Loss: 1.0606943368911743\n",
      "Epoch 91 / 500 | iteration 15 / 30 | Total Loss: 1.0298632383346558 | KNN Loss: 6.226792335510254 | BCE Loss: 1.0298632383346558\n",
      "Epoch 91 / 500 | iteration 20 / 30 | Total Loss: 1.0446548461914062 | KNN Loss: 6.226871967315674 | BCE Loss: 1.0446548461914062\n",
      "Epoch 91 / 500 | iteration 25 / 30 | Total Loss: 1.0765628814697266 | KNN Loss: 6.2266950607299805 | BCE Loss: 1.0765628814697266\n",
      "Epoch 92 / 500 | iteration 0 / 30 | Total Loss: 1.0518882274627686 | KNN Loss: 6.227048397064209 | BCE Loss: 1.0518882274627686\n",
      "Epoch 92 / 500 | iteration 5 / 30 | Total Loss: 1.0602848529815674 | KNN Loss: 6.226814270019531 | BCE Loss: 1.0602848529815674\n",
      "Epoch 92 / 500 | iteration 10 / 30 | Total Loss: 1.072857141494751 | KNN Loss: 6.226966381072998 | BCE Loss: 1.072857141494751\n",
      "Epoch 92 / 500 | iteration 15 / 30 | Total Loss: 1.041245460510254 | KNN Loss: 6.226831436157227 | BCE Loss: 1.041245460510254\n",
      "Epoch 92 / 500 | iteration 20 / 30 | Total Loss: 1.045889973640442 | KNN Loss: 6.2269415855407715 | BCE Loss: 1.045889973640442\n",
      "Epoch 92 / 500 | iteration 25 / 30 | Total Loss: 1.0255799293518066 | KNN Loss: 6.226894378662109 | BCE Loss: 1.0255799293518066\n",
      "Epoch 93 / 500 | iteration 0 / 30 | Total Loss: 1.051750898361206 | KNN Loss: 6.226707458496094 | BCE Loss: 1.051750898361206\n",
      "Epoch 93 / 500 | iteration 5 / 30 | Total Loss: 1.0607998371124268 | KNN Loss: 6.227359294891357 | BCE Loss: 1.0607998371124268\n",
      "Epoch 93 / 500 | iteration 10 / 30 | Total Loss: 1.013940453529358 | KNN Loss: 6.226840972900391 | BCE Loss: 1.013940453529358\n",
      "Epoch 93 / 500 | iteration 15 / 30 | Total Loss: 1.032716155052185 | KNN Loss: 6.227008819580078 | BCE Loss: 1.032716155052185\n",
      "Epoch 93 / 500 | iteration 20 / 30 | Total Loss: 1.0388247966766357 | KNN Loss: 6.2267279624938965 | BCE Loss: 1.0388247966766357\n",
      "Epoch 93 / 500 | iteration 25 / 30 | Total Loss: 1.0572245121002197 | KNN Loss: 6.227001190185547 | BCE Loss: 1.0572245121002197\n",
      "Epoch 94 / 500 | iteration 0 / 30 | Total Loss: 1.0341554880142212 | KNN Loss: 6.227011203765869 | BCE Loss: 1.0341554880142212\n",
      "Epoch 94 / 500 | iteration 5 / 30 | Total Loss: 1.0787653923034668 | KNN Loss: 6.226980209350586 | BCE Loss: 1.0787653923034668\n",
      "Epoch 94 / 500 | iteration 10 / 30 | Total Loss: 1.065770149230957 | KNN Loss: 6.226902008056641 | BCE Loss: 1.065770149230957\n",
      "Epoch 94 / 500 | iteration 15 / 30 | Total Loss: 1.0431039333343506 | KNN Loss: 6.227136135101318 | BCE Loss: 1.0431039333343506\n",
      "Epoch 94 / 500 | iteration 20 / 30 | Total Loss: 1.0553770065307617 | KNN Loss: 6.22718620300293 | BCE Loss: 1.0553770065307617\n",
      "Epoch 94 / 500 | iteration 25 / 30 | Total Loss: 1.0357139110565186 | KNN Loss: 6.226978778839111 | BCE Loss: 1.0357139110565186\n",
      "Epoch    95: reducing learning rate of group 0 to 1.2005e-03.\n",
      "Epoch 95 / 500 | iteration 0 / 30 | Total Loss: 1.024277687072754 | KNN Loss: 6.226975917816162 | BCE Loss: 1.024277687072754\n",
      "Epoch 95 / 500 | iteration 5 / 30 | Total Loss: 1.040536880493164 | KNN Loss: 6.22686243057251 | BCE Loss: 1.040536880493164\n",
      "Epoch 95 / 500 | iteration 10 / 30 | Total Loss: 1.034515142440796 | KNN Loss: 6.226848602294922 | BCE Loss: 1.034515142440796\n",
      "Epoch 95 / 500 | iteration 15 / 30 | Total Loss: 1.033618688583374 | KNN Loss: 6.227107524871826 | BCE Loss: 1.033618688583374\n",
      "Epoch 95 / 500 | iteration 20 / 30 | Total Loss: 1.0673999786376953 | KNN Loss: 6.226950168609619 | BCE Loss: 1.0673999786376953\n",
      "Epoch 95 / 500 | iteration 25 / 30 | Total Loss: 1.052901268005371 | KNN Loss: 6.22678279876709 | BCE Loss: 1.052901268005371\n",
      "Epoch 96 / 500 | iteration 0 / 30 | Total Loss: 1.0629554986953735 | KNN Loss: 6.2269182205200195 | BCE Loss: 1.0629554986953735\n",
      "Epoch 96 / 500 | iteration 5 / 30 | Total Loss: 1.0565531253814697 | KNN Loss: 6.226738452911377 | BCE Loss: 1.0565531253814697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 / 500 | iteration 10 / 30 | Total Loss: 1.0603450536727905 | KNN Loss: 6.22675085067749 | BCE Loss: 1.0603450536727905\n",
      "Epoch 96 / 500 | iteration 15 / 30 | Total Loss: 1.050800085067749 | KNN Loss: 6.2269086837768555 | BCE Loss: 1.050800085067749\n",
      "Epoch 96 / 500 | iteration 20 / 30 | Total Loss: 1.0563969612121582 | KNN Loss: 6.226683139801025 | BCE Loss: 1.0563969612121582\n",
      "Epoch 96 / 500 | iteration 25 / 30 | Total Loss: 1.0643882751464844 | KNN Loss: 6.226886749267578 | BCE Loss: 1.0643882751464844\n",
      "Epoch 97 / 500 | iteration 0 / 30 | Total Loss: 1.0618863105773926 | KNN Loss: 6.226844310760498 | BCE Loss: 1.0618863105773926\n",
      "Epoch 97 / 500 | iteration 5 / 30 | Total Loss: 1.0626922845840454 | KNN Loss: 6.226853847503662 | BCE Loss: 1.0626922845840454\n",
      "Epoch 97 / 500 | iteration 10 / 30 | Total Loss: 1.0466418266296387 | KNN Loss: 6.22709321975708 | BCE Loss: 1.0466418266296387\n",
      "Epoch 97 / 500 | iteration 15 / 30 | Total Loss: 1.0199904441833496 | KNN Loss: 6.227088928222656 | BCE Loss: 1.0199904441833496\n",
      "Epoch 97 / 500 | iteration 20 / 30 | Total Loss: 1.0705056190490723 | KNN Loss: 6.2267351150512695 | BCE Loss: 1.0705056190490723\n",
      "Epoch 97 / 500 | iteration 25 / 30 | Total Loss: 1.0472736358642578 | KNN Loss: 6.22699499130249 | BCE Loss: 1.0472736358642578\n",
      "Epoch 98 / 500 | iteration 0 / 30 | Total Loss: 1.0383903980255127 | KNN Loss: 6.226896286010742 | BCE Loss: 1.0383903980255127\n",
      "Epoch 98 / 500 | iteration 5 / 30 | Total Loss: 1.0554969310760498 | KNN Loss: 6.227254390716553 | BCE Loss: 1.0554969310760498\n",
      "Epoch 98 / 500 | iteration 10 / 30 | Total Loss: 1.0320074558258057 | KNN Loss: 6.227023124694824 | BCE Loss: 1.0320074558258057\n",
      "Epoch 98 / 500 | iteration 15 / 30 | Total Loss: 1.0196964740753174 | KNN Loss: 6.2270283699035645 | BCE Loss: 1.0196964740753174\n",
      "Epoch 98 / 500 | iteration 20 / 30 | Total Loss: 1.0432873964309692 | KNN Loss: 6.226903915405273 | BCE Loss: 1.0432873964309692\n",
      "Epoch 98 / 500 | iteration 25 / 30 | Total Loss: 1.0795961618423462 | KNN Loss: 6.227094650268555 | BCE Loss: 1.0795961618423462\n",
      "Epoch 99 / 500 | iteration 0 / 30 | Total Loss: 1.0286357402801514 | KNN Loss: 6.227017879486084 | BCE Loss: 1.0286357402801514\n",
      "Epoch 99 / 500 | iteration 5 / 30 | Total Loss: 1.0388410091400146 | KNN Loss: 6.226678371429443 | BCE Loss: 1.0388410091400146\n",
      "Epoch 99 / 500 | iteration 10 / 30 | Total Loss: 1.0452587604522705 | KNN Loss: 6.226916790008545 | BCE Loss: 1.0452587604522705\n",
      "Epoch 99 / 500 | iteration 15 / 30 | Total Loss: 1.053857445716858 | KNN Loss: 6.227081298828125 | BCE Loss: 1.053857445716858\n",
      "Epoch 99 / 500 | iteration 20 / 30 | Total Loss: 1.0465538501739502 | KNN Loss: 6.226917266845703 | BCE Loss: 1.0465538501739502\n",
      "Epoch 99 / 500 | iteration 25 / 30 | Total Loss: 1.0796523094177246 | KNN Loss: 6.227026462554932 | BCE Loss: 1.0796523094177246\n",
      "Epoch 100 / 500 | iteration 0 / 30 | Total Loss: 1.0364478826522827 | KNN Loss: 6.227151393890381 | BCE Loss: 1.0364478826522827\n",
      "Epoch 100 / 500 | iteration 5 / 30 | Total Loss: 1.0424926280975342 | KNN Loss: 6.227216720581055 | BCE Loss: 1.0424926280975342\n",
      "Epoch 100 / 500 | iteration 10 / 30 | Total Loss: 1.0586342811584473 | KNN Loss: 6.227035999298096 | BCE Loss: 1.0586342811584473\n",
      "Epoch 100 / 500 | iteration 15 / 30 | Total Loss: 1.0374796390533447 | KNN Loss: 6.2269062995910645 | BCE Loss: 1.0374796390533447\n",
      "Epoch 100 / 500 | iteration 20 / 30 | Total Loss: 1.0420033931732178 | KNN Loss: 6.2269062995910645 | BCE Loss: 1.0420033931732178\n",
      "Epoch 100 / 500 | iteration 25 / 30 | Total Loss: 1.057361125946045 | KNN Loss: 6.226703643798828 | BCE Loss: 1.057361125946045\n",
      "Epoch 101 / 500 | iteration 0 / 30 | Total Loss: 1.04117751121521 | KNN Loss: 6.226989269256592 | BCE Loss: 1.04117751121521\n",
      "Epoch 101 / 500 | iteration 5 / 30 | Total Loss: 1.047526240348816 | KNN Loss: 6.226644992828369 | BCE Loss: 1.047526240348816\n",
      "Epoch 101 / 500 | iteration 10 / 30 | Total Loss: 1.0649569034576416 | KNN Loss: 6.227038383483887 | BCE Loss: 1.0649569034576416\n",
      "Epoch 101 / 500 | iteration 15 / 30 | Total Loss: 1.0664112567901611 | KNN Loss: 6.226914882659912 | BCE Loss: 1.0664112567901611\n",
      "Epoch 101 / 500 | iteration 20 / 30 | Total Loss: 1.0665555000305176 | KNN Loss: 6.227106094360352 | BCE Loss: 1.0665555000305176\n",
      "Epoch 101 / 500 | iteration 25 / 30 | Total Loss: 1.0371780395507812 | KNN Loss: 6.2268385887146 | BCE Loss: 1.0371780395507812\n",
      "Epoch 102 / 500 | iteration 0 / 30 | Total Loss: 1.0609896183013916 | KNN Loss: 6.227023601531982 | BCE Loss: 1.0609896183013916\n",
      "Epoch 102 / 500 | iteration 5 / 30 | Total Loss: 1.037419319152832 | KNN Loss: 6.226999759674072 | BCE Loss: 1.037419319152832\n",
      "Epoch 102 / 500 | iteration 10 / 30 | Total Loss: 1.0417535305023193 | KNN Loss: 6.227133750915527 | BCE Loss: 1.0417535305023193\n",
      "Epoch 102 / 500 | iteration 15 / 30 | Total Loss: 1.037294626235962 | KNN Loss: 6.226943492889404 | BCE Loss: 1.037294626235962\n",
      "Epoch 102 / 500 | iteration 20 / 30 | Total Loss: 1.0525590181350708 | KNN Loss: 6.227020740509033 | BCE Loss: 1.0525590181350708\n",
      "Epoch 102 / 500 | iteration 25 / 30 | Total Loss: 1.05997896194458 | KNN Loss: 6.226830005645752 | BCE Loss: 1.05997896194458\n",
      "Epoch 103 / 500 | iteration 0 / 30 | Total Loss: 1.0432708263397217 | KNN Loss: 6.227027893066406 | BCE Loss: 1.0432708263397217\n",
      "Epoch 103 / 500 | iteration 5 / 30 | Total Loss: 1.035839319229126 | KNN Loss: 6.226803302764893 | BCE Loss: 1.035839319229126\n",
      "Epoch 103 / 500 | iteration 10 / 30 | Total Loss: 1.075766682624817 | KNN Loss: 6.2268877029418945 | BCE Loss: 1.075766682624817\n",
      "Epoch 103 / 500 | iteration 15 / 30 | Total Loss: 1.0757060050964355 | KNN Loss: 6.226654052734375 | BCE Loss: 1.0757060050964355\n",
      "Epoch 103 / 500 | iteration 20 / 30 | Total Loss: 1.0603145360946655 | KNN Loss: 6.226783275604248 | BCE Loss: 1.0603145360946655\n",
      "Epoch 103 / 500 | iteration 25 / 30 | Total Loss: 1.0363709926605225 | KNN Loss: 6.226673126220703 | BCE Loss: 1.0363709926605225\n",
      "Epoch 104 / 500 | iteration 0 / 30 | Total Loss: 1.0740196704864502 | KNN Loss: 6.2269287109375 | BCE Loss: 1.0740196704864502\n",
      "Epoch 104 / 500 | iteration 5 / 30 | Total Loss: 1.0408024787902832 | KNN Loss: 6.227025508880615 | BCE Loss: 1.0408024787902832\n",
      "Epoch 104 / 500 | iteration 10 / 30 | Total Loss: 1.0544596910476685 | KNN Loss: 6.22691011428833 | BCE Loss: 1.0544596910476685\n",
      "Epoch 104 / 500 | iteration 15 / 30 | Total Loss: 1.0834379196166992 | KNN Loss: 6.226974964141846 | BCE Loss: 1.0834379196166992\n",
      "Epoch 104 / 500 | iteration 20 / 30 | Total Loss: 1.063685417175293 | KNN Loss: 6.2267165184021 | BCE Loss: 1.063685417175293\n",
      "Epoch 104 / 500 | iteration 25 / 30 | Total Loss: 1.064488172531128 | KNN Loss: 6.226755619049072 | BCE Loss: 1.064488172531128\n",
      "Epoch 105 / 500 | iteration 0 / 30 | Total Loss: 1.0269346237182617 | KNN Loss: 6.227097034454346 | BCE Loss: 1.0269346237182617\n",
      "Epoch 105 / 500 | iteration 5 / 30 | Total Loss: 1.071542739868164 | KNN Loss: 6.2270188331604 | BCE Loss: 1.071542739868164\n",
      "Epoch 105 / 500 | iteration 10 / 30 | Total Loss: 1.0608463287353516 | KNN Loss: 6.226842880249023 | BCE Loss: 1.0608463287353516\n",
      "Epoch 105 / 500 | iteration 15 / 30 | Total Loss: 1.030583143234253 | KNN Loss: 6.22666597366333 | BCE Loss: 1.030583143234253\n",
      "Epoch 105 / 500 | iteration 20 / 30 | Total Loss: 1.0490400791168213 | KNN Loss: 6.227077007293701 | BCE Loss: 1.0490400791168213\n",
      "Epoch 105 / 500 | iteration 25 / 30 | Total Loss: 1.0438222885131836 | KNN Loss: 6.2271504402160645 | BCE Loss: 1.0438222885131836\n",
      "Epoch   106: reducing learning rate of group 0 to 8.4035e-04.\n",
      "Epoch 106 / 500 | iteration 0 / 30 | Total Loss: 1.0328211784362793 | KNN Loss: 6.226831912994385 | BCE Loss: 1.0328211784362793\n",
      "Epoch 106 / 500 | iteration 5 / 30 | Total Loss: 1.059926986694336 | KNN Loss: 6.226759910583496 | BCE Loss: 1.059926986694336\n",
      "Epoch 106 / 500 | iteration 10 / 30 | Total Loss: 1.0603055953979492 | KNN Loss: 6.226843357086182 | BCE Loss: 1.0603055953979492\n",
      "Epoch 106 / 500 | iteration 15 / 30 | Total Loss: 1.062208652496338 | KNN Loss: 6.2268171310424805 | BCE Loss: 1.062208652496338\n",
      "Epoch 106 / 500 | iteration 20 / 30 | Total Loss: 1.0473296642303467 | KNN Loss: 6.227181434631348 | BCE Loss: 1.0473296642303467\n",
      "Epoch 106 / 500 | iteration 25 / 30 | Total Loss: 1.0348016023635864 | KNN Loss: 6.226706504821777 | BCE Loss: 1.0348016023635864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 / 500 | iteration 0 / 30 | Total Loss: 1.045440912246704 | KNN Loss: 6.226930618286133 | BCE Loss: 1.045440912246704\n",
      "Epoch 107 / 500 | iteration 5 / 30 | Total Loss: 1.036458969116211 | KNN Loss: 6.226829528808594 | BCE Loss: 1.036458969116211\n",
      "Epoch 107 / 500 | iteration 10 / 30 | Total Loss: 1.0731292963027954 | KNN Loss: 6.226868152618408 | BCE Loss: 1.0731292963027954\n",
      "Epoch 107 / 500 | iteration 15 / 30 | Total Loss: 1.0812146663665771 | KNN Loss: 6.2269978523254395 | BCE Loss: 1.0812146663665771\n",
      "Epoch 107 / 500 | iteration 20 / 30 | Total Loss: 1.0514521598815918 | KNN Loss: 6.227014064788818 | BCE Loss: 1.0514521598815918\n",
      "Epoch 107 / 500 | iteration 25 / 30 | Total Loss: 1.0046002864837646 | KNN Loss: 6.226696014404297 | BCE Loss: 1.0046002864837646\n",
      "Epoch 108 / 500 | iteration 0 / 30 | Total Loss: 1.0442957878112793 | KNN Loss: 6.227020263671875 | BCE Loss: 1.0442957878112793\n",
      "Epoch 108 / 500 | iteration 5 / 30 | Total Loss: 1.0481359958648682 | KNN Loss: 6.226738929748535 | BCE Loss: 1.0481359958648682\n",
      "Epoch 108 / 500 | iteration 10 / 30 | Total Loss: 1.047960638999939 | KNN Loss: 6.226644039154053 | BCE Loss: 1.047960638999939\n",
      "Epoch 108 / 500 | iteration 15 / 30 | Total Loss: 1.064906120300293 | KNN Loss: 6.226816177368164 | BCE Loss: 1.064906120300293\n",
      "Epoch 108 / 500 | iteration 20 / 30 | Total Loss: 1.0542917251586914 | KNN Loss: 6.226568698883057 | BCE Loss: 1.0542917251586914\n",
      "Epoch 108 / 500 | iteration 25 / 30 | Total Loss: 1.0505582094192505 | KNN Loss: 6.22664737701416 | BCE Loss: 1.0505582094192505\n",
      "Epoch 109 / 500 | iteration 0 / 30 | Total Loss: 1.0503044128417969 | KNN Loss: 6.22667932510376 | BCE Loss: 1.0503044128417969\n",
      "Epoch 109 / 500 | iteration 5 / 30 | Total Loss: 1.0419790744781494 | KNN Loss: 6.226917266845703 | BCE Loss: 1.0419790744781494\n",
      "Epoch 109 / 500 | iteration 10 / 30 | Total Loss: 1.0436302423477173 | KNN Loss: 6.226737976074219 | BCE Loss: 1.0436302423477173\n",
      "Epoch 109 / 500 | iteration 15 / 30 | Total Loss: 1.0667215585708618 | KNN Loss: 6.227274417877197 | BCE Loss: 1.0667215585708618\n",
      "Epoch 109 / 500 | iteration 20 / 30 | Total Loss: 1.0623881816864014 | KNN Loss: 6.227020740509033 | BCE Loss: 1.0623881816864014\n",
      "Epoch 109 / 500 | iteration 25 / 30 | Total Loss: 1.0503218173980713 | KNN Loss: 6.227020263671875 | BCE Loss: 1.0503218173980713\n",
      "Epoch 110 / 500 | iteration 0 / 30 | Total Loss: 1.0559732913970947 | KNN Loss: 6.226901531219482 | BCE Loss: 1.0559732913970947\n",
      "Epoch 110 / 500 | iteration 5 / 30 | Total Loss: 1.0564157962799072 | KNN Loss: 6.227161884307861 | BCE Loss: 1.0564157962799072\n",
      "Epoch 110 / 500 | iteration 10 / 30 | Total Loss: 1.0352106094360352 | KNN Loss: 6.227202892303467 | BCE Loss: 1.0352106094360352\n",
      "Epoch 110 / 500 | iteration 15 / 30 | Total Loss: 1.0711485147476196 | KNN Loss: 6.226887226104736 | BCE Loss: 1.0711485147476196\n",
      "Epoch 110 / 500 | iteration 20 / 30 | Total Loss: 1.0265281200408936 | KNN Loss: 6.227108478546143 | BCE Loss: 1.0265281200408936\n",
      "Epoch 110 / 500 | iteration 25 / 30 | Total Loss: 1.0558688640594482 | KNN Loss: 6.226670742034912 | BCE Loss: 1.0558688640594482\n",
      "Epoch 111 / 500 | iteration 0 / 30 | Total Loss: 1.0153753757476807 | KNN Loss: 6.226903438568115 | BCE Loss: 1.0153753757476807\n",
      "Epoch 111 / 500 | iteration 5 / 30 | Total Loss: 1.050356388092041 | KNN Loss: 6.226691722869873 | BCE Loss: 1.050356388092041\n",
      "Epoch 111 / 500 | iteration 10 / 30 | Total Loss: 1.0444155931472778 | KNN Loss: 6.226717472076416 | BCE Loss: 1.0444155931472778\n",
      "Epoch 111 / 500 | iteration 15 / 30 | Total Loss: 1.0491998195648193 | KNN Loss: 6.2270121574401855 | BCE Loss: 1.0491998195648193\n",
      "Epoch 111 / 500 | iteration 20 / 30 | Total Loss: 1.06489896774292 | KNN Loss: 6.226995944976807 | BCE Loss: 1.06489896774292\n",
      "Epoch 111 / 500 | iteration 25 / 30 | Total Loss: 1.0761263370513916 | KNN Loss: 6.227202415466309 | BCE Loss: 1.0761263370513916\n",
      "Epoch 112 / 500 | iteration 0 / 30 | Total Loss: 1.0381951332092285 | KNN Loss: 6.226699352264404 | BCE Loss: 1.0381951332092285\n",
      "Epoch 112 / 500 | iteration 5 / 30 | Total Loss: 1.0602295398712158 | KNN Loss: 6.226701736450195 | BCE Loss: 1.0602295398712158\n",
      "Epoch 112 / 500 | iteration 10 / 30 | Total Loss: 1.059554100036621 | KNN Loss: 6.227013111114502 | BCE Loss: 1.059554100036621\n",
      "Epoch 112 / 500 | iteration 15 / 30 | Total Loss: 1.038122296333313 | KNN Loss: 6.226999759674072 | BCE Loss: 1.038122296333313\n",
      "Epoch 112 / 500 | iteration 20 / 30 | Total Loss: 1.0204517841339111 | KNN Loss: 6.226707935333252 | BCE Loss: 1.0204517841339111\n",
      "Epoch 112 / 500 | iteration 25 / 30 | Total Loss: 1.0577188730239868 | KNN Loss: 6.226873397827148 | BCE Loss: 1.0577188730239868\n",
      "Epoch 113 / 500 | iteration 0 / 30 | Total Loss: 1.0293796062469482 | KNN Loss: 6.226903438568115 | BCE Loss: 1.0293796062469482\n",
      "Epoch 113 / 500 | iteration 5 / 30 | Total Loss: 1.0477566719055176 | KNN Loss: 6.227114200592041 | BCE Loss: 1.0477566719055176\n",
      "Epoch 113 / 500 | iteration 10 / 30 | Total Loss: 1.0430662631988525 | KNN Loss: 6.227108478546143 | BCE Loss: 1.0430662631988525\n",
      "Epoch 113 / 500 | iteration 15 / 30 | Total Loss: 1.0641446113586426 | KNN Loss: 6.226652145385742 | BCE Loss: 1.0641446113586426\n",
      "Epoch 113 / 500 | iteration 20 / 30 | Total Loss: 1.0516560077667236 | KNN Loss: 6.227115631103516 | BCE Loss: 1.0516560077667236\n",
      "Epoch 113 / 500 | iteration 25 / 30 | Total Loss: 1.0640153884887695 | KNN Loss: 6.226797103881836 | BCE Loss: 1.0640153884887695\n",
      "Epoch 114 / 500 | iteration 0 / 30 | Total Loss: 1.0335257053375244 | KNN Loss: 6.226917743682861 | BCE Loss: 1.0335257053375244\n",
      "Epoch 114 / 500 | iteration 5 / 30 | Total Loss: 1.0366324186325073 | KNN Loss: 6.226891994476318 | BCE Loss: 1.0366324186325073\n",
      "Epoch 114 / 500 | iteration 10 / 30 | Total Loss: 1.0342988967895508 | KNN Loss: 6.227241516113281 | BCE Loss: 1.0342988967895508\n",
      "Epoch 114 / 500 | iteration 15 / 30 | Total Loss: 1.0396068096160889 | KNN Loss: 6.227163314819336 | BCE Loss: 1.0396068096160889\n",
      "Epoch 114 / 500 | iteration 20 / 30 | Total Loss: 1.045518159866333 | KNN Loss: 6.226714611053467 | BCE Loss: 1.045518159866333\n",
      "Epoch 114 / 500 | iteration 25 / 30 | Total Loss: 1.0479166507720947 | KNN Loss: 6.226913928985596 | BCE Loss: 1.0479166507720947\n",
      "Epoch 115 / 500 | iteration 0 / 30 | Total Loss: 1.0397298336029053 | KNN Loss: 6.227008819580078 | BCE Loss: 1.0397298336029053\n",
      "Epoch 115 / 500 | iteration 5 / 30 | Total Loss: 1.065040111541748 | KNN Loss: 6.22685432434082 | BCE Loss: 1.065040111541748\n",
      "Epoch 115 / 500 | iteration 10 / 30 | Total Loss: 1.0285354852676392 | KNN Loss: 6.226927757263184 | BCE Loss: 1.0285354852676392\n",
      "Epoch 115 / 500 | iteration 15 / 30 | Total Loss: 1.043890357017517 | KNN Loss: 6.226846694946289 | BCE Loss: 1.043890357017517\n",
      "Epoch 115 / 500 | iteration 20 / 30 | Total Loss: 1.0382146835327148 | KNN Loss: 6.2266669273376465 | BCE Loss: 1.0382146835327148\n",
      "Epoch 115 / 500 | iteration 25 / 30 | Total Loss: 1.0359952449798584 | KNN Loss: 6.227099895477295 | BCE Loss: 1.0359952449798584\n",
      "Epoch 116 / 500 | iteration 0 / 30 | Total Loss: 1.0720669031143188 | KNN Loss: 6.227081775665283 | BCE Loss: 1.0720669031143188\n",
      "Epoch 116 / 500 | iteration 5 / 30 | Total Loss: 1.0394929647445679 | KNN Loss: 6.227264404296875 | BCE Loss: 1.0394929647445679\n",
      "Epoch 116 / 500 | iteration 10 / 30 | Total Loss: 1.07126784324646 | KNN Loss: 6.227122783660889 | BCE Loss: 1.07126784324646\n",
      "Epoch 116 / 500 | iteration 15 / 30 | Total Loss: 1.04640793800354 | KNN Loss: 6.227035045623779 | BCE Loss: 1.04640793800354\n",
      "Epoch 116 / 500 | iteration 20 / 30 | Total Loss: 1.0306496620178223 | KNN Loss: 6.2268242835998535 | BCE Loss: 1.0306496620178223\n",
      "Epoch 116 / 500 | iteration 25 / 30 | Total Loss: 1.0528757572174072 | KNN Loss: 6.226787090301514 | BCE Loss: 1.0528757572174072\n",
      "Epoch   117: reducing learning rate of group 0 to 5.8824e-04.\n",
      "Epoch 117 / 500 | iteration 0 / 30 | Total Loss: 1.0532909631729126 | KNN Loss: 6.226605415344238 | BCE Loss: 1.0532909631729126\n",
      "Epoch 117 / 500 | iteration 5 / 30 | Total Loss: 1.05364191532135 | KNN Loss: 6.226849555969238 | BCE Loss: 1.05364191532135\n",
      "Epoch 117 / 500 | iteration 10 / 30 | Total Loss: 1.0684651136398315 | KNN Loss: 6.226941108703613 | BCE Loss: 1.0684651136398315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 / 500 | iteration 15 / 30 | Total Loss: 1.044250249862671 | KNN Loss: 6.226868629455566 | BCE Loss: 1.044250249862671\n",
      "Epoch 117 / 500 | iteration 20 / 30 | Total Loss: 1.0394551753997803 | KNN Loss: 6.227016448974609 | BCE Loss: 1.0394551753997803\n",
      "Epoch 117 / 500 | iteration 25 / 30 | Total Loss: 1.0605182647705078 | KNN Loss: 6.2265448570251465 | BCE Loss: 1.0605182647705078\n",
      "Epoch 118 / 500 | iteration 0 / 30 | Total Loss: 1.0465468168258667 | KNN Loss: 6.226943016052246 | BCE Loss: 1.0465468168258667\n",
      "Epoch 118 / 500 | iteration 5 / 30 | Total Loss: 1.057612657546997 | KNN Loss: 6.226848125457764 | BCE Loss: 1.057612657546997\n",
      "Epoch 118 / 500 | iteration 10 / 30 | Total Loss: 1.040324091911316 | KNN Loss: 6.226984977722168 | BCE Loss: 1.040324091911316\n",
      "Epoch 118 / 500 | iteration 15 / 30 | Total Loss: 1.057418704032898 | KNN Loss: 6.226921558380127 | BCE Loss: 1.057418704032898\n",
      "Epoch 118 / 500 | iteration 20 / 30 | Total Loss: 1.0508637428283691 | KNN Loss: 6.227057456970215 | BCE Loss: 1.0508637428283691\n",
      "Epoch 118 / 500 | iteration 25 / 30 | Total Loss: 1.0900242328643799 | KNN Loss: 6.22701358795166 | BCE Loss: 1.0900242328643799\n",
      "Epoch 119 / 500 | iteration 0 / 30 | Total Loss: 1.034307837486267 | KNN Loss: 6.226944923400879 | BCE Loss: 1.034307837486267\n",
      "Epoch 119 / 500 | iteration 5 / 30 | Total Loss: 1.0238115787506104 | KNN Loss: 6.226569652557373 | BCE Loss: 1.0238115787506104\n",
      "Epoch 119 / 500 | iteration 10 / 30 | Total Loss: 1.042943000793457 | KNN Loss: 6.2269768714904785 | BCE Loss: 1.042943000793457\n",
      "Epoch 119 / 500 | iteration 15 / 30 | Total Loss: 1.03831148147583 | KNN Loss: 6.226759910583496 | BCE Loss: 1.03831148147583\n",
      "Epoch 119 / 500 | iteration 20 / 30 | Total Loss: 1.0683494806289673 | KNN Loss: 6.226734161376953 | BCE Loss: 1.0683494806289673\n",
      "Epoch 119 / 500 | iteration 25 / 30 | Total Loss: 1.0378928184509277 | KNN Loss: 6.22664737701416 | BCE Loss: 1.0378928184509277\n",
      "Epoch 120 / 500 | iteration 0 / 30 | Total Loss: 1.0562622547149658 | KNN Loss: 6.2267680168151855 | BCE Loss: 1.0562622547149658\n",
      "Epoch 120 / 500 | iteration 5 / 30 | Total Loss: 1.045995831489563 | KNN Loss: 6.226855278015137 | BCE Loss: 1.045995831489563\n",
      "Epoch 120 / 500 | iteration 10 / 30 | Total Loss: 1.0462678670883179 | KNN Loss: 6.226525783538818 | BCE Loss: 1.0462678670883179\n",
      "Epoch 120 / 500 | iteration 15 / 30 | Total Loss: 1.048492670059204 | KNN Loss: 6.226717948913574 | BCE Loss: 1.048492670059204\n",
      "Epoch 120 / 500 | iteration 20 / 30 | Total Loss: 1.076761245727539 | KNN Loss: 6.226999759674072 | BCE Loss: 1.076761245727539\n",
      "Epoch 120 / 500 | iteration 25 / 30 | Total Loss: 1.042612075805664 | KNN Loss: 6.226634979248047 | BCE Loss: 1.042612075805664\n",
      "Epoch 121 / 500 | iteration 0 / 30 | Total Loss: 1.0558116436004639 | KNN Loss: 6.226907253265381 | BCE Loss: 1.0558116436004639\n",
      "Epoch 121 / 500 | iteration 5 / 30 | Total Loss: 1.0650701522827148 | KNN Loss: 6.227141857147217 | BCE Loss: 1.0650701522827148\n",
      "Epoch 121 / 500 | iteration 10 / 30 | Total Loss: 1.0089517831802368 | KNN Loss: 6.22698974609375 | BCE Loss: 1.0089517831802368\n",
      "Epoch 121 / 500 | iteration 15 / 30 | Total Loss: 1.0560107231140137 | KNN Loss: 6.226958751678467 | BCE Loss: 1.0560107231140137\n",
      "Epoch 121 / 500 | iteration 20 / 30 | Total Loss: 1.0592055320739746 | KNN Loss: 6.226861000061035 | BCE Loss: 1.0592055320739746\n",
      "Epoch 121 / 500 | iteration 25 / 30 | Total Loss: 1.0362722873687744 | KNN Loss: 6.226773262023926 | BCE Loss: 1.0362722873687744\n",
      "Epoch 122 / 500 | iteration 0 / 30 | Total Loss: 1.0174601078033447 | KNN Loss: 6.226668834686279 | BCE Loss: 1.0174601078033447\n",
      "Epoch 122 / 500 | iteration 5 / 30 | Total Loss: 1.034255862236023 | KNN Loss: 6.226829528808594 | BCE Loss: 1.034255862236023\n",
      "Epoch 122 / 500 | iteration 10 / 30 | Total Loss: 1.0617587566375732 | KNN Loss: 6.227090358734131 | BCE Loss: 1.0617587566375732\n",
      "Epoch 122 / 500 | iteration 15 / 30 | Total Loss: 1.0457615852355957 | KNN Loss: 6.226979732513428 | BCE Loss: 1.0457615852355957\n",
      "Epoch 122 / 500 | iteration 20 / 30 | Total Loss: 1.0307668447494507 | KNN Loss: 6.22685432434082 | BCE Loss: 1.0307668447494507\n",
      "Epoch 122 / 500 | iteration 25 / 30 | Total Loss: 1.0350394248962402 | KNN Loss: 6.2266387939453125 | BCE Loss: 1.0350394248962402\n",
      "Epoch 123 / 500 | iteration 0 / 30 | Total Loss: 1.062180757522583 | KNN Loss: 6.226993083953857 | BCE Loss: 1.062180757522583\n",
      "Epoch 123 / 500 | iteration 5 / 30 | Total Loss: 1.0644373893737793 | KNN Loss: 6.226888656616211 | BCE Loss: 1.0644373893737793\n",
      "Epoch 123 / 500 | iteration 10 / 30 | Total Loss: 1.0672876834869385 | KNN Loss: 6.226722717285156 | BCE Loss: 1.0672876834869385\n",
      "Epoch 123 / 500 | iteration 15 / 30 | Total Loss: 1.0512522459030151 | KNN Loss: 6.2266645431518555 | BCE Loss: 1.0512522459030151\n",
      "Epoch 123 / 500 | iteration 20 / 30 | Total Loss: 1.042051076889038 | KNN Loss: 6.2271318435668945 | BCE Loss: 1.042051076889038\n",
      "Epoch 123 / 500 | iteration 25 / 30 | Total Loss: 1.055063009262085 | KNN Loss: 6.227290153503418 | BCE Loss: 1.055063009262085\n",
      "Epoch 124 / 500 | iteration 0 / 30 | Total Loss: 1.0653976202011108 | KNN Loss: 6.2267045974731445 | BCE Loss: 1.0653976202011108\n",
      "Epoch 124 / 500 | iteration 5 / 30 | Total Loss: 1.0349165201187134 | KNN Loss: 6.226775169372559 | BCE Loss: 1.0349165201187134\n",
      "Epoch 124 / 500 | iteration 10 / 30 | Total Loss: 1.0940656661987305 | KNN Loss: 6.226836204528809 | BCE Loss: 1.0940656661987305\n",
      "Epoch 124 / 500 | iteration 15 / 30 | Total Loss: 1.0285148620605469 | KNN Loss: 6.226932048797607 | BCE Loss: 1.0285148620605469\n",
      "Epoch 124 / 500 | iteration 20 / 30 | Total Loss: 1.0505374670028687 | KNN Loss: 6.226896286010742 | BCE Loss: 1.0505374670028687\n",
      "Epoch 124 / 500 | iteration 25 / 30 | Total Loss: 1.0591639280319214 | KNN Loss: 6.22689962387085 | BCE Loss: 1.0591639280319214\n",
      "Epoch 125 / 500 | iteration 0 / 30 | Total Loss: 1.080101490020752 | KNN Loss: 6.2267279624938965 | BCE Loss: 1.080101490020752\n",
      "Epoch 125 / 500 | iteration 5 / 30 | Total Loss: 1.0394107103347778 | KNN Loss: 6.227142333984375 | BCE Loss: 1.0394107103347778\n",
      "Epoch 125 / 500 | iteration 10 / 30 | Total Loss: 1.0472966432571411 | KNN Loss: 6.227002143859863 | BCE Loss: 1.0472966432571411\n",
      "Epoch 125 / 500 | iteration 15 / 30 | Total Loss: 1.0533000230789185 | KNN Loss: 6.226684093475342 | BCE Loss: 1.0533000230789185\n",
      "Epoch 125 / 500 | iteration 20 / 30 | Total Loss: 1.0113003253936768 | KNN Loss: 6.226997375488281 | BCE Loss: 1.0113003253936768\n",
      "Epoch 125 / 500 | iteration 25 / 30 | Total Loss: 1.0632643699645996 | KNN Loss: 6.226902008056641 | BCE Loss: 1.0632643699645996\n",
      "Epoch 126 / 500 | iteration 0 / 30 | Total Loss: 1.0460331439971924 | KNN Loss: 6.227035999298096 | BCE Loss: 1.0460331439971924\n",
      "Epoch 126 / 500 | iteration 5 / 30 | Total Loss: 1.040895938873291 | KNN Loss: 6.227014064788818 | BCE Loss: 1.040895938873291\n",
      "Epoch 126 / 500 | iteration 10 / 30 | Total Loss: 1.0371384620666504 | KNN Loss: 6.226378917694092 | BCE Loss: 1.0371384620666504\n",
      "Epoch 126 / 500 | iteration 15 / 30 | Total Loss: 1.0582315921783447 | KNN Loss: 6.226924896240234 | BCE Loss: 1.0582315921783447\n",
      "Epoch 126 / 500 | iteration 20 / 30 | Total Loss: 1.0389363765716553 | KNN Loss: 6.226943016052246 | BCE Loss: 1.0389363765716553\n",
      "Epoch 126 / 500 | iteration 25 / 30 | Total Loss: 1.0467263460159302 | KNN Loss: 6.2269182205200195 | BCE Loss: 1.0467263460159302\n",
      "Epoch 127 / 500 | iteration 0 / 30 | Total Loss: 1.0497870445251465 | KNN Loss: 6.227005958557129 | BCE Loss: 1.0497870445251465\n",
      "Epoch 127 / 500 | iteration 5 / 30 | Total Loss: 1.0706506967544556 | KNN Loss: 6.22698450088501 | BCE Loss: 1.0706506967544556\n",
      "Epoch 127 / 500 | iteration 10 / 30 | Total Loss: 1.0699284076690674 | KNN Loss: 6.226665019989014 | BCE Loss: 1.0699284076690674\n",
      "Epoch 127 / 500 | iteration 15 / 30 | Total Loss: 1.0535167455673218 | KNN Loss: 6.227122783660889 | BCE Loss: 1.0535167455673218\n",
      "Epoch 127 / 500 | iteration 20 / 30 | Total Loss: 1.0042896270751953 | KNN Loss: 6.226651668548584 | BCE Loss: 1.0042896270751953\n",
      "Epoch 127 / 500 | iteration 25 / 30 | Total Loss: 1.0483876466751099 | KNN Loss: 6.2267022132873535 | BCE Loss: 1.0483876466751099\n",
      "Epoch   128: reducing learning rate of group 0 to 4.1177e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 / 500 | iteration 0 / 30 | Total Loss: 1.042443037033081 | KNN Loss: 6.2268805503845215 | BCE Loss: 1.042443037033081\n",
      "Epoch 128 / 500 | iteration 5 / 30 | Total Loss: 1.0773723125457764 | KNN Loss: 6.226934432983398 | BCE Loss: 1.0773723125457764\n",
      "Epoch 128 / 500 | iteration 10 / 30 | Total Loss: 1.0399131774902344 | KNN Loss: 6.227065086364746 | BCE Loss: 1.0399131774902344\n",
      "Epoch 128 / 500 | iteration 15 / 30 | Total Loss: 1.060936450958252 | KNN Loss: 6.227071285247803 | BCE Loss: 1.060936450958252\n",
      "Epoch 128 / 500 | iteration 20 / 30 | Total Loss: 1.035548210144043 | KNN Loss: 6.226974010467529 | BCE Loss: 1.035548210144043\n",
      "Epoch 128 / 500 | iteration 25 / 30 | Total Loss: 1.0282609462738037 | KNN Loss: 6.227021217346191 | BCE Loss: 1.0282609462738037\n",
      "Epoch 129 / 500 | iteration 0 / 30 | Total Loss: 1.0470993518829346 | KNN Loss: 6.2268967628479 | BCE Loss: 1.0470993518829346\n",
      "Epoch 129 / 500 | iteration 5 / 30 | Total Loss: 1.0671563148498535 | KNN Loss: 6.226925849914551 | BCE Loss: 1.0671563148498535\n",
      "Epoch 129 / 500 | iteration 10 / 30 | Total Loss: 1.0730891227722168 | KNN Loss: 6.226921081542969 | BCE Loss: 1.0730891227722168\n",
      "Epoch 129 / 500 | iteration 15 / 30 | Total Loss: 1.0666699409484863 | KNN Loss: 6.226834774017334 | BCE Loss: 1.0666699409484863\n",
      "Epoch 129 / 500 | iteration 20 / 30 | Total Loss: 1.0475270748138428 | KNN Loss: 6.226763725280762 | BCE Loss: 1.0475270748138428\n",
      "Epoch 129 / 500 | iteration 25 / 30 | Total Loss: 1.0470399856567383 | KNN Loss: 6.2270965576171875 | BCE Loss: 1.0470399856567383\n",
      "Epoch 130 / 500 | iteration 0 / 30 | Total Loss: 1.046367883682251 | KNN Loss: 6.226593017578125 | BCE Loss: 1.046367883682251\n",
      "Epoch 130 / 500 | iteration 5 / 30 | Total Loss: 1.0891450643539429 | KNN Loss: 6.22677755355835 | BCE Loss: 1.0891450643539429\n",
      "Epoch 130 / 500 | iteration 10 / 30 | Total Loss: 1.0379917621612549 | KNN Loss: 6.226861000061035 | BCE Loss: 1.0379917621612549\n",
      "Epoch 130 / 500 | iteration 15 / 30 | Total Loss: 1.0547528266906738 | KNN Loss: 6.226844787597656 | BCE Loss: 1.0547528266906738\n",
      "Epoch 130 / 500 | iteration 20 / 30 | Total Loss: 1.0702964067459106 | KNN Loss: 6.2267279624938965 | BCE Loss: 1.0702964067459106\n",
      "Epoch 130 / 500 | iteration 25 / 30 | Total Loss: 1.0324175357818604 | KNN Loss: 6.226759433746338 | BCE Loss: 1.0324175357818604\n",
      "Epoch 131 / 500 | iteration 0 / 30 | Total Loss: 1.0503425598144531 | KNN Loss: 6.227030277252197 | BCE Loss: 1.0503425598144531\n",
      "Epoch 131 / 500 | iteration 5 / 30 | Total Loss: 1.0466187000274658 | KNN Loss: 6.227017402648926 | BCE Loss: 1.0466187000274658\n",
      "Epoch 131 / 500 | iteration 10 / 30 | Total Loss: 1.0439587831497192 | KNN Loss: 6.2265496253967285 | BCE Loss: 1.0439587831497192\n",
      "Epoch 131 / 500 | iteration 15 / 30 | Total Loss: 1.0834076404571533 | KNN Loss: 6.227104663848877 | BCE Loss: 1.0834076404571533\n",
      "Epoch 131 / 500 | iteration 20 / 30 | Total Loss: 1.038844347000122 | KNN Loss: 6.226534366607666 | BCE Loss: 1.038844347000122\n",
      "Epoch 131 / 500 | iteration 25 / 30 | Total Loss: 1.0596442222595215 | KNN Loss: 6.2264790534973145 | BCE Loss: 1.0596442222595215\n",
      "Epoch 132 / 500 | iteration 0 / 30 | Total Loss: 1.049423336982727 | KNN Loss: 6.226685523986816 | BCE Loss: 1.049423336982727\n",
      "Epoch 132 / 500 | iteration 5 / 30 | Total Loss: 1.0426069498062134 | KNN Loss: 6.2264723777771 | BCE Loss: 1.0426069498062134\n",
      "Epoch 132 / 500 | iteration 10 / 30 | Total Loss: 1.0616600513458252 | KNN Loss: 6.2267961502075195 | BCE Loss: 1.0616600513458252\n",
      "Epoch 132 / 500 | iteration 15 / 30 | Total Loss: 1.0804998874664307 | KNN Loss: 6.226970195770264 | BCE Loss: 1.0804998874664307\n",
      "Epoch 132 / 500 | iteration 20 / 30 | Total Loss: 1.0489380359649658 | KNN Loss: 6.226647853851318 | BCE Loss: 1.0489380359649658\n",
      "Epoch 132 / 500 | iteration 25 / 30 | Total Loss: 1.0406492948532104 | KNN Loss: 6.226674556732178 | BCE Loss: 1.0406492948532104\n",
      "Epoch 133 / 500 | iteration 0 / 30 | Total Loss: 1.0776803493499756 | KNN Loss: 6.227177143096924 | BCE Loss: 1.0776803493499756\n",
      "Epoch 133 / 500 | iteration 5 / 30 | Total Loss: 1.0317258834838867 | KNN Loss: 6.226877689361572 | BCE Loss: 1.0317258834838867\n",
      "Epoch 133 / 500 | iteration 10 / 30 | Total Loss: 0.9904652833938599 | KNN Loss: 6.226850509643555 | BCE Loss: 0.9904652833938599\n",
      "Epoch 133 / 500 | iteration 15 / 30 | Total Loss: 1.0467500686645508 | KNN Loss: 6.226796627044678 | BCE Loss: 1.0467500686645508\n",
      "Epoch 133 / 500 | iteration 20 / 30 | Total Loss: 1.0533784627914429 | KNN Loss: 6.2269368171691895 | BCE Loss: 1.0533784627914429\n",
      "Epoch 133 / 500 | iteration 25 / 30 | Total Loss: 1.044370174407959 | KNN Loss: 6.226708889007568 | BCE Loss: 1.044370174407959\n",
      "Epoch 134 / 500 | iteration 0 / 30 | Total Loss: 1.0488736629486084 | KNN Loss: 6.226807594299316 | BCE Loss: 1.0488736629486084\n",
      "Epoch 134 / 500 | iteration 5 / 30 | Total Loss: 1.0407809019088745 | KNN Loss: 6.227057456970215 | BCE Loss: 1.0407809019088745\n",
      "Epoch 134 / 500 | iteration 10 / 30 | Total Loss: 1.0727487802505493 | KNN Loss: 6.226840972900391 | BCE Loss: 1.0727487802505493\n",
      "Epoch 134 / 500 | iteration 15 / 30 | Total Loss: 1.082074761390686 | KNN Loss: 6.226933479309082 | BCE Loss: 1.082074761390686\n",
      "Epoch 134 / 500 | iteration 20 / 30 | Total Loss: 1.0788445472717285 | KNN Loss: 6.227133274078369 | BCE Loss: 1.0788445472717285\n",
      "Epoch 134 / 500 | iteration 25 / 30 | Total Loss: 1.0611772537231445 | KNN Loss: 6.226737976074219 | BCE Loss: 1.0611772537231445\n",
      "Epoch 135 / 500 | iteration 0 / 30 | Total Loss: 1.0344085693359375 | KNN Loss: 6.226980686187744 | BCE Loss: 1.0344085693359375\n",
      "Epoch 135 / 500 | iteration 5 / 30 | Total Loss: 1.0541319847106934 | KNN Loss: 6.227006435394287 | BCE Loss: 1.0541319847106934\n",
      "Epoch 135 / 500 | iteration 10 / 30 | Total Loss: 1.0350974798202515 | KNN Loss: 6.227015495300293 | BCE Loss: 1.0350974798202515\n",
      "Epoch 135 / 500 | iteration 15 / 30 | Total Loss: 1.035853624343872 | KNN Loss: 6.226756572723389 | BCE Loss: 1.035853624343872\n",
      "Epoch 135 / 500 | iteration 20 / 30 | Total Loss: 1.0481431484222412 | KNN Loss: 6.226860523223877 | BCE Loss: 1.0481431484222412\n",
      "Epoch 135 / 500 | iteration 25 / 30 | Total Loss: 1.0348087549209595 | KNN Loss: 6.226973533630371 | BCE Loss: 1.0348087549209595\n",
      "Epoch 136 / 500 | iteration 0 / 30 | Total Loss: 1.0356262922286987 | KNN Loss: 6.226832866668701 | BCE Loss: 1.0356262922286987\n",
      "Epoch 136 / 500 | iteration 5 / 30 | Total Loss: 1.0766905546188354 | KNN Loss: 6.226780891418457 | BCE Loss: 1.0766905546188354\n",
      "Epoch 136 / 500 | iteration 10 / 30 | Total Loss: 1.029021143913269 | KNN Loss: 6.226560592651367 | BCE Loss: 1.029021143913269\n",
      "Epoch 136 / 500 | iteration 15 / 30 | Total Loss: 1.014232873916626 | KNN Loss: 6.226816177368164 | BCE Loss: 1.014232873916626\n",
      "Epoch 136 / 500 | iteration 20 / 30 | Total Loss: 1.0599517822265625 | KNN Loss: 6.226713180541992 | BCE Loss: 1.0599517822265625\n",
      "Epoch 136 / 500 | iteration 25 / 30 | Total Loss: 1.0634890794754028 | KNN Loss: 6.227086544036865 | BCE Loss: 1.0634890794754028\n",
      "Epoch 137 / 500 | iteration 0 / 30 | Total Loss: 1.0701251029968262 | KNN Loss: 6.22671365737915 | BCE Loss: 1.0701251029968262\n",
      "Epoch 137 / 500 | iteration 5 / 30 | Total Loss: 1.0680480003356934 | KNN Loss: 6.226901531219482 | BCE Loss: 1.0680480003356934\n",
      "Epoch 137 / 500 | iteration 10 / 30 | Total Loss: 1.0401943922042847 | KNN Loss: 6.226937770843506 | BCE Loss: 1.0401943922042847\n",
      "Epoch 137 / 500 | iteration 15 / 30 | Total Loss: 1.0713813304901123 | KNN Loss: 6.2269606590271 | BCE Loss: 1.0713813304901123\n",
      "Epoch 137 / 500 | iteration 20 / 30 | Total Loss: 1.04177987575531 | KNN Loss: 6.22719669342041 | BCE Loss: 1.04177987575531\n",
      "Epoch 137 / 500 | iteration 25 / 30 | Total Loss: 1.0511541366577148 | KNN Loss: 6.226963043212891 | BCE Loss: 1.0511541366577148\n",
      "Epoch 138 / 500 | iteration 0 / 30 | Total Loss: 1.044938325881958 | KNN Loss: 6.227128505706787 | BCE Loss: 1.044938325881958\n",
      "Epoch 138 / 500 | iteration 5 / 30 | Total Loss: 1.0679808855056763 | KNN Loss: 6.2269062995910645 | BCE Loss: 1.0679808855056763\n",
      "Epoch 138 / 500 | iteration 10 / 30 | Total Loss: 1.0473822355270386 | KNN Loss: 6.226789951324463 | BCE Loss: 1.0473822355270386\n",
      "Epoch 138 / 500 | iteration 15 / 30 | Total Loss: 1.049269437789917 | KNN Loss: 6.226818561553955 | BCE Loss: 1.049269437789917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 / 500 | iteration 20 / 30 | Total Loss: 1.0495957136154175 | KNN Loss: 6.226792335510254 | BCE Loss: 1.0495957136154175\n",
      "Epoch 138 / 500 | iteration 25 / 30 | Total Loss: 1.0606262683868408 | KNN Loss: 6.227038860321045 | BCE Loss: 1.0606262683868408\n",
      "Epoch   139: reducing learning rate of group 0 to 2.8824e-04.\n",
      "Epoch 139 / 500 | iteration 0 / 30 | Total Loss: 1.0573172569274902 | KNN Loss: 6.227077960968018 | BCE Loss: 1.0573172569274902\n",
      "Epoch 139 / 500 | iteration 5 / 30 | Total Loss: 1.0607187747955322 | KNN Loss: 6.226583480834961 | BCE Loss: 1.0607187747955322\n",
      "Epoch 139 / 500 | iteration 10 / 30 | Total Loss: 1.0605781078338623 | KNN Loss: 6.227216720581055 | BCE Loss: 1.0605781078338623\n",
      "Epoch 139 / 500 | iteration 15 / 30 | Total Loss: 1.06512451171875 | KNN Loss: 6.226833343505859 | BCE Loss: 1.06512451171875\n",
      "Epoch 139 / 500 | iteration 20 / 30 | Total Loss: 1.0430717468261719 | KNN Loss: 6.2271270751953125 | BCE Loss: 1.0430717468261719\n",
      "Epoch 139 / 500 | iteration 25 / 30 | Total Loss: 1.0150339603424072 | KNN Loss: 6.226953029632568 | BCE Loss: 1.0150339603424072\n",
      "Epoch 140 / 500 | iteration 0 / 30 | Total Loss: 1.079836130142212 | KNN Loss: 6.226940155029297 | BCE Loss: 1.079836130142212\n",
      "Epoch 140 / 500 | iteration 5 / 30 | Total Loss: 1.0821433067321777 | KNN Loss: 6.22683048248291 | BCE Loss: 1.0821433067321777\n",
      "Epoch 140 / 500 | iteration 10 / 30 | Total Loss: 1.044646978378296 | KNN Loss: 6.22720193862915 | BCE Loss: 1.044646978378296\n",
      "Epoch 140 / 500 | iteration 15 / 30 | Total Loss: 1.0322378873825073 | KNN Loss: 6.226722240447998 | BCE Loss: 1.0322378873825073\n",
      "Epoch 140 / 500 | iteration 20 / 30 | Total Loss: 1.0363776683807373 | KNN Loss: 6.226782321929932 | BCE Loss: 1.0363776683807373\n",
      "Epoch 140 / 500 | iteration 25 / 30 | Total Loss: 1.0578277111053467 | KNN Loss: 6.227022647857666 | BCE Loss: 1.0578277111053467\n",
      "Epoch 141 / 500 | iteration 0 / 30 | Total Loss: 1.0217747688293457 | KNN Loss: 6.227016448974609 | BCE Loss: 1.0217747688293457\n",
      "Epoch 141 / 500 | iteration 5 / 30 | Total Loss: 1.0498909950256348 | KNN Loss: 6.226602554321289 | BCE Loss: 1.0498909950256348\n",
      "Epoch 141 / 500 | iteration 10 / 30 | Total Loss: 1.046628475189209 | KNN Loss: 6.226768493652344 | BCE Loss: 1.046628475189209\n",
      "Epoch 141 / 500 | iteration 15 / 30 | Total Loss: 1.0638351440429688 | KNN Loss: 6.226738452911377 | BCE Loss: 1.0638351440429688\n",
      "Epoch 141 / 500 | iteration 20 / 30 | Total Loss: 1.046414852142334 | KNN Loss: 6.227259635925293 | BCE Loss: 1.046414852142334\n",
      "Epoch 141 / 500 | iteration 25 / 30 | Total Loss: 1.053612470626831 | KNN Loss: 6.226780891418457 | BCE Loss: 1.053612470626831\n",
      "Epoch 142 / 500 | iteration 0 / 30 | Total Loss: 1.0525778532028198 | KNN Loss: 6.227040767669678 | BCE Loss: 1.0525778532028198\n",
      "Epoch 142 / 500 | iteration 5 / 30 | Total Loss: 1.048457145690918 | KNN Loss: 6.227014541625977 | BCE Loss: 1.048457145690918\n",
      "Epoch 142 / 500 | iteration 10 / 30 | Total Loss: 1.0357563495635986 | KNN Loss: 6.226861953735352 | BCE Loss: 1.0357563495635986\n",
      "Epoch 142 / 500 | iteration 15 / 30 | Total Loss: 1.042816162109375 | KNN Loss: 6.226997375488281 | BCE Loss: 1.042816162109375\n",
      "Epoch 142 / 500 | iteration 20 / 30 | Total Loss: 1.037710428237915 | KNN Loss: 6.2267608642578125 | BCE Loss: 1.037710428237915\n",
      "Epoch 142 / 500 | iteration 25 / 30 | Total Loss: 1.0507161617279053 | KNN Loss: 6.227027416229248 | BCE Loss: 1.0507161617279053\n",
      "Epoch 143 / 500 | iteration 0 / 30 | Total Loss: 1.0750929117202759 | KNN Loss: 6.226862907409668 | BCE Loss: 1.0750929117202759\n",
      "Epoch 143 / 500 | iteration 5 / 30 | Total Loss: 1.019544005393982 | KNN Loss: 6.2269062995910645 | BCE Loss: 1.019544005393982\n",
      "Epoch 143 / 500 | iteration 10 / 30 | Total Loss: 1.0739281177520752 | KNN Loss: 6.226816654205322 | BCE Loss: 1.0739281177520752\n",
      "Epoch 143 / 500 | iteration 15 / 30 | Total Loss: 1.0706477165222168 | KNN Loss: 6.2271599769592285 | BCE Loss: 1.0706477165222168\n",
      "Epoch 143 / 500 | iteration 20 / 30 | Total Loss: 1.0450598001480103 | KNN Loss: 6.226695537567139 | BCE Loss: 1.0450598001480103\n",
      "Epoch 143 / 500 | iteration 25 / 30 | Total Loss: 1.0597033500671387 | KNN Loss: 6.227219581604004 | BCE Loss: 1.0597033500671387\n",
      "Epoch 144 / 500 | iteration 0 / 30 | Total Loss: 1.0385359525680542 | KNN Loss: 6.227078914642334 | BCE Loss: 1.0385359525680542\n",
      "Epoch 144 / 500 | iteration 5 / 30 | Total Loss: 1.0195741653442383 | KNN Loss: 6.226598262786865 | BCE Loss: 1.0195741653442383\n",
      "Epoch 144 / 500 | iteration 10 / 30 | Total Loss: 1.049086093902588 | KNN Loss: 6.2266058921813965 | BCE Loss: 1.049086093902588\n",
      "Epoch 144 / 500 | iteration 15 / 30 | Total Loss: 1.0353142023086548 | KNN Loss: 6.226402282714844 | BCE Loss: 1.0353142023086548\n",
      "Epoch 144 / 500 | iteration 20 / 30 | Total Loss: 1.0472946166992188 | KNN Loss: 6.226870059967041 | BCE Loss: 1.0472946166992188\n",
      "Epoch 144 / 500 | iteration 25 / 30 | Total Loss: 1.0505049228668213 | KNN Loss: 6.226903438568115 | BCE Loss: 1.0505049228668213\n",
      "Epoch 145 / 500 | iteration 0 / 30 | Total Loss: 1.0622127056121826 | KNN Loss: 6.226940631866455 | BCE Loss: 1.0622127056121826\n",
      "Epoch 145 / 500 | iteration 5 / 30 | Total Loss: 1.0621974468231201 | KNN Loss: 6.226843357086182 | BCE Loss: 1.0621974468231201\n",
      "Epoch 145 / 500 | iteration 10 / 30 | Total Loss: 1.040934443473816 | KNN Loss: 6.22668981552124 | BCE Loss: 1.040934443473816\n",
      "Epoch 145 / 500 | iteration 15 / 30 | Total Loss: 1.0703694820404053 | KNN Loss: 6.227008819580078 | BCE Loss: 1.0703694820404053\n",
      "Epoch 145 / 500 | iteration 20 / 30 | Total Loss: 1.0485074520111084 | KNN Loss: 6.227043628692627 | BCE Loss: 1.0485074520111084\n",
      "Epoch 145 / 500 | iteration 25 / 30 | Total Loss: 1.0314663648605347 | KNN Loss: 6.227033615112305 | BCE Loss: 1.0314663648605347\n",
      "Epoch 146 / 500 | iteration 0 / 30 | Total Loss: 1.0229674577713013 | KNN Loss: 6.226992607116699 | BCE Loss: 1.0229674577713013\n",
      "Epoch 146 / 500 | iteration 5 / 30 | Total Loss: 1.075855016708374 | KNN Loss: 6.226860523223877 | BCE Loss: 1.075855016708374\n",
      "Epoch 146 / 500 | iteration 10 / 30 | Total Loss: 1.04848313331604 | KNN Loss: 6.2271528244018555 | BCE Loss: 1.04848313331604\n",
      "Epoch 146 / 500 | iteration 15 / 30 | Total Loss: 1.0580402612686157 | KNN Loss: 6.2269287109375 | BCE Loss: 1.0580402612686157\n",
      "Epoch 146 / 500 | iteration 20 / 30 | Total Loss: 1.030022144317627 | KNN Loss: 6.226785182952881 | BCE Loss: 1.030022144317627\n",
      "Epoch 146 / 500 | iteration 25 / 30 | Total Loss: 1.07136070728302 | KNN Loss: 6.227046966552734 | BCE Loss: 1.07136070728302\n",
      "Epoch 147 / 500 | iteration 0 / 30 | Total Loss: 1.068090558052063 | KNN Loss: 6.2270307540893555 | BCE Loss: 1.068090558052063\n",
      "Epoch 147 / 500 | iteration 5 / 30 | Total Loss: 1.031747579574585 | KNN Loss: 6.226927757263184 | BCE Loss: 1.031747579574585\n",
      "Epoch 147 / 500 | iteration 10 / 30 | Total Loss: 1.058380365371704 | KNN Loss: 6.226956844329834 | BCE Loss: 1.058380365371704\n",
      "Epoch 147 / 500 | iteration 15 / 30 | Total Loss: 1.081737995147705 | KNN Loss: 6.227015972137451 | BCE Loss: 1.081737995147705\n",
      "Epoch 147 / 500 | iteration 20 / 30 | Total Loss: 1.0745911598205566 | KNN Loss: 6.227015972137451 | BCE Loss: 1.0745911598205566\n",
      "Epoch 147 / 500 | iteration 25 / 30 | Total Loss: 1.0713884830474854 | KNN Loss: 6.22685432434082 | BCE Loss: 1.0713884830474854\n",
      "Epoch 148 / 500 | iteration 0 / 30 | Total Loss: 1.0496952533721924 | KNN Loss: 6.226593494415283 | BCE Loss: 1.0496952533721924\n",
      "Epoch 148 / 500 | iteration 5 / 30 | Total Loss: 1.0255460739135742 | KNN Loss: 6.2272047996521 | BCE Loss: 1.0255460739135742\n",
      "Epoch 148 / 500 | iteration 10 / 30 | Total Loss: 1.0300201177597046 | KNN Loss: 6.2270731925964355 | BCE Loss: 1.0300201177597046\n",
      "Epoch 148 / 500 | iteration 15 / 30 | Total Loss: 1.056672215461731 | KNN Loss: 6.22705078125 | BCE Loss: 1.056672215461731\n",
      "Epoch 148 / 500 | iteration 20 / 30 | Total Loss: 1.0483372211456299 | KNN Loss: 6.226996421813965 | BCE Loss: 1.0483372211456299\n",
      "Epoch 148 / 500 | iteration 25 / 30 | Total Loss: 1.0422852039337158 | KNN Loss: 6.226921558380127 | BCE Loss: 1.0422852039337158\n",
      "Epoch 149 / 500 | iteration 0 / 30 | Total Loss: 1.0610517263412476 | KNN Loss: 6.226949691772461 | BCE Loss: 1.0610517263412476\n",
      "Epoch 149 / 500 | iteration 5 / 30 | Total Loss: 1.0561331510543823 | KNN Loss: 6.226876735687256 | BCE Loss: 1.0561331510543823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 / 500 | iteration 10 / 30 | Total Loss: 1.0562978982925415 | KNN Loss: 6.227269649505615 | BCE Loss: 1.0562978982925415\n",
      "Epoch 149 / 500 | iteration 15 / 30 | Total Loss: 1.0376942157745361 | KNN Loss: 6.226743221282959 | BCE Loss: 1.0376942157745361\n",
      "Epoch 149 / 500 | iteration 20 / 30 | Total Loss: 1.0255951881408691 | KNN Loss: 6.226550102233887 | BCE Loss: 1.0255951881408691\n",
      "Epoch 149 / 500 | iteration 25 / 30 | Total Loss: 1.0463883876800537 | KNN Loss: 6.226866722106934 | BCE Loss: 1.0463883876800537\n",
      "Epoch   150: reducing learning rate of group 0 to 2.0177e-04.\n",
      "Epoch 150 / 500 | iteration 0 / 30 | Total Loss: 1.0331904888153076 | KNN Loss: 6.2269110679626465 | BCE Loss: 1.0331904888153076\n",
      "Epoch 150 / 500 | iteration 5 / 30 | Total Loss: 1.0676355361938477 | KNN Loss: 6.226658344268799 | BCE Loss: 1.0676355361938477\n",
      "Epoch 150 / 500 | iteration 10 / 30 | Total Loss: 1.0651873350143433 | KNN Loss: 6.2268829345703125 | BCE Loss: 1.0651873350143433\n",
      "Epoch 150 / 500 | iteration 15 / 30 | Total Loss: 1.0040054321289062 | KNN Loss: 6.22707462310791 | BCE Loss: 1.0040054321289062\n",
      "Epoch 150 / 500 | iteration 20 / 30 | Total Loss: 1.0449719429016113 | KNN Loss: 6.227013111114502 | BCE Loss: 1.0449719429016113\n",
      "Epoch 150 / 500 | iteration 25 / 30 | Total Loss: 1.0557923316955566 | KNN Loss: 6.227029800415039 | BCE Loss: 1.0557923316955566\n",
      "Epoch 151 / 500 | iteration 0 / 30 | Total Loss: 1.002442717552185 | KNN Loss: 6.226687908172607 | BCE Loss: 1.002442717552185\n",
      "Epoch 151 / 500 | iteration 5 / 30 | Total Loss: 1.0484391450881958 | KNN Loss: 6.22700834274292 | BCE Loss: 1.0484391450881958\n",
      "Epoch 151 / 500 | iteration 10 / 30 | Total Loss: 1.0392565727233887 | KNN Loss: 6.2269978523254395 | BCE Loss: 1.0392565727233887\n",
      "Epoch 151 / 500 | iteration 15 / 30 | Total Loss: 1.0644478797912598 | KNN Loss: 6.2267374992370605 | BCE Loss: 1.0644478797912598\n",
      "Epoch 151 / 500 | iteration 20 / 30 | Total Loss: 1.06727933883667 | KNN Loss: 6.226684093475342 | BCE Loss: 1.06727933883667\n",
      "Epoch 151 / 500 | iteration 25 / 30 | Total Loss: 1.0436420440673828 | KNN Loss: 6.226779460906982 | BCE Loss: 1.0436420440673828\n",
      "Epoch 152 / 500 | iteration 0 / 30 | Total Loss: 1.061947226524353 | KNN Loss: 6.227047920227051 | BCE Loss: 1.061947226524353\n",
      "Epoch 152 / 500 | iteration 5 / 30 | Total Loss: 1.0328538417816162 | KNN Loss: 6.226868152618408 | BCE Loss: 1.0328538417816162\n",
      "Epoch 152 / 500 | iteration 10 / 30 | Total Loss: 1.0679161548614502 | KNN Loss: 6.226887226104736 | BCE Loss: 1.0679161548614502\n",
      "Epoch 152 / 500 | iteration 15 / 30 | Total Loss: 1.083472728729248 | KNN Loss: 6.2265496253967285 | BCE Loss: 1.083472728729248\n",
      "Epoch 152 / 500 | iteration 20 / 30 | Total Loss: 1.049146294593811 | KNN Loss: 6.226860046386719 | BCE Loss: 1.049146294593811\n",
      "Epoch 152 / 500 | iteration 25 / 30 | Total Loss: 1.0403865575790405 | KNN Loss: 6.227122783660889 | BCE Loss: 1.0403865575790405\n",
      "Epoch 153 / 500 | iteration 0 / 30 | Total Loss: 1.064573049545288 | KNN Loss: 6.226746082305908 | BCE Loss: 1.064573049545288\n",
      "Epoch 153 / 500 | iteration 5 / 30 | Total Loss: 1.0574371814727783 | KNN Loss: 6.227151393890381 | BCE Loss: 1.0574371814727783\n",
      "Epoch 153 / 500 | iteration 10 / 30 | Total Loss: 1.0920827388763428 | KNN Loss: 6.226739406585693 | BCE Loss: 1.0920827388763428\n",
      "Epoch 153 / 500 | iteration 15 / 30 | Total Loss: 1.0728132724761963 | KNN Loss: 6.227121829986572 | BCE Loss: 1.0728132724761963\n",
      "Epoch 153 / 500 | iteration 20 / 30 | Total Loss: 1.0617156028747559 | KNN Loss: 6.226716041564941 | BCE Loss: 1.0617156028747559\n",
      "Epoch 153 / 500 | iteration 25 / 30 | Total Loss: 1.0770504474639893 | KNN Loss: 6.226677417755127 | BCE Loss: 1.0770504474639893\n",
      "Epoch 154 / 500 | iteration 0 / 30 | Total Loss: 1.0814540386199951 | KNN Loss: 6.226817607879639 | BCE Loss: 1.0814540386199951\n",
      "Epoch 154 / 500 | iteration 5 / 30 | Total Loss: 1.040541172027588 | KNN Loss: 6.226774215698242 | BCE Loss: 1.040541172027588\n",
      "Epoch 154 / 500 | iteration 10 / 30 | Total Loss: 1.0593628883361816 | KNN Loss: 6.226985931396484 | BCE Loss: 1.0593628883361816\n",
      "Epoch 154 / 500 | iteration 15 / 30 | Total Loss: 1.0516362190246582 | KNN Loss: 6.227200508117676 | BCE Loss: 1.0516362190246582\n",
      "Epoch 154 / 500 | iteration 20 / 30 | Total Loss: 1.0318673849105835 | KNN Loss: 6.226864337921143 | BCE Loss: 1.0318673849105835\n",
      "Epoch 154 / 500 | iteration 25 / 30 | Total Loss: 1.0363086462020874 | KNN Loss: 6.227216720581055 | BCE Loss: 1.0363086462020874\n",
      "Epoch 155 / 500 | iteration 0 / 30 | Total Loss: 1.0601067543029785 | KNN Loss: 6.226843357086182 | BCE Loss: 1.0601067543029785\n",
      "Epoch 155 / 500 | iteration 5 / 30 | Total Loss: 1.0775482654571533 | KNN Loss: 6.226888179779053 | BCE Loss: 1.0775482654571533\n",
      "Epoch 155 / 500 | iteration 10 / 30 | Total Loss: 1.0872802734375 | KNN Loss: 6.226851463317871 | BCE Loss: 1.0872802734375\n",
      "Epoch 155 / 500 | iteration 15 / 30 | Total Loss: 1.0451847314834595 | KNN Loss: 6.22690486907959 | BCE Loss: 1.0451847314834595\n",
      "Epoch 155 / 500 | iteration 20 / 30 | Total Loss: 1.0632745027542114 | KNN Loss: 6.226799488067627 | BCE Loss: 1.0632745027542114\n",
      "Epoch 155 / 500 | iteration 25 / 30 | Total Loss: 1.0584025382995605 | KNN Loss: 6.2266316413879395 | BCE Loss: 1.0584025382995605\n",
      "Epoch 156 / 500 | iteration 0 / 30 | Total Loss: 1.0476512908935547 | KNN Loss: 6.226679801940918 | BCE Loss: 1.0476512908935547\n",
      "Epoch 156 / 500 | iteration 5 / 30 | Total Loss: 1.0432666540145874 | KNN Loss: 6.227062702178955 | BCE Loss: 1.0432666540145874\n",
      "Epoch 156 / 500 | iteration 10 / 30 | Total Loss: 1.0435010194778442 | KNN Loss: 6.226924419403076 | BCE Loss: 1.0435010194778442\n",
      "Epoch 156 / 500 | iteration 15 / 30 | Total Loss: 1.0790592432022095 | KNN Loss: 6.226729393005371 | BCE Loss: 1.0790592432022095\n",
      "Epoch 156 / 500 | iteration 20 / 30 | Total Loss: 1.0367927551269531 | KNN Loss: 6.227069854736328 | BCE Loss: 1.0367927551269531\n",
      "Epoch 156 / 500 | iteration 25 / 30 | Total Loss: 1.058518648147583 | KNN Loss: 6.226758003234863 | BCE Loss: 1.058518648147583\n",
      "Epoch 157 / 500 | iteration 0 / 30 | Total Loss: 1.0533843040466309 | KNN Loss: 6.226865768432617 | BCE Loss: 1.0533843040466309\n",
      "Epoch 157 / 500 | iteration 5 / 30 | Total Loss: 1.0797793865203857 | KNN Loss: 6.226646900177002 | BCE Loss: 1.0797793865203857\n",
      "Epoch 157 / 500 | iteration 10 / 30 | Total Loss: 1.063048005104065 | KNN Loss: 6.226912975311279 | BCE Loss: 1.063048005104065\n",
      "Epoch 157 / 500 | iteration 15 / 30 | Total Loss: 1.0459691286087036 | KNN Loss: 6.226747035980225 | BCE Loss: 1.0459691286087036\n",
      "Epoch 157 / 500 | iteration 20 / 30 | Total Loss: 1.0312128067016602 | KNN Loss: 6.226933479309082 | BCE Loss: 1.0312128067016602\n",
      "Epoch 157 / 500 | iteration 25 / 30 | Total Loss: 1.036479115486145 | KNN Loss: 6.226571559906006 | BCE Loss: 1.036479115486145\n",
      "Epoch 158 / 500 | iteration 0 / 30 | Total Loss: 1.0492768287658691 | KNN Loss: 6.226870059967041 | BCE Loss: 1.0492768287658691\n",
      "Epoch 158 / 500 | iteration 5 / 30 | Total Loss: 1.0785986185073853 | KNN Loss: 6.226622104644775 | BCE Loss: 1.0785986185073853\n",
      "Epoch 158 / 500 | iteration 10 / 30 | Total Loss: 1.0214831829071045 | KNN Loss: 6.226795673370361 | BCE Loss: 1.0214831829071045\n",
      "Epoch 158 / 500 | iteration 15 / 30 | Total Loss: 1.0607144832611084 | KNN Loss: 6.226951599121094 | BCE Loss: 1.0607144832611084\n",
      "Epoch 158 / 500 | iteration 20 / 30 | Total Loss: 1.0463205575942993 | KNN Loss: 6.2267069816589355 | BCE Loss: 1.0463205575942993\n",
      "Epoch 158 / 500 | iteration 25 / 30 | Total Loss: 1.0205434560775757 | KNN Loss: 6.2265214920043945 | BCE Loss: 1.0205434560775757\n",
      "Epoch 159 / 500 | iteration 0 / 30 | Total Loss: 1.0351687669754028 | KNN Loss: 6.226785182952881 | BCE Loss: 1.0351687669754028\n",
      "Epoch 159 / 500 | iteration 5 / 30 | Total Loss: 1.069461703300476 | KNN Loss: 6.226815223693848 | BCE Loss: 1.069461703300476\n",
      "Epoch 159 / 500 | iteration 10 / 30 | Total Loss: 1.0494085550308228 | KNN Loss: 6.226741313934326 | BCE Loss: 1.0494085550308228\n",
      "Epoch 159 / 500 | iteration 15 / 30 | Total Loss: 1.0311814546585083 | KNN Loss: 6.226937770843506 | BCE Loss: 1.0311814546585083\n",
      "Epoch 159 / 500 | iteration 20 / 30 | Total Loss: 1.0590794086456299 | KNN Loss: 6.2268500328063965 | BCE Loss: 1.0590794086456299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 / 500 | iteration 25 / 30 | Total Loss: 1.076477289199829 | KNN Loss: 6.227128982543945 | BCE Loss: 1.076477289199829\n",
      "Epoch 160 / 500 | iteration 0 / 30 | Total Loss: 1.0566004514694214 | KNN Loss: 6.227077960968018 | BCE Loss: 1.0566004514694214\n",
      "Epoch 160 / 500 | iteration 5 / 30 | Total Loss: 1.0471282005310059 | KNN Loss: 6.226767539978027 | BCE Loss: 1.0471282005310059\n",
      "Epoch 160 / 500 | iteration 10 / 30 | Total Loss: 1.0086981058120728 | KNN Loss: 6.226433753967285 | BCE Loss: 1.0086981058120728\n",
      "Epoch 160 / 500 | iteration 15 / 30 | Total Loss: 1.0347754955291748 | KNN Loss: 6.226790428161621 | BCE Loss: 1.0347754955291748\n",
      "Epoch 160 / 500 | iteration 20 / 30 | Total Loss: 1.0571165084838867 | KNN Loss: 6.226821422576904 | BCE Loss: 1.0571165084838867\n",
      "Epoch 160 / 500 | iteration 25 / 30 | Total Loss: 1.0350394248962402 | KNN Loss: 6.227270126342773 | BCE Loss: 1.0350394248962402\n",
      "Epoch   161: reducing learning rate of group 0 to 1.4124e-04.\n",
      "Epoch 161 / 500 | iteration 0 / 30 | Total Loss: 1.0443525314331055 | KNN Loss: 6.226892948150635 | BCE Loss: 1.0443525314331055\n",
      "Epoch 161 / 500 | iteration 5 / 30 | Total Loss: 1.0508108139038086 | KNN Loss: 6.226760387420654 | BCE Loss: 1.0508108139038086\n",
      "Epoch 161 / 500 | iteration 10 / 30 | Total Loss: 1.0656168460845947 | KNN Loss: 6.227221488952637 | BCE Loss: 1.0656168460845947\n",
      "Epoch 161 / 500 | iteration 15 / 30 | Total Loss: 1.0478408336639404 | KNN Loss: 6.226992607116699 | BCE Loss: 1.0478408336639404\n",
      "Epoch 161 / 500 | iteration 20 / 30 | Total Loss: 1.0571047067642212 | KNN Loss: 6.227076530456543 | BCE Loss: 1.0571047067642212\n",
      "Epoch 161 / 500 | iteration 25 / 30 | Total Loss: 1.083960771560669 | KNN Loss: 6.227090835571289 | BCE Loss: 1.083960771560669\n",
      "Epoch 162 / 500 | iteration 0 / 30 | Total Loss: 1.0525109767913818 | KNN Loss: 6.227031707763672 | BCE Loss: 1.0525109767913818\n",
      "Epoch 162 / 500 | iteration 5 / 30 | Total Loss: 1.0351730585098267 | KNN Loss: 6.227038860321045 | BCE Loss: 1.0351730585098267\n",
      "Epoch 162 / 500 | iteration 10 / 30 | Total Loss: 1.0363109111785889 | KNN Loss: 6.227020263671875 | BCE Loss: 1.0363109111785889\n",
      "Epoch 162 / 500 | iteration 15 / 30 | Total Loss: 1.0473742485046387 | KNN Loss: 6.226758003234863 | BCE Loss: 1.0473742485046387\n",
      "Epoch 162 / 500 | iteration 20 / 30 | Total Loss: 1.0422091484069824 | KNN Loss: 6.22684907913208 | BCE Loss: 1.0422091484069824\n",
      "Epoch 162 / 500 | iteration 25 / 30 | Total Loss: 1.0562026500701904 | KNN Loss: 6.226968288421631 | BCE Loss: 1.0562026500701904\n",
      "Epoch 163 / 500 | iteration 0 / 30 | Total Loss: 1.0563712120056152 | KNN Loss: 6.226817607879639 | BCE Loss: 1.0563712120056152\n",
      "Epoch 163 / 500 | iteration 5 / 30 | Total Loss: 1.0252559185028076 | KNN Loss: 6.22686243057251 | BCE Loss: 1.0252559185028076\n",
      "Epoch 163 / 500 | iteration 10 / 30 | Total Loss: 1.0471246242523193 | KNN Loss: 6.226884365081787 | BCE Loss: 1.0471246242523193\n",
      "Epoch 163 / 500 | iteration 15 / 30 | Total Loss: 1.0650852918624878 | KNN Loss: 6.226928234100342 | BCE Loss: 1.0650852918624878\n",
      "Epoch 163 / 500 | iteration 20 / 30 | Total Loss: 1.0790886878967285 | KNN Loss: 6.2268242835998535 | BCE Loss: 1.0790886878967285\n",
      "Epoch 163 / 500 | iteration 25 / 30 | Total Loss: 1.0934009552001953 | KNN Loss: 6.227022171020508 | BCE Loss: 1.0934009552001953\n",
      "Epoch 164 / 500 | iteration 0 / 30 | Total Loss: 1.0086236000061035 | KNN Loss: 6.226954460144043 | BCE Loss: 1.0086236000061035\n",
      "Epoch 164 / 500 | iteration 5 / 30 | Total Loss: 1.0677647590637207 | KNN Loss: 6.226583957672119 | BCE Loss: 1.0677647590637207\n",
      "Epoch 164 / 500 | iteration 10 / 30 | Total Loss: 1.06361985206604 | KNN Loss: 6.226937770843506 | BCE Loss: 1.06361985206604\n",
      "Epoch 164 / 500 | iteration 15 / 30 | Total Loss: 1.0385284423828125 | KNN Loss: 6.226885795593262 | BCE Loss: 1.0385284423828125\n",
      "Epoch 164 / 500 | iteration 20 / 30 | Total Loss: 1.0502386093139648 | KNN Loss: 6.2269978523254395 | BCE Loss: 1.0502386093139648\n",
      "Epoch 164 / 500 | iteration 25 / 30 | Total Loss: 1.0777621269226074 | KNN Loss: 6.227105617523193 | BCE Loss: 1.0777621269226074\n",
      "Epoch 165 / 500 | iteration 0 / 30 | Total Loss: 1.0527987480163574 | KNN Loss: 6.226980209350586 | BCE Loss: 1.0527987480163574\n",
      "Epoch 165 / 500 | iteration 5 / 30 | Total Loss: 1.0510544776916504 | KNN Loss: 6.226413249969482 | BCE Loss: 1.0510544776916504\n",
      "Epoch 165 / 500 | iteration 10 / 30 | Total Loss: 1.045203685760498 | KNN Loss: 6.227160930633545 | BCE Loss: 1.045203685760498\n",
      "Epoch 165 / 500 | iteration 15 / 30 | Total Loss: 1.0405206680297852 | KNN Loss: 6.226836204528809 | BCE Loss: 1.0405206680297852\n",
      "Epoch 165 / 500 | iteration 20 / 30 | Total Loss: 1.0417429208755493 | KNN Loss: 6.227023601531982 | BCE Loss: 1.0417429208755493\n",
      "Epoch 165 / 500 | iteration 25 / 30 | Total Loss: 1.030360221862793 | KNN Loss: 6.226804733276367 | BCE Loss: 1.030360221862793\n",
      "Epoch 166 / 500 | iteration 0 / 30 | Total Loss: 1.0633844137191772 | KNN Loss: 6.227022171020508 | BCE Loss: 1.0633844137191772\n",
      "Epoch 166 / 500 | iteration 5 / 30 | Total Loss: 1.0432748794555664 | KNN Loss: 6.226889133453369 | BCE Loss: 1.0432748794555664\n",
      "Epoch 166 / 500 | iteration 10 / 30 | Total Loss: 1.0461008548736572 | KNN Loss: 6.227018356323242 | BCE Loss: 1.0461008548736572\n",
      "Epoch 166 / 500 | iteration 15 / 30 | Total Loss: 1.0620663166046143 | KNN Loss: 6.226768970489502 | BCE Loss: 1.0620663166046143\n",
      "Epoch 166 / 500 | iteration 20 / 30 | Total Loss: 1.0681684017181396 | KNN Loss: 6.226963520050049 | BCE Loss: 1.0681684017181396\n",
      "Epoch 166 / 500 | iteration 25 / 30 | Total Loss: 1.0421481132507324 | KNN Loss: 6.226747512817383 | BCE Loss: 1.0421481132507324\n",
      "Epoch 167 / 500 | iteration 0 / 30 | Total Loss: 1.0159270763397217 | KNN Loss: 6.2267327308654785 | BCE Loss: 1.0159270763397217\n",
      "Epoch 167 / 500 | iteration 5 / 30 | Total Loss: 1.0483949184417725 | KNN Loss: 6.2268290519714355 | BCE Loss: 1.0483949184417725\n",
      "Epoch 167 / 500 | iteration 10 / 30 | Total Loss: 1.0571951866149902 | KNN Loss: 6.226878643035889 | BCE Loss: 1.0571951866149902\n",
      "Epoch 167 / 500 | iteration 15 / 30 | Total Loss: 1.0478140115737915 | KNN Loss: 6.227119445800781 | BCE Loss: 1.0478140115737915\n",
      "Epoch 167 / 500 | iteration 20 / 30 | Total Loss: 1.0644352436065674 | KNN Loss: 6.226840496063232 | BCE Loss: 1.0644352436065674\n",
      "Epoch 167 / 500 | iteration 25 / 30 | Total Loss: 1.0299382209777832 | KNN Loss: 6.226871013641357 | BCE Loss: 1.0299382209777832\n",
      "Epoch 168 / 500 | iteration 0 / 30 | Total Loss: 1.0266036987304688 | KNN Loss: 6.226858139038086 | BCE Loss: 1.0266036987304688\n",
      "Epoch 168 / 500 | iteration 5 / 30 | Total Loss: 1.0726168155670166 | KNN Loss: 6.227142333984375 | BCE Loss: 1.0726168155670166\n",
      "Epoch 168 / 500 | iteration 10 / 30 | Total Loss: 1.0585458278656006 | KNN Loss: 6.227048397064209 | BCE Loss: 1.0585458278656006\n",
      "Epoch 168 / 500 | iteration 15 / 30 | Total Loss: 1.0370287895202637 | KNN Loss: 6.226721286773682 | BCE Loss: 1.0370287895202637\n",
      "Epoch 168 / 500 | iteration 20 / 30 | Total Loss: 1.0315909385681152 | KNN Loss: 6.226866722106934 | BCE Loss: 1.0315909385681152\n",
      "Epoch 168 / 500 | iteration 25 / 30 | Total Loss: 1.0456602573394775 | KNN Loss: 6.226953029632568 | BCE Loss: 1.0456602573394775\n",
      "Epoch 169 / 500 | iteration 0 / 30 | Total Loss: 1.0368456840515137 | KNN Loss: 6.227078914642334 | BCE Loss: 1.0368456840515137\n",
      "Epoch 169 / 500 | iteration 5 / 30 | Total Loss: 1.0556776523590088 | KNN Loss: 6.227025985717773 | BCE Loss: 1.0556776523590088\n",
      "Epoch 169 / 500 | iteration 10 / 30 | Total Loss: 1.0505304336547852 | KNN Loss: 6.227114200592041 | BCE Loss: 1.0505304336547852\n",
      "Epoch 169 / 500 | iteration 15 / 30 | Total Loss: 1.0566686391830444 | KNN Loss: 6.227054119110107 | BCE Loss: 1.0566686391830444\n",
      "Epoch 169 / 500 | iteration 20 / 30 | Total Loss: 1.0658040046691895 | KNN Loss: 6.226984024047852 | BCE Loss: 1.0658040046691895\n",
      "Epoch 169 / 500 | iteration 25 / 30 | Total Loss: 1.0126231908798218 | KNN Loss: 6.226832389831543 | BCE Loss: 1.0126231908798218\n",
      "Epoch 170 / 500 | iteration 0 / 30 | Total Loss: 1.063085675239563 | KNN Loss: 6.2267231941223145 | BCE Loss: 1.063085675239563\n",
      "Epoch 170 / 500 | iteration 5 / 30 | Total Loss: 1.0394937992095947 | KNN Loss: 6.226713180541992 | BCE Loss: 1.0394937992095947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 / 500 | iteration 10 / 30 | Total Loss: 1.0616375207901 | KNN Loss: 6.2268595695495605 | BCE Loss: 1.0616375207901\n",
      "Epoch 170 / 500 | iteration 15 / 30 | Total Loss: 1.07437002658844 | KNN Loss: 6.226970672607422 | BCE Loss: 1.07437002658844\n",
      "Epoch 170 / 500 | iteration 20 / 30 | Total Loss: 1.0691665410995483 | KNN Loss: 6.22697639465332 | BCE Loss: 1.0691665410995483\n",
      "Epoch 170 / 500 | iteration 25 / 30 | Total Loss: 1.04924476146698 | KNN Loss: 6.226975917816162 | BCE Loss: 1.04924476146698\n",
      "Epoch 171 / 500 | iteration 0 / 30 | Total Loss: 1.049546241760254 | KNN Loss: 6.226875305175781 | BCE Loss: 1.049546241760254\n",
      "Epoch 171 / 500 | iteration 5 / 30 | Total Loss: 1.0546324253082275 | KNN Loss: 6.2266387939453125 | BCE Loss: 1.0546324253082275\n",
      "Epoch 171 / 500 | iteration 10 / 30 | Total Loss: 1.0438556671142578 | KNN Loss: 6.226565361022949 | BCE Loss: 1.0438556671142578\n",
      "Epoch 171 / 500 | iteration 15 / 30 | Total Loss: 1.0355594158172607 | KNN Loss: 6.226954460144043 | BCE Loss: 1.0355594158172607\n",
      "Epoch 171 / 500 | iteration 20 / 30 | Total Loss: 1.063619613647461 | KNN Loss: 6.226945400238037 | BCE Loss: 1.063619613647461\n",
      "Epoch 171 / 500 | iteration 25 / 30 | Total Loss: 1.0779160261154175 | KNN Loss: 6.22683572769165 | BCE Loss: 1.0779160261154175\n",
      "Epoch   172: reducing learning rate of group 0 to 9.8866e-05.\n",
      "Epoch 172 / 500 | iteration 0 / 30 | Total Loss: 1.046483039855957 | KNN Loss: 6.226991653442383 | BCE Loss: 1.046483039855957\n",
      "Epoch 172 / 500 | iteration 5 / 30 | Total Loss: 1.0449455976486206 | KNN Loss: 6.226922035217285 | BCE Loss: 1.0449455976486206\n",
      "Epoch 172 / 500 | iteration 10 / 30 | Total Loss: 1.0440101623535156 | KNN Loss: 6.226681232452393 | BCE Loss: 1.0440101623535156\n",
      "Epoch 172 / 500 | iteration 15 / 30 | Total Loss: 1.052949070930481 | KNN Loss: 6.227085113525391 | BCE Loss: 1.052949070930481\n",
      "Epoch 172 / 500 | iteration 20 / 30 | Total Loss: 1.0272372961044312 | KNN Loss: 6.226718425750732 | BCE Loss: 1.0272372961044312\n",
      "Epoch 172 / 500 | iteration 25 / 30 | Total Loss: 1.0408661365509033 | KNN Loss: 6.226993083953857 | BCE Loss: 1.0408661365509033\n",
      "Epoch 173 / 500 | iteration 0 / 30 | Total Loss: 1.0637602806091309 | KNN Loss: 6.227205753326416 | BCE Loss: 1.0637602806091309\n",
      "Epoch 173 / 500 | iteration 5 / 30 | Total Loss: 1.0632414817810059 | KNN Loss: 6.226879596710205 | BCE Loss: 1.0632414817810059\n",
      "Epoch 173 / 500 | iteration 10 / 30 | Total Loss: 1.0884897708892822 | KNN Loss: 6.226789474487305 | BCE Loss: 1.0884897708892822\n",
      "Epoch 173 / 500 | iteration 15 / 30 | Total Loss: 1.0455455780029297 | KNN Loss: 6.226994514465332 | BCE Loss: 1.0455455780029297\n",
      "Epoch 173 / 500 | iteration 20 / 30 | Total Loss: 1.0433282852172852 | KNN Loss: 6.226547718048096 | BCE Loss: 1.0433282852172852\n",
      "Epoch 173 / 500 | iteration 25 / 30 | Total Loss: 1.0641934871673584 | KNN Loss: 6.227108001708984 | BCE Loss: 1.0641934871673584\n",
      "Epoch 174 / 500 | iteration 0 / 30 | Total Loss: 1.0481452941894531 | KNN Loss: 6.226764678955078 | BCE Loss: 1.0481452941894531\n",
      "Epoch 174 / 500 | iteration 5 / 30 | Total Loss: 1.0594141483306885 | KNN Loss: 6.226729869842529 | BCE Loss: 1.0594141483306885\n",
      "Epoch 174 / 500 | iteration 10 / 30 | Total Loss: 1.0245048999786377 | KNN Loss: 6.226477146148682 | BCE Loss: 1.0245048999786377\n",
      "Epoch 174 / 500 | iteration 15 / 30 | Total Loss: 1.0574826002120972 | KNN Loss: 6.226940631866455 | BCE Loss: 1.0574826002120972\n",
      "Epoch 174 / 500 | iteration 20 / 30 | Total Loss: 1.0360627174377441 | KNN Loss: 6.2268967628479 | BCE Loss: 1.0360627174377441\n",
      "Epoch 174 / 500 | iteration 25 / 30 | Total Loss: 1.0587854385375977 | KNN Loss: 6.227099895477295 | BCE Loss: 1.0587854385375977\n",
      "Epoch 175 / 500 | iteration 0 / 30 | Total Loss: 1.0557141304016113 | KNN Loss: 6.226767063140869 | BCE Loss: 1.0557141304016113\n",
      "Epoch 175 / 500 | iteration 5 / 30 | Total Loss: 1.0490483045578003 | KNN Loss: 6.226964950561523 | BCE Loss: 1.0490483045578003\n",
      "Epoch 175 / 500 | iteration 10 / 30 | Total Loss: 1.0329850912094116 | KNN Loss: 6.2268476486206055 | BCE Loss: 1.0329850912094116\n",
      "Epoch 175 / 500 | iteration 15 / 30 | Total Loss: 1.0406494140625 | KNN Loss: 6.226958751678467 | BCE Loss: 1.0406494140625\n",
      "Epoch 175 / 500 | iteration 20 / 30 | Total Loss: 1.053378939628601 | KNN Loss: 6.226888656616211 | BCE Loss: 1.053378939628601\n",
      "Epoch 175 / 500 | iteration 25 / 30 | Total Loss: 1.051714301109314 | KNN Loss: 6.226548194885254 | BCE Loss: 1.051714301109314\n",
      "Epoch 176 / 500 | iteration 0 / 30 | Total Loss: 1.0549626350402832 | KNN Loss: 6.226840019226074 | BCE Loss: 1.0549626350402832\n",
      "Epoch 176 / 500 | iteration 5 / 30 | Total Loss: 1.0441973209381104 | KNN Loss: 6.227306842803955 | BCE Loss: 1.0441973209381104\n",
      "Epoch 176 / 500 | iteration 10 / 30 | Total Loss: 1.040026068687439 | KNN Loss: 6.226988792419434 | BCE Loss: 1.040026068687439\n",
      "Epoch 176 / 500 | iteration 15 / 30 | Total Loss: 1.0396384000778198 | KNN Loss: 6.226929664611816 | BCE Loss: 1.0396384000778198\n",
      "Epoch 176 / 500 | iteration 20 / 30 | Total Loss: 1.072645902633667 | KNN Loss: 6.227208614349365 | BCE Loss: 1.072645902633667\n",
      "Epoch 176 / 500 | iteration 25 / 30 | Total Loss: 1.037961721420288 | KNN Loss: 6.226843357086182 | BCE Loss: 1.037961721420288\n",
      "Epoch 177 / 500 | iteration 0 / 30 | Total Loss: 1.050337314605713 | KNN Loss: 6.227214813232422 | BCE Loss: 1.050337314605713\n",
      "Epoch 177 / 500 | iteration 5 / 30 | Total Loss: 1.0370136499404907 | KNN Loss: 6.227170944213867 | BCE Loss: 1.0370136499404907\n",
      "Epoch 177 / 500 | iteration 10 / 30 | Total Loss: 1.0532450675964355 | KNN Loss: 6.227004528045654 | BCE Loss: 1.0532450675964355\n",
      "Epoch 177 / 500 | iteration 15 / 30 | Total Loss: 1.0337945222854614 | KNN Loss: 6.227010726928711 | BCE Loss: 1.0337945222854614\n",
      "Epoch 177 / 500 | iteration 20 / 30 | Total Loss: 1.040244460105896 | KNN Loss: 6.226908206939697 | BCE Loss: 1.040244460105896\n",
      "Epoch 177 / 500 | iteration 25 / 30 | Total Loss: 1.0461996793746948 | KNN Loss: 6.226851463317871 | BCE Loss: 1.0461996793746948\n",
      "Epoch 178 / 500 | iteration 0 / 30 | Total Loss: 1.0361049175262451 | KNN Loss: 6.226670742034912 | BCE Loss: 1.0361049175262451\n",
      "Epoch 178 / 500 | iteration 5 / 30 | Total Loss: 1.0137227773666382 | KNN Loss: 6.226818561553955 | BCE Loss: 1.0137227773666382\n",
      "Epoch 178 / 500 | iteration 10 / 30 | Total Loss: 1.040785551071167 | KNN Loss: 6.227036952972412 | BCE Loss: 1.040785551071167\n",
      "Epoch 178 / 500 | iteration 15 / 30 | Total Loss: 1.0843027830123901 | KNN Loss: 6.227161407470703 | BCE Loss: 1.0843027830123901\n",
      "Epoch 178 / 500 | iteration 20 / 30 | Total Loss: 1.0319974422454834 | KNN Loss: 6.2268195152282715 | BCE Loss: 1.0319974422454834\n",
      "Epoch 178 / 500 | iteration 25 / 30 | Total Loss: 1.0677900314331055 | KNN Loss: 6.226677894592285 | BCE Loss: 1.0677900314331055\n",
      "Epoch 179 / 500 | iteration 0 / 30 | Total Loss: 1.0546648502349854 | KNN Loss: 6.226779937744141 | BCE Loss: 1.0546648502349854\n",
      "Epoch 179 / 500 | iteration 5 / 30 | Total Loss: 1.0522139072418213 | KNN Loss: 6.2270379066467285 | BCE Loss: 1.0522139072418213\n",
      "Epoch 179 / 500 | iteration 10 / 30 | Total Loss: 1.0672998428344727 | KNN Loss: 6.226896286010742 | BCE Loss: 1.0672998428344727\n",
      "Epoch 179 / 500 | iteration 15 / 30 | Total Loss: 1.0526866912841797 | KNN Loss: 6.226995944976807 | BCE Loss: 1.0526866912841797\n",
      "Epoch 179 / 500 | iteration 20 / 30 | Total Loss: 1.0675995349884033 | KNN Loss: 6.226757526397705 | BCE Loss: 1.0675995349884033\n",
      "Epoch 179 / 500 | iteration 25 / 30 | Total Loss: 1.0765156745910645 | KNN Loss: 6.2272210121154785 | BCE Loss: 1.0765156745910645\n",
      "Epoch 180 / 500 | iteration 0 / 30 | Total Loss: 1.0481350421905518 | KNN Loss: 6.2269182205200195 | BCE Loss: 1.0481350421905518\n",
      "Epoch 180 / 500 | iteration 5 / 30 | Total Loss: 1.0381497144699097 | KNN Loss: 6.226628303527832 | BCE Loss: 1.0381497144699097\n",
      "Epoch 180 / 500 | iteration 10 / 30 | Total Loss: 1.0572696924209595 | KNN Loss: 6.226712226867676 | BCE Loss: 1.0572696924209595\n",
      "Epoch 180 / 500 | iteration 15 / 30 | Total Loss: 1.0744094848632812 | KNN Loss: 6.226888179779053 | BCE Loss: 1.0744094848632812\n",
      "Epoch 180 / 500 | iteration 20 / 30 | Total Loss: 1.0310527086257935 | KNN Loss: 6.226985931396484 | BCE Loss: 1.0310527086257935\n",
      "Epoch 180 / 500 | iteration 25 / 30 | Total Loss: 1.0599331855773926 | KNN Loss: 6.226973056793213 | BCE Loss: 1.0599331855773926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181 / 500 | iteration 0 / 30 | Total Loss: 1.0623252391815186 | KNN Loss: 6.226928234100342 | BCE Loss: 1.0623252391815186\n",
      "Epoch 181 / 500 | iteration 5 / 30 | Total Loss: 1.070289969444275 | KNN Loss: 6.22699499130249 | BCE Loss: 1.070289969444275\n",
      "Epoch 181 / 500 | iteration 10 / 30 | Total Loss: 1.02224600315094 | KNN Loss: 6.226816654205322 | BCE Loss: 1.02224600315094\n",
      "Epoch 181 / 500 | iteration 15 / 30 | Total Loss: 1.0373693704605103 | KNN Loss: 6.226861000061035 | BCE Loss: 1.0373693704605103\n",
      "Epoch 181 / 500 | iteration 20 / 30 | Total Loss: 1.0419515371322632 | KNN Loss: 6.2267680168151855 | BCE Loss: 1.0419515371322632\n",
      "Epoch 181 / 500 | iteration 25 / 30 | Total Loss: 1.0479635000228882 | KNN Loss: 6.226902484893799 | BCE Loss: 1.0479635000228882\n",
      "Epoch 182 / 500 | iteration 0 / 30 | Total Loss: 1.0527113676071167 | KNN Loss: 6.2272114753723145 | BCE Loss: 1.0527113676071167\n",
      "Epoch 182 / 500 | iteration 5 / 30 | Total Loss: 1.066657543182373 | KNN Loss: 6.226917743682861 | BCE Loss: 1.066657543182373\n",
      "Epoch 182 / 500 | iteration 10 / 30 | Total Loss: 1.0902104377746582 | KNN Loss: 6.2269511222839355 | BCE Loss: 1.0902104377746582\n",
      "Epoch 182 / 500 | iteration 15 / 30 | Total Loss: 1.079056978225708 | KNN Loss: 6.226633071899414 | BCE Loss: 1.079056978225708\n",
      "Epoch 182 / 500 | iteration 20 / 30 | Total Loss: 1.0506646633148193 | KNN Loss: 6.226741313934326 | BCE Loss: 1.0506646633148193\n",
      "Epoch 182 / 500 | iteration 25 / 30 | Total Loss: 1.0680177211761475 | KNN Loss: 6.2270355224609375 | BCE Loss: 1.0680177211761475\n",
      "Epoch   183: reducing learning rate of group 0 to 6.9206e-05.\n",
      "Epoch 183 / 500 | iteration 0 / 30 | Total Loss: 1.058112382888794 | KNN Loss: 6.2268171310424805 | BCE Loss: 1.058112382888794\n",
      "Epoch 183 / 500 | iteration 5 / 30 | Total Loss: 1.0562710762023926 | KNN Loss: 6.2271833419799805 | BCE Loss: 1.0562710762023926\n",
      "Epoch 183 / 500 | iteration 10 / 30 | Total Loss: 1.0308456420898438 | KNN Loss: 6.2267680168151855 | BCE Loss: 1.0308456420898438\n",
      "Epoch 183 / 500 | iteration 15 / 30 | Total Loss: 1.0562236309051514 | KNN Loss: 6.226953983306885 | BCE Loss: 1.0562236309051514\n",
      "Epoch 183 / 500 | iteration 20 / 30 | Total Loss: 1.054985761642456 | KNN Loss: 6.226814270019531 | BCE Loss: 1.054985761642456\n",
      "Epoch 183 / 500 | iteration 25 / 30 | Total Loss: 1.0570335388183594 | KNN Loss: 6.22681999206543 | BCE Loss: 1.0570335388183594\n",
      "Epoch 184 / 500 | iteration 0 / 30 | Total Loss: 1.068831205368042 | KNN Loss: 6.226973056793213 | BCE Loss: 1.068831205368042\n",
      "Epoch 184 / 500 | iteration 5 / 30 | Total Loss: 1.0541880130767822 | KNN Loss: 6.227050304412842 | BCE Loss: 1.0541880130767822\n",
      "Epoch 184 / 500 | iteration 10 / 30 | Total Loss: 1.0366429090499878 | KNN Loss: 6.226815700531006 | BCE Loss: 1.0366429090499878\n",
      "Epoch 184 / 500 | iteration 15 / 30 | Total Loss: 1.0749928951263428 | KNN Loss: 6.226778507232666 | BCE Loss: 1.0749928951263428\n",
      "Epoch 184 / 500 | iteration 20 / 30 | Total Loss: 1.0599218606948853 | KNN Loss: 6.226747512817383 | BCE Loss: 1.0599218606948853\n",
      "Epoch 184 / 500 | iteration 25 / 30 | Total Loss: 1.0567481517791748 | KNN Loss: 6.227161884307861 | BCE Loss: 1.0567481517791748\n",
      "Epoch 185 / 500 | iteration 0 / 30 | Total Loss: 1.0653469562530518 | KNN Loss: 6.227011203765869 | BCE Loss: 1.0653469562530518\n",
      "Epoch 185 / 500 | iteration 5 / 30 | Total Loss: 1.0818736553192139 | KNN Loss: 6.226644039154053 | BCE Loss: 1.0818736553192139\n",
      "Epoch 185 / 500 | iteration 10 / 30 | Total Loss: 1.0432994365692139 | KNN Loss: 6.226853370666504 | BCE Loss: 1.0432994365692139\n",
      "Epoch 185 / 500 | iteration 15 / 30 | Total Loss: 1.0529143810272217 | KNN Loss: 6.226420879364014 | BCE Loss: 1.0529143810272217\n",
      "Epoch 185 / 500 | iteration 20 / 30 | Total Loss: 1.0683982372283936 | KNN Loss: 6.227064609527588 | BCE Loss: 1.0683982372283936\n",
      "Epoch 185 / 500 | iteration 25 / 30 | Total Loss: 1.0184857845306396 | KNN Loss: 6.227204322814941 | BCE Loss: 1.0184857845306396\n",
      "Epoch 186 / 500 | iteration 0 / 30 | Total Loss: 1.0108040571212769 | KNN Loss: 6.226870536804199 | BCE Loss: 1.0108040571212769\n",
      "Epoch 186 / 500 | iteration 5 / 30 | Total Loss: 1.049993634223938 | KNN Loss: 6.22683048248291 | BCE Loss: 1.049993634223938\n",
      "Epoch 186 / 500 | iteration 10 / 30 | Total Loss: 1.0327353477478027 | KNN Loss: 6.2266740798950195 | BCE Loss: 1.0327353477478027\n",
      "Epoch 186 / 500 | iteration 15 / 30 | Total Loss: 1.029646396636963 | KNN Loss: 6.227055549621582 | BCE Loss: 1.029646396636963\n",
      "Epoch 186 / 500 | iteration 20 / 30 | Total Loss: 1.0733323097229004 | KNN Loss: 6.226921081542969 | BCE Loss: 1.0733323097229004\n",
      "Epoch 186 / 500 | iteration 25 / 30 | Total Loss: 1.065488576889038 | KNN Loss: 6.2269487380981445 | BCE Loss: 1.065488576889038\n",
      "Epoch 187 / 500 | iteration 0 / 30 | Total Loss: 1.0431981086730957 | KNN Loss: 6.226730823516846 | BCE Loss: 1.0431981086730957\n",
      "Epoch 187 / 500 | iteration 5 / 30 | Total Loss: 1.0415065288543701 | KNN Loss: 6.226743698120117 | BCE Loss: 1.0415065288543701\n",
      "Epoch 187 / 500 | iteration 10 / 30 | Total Loss: 1.063428282737732 | KNN Loss: 6.226799964904785 | BCE Loss: 1.063428282737732\n",
      "Epoch 187 / 500 | iteration 15 / 30 | Total Loss: 1.0679314136505127 | KNN Loss: 6.226912021636963 | BCE Loss: 1.0679314136505127\n",
      "Epoch 187 / 500 | iteration 20 / 30 | Total Loss: 1.0602290630340576 | KNN Loss: 6.226785182952881 | BCE Loss: 1.0602290630340576\n",
      "Epoch 187 / 500 | iteration 25 / 30 | Total Loss: 1.0499303340911865 | KNN Loss: 6.226986408233643 | BCE Loss: 1.0499303340911865\n",
      "Epoch 188 / 500 | iteration 0 / 30 | Total Loss: 1.037540078163147 | KNN Loss: 6.226886749267578 | BCE Loss: 1.037540078163147\n",
      "Epoch 188 / 500 | iteration 5 / 30 | Total Loss: 1.0834494829177856 | KNN Loss: 6.226849555969238 | BCE Loss: 1.0834494829177856\n",
      "Epoch 188 / 500 | iteration 10 / 30 | Total Loss: 1.0360130071640015 | KNN Loss: 6.227114677429199 | BCE Loss: 1.0360130071640015\n",
      "Epoch 188 / 500 | iteration 15 / 30 | Total Loss: 1.0557178258895874 | KNN Loss: 6.226827621459961 | BCE Loss: 1.0557178258895874\n",
      "Epoch 188 / 500 | iteration 20 / 30 | Total Loss: 1.0387256145477295 | KNN Loss: 6.2266740798950195 | BCE Loss: 1.0387256145477295\n",
      "Epoch 188 / 500 | iteration 25 / 30 | Total Loss: 1.067960500717163 | KNN Loss: 6.226678371429443 | BCE Loss: 1.067960500717163\n",
      "Epoch 189 / 500 | iteration 0 / 30 | Total Loss: 1.0544755458831787 | KNN Loss: 6.227144241333008 | BCE Loss: 1.0544755458831787\n",
      "Epoch 189 / 500 | iteration 5 / 30 | Total Loss: 1.0396056175231934 | KNN Loss: 6.22684907913208 | BCE Loss: 1.0396056175231934\n",
      "Epoch 189 / 500 | iteration 10 / 30 | Total Loss: 1.0714644193649292 | KNN Loss: 6.226832389831543 | BCE Loss: 1.0714644193649292\n",
      "Epoch 189 / 500 | iteration 15 / 30 | Total Loss: 1.0238229036331177 | KNN Loss: 6.227059841156006 | BCE Loss: 1.0238229036331177\n",
      "Epoch 189 / 500 | iteration 20 / 30 | Total Loss: 1.0608716011047363 | KNN Loss: 6.226625919342041 | BCE Loss: 1.0608716011047363\n",
      "Epoch 189 / 500 | iteration 25 / 30 | Total Loss: 1.0625064373016357 | KNN Loss: 6.226836204528809 | BCE Loss: 1.0625064373016357\n",
      "Epoch 190 / 500 | iteration 0 / 30 | Total Loss: 1.0606205463409424 | KNN Loss: 6.226644515991211 | BCE Loss: 1.0606205463409424\n",
      "Epoch 190 / 500 | iteration 5 / 30 | Total Loss: 1.0717874765396118 | KNN Loss: 6.227052688598633 | BCE Loss: 1.0717874765396118\n",
      "Epoch 190 / 500 | iteration 10 / 30 | Total Loss: 1.0421957969665527 | KNN Loss: 6.22687292098999 | BCE Loss: 1.0421957969665527\n",
      "Epoch 190 / 500 | iteration 15 / 30 | Total Loss: 1.0461019277572632 | KNN Loss: 6.227092742919922 | BCE Loss: 1.0461019277572632\n",
      "Epoch 190 / 500 | iteration 20 / 30 | Total Loss: 1.0342669486999512 | KNN Loss: 6.226537704467773 | BCE Loss: 1.0342669486999512\n",
      "Epoch 190 / 500 | iteration 25 / 30 | Total Loss: 1.0244622230529785 | KNN Loss: 6.226842880249023 | BCE Loss: 1.0244622230529785\n",
      "Epoch 191 / 500 | iteration 0 / 30 | Total Loss: 1.0712854862213135 | KNN Loss: 6.226918697357178 | BCE Loss: 1.0712854862213135\n",
      "Epoch 191 / 500 | iteration 5 / 30 | Total Loss: 1.0707956552505493 | KNN Loss: 6.226965427398682 | BCE Loss: 1.0707956552505493\n",
      "Epoch 191 / 500 | iteration 10 / 30 | Total Loss: 1.0166056156158447 | KNN Loss: 6.22660493850708 | BCE Loss: 1.0166056156158447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191 / 500 | iteration 15 / 30 | Total Loss: 1.0322407484054565 | KNN Loss: 6.227099418640137 | BCE Loss: 1.0322407484054565\n",
      "Epoch 191 / 500 | iteration 20 / 30 | Total Loss: 1.0836859941482544 | KNN Loss: 6.22698450088501 | BCE Loss: 1.0836859941482544\n",
      "Epoch 191 / 500 | iteration 25 / 30 | Total Loss: 1.0590853691101074 | KNN Loss: 6.22674036026001 | BCE Loss: 1.0590853691101074\n",
      "Epoch 192 / 500 | iteration 0 / 30 | Total Loss: 1.0102930068969727 | KNN Loss: 6.2269110679626465 | BCE Loss: 1.0102930068969727\n",
      "Epoch 192 / 500 | iteration 5 / 30 | Total Loss: 1.0650807619094849 | KNN Loss: 6.226867198944092 | BCE Loss: 1.0650807619094849\n",
      "Epoch 192 / 500 | iteration 10 / 30 | Total Loss: 1.0559502840042114 | KNN Loss: 6.226860523223877 | BCE Loss: 1.0559502840042114\n",
      "Epoch 192 / 500 | iteration 15 / 30 | Total Loss: 1.0615205764770508 | KNN Loss: 6.226774215698242 | BCE Loss: 1.0615205764770508\n",
      "Epoch 192 / 500 | iteration 20 / 30 | Total Loss: 1.0490975379943848 | KNN Loss: 6.226949691772461 | BCE Loss: 1.0490975379943848\n",
      "Epoch 192 / 500 | iteration 25 / 30 | Total Loss: 1.0588222742080688 | KNN Loss: 6.226785659790039 | BCE Loss: 1.0588222742080688\n",
      "Epoch 193 / 500 | iteration 0 / 30 | Total Loss: 1.0261344909667969 | KNN Loss: 6.22695255279541 | BCE Loss: 1.0261344909667969\n",
      "Epoch 193 / 500 | iteration 5 / 30 | Total Loss: 1.0636756420135498 | KNN Loss: 6.227022647857666 | BCE Loss: 1.0636756420135498\n",
      "Epoch 193 / 500 | iteration 10 / 30 | Total Loss: 1.04628586769104 | KNN Loss: 6.226791858673096 | BCE Loss: 1.04628586769104\n",
      "Epoch 193 / 500 | iteration 15 / 30 | Total Loss: 1.0922322273254395 | KNN Loss: 6.226964473724365 | BCE Loss: 1.0922322273254395\n",
      "Epoch 193 / 500 | iteration 20 / 30 | Total Loss: 1.033879041671753 | KNN Loss: 6.227024555206299 | BCE Loss: 1.033879041671753\n",
      "Epoch 193 / 500 | iteration 25 / 30 | Total Loss: 1.0366387367248535 | KNN Loss: 6.22713041305542 | BCE Loss: 1.0366387367248535\n",
      "Epoch   194: reducing learning rate of group 0 to 4.8445e-05.\n",
      "Epoch 194 / 500 | iteration 0 / 30 | Total Loss: 1.0410444736480713 | KNN Loss: 6.226754665374756 | BCE Loss: 1.0410444736480713\n",
      "Epoch 194 / 500 | iteration 5 / 30 | Total Loss: 1.0510790348052979 | KNN Loss: 6.226794242858887 | BCE Loss: 1.0510790348052979\n",
      "Epoch 194 / 500 | iteration 10 / 30 | Total Loss: 1.0598224401474 | KNN Loss: 6.22711181640625 | BCE Loss: 1.0598224401474\n",
      "Epoch 194 / 500 | iteration 15 / 30 | Total Loss: 1.0301804542541504 | KNN Loss: 6.226596355438232 | BCE Loss: 1.0301804542541504\n",
      "Epoch 194 / 500 | iteration 20 / 30 | Total Loss: 1.037071943283081 | KNN Loss: 6.2269158363342285 | BCE Loss: 1.037071943283081\n",
      "Epoch 194 / 500 | iteration 25 / 30 | Total Loss: 1.0590438842773438 | KNN Loss: 6.227200984954834 | BCE Loss: 1.0590438842773438\n",
      "Epoch 195 / 500 | iteration 0 / 30 | Total Loss: 1.0636135339736938 | KNN Loss: 6.226876258850098 | BCE Loss: 1.0636135339736938\n",
      "Epoch 195 / 500 | iteration 5 / 30 | Total Loss: 1.062950849533081 | KNN Loss: 6.226813316345215 | BCE Loss: 1.062950849533081\n",
      "Epoch 195 / 500 | iteration 10 / 30 | Total Loss: 1.0376684665679932 | KNN Loss: 6.226905345916748 | BCE Loss: 1.0376684665679932\n",
      "Epoch 195 / 500 | iteration 15 / 30 | Total Loss: 1.0583820343017578 | KNN Loss: 6.2270026206970215 | BCE Loss: 1.0583820343017578\n",
      "Epoch 195 / 500 | iteration 20 / 30 | Total Loss: 1.0431445837020874 | KNN Loss: 6.226804256439209 | BCE Loss: 1.0431445837020874\n",
      "Epoch 195 / 500 | iteration 25 / 30 | Total Loss: 1.0423922538757324 | KNN Loss: 6.226749420166016 | BCE Loss: 1.0423922538757324\n",
      "Epoch 196 / 500 | iteration 0 / 30 | Total Loss: 1.07097327709198 | KNN Loss: 6.226642608642578 | BCE Loss: 1.07097327709198\n",
      "Epoch 196 / 500 | iteration 5 / 30 | Total Loss: 1.0398218631744385 | KNN Loss: 6.226996421813965 | BCE Loss: 1.0398218631744385\n",
      "Epoch 196 / 500 | iteration 10 / 30 | Total Loss: 1.037590503692627 | KNN Loss: 6.226767063140869 | BCE Loss: 1.037590503692627\n",
      "Epoch 196 / 500 | iteration 15 / 30 | Total Loss: 1.0611933469772339 | KNN Loss: 6.226845741271973 | BCE Loss: 1.0611933469772339\n",
      "Epoch 196 / 500 | iteration 20 / 30 | Total Loss: 1.0782124996185303 | KNN Loss: 6.226840019226074 | BCE Loss: 1.0782124996185303\n",
      "Epoch 196 / 500 | iteration 25 / 30 | Total Loss: 1.0374246835708618 | KNN Loss: 6.226752758026123 | BCE Loss: 1.0374246835708618\n",
      "Epoch 197 / 500 | iteration 0 / 30 | Total Loss: 1.0525791645050049 | KNN Loss: 6.226985454559326 | BCE Loss: 1.0525791645050049\n",
      "Epoch 197 / 500 | iteration 5 / 30 | Total Loss: 1.046626091003418 | KNN Loss: 6.226656913757324 | BCE Loss: 1.046626091003418\n",
      "Epoch 197 / 500 | iteration 10 / 30 | Total Loss: 1.0453498363494873 | KNN Loss: 6.227035999298096 | BCE Loss: 1.0453498363494873\n",
      "Epoch 197 / 500 | iteration 15 / 30 | Total Loss: 1.0563137531280518 | KNN Loss: 6.227020740509033 | BCE Loss: 1.0563137531280518\n",
      "Epoch 197 / 500 | iteration 20 / 30 | Total Loss: 1.0486640930175781 | KNN Loss: 6.226912498474121 | BCE Loss: 1.0486640930175781\n",
      "Epoch 197 / 500 | iteration 25 / 30 | Total Loss: 1.0512375831604004 | KNN Loss: 6.227133750915527 | BCE Loss: 1.0512375831604004\n",
      "Epoch 198 / 500 | iteration 0 / 30 | Total Loss: 1.045201301574707 | KNN Loss: 6.226998329162598 | BCE Loss: 1.045201301574707\n",
      "Epoch 198 / 500 | iteration 5 / 30 | Total Loss: 1.0608816146850586 | KNN Loss: 6.226829528808594 | BCE Loss: 1.0608816146850586\n",
      "Epoch 198 / 500 | iteration 10 / 30 | Total Loss: 1.021355390548706 | KNN Loss: 6.2268500328063965 | BCE Loss: 1.021355390548706\n",
      "Epoch 198 / 500 | iteration 15 / 30 | Total Loss: 1.0569521188735962 | KNN Loss: 6.226806640625 | BCE Loss: 1.0569521188735962\n",
      "Epoch 198 / 500 | iteration 20 / 30 | Total Loss: 1.0454039573669434 | KNN Loss: 6.226828098297119 | BCE Loss: 1.0454039573669434\n",
      "Epoch 198 / 500 | iteration 25 / 30 | Total Loss: 1.0682556629180908 | KNN Loss: 6.226897239685059 | BCE Loss: 1.0682556629180908\n",
      "Epoch 199 / 500 | iteration 0 / 30 | Total Loss: 1.0265178680419922 | KNN Loss: 6.226614475250244 | BCE Loss: 1.0265178680419922\n",
      "Epoch 199 / 500 | iteration 5 / 30 | Total Loss: 1.0676636695861816 | KNN Loss: 6.226587295532227 | BCE Loss: 1.0676636695861816\n",
      "Epoch 199 / 500 | iteration 10 / 30 | Total Loss: 1.0632431507110596 | KNN Loss: 6.226860523223877 | BCE Loss: 1.0632431507110596\n",
      "Epoch 199 / 500 | iteration 15 / 30 | Total Loss: 1.0850205421447754 | KNN Loss: 6.227388381958008 | BCE Loss: 1.0850205421447754\n",
      "Epoch 199 / 500 | iteration 20 / 30 | Total Loss: 1.0985689163208008 | KNN Loss: 6.2266459465026855 | BCE Loss: 1.0985689163208008\n",
      "Epoch 199 / 500 | iteration 25 / 30 | Total Loss: 1.040287733078003 | KNN Loss: 6.226975917816162 | BCE Loss: 1.040287733078003\n",
      "Epoch 200 / 500 | iteration 0 / 30 | Total Loss: 1.0340850353240967 | KNN Loss: 6.2267279624938965 | BCE Loss: 1.0340850353240967\n",
      "Epoch 200 / 500 | iteration 5 / 30 | Total Loss: 1.031947135925293 | KNN Loss: 6.226814270019531 | BCE Loss: 1.031947135925293\n",
      "Epoch 200 / 500 | iteration 10 / 30 | Total Loss: 1.0506563186645508 | KNN Loss: 6.22687292098999 | BCE Loss: 1.0506563186645508\n",
      "Epoch 200 / 500 | iteration 15 / 30 | Total Loss: 1.0487393140792847 | KNN Loss: 6.226799011230469 | BCE Loss: 1.0487393140792847\n",
      "Epoch 200 / 500 | iteration 20 / 30 | Total Loss: 1.0614856481552124 | KNN Loss: 6.226527690887451 | BCE Loss: 1.0614856481552124\n",
      "Epoch 200 / 500 | iteration 25 / 30 | Total Loss: 1.049246907234192 | KNN Loss: 6.227020263671875 | BCE Loss: 1.049246907234192\n",
      "Epoch 201 / 500 | iteration 0 / 30 | Total Loss: 1.0364432334899902 | KNN Loss: 6.22704553604126 | BCE Loss: 1.0364432334899902\n",
      "Epoch 201 / 500 | iteration 5 / 30 | Total Loss: 1.0289571285247803 | KNN Loss: 6.226868629455566 | BCE Loss: 1.0289571285247803\n",
      "Epoch 201 / 500 | iteration 10 / 30 | Total Loss: 1.0613079071044922 | KNN Loss: 6.2268500328063965 | BCE Loss: 1.0613079071044922\n",
      "Epoch 201 / 500 | iteration 15 / 30 | Total Loss: 1.0475578308105469 | KNN Loss: 6.226929664611816 | BCE Loss: 1.0475578308105469\n",
      "Epoch 201 / 500 | iteration 20 / 30 | Total Loss: 1.0641968250274658 | KNN Loss: 6.2269697189331055 | BCE Loss: 1.0641968250274658\n",
      "Epoch 201 / 500 | iteration 25 / 30 | Total Loss: 1.051313877105713 | KNN Loss: 6.226441383361816 | BCE Loss: 1.051313877105713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202 / 500 | iteration 0 / 30 | Total Loss: 1.0554401874542236 | KNN Loss: 6.226815700531006 | BCE Loss: 1.0554401874542236\n",
      "Epoch 202 / 500 | iteration 5 / 30 | Total Loss: 1.070899248123169 | KNN Loss: 6.2269368171691895 | BCE Loss: 1.070899248123169\n",
      "Epoch 202 / 500 | iteration 10 / 30 | Total Loss: 1.049095630645752 | KNN Loss: 6.22702169418335 | BCE Loss: 1.049095630645752\n",
      "Epoch 202 / 500 | iteration 15 / 30 | Total Loss: 1.040338158607483 | KNN Loss: 6.226525783538818 | BCE Loss: 1.040338158607483\n",
      "Epoch 202 / 500 | iteration 20 / 30 | Total Loss: 1.0707011222839355 | KNN Loss: 6.226597785949707 | BCE Loss: 1.0707011222839355\n",
      "Epoch 202 / 500 | iteration 25 / 30 | Total Loss: 1.0314799547195435 | KNN Loss: 6.226867198944092 | BCE Loss: 1.0314799547195435\n",
      "Epoch 203 / 500 | iteration 0 / 30 | Total Loss: 1.0740795135498047 | KNN Loss: 6.226897239685059 | BCE Loss: 1.0740795135498047\n",
      "Epoch 203 / 500 | iteration 5 / 30 | Total Loss: 1.0412496328353882 | KNN Loss: 6.227119445800781 | BCE Loss: 1.0412496328353882\n",
      "Epoch 203 / 500 | iteration 10 / 30 | Total Loss: 1.0372880697250366 | KNN Loss: 6.226468563079834 | BCE Loss: 1.0372880697250366\n",
      "Epoch 203 / 500 | iteration 15 / 30 | Total Loss: 1.0348793268203735 | KNN Loss: 6.226770877838135 | BCE Loss: 1.0348793268203735\n",
      "Epoch 203 / 500 | iteration 20 / 30 | Total Loss: 1.0676119327545166 | KNN Loss: 6.227097034454346 | BCE Loss: 1.0676119327545166\n",
      "Epoch 203 / 500 | iteration 25 / 30 | Total Loss: 1.059637427330017 | KNN Loss: 6.226899147033691 | BCE Loss: 1.059637427330017\n",
      "Epoch 204 / 500 | iteration 0 / 30 | Total Loss: 1.0736361742019653 | KNN Loss: 6.22674560546875 | BCE Loss: 1.0736361742019653\n",
      "Epoch 204 / 500 | iteration 5 / 30 | Total Loss: 1.050387978553772 | KNN Loss: 6.2266845703125 | BCE Loss: 1.050387978553772\n",
      "Epoch 204 / 500 | iteration 10 / 30 | Total Loss: 1.0515282154083252 | KNN Loss: 6.226909637451172 | BCE Loss: 1.0515282154083252\n",
      "Epoch 204 / 500 | iteration 15 / 30 | Total Loss: 1.058304786682129 | KNN Loss: 6.22683572769165 | BCE Loss: 1.058304786682129\n",
      "Epoch 204 / 500 | iteration 20 / 30 | Total Loss: 1.052509069442749 | KNN Loss: 6.22687292098999 | BCE Loss: 1.052509069442749\n",
      "Epoch 204 / 500 | iteration 25 / 30 | Total Loss: 1.0274763107299805 | KNN Loss: 6.226455211639404 | BCE Loss: 1.0274763107299805\n",
      "Epoch   205: reducing learning rate of group 0 to 3.3911e-05.\n",
      "Epoch 205 / 500 | iteration 0 / 30 | Total Loss: 1.0444755554199219 | KNN Loss: 6.227321624755859 | BCE Loss: 1.0444755554199219\n",
      "Epoch 205 / 500 | iteration 5 / 30 | Total Loss: 1.0696539878845215 | KNN Loss: 6.226856708526611 | BCE Loss: 1.0696539878845215\n",
      "Epoch 205 / 500 | iteration 10 / 30 | Total Loss: 1.0520118474960327 | KNN Loss: 6.2264885902404785 | BCE Loss: 1.0520118474960327\n",
      "Epoch 205 / 500 | iteration 15 / 30 | Total Loss: 1.0393860340118408 | KNN Loss: 6.226828575134277 | BCE Loss: 1.0393860340118408\n",
      "Epoch 205 / 500 | iteration 20 / 30 | Total Loss: 1.038490653038025 | KNN Loss: 6.227095603942871 | BCE Loss: 1.038490653038025\n",
      "Epoch 205 / 500 | iteration 25 / 30 | Total Loss: 1.0559751987457275 | KNN Loss: 6.227104187011719 | BCE Loss: 1.0559751987457275\n",
      "Epoch 206 / 500 | iteration 0 / 30 | Total Loss: 1.0324028730392456 | KNN Loss: 6.226781368255615 | BCE Loss: 1.0324028730392456\n",
      "Epoch 206 / 500 | iteration 5 / 30 | Total Loss: 1.0390515327453613 | KNN Loss: 6.22715950012207 | BCE Loss: 1.0390515327453613\n",
      "Epoch 206 / 500 | iteration 10 / 30 | Total Loss: 1.041121482849121 | KNN Loss: 6.226766586303711 | BCE Loss: 1.041121482849121\n",
      "Epoch 206 / 500 | iteration 15 / 30 | Total Loss: 1.0425734519958496 | KNN Loss: 6.226792335510254 | BCE Loss: 1.0425734519958496\n",
      "Epoch 206 / 500 | iteration 20 / 30 | Total Loss: 1.0658973455429077 | KNN Loss: 6.227229595184326 | BCE Loss: 1.0658973455429077\n",
      "Epoch 206 / 500 | iteration 25 / 30 | Total Loss: 1.0852984189987183 | KNN Loss: 6.2271575927734375 | BCE Loss: 1.0852984189987183\n",
      "Epoch 207 / 500 | iteration 0 / 30 | Total Loss: 1.0544919967651367 | KNN Loss: 6.226837158203125 | BCE Loss: 1.0544919967651367\n",
      "Epoch 207 / 500 | iteration 5 / 30 | Total Loss: 1.0606238842010498 | KNN Loss: 6.227045059204102 | BCE Loss: 1.0606238842010498\n",
      "Epoch 207 / 500 | iteration 10 / 30 | Total Loss: 1.0236570835113525 | KNN Loss: 6.226874828338623 | BCE Loss: 1.0236570835113525\n",
      "Epoch 207 / 500 | iteration 15 / 30 | Total Loss: 1.0486977100372314 | KNN Loss: 6.226780414581299 | BCE Loss: 1.0486977100372314\n",
      "Epoch 207 / 500 | iteration 20 / 30 | Total Loss: 1.0214662551879883 | KNN Loss: 6.227034568786621 | BCE Loss: 1.0214662551879883\n",
      "Epoch 207 / 500 | iteration 25 / 30 | Total Loss: 1.0467019081115723 | KNN Loss: 6.22700834274292 | BCE Loss: 1.0467019081115723\n",
      "Epoch 208 / 500 | iteration 0 / 30 | Total Loss: 1.0378018617630005 | KNN Loss: 6.22672700881958 | BCE Loss: 1.0378018617630005\n",
      "Epoch 208 / 500 | iteration 5 / 30 | Total Loss: 1.068539023399353 | KNN Loss: 6.226901531219482 | BCE Loss: 1.068539023399353\n",
      "Epoch 208 / 500 | iteration 10 / 30 | Total Loss: 1.04177987575531 | KNN Loss: 6.226948261260986 | BCE Loss: 1.04177987575531\n",
      "Epoch 208 / 500 | iteration 15 / 30 | Total Loss: 1.0634121894836426 | KNN Loss: 6.227055072784424 | BCE Loss: 1.0634121894836426\n",
      "Epoch 208 / 500 | iteration 20 / 30 | Total Loss: 1.040644645690918 | KNN Loss: 6.226739406585693 | BCE Loss: 1.040644645690918\n",
      "Epoch 208 / 500 | iteration 25 / 30 | Total Loss: 1.0488865375518799 | KNN Loss: 6.22694206237793 | BCE Loss: 1.0488865375518799\n",
      "Epoch 209 / 500 | iteration 0 / 30 | Total Loss: 1.0596401691436768 | KNN Loss: 6.227215766906738 | BCE Loss: 1.0596401691436768\n",
      "Epoch 209 / 500 | iteration 5 / 30 | Total Loss: 1.0610978603363037 | KNN Loss: 6.227084159851074 | BCE Loss: 1.0610978603363037\n",
      "Epoch 209 / 500 | iteration 10 / 30 | Total Loss: 1.0466282367706299 | KNN Loss: 6.226902484893799 | BCE Loss: 1.0466282367706299\n",
      "Epoch 209 / 500 | iteration 15 / 30 | Total Loss: 1.0638219118118286 | KNN Loss: 6.226923942565918 | BCE Loss: 1.0638219118118286\n",
      "Epoch 209 / 500 | iteration 20 / 30 | Total Loss: 1.0528439283370972 | KNN Loss: 6.226841926574707 | BCE Loss: 1.0528439283370972\n",
      "Epoch 209 / 500 | iteration 25 / 30 | Total Loss: 1.0462234020233154 | KNN Loss: 6.226717472076416 | BCE Loss: 1.0462234020233154\n",
      "Epoch 210 / 500 | iteration 0 / 30 | Total Loss: 1.0486512184143066 | KNN Loss: 6.2269439697265625 | BCE Loss: 1.0486512184143066\n",
      "Epoch 210 / 500 | iteration 5 / 30 | Total Loss: 1.0542160272598267 | KNN Loss: 6.226855754852295 | BCE Loss: 1.0542160272598267\n",
      "Epoch 210 / 500 | iteration 10 / 30 | Total Loss: 1.0621323585510254 | KNN Loss: 6.226945400238037 | BCE Loss: 1.0621323585510254\n",
      "Epoch 210 / 500 | iteration 15 / 30 | Total Loss: 1.056532859802246 | KNN Loss: 6.226937770843506 | BCE Loss: 1.056532859802246\n",
      "Epoch 210 / 500 | iteration 20 / 30 | Total Loss: 1.0138872861862183 | KNN Loss: 6.226639270782471 | BCE Loss: 1.0138872861862183\n",
      "Epoch 210 / 500 | iteration 25 / 30 | Total Loss: 1.035966396331787 | KNN Loss: 6.226748943328857 | BCE Loss: 1.035966396331787\n",
      "Epoch 211 / 500 | iteration 0 / 30 | Total Loss: 1.0508009195327759 | KNN Loss: 6.2268242835998535 | BCE Loss: 1.0508009195327759\n",
      "Epoch 211 / 500 | iteration 5 / 30 | Total Loss: 1.067164659500122 | KNN Loss: 6.227025985717773 | BCE Loss: 1.067164659500122\n",
      "Epoch 211 / 500 | iteration 10 / 30 | Total Loss: 1.0687439441680908 | KNN Loss: 6.226818561553955 | BCE Loss: 1.0687439441680908\n",
      "Epoch 211 / 500 | iteration 15 / 30 | Total Loss: 1.0606513023376465 | KNN Loss: 6.226743221282959 | BCE Loss: 1.0606513023376465\n",
      "Epoch 211 / 500 | iteration 20 / 30 | Total Loss: 1.0431510210037231 | KNN Loss: 6.226644992828369 | BCE Loss: 1.0431510210037231\n",
      "Epoch 211 / 500 | iteration 25 / 30 | Total Loss: 1.0394418239593506 | KNN Loss: 6.226737022399902 | BCE Loss: 1.0394418239593506\n",
      "Epoch 212 / 500 | iteration 0 / 30 | Total Loss: 1.0498971939086914 | KNN Loss: 6.2268171310424805 | BCE Loss: 1.0498971939086914\n",
      "Epoch 212 / 500 | iteration 5 / 30 | Total Loss: 1.0417195558547974 | KNN Loss: 6.227004528045654 | BCE Loss: 1.0417195558547974\n",
      "Epoch 212 / 500 | iteration 10 / 30 | Total Loss: 1.0638086795806885 | KNN Loss: 6.22693395614624 | BCE Loss: 1.0638086795806885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212 / 500 | iteration 15 / 30 | Total Loss: 1.0406173467636108 | KNN Loss: 6.226927757263184 | BCE Loss: 1.0406173467636108\n",
      "Epoch 212 / 500 | iteration 20 / 30 | Total Loss: 1.044654369354248 | KNN Loss: 6.2265472412109375 | BCE Loss: 1.044654369354248\n",
      "Epoch 212 / 500 | iteration 25 / 30 | Total Loss: 1.0590059757232666 | KNN Loss: 6.226870536804199 | BCE Loss: 1.0590059757232666\n",
      "Epoch 213 / 500 | iteration 0 / 30 | Total Loss: 1.036024808883667 | KNN Loss: 6.227085113525391 | BCE Loss: 1.036024808883667\n",
      "Epoch 213 / 500 | iteration 5 / 30 | Total Loss: 1.0623430013656616 | KNN Loss: 6.226907253265381 | BCE Loss: 1.0623430013656616\n",
      "Epoch 213 / 500 | iteration 10 / 30 | Total Loss: 1.050119400024414 | KNN Loss: 6.226696491241455 | BCE Loss: 1.050119400024414\n",
      "Epoch 213 / 500 | iteration 15 / 30 | Total Loss: 1.0394859313964844 | KNN Loss: 6.2268147468566895 | BCE Loss: 1.0394859313964844\n",
      "Epoch 213 / 500 | iteration 20 / 30 | Total Loss: 1.0428714752197266 | KNN Loss: 6.226780414581299 | BCE Loss: 1.0428714752197266\n",
      "Epoch 213 / 500 | iteration 25 / 30 | Total Loss: 1.0607807636260986 | KNN Loss: 6.226471900939941 | BCE Loss: 1.0607807636260986\n",
      "Epoch 214 / 500 | iteration 0 / 30 | Total Loss: 1.0677896738052368 | KNN Loss: 6.227095603942871 | BCE Loss: 1.0677896738052368\n",
      "Epoch 214 / 500 | iteration 5 / 30 | Total Loss: 1.0206024646759033 | KNN Loss: 6.2273030281066895 | BCE Loss: 1.0206024646759033\n",
      "Epoch 214 / 500 | iteration 10 / 30 | Total Loss: 1.0683118104934692 | KNN Loss: 6.22698974609375 | BCE Loss: 1.0683118104934692\n",
      "Epoch 214 / 500 | iteration 15 / 30 | Total Loss: 1.0524903535842896 | KNN Loss: 6.2268195152282715 | BCE Loss: 1.0524903535842896\n",
      "Epoch 214 / 500 | iteration 20 / 30 | Total Loss: 1.0567295551300049 | KNN Loss: 6.227048397064209 | BCE Loss: 1.0567295551300049\n",
      "Epoch 214 / 500 | iteration 25 / 30 | Total Loss: 1.0540803670883179 | KNN Loss: 6.22706937789917 | BCE Loss: 1.0540803670883179\n",
      "Epoch 215 / 500 | iteration 0 / 30 | Total Loss: 1.073466181755066 | KNN Loss: 6.226885795593262 | BCE Loss: 1.073466181755066\n",
      "Epoch 215 / 500 | iteration 5 / 30 | Total Loss: 1.0302956104278564 | KNN Loss: 6.226815700531006 | BCE Loss: 1.0302956104278564\n",
      "Epoch 215 / 500 | iteration 10 / 30 | Total Loss: 1.0474128723144531 | KNN Loss: 6.226726531982422 | BCE Loss: 1.0474128723144531\n",
      "Epoch 215 / 500 | iteration 15 / 30 | Total Loss: 1.0572595596313477 | KNN Loss: 6.226822853088379 | BCE Loss: 1.0572595596313477\n",
      "Epoch 215 / 500 | iteration 20 / 30 | Total Loss: 1.0404726266860962 | KNN Loss: 6.226942539215088 | BCE Loss: 1.0404726266860962\n",
      "Epoch 215 / 500 | iteration 25 / 30 | Total Loss: 1.0374051332473755 | KNN Loss: 6.226667881011963 | BCE Loss: 1.0374051332473755\n",
      "Epoch   216: reducing learning rate of group 0 to 2.3738e-05.\n",
      "Epoch 216 / 500 | iteration 0 / 30 | Total Loss: 1.0725756883621216 | KNN Loss: 6.2269287109375 | BCE Loss: 1.0725756883621216\n",
      "Epoch 216 / 500 | iteration 5 / 30 | Total Loss: 1.0554907321929932 | KNN Loss: 6.226561069488525 | BCE Loss: 1.0554907321929932\n",
      "Epoch 216 / 500 | iteration 10 / 30 | Total Loss: 1.0601593255996704 | KNN Loss: 6.226980686187744 | BCE Loss: 1.0601593255996704\n",
      "Epoch 216 / 500 | iteration 15 / 30 | Total Loss: 1.0518364906311035 | KNN Loss: 6.22659969329834 | BCE Loss: 1.0518364906311035\n",
      "Epoch 216 / 500 | iteration 20 / 30 | Total Loss: 1.0569264888763428 | KNN Loss: 6.227184295654297 | BCE Loss: 1.0569264888763428\n",
      "Epoch 216 / 500 | iteration 25 / 30 | Total Loss: 1.064979076385498 | KNN Loss: 6.226953029632568 | BCE Loss: 1.064979076385498\n",
      "Epoch 217 / 500 | iteration 0 / 30 | Total Loss: 1.0848591327667236 | KNN Loss: 6.226986885070801 | BCE Loss: 1.0848591327667236\n",
      "Epoch 217 / 500 | iteration 5 / 30 | Total Loss: 1.0754599571228027 | KNN Loss: 6.22681188583374 | BCE Loss: 1.0754599571228027\n",
      "Epoch 217 / 500 | iteration 10 / 30 | Total Loss: 1.0519096851348877 | KNN Loss: 6.226724147796631 | BCE Loss: 1.0519096851348877\n",
      "Epoch 217 / 500 | iteration 15 / 30 | Total Loss: 1.0608909130096436 | KNN Loss: 6.226863861083984 | BCE Loss: 1.0608909130096436\n",
      "Epoch 217 / 500 | iteration 20 / 30 | Total Loss: 1.0520685911178589 | KNN Loss: 6.226778984069824 | BCE Loss: 1.0520685911178589\n",
      "Epoch 217 / 500 | iteration 25 / 30 | Total Loss: 1.0607434511184692 | KNN Loss: 6.226922988891602 | BCE Loss: 1.0607434511184692\n",
      "Epoch 218 / 500 | iteration 0 / 30 | Total Loss: 1.0387930870056152 | KNN Loss: 6.226893424987793 | BCE Loss: 1.0387930870056152\n",
      "Epoch 218 / 500 | iteration 5 / 30 | Total Loss: 1.044957160949707 | KNN Loss: 6.226754188537598 | BCE Loss: 1.044957160949707\n",
      "Epoch 218 / 500 | iteration 10 / 30 | Total Loss: 1.0723191499710083 | KNN Loss: 6.22713041305542 | BCE Loss: 1.0723191499710083\n",
      "Epoch 218 / 500 | iteration 15 / 30 | Total Loss: 1.0472142696380615 | KNN Loss: 6.226900100708008 | BCE Loss: 1.0472142696380615\n",
      "Epoch 218 / 500 | iteration 20 / 30 | Total Loss: 1.0373969078063965 | KNN Loss: 6.226770877838135 | BCE Loss: 1.0373969078063965\n",
      "Epoch 218 / 500 | iteration 25 / 30 | Total Loss: 1.0632874965667725 | KNN Loss: 6.22690486907959 | BCE Loss: 1.0632874965667725\n",
      "Epoch 219 / 500 | iteration 0 / 30 | Total Loss: 1.037858009338379 | KNN Loss: 6.22681188583374 | BCE Loss: 1.037858009338379\n",
      "Epoch 219 / 500 | iteration 5 / 30 | Total Loss: 1.0625014305114746 | KNN Loss: 6.226680755615234 | BCE Loss: 1.0625014305114746\n",
      "Epoch 219 / 500 | iteration 10 / 30 | Total Loss: 1.0392670631408691 | KNN Loss: 6.2272419929504395 | BCE Loss: 1.0392670631408691\n",
      "Epoch 219 / 500 | iteration 15 / 30 | Total Loss: 1.0368998050689697 | KNN Loss: 6.227155685424805 | BCE Loss: 1.0368998050689697\n",
      "Epoch 219 / 500 | iteration 20 / 30 | Total Loss: 1.041682243347168 | KNN Loss: 6.226648807525635 | BCE Loss: 1.041682243347168\n",
      "Epoch 219 / 500 | iteration 25 / 30 | Total Loss: 1.0549359321594238 | KNN Loss: 6.227214336395264 | BCE Loss: 1.0549359321594238\n",
      "Epoch 220 / 500 | iteration 0 / 30 | Total Loss: 1.0437746047973633 | KNN Loss: 6.226937294006348 | BCE Loss: 1.0437746047973633\n",
      "Epoch 220 / 500 | iteration 5 / 30 | Total Loss: 1.0483214855194092 | KNN Loss: 6.226764678955078 | BCE Loss: 1.0483214855194092\n",
      "Epoch 220 / 500 | iteration 10 / 30 | Total Loss: 1.0578644275665283 | KNN Loss: 6.226799964904785 | BCE Loss: 1.0578644275665283\n",
      "Epoch 220 / 500 | iteration 15 / 30 | Total Loss: 1.0416706800460815 | KNN Loss: 6.226817607879639 | BCE Loss: 1.0416706800460815\n",
      "Epoch 220 / 500 | iteration 20 / 30 | Total Loss: 1.0255299806594849 | KNN Loss: 6.226883888244629 | BCE Loss: 1.0255299806594849\n",
      "Epoch 220 / 500 | iteration 25 / 30 | Total Loss: 1.087754726409912 | KNN Loss: 6.227126121520996 | BCE Loss: 1.087754726409912\n",
      "Epoch 221 / 500 | iteration 0 / 30 | Total Loss: 1.0486342906951904 | KNN Loss: 6.226838111877441 | BCE Loss: 1.0486342906951904\n",
      "Epoch 221 / 500 | iteration 5 / 30 | Total Loss: 1.0602483749389648 | KNN Loss: 6.22715950012207 | BCE Loss: 1.0602483749389648\n",
      "Epoch 221 / 500 | iteration 10 / 30 | Total Loss: 1.0479528903961182 | KNN Loss: 6.227035045623779 | BCE Loss: 1.0479528903961182\n",
      "Epoch 221 / 500 | iteration 15 / 30 | Total Loss: 1.0851867198944092 | KNN Loss: 6.2266645431518555 | BCE Loss: 1.0851867198944092\n",
      "Epoch 221 / 500 | iteration 20 / 30 | Total Loss: 1.058016300201416 | KNN Loss: 6.226412296295166 | BCE Loss: 1.058016300201416\n",
      "Epoch 221 / 500 | iteration 25 / 30 | Total Loss: 1.0529274940490723 | KNN Loss: 6.227029800415039 | BCE Loss: 1.0529274940490723\n",
      "Epoch 222 / 500 | iteration 0 / 30 | Total Loss: 1.0582756996154785 | KNN Loss: 6.226865768432617 | BCE Loss: 1.0582756996154785\n",
      "Epoch 222 / 500 | iteration 5 / 30 | Total Loss: 1.0782153606414795 | KNN Loss: 6.226661682128906 | BCE Loss: 1.0782153606414795\n",
      "Epoch 222 / 500 | iteration 10 / 30 | Total Loss: 1.0397462844848633 | KNN Loss: 6.226738452911377 | BCE Loss: 1.0397462844848633\n",
      "Epoch 222 / 500 | iteration 15 / 30 | Total Loss: 1.063392996788025 | KNN Loss: 6.226944446563721 | BCE Loss: 1.063392996788025\n",
      "Epoch 222 / 500 | iteration 20 / 30 | Total Loss: 1.0556590557098389 | KNN Loss: 6.226958751678467 | BCE Loss: 1.0556590557098389\n",
      "Epoch 222 / 500 | iteration 25 / 30 | Total Loss: 1.070844292640686 | KNN Loss: 6.227115154266357 | BCE Loss: 1.070844292640686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223 / 500 | iteration 0 / 30 | Total Loss: 1.0365090370178223 | KNN Loss: 6.226977825164795 | BCE Loss: 1.0365090370178223\n",
      "Epoch 223 / 500 | iteration 5 / 30 | Total Loss: 1.0410178899765015 | KNN Loss: 6.22702169418335 | BCE Loss: 1.0410178899765015\n",
      "Epoch 223 / 500 | iteration 10 / 30 | Total Loss: 1.010920524597168 | KNN Loss: 6.226714611053467 | BCE Loss: 1.010920524597168\n",
      "Epoch 223 / 500 | iteration 15 / 30 | Total Loss: 1.0478696823120117 | KNN Loss: 6.226889133453369 | BCE Loss: 1.0478696823120117\n",
      "Epoch 223 / 500 | iteration 20 / 30 | Total Loss: 1.0529683828353882 | KNN Loss: 6.226987361907959 | BCE Loss: 1.0529683828353882\n",
      "Epoch 223 / 500 | iteration 25 / 30 | Total Loss: 1.043717622756958 | KNN Loss: 6.2266459465026855 | BCE Loss: 1.043717622756958\n",
      "Epoch 224 / 500 | iteration 0 / 30 | Total Loss: 1.0927985906600952 | KNN Loss: 6.226918697357178 | BCE Loss: 1.0927985906600952\n",
      "Epoch 224 / 500 | iteration 5 / 30 | Total Loss: 1.043976902961731 | KNN Loss: 6.226938247680664 | BCE Loss: 1.043976902961731\n",
      "Epoch 224 / 500 | iteration 10 / 30 | Total Loss: 1.052948236465454 | KNN Loss: 6.227040767669678 | BCE Loss: 1.052948236465454\n",
      "Epoch 224 / 500 | iteration 15 / 30 | Total Loss: 1.0488858222961426 | KNN Loss: 6.226884841918945 | BCE Loss: 1.0488858222961426\n",
      "Epoch 224 / 500 | iteration 20 / 30 | Total Loss: 1.0670433044433594 | KNN Loss: 6.226715564727783 | BCE Loss: 1.0670433044433594\n",
      "Epoch 224 / 500 | iteration 25 / 30 | Total Loss: 1.0595221519470215 | KNN Loss: 6.226849555969238 | BCE Loss: 1.0595221519470215\n",
      "Epoch 225 / 500 | iteration 0 / 30 | Total Loss: 1.074364423751831 | KNN Loss: 6.226587295532227 | BCE Loss: 1.074364423751831\n",
      "Epoch 225 / 500 | iteration 5 / 30 | Total Loss: 1.0279724597930908 | KNN Loss: 6.226866245269775 | BCE Loss: 1.0279724597930908\n",
      "Epoch 225 / 500 | iteration 10 / 30 | Total Loss: 1.023930549621582 | KNN Loss: 6.226960182189941 | BCE Loss: 1.023930549621582\n",
      "Epoch 225 / 500 | iteration 15 / 30 | Total Loss: 1.0464506149291992 | KNN Loss: 6.2267045974731445 | BCE Loss: 1.0464506149291992\n",
      "Epoch 225 / 500 | iteration 20 / 30 | Total Loss: 1.0756549835205078 | KNN Loss: 6.226701259613037 | BCE Loss: 1.0756549835205078\n",
      "Epoch 225 / 500 | iteration 25 / 30 | Total Loss: 1.0522849559783936 | KNN Loss: 6.227013111114502 | BCE Loss: 1.0522849559783936\n",
      "Epoch 226 / 500 | iteration 0 / 30 | Total Loss: 1.0474340915679932 | KNN Loss: 6.22695255279541 | BCE Loss: 1.0474340915679932\n",
      "Epoch 226 / 500 | iteration 5 / 30 | Total Loss: 1.0416316986083984 | KNN Loss: 6.2268877029418945 | BCE Loss: 1.0416316986083984\n",
      "Epoch 226 / 500 | iteration 10 / 30 | Total Loss: 1.0536028146743774 | KNN Loss: 6.227027416229248 | BCE Loss: 1.0536028146743774\n",
      "Epoch 226 / 500 | iteration 15 / 30 | Total Loss: 1.0493673086166382 | KNN Loss: 6.226869106292725 | BCE Loss: 1.0493673086166382\n",
      "Epoch 226 / 500 | iteration 20 / 30 | Total Loss: 1.0453077554702759 | KNN Loss: 6.226869106292725 | BCE Loss: 1.0453077554702759\n",
      "Epoch 226 / 500 | iteration 25 / 30 | Total Loss: 1.0889370441436768 | KNN Loss: 6.226698875427246 | BCE Loss: 1.0889370441436768\n",
      "Epoch   227: reducing learning rate of group 0 to 1.6616e-05.\n",
      "Epoch 227 / 500 | iteration 0 / 30 | Total Loss: 1.0639660358428955 | KNN Loss: 6.226817607879639 | BCE Loss: 1.0639660358428955\n",
      "Epoch 227 / 500 | iteration 5 / 30 | Total Loss: 1.0331718921661377 | KNN Loss: 6.22698450088501 | BCE Loss: 1.0331718921661377\n",
      "Epoch 227 / 500 | iteration 10 / 30 | Total Loss: 1.048008680343628 | KNN Loss: 6.226952075958252 | BCE Loss: 1.048008680343628\n",
      "Epoch 227 / 500 | iteration 15 / 30 | Total Loss: 1.032799482345581 | KNN Loss: 6.226682186126709 | BCE Loss: 1.032799482345581\n",
      "Epoch 227 / 500 | iteration 20 / 30 | Total Loss: 1.0406157970428467 | KNN Loss: 6.226609706878662 | BCE Loss: 1.0406157970428467\n",
      "Epoch 227 / 500 | iteration 25 / 30 | Total Loss: 1.0564144849777222 | KNN Loss: 6.226922035217285 | BCE Loss: 1.0564144849777222\n",
      "Epoch 228 / 500 | iteration 0 / 30 | Total Loss: 1.0380668640136719 | KNN Loss: 6.226724624633789 | BCE Loss: 1.0380668640136719\n",
      "Epoch 228 / 500 | iteration 5 / 30 | Total Loss: 1.0318365097045898 | KNN Loss: 6.226744651794434 | BCE Loss: 1.0318365097045898\n",
      "Epoch 228 / 500 | iteration 10 / 30 | Total Loss: 1.0126733779907227 | KNN Loss: 6.22686243057251 | BCE Loss: 1.0126733779907227\n",
      "Epoch 228 / 500 | iteration 15 / 30 | Total Loss: 1.0778532028198242 | KNN Loss: 6.227093696594238 | BCE Loss: 1.0778532028198242\n",
      "Epoch 228 / 500 | iteration 20 / 30 | Total Loss: 1.0614044666290283 | KNN Loss: 6.2272443771362305 | BCE Loss: 1.0614044666290283\n",
      "Epoch 228 / 500 | iteration 25 / 30 | Total Loss: 1.0322346687316895 | KNN Loss: 6.227168560028076 | BCE Loss: 1.0322346687316895\n",
      "Epoch 229 / 500 | iteration 0 / 30 | Total Loss: 1.0428324937820435 | KNN Loss: 6.2269487380981445 | BCE Loss: 1.0428324937820435\n",
      "Epoch 229 / 500 | iteration 5 / 30 | Total Loss: 1.0482515096664429 | KNN Loss: 6.226706027984619 | BCE Loss: 1.0482515096664429\n",
      "Epoch 229 / 500 | iteration 10 / 30 | Total Loss: 1.069374442100525 | KNN Loss: 6.226830005645752 | BCE Loss: 1.069374442100525\n",
      "Epoch 229 / 500 | iteration 15 / 30 | Total Loss: 1.0463593006134033 | KNN Loss: 6.226909637451172 | BCE Loss: 1.0463593006134033\n",
      "Epoch 229 / 500 | iteration 20 / 30 | Total Loss: 1.0342177152633667 | KNN Loss: 6.226810932159424 | BCE Loss: 1.0342177152633667\n",
      "Epoch 229 / 500 | iteration 25 / 30 | Total Loss: 1.029650092124939 | KNN Loss: 6.226824760437012 | BCE Loss: 1.029650092124939\n",
      "Epoch 230 / 500 | iteration 0 / 30 | Total Loss: 1.0607810020446777 | KNN Loss: 6.226801872253418 | BCE Loss: 1.0607810020446777\n",
      "Epoch 230 / 500 | iteration 5 / 30 | Total Loss: 1.0721333026885986 | KNN Loss: 6.22705078125 | BCE Loss: 1.0721333026885986\n",
      "Epoch 230 / 500 | iteration 10 / 30 | Total Loss: 1.05539870262146 | KNN Loss: 6.22695779800415 | BCE Loss: 1.05539870262146\n",
      "Epoch 230 / 500 | iteration 15 / 30 | Total Loss: 1.0613051652908325 | KNN Loss: 6.226667881011963 | BCE Loss: 1.0613051652908325\n",
      "Epoch 230 / 500 | iteration 20 / 30 | Total Loss: 1.020079493522644 | KNN Loss: 6.226807594299316 | BCE Loss: 1.020079493522644\n",
      "Epoch 230 / 500 | iteration 25 / 30 | Total Loss: 1.043515682220459 | KNN Loss: 6.2267327308654785 | BCE Loss: 1.043515682220459\n",
      "Epoch 231 / 500 | iteration 0 / 30 | Total Loss: 1.0480060577392578 | KNN Loss: 6.227085113525391 | BCE Loss: 1.0480060577392578\n",
      "Epoch 231 / 500 | iteration 5 / 30 | Total Loss: 1.051239252090454 | KNN Loss: 6.226794719696045 | BCE Loss: 1.051239252090454\n",
      "Epoch 231 / 500 | iteration 10 / 30 | Total Loss: 1.043283462524414 | KNN Loss: 6.227109432220459 | BCE Loss: 1.043283462524414\n",
      "Epoch 231 / 500 | iteration 15 / 30 | Total Loss: 1.0720019340515137 | KNN Loss: 6.227181911468506 | BCE Loss: 1.0720019340515137\n",
      "Epoch 231 / 500 | iteration 20 / 30 | Total Loss: 1.0790996551513672 | KNN Loss: 6.226649284362793 | BCE Loss: 1.0790996551513672\n",
      "Epoch 231 / 500 | iteration 25 / 30 | Total Loss: 1.0388755798339844 | KNN Loss: 6.227029323577881 | BCE Loss: 1.0388755798339844\n",
      "Epoch 232 / 500 | iteration 0 / 30 | Total Loss: 1.03727388381958 | KNN Loss: 6.2266669273376465 | BCE Loss: 1.03727388381958\n",
      "Epoch 232 / 500 | iteration 5 / 30 | Total Loss: 1.0382264852523804 | KNN Loss: 6.226802825927734 | BCE Loss: 1.0382264852523804\n",
      "Epoch 232 / 500 | iteration 10 / 30 | Total Loss: 1.0415925979614258 | KNN Loss: 6.226448059082031 | BCE Loss: 1.0415925979614258\n",
      "Epoch 232 / 500 | iteration 15 / 30 | Total Loss: 1.0470308065414429 | KNN Loss: 6.227014541625977 | BCE Loss: 1.0470308065414429\n",
      "Epoch 232 / 500 | iteration 20 / 30 | Total Loss: 1.0384323596954346 | KNN Loss: 6.22661828994751 | BCE Loss: 1.0384323596954346\n",
      "Epoch 232 / 500 | iteration 25 / 30 | Total Loss: 1.052647352218628 | KNN Loss: 6.226696968078613 | BCE Loss: 1.052647352218628\n",
      "Epoch 233 / 500 | iteration 0 / 30 | Total Loss: 1.050333023071289 | KNN Loss: 6.226771831512451 | BCE Loss: 1.050333023071289\n",
      "Epoch 233 / 500 | iteration 5 / 30 | Total Loss: 1.0212723016738892 | KNN Loss: 6.2271528244018555 | BCE Loss: 1.0212723016738892\n",
      "Epoch 233 / 500 | iteration 10 / 30 | Total Loss: 1.0206317901611328 | KNN Loss: 6.226937294006348 | BCE Loss: 1.0206317901611328\n",
      "Epoch 233 / 500 | iteration 15 / 30 | Total Loss: 1.0828832387924194 | KNN Loss: 6.227089881896973 | BCE Loss: 1.0828832387924194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233 / 500 | iteration 20 / 30 | Total Loss: 1.0241713523864746 | KNN Loss: 6.2269134521484375 | BCE Loss: 1.0241713523864746\n",
      "Epoch 233 / 500 | iteration 25 / 30 | Total Loss: 1.0648051500320435 | KNN Loss: 6.226967811584473 | BCE Loss: 1.0648051500320435\n",
      "Epoch 234 / 500 | iteration 0 / 30 | Total Loss: 1.0805978775024414 | KNN Loss: 6.226791858673096 | BCE Loss: 1.0805978775024414\n",
      "Epoch 234 / 500 | iteration 5 / 30 | Total Loss: 1.0411412715911865 | KNN Loss: 6.226834297180176 | BCE Loss: 1.0411412715911865\n",
      "Epoch 234 / 500 | iteration 10 / 30 | Total Loss: 1.0600465536117554 | KNN Loss: 6.226978302001953 | BCE Loss: 1.0600465536117554\n",
      "Epoch 234 / 500 | iteration 15 / 30 | Total Loss: 1.0166292190551758 | KNN Loss: 6.226944923400879 | BCE Loss: 1.0166292190551758\n",
      "Epoch 234 / 500 | iteration 20 / 30 | Total Loss: 1.0721124410629272 | KNN Loss: 6.227112293243408 | BCE Loss: 1.0721124410629272\n",
      "Epoch 234 / 500 | iteration 25 / 30 | Total Loss: 1.0578986406326294 | KNN Loss: 6.2270331382751465 | BCE Loss: 1.0578986406326294\n",
      "Epoch 235 / 500 | iteration 0 / 30 | Total Loss: 1.0565946102142334 | KNN Loss: 6.226894855499268 | BCE Loss: 1.0565946102142334\n",
      "Epoch 235 / 500 | iteration 5 / 30 | Total Loss: 1.0374131202697754 | KNN Loss: 6.227057933807373 | BCE Loss: 1.0374131202697754\n",
      "Epoch 235 / 500 | iteration 10 / 30 | Total Loss: 1.0757585763931274 | KNN Loss: 6.226836681365967 | BCE Loss: 1.0757585763931274\n",
      "Epoch 235 / 500 | iteration 15 / 30 | Total Loss: 1.0566680431365967 | KNN Loss: 6.227090358734131 | BCE Loss: 1.0566680431365967\n",
      "Epoch 235 / 500 | iteration 20 / 30 | Total Loss: 1.0535731315612793 | KNN Loss: 6.227071762084961 | BCE Loss: 1.0535731315612793\n",
      "Epoch 235 / 500 | iteration 25 / 30 | Total Loss: 1.0308234691619873 | KNN Loss: 6.2267746925354 | BCE Loss: 1.0308234691619873\n",
      "Epoch 236 / 500 | iteration 0 / 30 | Total Loss: 1.0583090782165527 | KNN Loss: 6.226921558380127 | BCE Loss: 1.0583090782165527\n",
      "Epoch 236 / 500 | iteration 5 / 30 | Total Loss: 1.0261564254760742 | KNN Loss: 6.226630210876465 | BCE Loss: 1.0261564254760742\n",
      "Epoch 236 / 500 | iteration 10 / 30 | Total Loss: 1.064489722251892 | KNN Loss: 6.227106094360352 | BCE Loss: 1.064489722251892\n",
      "Epoch 236 / 500 | iteration 15 / 30 | Total Loss: 1.061678171157837 | KNN Loss: 6.226918697357178 | BCE Loss: 1.061678171157837\n",
      "Epoch 236 / 500 | iteration 20 / 30 | Total Loss: 1.0645564794540405 | KNN Loss: 6.2267746925354 | BCE Loss: 1.0645564794540405\n",
      "Epoch 236 / 500 | iteration 25 / 30 | Total Loss: 1.0348381996154785 | KNN Loss: 6.226734638214111 | BCE Loss: 1.0348381996154785\n",
      "Epoch 237 / 500 | iteration 0 / 30 | Total Loss: 1.05118989944458 | KNN Loss: 6.226884841918945 | BCE Loss: 1.05118989944458\n",
      "Epoch 237 / 500 | iteration 5 / 30 | Total Loss: 1.0544874668121338 | KNN Loss: 6.227047443389893 | BCE Loss: 1.0544874668121338\n",
      "Epoch 237 / 500 | iteration 10 / 30 | Total Loss: 1.0456950664520264 | KNN Loss: 6.226763725280762 | BCE Loss: 1.0456950664520264\n",
      "Epoch 237 / 500 | iteration 15 / 30 | Total Loss: 1.0645487308502197 | KNN Loss: 6.2272491455078125 | BCE Loss: 1.0645487308502197\n",
      "Epoch 237 / 500 | iteration 20 / 30 | Total Loss: 1.0454152822494507 | KNN Loss: 6.226998329162598 | BCE Loss: 1.0454152822494507\n",
      "Epoch 237 / 500 | iteration 25 / 30 | Total Loss: 1.0284076929092407 | KNN Loss: 6.226709365844727 | BCE Loss: 1.0284076929092407\n",
      "Epoch   238: reducing learning rate of group 0 to 1.1632e-05.\n",
      "Epoch 238 / 500 | iteration 0 / 30 | Total Loss: 1.0591020584106445 | KNN Loss: 6.226592063903809 | BCE Loss: 1.0591020584106445\n",
      "Epoch 238 / 500 | iteration 5 / 30 | Total Loss: 1.0675487518310547 | KNN Loss: 6.227142333984375 | BCE Loss: 1.0675487518310547\n",
      "Epoch 238 / 500 | iteration 10 / 30 | Total Loss: 1.017614722251892 | KNN Loss: 6.2267537117004395 | BCE Loss: 1.017614722251892\n",
      "Epoch 238 / 500 | iteration 15 / 30 | Total Loss: 1.0215914249420166 | KNN Loss: 6.22711706161499 | BCE Loss: 1.0215914249420166\n",
      "Epoch 238 / 500 | iteration 20 / 30 | Total Loss: 1.0833470821380615 | KNN Loss: 6.2272162437438965 | BCE Loss: 1.0833470821380615\n",
      "Epoch 238 / 500 | iteration 25 / 30 | Total Loss: 1.0211308002471924 | KNN Loss: 6.227074146270752 | BCE Loss: 1.0211308002471924\n",
      "Epoch 239 / 500 | iteration 0 / 30 | Total Loss: 1.056242823600769 | KNN Loss: 6.226911544799805 | BCE Loss: 1.056242823600769\n",
      "Epoch 239 / 500 | iteration 5 / 30 | Total Loss: 1.0182836055755615 | KNN Loss: 6.227029800415039 | BCE Loss: 1.0182836055755615\n",
      "Epoch 239 / 500 | iteration 10 / 30 | Total Loss: 1.0269057750701904 | KNN Loss: 6.2264485359191895 | BCE Loss: 1.0269057750701904\n",
      "Epoch 239 / 500 | iteration 15 / 30 | Total Loss: 1.0783846378326416 | KNN Loss: 6.227326393127441 | BCE Loss: 1.0783846378326416\n",
      "Epoch 239 / 500 | iteration 20 / 30 | Total Loss: 1.029956579208374 | KNN Loss: 6.226818084716797 | BCE Loss: 1.029956579208374\n",
      "Epoch 239 / 500 | iteration 25 / 30 | Total Loss: 1.0641270875930786 | KNN Loss: 6.226934432983398 | BCE Loss: 1.0641270875930786\n",
      "Epoch 240 / 500 | iteration 0 / 30 | Total Loss: 1.0440871715545654 | KNN Loss: 6.227031230926514 | BCE Loss: 1.0440871715545654\n",
      "Epoch 240 / 500 | iteration 5 / 30 | Total Loss: 1.0861449241638184 | KNN Loss: 6.227039813995361 | BCE Loss: 1.0861449241638184\n",
      "Epoch 240 / 500 | iteration 10 / 30 | Total Loss: 1.034641146659851 | KNN Loss: 6.227001190185547 | BCE Loss: 1.034641146659851\n",
      "Epoch 240 / 500 | iteration 15 / 30 | Total Loss: 1.0680725574493408 | KNN Loss: 6.227060317993164 | BCE Loss: 1.0680725574493408\n",
      "Epoch 240 / 500 | iteration 20 / 30 | Total Loss: 1.0360214710235596 | KNN Loss: 6.226860523223877 | BCE Loss: 1.0360214710235596\n",
      "Epoch 240 / 500 | iteration 25 / 30 | Total Loss: 1.0587494373321533 | KNN Loss: 6.227036952972412 | BCE Loss: 1.0587494373321533\n",
      "Epoch 241 / 500 | iteration 0 / 30 | Total Loss: 1.063246488571167 | KNN Loss: 6.226841926574707 | BCE Loss: 1.063246488571167\n",
      "Epoch 241 / 500 | iteration 5 / 30 | Total Loss: 1.0592055320739746 | KNN Loss: 6.22675895690918 | BCE Loss: 1.0592055320739746\n",
      "Epoch 241 / 500 | iteration 10 / 30 | Total Loss: 1.0508736371994019 | KNN Loss: 6.226802825927734 | BCE Loss: 1.0508736371994019\n",
      "Epoch 241 / 500 | iteration 15 / 30 | Total Loss: 1.072871446609497 | KNN Loss: 6.226924896240234 | BCE Loss: 1.072871446609497\n",
      "Epoch 241 / 500 | iteration 20 / 30 | Total Loss: 1.0340092182159424 | KNN Loss: 6.226474285125732 | BCE Loss: 1.0340092182159424\n",
      "Epoch 241 / 500 | iteration 25 / 30 | Total Loss: 1.0318520069122314 | KNN Loss: 6.227049350738525 | BCE Loss: 1.0318520069122314\n",
      "Epoch 242 / 500 | iteration 0 / 30 | Total Loss: 1.0567632913589478 | KNN Loss: 6.226998329162598 | BCE Loss: 1.0567632913589478\n",
      "Epoch 242 / 500 | iteration 5 / 30 | Total Loss: 1.063317060470581 | KNN Loss: 6.226935386657715 | BCE Loss: 1.063317060470581\n",
      "Epoch 242 / 500 | iteration 10 / 30 | Total Loss: 1.028631567955017 | KNN Loss: 6.226907253265381 | BCE Loss: 1.028631567955017\n",
      "Epoch 242 / 500 | iteration 15 / 30 | Total Loss: 1.0689383745193481 | KNN Loss: 6.227006435394287 | BCE Loss: 1.0689383745193481\n",
      "Epoch 242 / 500 | iteration 20 / 30 | Total Loss: 1.0489346981048584 | KNN Loss: 6.2269792556762695 | BCE Loss: 1.0489346981048584\n",
      "Epoch 242 / 500 | iteration 25 / 30 | Total Loss: 1.0325806140899658 | KNN Loss: 6.2269086837768555 | BCE Loss: 1.0325806140899658\n",
      "Epoch 243 / 500 | iteration 0 / 30 | Total Loss: 1.0383647680282593 | KNN Loss: 6.2268595695495605 | BCE Loss: 1.0383647680282593\n",
      "Epoch 243 / 500 | iteration 5 / 30 | Total Loss: 1.0319387912750244 | KNN Loss: 6.2272515296936035 | BCE Loss: 1.0319387912750244\n",
      "Epoch 243 / 500 | iteration 10 / 30 | Total Loss: 1.055215835571289 | KNN Loss: 6.226830959320068 | BCE Loss: 1.055215835571289\n",
      "Epoch 243 / 500 | iteration 15 / 30 | Total Loss: 1.0328402519226074 | KNN Loss: 6.22692346572876 | BCE Loss: 1.0328402519226074\n",
      "Epoch 243 / 500 | iteration 20 / 30 | Total Loss: 1.0585300922393799 | KNN Loss: 6.227253437042236 | BCE Loss: 1.0585300922393799\n",
      "Epoch 243 / 500 | iteration 25 / 30 | Total Loss: 1.0428237915039062 | KNN Loss: 6.227062702178955 | BCE Loss: 1.0428237915039062\n",
      "Epoch 244 / 500 | iteration 0 / 30 | Total Loss: 1.063894271850586 | KNN Loss: 6.22714900970459 | BCE Loss: 1.063894271850586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244 / 500 | iteration 5 / 30 | Total Loss: 1.065881371498108 | KNN Loss: 6.227015972137451 | BCE Loss: 1.065881371498108\n",
      "Epoch 244 / 500 | iteration 10 / 30 | Total Loss: 1.05806303024292 | KNN Loss: 6.227002143859863 | BCE Loss: 1.05806303024292\n",
      "Epoch 244 / 500 | iteration 15 / 30 | Total Loss: 1.0601227283477783 | KNN Loss: 6.226663112640381 | BCE Loss: 1.0601227283477783\n",
      "Epoch 244 / 500 | iteration 20 / 30 | Total Loss: 1.0578258037567139 | KNN Loss: 6.226873874664307 | BCE Loss: 1.0578258037567139\n",
      "Epoch 244 / 500 | iteration 25 / 30 | Total Loss: 1.048478603363037 | KNN Loss: 6.2269134521484375 | BCE Loss: 1.048478603363037\n",
      "Epoch 245 / 500 | iteration 0 / 30 | Total Loss: 1.0473240613937378 | KNN Loss: 6.22663688659668 | BCE Loss: 1.0473240613937378\n",
      "Epoch 245 / 500 | iteration 5 / 30 | Total Loss: 1.0441851615905762 | KNN Loss: 6.22693395614624 | BCE Loss: 1.0441851615905762\n",
      "Epoch 245 / 500 | iteration 10 / 30 | Total Loss: 1.0393147468566895 | KNN Loss: 6.226897716522217 | BCE Loss: 1.0393147468566895\n",
      "Epoch 245 / 500 | iteration 15 / 30 | Total Loss: 1.0634377002716064 | KNN Loss: 6.2269062995910645 | BCE Loss: 1.0634377002716064\n",
      "Epoch 245 / 500 | iteration 20 / 30 | Total Loss: 1.0468796491622925 | KNN Loss: 6.226780414581299 | BCE Loss: 1.0468796491622925\n",
      "Epoch 245 / 500 | iteration 25 / 30 | Total Loss: 1.0355589389801025 | KNN Loss: 6.226869106292725 | BCE Loss: 1.0355589389801025\n",
      "Epoch 246 / 500 | iteration 0 / 30 | Total Loss: 1.0716016292572021 | KNN Loss: 6.226958751678467 | BCE Loss: 1.0716016292572021\n",
      "Epoch 246 / 500 | iteration 5 / 30 | Total Loss: 1.048821210861206 | KNN Loss: 6.227007865905762 | BCE Loss: 1.048821210861206\n",
      "Epoch 246 / 500 | iteration 10 / 30 | Total Loss: 1.0463805198669434 | KNN Loss: 6.227020263671875 | BCE Loss: 1.0463805198669434\n",
      "Epoch 246 / 500 | iteration 15 / 30 | Total Loss: 1.0698816776275635 | KNN Loss: 6.226604461669922 | BCE Loss: 1.0698816776275635\n",
      "Epoch 246 / 500 | iteration 20 / 30 | Total Loss: 1.0432724952697754 | KNN Loss: 6.226674556732178 | BCE Loss: 1.0432724952697754\n",
      "Epoch 246 / 500 | iteration 25 / 30 | Total Loss: 1.0632758140563965 | KNN Loss: 6.226670742034912 | BCE Loss: 1.0632758140563965\n",
      "Epoch 247 / 500 | iteration 0 / 30 | Total Loss: 1.0322009325027466 | KNN Loss: 6.22674036026001 | BCE Loss: 1.0322009325027466\n",
      "Epoch 247 / 500 | iteration 5 / 30 | Total Loss: 1.060190200805664 | KNN Loss: 6.226988315582275 | BCE Loss: 1.060190200805664\n",
      "Epoch 247 / 500 | iteration 10 / 30 | Total Loss: 1.0609019994735718 | KNN Loss: 6.226898670196533 | BCE Loss: 1.0609019994735718\n",
      "Epoch 247 / 500 | iteration 15 / 30 | Total Loss: 1.0769695043563843 | KNN Loss: 6.227170944213867 | BCE Loss: 1.0769695043563843\n",
      "Epoch 247 / 500 | iteration 20 / 30 | Total Loss: 1.086154580116272 | KNN Loss: 6.2266459465026855 | BCE Loss: 1.086154580116272\n",
      "Epoch 247 / 500 | iteration 25 / 30 | Total Loss: 1.05454683303833 | KNN Loss: 6.226663589477539 | BCE Loss: 1.05454683303833\n",
      "Epoch 248 / 500 | iteration 0 / 30 | Total Loss: 1.063014030456543 | KNN Loss: 6.226809024810791 | BCE Loss: 1.063014030456543\n",
      "Epoch 248 / 500 | iteration 5 / 30 | Total Loss: 1.0333067178726196 | KNN Loss: 6.227142333984375 | BCE Loss: 1.0333067178726196\n",
      "Epoch 248 / 500 | iteration 10 / 30 | Total Loss: 1.0369994640350342 | KNN Loss: 6.227054119110107 | BCE Loss: 1.0369994640350342\n",
      "Epoch 248 / 500 | iteration 15 / 30 | Total Loss: 1.0693601369857788 | KNN Loss: 6.2269287109375 | BCE Loss: 1.0693601369857788\n",
      "Epoch 248 / 500 | iteration 20 / 30 | Total Loss: 1.0715579986572266 | KNN Loss: 6.226813316345215 | BCE Loss: 1.0715579986572266\n",
      "Epoch 248 / 500 | iteration 25 / 30 | Total Loss: 1.051835060119629 | KNN Loss: 6.226644515991211 | BCE Loss: 1.051835060119629\n",
      "Epoch   249: reducing learning rate of group 0 to 8.1421e-06.\n",
      "Epoch 249 / 500 | iteration 0 / 30 | Total Loss: 1.0538032054901123 | KNN Loss: 6.226861000061035 | BCE Loss: 1.0538032054901123\n",
      "Epoch 249 / 500 | iteration 5 / 30 | Total Loss: 1.0669785737991333 | KNN Loss: 6.226931095123291 | BCE Loss: 1.0669785737991333\n",
      "Epoch 249 / 500 | iteration 10 / 30 | Total Loss: 1.0478804111480713 | KNN Loss: 6.226963043212891 | BCE Loss: 1.0478804111480713\n",
      "Epoch 249 / 500 | iteration 15 / 30 | Total Loss: 1.0400487184524536 | KNN Loss: 6.227015018463135 | BCE Loss: 1.0400487184524536\n",
      "Epoch 249 / 500 | iteration 20 / 30 | Total Loss: 1.065953016281128 | KNN Loss: 6.226733207702637 | BCE Loss: 1.065953016281128\n",
      "Epoch 249 / 500 | iteration 25 / 30 | Total Loss: 1.0241371393203735 | KNN Loss: 6.227142333984375 | BCE Loss: 1.0241371393203735\n",
      "Epoch 250 / 500 | iteration 0 / 30 | Total Loss: 1.0618464946746826 | KNN Loss: 6.226817607879639 | BCE Loss: 1.0618464946746826\n",
      "Epoch 250 / 500 | iteration 5 / 30 | Total Loss: 1.0496788024902344 | KNN Loss: 6.226524353027344 | BCE Loss: 1.0496788024902344\n",
      "Epoch 250 / 500 | iteration 10 / 30 | Total Loss: 1.0498470067977905 | KNN Loss: 6.226789951324463 | BCE Loss: 1.0498470067977905\n",
      "Epoch 250 / 500 | iteration 15 / 30 | Total Loss: 1.0663018226623535 | KNN Loss: 6.2270989418029785 | BCE Loss: 1.0663018226623535\n",
      "Epoch 250 / 500 | iteration 20 / 30 | Total Loss: 1.0473617315292358 | KNN Loss: 6.226896286010742 | BCE Loss: 1.0473617315292358\n",
      "Epoch 250 / 500 | iteration 25 / 30 | Total Loss: 1.056124210357666 | KNN Loss: 6.227077960968018 | BCE Loss: 1.056124210357666\n",
      "Epoch 251 / 500 | iteration 0 / 30 | Total Loss: 1.029550552368164 | KNN Loss: 6.226807117462158 | BCE Loss: 1.029550552368164\n",
      "Epoch 251 / 500 | iteration 5 / 30 | Total Loss: 1.075371503829956 | KNN Loss: 6.227135181427002 | BCE Loss: 1.075371503829956\n",
      "Epoch 251 / 500 | iteration 10 / 30 | Total Loss: 1.0328178405761719 | KNN Loss: 6.226888656616211 | BCE Loss: 1.0328178405761719\n",
      "Epoch 251 / 500 | iteration 15 / 30 | Total Loss: 1.046017050743103 | KNN Loss: 6.227106094360352 | BCE Loss: 1.046017050743103\n",
      "Epoch 251 / 500 | iteration 20 / 30 | Total Loss: 1.0573256015777588 | KNN Loss: 6.226860046386719 | BCE Loss: 1.0573256015777588\n",
      "Epoch 251 / 500 | iteration 25 / 30 | Total Loss: 1.050339698791504 | KNN Loss: 6.226892948150635 | BCE Loss: 1.050339698791504\n",
      "Epoch 252 / 500 | iteration 0 / 30 | Total Loss: 1.0306018590927124 | KNN Loss: 6.226912975311279 | BCE Loss: 1.0306018590927124\n",
      "Epoch 252 / 500 | iteration 5 / 30 | Total Loss: 1.0762362480163574 | KNN Loss: 6.226799964904785 | BCE Loss: 1.0762362480163574\n",
      "Epoch 252 / 500 | iteration 10 / 30 | Total Loss: 1.0670292377471924 | KNN Loss: 6.226707935333252 | BCE Loss: 1.0670292377471924\n",
      "Epoch 252 / 500 | iteration 15 / 30 | Total Loss: 1.0441043376922607 | KNN Loss: 6.227024555206299 | BCE Loss: 1.0441043376922607\n",
      "Epoch 252 / 500 | iteration 20 / 30 | Total Loss: 1.0503696203231812 | KNN Loss: 6.226733684539795 | BCE Loss: 1.0503696203231812\n",
      "Epoch 252 / 500 | iteration 25 / 30 | Total Loss: 1.035693883895874 | KNN Loss: 6.226837158203125 | BCE Loss: 1.035693883895874\n",
      "Epoch 253 / 500 | iteration 0 / 30 | Total Loss: 1.0517899990081787 | KNN Loss: 6.22697639465332 | BCE Loss: 1.0517899990081787\n",
      "Epoch 253 / 500 | iteration 5 / 30 | Total Loss: 1.0516626834869385 | KNN Loss: 6.227013111114502 | BCE Loss: 1.0516626834869385\n",
      "Epoch 253 / 500 | iteration 10 / 30 | Total Loss: 1.0581389665603638 | KNN Loss: 6.22676420211792 | BCE Loss: 1.0581389665603638\n",
      "Epoch 253 / 500 | iteration 15 / 30 | Total Loss: 1.0706720352172852 | KNN Loss: 6.226880073547363 | BCE Loss: 1.0706720352172852\n",
      "Epoch 253 / 500 | iteration 20 / 30 | Total Loss: 1.0378111600875854 | KNN Loss: 6.2270402908325195 | BCE Loss: 1.0378111600875854\n",
      "Epoch 253 / 500 | iteration 25 / 30 | Total Loss: 1.0496550798416138 | KNN Loss: 6.226527214050293 | BCE Loss: 1.0496550798416138\n",
      "Epoch 254 / 500 | iteration 0 / 30 | Total Loss: 1.0063282251358032 | KNN Loss: 6.226757049560547 | BCE Loss: 1.0063282251358032\n",
      "Epoch 254 / 500 | iteration 5 / 30 | Total Loss: 1.040331244468689 | KNN Loss: 6.226866722106934 | BCE Loss: 1.040331244468689\n",
      "Epoch 254 / 500 | iteration 10 / 30 | Total Loss: 1.052780032157898 | KNN Loss: 6.226822853088379 | BCE Loss: 1.052780032157898\n",
      "Epoch 254 / 500 | iteration 15 / 30 | Total Loss: 1.066016435623169 | KNN Loss: 6.227025985717773 | BCE Loss: 1.066016435623169\n",
      "Epoch 254 / 500 | iteration 20 / 30 | Total Loss: 1.0316365957260132 | KNN Loss: 6.226729869842529 | BCE Loss: 1.0316365957260132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254 / 500 | iteration 25 / 30 | Total Loss: 1.075943946838379 | KNN Loss: 6.226963043212891 | BCE Loss: 1.075943946838379\n",
      "Epoch 255 / 500 | iteration 0 / 30 | Total Loss: 1.0674834251403809 | KNN Loss: 6.226994514465332 | BCE Loss: 1.0674834251403809\n",
      "Epoch 255 / 500 | iteration 5 / 30 | Total Loss: 1.0355924367904663 | KNN Loss: 6.227250099182129 | BCE Loss: 1.0355924367904663\n",
      "Epoch 255 / 500 | iteration 10 / 30 | Total Loss: 1.0497645139694214 | KNN Loss: 6.226935386657715 | BCE Loss: 1.0497645139694214\n",
      "Epoch 255 / 500 | iteration 15 / 30 | Total Loss: 1.0508261919021606 | KNN Loss: 6.226415634155273 | BCE Loss: 1.0508261919021606\n",
      "Epoch 255 / 500 | iteration 20 / 30 | Total Loss: 1.063277244567871 | KNN Loss: 6.226919174194336 | BCE Loss: 1.063277244567871\n",
      "Epoch 255 / 500 | iteration 25 / 30 | Total Loss: 1.0400593280792236 | KNN Loss: 6.226562023162842 | BCE Loss: 1.0400593280792236\n",
      "Epoch 256 / 500 | iteration 0 / 30 | Total Loss: 1.0698119401931763 | KNN Loss: 6.22683572769165 | BCE Loss: 1.0698119401931763\n",
      "Epoch 256 / 500 | iteration 5 / 30 | Total Loss: 1.0779021978378296 | KNN Loss: 6.2264909744262695 | BCE Loss: 1.0779021978378296\n",
      "Epoch 256 / 500 | iteration 10 / 30 | Total Loss: 1.0308153629302979 | KNN Loss: 6.22707462310791 | BCE Loss: 1.0308153629302979\n",
      "Epoch 256 / 500 | iteration 15 / 30 | Total Loss: 1.0451264381408691 | KNN Loss: 6.226992130279541 | BCE Loss: 1.0451264381408691\n",
      "Epoch 256 / 500 | iteration 20 / 30 | Total Loss: 1.0416796207427979 | KNN Loss: 6.227118968963623 | BCE Loss: 1.0416796207427979\n",
      "Epoch 256 / 500 | iteration 25 / 30 | Total Loss: 1.0711281299591064 | KNN Loss: 6.226762771606445 | BCE Loss: 1.0711281299591064\n",
      "Epoch 257 / 500 | iteration 0 / 30 | Total Loss: 1.044297456741333 | KNN Loss: 6.226648330688477 | BCE Loss: 1.044297456741333\n",
      "Epoch 257 / 500 | iteration 5 / 30 | Total Loss: 1.0261297225952148 | KNN Loss: 6.2269110679626465 | BCE Loss: 1.0261297225952148\n",
      "Epoch 257 / 500 | iteration 10 / 30 | Total Loss: 1.0596497058868408 | KNN Loss: 6.226718425750732 | BCE Loss: 1.0596497058868408\n",
      "Epoch 257 / 500 | iteration 15 / 30 | Total Loss: 1.0369641780853271 | KNN Loss: 6.227169990539551 | BCE Loss: 1.0369641780853271\n",
      "Epoch 257 / 500 | iteration 20 / 30 | Total Loss: 1.0629684925079346 | KNN Loss: 6.226944923400879 | BCE Loss: 1.0629684925079346\n",
      "Epoch 257 / 500 | iteration 25 / 30 | Total Loss: 1.023982286453247 | KNN Loss: 6.2269368171691895 | BCE Loss: 1.023982286453247\n",
      "Epoch 258 / 500 | iteration 0 / 30 | Total Loss: 1.0641677379608154 | KNN Loss: 6.227260112762451 | BCE Loss: 1.0641677379608154\n",
      "Epoch 258 / 500 | iteration 5 / 30 | Total Loss: 1.0577151775360107 | KNN Loss: 6.226790904998779 | BCE Loss: 1.0577151775360107\n",
      "Epoch 258 / 500 | iteration 10 / 30 | Total Loss: 1.0421202182769775 | KNN Loss: 6.22681188583374 | BCE Loss: 1.0421202182769775\n",
      "Epoch 258 / 500 | iteration 15 / 30 | Total Loss: 1.0850679874420166 | KNN Loss: 6.226813793182373 | BCE Loss: 1.0850679874420166\n",
      "Epoch 258 / 500 | iteration 20 / 30 | Total Loss: 1.0384361743927002 | KNN Loss: 6.226779460906982 | BCE Loss: 1.0384361743927002\n",
      "Epoch 258 / 500 | iteration 25 / 30 | Total Loss: 1.0590211153030396 | KNN Loss: 6.226884841918945 | BCE Loss: 1.0590211153030396\n",
      "Epoch 259 / 500 | iteration 0 / 30 | Total Loss: 1.092292070388794 | KNN Loss: 6.226855278015137 | BCE Loss: 1.092292070388794\n",
      "Epoch 259 / 500 | iteration 5 / 30 | Total Loss: 1.03568434715271 | KNN Loss: 6.226728439331055 | BCE Loss: 1.03568434715271\n",
      "Epoch 259 / 500 | iteration 10 / 30 | Total Loss: 1.0491485595703125 | KNN Loss: 6.226914882659912 | BCE Loss: 1.0491485595703125\n",
      "Epoch 259 / 500 | iteration 15 / 30 | Total Loss: 1.0439902544021606 | KNN Loss: 6.226996898651123 | BCE Loss: 1.0439902544021606\n",
      "Epoch 259 / 500 | iteration 20 / 30 | Total Loss: 1.0548827648162842 | KNN Loss: 6.22673225402832 | BCE Loss: 1.0548827648162842\n",
      "Epoch 259 / 500 | iteration 25 / 30 | Total Loss: 1.0287100076675415 | KNN Loss: 6.227252006530762 | BCE Loss: 1.0287100076675415\n",
      "Epoch   260: reducing learning rate of group 0 to 5.6994e-06.\n",
      "Epoch 260 / 500 | iteration 0 / 30 | Total Loss: 1.0968918800354004 | KNN Loss: 6.226816177368164 | BCE Loss: 1.0968918800354004\n",
      "Epoch 260 / 500 | iteration 5 / 30 | Total Loss: 1.0299062728881836 | KNN Loss: 6.226833343505859 | BCE Loss: 1.0299062728881836\n",
      "Epoch 260 / 500 | iteration 10 / 30 | Total Loss: 1.0584160089492798 | KNN Loss: 6.226955413818359 | BCE Loss: 1.0584160089492798\n",
      "Epoch 260 / 500 | iteration 15 / 30 | Total Loss: 1.0661766529083252 | KNN Loss: 6.226663589477539 | BCE Loss: 1.0661766529083252\n",
      "Epoch 260 / 500 | iteration 20 / 30 | Total Loss: 1.0679049491882324 | KNN Loss: 6.227023601531982 | BCE Loss: 1.0679049491882324\n",
      "Epoch 260 / 500 | iteration 25 / 30 | Total Loss: 1.008915901184082 | KNN Loss: 6.226781368255615 | BCE Loss: 1.008915901184082\n",
      "Epoch 261 / 500 | iteration 0 / 30 | Total Loss: 1.0806208848953247 | KNN Loss: 6.226911544799805 | BCE Loss: 1.0806208848953247\n",
      "Epoch 261 / 500 | iteration 5 / 30 | Total Loss: 1.0431463718414307 | KNN Loss: 6.226835250854492 | BCE Loss: 1.0431463718414307\n",
      "Epoch 261 / 500 | iteration 10 / 30 | Total Loss: 1.0516570806503296 | KNN Loss: 6.226539611816406 | BCE Loss: 1.0516570806503296\n",
      "Epoch 261 / 500 | iteration 15 / 30 | Total Loss: 1.0355247259140015 | KNN Loss: 6.2268853187561035 | BCE Loss: 1.0355247259140015\n",
      "Epoch 261 / 500 | iteration 20 / 30 | Total Loss: 1.0746924877166748 | KNN Loss: 6.226948261260986 | BCE Loss: 1.0746924877166748\n",
      "Epoch 261 / 500 | iteration 25 / 30 | Total Loss: 1.0187468528747559 | KNN Loss: 6.22706937789917 | BCE Loss: 1.0187468528747559\n",
      "Epoch 262 / 500 | iteration 0 / 30 | Total Loss: 1.0334057807922363 | KNN Loss: 6.2270636558532715 | BCE Loss: 1.0334057807922363\n",
      "Epoch 262 / 500 | iteration 5 / 30 | Total Loss: 1.0510501861572266 | KNN Loss: 6.226712226867676 | BCE Loss: 1.0510501861572266\n",
      "Epoch 262 / 500 | iteration 10 / 30 | Total Loss: 1.059600830078125 | KNN Loss: 6.226998805999756 | BCE Loss: 1.059600830078125\n",
      "Epoch 262 / 500 | iteration 15 / 30 | Total Loss: 1.0855934619903564 | KNN Loss: 6.226949214935303 | BCE Loss: 1.0855934619903564\n",
      "Epoch 262 / 500 | iteration 20 / 30 | Total Loss: 1.0317784547805786 | KNN Loss: 6.227017402648926 | BCE Loss: 1.0317784547805786\n",
      "Epoch 262 / 500 | iteration 25 / 30 | Total Loss: 1.0383713245391846 | KNN Loss: 6.2267303466796875 | BCE Loss: 1.0383713245391846\n",
      "Epoch 263 / 500 | iteration 0 / 30 | Total Loss: 1.0365309715270996 | KNN Loss: 6.226989269256592 | BCE Loss: 1.0365309715270996\n",
      "Epoch 263 / 500 | iteration 5 / 30 | Total Loss: 1.0463453531265259 | KNN Loss: 6.226810932159424 | BCE Loss: 1.0463453531265259\n",
      "Epoch 263 / 500 | iteration 10 / 30 | Total Loss: 1.064889669418335 | KNN Loss: 6.226977348327637 | BCE Loss: 1.064889669418335\n",
      "Epoch 263 / 500 | iteration 15 / 30 | Total Loss: 1.0642900466918945 | KNN Loss: 6.226660251617432 | BCE Loss: 1.0642900466918945\n",
      "Epoch 263 / 500 | iteration 20 / 30 | Total Loss: 1.0517358779907227 | KNN Loss: 6.226693153381348 | BCE Loss: 1.0517358779907227\n",
      "Epoch 263 / 500 | iteration 25 / 30 | Total Loss: 1.0507756471633911 | KNN Loss: 6.226879596710205 | BCE Loss: 1.0507756471633911\n",
      "Epoch 264 / 500 | iteration 0 / 30 | Total Loss: 1.0502398014068604 | KNN Loss: 6.226933479309082 | BCE Loss: 1.0502398014068604\n",
      "Epoch 264 / 500 | iteration 5 / 30 | Total Loss: 1.0545599460601807 | KNN Loss: 6.226956844329834 | BCE Loss: 1.0545599460601807\n",
      "Epoch 264 / 500 | iteration 10 / 30 | Total Loss: 1.0769271850585938 | KNN Loss: 6.226935386657715 | BCE Loss: 1.0769271850585938\n",
      "Epoch 264 / 500 | iteration 15 / 30 | Total Loss: 1.0358787775039673 | KNN Loss: 6.226859092712402 | BCE Loss: 1.0358787775039673\n",
      "Epoch 264 / 500 | iteration 20 / 30 | Total Loss: 1.0820602178573608 | KNN Loss: 6.226877689361572 | BCE Loss: 1.0820602178573608\n",
      "Epoch 264 / 500 | iteration 25 / 30 | Total Loss: 1.0545454025268555 | KNN Loss: 6.226840972900391 | BCE Loss: 1.0545454025268555\n",
      "Epoch 265 / 500 | iteration 0 / 30 | Total Loss: 1.0447230339050293 | KNN Loss: 6.2266974449157715 | BCE Loss: 1.0447230339050293\n",
      "Epoch 265 / 500 | iteration 5 / 30 | Total Loss: 1.032055377960205 | KNN Loss: 6.226906776428223 | BCE Loss: 1.032055377960205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 265 / 500 | iteration 10 / 30 | Total Loss: 1.0564132928848267 | KNN Loss: 6.226837635040283 | BCE Loss: 1.0564132928848267\n",
      "Epoch 265 / 500 | iteration 15 / 30 | Total Loss: 1.0412437915802002 | KNN Loss: 6.226728916168213 | BCE Loss: 1.0412437915802002\n",
      "Epoch 265 / 500 | iteration 20 / 30 | Total Loss: 1.0547711849212646 | KNN Loss: 6.226656436920166 | BCE Loss: 1.0547711849212646\n",
      "Epoch 265 / 500 | iteration 25 / 30 | Total Loss: 1.0370988845825195 | KNN Loss: 6.226762771606445 | BCE Loss: 1.0370988845825195\n",
      "Epoch 266 / 500 | iteration 0 / 30 | Total Loss: 1.0700490474700928 | KNN Loss: 6.22704553604126 | BCE Loss: 1.0700490474700928\n",
      "Epoch 266 / 500 | iteration 5 / 30 | Total Loss: 1.048577070236206 | KNN Loss: 6.226825714111328 | BCE Loss: 1.048577070236206\n",
      "Epoch 266 / 500 | iteration 10 / 30 | Total Loss: 1.0356485843658447 | KNN Loss: 6.226738452911377 | BCE Loss: 1.0356485843658447\n",
      "Epoch 266 / 500 | iteration 15 / 30 | Total Loss: 1.0310592651367188 | KNN Loss: 6.226920127868652 | BCE Loss: 1.0310592651367188\n",
      "Epoch 266 / 500 | iteration 20 / 30 | Total Loss: 1.0524163246154785 | KNN Loss: 6.2265825271606445 | BCE Loss: 1.0524163246154785\n",
      "Epoch 266 / 500 | iteration 25 / 30 | Total Loss: 1.0392625331878662 | KNN Loss: 6.226618766784668 | BCE Loss: 1.0392625331878662\n",
      "Epoch 267 / 500 | iteration 0 / 30 | Total Loss: 1.0189913511276245 | KNN Loss: 6.226992607116699 | BCE Loss: 1.0189913511276245\n",
      "Epoch 267 / 500 | iteration 5 / 30 | Total Loss: 1.0237771272659302 | KNN Loss: 6.227024555206299 | BCE Loss: 1.0237771272659302\n",
      "Epoch 267 / 500 | iteration 10 / 30 | Total Loss: 1.0407781600952148 | KNN Loss: 6.227066993713379 | BCE Loss: 1.0407781600952148\n",
      "Epoch 267 / 500 | iteration 15 / 30 | Total Loss: 1.0430757999420166 | KNN Loss: 6.227002143859863 | BCE Loss: 1.0430757999420166\n",
      "Epoch 267 / 500 | iteration 20 / 30 | Total Loss: 1.080573320388794 | KNN Loss: 6.226754188537598 | BCE Loss: 1.080573320388794\n",
      "Epoch 267 / 500 | iteration 25 / 30 | Total Loss: 1.049748182296753 | KNN Loss: 6.226809978485107 | BCE Loss: 1.049748182296753\n",
      "Epoch 268 / 500 | iteration 0 / 30 | Total Loss: 1.0570545196533203 | KNN Loss: 6.226937294006348 | BCE Loss: 1.0570545196533203\n",
      "Epoch 268 / 500 | iteration 5 / 30 | Total Loss: 1.0225725173950195 | KNN Loss: 6.226780891418457 | BCE Loss: 1.0225725173950195\n",
      "Epoch 268 / 500 | iteration 10 / 30 | Total Loss: 1.074397325515747 | KNN Loss: 6.226918697357178 | BCE Loss: 1.074397325515747\n",
      "Epoch 268 / 500 | iteration 15 / 30 | Total Loss: 1.0802842378616333 | KNN Loss: 6.227034568786621 | BCE Loss: 1.0802842378616333\n",
      "Epoch 268 / 500 | iteration 20 / 30 | Total Loss: 1.0267486572265625 | KNN Loss: 6.226919651031494 | BCE Loss: 1.0267486572265625\n",
      "Epoch 268 / 500 | iteration 25 / 30 | Total Loss: 1.048163890838623 | KNN Loss: 6.22706413269043 | BCE Loss: 1.048163890838623\n",
      "Epoch 269 / 500 | iteration 0 / 30 | Total Loss: 1.0858665704727173 | KNN Loss: 6.227047443389893 | BCE Loss: 1.0858665704727173\n",
      "Epoch 269 / 500 | iteration 5 / 30 | Total Loss: 1.0364181995391846 | KNN Loss: 6.226765155792236 | BCE Loss: 1.0364181995391846\n",
      "Epoch 269 / 500 | iteration 10 / 30 | Total Loss: 1.0139482021331787 | KNN Loss: 6.226729869842529 | BCE Loss: 1.0139482021331787\n",
      "Epoch 269 / 500 | iteration 15 / 30 | Total Loss: 1.0303796529769897 | KNN Loss: 6.226846218109131 | BCE Loss: 1.0303796529769897\n",
      "Epoch 269 / 500 | iteration 20 / 30 | Total Loss: 1.0516116619110107 | KNN Loss: 6.226904392242432 | BCE Loss: 1.0516116619110107\n",
      "Epoch 269 / 500 | iteration 25 / 30 | Total Loss: 1.062145471572876 | KNN Loss: 6.226761341094971 | BCE Loss: 1.062145471572876\n",
      "Epoch 270 / 500 | iteration 0 / 30 | Total Loss: 1.0738136768341064 | KNN Loss: 6.226919174194336 | BCE Loss: 1.0738136768341064\n",
      "Epoch 270 / 500 | iteration 5 / 30 | Total Loss: 1.058885097503662 | KNN Loss: 6.226776599884033 | BCE Loss: 1.058885097503662\n",
      "Epoch 270 / 500 | iteration 10 / 30 | Total Loss: 1.0590875148773193 | KNN Loss: 6.226950168609619 | BCE Loss: 1.0590875148773193\n",
      "Epoch 270 / 500 | iteration 15 / 30 | Total Loss: 1.0656991004943848 | KNN Loss: 6.226912021636963 | BCE Loss: 1.0656991004943848\n",
      "Epoch 270 / 500 | iteration 20 / 30 | Total Loss: 1.0638118982315063 | KNN Loss: 6.22666597366333 | BCE Loss: 1.0638118982315063\n",
      "Epoch 270 / 500 | iteration 25 / 30 | Total Loss: 1.0174710750579834 | KNN Loss: 6.227016925811768 | BCE Loss: 1.0174710750579834\n",
      "Epoch   271: reducing learning rate of group 0 to 3.9896e-06.\n",
      "Epoch 271 / 500 | iteration 0 / 30 | Total Loss: 1.0481113195419312 | KNN Loss: 6.2268524169921875 | BCE Loss: 1.0481113195419312\n",
      "Epoch 271 / 500 | iteration 5 / 30 | Total Loss: 1.0464015007019043 | KNN Loss: 6.226576328277588 | BCE Loss: 1.0464015007019043\n",
      "Epoch 271 / 500 | iteration 10 / 30 | Total Loss: 1.0495102405548096 | KNN Loss: 6.226935863494873 | BCE Loss: 1.0495102405548096\n",
      "Epoch 271 / 500 | iteration 15 / 30 | Total Loss: 1.0534712076187134 | KNN Loss: 6.226927280426025 | BCE Loss: 1.0534712076187134\n",
      "Epoch 271 / 500 | iteration 20 / 30 | Total Loss: 1.0369443893432617 | KNN Loss: 6.2271647453308105 | BCE Loss: 1.0369443893432617\n",
      "Epoch 271 / 500 | iteration 25 / 30 | Total Loss: 1.0467629432678223 | KNN Loss: 6.226744174957275 | BCE Loss: 1.0467629432678223\n",
      "Epoch 272 / 500 | iteration 0 / 30 | Total Loss: 1.0455336570739746 | KNN Loss: 6.226898670196533 | BCE Loss: 1.0455336570739746\n",
      "Epoch 272 / 500 | iteration 5 / 30 | Total Loss: 1.0615851879119873 | KNN Loss: 6.226710796356201 | BCE Loss: 1.0615851879119873\n",
      "Epoch 272 / 500 | iteration 10 / 30 | Total Loss: 1.0273518562316895 | KNN Loss: 6.226861000061035 | BCE Loss: 1.0273518562316895\n",
      "Epoch 272 / 500 | iteration 15 / 30 | Total Loss: 1.076984167098999 | KNN Loss: 6.22676944732666 | BCE Loss: 1.076984167098999\n",
      "Epoch 272 / 500 | iteration 20 / 30 | Total Loss: 1.0236300230026245 | KNN Loss: 6.227063179016113 | BCE Loss: 1.0236300230026245\n",
      "Epoch 272 / 500 | iteration 25 / 30 | Total Loss: 1.0549979209899902 | KNN Loss: 6.226990222930908 | BCE Loss: 1.0549979209899902\n",
      "Epoch 273 / 500 | iteration 0 / 30 | Total Loss: 1.0429997444152832 | KNN Loss: 6.2268290519714355 | BCE Loss: 1.0429997444152832\n",
      "Epoch 273 / 500 | iteration 5 / 30 | Total Loss: 1.0501389503479004 | KNN Loss: 6.226769924163818 | BCE Loss: 1.0501389503479004\n",
      "Epoch 273 / 500 | iteration 10 / 30 | Total Loss: 1.0450787544250488 | KNN Loss: 6.226995468139648 | BCE Loss: 1.0450787544250488\n",
      "Epoch 273 / 500 | iteration 15 / 30 | Total Loss: 1.0671074390411377 | KNN Loss: 6.2267632484436035 | BCE Loss: 1.0671074390411377\n",
      "Epoch 273 / 500 | iteration 20 / 30 | Total Loss: 1.0196107625961304 | KNN Loss: 6.226563453674316 | BCE Loss: 1.0196107625961304\n",
      "Epoch 273 / 500 | iteration 25 / 30 | Total Loss: 1.079549789428711 | KNN Loss: 6.2271013259887695 | BCE Loss: 1.079549789428711\n",
      "Epoch 274 / 500 | iteration 0 / 30 | Total Loss: 1.0695281028747559 | KNN Loss: 6.22704553604126 | BCE Loss: 1.0695281028747559\n",
      "Epoch 274 / 500 | iteration 5 / 30 | Total Loss: 1.0605634450912476 | KNN Loss: 6.226872444152832 | BCE Loss: 1.0605634450912476\n",
      "Epoch 274 / 500 | iteration 10 / 30 | Total Loss: 1.0449877977371216 | KNN Loss: 6.22661018371582 | BCE Loss: 1.0449877977371216\n",
      "Epoch 274 / 500 | iteration 15 / 30 | Total Loss: 1.0474121570587158 | KNN Loss: 6.226627349853516 | BCE Loss: 1.0474121570587158\n",
      "Epoch 274 / 500 | iteration 20 / 30 | Total Loss: 1.0312410593032837 | KNN Loss: 6.226944923400879 | BCE Loss: 1.0312410593032837\n",
      "Epoch 274 / 500 | iteration 25 / 30 | Total Loss: 1.0638993978500366 | KNN Loss: 6.227064609527588 | BCE Loss: 1.0638993978500366\n",
      "Epoch 275 / 500 | iteration 0 / 30 | Total Loss: 1.054610013961792 | KNN Loss: 6.226812839508057 | BCE Loss: 1.054610013961792\n",
      "Epoch 275 / 500 | iteration 5 / 30 | Total Loss: 1.0411958694458008 | KNN Loss: 6.2272138595581055 | BCE Loss: 1.0411958694458008\n",
      "Epoch 275 / 500 | iteration 10 / 30 | Total Loss: 1.0785346031188965 | KNN Loss: 6.226709842681885 | BCE Loss: 1.0785346031188965\n",
      "Epoch 275 / 500 | iteration 15 / 30 | Total Loss: 1.0578012466430664 | KNN Loss: 6.226738452911377 | BCE Loss: 1.0578012466430664\n",
      "Epoch 275 / 500 | iteration 20 / 30 | Total Loss: 1.0387872457504272 | KNN Loss: 6.2269463539123535 | BCE Loss: 1.0387872457504272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275 / 500 | iteration 25 / 30 | Total Loss: 1.0494046211242676 | KNN Loss: 6.227067947387695 | BCE Loss: 1.0494046211242676\n",
      "Epoch 276 / 500 | iteration 0 / 30 | Total Loss: 1.0572210550308228 | KNN Loss: 6.227041721343994 | BCE Loss: 1.0572210550308228\n",
      "Epoch 276 / 500 | iteration 5 / 30 | Total Loss: 1.0414752960205078 | KNN Loss: 6.226471900939941 | BCE Loss: 1.0414752960205078\n",
      "Epoch 276 / 500 | iteration 10 / 30 | Total Loss: 1.0326828956604004 | KNN Loss: 6.226677417755127 | BCE Loss: 1.0326828956604004\n",
      "Epoch 276 / 500 | iteration 15 / 30 | Total Loss: 1.026505708694458 | KNN Loss: 6.226903915405273 | BCE Loss: 1.026505708694458\n",
      "Epoch 276 / 500 | iteration 20 / 30 | Total Loss: 1.0510408878326416 | KNN Loss: 6.227099418640137 | BCE Loss: 1.0510408878326416\n",
      "Epoch 276 / 500 | iteration 25 / 30 | Total Loss: 1.0704619884490967 | KNN Loss: 6.226993560791016 | BCE Loss: 1.0704619884490967\n",
      "Epoch 277 / 500 | iteration 0 / 30 | Total Loss: 1.0390326976776123 | KNN Loss: 6.226654529571533 | BCE Loss: 1.0390326976776123\n",
      "Epoch 277 / 500 | iteration 5 / 30 | Total Loss: 1.0444886684417725 | KNN Loss: 6.226794242858887 | BCE Loss: 1.0444886684417725\n",
      "Epoch 277 / 500 | iteration 10 / 30 | Total Loss: 1.0408282279968262 | KNN Loss: 6.227065086364746 | BCE Loss: 1.0408282279968262\n",
      "Epoch 277 / 500 | iteration 15 / 30 | Total Loss: 1.0564390420913696 | KNN Loss: 6.226899147033691 | BCE Loss: 1.0564390420913696\n",
      "Epoch 277 / 500 | iteration 20 / 30 | Total Loss: 1.0513758659362793 | KNN Loss: 6.226822376251221 | BCE Loss: 1.0513758659362793\n",
      "Epoch 277 / 500 | iteration 25 / 30 | Total Loss: 1.0385897159576416 | KNN Loss: 6.226856708526611 | BCE Loss: 1.0385897159576416\n",
      "Epoch 278 / 500 | iteration 0 / 30 | Total Loss: 1.0442543029785156 | KNN Loss: 6.226783752441406 | BCE Loss: 1.0442543029785156\n",
      "Epoch 278 / 500 | iteration 5 / 30 | Total Loss: 1.0448788404464722 | KNN Loss: 6.226747512817383 | BCE Loss: 1.0448788404464722\n",
      "Epoch 278 / 500 | iteration 10 / 30 | Total Loss: 1.0636544227600098 | KNN Loss: 6.226918697357178 | BCE Loss: 1.0636544227600098\n",
      "Epoch 278 / 500 | iteration 15 / 30 | Total Loss: 1.0448739528656006 | KNN Loss: 6.226891994476318 | BCE Loss: 1.0448739528656006\n",
      "Epoch 278 / 500 | iteration 20 / 30 | Total Loss: 1.054610013961792 | KNN Loss: 6.227137565612793 | BCE Loss: 1.054610013961792\n",
      "Epoch 278 / 500 | iteration 25 / 30 | Total Loss: 1.0511802434921265 | KNN Loss: 6.226772785186768 | BCE Loss: 1.0511802434921265\n",
      "Epoch 279 / 500 | iteration 0 / 30 | Total Loss: 1.0597164630889893 | KNN Loss: 6.227128028869629 | BCE Loss: 1.0597164630889893\n",
      "Epoch 279 / 500 | iteration 5 / 30 | Total Loss: 1.0642955303192139 | KNN Loss: 6.226720809936523 | BCE Loss: 1.0642955303192139\n",
      "Epoch 279 / 500 | iteration 10 / 30 | Total Loss: 1.0586204528808594 | KNN Loss: 6.227115631103516 | BCE Loss: 1.0586204528808594\n",
      "Epoch 279 / 500 | iteration 15 / 30 | Total Loss: 1.0412873029708862 | KNN Loss: 6.226724147796631 | BCE Loss: 1.0412873029708862\n",
      "Epoch 279 / 500 | iteration 20 / 30 | Total Loss: 1.0352462530136108 | KNN Loss: 6.22689962387085 | BCE Loss: 1.0352462530136108\n",
      "Epoch 279 / 500 | iteration 25 / 30 | Total Loss: 1.0641424655914307 | KNN Loss: 6.227092742919922 | BCE Loss: 1.0641424655914307\n",
      "Epoch 280 / 500 | iteration 0 / 30 | Total Loss: 1.0414189100265503 | KNN Loss: 6.226810932159424 | BCE Loss: 1.0414189100265503\n",
      "Epoch 280 / 500 | iteration 5 / 30 | Total Loss: 1.05023193359375 | KNN Loss: 6.226719379425049 | BCE Loss: 1.05023193359375\n",
      "Epoch 280 / 500 | iteration 10 / 30 | Total Loss: 1.0611950159072876 | KNN Loss: 6.227033615112305 | BCE Loss: 1.0611950159072876\n",
      "Epoch 280 / 500 | iteration 15 / 30 | Total Loss: 1.0405607223510742 | KNN Loss: 6.226743221282959 | BCE Loss: 1.0405607223510742\n",
      "Epoch 280 / 500 | iteration 20 / 30 | Total Loss: 1.0637152194976807 | KNN Loss: 6.22656774520874 | BCE Loss: 1.0637152194976807\n",
      "Epoch 280 / 500 | iteration 25 / 30 | Total Loss: 1.0382320880889893 | KNN Loss: 6.226637363433838 | BCE Loss: 1.0382320880889893\n",
      "Epoch 281 / 500 | iteration 0 / 30 | Total Loss: 1.0710231065750122 | KNN Loss: 6.2270636558532715 | BCE Loss: 1.0710231065750122\n",
      "Epoch 281 / 500 | iteration 5 / 30 | Total Loss: 1.0180656909942627 | KNN Loss: 6.226805686950684 | BCE Loss: 1.0180656909942627\n",
      "Epoch 281 / 500 | iteration 10 / 30 | Total Loss: 1.0756152868270874 | KNN Loss: 6.227201461791992 | BCE Loss: 1.0756152868270874\n",
      "Epoch 281 / 500 | iteration 15 / 30 | Total Loss: 1.0747735500335693 | KNN Loss: 6.226598739624023 | BCE Loss: 1.0747735500335693\n",
      "Epoch 281 / 500 | iteration 20 / 30 | Total Loss: 1.0454221963882446 | KNN Loss: 6.227042198181152 | BCE Loss: 1.0454221963882446\n",
      "Epoch 281 / 500 | iteration 25 / 30 | Total Loss: 1.0625994205474854 | KNN Loss: 6.226917743682861 | BCE Loss: 1.0625994205474854\n",
      "Epoch   282: reducing learning rate of group 0 to 2.7927e-06.\n",
      "Epoch 282 / 500 | iteration 0 / 30 | Total Loss: 1.032944917678833 | KNN Loss: 6.226982593536377 | BCE Loss: 1.032944917678833\n",
      "Epoch 282 / 500 | iteration 5 / 30 | Total Loss: 1.0485539436340332 | KNN Loss: 6.22694206237793 | BCE Loss: 1.0485539436340332\n",
      "Epoch 282 / 500 | iteration 10 / 30 | Total Loss: 1.0644878149032593 | KNN Loss: 6.226921558380127 | BCE Loss: 1.0644878149032593\n",
      "Epoch 282 / 500 | iteration 15 / 30 | Total Loss: 1.0505163669586182 | KNN Loss: 6.226943016052246 | BCE Loss: 1.0505163669586182\n",
      "Epoch 282 / 500 | iteration 20 / 30 | Total Loss: 1.0479202270507812 | KNN Loss: 6.226797103881836 | BCE Loss: 1.0479202270507812\n",
      "Epoch 282 / 500 | iteration 25 / 30 | Total Loss: 1.0773272514343262 | KNN Loss: 6.227039337158203 | BCE Loss: 1.0773272514343262\n",
      "Epoch 283 / 500 | iteration 0 / 30 | Total Loss: 1.042654275894165 | KNN Loss: 6.227085590362549 | BCE Loss: 1.042654275894165\n",
      "Epoch 283 / 500 | iteration 5 / 30 | Total Loss: 1.085170030593872 | KNN Loss: 6.226871013641357 | BCE Loss: 1.085170030593872\n",
      "Epoch 283 / 500 | iteration 10 / 30 | Total Loss: 1.0231115818023682 | KNN Loss: 6.226943492889404 | BCE Loss: 1.0231115818023682\n",
      "Epoch 283 / 500 | iteration 15 / 30 | Total Loss: 1.0762405395507812 | KNN Loss: 6.227149486541748 | BCE Loss: 1.0762405395507812\n",
      "Epoch 283 / 500 | iteration 20 / 30 | Total Loss: 1.0619380474090576 | KNN Loss: 6.226808071136475 | BCE Loss: 1.0619380474090576\n",
      "Epoch 283 / 500 | iteration 25 / 30 | Total Loss: 1.0354793071746826 | KNN Loss: 6.226740837097168 | BCE Loss: 1.0354793071746826\n",
      "Epoch 284 / 500 | iteration 0 / 30 | Total Loss: 1.0364724397659302 | KNN Loss: 6.226772308349609 | BCE Loss: 1.0364724397659302\n",
      "Epoch 284 / 500 | iteration 5 / 30 | Total Loss: 1.0389506816864014 | KNN Loss: 6.226837635040283 | BCE Loss: 1.0389506816864014\n",
      "Epoch 284 / 500 | iteration 10 / 30 | Total Loss: 1.040982723236084 | KNN Loss: 6.2269206047058105 | BCE Loss: 1.040982723236084\n",
      "Epoch 284 / 500 | iteration 15 / 30 | Total Loss: 1.0695829391479492 | KNN Loss: 6.227019786834717 | BCE Loss: 1.0695829391479492\n",
      "Epoch 284 / 500 | iteration 20 / 30 | Total Loss: 1.0553944110870361 | KNN Loss: 6.2266130447387695 | BCE Loss: 1.0553944110870361\n",
      "Epoch 284 / 500 | iteration 25 / 30 | Total Loss: 1.0497844219207764 | KNN Loss: 6.226893424987793 | BCE Loss: 1.0497844219207764\n",
      "Epoch 285 / 500 | iteration 0 / 30 | Total Loss: 1.0470706224441528 | KNN Loss: 6.227010250091553 | BCE Loss: 1.0470706224441528\n",
      "Epoch 285 / 500 | iteration 5 / 30 | Total Loss: 1.0587871074676514 | KNN Loss: 6.226694583892822 | BCE Loss: 1.0587871074676514\n",
      "Epoch 285 / 500 | iteration 10 / 30 | Total Loss: 1.0507758855819702 | KNN Loss: 6.226999759674072 | BCE Loss: 1.0507758855819702\n",
      "Epoch 285 / 500 | iteration 15 / 30 | Total Loss: 1.0210654735565186 | KNN Loss: 6.22672700881958 | BCE Loss: 1.0210654735565186\n",
      "Epoch 285 / 500 | iteration 20 / 30 | Total Loss: 1.052535891532898 | KNN Loss: 6.226921081542969 | BCE Loss: 1.052535891532898\n",
      "Epoch 285 / 500 | iteration 25 / 30 | Total Loss: 1.0240938663482666 | KNN Loss: 6.226815223693848 | BCE Loss: 1.0240938663482666\n",
      "Epoch 286 / 500 | iteration 0 / 30 | Total Loss: 1.0342885255813599 | KNN Loss: 6.22679328918457 | BCE Loss: 1.0342885255813599\n",
      "Epoch 286 / 500 | iteration 5 / 30 | Total Loss: 1.0432047843933105 | KNN Loss: 6.226831436157227 | BCE Loss: 1.0432047843933105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286 / 500 | iteration 10 / 30 | Total Loss: 1.0557183027267456 | KNN Loss: 6.227101802825928 | BCE Loss: 1.0557183027267456\n",
      "Epoch 286 / 500 | iteration 15 / 30 | Total Loss: 1.0336003303527832 | KNN Loss: 6.2269206047058105 | BCE Loss: 1.0336003303527832\n",
      "Epoch 286 / 500 | iteration 20 / 30 | Total Loss: 1.0574395656585693 | KNN Loss: 6.226722240447998 | BCE Loss: 1.0574395656585693\n",
      "Epoch 286 / 500 | iteration 25 / 30 | Total Loss: 1.031369686126709 | KNN Loss: 6.226720333099365 | BCE Loss: 1.031369686126709\n",
      "Epoch 287 / 500 | iteration 0 / 30 | Total Loss: 1.071319580078125 | KNN Loss: 6.226885795593262 | BCE Loss: 1.071319580078125\n",
      "Epoch 287 / 500 | iteration 5 / 30 | Total Loss: 1.043230652809143 | KNN Loss: 6.226687908172607 | BCE Loss: 1.043230652809143\n",
      "Epoch 287 / 500 | iteration 10 / 30 | Total Loss: 1.0752365589141846 | KNN Loss: 6.227033615112305 | BCE Loss: 1.0752365589141846\n",
      "Epoch 287 / 500 | iteration 15 / 30 | Total Loss: 1.0289485454559326 | KNN Loss: 6.22705078125 | BCE Loss: 1.0289485454559326\n",
      "Epoch 287 / 500 | iteration 20 / 30 | Total Loss: 1.048688530921936 | KNN Loss: 6.2268195152282715 | BCE Loss: 1.048688530921936\n",
      "Epoch 287 / 500 | iteration 25 / 30 | Total Loss: 1.0387094020843506 | KNN Loss: 6.227004051208496 | BCE Loss: 1.0387094020843506\n",
      "Epoch 288 / 500 | iteration 0 / 30 | Total Loss: 1.0553057193756104 | KNN Loss: 6.226865291595459 | BCE Loss: 1.0553057193756104\n",
      "Epoch 288 / 500 | iteration 5 / 30 | Total Loss: 1.0733330249786377 | KNN Loss: 6.226852893829346 | BCE Loss: 1.0733330249786377\n",
      "Epoch 288 / 500 | iteration 10 / 30 | Total Loss: 1.070518970489502 | KNN Loss: 6.227174282073975 | BCE Loss: 1.070518970489502\n",
      "Epoch 288 / 500 | iteration 15 / 30 | Total Loss: 1.0802900791168213 | KNN Loss: 6.2269721031188965 | BCE Loss: 1.0802900791168213\n",
      "Epoch 288 / 500 | iteration 20 / 30 | Total Loss: 1.0498833656311035 | KNN Loss: 6.226771831512451 | BCE Loss: 1.0498833656311035\n",
      "Epoch 288 / 500 | iteration 25 / 30 | Total Loss: 1.054839849472046 | KNN Loss: 6.226905822753906 | BCE Loss: 1.054839849472046\n",
      "Epoch 289 / 500 | iteration 0 / 30 | Total Loss: 1.0527660846710205 | KNN Loss: 6.226916790008545 | BCE Loss: 1.0527660846710205\n",
      "Epoch 289 / 500 | iteration 5 / 30 | Total Loss: 1.073768973350525 | KNN Loss: 6.226938724517822 | BCE Loss: 1.073768973350525\n",
      "Epoch 289 / 500 | iteration 10 / 30 | Total Loss: 1.0374810695648193 | KNN Loss: 6.226746559143066 | BCE Loss: 1.0374810695648193\n",
      "Epoch 289 / 500 | iteration 15 / 30 | Total Loss: 1.022892713546753 | KNN Loss: 6.226977825164795 | BCE Loss: 1.022892713546753\n",
      "Epoch 289 / 500 | iteration 20 / 30 | Total Loss: 1.0510213375091553 | KNN Loss: 6.226796627044678 | BCE Loss: 1.0510213375091553\n",
      "Epoch 289 / 500 | iteration 25 / 30 | Total Loss: 1.0485007762908936 | KNN Loss: 6.2264814376831055 | BCE Loss: 1.0485007762908936\n",
      "Epoch 290 / 500 | iteration 0 / 30 | Total Loss: 1.0189355611801147 | KNN Loss: 6.226713180541992 | BCE Loss: 1.0189355611801147\n",
      "Epoch 290 / 500 | iteration 5 / 30 | Total Loss: 1.0393803119659424 | KNN Loss: 6.226864814758301 | BCE Loss: 1.0393803119659424\n",
      "Epoch 290 / 500 | iteration 10 / 30 | Total Loss: 1.0705245733261108 | KNN Loss: 6.226751804351807 | BCE Loss: 1.0705245733261108\n",
      "Epoch 290 / 500 | iteration 15 / 30 | Total Loss: 1.0702085494995117 | KNN Loss: 6.227046966552734 | BCE Loss: 1.0702085494995117\n",
      "Epoch 290 / 500 | iteration 20 / 30 | Total Loss: 1.035370111465454 | KNN Loss: 6.22686243057251 | BCE Loss: 1.035370111465454\n",
      "Epoch 290 / 500 | iteration 25 / 30 | Total Loss: 1.0109375715255737 | KNN Loss: 6.2270402908325195 | BCE Loss: 1.0109375715255737\n",
      "Epoch 291 / 500 | iteration 0 / 30 | Total Loss: 1.0553922653198242 | KNN Loss: 6.226867198944092 | BCE Loss: 1.0553922653198242\n",
      "Epoch 291 / 500 | iteration 5 / 30 | Total Loss: 1.0405998229980469 | KNN Loss: 6.227049350738525 | BCE Loss: 1.0405998229980469\n",
      "Epoch 291 / 500 | iteration 10 / 30 | Total Loss: 1.0464708805084229 | KNN Loss: 6.226554870605469 | BCE Loss: 1.0464708805084229\n",
      "Epoch 291 / 500 | iteration 15 / 30 | Total Loss: 1.0458844900131226 | KNN Loss: 6.226775646209717 | BCE Loss: 1.0458844900131226\n",
      "Epoch 291 / 500 | iteration 20 / 30 | Total Loss: 1.0361226797103882 | KNN Loss: 6.227108955383301 | BCE Loss: 1.0361226797103882\n",
      "Epoch 291 / 500 | iteration 25 / 30 | Total Loss: 1.072298288345337 | KNN Loss: 6.227203845977783 | BCE Loss: 1.072298288345337\n",
      "Epoch 292 / 500 | iteration 0 / 30 | Total Loss: 1.0826218128204346 | KNN Loss: 6.226743698120117 | BCE Loss: 1.0826218128204346\n",
      "Epoch 292 / 500 | iteration 5 / 30 | Total Loss: 1.0432456731796265 | KNN Loss: 6.226858139038086 | BCE Loss: 1.0432456731796265\n",
      "Epoch 292 / 500 | iteration 10 / 30 | Total Loss: 1.0730321407318115 | KNN Loss: 6.226969242095947 | BCE Loss: 1.0730321407318115\n",
      "Epoch 292 / 500 | iteration 15 / 30 | Total Loss: 1.046538233757019 | KNN Loss: 6.227008819580078 | BCE Loss: 1.046538233757019\n",
      "Epoch 292 / 500 | iteration 20 / 30 | Total Loss: 1.0730432271957397 | KNN Loss: 6.22706937789917 | BCE Loss: 1.0730432271957397\n",
      "Epoch 292 / 500 | iteration 25 / 30 | Total Loss: 1.051456332206726 | KNN Loss: 6.227201461791992 | BCE Loss: 1.051456332206726\n",
      "Epoch   293: reducing learning rate of group 0 to 1.9549e-06.\n",
      "Epoch 293 / 500 | iteration 0 / 30 | Total Loss: 1.0636630058288574 | KNN Loss: 6.22684907913208 | BCE Loss: 1.0636630058288574\n",
      "Epoch 293 / 500 | iteration 5 / 30 | Total Loss: 1.0503103733062744 | KNN Loss: 6.226947784423828 | BCE Loss: 1.0503103733062744\n",
      "Epoch 293 / 500 | iteration 10 / 30 | Total Loss: 1.0734193325042725 | KNN Loss: 6.22678804397583 | BCE Loss: 1.0734193325042725\n",
      "Epoch 293 / 500 | iteration 15 / 30 | Total Loss: 1.0353806018829346 | KNN Loss: 6.2268218994140625 | BCE Loss: 1.0353806018829346\n",
      "Epoch 293 / 500 | iteration 20 / 30 | Total Loss: 1.0716619491577148 | KNN Loss: 6.226807594299316 | BCE Loss: 1.0716619491577148\n",
      "Epoch 293 / 500 | iteration 25 / 30 | Total Loss: 1.0498337745666504 | KNN Loss: 6.226892948150635 | BCE Loss: 1.0498337745666504\n",
      "Epoch 294 / 500 | iteration 0 / 30 | Total Loss: 1.0410809516906738 | KNN Loss: 6.2271199226379395 | BCE Loss: 1.0410809516906738\n",
      "Epoch 294 / 500 | iteration 5 / 30 | Total Loss: 1.0110342502593994 | KNN Loss: 6.226930618286133 | BCE Loss: 1.0110342502593994\n",
      "Epoch 294 / 500 | iteration 10 / 30 | Total Loss: 1.0375961065292358 | KNN Loss: 6.227003574371338 | BCE Loss: 1.0375961065292358\n",
      "Epoch 294 / 500 | iteration 15 / 30 | Total Loss: 1.030902624130249 | KNN Loss: 6.2268853187561035 | BCE Loss: 1.030902624130249\n",
      "Epoch 294 / 500 | iteration 20 / 30 | Total Loss: 1.0586270093917847 | KNN Loss: 6.226456165313721 | BCE Loss: 1.0586270093917847\n",
      "Epoch 294 / 500 | iteration 25 / 30 | Total Loss: 1.0507700443267822 | KNN Loss: 6.226917743682861 | BCE Loss: 1.0507700443267822\n",
      "Epoch 295 / 500 | iteration 0 / 30 | Total Loss: 1.044221043586731 | KNN Loss: 6.226681232452393 | BCE Loss: 1.044221043586731\n",
      "Epoch 295 / 500 | iteration 5 / 30 | Total Loss: 1.0744819641113281 | KNN Loss: 6.226839542388916 | BCE Loss: 1.0744819641113281\n",
      "Epoch 295 / 500 | iteration 10 / 30 | Total Loss: 1.0357286930084229 | KNN Loss: 6.226666450500488 | BCE Loss: 1.0357286930084229\n",
      "Epoch 295 / 500 | iteration 15 / 30 | Total Loss: 1.083000898361206 | KNN Loss: 6.22666072845459 | BCE Loss: 1.083000898361206\n",
      "Epoch 295 / 500 | iteration 20 / 30 | Total Loss: 1.0790355205535889 | KNN Loss: 6.226995944976807 | BCE Loss: 1.0790355205535889\n",
      "Epoch 295 / 500 | iteration 25 / 30 | Total Loss: 1.0707926750183105 | KNN Loss: 6.227113723754883 | BCE Loss: 1.0707926750183105\n",
      "Epoch 296 / 500 | iteration 0 / 30 | Total Loss: 1.0851809978485107 | KNN Loss: 6.227052211761475 | BCE Loss: 1.0851809978485107\n",
      "Epoch 296 / 500 | iteration 5 / 30 | Total Loss: 1.0577975511550903 | KNN Loss: 6.226644515991211 | BCE Loss: 1.0577975511550903\n",
      "Epoch 296 / 500 | iteration 10 / 30 | Total Loss: 1.086787223815918 | KNN Loss: 6.226682186126709 | BCE Loss: 1.086787223815918\n",
      "Epoch 296 / 500 | iteration 15 / 30 | Total Loss: 1.0573921203613281 | KNN Loss: 6.226998805999756 | BCE Loss: 1.0573921203613281\n",
      "Epoch 296 / 500 | iteration 20 / 30 | Total Loss: 1.0480326414108276 | KNN Loss: 6.226840972900391 | BCE Loss: 1.0480326414108276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296 / 500 | iteration 25 / 30 | Total Loss: 1.0411936044692993 | KNN Loss: 6.22706413269043 | BCE Loss: 1.0411936044692993\n",
      "Epoch 297 / 500 | iteration 0 / 30 | Total Loss: 1.055984616279602 | KNN Loss: 6.227064609527588 | BCE Loss: 1.055984616279602\n",
      "Epoch 297 / 500 | iteration 5 / 30 | Total Loss: 1.0472931861877441 | KNN Loss: 6.226950645446777 | BCE Loss: 1.0472931861877441\n",
      "Epoch 297 / 500 | iteration 10 / 30 | Total Loss: 1.00771164894104 | KNN Loss: 6.227148056030273 | BCE Loss: 1.00771164894104\n",
      "Epoch 297 / 500 | iteration 15 / 30 | Total Loss: 1.0632202625274658 | KNN Loss: 6.226799011230469 | BCE Loss: 1.0632202625274658\n",
      "Epoch 297 / 500 | iteration 20 / 30 | Total Loss: 1.030023217201233 | KNN Loss: 6.226908206939697 | BCE Loss: 1.030023217201233\n",
      "Epoch 297 / 500 | iteration 25 / 30 | Total Loss: 1.0804083347320557 | KNN Loss: 6.226727485656738 | BCE Loss: 1.0804083347320557\n",
      "Epoch 298 / 500 | iteration 0 / 30 | Total Loss: 1.0481376647949219 | KNN Loss: 6.226726055145264 | BCE Loss: 1.0481376647949219\n",
      "Epoch 298 / 500 | iteration 5 / 30 | Total Loss: 1.075466275215149 | KNN Loss: 6.226741313934326 | BCE Loss: 1.075466275215149\n",
      "Epoch 298 / 500 | iteration 10 / 30 | Total Loss: 1.0708446502685547 | KNN Loss: 6.226760387420654 | BCE Loss: 1.0708446502685547\n",
      "Epoch 298 / 500 | iteration 15 / 30 | Total Loss: 1.0777437686920166 | KNN Loss: 6.22713041305542 | BCE Loss: 1.0777437686920166\n",
      "Epoch 298 / 500 | iteration 20 / 30 | Total Loss: 1.0792043209075928 | KNN Loss: 6.227018356323242 | BCE Loss: 1.0792043209075928\n",
      "Epoch 298 / 500 | iteration 25 / 30 | Total Loss: 1.0546927452087402 | KNN Loss: 6.226857662200928 | BCE Loss: 1.0546927452087402\n",
      "Epoch 299 / 500 | iteration 0 / 30 | Total Loss: 1.0392733812332153 | KNN Loss: 6.226954936981201 | BCE Loss: 1.0392733812332153\n",
      "Epoch 299 / 500 | iteration 5 / 30 | Total Loss: 1.080354928970337 | KNN Loss: 6.227004051208496 | BCE Loss: 1.080354928970337\n",
      "Epoch 299 / 500 | iteration 10 / 30 | Total Loss: 1.043046474456787 | KNN Loss: 6.226772785186768 | BCE Loss: 1.043046474456787\n",
      "Epoch 299 / 500 | iteration 15 / 30 | Total Loss: 1.0685763359069824 | KNN Loss: 6.227066516876221 | BCE Loss: 1.0685763359069824\n",
      "Epoch 299 / 500 | iteration 20 / 30 | Total Loss: 1.0675475597381592 | KNN Loss: 6.22707986831665 | BCE Loss: 1.0675475597381592\n",
      "Epoch 299 / 500 | iteration 25 / 30 | Total Loss: 1.041656732559204 | KNN Loss: 6.226812839508057 | BCE Loss: 1.041656732559204\n",
      "Epoch 300 / 500 | iteration 0 / 30 | Total Loss: 1.0367050170898438 | KNN Loss: 6.2269511222839355 | BCE Loss: 1.0367050170898438\n",
      "Epoch 300 / 500 | iteration 5 / 30 | Total Loss: 1.0522966384887695 | KNN Loss: 6.226932048797607 | BCE Loss: 1.0522966384887695\n",
      "Epoch 300 / 500 | iteration 10 / 30 | Total Loss: 1.0351686477661133 | KNN Loss: 6.226795673370361 | BCE Loss: 1.0351686477661133\n",
      "Epoch 300 / 500 | iteration 15 / 30 | Total Loss: 1.0325396060943604 | KNN Loss: 6.226786136627197 | BCE Loss: 1.0325396060943604\n",
      "Epoch 300 / 500 | iteration 20 / 30 | Total Loss: 1.0343356132507324 | KNN Loss: 6.226596832275391 | BCE Loss: 1.0343356132507324\n",
      "Epoch 300 / 500 | iteration 25 / 30 | Total Loss: 1.0553231239318848 | KNN Loss: 6.226772308349609 | BCE Loss: 1.0553231239318848\n",
      "Epoch 301 / 500 | iteration 0 / 30 | Total Loss: 1.0576221942901611 | KNN Loss: 6.226898193359375 | BCE Loss: 1.0576221942901611\n",
      "Epoch 301 / 500 | iteration 5 / 30 | Total Loss: 1.0357393026351929 | KNN Loss: 6.226862907409668 | BCE Loss: 1.0357393026351929\n",
      "Epoch 301 / 500 | iteration 10 / 30 | Total Loss: 1.0681726932525635 | KNN Loss: 6.226872444152832 | BCE Loss: 1.0681726932525635\n",
      "Epoch 301 / 500 | iteration 15 / 30 | Total Loss: 1.066506028175354 | KNN Loss: 6.226842880249023 | BCE Loss: 1.066506028175354\n",
      "Epoch 301 / 500 | iteration 20 / 30 | Total Loss: 1.0553302764892578 | KNN Loss: 6.226723670959473 | BCE Loss: 1.0553302764892578\n",
      "Epoch 301 / 500 | iteration 25 / 30 | Total Loss: 1.0558823347091675 | KNN Loss: 6.226582050323486 | BCE Loss: 1.0558823347091675\n",
      "Epoch 302 / 500 | iteration 0 / 30 | Total Loss: 1.0437344312667847 | KNN Loss: 6.226935863494873 | BCE Loss: 1.0437344312667847\n",
      "Epoch 302 / 500 | iteration 5 / 30 | Total Loss: 1.0687975883483887 | KNN Loss: 6.227028846740723 | BCE Loss: 1.0687975883483887\n",
      "Epoch 302 / 500 | iteration 10 / 30 | Total Loss: 1.0758674144744873 | KNN Loss: 6.226868629455566 | BCE Loss: 1.0758674144744873\n",
      "Epoch 302 / 500 | iteration 15 / 30 | Total Loss: 1.0453327894210815 | KNN Loss: 6.227250099182129 | BCE Loss: 1.0453327894210815\n",
      "Epoch 302 / 500 | iteration 20 / 30 | Total Loss: 1.0450515747070312 | KNN Loss: 6.227108955383301 | BCE Loss: 1.0450515747070312\n",
      "Epoch 302 / 500 | iteration 25 / 30 | Total Loss: 1.041144609451294 | KNN Loss: 6.22689962387085 | BCE Loss: 1.041144609451294\n",
      "Epoch 303 / 500 | iteration 0 / 30 | Total Loss: 1.0436164140701294 | KNN Loss: 6.226777076721191 | BCE Loss: 1.0436164140701294\n",
      "Epoch 303 / 500 | iteration 5 / 30 | Total Loss: 1.05875825881958 | KNN Loss: 6.226709842681885 | BCE Loss: 1.05875825881958\n",
      "Epoch 303 / 500 | iteration 10 / 30 | Total Loss: 1.0789499282836914 | KNN Loss: 6.226955413818359 | BCE Loss: 1.0789499282836914\n",
      "Epoch 303 / 500 | iteration 15 / 30 | Total Loss: 1.0405770540237427 | KNN Loss: 6.226725101470947 | BCE Loss: 1.0405770540237427\n",
      "Epoch 303 / 500 | iteration 20 / 30 | Total Loss: 1.041689157485962 | KNN Loss: 6.226902484893799 | BCE Loss: 1.041689157485962\n",
      "Epoch 303 / 500 | iteration 25 / 30 | Total Loss: 1.0808241367340088 | KNN Loss: 6.227234840393066 | BCE Loss: 1.0808241367340088\n",
      "Epoch   304: reducing learning rate of group 0 to 1.3684e-06.\n",
      "Epoch 304 / 500 | iteration 0 / 30 | Total Loss: 1.0612645149230957 | KNN Loss: 6.227028846740723 | BCE Loss: 1.0612645149230957\n",
      "Epoch 304 / 500 | iteration 5 / 30 | Total Loss: 1.0503735542297363 | KNN Loss: 6.2265520095825195 | BCE Loss: 1.0503735542297363\n",
      "Epoch 304 / 500 | iteration 10 / 30 | Total Loss: 1.0561715364456177 | KNN Loss: 6.226864337921143 | BCE Loss: 1.0561715364456177\n",
      "Epoch 304 / 500 | iteration 15 / 30 | Total Loss: 1.0412702560424805 | KNN Loss: 6.226926326751709 | BCE Loss: 1.0412702560424805\n",
      "Epoch 304 / 500 | iteration 20 / 30 | Total Loss: 1.0811158418655396 | KNN Loss: 6.227063179016113 | BCE Loss: 1.0811158418655396\n",
      "Epoch 304 / 500 | iteration 25 / 30 | Total Loss: 1.0451921224594116 | KNN Loss: 6.226984977722168 | BCE Loss: 1.0451921224594116\n",
      "Epoch 305 / 500 | iteration 0 / 30 | Total Loss: 1.0662167072296143 | KNN Loss: 6.226893424987793 | BCE Loss: 1.0662167072296143\n",
      "Epoch 305 / 500 | iteration 5 / 30 | Total Loss: 1.0332727432250977 | KNN Loss: 6.2271528244018555 | BCE Loss: 1.0332727432250977\n",
      "Epoch 305 / 500 | iteration 10 / 30 | Total Loss: 1.054306983947754 | KNN Loss: 6.227184772491455 | BCE Loss: 1.054306983947754\n",
      "Epoch 305 / 500 | iteration 15 / 30 | Total Loss: 1.0733047723770142 | KNN Loss: 6.226884365081787 | BCE Loss: 1.0733047723770142\n",
      "Epoch 305 / 500 | iteration 20 / 30 | Total Loss: 1.03875732421875 | KNN Loss: 6.227128505706787 | BCE Loss: 1.03875732421875\n",
      "Epoch 305 / 500 | iteration 25 / 30 | Total Loss: 1.0208438634872437 | KNN Loss: 6.226786136627197 | BCE Loss: 1.0208438634872437\n",
      "Epoch 306 / 500 | iteration 0 / 30 | Total Loss: 1.0554838180541992 | KNN Loss: 6.226924419403076 | BCE Loss: 1.0554838180541992\n",
      "Epoch 306 / 500 | iteration 5 / 30 | Total Loss: 1.0592000484466553 | KNN Loss: 6.227030277252197 | BCE Loss: 1.0592000484466553\n",
      "Epoch 306 / 500 | iteration 10 / 30 | Total Loss: 1.04921293258667 | KNN Loss: 6.22677755355835 | BCE Loss: 1.04921293258667\n",
      "Epoch 306 / 500 | iteration 15 / 30 | Total Loss: 1.0530822277069092 | KNN Loss: 6.22689962387085 | BCE Loss: 1.0530822277069092\n",
      "Epoch 306 / 500 | iteration 20 / 30 | Total Loss: 1.0432329177856445 | KNN Loss: 6.226952075958252 | BCE Loss: 1.0432329177856445\n",
      "Epoch 306 / 500 | iteration 25 / 30 | Total Loss: 1.068258285522461 | KNN Loss: 6.227058410644531 | BCE Loss: 1.068258285522461\n",
      "Epoch 307 / 500 | iteration 0 / 30 | Total Loss: 1.055821418762207 | KNN Loss: 6.227001190185547 | BCE Loss: 1.055821418762207\n",
      "Epoch 307 / 500 | iteration 5 / 30 | Total Loss: 1.0178813934326172 | KNN Loss: 6.227060794830322 | BCE Loss: 1.0178813934326172\n",
      "Epoch 307 / 500 | iteration 10 / 30 | Total Loss: 1.068810224533081 | KNN Loss: 6.2268967628479 | BCE Loss: 1.068810224533081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307 / 500 | iteration 15 / 30 | Total Loss: 1.062995433807373 | KNN Loss: 6.227226734161377 | BCE Loss: 1.062995433807373\n",
      "Epoch 307 / 500 | iteration 20 / 30 | Total Loss: 1.0576951503753662 | KNN Loss: 6.226957321166992 | BCE Loss: 1.0576951503753662\n",
      "Epoch 307 / 500 | iteration 25 / 30 | Total Loss: 1.057387113571167 | KNN Loss: 6.227044105529785 | BCE Loss: 1.057387113571167\n",
      "Epoch 308 / 500 | iteration 0 / 30 | Total Loss: 1.0620652437210083 | KNN Loss: 6.226962089538574 | BCE Loss: 1.0620652437210083\n",
      "Epoch 308 / 500 | iteration 5 / 30 | Total Loss: 1.0354008674621582 | KNN Loss: 6.226673603057861 | BCE Loss: 1.0354008674621582\n",
      "Epoch 308 / 500 | iteration 10 / 30 | Total Loss: 1.067190170288086 | KNN Loss: 6.227007865905762 | BCE Loss: 1.067190170288086\n",
      "Epoch 308 / 500 | iteration 15 / 30 | Total Loss: 1.0475444793701172 | KNN Loss: 6.22662353515625 | BCE Loss: 1.0475444793701172\n",
      "Epoch 308 / 500 | iteration 20 / 30 | Total Loss: 1.0546373128890991 | KNN Loss: 6.2266845703125 | BCE Loss: 1.0546373128890991\n",
      "Epoch 308 / 500 | iteration 25 / 30 | Total Loss: 1.0737745761871338 | KNN Loss: 6.226643085479736 | BCE Loss: 1.0737745761871338\n",
      "Epoch 309 / 500 | iteration 0 / 30 | Total Loss: 1.0578020811080933 | KNN Loss: 6.226951599121094 | BCE Loss: 1.0578020811080933\n",
      "Epoch 309 / 500 | iteration 5 / 30 | Total Loss: 1.0641506910324097 | KNN Loss: 6.227057933807373 | BCE Loss: 1.0641506910324097\n",
      "Epoch 309 / 500 | iteration 10 / 30 | Total Loss: 1.071962594985962 | KNN Loss: 6.226897239685059 | BCE Loss: 1.071962594985962\n",
      "Epoch 309 / 500 | iteration 15 / 30 | Total Loss: 1.0359599590301514 | KNN Loss: 6.226814270019531 | BCE Loss: 1.0359599590301514\n",
      "Epoch 309 / 500 | iteration 20 / 30 | Total Loss: 1.031517505645752 | KNN Loss: 6.226823806762695 | BCE Loss: 1.031517505645752\n",
      "Epoch 309 / 500 | iteration 25 / 30 | Total Loss: 1.050947904586792 | KNN Loss: 6.22693395614624 | BCE Loss: 1.050947904586792\n",
      "Epoch 310 / 500 | iteration 0 / 30 | Total Loss: 1.0492256879806519 | KNN Loss: 6.2270073890686035 | BCE Loss: 1.0492256879806519\n",
      "Epoch 310 / 500 | iteration 5 / 30 | Total Loss: 1.0559197664260864 | KNN Loss: 6.227208137512207 | BCE Loss: 1.0559197664260864\n",
      "Epoch 310 / 500 | iteration 10 / 30 | Total Loss: 1.088549256324768 | KNN Loss: 6.22682523727417 | BCE Loss: 1.088549256324768\n",
      "Epoch 310 / 500 | iteration 15 / 30 | Total Loss: 1.0451349020004272 | KNN Loss: 6.226779460906982 | BCE Loss: 1.0451349020004272\n",
      "Epoch 310 / 500 | iteration 20 / 30 | Total Loss: 1.0337004661560059 | KNN Loss: 6.22681999206543 | BCE Loss: 1.0337004661560059\n",
      "Epoch 310 / 500 | iteration 25 / 30 | Total Loss: 1.020676612854004 | KNN Loss: 6.227163791656494 | BCE Loss: 1.020676612854004\n",
      "Epoch 311 / 500 | iteration 0 / 30 | Total Loss: 1.0628571510314941 | KNN Loss: 6.22712516784668 | BCE Loss: 1.0628571510314941\n",
      "Epoch 311 / 500 | iteration 5 / 30 | Total Loss: 1.0649080276489258 | KNN Loss: 6.2270941734313965 | BCE Loss: 1.0649080276489258\n",
      "Epoch 311 / 500 | iteration 10 / 30 | Total Loss: 1.0341598987579346 | KNN Loss: 6.227041244506836 | BCE Loss: 1.0341598987579346\n",
      "Epoch 311 / 500 | iteration 15 / 30 | Total Loss: 1.0664260387420654 | KNN Loss: 6.226881980895996 | BCE Loss: 1.0664260387420654\n",
      "Epoch 311 / 500 | iteration 20 / 30 | Total Loss: 1.0515644550323486 | KNN Loss: 6.226861476898193 | BCE Loss: 1.0515644550323486\n",
      "Epoch 311 / 500 | iteration 25 / 30 | Total Loss: 1.0474658012390137 | KNN Loss: 6.226873874664307 | BCE Loss: 1.0474658012390137\n",
      "Epoch 312 / 500 | iteration 0 / 30 | Total Loss: 1.0713491439819336 | KNN Loss: 6.226778030395508 | BCE Loss: 1.0713491439819336\n",
      "Epoch 312 / 500 | iteration 5 / 30 | Total Loss: 1.039672613143921 | KNN Loss: 6.2268476486206055 | BCE Loss: 1.039672613143921\n",
      "Epoch 312 / 500 | iteration 10 / 30 | Total Loss: 1.0348297357559204 | KNN Loss: 6.226770401000977 | BCE Loss: 1.0348297357559204\n",
      "Epoch 312 / 500 | iteration 15 / 30 | Total Loss: 1.058269739151001 | KNN Loss: 6.226593017578125 | BCE Loss: 1.058269739151001\n",
      "Epoch 312 / 500 | iteration 20 / 30 | Total Loss: 1.0481914281845093 | KNN Loss: 6.226536273956299 | BCE Loss: 1.0481914281845093\n",
      "Epoch 312 / 500 | iteration 25 / 30 | Total Loss: 1.0367364883422852 | KNN Loss: 6.2267374992370605 | BCE Loss: 1.0367364883422852\n",
      "Epoch 313 / 500 | iteration 0 / 30 | Total Loss: 1.0307128429412842 | KNN Loss: 6.226559162139893 | BCE Loss: 1.0307128429412842\n",
      "Epoch 313 / 500 | iteration 5 / 30 | Total Loss: 1.04535710811615 | KNN Loss: 6.22695255279541 | BCE Loss: 1.04535710811615\n",
      "Epoch 313 / 500 | iteration 10 / 30 | Total Loss: 1.045219898223877 | KNN Loss: 6.226980209350586 | BCE Loss: 1.045219898223877\n",
      "Epoch 313 / 500 | iteration 15 / 30 | Total Loss: 1.0389795303344727 | KNN Loss: 6.226942539215088 | BCE Loss: 1.0389795303344727\n",
      "Epoch 313 / 500 | iteration 20 / 30 | Total Loss: 1.0625317096710205 | KNN Loss: 6.226836681365967 | BCE Loss: 1.0625317096710205\n",
      "Epoch 313 / 500 | iteration 25 / 30 | Total Loss: 1.0355970859527588 | KNN Loss: 6.226790904998779 | BCE Loss: 1.0355970859527588\n",
      "Epoch 314 / 500 | iteration 0 / 30 | Total Loss: 1.0242040157318115 | KNN Loss: 6.226759433746338 | BCE Loss: 1.0242040157318115\n",
      "Epoch 314 / 500 | iteration 5 / 30 | Total Loss: 1.0264164209365845 | KNN Loss: 6.226917266845703 | BCE Loss: 1.0264164209365845\n",
      "Epoch 314 / 500 | iteration 10 / 30 | Total Loss: 1.06490159034729 | KNN Loss: 6.226901054382324 | BCE Loss: 1.06490159034729\n",
      "Epoch 314 / 500 | iteration 15 / 30 | Total Loss: 1.080863118171692 | KNN Loss: 6.226786136627197 | BCE Loss: 1.080863118171692\n",
      "Epoch 314 / 500 | iteration 20 / 30 | Total Loss: 1.0353355407714844 | KNN Loss: 6.227011203765869 | BCE Loss: 1.0353355407714844\n",
      "Epoch 314 / 500 | iteration 25 / 30 | Total Loss: 1.0400745868682861 | KNN Loss: 6.226803302764893 | BCE Loss: 1.0400745868682861\n",
      "Epoch   315: reducing learning rate of group 0 to 9.5791e-07.\n",
      "Epoch 315 / 500 | iteration 0 / 30 | Total Loss: 1.041558027267456 | KNN Loss: 6.226953983306885 | BCE Loss: 1.041558027267456\n",
      "Epoch 315 / 500 | iteration 5 / 30 | Total Loss: 1.0766708850860596 | KNN Loss: 6.226556301116943 | BCE Loss: 1.0766708850860596\n",
      "Epoch 315 / 500 | iteration 10 / 30 | Total Loss: 1.036750078201294 | KNN Loss: 6.227028846740723 | BCE Loss: 1.036750078201294\n",
      "Epoch 315 / 500 | iteration 15 / 30 | Total Loss: 1.057365894317627 | KNN Loss: 6.226846218109131 | BCE Loss: 1.057365894317627\n",
      "Epoch 315 / 500 | iteration 20 / 30 | Total Loss: 1.036754846572876 | KNN Loss: 6.226779460906982 | BCE Loss: 1.036754846572876\n",
      "Epoch 315 / 500 | iteration 25 / 30 | Total Loss: 1.0682283639907837 | KNN Loss: 6.227166652679443 | BCE Loss: 1.0682283639907837\n",
      "Epoch 316 / 500 | iteration 0 / 30 | Total Loss: 1.0520741939544678 | KNN Loss: 6.226875305175781 | BCE Loss: 1.0520741939544678\n",
      "Epoch 316 / 500 | iteration 5 / 30 | Total Loss: 1.0686142444610596 | KNN Loss: 6.226631164550781 | BCE Loss: 1.0686142444610596\n",
      "Epoch 316 / 500 | iteration 10 / 30 | Total Loss: 1.045574426651001 | KNN Loss: 6.227027893066406 | BCE Loss: 1.045574426651001\n",
      "Epoch 316 / 500 | iteration 15 / 30 | Total Loss: 1.0781402587890625 | KNN Loss: 6.226948261260986 | BCE Loss: 1.0781402587890625\n",
      "Epoch 316 / 500 | iteration 20 / 30 | Total Loss: 1.063399314880371 | KNN Loss: 6.227138996124268 | BCE Loss: 1.063399314880371\n",
      "Epoch 316 / 500 | iteration 25 / 30 | Total Loss: 1.0544002056121826 | KNN Loss: 6.226673603057861 | BCE Loss: 1.0544002056121826\n",
      "Epoch 317 / 500 | iteration 0 / 30 | Total Loss: 1.0825098752975464 | KNN Loss: 6.226909160614014 | BCE Loss: 1.0825098752975464\n",
      "Epoch 317 / 500 | iteration 5 / 30 | Total Loss: 1.0731961727142334 | KNN Loss: 6.227206707000732 | BCE Loss: 1.0731961727142334\n",
      "Epoch 317 / 500 | iteration 10 / 30 | Total Loss: 1.023863434791565 | KNN Loss: 6.226902008056641 | BCE Loss: 1.023863434791565\n",
      "Epoch 317 / 500 | iteration 15 / 30 | Total Loss: 1.0340642929077148 | KNN Loss: 6.226641654968262 | BCE Loss: 1.0340642929077148\n",
      "Epoch 317 / 500 | iteration 20 / 30 | Total Loss: 1.0457687377929688 | KNN Loss: 6.226659297943115 | BCE Loss: 1.0457687377929688\n",
      "Epoch 317 / 500 | iteration 25 / 30 | Total Loss: 1.043468713760376 | KNN Loss: 6.226730823516846 | BCE Loss: 1.043468713760376\n",
      "Epoch 318 / 500 | iteration 0 / 30 | Total Loss: 1.0169098377227783 | KNN Loss: 6.2266740798950195 | BCE Loss: 1.0169098377227783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318 / 500 | iteration 5 / 30 | Total Loss: 1.084618091583252 | KNN Loss: 6.226693153381348 | BCE Loss: 1.084618091583252\n",
      "Epoch 318 / 500 | iteration 10 / 30 | Total Loss: 1.0383810997009277 | KNN Loss: 6.226623058319092 | BCE Loss: 1.0383810997009277\n",
      "Epoch 318 / 500 | iteration 15 / 30 | Total Loss: 1.0358498096466064 | KNN Loss: 6.2269134521484375 | BCE Loss: 1.0358498096466064\n",
      "Epoch 318 / 500 | iteration 20 / 30 | Total Loss: 1.0525397062301636 | KNN Loss: 6.226765155792236 | BCE Loss: 1.0525397062301636\n",
      "Epoch 318 / 500 | iteration 25 / 30 | Total Loss: 1.0377707481384277 | KNN Loss: 6.226866245269775 | BCE Loss: 1.0377707481384277\n",
      "Epoch 319 / 500 | iteration 0 / 30 | Total Loss: 1.0531634092330933 | KNN Loss: 6.226933002471924 | BCE Loss: 1.0531634092330933\n",
      "Epoch 319 / 500 | iteration 5 / 30 | Total Loss: 1.0302256345748901 | KNN Loss: 6.226992607116699 | BCE Loss: 1.0302256345748901\n",
      "Epoch 319 / 500 | iteration 10 / 30 | Total Loss: 1.046430230140686 | KNN Loss: 6.226705551147461 | BCE Loss: 1.046430230140686\n",
      "Epoch 319 / 500 | iteration 15 / 30 | Total Loss: 1.0809731483459473 | KNN Loss: 6.227024555206299 | BCE Loss: 1.0809731483459473\n",
      "Epoch 319 / 500 | iteration 20 / 30 | Total Loss: 1.0661654472351074 | KNN Loss: 6.226881980895996 | BCE Loss: 1.0661654472351074\n",
      "Epoch 319 / 500 | iteration 25 / 30 | Total Loss: 1.0439953804016113 | KNN Loss: 6.226936340332031 | BCE Loss: 1.0439953804016113\n",
      "Epoch 320 / 500 | iteration 0 / 30 | Total Loss: 1.0508723258972168 | KNN Loss: 6.226909160614014 | BCE Loss: 1.0508723258972168\n",
      "Epoch 320 / 500 | iteration 5 / 30 | Total Loss: 1.0317469835281372 | KNN Loss: 6.227041721343994 | BCE Loss: 1.0317469835281372\n",
      "Epoch 320 / 500 | iteration 10 / 30 | Total Loss: 1.0734213590621948 | KNN Loss: 6.226962566375732 | BCE Loss: 1.0734213590621948\n",
      "Epoch 320 / 500 | iteration 15 / 30 | Total Loss: 1.0209035873413086 | KNN Loss: 6.226861953735352 | BCE Loss: 1.0209035873413086\n",
      "Epoch 320 / 500 | iteration 20 / 30 | Total Loss: 1.0649831295013428 | KNN Loss: 6.226831912994385 | BCE Loss: 1.0649831295013428\n",
      "Epoch 320 / 500 | iteration 25 / 30 | Total Loss: 1.043953776359558 | KNN Loss: 6.226903438568115 | BCE Loss: 1.043953776359558\n",
      "Epoch 321 / 500 | iteration 0 / 30 | Total Loss: 1.0545204877853394 | KNN Loss: 6.226901054382324 | BCE Loss: 1.0545204877853394\n",
      "Epoch 321 / 500 | iteration 5 / 30 | Total Loss: 1.0751078128814697 | KNN Loss: 6.226644992828369 | BCE Loss: 1.0751078128814697\n",
      "Epoch 321 / 500 | iteration 10 / 30 | Total Loss: 1.03146493434906 | KNN Loss: 6.226698398590088 | BCE Loss: 1.03146493434906\n",
      "Epoch 321 / 500 | iteration 15 / 30 | Total Loss: 1.0480799674987793 | KNN Loss: 6.226956844329834 | BCE Loss: 1.0480799674987793\n",
      "Epoch 321 / 500 | iteration 20 / 30 | Total Loss: 1.0454838275909424 | KNN Loss: 6.226953983306885 | BCE Loss: 1.0454838275909424\n",
      "Epoch 321 / 500 | iteration 25 / 30 | Total Loss: 1.067603588104248 | KNN Loss: 6.2268195152282715 | BCE Loss: 1.067603588104248\n",
      "Epoch 322 / 500 | iteration 0 / 30 | Total Loss: 1.053966760635376 | KNN Loss: 6.2269463539123535 | BCE Loss: 1.053966760635376\n",
      "Epoch 322 / 500 | iteration 5 / 30 | Total Loss: 1.0431022644042969 | KNN Loss: 6.226779460906982 | BCE Loss: 1.0431022644042969\n",
      "Epoch 322 / 500 | iteration 10 / 30 | Total Loss: 1.0164587497711182 | KNN Loss: 6.226936340332031 | BCE Loss: 1.0164587497711182\n",
      "Epoch 322 / 500 | iteration 15 / 30 | Total Loss: 1.0266984701156616 | KNN Loss: 6.226828098297119 | BCE Loss: 1.0266984701156616\n",
      "Epoch 322 / 500 | iteration 20 / 30 | Total Loss: 1.0807702541351318 | KNN Loss: 6.226780891418457 | BCE Loss: 1.0807702541351318\n",
      "Epoch 322 / 500 | iteration 25 / 30 | Total Loss: 1.056236982345581 | KNN Loss: 6.226846218109131 | BCE Loss: 1.056236982345581\n",
      "Epoch 323 / 500 | iteration 0 / 30 | Total Loss: 1.0402684211730957 | KNN Loss: 6.227005958557129 | BCE Loss: 1.0402684211730957\n",
      "Epoch 323 / 500 | iteration 5 / 30 | Total Loss: 1.0300960540771484 | KNN Loss: 6.22685432434082 | BCE Loss: 1.0300960540771484\n",
      "Epoch 323 / 500 | iteration 10 / 30 | Total Loss: 1.0332834720611572 | KNN Loss: 6.226638317108154 | BCE Loss: 1.0332834720611572\n",
      "Epoch 323 / 500 | iteration 15 / 30 | Total Loss: 1.0579137802124023 | KNN Loss: 6.226720333099365 | BCE Loss: 1.0579137802124023\n",
      "Epoch 323 / 500 | iteration 20 / 30 | Total Loss: 1.0770988464355469 | KNN Loss: 6.227126598358154 | BCE Loss: 1.0770988464355469\n",
      "Epoch 323 / 500 | iteration 25 / 30 | Total Loss: 1.0457216501235962 | KNN Loss: 6.226619243621826 | BCE Loss: 1.0457216501235962\n",
      "Epoch 324 / 500 | iteration 0 / 30 | Total Loss: 1.0536632537841797 | KNN Loss: 6.2270827293396 | BCE Loss: 1.0536632537841797\n",
      "Epoch 324 / 500 | iteration 5 / 30 | Total Loss: 1.0379774570465088 | KNN Loss: 6.226939678192139 | BCE Loss: 1.0379774570465088\n",
      "Epoch 324 / 500 | iteration 10 / 30 | Total Loss: 1.0566706657409668 | KNN Loss: 6.2270026206970215 | BCE Loss: 1.0566706657409668\n",
      "Epoch 324 / 500 | iteration 15 / 30 | Total Loss: 1.0491623878479004 | KNN Loss: 6.227111339569092 | BCE Loss: 1.0491623878479004\n",
      "Epoch 324 / 500 | iteration 20 / 30 | Total Loss: 1.0760998725891113 | KNN Loss: 6.2267303466796875 | BCE Loss: 1.0760998725891113\n",
      "Epoch 324 / 500 | iteration 25 / 30 | Total Loss: 1.0261720418930054 | KNN Loss: 6.226670742034912 | BCE Loss: 1.0261720418930054\n",
      "Epoch 325 / 500 | iteration 0 / 30 | Total Loss: 1.060781717300415 | KNN Loss: 6.226809501647949 | BCE Loss: 1.060781717300415\n",
      "Epoch 325 / 500 | iteration 5 / 30 | Total Loss: 1.04701566696167 | KNN Loss: 6.226895332336426 | BCE Loss: 1.04701566696167\n",
      "Epoch 325 / 500 | iteration 10 / 30 | Total Loss: 1.03825843334198 | KNN Loss: 6.226898670196533 | BCE Loss: 1.03825843334198\n",
      "Epoch 325 / 500 | iteration 15 / 30 | Total Loss: 1.021428108215332 | KNN Loss: 6.226722240447998 | BCE Loss: 1.021428108215332\n",
      "Epoch 325 / 500 | iteration 20 / 30 | Total Loss: 1.0568652153015137 | KNN Loss: 6.2266154289245605 | BCE Loss: 1.0568652153015137\n",
      "Epoch 325 / 500 | iteration 25 / 30 | Total Loss: 1.0449832677841187 | KNN Loss: 6.226561069488525 | BCE Loss: 1.0449832677841187\n",
      "Epoch   326: reducing learning rate of group 0 to 6.7053e-07.\n",
      "Epoch 326 / 500 | iteration 0 / 30 | Total Loss: 1.0448890924453735 | KNN Loss: 6.226822376251221 | BCE Loss: 1.0448890924453735\n",
      "Epoch 326 / 500 | iteration 5 / 30 | Total Loss: 1.084090232849121 | KNN Loss: 6.226795196533203 | BCE Loss: 1.084090232849121\n",
      "Epoch 326 / 500 | iteration 10 / 30 | Total Loss: 1.0346324443817139 | KNN Loss: 6.22677755355835 | BCE Loss: 1.0346324443817139\n",
      "Epoch 326 / 500 | iteration 15 / 30 | Total Loss: 1.055315375328064 | KNN Loss: 6.226930141448975 | BCE Loss: 1.055315375328064\n",
      "Epoch 326 / 500 | iteration 20 / 30 | Total Loss: 1.01582932472229 | KNN Loss: 6.226994037628174 | BCE Loss: 1.01582932472229\n",
      "Epoch 326 / 500 | iteration 25 / 30 | Total Loss: 1.0531809329986572 | KNN Loss: 6.226991176605225 | BCE Loss: 1.0531809329986572\n",
      "Epoch 327 / 500 | iteration 0 / 30 | Total Loss: 1.0417218208312988 | KNN Loss: 6.226621627807617 | BCE Loss: 1.0417218208312988\n",
      "Epoch 327 / 500 | iteration 5 / 30 | Total Loss: 1.0526130199432373 | KNN Loss: 6.226767539978027 | BCE Loss: 1.0526130199432373\n",
      "Epoch 327 / 500 | iteration 10 / 30 | Total Loss: 1.0498340129852295 | KNN Loss: 6.226833820343018 | BCE Loss: 1.0498340129852295\n",
      "Epoch 327 / 500 | iteration 15 / 30 | Total Loss: 1.0417134761810303 | KNN Loss: 6.226816654205322 | BCE Loss: 1.0417134761810303\n",
      "Epoch 327 / 500 | iteration 20 / 30 | Total Loss: 1.0893580913543701 | KNN Loss: 6.226873874664307 | BCE Loss: 1.0893580913543701\n",
      "Epoch 327 / 500 | iteration 25 / 30 | Total Loss: 1.0464632511138916 | KNN Loss: 6.2271013259887695 | BCE Loss: 1.0464632511138916\n",
      "Epoch 328 / 500 | iteration 0 / 30 | Total Loss: 1.0517289638519287 | KNN Loss: 6.227039337158203 | BCE Loss: 1.0517289638519287\n",
      "Epoch 328 / 500 | iteration 5 / 30 | Total Loss: 1.0817972421646118 | KNN Loss: 6.226959228515625 | BCE Loss: 1.0817972421646118\n",
      "Epoch 328 / 500 | iteration 10 / 30 | Total Loss: 1.0701019763946533 | KNN Loss: 6.2268595695495605 | BCE Loss: 1.0701019763946533\n",
      "Epoch 328 / 500 | iteration 15 / 30 | Total Loss: 1.0651135444641113 | KNN Loss: 6.2268171310424805 | BCE Loss: 1.0651135444641113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328 / 500 | iteration 20 / 30 | Total Loss: 1.0383208990097046 | KNN Loss: 6.226868629455566 | BCE Loss: 1.0383208990097046\n",
      "Epoch 328 / 500 | iteration 25 / 30 | Total Loss: 1.0299129486083984 | KNN Loss: 6.227171897888184 | BCE Loss: 1.0299129486083984\n",
      "Epoch 329 / 500 | iteration 0 / 30 | Total Loss: 1.0493028163909912 | KNN Loss: 6.227002143859863 | BCE Loss: 1.0493028163909912\n",
      "Epoch 329 / 500 | iteration 5 / 30 | Total Loss: 1.0455604791641235 | KNN Loss: 6.226907253265381 | BCE Loss: 1.0455604791641235\n",
      "Epoch 329 / 500 | iteration 10 / 30 | Total Loss: 1.0510529279708862 | KNN Loss: 6.226870536804199 | BCE Loss: 1.0510529279708862\n",
      "Epoch 329 / 500 | iteration 15 / 30 | Total Loss: 1.0584723949432373 | KNN Loss: 6.226937770843506 | BCE Loss: 1.0584723949432373\n",
      "Epoch 329 / 500 | iteration 20 / 30 | Total Loss: 1.0623018741607666 | KNN Loss: 6.227108955383301 | BCE Loss: 1.0623018741607666\n",
      "Epoch 329 / 500 | iteration 25 / 30 | Total Loss: 1.0264055728912354 | KNN Loss: 6.226986408233643 | BCE Loss: 1.0264055728912354\n",
      "Epoch 330 / 500 | iteration 0 / 30 | Total Loss: 1.039488673210144 | KNN Loss: 6.226818084716797 | BCE Loss: 1.039488673210144\n",
      "Epoch 330 / 500 | iteration 5 / 30 | Total Loss: 1.0500491857528687 | KNN Loss: 6.226640224456787 | BCE Loss: 1.0500491857528687\n",
      "Epoch 330 / 500 | iteration 10 / 30 | Total Loss: 1.0598478317260742 | KNN Loss: 6.226840019226074 | BCE Loss: 1.0598478317260742\n",
      "Epoch 330 / 500 | iteration 15 / 30 | Total Loss: 1.017473816871643 | KNN Loss: 6.2269392013549805 | BCE Loss: 1.017473816871643\n",
      "Epoch 330 / 500 | iteration 20 / 30 | Total Loss: 1.0649423599243164 | KNN Loss: 6.226850509643555 | BCE Loss: 1.0649423599243164\n",
      "Epoch 330 / 500 | iteration 25 / 30 | Total Loss: 1.0366926193237305 | KNN Loss: 6.226855278015137 | BCE Loss: 1.0366926193237305\n",
      "Epoch 331 / 500 | iteration 0 / 30 | Total Loss: 1.055664300918579 | KNN Loss: 6.227177143096924 | BCE Loss: 1.055664300918579\n",
      "Epoch 331 / 500 | iteration 5 / 30 | Total Loss: 1.040880560874939 | KNN Loss: 6.226729393005371 | BCE Loss: 1.040880560874939\n",
      "Epoch 331 / 500 | iteration 10 / 30 | Total Loss: 1.0546085834503174 | KNN Loss: 6.226509094238281 | BCE Loss: 1.0546085834503174\n",
      "Epoch 331 / 500 | iteration 15 / 30 | Total Loss: 1.0395853519439697 | KNN Loss: 6.226990222930908 | BCE Loss: 1.0395853519439697\n",
      "Epoch 331 / 500 | iteration 20 / 30 | Total Loss: 1.032005786895752 | KNN Loss: 6.227102279663086 | BCE Loss: 1.032005786895752\n",
      "Epoch 331 / 500 | iteration 25 / 30 | Total Loss: 1.065969705581665 | KNN Loss: 6.226581573486328 | BCE Loss: 1.065969705581665\n",
      "Epoch 332 / 500 | iteration 0 / 30 | Total Loss: 1.0878922939300537 | KNN Loss: 6.2272467613220215 | BCE Loss: 1.0878922939300537\n",
      "Epoch 332 / 500 | iteration 5 / 30 | Total Loss: 1.0635364055633545 | KNN Loss: 6.226864337921143 | BCE Loss: 1.0635364055633545\n",
      "Epoch 332 / 500 | iteration 10 / 30 | Total Loss: 1.030868411064148 | KNN Loss: 6.22691535949707 | BCE Loss: 1.030868411064148\n",
      "Epoch 332 / 500 | iteration 15 / 30 | Total Loss: 1.042633056640625 | KNN Loss: 6.227114200592041 | BCE Loss: 1.042633056640625\n",
      "Epoch 332 / 500 | iteration 20 / 30 | Total Loss: 1.0261775255203247 | KNN Loss: 6.2268147468566895 | BCE Loss: 1.0261775255203247\n",
      "Epoch 332 / 500 | iteration 25 / 30 | Total Loss: 1.045264720916748 | KNN Loss: 6.226588726043701 | BCE Loss: 1.045264720916748\n",
      "Epoch 333 / 500 | iteration 0 / 30 | Total Loss: 1.0579901933670044 | KNN Loss: 6.226657390594482 | BCE Loss: 1.0579901933670044\n",
      "Epoch 333 / 500 | iteration 5 / 30 | Total Loss: 1.0399082899093628 | KNN Loss: 6.226888179779053 | BCE Loss: 1.0399082899093628\n",
      "Epoch 333 / 500 | iteration 10 / 30 | Total Loss: 1.0625433921813965 | KNN Loss: 6.226813316345215 | BCE Loss: 1.0625433921813965\n",
      "Epoch 333 / 500 | iteration 15 / 30 | Total Loss: 1.052096962928772 | KNN Loss: 6.226873397827148 | BCE Loss: 1.052096962928772\n",
      "Epoch 333 / 500 | iteration 20 / 30 | Total Loss: 1.0400631427764893 | KNN Loss: 6.226983070373535 | BCE Loss: 1.0400631427764893\n",
      "Epoch 333 / 500 | iteration 25 / 30 | Total Loss: 1.052054524421692 | KNN Loss: 6.226903438568115 | BCE Loss: 1.052054524421692\n",
      "Epoch 334 / 500 | iteration 0 / 30 | Total Loss: 1.0481144189834595 | KNN Loss: 6.226849555969238 | BCE Loss: 1.0481144189834595\n",
      "Epoch 334 / 500 | iteration 5 / 30 | Total Loss: 1.0614725351333618 | KNN Loss: 6.2267866134643555 | BCE Loss: 1.0614725351333618\n",
      "Epoch 334 / 500 | iteration 10 / 30 | Total Loss: 1.0144575834274292 | KNN Loss: 6.226733684539795 | BCE Loss: 1.0144575834274292\n",
      "Epoch 334 / 500 | iteration 15 / 30 | Total Loss: 1.0454554557800293 | KNN Loss: 6.226912021636963 | BCE Loss: 1.0454554557800293\n",
      "Epoch 334 / 500 | iteration 20 / 30 | Total Loss: 1.0464749336242676 | KNN Loss: 6.226480484008789 | BCE Loss: 1.0464749336242676\n",
      "Epoch 334 / 500 | iteration 25 / 30 | Total Loss: 1.0585376024246216 | KNN Loss: 6.226874828338623 | BCE Loss: 1.0585376024246216\n",
      "Epoch 335 / 500 | iteration 0 / 30 | Total Loss: 1.055320143699646 | KNN Loss: 6.226705551147461 | BCE Loss: 1.055320143699646\n",
      "Epoch 335 / 500 | iteration 5 / 30 | Total Loss: 1.0603135824203491 | KNN Loss: 6.226935386657715 | BCE Loss: 1.0603135824203491\n",
      "Epoch 335 / 500 | iteration 10 / 30 | Total Loss: 1.0404384136199951 | KNN Loss: 6.22688627243042 | BCE Loss: 1.0404384136199951\n",
      "Epoch 335 / 500 | iteration 15 / 30 | Total Loss: 1.0304853916168213 | KNN Loss: 6.226748466491699 | BCE Loss: 1.0304853916168213\n",
      "Epoch 335 / 500 | iteration 20 / 30 | Total Loss: 1.0300943851470947 | KNN Loss: 6.226828575134277 | BCE Loss: 1.0300943851470947\n",
      "Epoch 335 / 500 | iteration 25 / 30 | Total Loss: 1.0586364269256592 | KNN Loss: 6.226855754852295 | BCE Loss: 1.0586364269256592\n",
      "Epoch 336 / 500 | iteration 0 / 30 | Total Loss: 1.010080099105835 | KNN Loss: 6.2267842292785645 | BCE Loss: 1.010080099105835\n",
      "Epoch 336 / 500 | iteration 5 / 30 | Total Loss: 1.0454903841018677 | KNN Loss: 6.227005481719971 | BCE Loss: 1.0454903841018677\n",
      "Epoch 336 / 500 | iteration 10 / 30 | Total Loss: 1.040665864944458 | KNN Loss: 6.226768970489502 | BCE Loss: 1.040665864944458\n",
      "Epoch 336 / 500 | iteration 15 / 30 | Total Loss: 1.0523858070373535 | KNN Loss: 6.226861476898193 | BCE Loss: 1.0523858070373535\n",
      "Epoch 336 / 500 | iteration 20 / 30 | Total Loss: 1.0277698040008545 | KNN Loss: 6.226923942565918 | BCE Loss: 1.0277698040008545\n",
      "Epoch 336 / 500 | iteration 25 / 30 | Total Loss: 1.0599335432052612 | KNN Loss: 6.226927757263184 | BCE Loss: 1.0599335432052612\n",
      "Epoch   337: reducing learning rate of group 0 to 4.6937e-07.\n",
      "Epoch 337 / 500 | iteration 0 / 30 | Total Loss: 1.0398808717727661 | KNN Loss: 6.226964950561523 | BCE Loss: 1.0398808717727661\n",
      "Epoch 337 / 500 | iteration 5 / 30 | Total Loss: 1.0605558156967163 | KNN Loss: 6.227006435394287 | BCE Loss: 1.0605558156967163\n",
      "Epoch 337 / 500 | iteration 10 / 30 | Total Loss: 1.0655064582824707 | KNN Loss: 6.226879119873047 | BCE Loss: 1.0655064582824707\n",
      "Epoch 337 / 500 | iteration 15 / 30 | Total Loss: 1.0211288928985596 | KNN Loss: 6.227136135101318 | BCE Loss: 1.0211288928985596\n",
      "Epoch 337 / 500 | iteration 20 / 30 | Total Loss: 1.0124311447143555 | KNN Loss: 6.226723670959473 | BCE Loss: 1.0124311447143555\n",
      "Epoch 337 / 500 | iteration 25 / 30 | Total Loss: 1.048767328262329 | KNN Loss: 6.22646427154541 | BCE Loss: 1.048767328262329\n",
      "Epoch 338 / 500 | iteration 0 / 30 | Total Loss: 1.076183557510376 | KNN Loss: 6.226771354675293 | BCE Loss: 1.076183557510376\n",
      "Epoch 338 / 500 | iteration 5 / 30 | Total Loss: 1.0199553966522217 | KNN Loss: 6.226940631866455 | BCE Loss: 1.0199553966522217\n",
      "Epoch 338 / 500 | iteration 10 / 30 | Total Loss: 1.0529663562774658 | KNN Loss: 6.2272233963012695 | BCE Loss: 1.0529663562774658\n",
      "Epoch 338 / 500 | iteration 15 / 30 | Total Loss: 1.0498098134994507 | KNN Loss: 6.22695779800415 | BCE Loss: 1.0498098134994507\n",
      "Epoch 338 / 500 | iteration 20 / 30 | Total Loss: 1.0487308502197266 | KNN Loss: 6.226718425750732 | BCE Loss: 1.0487308502197266\n",
      "Epoch 338 / 500 | iteration 25 / 30 | Total Loss: 1.0696229934692383 | KNN Loss: 6.226844310760498 | BCE Loss: 1.0696229934692383\n",
      "Epoch 339 / 500 | iteration 0 / 30 | Total Loss: 1.0487065315246582 | KNN Loss: 6.226914882659912 | BCE Loss: 1.0487065315246582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339 / 500 | iteration 5 / 30 | Total Loss: 1.0491628646850586 | KNN Loss: 6.22667121887207 | BCE Loss: 1.0491628646850586\n",
      "Epoch 339 / 500 | iteration 10 / 30 | Total Loss: 1.0504395961761475 | KNN Loss: 6.226828098297119 | BCE Loss: 1.0504395961761475\n",
      "Epoch 339 / 500 | iteration 15 / 30 | Total Loss: 1.0080511569976807 | KNN Loss: 6.226879596710205 | BCE Loss: 1.0080511569976807\n",
      "Epoch 339 / 500 | iteration 20 / 30 | Total Loss: 1.0510786771774292 | KNN Loss: 6.2266645431518555 | BCE Loss: 1.0510786771774292\n",
      "Epoch 339 / 500 | iteration 25 / 30 | Total Loss: 1.0249855518341064 | KNN Loss: 6.2270660400390625 | BCE Loss: 1.0249855518341064\n",
      "Epoch 340 / 500 | iteration 0 / 30 | Total Loss: 1.0923376083374023 | KNN Loss: 6.226940631866455 | BCE Loss: 1.0923376083374023\n",
      "Epoch 340 / 500 | iteration 5 / 30 | Total Loss: 1.0316810607910156 | KNN Loss: 6.226646900177002 | BCE Loss: 1.0316810607910156\n",
      "Epoch 340 / 500 | iteration 10 / 30 | Total Loss: 1.0597476959228516 | KNN Loss: 6.2270026206970215 | BCE Loss: 1.0597476959228516\n",
      "Epoch 340 / 500 | iteration 15 / 30 | Total Loss: 1.040520429611206 | KNN Loss: 6.2268524169921875 | BCE Loss: 1.040520429611206\n",
      "Epoch 340 / 500 | iteration 20 / 30 | Total Loss: 1.0438473224639893 | KNN Loss: 6.226707458496094 | BCE Loss: 1.0438473224639893\n",
      "Epoch 340 / 500 | iteration 25 / 30 | Total Loss: 1.0579402446746826 | KNN Loss: 6.226766586303711 | BCE Loss: 1.0579402446746826\n",
      "Epoch 341 / 500 | iteration 0 / 30 | Total Loss: 1.0481137037277222 | KNN Loss: 6.226627349853516 | BCE Loss: 1.0481137037277222\n",
      "Epoch 341 / 500 | iteration 5 / 30 | Total Loss: 1.0619637966156006 | KNN Loss: 6.226673603057861 | BCE Loss: 1.0619637966156006\n",
      "Epoch 341 / 500 | iteration 10 / 30 | Total Loss: 1.0542397499084473 | KNN Loss: 6.227044582366943 | BCE Loss: 1.0542397499084473\n",
      "Epoch 341 / 500 | iteration 15 / 30 | Total Loss: 1.0516668558120728 | KNN Loss: 6.22671365737915 | BCE Loss: 1.0516668558120728\n",
      "Epoch 341 / 500 | iteration 20 / 30 | Total Loss: 1.0703237056732178 | KNN Loss: 6.226894378662109 | BCE Loss: 1.0703237056732178\n",
      "Epoch 341 / 500 | iteration 25 / 30 | Total Loss: 1.0181175470352173 | KNN Loss: 6.2270708084106445 | BCE Loss: 1.0181175470352173\n",
      "Epoch 342 / 500 | iteration 0 / 30 | Total Loss: 1.052211046218872 | KNN Loss: 6.227091312408447 | BCE Loss: 1.052211046218872\n",
      "Epoch 342 / 500 | iteration 5 / 30 | Total Loss: 1.0676288604736328 | KNN Loss: 6.22667932510376 | BCE Loss: 1.0676288604736328\n",
      "Epoch 342 / 500 | iteration 10 / 30 | Total Loss: 1.0674159526824951 | KNN Loss: 6.226848602294922 | BCE Loss: 1.0674159526824951\n",
      "Epoch 342 / 500 | iteration 15 / 30 | Total Loss: 1.0826458930969238 | KNN Loss: 6.226916313171387 | BCE Loss: 1.0826458930969238\n",
      "Epoch 342 / 500 | iteration 20 / 30 | Total Loss: 1.0606544017791748 | KNN Loss: 6.226937294006348 | BCE Loss: 1.0606544017791748\n",
      "Epoch 342 / 500 | iteration 25 / 30 | Total Loss: 1.0606961250305176 | KNN Loss: 6.227106094360352 | BCE Loss: 1.0606961250305176\n",
      "Epoch 343 / 500 | iteration 0 / 30 | Total Loss: 1.071216344833374 | KNN Loss: 6.226686000823975 | BCE Loss: 1.071216344833374\n",
      "Epoch 343 / 500 | iteration 5 / 30 | Total Loss: 1.035268783569336 | KNN Loss: 6.226775646209717 | BCE Loss: 1.035268783569336\n",
      "Epoch 343 / 500 | iteration 10 / 30 | Total Loss: 1.052322506904602 | KNN Loss: 6.226962089538574 | BCE Loss: 1.052322506904602\n",
      "Epoch 343 / 500 | iteration 15 / 30 | Total Loss: 1.0714203119277954 | KNN Loss: 6.226842403411865 | BCE Loss: 1.0714203119277954\n",
      "Epoch 343 / 500 | iteration 20 / 30 | Total Loss: 1.0518079996109009 | KNN Loss: 6.226950645446777 | BCE Loss: 1.0518079996109009\n",
      "Epoch 343 / 500 | iteration 25 / 30 | Total Loss: 1.0307855606079102 | KNN Loss: 6.227010726928711 | BCE Loss: 1.0307855606079102\n",
      "Epoch 344 / 500 | iteration 0 / 30 | Total Loss: 1.054711103439331 | KNN Loss: 6.227090835571289 | BCE Loss: 1.054711103439331\n",
      "Epoch 344 / 500 | iteration 5 / 30 | Total Loss: 1.0963764190673828 | KNN Loss: 6.2268266677856445 | BCE Loss: 1.0963764190673828\n",
      "Epoch 344 / 500 | iteration 10 / 30 | Total Loss: 1.0744391679763794 | KNN Loss: 6.22682523727417 | BCE Loss: 1.0744391679763794\n",
      "Epoch 344 / 500 | iteration 15 / 30 | Total Loss: 1.043534755706787 | KNN Loss: 6.226861000061035 | BCE Loss: 1.043534755706787\n",
      "Epoch 344 / 500 | iteration 20 / 30 | Total Loss: 1.0606592893600464 | KNN Loss: 6.227116107940674 | BCE Loss: 1.0606592893600464\n",
      "Epoch 344 / 500 | iteration 25 / 30 | Total Loss: 1.0538618564605713 | KNN Loss: 6.2268218994140625 | BCE Loss: 1.0538618564605713\n",
      "Epoch 345 / 500 | iteration 0 / 30 | Total Loss: 1.0941286087036133 | KNN Loss: 6.227041721343994 | BCE Loss: 1.0941286087036133\n",
      "Epoch 345 / 500 | iteration 5 / 30 | Total Loss: 1.0447238683700562 | KNN Loss: 6.226683139801025 | BCE Loss: 1.0447238683700562\n",
      "Epoch 345 / 500 | iteration 10 / 30 | Total Loss: 1.0452566146850586 | KNN Loss: 6.227118968963623 | BCE Loss: 1.0452566146850586\n",
      "Epoch 345 / 500 | iteration 15 / 30 | Total Loss: 1.061775803565979 | KNN Loss: 6.226682186126709 | BCE Loss: 1.061775803565979\n",
      "Epoch 345 / 500 | iteration 20 / 30 | Total Loss: 1.0772817134857178 | KNN Loss: 6.226943016052246 | BCE Loss: 1.0772817134857178\n",
      "Epoch 345 / 500 | iteration 25 / 30 | Total Loss: 1.0624310970306396 | KNN Loss: 6.227126121520996 | BCE Loss: 1.0624310970306396\n",
      "Epoch 346 / 500 | iteration 0 / 30 | Total Loss: 1.0690597295761108 | KNN Loss: 6.226866245269775 | BCE Loss: 1.0690597295761108\n",
      "Epoch 346 / 500 | iteration 5 / 30 | Total Loss: 1.0397870540618896 | KNN Loss: 6.226839542388916 | BCE Loss: 1.0397870540618896\n",
      "Epoch 346 / 500 | iteration 10 / 30 | Total Loss: 1.0373375415802002 | KNN Loss: 6.226809978485107 | BCE Loss: 1.0373375415802002\n",
      "Epoch 346 / 500 | iteration 15 / 30 | Total Loss: 1.0563985109329224 | KNN Loss: 6.226828575134277 | BCE Loss: 1.0563985109329224\n",
      "Epoch 346 / 500 | iteration 20 / 30 | Total Loss: 1.070873737335205 | KNN Loss: 6.226856231689453 | BCE Loss: 1.070873737335205\n",
      "Epoch 346 / 500 | iteration 25 / 30 | Total Loss: 1.032352328300476 | KNN Loss: 6.226882457733154 | BCE Loss: 1.032352328300476\n",
      "Epoch 347 / 500 | iteration 0 / 30 | Total Loss: 1.0659081935882568 | KNN Loss: 6.226869106292725 | BCE Loss: 1.0659081935882568\n",
      "Epoch 347 / 500 | iteration 5 / 30 | Total Loss: 1.0530500411987305 | KNN Loss: 6.226774215698242 | BCE Loss: 1.0530500411987305\n",
      "Epoch 347 / 500 | iteration 10 / 30 | Total Loss: 1.069018006324768 | KNN Loss: 6.226665496826172 | BCE Loss: 1.069018006324768\n",
      "Epoch 347 / 500 | iteration 15 / 30 | Total Loss: 1.0629223585128784 | KNN Loss: 6.226677894592285 | BCE Loss: 1.0629223585128784\n",
      "Epoch 347 / 500 | iteration 20 / 30 | Total Loss: 1.0254743099212646 | KNN Loss: 6.22674036026001 | BCE Loss: 1.0254743099212646\n",
      "Epoch 347 / 500 | iteration 25 / 30 | Total Loss: 1.0317779779434204 | KNN Loss: 6.226974964141846 | BCE Loss: 1.0317779779434204\n",
      "Epoch   348: reducing learning rate of group 0 to 3.2856e-07.\n",
      "Epoch 348 / 500 | iteration 0 / 30 | Total Loss: 1.0595983266830444 | KNN Loss: 6.22688627243042 | BCE Loss: 1.0595983266830444\n",
      "Epoch 348 / 500 | iteration 5 / 30 | Total Loss: 1.0709521770477295 | KNN Loss: 6.226906776428223 | BCE Loss: 1.0709521770477295\n",
      "Epoch 348 / 500 | iteration 10 / 30 | Total Loss: 1.0491708517074585 | KNN Loss: 6.226996898651123 | BCE Loss: 1.0491708517074585\n",
      "Epoch 348 / 500 | iteration 15 / 30 | Total Loss: 1.0490539073944092 | KNN Loss: 6.226503849029541 | BCE Loss: 1.0490539073944092\n",
      "Epoch 348 / 500 | iteration 20 / 30 | Total Loss: 1.0663641691207886 | KNN Loss: 6.227024555206299 | BCE Loss: 1.0663641691207886\n",
      "Epoch 348 / 500 | iteration 25 / 30 | Total Loss: 1.029600739479065 | KNN Loss: 6.2266845703125 | BCE Loss: 1.029600739479065\n",
      "Epoch 349 / 500 | iteration 0 / 30 | Total Loss: 1.0234416723251343 | KNN Loss: 6.226909160614014 | BCE Loss: 1.0234416723251343\n",
      "Epoch 349 / 500 | iteration 5 / 30 | Total Loss: 1.0621764659881592 | KNN Loss: 6.226433277130127 | BCE Loss: 1.0621764659881592\n",
      "Epoch 349 / 500 | iteration 10 / 30 | Total Loss: 1.0299651622772217 | KNN Loss: 6.226998805999756 | BCE Loss: 1.0299651622772217\n",
      "Epoch 349 / 500 | iteration 15 / 30 | Total Loss: 1.0417269468307495 | KNN Loss: 6.227138519287109 | BCE Loss: 1.0417269468307495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349 / 500 | iteration 20 / 30 | Total Loss: 1.0686166286468506 | KNN Loss: 6.226937770843506 | BCE Loss: 1.0686166286468506\n",
      "Epoch 349 / 500 | iteration 25 / 30 | Total Loss: 1.1126576662063599 | KNN Loss: 6.227221965789795 | BCE Loss: 1.1126576662063599\n",
      "Epoch 350 / 500 | iteration 0 / 30 | Total Loss: 1.066407561302185 | KNN Loss: 6.226893424987793 | BCE Loss: 1.066407561302185\n",
      "Epoch 350 / 500 | iteration 5 / 30 | Total Loss: 1.030342936515808 | KNN Loss: 6.226999759674072 | BCE Loss: 1.030342936515808\n",
      "Epoch 350 / 500 | iteration 10 / 30 | Total Loss: 1.0249712467193604 | KNN Loss: 6.226402759552002 | BCE Loss: 1.0249712467193604\n",
      "Epoch 350 / 500 | iteration 15 / 30 | Total Loss: 1.03749680519104 | KNN Loss: 6.2267961502075195 | BCE Loss: 1.03749680519104\n",
      "Epoch 350 / 500 | iteration 20 / 30 | Total Loss: 1.0640727281570435 | KNN Loss: 6.227158546447754 | BCE Loss: 1.0640727281570435\n",
      "Epoch 350 / 500 | iteration 25 / 30 | Total Loss: 1.048877239227295 | KNN Loss: 6.2268595695495605 | BCE Loss: 1.048877239227295\n",
      "Epoch 351 / 500 | iteration 0 / 30 | Total Loss: 1.0520672798156738 | KNN Loss: 6.2269744873046875 | BCE Loss: 1.0520672798156738\n",
      "Epoch 351 / 500 | iteration 5 / 30 | Total Loss: 1.062758207321167 | KNN Loss: 6.2269487380981445 | BCE Loss: 1.062758207321167\n",
      "Epoch 351 / 500 | iteration 10 / 30 | Total Loss: 1.0578638315200806 | KNN Loss: 6.226931571960449 | BCE Loss: 1.0578638315200806\n",
      "Epoch 351 / 500 | iteration 15 / 30 | Total Loss: 1.060178279876709 | KNN Loss: 6.226768970489502 | BCE Loss: 1.060178279876709\n",
      "Epoch 351 / 500 | iteration 20 / 30 | Total Loss: 1.0381298065185547 | KNN Loss: 6.227019786834717 | BCE Loss: 1.0381298065185547\n",
      "Epoch 351 / 500 | iteration 25 / 30 | Total Loss: 1.0311932563781738 | KNN Loss: 6.226938247680664 | BCE Loss: 1.0311932563781738\n",
      "Epoch 352 / 500 | iteration 0 / 30 | Total Loss: 1.0381009578704834 | KNN Loss: 6.226848602294922 | BCE Loss: 1.0381009578704834\n",
      "Epoch 352 / 500 | iteration 5 / 30 | Total Loss: 1.089085340499878 | KNN Loss: 6.227181911468506 | BCE Loss: 1.089085340499878\n",
      "Epoch 352 / 500 | iteration 10 / 30 | Total Loss: 1.0365698337554932 | KNN Loss: 6.226902484893799 | BCE Loss: 1.0365698337554932\n",
      "Epoch 352 / 500 | iteration 15 / 30 | Total Loss: 1.033294439315796 | KNN Loss: 6.226625919342041 | BCE Loss: 1.033294439315796\n",
      "Epoch 352 / 500 | iteration 20 / 30 | Total Loss: 1.0613465309143066 | KNN Loss: 6.226794242858887 | BCE Loss: 1.0613465309143066\n",
      "Epoch 352 / 500 | iteration 25 / 30 | Total Loss: 1.0456173419952393 | KNN Loss: 6.226779460906982 | BCE Loss: 1.0456173419952393\n",
      "Epoch 353 / 500 | iteration 0 / 30 | Total Loss: 1.0684902667999268 | KNN Loss: 6.227015972137451 | BCE Loss: 1.0684902667999268\n",
      "Epoch 353 / 500 | iteration 5 / 30 | Total Loss: 1.0653587579727173 | KNN Loss: 6.2269673347473145 | BCE Loss: 1.0653587579727173\n",
      "Epoch 353 / 500 | iteration 10 / 30 | Total Loss: 1.0348953008651733 | KNN Loss: 6.2267045974731445 | BCE Loss: 1.0348953008651733\n",
      "Epoch 353 / 500 | iteration 15 / 30 | Total Loss: 1.011843204498291 | KNN Loss: 6.227081298828125 | BCE Loss: 1.011843204498291\n",
      "Epoch 353 / 500 | iteration 20 / 30 | Total Loss: 1.0245885848999023 | KNN Loss: 6.227018356323242 | BCE Loss: 1.0245885848999023\n",
      "Epoch 353 / 500 | iteration 25 / 30 | Total Loss: 1.080127239227295 | KNN Loss: 6.226734638214111 | BCE Loss: 1.080127239227295\n",
      "Epoch 354 / 500 | iteration 0 / 30 | Total Loss: 1.0058873891830444 | KNN Loss: 6.226886749267578 | BCE Loss: 1.0058873891830444\n",
      "Epoch 354 / 500 | iteration 5 / 30 | Total Loss: 1.024641513824463 | KNN Loss: 6.226959228515625 | BCE Loss: 1.024641513824463\n",
      "Epoch 354 / 500 | iteration 10 / 30 | Total Loss: 1.0464437007904053 | KNN Loss: 6.226908206939697 | BCE Loss: 1.0464437007904053\n",
      "Epoch 354 / 500 | iteration 15 / 30 | Total Loss: 1.0564104318618774 | KNN Loss: 6.226873874664307 | BCE Loss: 1.0564104318618774\n",
      "Epoch 354 / 500 | iteration 20 / 30 | Total Loss: 1.07429039478302 | KNN Loss: 6.226881504058838 | BCE Loss: 1.07429039478302\n",
      "Epoch 354 / 500 | iteration 25 / 30 | Total Loss: 1.0571725368499756 | KNN Loss: 6.226634979248047 | BCE Loss: 1.0571725368499756\n",
      "Epoch 355 / 500 | iteration 0 / 30 | Total Loss: 1.056295394897461 | KNN Loss: 6.2269744873046875 | BCE Loss: 1.056295394897461\n",
      "Epoch 355 / 500 | iteration 5 / 30 | Total Loss: 1.072629451751709 | KNN Loss: 6.226555824279785 | BCE Loss: 1.072629451751709\n",
      "Epoch 355 / 500 | iteration 10 / 30 | Total Loss: 1.0513951778411865 | KNN Loss: 6.226745128631592 | BCE Loss: 1.0513951778411865\n",
      "Epoch 355 / 500 | iteration 15 / 30 | Total Loss: 1.0593254566192627 | KNN Loss: 6.2268548011779785 | BCE Loss: 1.0593254566192627\n",
      "Epoch 355 / 500 | iteration 20 / 30 | Total Loss: 1.0353024005889893 | KNN Loss: 6.227164268493652 | BCE Loss: 1.0353024005889893\n",
      "Epoch 355 / 500 | iteration 25 / 30 | Total Loss: 1.0583069324493408 | KNN Loss: 6.226790428161621 | BCE Loss: 1.0583069324493408\n",
      "Epoch 356 / 500 | iteration 0 / 30 | Total Loss: 1.040183186531067 | KNN Loss: 6.226711750030518 | BCE Loss: 1.040183186531067\n",
      "Epoch 356 / 500 | iteration 5 / 30 | Total Loss: 1.061509132385254 | KNN Loss: 6.227022171020508 | BCE Loss: 1.061509132385254\n",
      "Epoch 356 / 500 | iteration 10 / 30 | Total Loss: 1.0818099975585938 | KNN Loss: 6.226725101470947 | BCE Loss: 1.0818099975585938\n",
      "Epoch 356 / 500 | iteration 15 / 30 | Total Loss: 1.0449132919311523 | KNN Loss: 6.226800918579102 | BCE Loss: 1.0449132919311523\n",
      "Epoch 356 / 500 | iteration 20 / 30 | Total Loss: 1.07340669631958 | KNN Loss: 6.226952075958252 | BCE Loss: 1.07340669631958\n",
      "Epoch 356 / 500 | iteration 25 / 30 | Total Loss: 1.0351777076721191 | KNN Loss: 6.2270402908325195 | BCE Loss: 1.0351777076721191\n",
      "Epoch 357 / 500 | iteration 0 / 30 | Total Loss: 1.062657356262207 | KNN Loss: 6.226776123046875 | BCE Loss: 1.062657356262207\n",
      "Epoch 357 / 500 | iteration 5 / 30 | Total Loss: 1.054635763168335 | KNN Loss: 6.227241039276123 | BCE Loss: 1.054635763168335\n",
      "Epoch 357 / 500 | iteration 10 / 30 | Total Loss: 1.0683448314666748 | KNN Loss: 6.226696014404297 | BCE Loss: 1.0683448314666748\n",
      "Epoch 357 / 500 | iteration 15 / 30 | Total Loss: 1.034616470336914 | KNN Loss: 6.227053165435791 | BCE Loss: 1.034616470336914\n",
      "Epoch 357 / 500 | iteration 20 / 30 | Total Loss: 1.020204782485962 | KNN Loss: 6.2269062995910645 | BCE Loss: 1.020204782485962\n",
      "Epoch 357 / 500 | iteration 25 / 30 | Total Loss: 1.0122275352478027 | KNN Loss: 6.226985454559326 | BCE Loss: 1.0122275352478027\n",
      "Epoch 358 / 500 | iteration 0 / 30 | Total Loss: 1.0381312370300293 | KNN Loss: 6.2270026206970215 | BCE Loss: 1.0381312370300293\n",
      "Epoch 358 / 500 | iteration 5 / 30 | Total Loss: 1.0395883321762085 | KNN Loss: 6.226547718048096 | BCE Loss: 1.0395883321762085\n",
      "Epoch 358 / 500 | iteration 10 / 30 | Total Loss: 1.0090374946594238 | KNN Loss: 6.226893424987793 | BCE Loss: 1.0090374946594238\n",
      "Epoch 358 / 500 | iteration 15 / 30 | Total Loss: 1.0654667615890503 | KNN Loss: 6.22667932510376 | BCE Loss: 1.0654667615890503\n",
      "Epoch 358 / 500 | iteration 20 / 30 | Total Loss: 1.0424447059631348 | KNN Loss: 6.227043151855469 | BCE Loss: 1.0424447059631348\n",
      "Epoch 358 / 500 | iteration 25 / 30 | Total Loss: 1.0346994400024414 | KNN Loss: 6.226700305938721 | BCE Loss: 1.0346994400024414\n",
      "Epoch   359: reducing learning rate of group 0 to 2.2999e-07.\n",
      "Epoch 359 / 500 | iteration 0 / 30 | Total Loss: 1.0266735553741455 | KNN Loss: 6.226921558380127 | BCE Loss: 1.0266735553741455\n",
      "Epoch 359 / 500 | iteration 5 / 30 | Total Loss: 1.0644094944000244 | KNN Loss: 6.227109909057617 | BCE Loss: 1.0644094944000244\n",
      "Epoch 359 / 500 | iteration 10 / 30 | Total Loss: 1.0562183856964111 | KNN Loss: 6.227013111114502 | BCE Loss: 1.0562183856964111\n",
      "Epoch 359 / 500 | iteration 15 / 30 | Total Loss: 1.0414127111434937 | KNN Loss: 6.2268218994140625 | BCE Loss: 1.0414127111434937\n",
      "Epoch 359 / 500 | iteration 20 / 30 | Total Loss: 1.0686389207839966 | KNN Loss: 6.226990699768066 | BCE Loss: 1.0686389207839966\n",
      "Epoch 359 / 500 | iteration 25 / 30 | Total Loss: 1.045470952987671 | KNN Loss: 6.226470947265625 | BCE Loss: 1.045470952987671\n",
      "Epoch 360 / 500 | iteration 0 / 30 | Total Loss: 1.081250786781311 | KNN Loss: 6.226908206939697 | BCE Loss: 1.081250786781311\n",
      "Epoch 360 / 500 | iteration 5 / 30 | Total Loss: 1.0539608001708984 | KNN Loss: 6.226929664611816 | BCE Loss: 1.0539608001708984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360 / 500 | iteration 10 / 30 | Total Loss: 1.011671781539917 | KNN Loss: 6.226860046386719 | BCE Loss: 1.011671781539917\n",
      "Epoch 360 / 500 | iteration 15 / 30 | Total Loss: 1.0535238981246948 | KNN Loss: 6.226858615875244 | BCE Loss: 1.0535238981246948\n",
      "Epoch 360 / 500 | iteration 20 / 30 | Total Loss: 1.0723010301589966 | KNN Loss: 6.227019786834717 | BCE Loss: 1.0723010301589966\n",
      "Epoch 360 / 500 | iteration 25 / 30 | Total Loss: 1.06814444065094 | KNN Loss: 6.226754665374756 | BCE Loss: 1.06814444065094\n",
      "Epoch 361 / 500 | iteration 0 / 30 | Total Loss: 1.0720678567886353 | KNN Loss: 6.2269606590271 | BCE Loss: 1.0720678567886353\n",
      "Epoch 361 / 500 | iteration 5 / 30 | Total Loss: 1.0251882076263428 | KNN Loss: 6.227046966552734 | BCE Loss: 1.0251882076263428\n",
      "Epoch 361 / 500 | iteration 10 / 30 | Total Loss: 1.0776755809783936 | KNN Loss: 6.2266621589660645 | BCE Loss: 1.0776755809783936\n",
      "Epoch 361 / 500 | iteration 15 / 30 | Total Loss: 1.052001953125 | KNN Loss: 6.226693630218506 | BCE Loss: 1.052001953125\n",
      "Epoch 361 / 500 | iteration 20 / 30 | Total Loss: 1.0817246437072754 | KNN Loss: 6.226428508758545 | BCE Loss: 1.0817246437072754\n",
      "Epoch 361 / 500 | iteration 25 / 30 | Total Loss: 1.0360931158065796 | KNN Loss: 6.226755142211914 | BCE Loss: 1.0360931158065796\n",
      "Epoch 362 / 500 | iteration 0 / 30 | Total Loss: 1.0431891679763794 | KNN Loss: 6.2269062995910645 | BCE Loss: 1.0431891679763794\n",
      "Epoch 362 / 500 | iteration 5 / 30 | Total Loss: 1.0714046955108643 | KNN Loss: 6.226840972900391 | BCE Loss: 1.0714046955108643\n",
      "Epoch 362 / 500 | iteration 10 / 30 | Total Loss: 1.0349198579788208 | KNN Loss: 6.226659774780273 | BCE Loss: 1.0349198579788208\n",
      "Epoch 362 / 500 | iteration 15 / 30 | Total Loss: 1.0593945980072021 | KNN Loss: 6.226782321929932 | BCE Loss: 1.0593945980072021\n",
      "Epoch 362 / 500 | iteration 20 / 30 | Total Loss: 1.0640301704406738 | KNN Loss: 6.226613521575928 | BCE Loss: 1.0640301704406738\n",
      "Epoch 362 / 500 | iteration 25 / 30 | Total Loss: 1.0448501110076904 | KNN Loss: 6.226573467254639 | BCE Loss: 1.0448501110076904\n",
      "Epoch 363 / 500 | iteration 0 / 30 | Total Loss: 1.0267691612243652 | KNN Loss: 6.226965427398682 | BCE Loss: 1.0267691612243652\n",
      "Epoch 363 / 500 | iteration 5 / 30 | Total Loss: 1.044233798980713 | KNN Loss: 6.226684093475342 | BCE Loss: 1.044233798980713\n",
      "Epoch 363 / 500 | iteration 10 / 30 | Total Loss: 1.0415148735046387 | KNN Loss: 6.226877689361572 | BCE Loss: 1.0415148735046387\n",
      "Epoch 363 / 500 | iteration 15 / 30 | Total Loss: 1.047368049621582 | KNN Loss: 6.226761341094971 | BCE Loss: 1.047368049621582\n",
      "Epoch 363 / 500 | iteration 20 / 30 | Total Loss: 1.05564284324646 | KNN Loss: 6.2269206047058105 | BCE Loss: 1.05564284324646\n",
      "Epoch 363 / 500 | iteration 25 / 30 | Total Loss: 1.0450239181518555 | KNN Loss: 6.2272820472717285 | BCE Loss: 1.0450239181518555\n",
      "Epoch 364 / 500 | iteration 0 / 30 | Total Loss: 1.0366054773330688 | KNN Loss: 6.227108955383301 | BCE Loss: 1.0366054773330688\n",
      "Epoch 364 / 500 | iteration 5 / 30 | Total Loss: 1.0719465017318726 | KNN Loss: 6.22713565826416 | BCE Loss: 1.0719465017318726\n",
      "Epoch 364 / 500 | iteration 10 / 30 | Total Loss: 1.012866735458374 | KNN Loss: 6.226841926574707 | BCE Loss: 1.012866735458374\n",
      "Epoch 364 / 500 | iteration 15 / 30 | Total Loss: 1.0733100175857544 | KNN Loss: 6.226810932159424 | BCE Loss: 1.0733100175857544\n",
      "Epoch 364 / 500 | iteration 20 / 30 | Total Loss: 1.0544817447662354 | KNN Loss: 6.226919651031494 | BCE Loss: 1.0544817447662354\n",
      "Epoch 364 / 500 | iteration 25 / 30 | Total Loss: 1.0617327690124512 | KNN Loss: 6.226836204528809 | BCE Loss: 1.0617327690124512\n",
      "Epoch 365 / 500 | iteration 0 / 30 | Total Loss: 1.0530571937561035 | KNN Loss: 6.227039813995361 | BCE Loss: 1.0530571937561035\n",
      "Epoch 365 / 500 | iteration 5 / 30 | Total Loss: 1.0394179821014404 | KNN Loss: 6.227048873901367 | BCE Loss: 1.0394179821014404\n",
      "Epoch 365 / 500 | iteration 10 / 30 | Total Loss: 1.0567021369934082 | KNN Loss: 6.226916313171387 | BCE Loss: 1.0567021369934082\n",
      "Epoch 365 / 500 | iteration 15 / 30 | Total Loss: 1.0397971868515015 | KNN Loss: 6.2267537117004395 | BCE Loss: 1.0397971868515015\n",
      "Epoch 365 / 500 | iteration 20 / 30 | Total Loss: 1.0581612586975098 | KNN Loss: 6.2269978523254395 | BCE Loss: 1.0581612586975098\n",
      "Epoch 365 / 500 | iteration 25 / 30 | Total Loss: 1.0653910636901855 | KNN Loss: 6.226795196533203 | BCE Loss: 1.0653910636901855\n",
      "Epoch 366 / 500 | iteration 0 / 30 | Total Loss: 1.038299560546875 | KNN Loss: 6.226946830749512 | BCE Loss: 1.038299560546875\n",
      "Epoch 366 / 500 | iteration 5 / 30 | Total Loss: 1.057183861732483 | KNN Loss: 6.226963043212891 | BCE Loss: 1.057183861732483\n",
      "Epoch 366 / 500 | iteration 10 / 30 | Total Loss: 1.0499078035354614 | KNN Loss: 6.226944446563721 | BCE Loss: 1.0499078035354614\n",
      "Epoch 366 / 500 | iteration 15 / 30 | Total Loss: 1.0541173219680786 | KNN Loss: 6.22680139541626 | BCE Loss: 1.0541173219680786\n",
      "Epoch 366 / 500 | iteration 20 / 30 | Total Loss: 1.0754306316375732 | KNN Loss: 6.226917743682861 | BCE Loss: 1.0754306316375732\n",
      "Epoch 366 / 500 | iteration 25 / 30 | Total Loss: 1.0549384355545044 | KNN Loss: 6.226639747619629 | BCE Loss: 1.0549384355545044\n",
      "Epoch 367 / 500 | iteration 0 / 30 | Total Loss: 1.018315315246582 | KNN Loss: 6.2268900871276855 | BCE Loss: 1.018315315246582\n",
      "Epoch 367 / 500 | iteration 5 / 30 | Total Loss: 1.0380048751831055 | KNN Loss: 6.227015972137451 | BCE Loss: 1.0380048751831055\n",
      "Epoch 367 / 500 | iteration 10 / 30 | Total Loss: 1.070282220840454 | KNN Loss: 6.2271952629089355 | BCE Loss: 1.070282220840454\n",
      "Epoch 367 / 500 | iteration 15 / 30 | Total Loss: 1.076114535331726 | KNN Loss: 6.226970195770264 | BCE Loss: 1.076114535331726\n",
      "Epoch 367 / 500 | iteration 20 / 30 | Total Loss: 1.0346800088882446 | KNN Loss: 6.22704553604126 | BCE Loss: 1.0346800088882446\n",
      "Epoch 367 / 500 | iteration 25 / 30 | Total Loss: 1.062119960784912 | KNN Loss: 6.2271246910095215 | BCE Loss: 1.062119960784912\n",
      "Epoch 368 / 500 | iteration 0 / 30 | Total Loss: 1.0231847763061523 | KNN Loss: 6.226971626281738 | BCE Loss: 1.0231847763061523\n",
      "Epoch 368 / 500 | iteration 5 / 30 | Total Loss: 1.0487256050109863 | KNN Loss: 6.22703742980957 | BCE Loss: 1.0487256050109863\n",
      "Epoch 368 / 500 | iteration 10 / 30 | Total Loss: 1.07787024974823 | KNN Loss: 6.226858139038086 | BCE Loss: 1.07787024974823\n",
      "Epoch 368 / 500 | iteration 15 / 30 | Total Loss: 1.0709598064422607 | KNN Loss: 6.226855278015137 | BCE Loss: 1.0709598064422607\n",
      "Epoch 368 / 500 | iteration 20 / 30 | Total Loss: 1.0312128067016602 | KNN Loss: 6.226737022399902 | BCE Loss: 1.0312128067016602\n",
      "Epoch 368 / 500 | iteration 25 / 30 | Total Loss: 1.0681755542755127 | KNN Loss: 6.226923942565918 | BCE Loss: 1.0681755542755127\n",
      "Epoch 369 / 500 | iteration 0 / 30 | Total Loss: 1.0712883472442627 | KNN Loss: 6.226983070373535 | BCE Loss: 1.0712883472442627\n",
      "Epoch 369 / 500 | iteration 5 / 30 | Total Loss: 1.0538604259490967 | KNN Loss: 6.2267961502075195 | BCE Loss: 1.0538604259490967\n",
      "Epoch 369 / 500 | iteration 10 / 30 | Total Loss: 1.0264148712158203 | KNN Loss: 6.226898193359375 | BCE Loss: 1.0264148712158203\n",
      "Epoch 369 / 500 | iteration 15 / 30 | Total Loss: 1.070742130279541 | KNN Loss: 6.22683572769165 | BCE Loss: 1.070742130279541\n",
      "Epoch 369 / 500 | iteration 20 / 30 | Total Loss: 1.0483123064041138 | KNN Loss: 6.227024078369141 | BCE Loss: 1.0483123064041138\n",
      "Epoch 369 / 500 | iteration 25 / 30 | Total Loss: 1.04004967212677 | KNN Loss: 6.2266764640808105 | BCE Loss: 1.04004967212677\n",
      "Epoch   370: reducing learning rate of group 0 to 1.6100e-07.\n",
      "Epoch 370 / 500 | iteration 0 / 30 | Total Loss: 1.059484839439392 | KNN Loss: 6.226988792419434 | BCE Loss: 1.059484839439392\n",
      "Epoch 370 / 500 | iteration 5 / 30 | Total Loss: 1.0100630521774292 | KNN Loss: 6.2270612716674805 | BCE Loss: 1.0100630521774292\n",
      "Epoch 370 / 500 | iteration 10 / 30 | Total Loss: 1.0431451797485352 | KNN Loss: 6.226912498474121 | BCE Loss: 1.0431451797485352\n",
      "Epoch 370 / 500 | iteration 15 / 30 | Total Loss: 1.0428296327590942 | KNN Loss: 6.226810932159424 | BCE Loss: 1.0428296327590942\n",
      "Epoch 370 / 500 | iteration 20 / 30 | Total Loss: 1.0454976558685303 | KNN Loss: 6.226650714874268 | BCE Loss: 1.0454976558685303\n",
      "Epoch 370 / 500 | iteration 25 / 30 | Total Loss: 1.054433822631836 | KNN Loss: 6.226556301116943 | BCE Loss: 1.054433822631836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371 / 500 | iteration 0 / 30 | Total Loss: 1.0554600954055786 | KNN Loss: 6.226508617401123 | BCE Loss: 1.0554600954055786\n",
      "Epoch 371 / 500 | iteration 5 / 30 | Total Loss: 1.0589137077331543 | KNN Loss: 6.226742267608643 | BCE Loss: 1.0589137077331543\n",
      "Epoch 371 / 500 | iteration 10 / 30 | Total Loss: 1.0744062662124634 | KNN Loss: 6.226871013641357 | BCE Loss: 1.0744062662124634\n",
      "Epoch 371 / 500 | iteration 15 / 30 | Total Loss: 1.0271823406219482 | KNN Loss: 6.2269287109375 | BCE Loss: 1.0271823406219482\n",
      "Epoch 371 / 500 | iteration 20 / 30 | Total Loss: 1.051118016242981 | KNN Loss: 6.2270402908325195 | BCE Loss: 1.051118016242981\n",
      "Epoch 371 / 500 | iteration 25 / 30 | Total Loss: 1.0544267892837524 | KNN Loss: 6.2272629737854 | BCE Loss: 1.0544267892837524\n",
      "Epoch 372 / 500 | iteration 0 / 30 | Total Loss: 1.0607872009277344 | KNN Loss: 6.2267842292785645 | BCE Loss: 1.0607872009277344\n",
      "Epoch 372 / 500 | iteration 5 / 30 | Total Loss: 1.0319286584854126 | KNN Loss: 6.2268476486206055 | BCE Loss: 1.0319286584854126\n",
      "Epoch 372 / 500 | iteration 10 / 30 | Total Loss: 1.0874016284942627 | KNN Loss: 6.226940631866455 | BCE Loss: 1.0874016284942627\n",
      "Epoch 372 / 500 | iteration 15 / 30 | Total Loss: 1.0327683687210083 | KNN Loss: 6.2266526222229 | BCE Loss: 1.0327683687210083\n",
      "Epoch 372 / 500 | iteration 20 / 30 | Total Loss: 1.0746290683746338 | KNN Loss: 6.227011203765869 | BCE Loss: 1.0746290683746338\n",
      "Epoch 372 / 500 | iteration 25 / 30 | Total Loss: 1.0475332736968994 | KNN Loss: 6.226800918579102 | BCE Loss: 1.0475332736968994\n",
      "Epoch 373 / 500 | iteration 0 / 30 | Total Loss: 1.0380563735961914 | KNN Loss: 6.2269792556762695 | BCE Loss: 1.0380563735961914\n",
      "Epoch 373 / 500 | iteration 5 / 30 | Total Loss: 1.036852240562439 | KNN Loss: 6.2268853187561035 | BCE Loss: 1.036852240562439\n",
      "Epoch 373 / 500 | iteration 10 / 30 | Total Loss: 1.0574091672897339 | KNN Loss: 6.226686477661133 | BCE Loss: 1.0574091672897339\n",
      "Epoch 373 / 500 | iteration 15 / 30 | Total Loss: 1.0289630889892578 | KNN Loss: 6.22667121887207 | BCE Loss: 1.0289630889892578\n",
      "Epoch 373 / 500 | iteration 20 / 30 | Total Loss: 1.028775691986084 | KNN Loss: 6.227100849151611 | BCE Loss: 1.028775691986084\n",
      "Epoch 373 / 500 | iteration 25 / 30 | Total Loss: 1.0587794780731201 | KNN Loss: 6.2268171310424805 | BCE Loss: 1.0587794780731201\n",
      "Epoch 374 / 500 | iteration 0 / 30 | Total Loss: 1.0531716346740723 | KNN Loss: 6.226704120635986 | BCE Loss: 1.0531716346740723\n",
      "Epoch 374 / 500 | iteration 5 / 30 | Total Loss: 1.058314561843872 | KNN Loss: 6.22659969329834 | BCE Loss: 1.058314561843872\n",
      "Epoch 374 / 500 | iteration 10 / 30 | Total Loss: 1.0618226528167725 | KNN Loss: 6.226808071136475 | BCE Loss: 1.0618226528167725\n",
      "Epoch 374 / 500 | iteration 15 / 30 | Total Loss: 1.0301975011825562 | KNN Loss: 6.2269606590271 | BCE Loss: 1.0301975011825562\n",
      "Epoch 374 / 500 | iteration 20 / 30 | Total Loss: 1.063619613647461 | KNN Loss: 6.226628303527832 | BCE Loss: 1.063619613647461\n",
      "Epoch 374 / 500 | iteration 25 / 30 | Total Loss: 1.0301908254623413 | KNN Loss: 6.226901531219482 | BCE Loss: 1.0301908254623413\n",
      "Epoch 375 / 500 | iteration 0 / 30 | Total Loss: 1.0693788528442383 | KNN Loss: 6.226706027984619 | BCE Loss: 1.0693788528442383\n",
      "Epoch 375 / 500 | iteration 5 / 30 | Total Loss: 1.0684800148010254 | KNN Loss: 6.226913928985596 | BCE Loss: 1.0684800148010254\n",
      "Epoch 375 / 500 | iteration 10 / 30 | Total Loss: 1.0508933067321777 | KNN Loss: 6.2272491455078125 | BCE Loss: 1.0508933067321777\n",
      "Epoch 375 / 500 | iteration 15 / 30 | Total Loss: 1.0315673351287842 | KNN Loss: 6.226656436920166 | BCE Loss: 1.0315673351287842\n",
      "Epoch 375 / 500 | iteration 20 / 30 | Total Loss: 1.066840410232544 | KNN Loss: 6.227046966552734 | BCE Loss: 1.066840410232544\n",
      "Epoch 375 / 500 | iteration 25 / 30 | Total Loss: 1.065474033355713 | KNN Loss: 6.226799488067627 | BCE Loss: 1.065474033355713\n",
      "Epoch 376 / 500 | iteration 0 / 30 | Total Loss: 1.0591139793395996 | KNN Loss: 6.226892948150635 | BCE Loss: 1.0591139793395996\n",
      "Epoch 376 / 500 | iteration 5 / 30 | Total Loss: 1.0414996147155762 | KNN Loss: 6.226888656616211 | BCE Loss: 1.0414996147155762\n",
      "Epoch 376 / 500 | iteration 10 / 30 | Total Loss: 1.0916589498519897 | KNN Loss: 6.226964473724365 | BCE Loss: 1.0916589498519897\n",
      "Epoch 376 / 500 | iteration 15 / 30 | Total Loss: 1.0503849983215332 | KNN Loss: 6.226550102233887 | BCE Loss: 1.0503849983215332\n",
      "Epoch 376 / 500 | iteration 20 / 30 | Total Loss: 1.0498809814453125 | KNN Loss: 6.226840972900391 | BCE Loss: 1.0498809814453125\n",
      "Epoch 376 / 500 | iteration 25 / 30 | Total Loss: 1.0628074407577515 | KNN Loss: 6.226822376251221 | BCE Loss: 1.0628074407577515\n",
      "Epoch 377 / 500 | iteration 0 / 30 | Total Loss: 1.016453742980957 | KNN Loss: 6.226893424987793 | BCE Loss: 1.016453742980957\n",
      "Epoch 377 / 500 | iteration 5 / 30 | Total Loss: 1.0796661376953125 | KNN Loss: 6.227163791656494 | BCE Loss: 1.0796661376953125\n",
      "Epoch 377 / 500 | iteration 10 / 30 | Total Loss: 1.038872480392456 | KNN Loss: 6.2268147468566895 | BCE Loss: 1.038872480392456\n",
      "Epoch 377 / 500 | iteration 15 / 30 | Total Loss: 1.0296378135681152 | KNN Loss: 6.22688627243042 | BCE Loss: 1.0296378135681152\n",
      "Epoch 377 / 500 | iteration 20 / 30 | Total Loss: 1.04514479637146 | KNN Loss: 6.226889133453369 | BCE Loss: 1.04514479637146\n",
      "Epoch 377 / 500 | iteration 25 / 30 | Total Loss: 1.0617218017578125 | KNN Loss: 6.227169036865234 | BCE Loss: 1.0617218017578125\n",
      "Epoch 378 / 500 | iteration 0 / 30 | Total Loss: 1.030766487121582 | KNN Loss: 6.226743221282959 | BCE Loss: 1.030766487121582\n",
      "Epoch 378 / 500 | iteration 5 / 30 | Total Loss: 1.0356776714324951 | KNN Loss: 6.22657585144043 | BCE Loss: 1.0356776714324951\n",
      "Epoch 378 / 500 | iteration 10 / 30 | Total Loss: 1.0593349933624268 | KNN Loss: 6.227016448974609 | BCE Loss: 1.0593349933624268\n",
      "Epoch 378 / 500 | iteration 15 / 30 | Total Loss: 1.0836182832717896 | KNN Loss: 6.2270989418029785 | BCE Loss: 1.0836182832717896\n",
      "Epoch 378 / 500 | iteration 20 / 30 | Total Loss: 1.0149866342544556 | KNN Loss: 6.227000713348389 | BCE Loss: 1.0149866342544556\n",
      "Epoch 378 / 500 | iteration 25 / 30 | Total Loss: 1.023247480392456 | KNN Loss: 6.226990699768066 | BCE Loss: 1.023247480392456\n",
      "Epoch 379 / 500 | iteration 0 / 30 | Total Loss: 1.0831176042556763 | KNN Loss: 6.227016448974609 | BCE Loss: 1.0831176042556763\n",
      "Epoch 379 / 500 | iteration 5 / 30 | Total Loss: 1.060982346534729 | KNN Loss: 6.226507663726807 | BCE Loss: 1.060982346534729\n",
      "Epoch 379 / 500 | iteration 10 / 30 | Total Loss: 1.0366005897521973 | KNN Loss: 6.226850986480713 | BCE Loss: 1.0366005897521973\n",
      "Epoch 379 / 500 | iteration 15 / 30 | Total Loss: 1.0513451099395752 | KNN Loss: 6.22649621963501 | BCE Loss: 1.0513451099395752\n",
      "Epoch 379 / 500 | iteration 20 / 30 | Total Loss: 1.02693510055542 | KNN Loss: 6.226943016052246 | BCE Loss: 1.02693510055542\n",
      "Epoch 379 / 500 | iteration 25 / 30 | Total Loss: 1.0563185214996338 | KNN Loss: 6.226679801940918 | BCE Loss: 1.0563185214996338\n",
      "Epoch 380 / 500 | iteration 0 / 30 | Total Loss: 1.0700715780258179 | KNN Loss: 6.227145671844482 | BCE Loss: 1.0700715780258179\n",
      "Epoch 380 / 500 | iteration 5 / 30 | Total Loss: 1.0466299057006836 | KNN Loss: 6.226872444152832 | BCE Loss: 1.0466299057006836\n",
      "Epoch 380 / 500 | iteration 10 / 30 | Total Loss: 1.0440646409988403 | KNN Loss: 6.227116584777832 | BCE Loss: 1.0440646409988403\n",
      "Epoch 380 / 500 | iteration 15 / 30 | Total Loss: 1.0461833477020264 | KNN Loss: 6.226775646209717 | BCE Loss: 1.0461833477020264\n",
      "Epoch 380 / 500 | iteration 20 / 30 | Total Loss: 1.02755606174469 | KNN Loss: 6.2267985343933105 | BCE Loss: 1.02755606174469\n",
      "Epoch 380 / 500 | iteration 25 / 30 | Total Loss: 1.029432773590088 | KNN Loss: 6.226757526397705 | BCE Loss: 1.029432773590088\n",
      "Epoch   381: reducing learning rate of group 0 to 1.1270e-07.\n",
      "Epoch 381 / 500 | iteration 0 / 30 | Total Loss: 1.070199728012085 | KNN Loss: 6.227071285247803 | BCE Loss: 1.070199728012085\n",
      "Epoch 381 / 500 | iteration 5 / 30 | Total Loss: 1.1030827760696411 | KNN Loss: 6.226903915405273 | BCE Loss: 1.1030827760696411\n",
      "Epoch 381 / 500 | iteration 10 / 30 | Total Loss: 1.0564069747924805 | KNN Loss: 6.226970195770264 | BCE Loss: 1.0564069747924805\n",
      "Epoch 381 / 500 | iteration 15 / 30 | Total Loss: 1.0366324186325073 | KNN Loss: 6.226870536804199 | BCE Loss: 1.0366324186325073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381 / 500 | iteration 20 / 30 | Total Loss: 1.0663492679595947 | KNN Loss: 6.226807117462158 | BCE Loss: 1.0663492679595947\n",
      "Epoch 381 / 500 | iteration 25 / 30 | Total Loss: 1.0421209335327148 | KNN Loss: 6.226771354675293 | BCE Loss: 1.0421209335327148\n",
      "Epoch 382 / 500 | iteration 0 / 30 | Total Loss: 1.0716760158538818 | KNN Loss: 6.226850986480713 | BCE Loss: 1.0716760158538818\n",
      "Epoch 382 / 500 | iteration 5 / 30 | Total Loss: 1.0899244546890259 | KNN Loss: 6.22730016708374 | BCE Loss: 1.0899244546890259\n",
      "Epoch 382 / 500 | iteration 10 / 30 | Total Loss: 1.0272246599197388 | KNN Loss: 6.226653099060059 | BCE Loss: 1.0272246599197388\n",
      "Epoch 382 / 500 | iteration 15 / 30 | Total Loss: 1.053100347518921 | KNN Loss: 6.2268877029418945 | BCE Loss: 1.053100347518921\n",
      "Epoch 382 / 500 | iteration 20 / 30 | Total Loss: 1.0508770942687988 | KNN Loss: 6.226931095123291 | BCE Loss: 1.0508770942687988\n",
      "Epoch 382 / 500 | iteration 25 / 30 | Total Loss: 1.0225175619125366 | KNN Loss: 6.226702690124512 | BCE Loss: 1.0225175619125366\n",
      "Epoch 383 / 500 | iteration 0 / 30 | Total Loss: 1.018951654434204 | KNN Loss: 6.226766109466553 | BCE Loss: 1.018951654434204\n",
      "Epoch 383 / 500 | iteration 5 / 30 | Total Loss: 1.0351629257202148 | KNN Loss: 6.226681232452393 | BCE Loss: 1.0351629257202148\n",
      "Epoch 383 / 500 | iteration 10 / 30 | Total Loss: 1.0570831298828125 | KNN Loss: 6.226929187774658 | BCE Loss: 1.0570831298828125\n",
      "Epoch 383 / 500 | iteration 15 / 30 | Total Loss: 1.087477445602417 | KNN Loss: 6.226987838745117 | BCE Loss: 1.087477445602417\n",
      "Epoch 383 / 500 | iteration 20 / 30 | Total Loss: 1.0590366125106812 | KNN Loss: 6.2267165184021 | BCE Loss: 1.0590366125106812\n",
      "Epoch 383 / 500 | iteration 25 / 30 | Total Loss: 1.0731160640716553 | KNN Loss: 6.226802825927734 | BCE Loss: 1.0731160640716553\n",
      "Epoch 384 / 500 | iteration 0 / 30 | Total Loss: 1.0269839763641357 | KNN Loss: 6.2269110679626465 | BCE Loss: 1.0269839763641357\n",
      "Epoch 384 / 500 | iteration 5 / 30 | Total Loss: 1.0432324409484863 | KNN Loss: 6.226553440093994 | BCE Loss: 1.0432324409484863\n",
      "Epoch 384 / 500 | iteration 10 / 30 | Total Loss: 1.0647528171539307 | KNN Loss: 6.227178573608398 | BCE Loss: 1.0647528171539307\n",
      "Epoch 384 / 500 | iteration 15 / 30 | Total Loss: 1.0172326564788818 | KNN Loss: 6.226943016052246 | BCE Loss: 1.0172326564788818\n",
      "Epoch 384 / 500 | iteration 20 / 30 | Total Loss: 1.0709413290023804 | KNN Loss: 6.227055072784424 | BCE Loss: 1.0709413290023804\n",
      "Epoch 384 / 500 | iteration 25 / 30 | Total Loss: 1.0556812286376953 | KNN Loss: 6.226901531219482 | BCE Loss: 1.0556812286376953\n",
      "Epoch 385 / 500 | iteration 0 / 30 | Total Loss: 1.039999008178711 | KNN Loss: 6.2267303466796875 | BCE Loss: 1.039999008178711\n",
      "Epoch 385 / 500 | iteration 5 / 30 | Total Loss: 1.034684658050537 | KNN Loss: 6.227153778076172 | BCE Loss: 1.034684658050537\n",
      "Epoch 385 / 500 | iteration 10 / 30 | Total Loss: 1.062595009803772 | KNN Loss: 6.2269744873046875 | BCE Loss: 1.062595009803772\n",
      "Epoch 385 / 500 | iteration 15 / 30 | Total Loss: 1.0379984378814697 | KNN Loss: 6.226939678192139 | BCE Loss: 1.0379984378814697\n",
      "Epoch 385 / 500 | iteration 20 / 30 | Total Loss: 1.0518749952316284 | KNN Loss: 6.227081775665283 | BCE Loss: 1.0518749952316284\n",
      "Epoch 385 / 500 | iteration 25 / 30 | Total Loss: 1.0378683805465698 | KNN Loss: 6.227036952972412 | BCE Loss: 1.0378683805465698\n",
      "Epoch 386 / 500 | iteration 0 / 30 | Total Loss: 1.0555708408355713 | KNN Loss: 6.226598739624023 | BCE Loss: 1.0555708408355713\n",
      "Epoch 386 / 500 | iteration 5 / 30 | Total Loss: 1.0273025035858154 | KNN Loss: 6.226945877075195 | BCE Loss: 1.0273025035858154\n",
      "Epoch 386 / 500 | iteration 10 / 30 | Total Loss: 1.068544626235962 | KNN Loss: 6.226895809173584 | BCE Loss: 1.068544626235962\n",
      "Epoch 386 / 500 | iteration 15 / 30 | Total Loss: 1.033886194229126 | KNN Loss: 6.2266340255737305 | BCE Loss: 1.033886194229126\n",
      "Epoch 386 / 500 | iteration 20 / 30 | Total Loss: 1.0421524047851562 | KNN Loss: 6.226942539215088 | BCE Loss: 1.0421524047851562\n",
      "Epoch 386 / 500 | iteration 25 / 30 | Total Loss: 1.038243293762207 | KNN Loss: 6.226643085479736 | BCE Loss: 1.038243293762207\n",
      "Epoch 387 / 500 | iteration 0 / 30 | Total Loss: 1.056308388710022 | KNN Loss: 6.226895332336426 | BCE Loss: 1.056308388710022\n",
      "Epoch 387 / 500 | iteration 5 / 30 | Total Loss: 1.0751688480377197 | KNN Loss: 6.226883888244629 | BCE Loss: 1.0751688480377197\n",
      "Epoch 387 / 500 | iteration 10 / 30 | Total Loss: 1.0604615211486816 | KNN Loss: 6.227004528045654 | BCE Loss: 1.0604615211486816\n",
      "Epoch 387 / 500 | iteration 15 / 30 | Total Loss: 1.0524699687957764 | KNN Loss: 6.2268571853637695 | BCE Loss: 1.0524699687957764\n",
      "Epoch 387 / 500 | iteration 20 / 30 | Total Loss: 1.0448453426361084 | KNN Loss: 6.2265543937683105 | BCE Loss: 1.0448453426361084\n",
      "Epoch 387 / 500 | iteration 25 / 30 | Total Loss: 1.029829978942871 | KNN Loss: 6.226638317108154 | BCE Loss: 1.029829978942871\n",
      "Epoch 388 / 500 | iteration 0 / 30 | Total Loss: 1.1047543287277222 | KNN Loss: 6.226984977722168 | BCE Loss: 1.1047543287277222\n",
      "Epoch 388 / 500 | iteration 5 / 30 | Total Loss: 1.0668599605560303 | KNN Loss: 6.226644039154053 | BCE Loss: 1.0668599605560303\n",
      "Epoch 388 / 500 | iteration 10 / 30 | Total Loss: 1.0535483360290527 | KNN Loss: 6.227214813232422 | BCE Loss: 1.0535483360290527\n",
      "Epoch 388 / 500 | iteration 15 / 30 | Total Loss: 1.0518770217895508 | KNN Loss: 6.226925849914551 | BCE Loss: 1.0518770217895508\n",
      "Epoch 388 / 500 | iteration 20 / 30 | Total Loss: 1.0355916023254395 | KNN Loss: 6.226530075073242 | BCE Loss: 1.0355916023254395\n",
      "Epoch 388 / 500 | iteration 25 / 30 | Total Loss: 1.0594987869262695 | KNN Loss: 6.226681709289551 | BCE Loss: 1.0594987869262695\n",
      "Epoch 389 / 500 | iteration 0 / 30 | Total Loss: 1.0396265983581543 | KNN Loss: 6.226835250854492 | BCE Loss: 1.0396265983581543\n",
      "Epoch 389 / 500 | iteration 5 / 30 | Total Loss: 1.099238634109497 | KNN Loss: 6.227057933807373 | BCE Loss: 1.099238634109497\n",
      "Epoch 389 / 500 | iteration 10 / 30 | Total Loss: 1.0527682304382324 | KNN Loss: 6.226588726043701 | BCE Loss: 1.0527682304382324\n",
      "Epoch 389 / 500 | iteration 15 / 30 | Total Loss: 1.0671614408493042 | KNN Loss: 6.2268853187561035 | BCE Loss: 1.0671614408493042\n",
      "Epoch 389 / 500 | iteration 20 / 30 | Total Loss: 1.041187047958374 | KNN Loss: 6.22697639465332 | BCE Loss: 1.041187047958374\n",
      "Epoch 389 / 500 | iteration 25 / 30 | Total Loss: 1.0295538902282715 | KNN Loss: 6.226962566375732 | BCE Loss: 1.0295538902282715\n",
      "Epoch 390 / 500 | iteration 0 / 30 | Total Loss: 1.0598450899124146 | KNN Loss: 6.227001667022705 | BCE Loss: 1.0598450899124146\n",
      "Epoch 390 / 500 | iteration 5 / 30 | Total Loss: 1.0485332012176514 | KNN Loss: 6.226809978485107 | BCE Loss: 1.0485332012176514\n",
      "Epoch 390 / 500 | iteration 10 / 30 | Total Loss: 1.0797621011734009 | KNN Loss: 6.2269978523254395 | BCE Loss: 1.0797621011734009\n",
      "Epoch 390 / 500 | iteration 15 / 30 | Total Loss: 1.0381217002868652 | KNN Loss: 6.226840496063232 | BCE Loss: 1.0381217002868652\n",
      "Epoch 390 / 500 | iteration 20 / 30 | Total Loss: 1.0344487428665161 | KNN Loss: 6.226714611053467 | BCE Loss: 1.0344487428665161\n",
      "Epoch 390 / 500 | iteration 25 / 30 | Total Loss: 1.043212652206421 | KNN Loss: 6.227046489715576 | BCE Loss: 1.043212652206421\n",
      "Epoch 391 / 500 | iteration 0 / 30 | Total Loss: 1.0677611827850342 | KNN Loss: 6.2271552085876465 | BCE Loss: 1.0677611827850342\n",
      "Epoch 391 / 500 | iteration 5 / 30 | Total Loss: 1.0546993017196655 | KNN Loss: 6.2266459465026855 | BCE Loss: 1.0546993017196655\n",
      "Epoch 391 / 500 | iteration 10 / 30 | Total Loss: 1.0440709590911865 | KNN Loss: 6.226902008056641 | BCE Loss: 1.0440709590911865\n",
      "Epoch 391 / 500 | iteration 15 / 30 | Total Loss: 1.0513108968734741 | KNN Loss: 6.226607322692871 | BCE Loss: 1.0513108968734741\n",
      "Epoch 391 / 500 | iteration 20 / 30 | Total Loss: 1.0689294338226318 | KNN Loss: 6.22679328918457 | BCE Loss: 1.0689294338226318\n",
      "Epoch 391 / 500 | iteration 25 / 30 | Total Loss: 1.0656774044036865 | KNN Loss: 6.226932525634766 | BCE Loss: 1.0656774044036865\n",
      "Epoch   392: reducing learning rate of group 0 to 7.8888e-08.\n",
      "Epoch 392 / 500 | iteration 0 / 30 | Total Loss: 1.0404151678085327 | KNN Loss: 6.226757049560547 | BCE Loss: 1.0404151678085327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392 / 500 | iteration 5 / 30 | Total Loss: 1.0249288082122803 | KNN Loss: 6.226827621459961 | BCE Loss: 1.0249288082122803\n",
      "Epoch 392 / 500 | iteration 10 / 30 | Total Loss: 1.0448682308197021 | KNN Loss: 6.2268385887146 | BCE Loss: 1.0448682308197021\n",
      "Epoch 392 / 500 | iteration 15 / 30 | Total Loss: 1.0646051168441772 | KNN Loss: 6.226797580718994 | BCE Loss: 1.0646051168441772\n",
      "Epoch 392 / 500 | iteration 20 / 30 | Total Loss: 1.059933066368103 | KNN Loss: 6.226742267608643 | BCE Loss: 1.059933066368103\n",
      "Epoch 392 / 500 | iteration 25 / 30 | Total Loss: 1.069427251815796 | KNN Loss: 6.226789951324463 | BCE Loss: 1.069427251815796\n",
      "Epoch 393 / 500 | iteration 0 / 30 | Total Loss: 1.0437631607055664 | KNN Loss: 6.226999282836914 | BCE Loss: 1.0437631607055664\n",
      "Epoch 393 / 500 | iteration 5 / 30 | Total Loss: 1.0496611595153809 | KNN Loss: 6.226742267608643 | BCE Loss: 1.0496611595153809\n",
      "Epoch 393 / 500 | iteration 10 / 30 | Total Loss: 1.05628502368927 | KNN Loss: 6.226803779602051 | BCE Loss: 1.05628502368927\n",
      "Epoch 393 / 500 | iteration 15 / 30 | Total Loss: 1.0618728399276733 | KNN Loss: 6.22701358795166 | BCE Loss: 1.0618728399276733\n",
      "Epoch 393 / 500 | iteration 20 / 30 | Total Loss: 1.0784273147583008 | KNN Loss: 6.226855278015137 | BCE Loss: 1.0784273147583008\n",
      "Epoch 393 / 500 | iteration 25 / 30 | Total Loss: 1.0628098249435425 | KNN Loss: 6.226855754852295 | BCE Loss: 1.0628098249435425\n",
      "Epoch 394 / 500 | iteration 0 / 30 | Total Loss: 1.0461251735687256 | KNN Loss: 6.226945877075195 | BCE Loss: 1.0461251735687256\n",
      "Epoch 394 / 500 | iteration 5 / 30 | Total Loss: 1.0537223815917969 | KNN Loss: 6.226517677307129 | BCE Loss: 1.0537223815917969\n",
      "Epoch 394 / 500 | iteration 10 / 30 | Total Loss: 1.0489704608917236 | KNN Loss: 6.226986408233643 | BCE Loss: 1.0489704608917236\n",
      "Epoch 394 / 500 | iteration 15 / 30 | Total Loss: 1.0549875497817993 | KNN Loss: 6.226831436157227 | BCE Loss: 1.0549875497817993\n",
      "Epoch 394 / 500 | iteration 20 / 30 | Total Loss: 1.0454200506210327 | KNN Loss: 6.226872444152832 | BCE Loss: 1.0454200506210327\n",
      "Epoch 394 / 500 | iteration 25 / 30 | Total Loss: 1.035607099533081 | KNN Loss: 6.226870536804199 | BCE Loss: 1.035607099533081\n",
      "Epoch 395 / 500 | iteration 0 / 30 | Total Loss: 1.0514380931854248 | KNN Loss: 6.226986885070801 | BCE Loss: 1.0514380931854248\n",
      "Epoch 395 / 500 | iteration 5 / 30 | Total Loss: 1.0501365661621094 | KNN Loss: 6.226998805999756 | BCE Loss: 1.0501365661621094\n",
      "Epoch 395 / 500 | iteration 10 / 30 | Total Loss: 1.059496521949768 | KNN Loss: 6.22682523727417 | BCE Loss: 1.059496521949768\n",
      "Epoch 395 / 500 | iteration 15 / 30 | Total Loss: 1.0422093868255615 | KNN Loss: 6.226807117462158 | BCE Loss: 1.0422093868255615\n",
      "Epoch 395 / 500 | iteration 20 / 30 | Total Loss: 1.0662589073181152 | KNN Loss: 6.226867198944092 | BCE Loss: 1.0662589073181152\n",
      "Epoch 395 / 500 | iteration 25 / 30 | Total Loss: 1.041648030281067 | KNN Loss: 6.226978778839111 | BCE Loss: 1.041648030281067\n",
      "Epoch 396 / 500 | iteration 0 / 30 | Total Loss: 1.0224277973175049 | KNN Loss: 6.2269134521484375 | BCE Loss: 1.0224277973175049\n",
      "Epoch 396 / 500 | iteration 5 / 30 | Total Loss: 1.0334968566894531 | KNN Loss: 6.226739406585693 | BCE Loss: 1.0334968566894531\n",
      "Epoch 396 / 500 | iteration 10 / 30 | Total Loss: 1.062042236328125 | KNN Loss: 6.227279186248779 | BCE Loss: 1.062042236328125\n",
      "Epoch 396 / 500 | iteration 15 / 30 | Total Loss: 1.077246904373169 | KNN Loss: 6.227019786834717 | BCE Loss: 1.077246904373169\n",
      "Epoch 396 / 500 | iteration 20 / 30 | Total Loss: 1.048392415046692 | KNN Loss: 6.226877689361572 | BCE Loss: 1.048392415046692\n",
      "Epoch 396 / 500 | iteration 25 / 30 | Total Loss: 1.0276055335998535 | KNN Loss: 6.226650238037109 | BCE Loss: 1.0276055335998535\n",
      "Epoch 397 / 500 | iteration 0 / 30 | Total Loss: 1.049013376235962 | KNN Loss: 6.227056980133057 | BCE Loss: 1.049013376235962\n",
      "Epoch 397 / 500 | iteration 5 / 30 | Total Loss: 1.0544652938842773 | KNN Loss: 6.226782321929932 | BCE Loss: 1.0544652938842773\n",
      "Epoch 397 / 500 | iteration 10 / 30 | Total Loss: 1.0460988283157349 | KNN Loss: 6.226886749267578 | BCE Loss: 1.0460988283157349\n",
      "Epoch 397 / 500 | iteration 15 / 30 | Total Loss: 1.0451198816299438 | KNN Loss: 6.226473331451416 | BCE Loss: 1.0451198816299438\n",
      "Epoch 397 / 500 | iteration 20 / 30 | Total Loss: 1.0726337432861328 | KNN Loss: 6.226664066314697 | BCE Loss: 1.0726337432861328\n",
      "Epoch 397 / 500 | iteration 25 / 30 | Total Loss: 1.0537118911743164 | KNN Loss: 6.226872444152832 | BCE Loss: 1.0537118911743164\n",
      "Epoch 398 / 500 | iteration 0 / 30 | Total Loss: 1.0588847398757935 | KNN Loss: 6.226699352264404 | BCE Loss: 1.0588847398757935\n",
      "Epoch 398 / 500 | iteration 5 / 30 | Total Loss: 1.0713937282562256 | KNN Loss: 6.226751327514648 | BCE Loss: 1.0713937282562256\n",
      "Epoch 398 / 500 | iteration 10 / 30 | Total Loss: 1.055423378944397 | KNN Loss: 6.22674036026001 | BCE Loss: 1.055423378944397\n",
      "Epoch 398 / 500 | iteration 15 / 30 | Total Loss: 1.0538948774337769 | KNN Loss: 6.2270660400390625 | BCE Loss: 1.0538948774337769\n",
      "Epoch 398 / 500 | iteration 20 / 30 | Total Loss: 1.0406403541564941 | KNN Loss: 6.22733736038208 | BCE Loss: 1.0406403541564941\n",
      "Epoch 398 / 500 | iteration 25 / 30 | Total Loss: 1.0555939674377441 | KNN Loss: 6.227004528045654 | BCE Loss: 1.0555939674377441\n",
      "Epoch 399 / 500 | iteration 0 / 30 | Total Loss: 1.0653021335601807 | KNN Loss: 6.226953506469727 | BCE Loss: 1.0653021335601807\n",
      "Epoch 399 / 500 | iteration 5 / 30 | Total Loss: 1.0525463819503784 | KNN Loss: 6.226933479309082 | BCE Loss: 1.0525463819503784\n",
      "Epoch 399 / 500 | iteration 10 / 30 | Total Loss: 1.0478100776672363 | KNN Loss: 6.227015018463135 | BCE Loss: 1.0478100776672363\n",
      "Epoch 399 / 500 | iteration 15 / 30 | Total Loss: 1.0569535493850708 | KNN Loss: 6.227099418640137 | BCE Loss: 1.0569535493850708\n",
      "Epoch 399 / 500 | iteration 20 / 30 | Total Loss: 1.0455360412597656 | KNN Loss: 6.226902961730957 | BCE Loss: 1.0455360412597656\n",
      "Epoch 399 / 500 | iteration 25 / 30 | Total Loss: 1.0350192785263062 | KNN Loss: 6.226819038391113 | BCE Loss: 1.0350192785263062\n",
      "Epoch 400 / 500 | iteration 0 / 30 | Total Loss: 1.0737676620483398 | KNN Loss: 6.226871490478516 | BCE Loss: 1.0737676620483398\n",
      "Epoch 400 / 500 | iteration 5 / 30 | Total Loss: 1.0605955123901367 | KNN Loss: 6.226516246795654 | BCE Loss: 1.0605955123901367\n",
      "Epoch 400 / 500 | iteration 10 / 30 | Total Loss: 1.035569429397583 | KNN Loss: 6.2267560958862305 | BCE Loss: 1.035569429397583\n",
      "Epoch 400 / 500 | iteration 15 / 30 | Total Loss: 1.0590554475784302 | KNN Loss: 6.226754188537598 | BCE Loss: 1.0590554475784302\n",
      "Epoch 400 / 500 | iteration 20 / 30 | Total Loss: 1.0303584337234497 | KNN Loss: 6.226841926574707 | BCE Loss: 1.0303584337234497\n",
      "Epoch 400 / 500 | iteration 25 / 30 | Total Loss: 1.055001139640808 | KNN Loss: 6.226805210113525 | BCE Loss: 1.055001139640808\n",
      "Epoch 401 / 500 | iteration 0 / 30 | Total Loss: 1.0438125133514404 | KNN Loss: 6.226929187774658 | BCE Loss: 1.0438125133514404\n",
      "Epoch 401 / 500 | iteration 5 / 30 | Total Loss: 1.0580008029937744 | KNN Loss: 6.226871490478516 | BCE Loss: 1.0580008029937744\n",
      "Epoch 401 / 500 | iteration 10 / 30 | Total Loss: 1.0443942546844482 | KNN Loss: 6.2272748947143555 | BCE Loss: 1.0443942546844482\n",
      "Epoch 401 / 500 | iteration 15 / 30 | Total Loss: 1.0625263452529907 | KNN Loss: 6.226962089538574 | BCE Loss: 1.0625263452529907\n",
      "Epoch 401 / 500 | iteration 20 / 30 | Total Loss: 1.0558249950408936 | KNN Loss: 6.22691535949707 | BCE Loss: 1.0558249950408936\n",
      "Epoch 401 / 500 | iteration 25 / 30 | Total Loss: 1.0199568271636963 | KNN Loss: 6.2270612716674805 | BCE Loss: 1.0199568271636963\n",
      "Epoch 402 / 500 | iteration 0 / 30 | Total Loss: 1.0762615203857422 | KNN Loss: 6.22685432434082 | BCE Loss: 1.0762615203857422\n",
      "Epoch 402 / 500 | iteration 5 / 30 | Total Loss: 1.0463826656341553 | KNN Loss: 6.226718902587891 | BCE Loss: 1.0463826656341553\n",
      "Epoch 402 / 500 | iteration 10 / 30 | Total Loss: 1.056246280670166 | KNN Loss: 6.226780414581299 | BCE Loss: 1.056246280670166\n",
      "Epoch 402 / 500 | iteration 15 / 30 | Total Loss: 1.0514872074127197 | KNN Loss: 6.226670265197754 | BCE Loss: 1.0514872074127197\n",
      "Epoch 402 / 500 | iteration 20 / 30 | Total Loss: 1.0692164897918701 | KNN Loss: 6.226660251617432 | BCE Loss: 1.0692164897918701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402 / 500 | iteration 25 / 30 | Total Loss: 1.0361123085021973 | KNN Loss: 6.226984024047852 | BCE Loss: 1.0361123085021973\n",
      "Epoch   403: reducing learning rate of group 0 to 5.5221e-08.\n",
      "Epoch 403 / 500 | iteration 0 / 30 | Total Loss: 1.066566824913025 | KNN Loss: 6.226778984069824 | BCE Loss: 1.066566824913025\n",
      "Epoch 403 / 500 | iteration 5 / 30 | Total Loss: 1.0680656433105469 | KNN Loss: 6.226938724517822 | BCE Loss: 1.0680656433105469\n",
      "Epoch 403 / 500 | iteration 10 / 30 | Total Loss: 1.0470733642578125 | KNN Loss: 6.226911544799805 | BCE Loss: 1.0470733642578125\n",
      "Epoch 403 / 500 | iteration 15 / 30 | Total Loss: 1.0465502738952637 | KNN Loss: 6.226790428161621 | BCE Loss: 1.0465502738952637\n",
      "Epoch 403 / 500 | iteration 20 / 30 | Total Loss: 1.0392248630523682 | KNN Loss: 6.226500511169434 | BCE Loss: 1.0392248630523682\n",
      "Epoch 403 / 500 | iteration 25 / 30 | Total Loss: 1.0770124197006226 | KNN Loss: 6.226837158203125 | BCE Loss: 1.0770124197006226\n",
      "Epoch 404 / 500 | iteration 0 / 30 | Total Loss: 1.0761158466339111 | KNN Loss: 6.227214336395264 | BCE Loss: 1.0761158466339111\n",
      "Epoch 404 / 500 | iteration 5 / 30 | Total Loss: 1.0449999570846558 | KNN Loss: 6.226798057556152 | BCE Loss: 1.0449999570846558\n",
      "Epoch 404 / 500 | iteration 10 / 30 | Total Loss: 1.0729179382324219 | KNN Loss: 6.2269463539123535 | BCE Loss: 1.0729179382324219\n",
      "Epoch 404 / 500 | iteration 15 / 30 | Total Loss: 1.0827140808105469 | KNN Loss: 6.226990222930908 | BCE Loss: 1.0827140808105469\n",
      "Epoch 404 / 500 | iteration 20 / 30 | Total Loss: 1.0529063940048218 | KNN Loss: 6.226280689239502 | BCE Loss: 1.0529063940048218\n",
      "Epoch 404 / 500 | iteration 25 / 30 | Total Loss: 1.0355687141418457 | KNN Loss: 6.226898670196533 | BCE Loss: 1.0355687141418457\n",
      "Epoch 405 / 500 | iteration 0 / 30 | Total Loss: 1.0506434440612793 | KNN Loss: 6.226987361907959 | BCE Loss: 1.0506434440612793\n",
      "Epoch 405 / 500 | iteration 5 / 30 | Total Loss: 1.0594377517700195 | KNN Loss: 6.226827621459961 | BCE Loss: 1.0594377517700195\n",
      "Epoch 405 / 500 | iteration 10 / 30 | Total Loss: 1.049161672592163 | KNN Loss: 6.226772785186768 | BCE Loss: 1.049161672592163\n",
      "Epoch 405 / 500 | iteration 15 / 30 | Total Loss: 1.0524460077285767 | KNN Loss: 6.2268171310424805 | BCE Loss: 1.0524460077285767\n",
      "Epoch 405 / 500 | iteration 20 / 30 | Total Loss: 1.0341577529907227 | KNN Loss: 6.226597785949707 | BCE Loss: 1.0341577529907227\n",
      "Epoch 405 / 500 | iteration 25 / 30 | Total Loss: 1.0334084033966064 | KNN Loss: 6.226899147033691 | BCE Loss: 1.0334084033966064\n",
      "Epoch 406 / 500 | iteration 0 / 30 | Total Loss: 1.0315403938293457 | KNN Loss: 6.22695255279541 | BCE Loss: 1.0315403938293457\n",
      "Epoch 406 / 500 | iteration 5 / 30 | Total Loss: 1.0489000082015991 | KNN Loss: 6.227170467376709 | BCE Loss: 1.0489000082015991\n",
      "Epoch 406 / 500 | iteration 10 / 30 | Total Loss: 1.0299623012542725 | KNN Loss: 6.226912975311279 | BCE Loss: 1.0299623012542725\n",
      "Epoch 406 / 500 | iteration 15 / 30 | Total Loss: 1.0236172676086426 | KNN Loss: 6.227036952972412 | BCE Loss: 1.0236172676086426\n",
      "Epoch 406 / 500 | iteration 20 / 30 | Total Loss: 1.0542824268341064 | KNN Loss: 6.226720333099365 | BCE Loss: 1.0542824268341064\n",
      "Epoch 406 / 500 | iteration 25 / 30 | Total Loss: 1.0510239601135254 | KNN Loss: 6.226831912994385 | BCE Loss: 1.0510239601135254\n",
      "Epoch 407 / 500 | iteration 0 / 30 | Total Loss: 1.073065996170044 | KNN Loss: 6.227200508117676 | BCE Loss: 1.073065996170044\n",
      "Epoch 407 / 500 | iteration 5 / 30 | Total Loss: 1.057239055633545 | KNN Loss: 6.226646423339844 | BCE Loss: 1.057239055633545\n",
      "Epoch 407 / 500 | iteration 10 / 30 | Total Loss: 1.0726490020751953 | KNN Loss: 6.2266716957092285 | BCE Loss: 1.0726490020751953\n",
      "Epoch 407 / 500 | iteration 15 / 30 | Total Loss: 1.0649579763412476 | KNN Loss: 6.226818084716797 | BCE Loss: 1.0649579763412476\n",
      "Epoch 407 / 500 | iteration 20 / 30 | Total Loss: 1.0752296447753906 | KNN Loss: 6.226783275604248 | BCE Loss: 1.0752296447753906\n",
      "Epoch 407 / 500 | iteration 25 / 30 | Total Loss: 1.0455594062805176 | KNN Loss: 6.226988315582275 | BCE Loss: 1.0455594062805176\n",
      "Epoch 408 / 500 | iteration 0 / 30 | Total Loss: 1.0483949184417725 | KNN Loss: 6.226677417755127 | BCE Loss: 1.0483949184417725\n",
      "Epoch 408 / 500 | iteration 5 / 30 | Total Loss: 1.074718952178955 | KNN Loss: 6.22695255279541 | BCE Loss: 1.074718952178955\n",
      "Epoch 408 / 500 | iteration 10 / 30 | Total Loss: 1.0466389656066895 | KNN Loss: 6.226717472076416 | BCE Loss: 1.0466389656066895\n",
      "Epoch 408 / 500 | iteration 15 / 30 | Total Loss: 1.0713155269622803 | KNN Loss: 6.226816654205322 | BCE Loss: 1.0713155269622803\n",
      "Epoch 408 / 500 | iteration 20 / 30 | Total Loss: 1.0573277473449707 | KNN Loss: 6.2267913818359375 | BCE Loss: 1.0573277473449707\n",
      "Epoch 408 / 500 | iteration 25 / 30 | Total Loss: 1.0643494129180908 | KNN Loss: 6.2271952629089355 | BCE Loss: 1.0643494129180908\n",
      "Epoch 409 / 500 | iteration 0 / 30 | Total Loss: 1.061819314956665 | KNN Loss: 6.2266387939453125 | BCE Loss: 1.061819314956665\n",
      "Epoch 409 / 500 | iteration 5 / 30 | Total Loss: 1.0392348766326904 | KNN Loss: 6.227073669433594 | BCE Loss: 1.0392348766326904\n",
      "Epoch 409 / 500 | iteration 10 / 30 | Total Loss: 1.0850300788879395 | KNN Loss: 6.22660493850708 | BCE Loss: 1.0850300788879395\n",
      "Epoch 409 / 500 | iteration 15 / 30 | Total Loss: 1.0475389957427979 | KNN Loss: 6.226655960083008 | BCE Loss: 1.0475389957427979\n",
      "Epoch 409 / 500 | iteration 20 / 30 | Total Loss: 1.024280309677124 | KNN Loss: 6.226767063140869 | BCE Loss: 1.024280309677124\n",
      "Epoch 409 / 500 | iteration 25 / 30 | Total Loss: 1.014899730682373 | KNN Loss: 6.226907730102539 | BCE Loss: 1.014899730682373\n",
      "Epoch 410 / 500 | iteration 0 / 30 | Total Loss: 1.040692925453186 | KNN Loss: 6.227070331573486 | BCE Loss: 1.040692925453186\n",
      "Epoch 410 / 500 | iteration 5 / 30 | Total Loss: 1.032798171043396 | KNN Loss: 6.227000713348389 | BCE Loss: 1.032798171043396\n",
      "Epoch 410 / 500 | iteration 10 / 30 | Total Loss: 1.0121281147003174 | KNN Loss: 6.226751327514648 | BCE Loss: 1.0121281147003174\n",
      "Epoch 410 / 500 | iteration 15 / 30 | Total Loss: 1.0291011333465576 | KNN Loss: 6.226830005645752 | BCE Loss: 1.0291011333465576\n",
      "Epoch 410 / 500 | iteration 20 / 30 | Total Loss: 1.0174038410186768 | KNN Loss: 6.226840019226074 | BCE Loss: 1.0174038410186768\n",
      "Epoch 410 / 500 | iteration 25 / 30 | Total Loss: 1.0620112419128418 | KNN Loss: 6.226907730102539 | BCE Loss: 1.0620112419128418\n",
      "Epoch 411 / 500 | iteration 0 / 30 | Total Loss: 1.0496363639831543 | KNN Loss: 6.226810932159424 | BCE Loss: 1.0496363639831543\n",
      "Epoch 411 / 500 | iteration 5 / 30 | Total Loss: 1.0505032539367676 | KNN Loss: 6.2268900871276855 | BCE Loss: 1.0505032539367676\n",
      "Epoch 411 / 500 | iteration 10 / 30 | Total Loss: 1.0836361646652222 | KNN Loss: 6.227001667022705 | BCE Loss: 1.0836361646652222\n",
      "Epoch 411 / 500 | iteration 15 / 30 | Total Loss: 1.028930902481079 | KNN Loss: 6.226924896240234 | BCE Loss: 1.028930902481079\n",
      "Epoch 411 / 500 | iteration 20 / 30 | Total Loss: 1.0308585166931152 | KNN Loss: 6.227027893066406 | BCE Loss: 1.0308585166931152\n",
      "Epoch 411 / 500 | iteration 25 / 30 | Total Loss: 1.055855393409729 | KNN Loss: 6.226984977722168 | BCE Loss: 1.055855393409729\n",
      "Epoch 412 / 500 | iteration 0 / 30 | Total Loss: 1.046787142753601 | KNN Loss: 6.226999282836914 | BCE Loss: 1.046787142753601\n",
      "Epoch 412 / 500 | iteration 5 / 30 | Total Loss: 1.0702831745147705 | KNN Loss: 6.226829528808594 | BCE Loss: 1.0702831745147705\n",
      "Epoch 412 / 500 | iteration 10 / 30 | Total Loss: 1.0679140090942383 | KNN Loss: 6.227092266082764 | BCE Loss: 1.0679140090942383\n",
      "Epoch 412 / 500 | iteration 15 / 30 | Total Loss: 1.0677202939987183 | KNN Loss: 6.226961135864258 | BCE Loss: 1.0677202939987183\n",
      "Epoch 412 / 500 | iteration 20 / 30 | Total Loss: 1.0813379287719727 | KNN Loss: 6.226851463317871 | BCE Loss: 1.0813379287719727\n",
      "Epoch 412 / 500 | iteration 25 / 30 | Total Loss: 1.0714739561080933 | KNN Loss: 6.22691535949707 | BCE Loss: 1.0714739561080933\n",
      "Epoch 413 / 500 | iteration 0 / 30 | Total Loss: 1.0663342475891113 | KNN Loss: 6.22670316696167 | BCE Loss: 1.0663342475891113\n",
      "Epoch 413 / 500 | iteration 5 / 30 | Total Loss: 1.032064437866211 | KNN Loss: 6.2269721031188965 | BCE Loss: 1.032064437866211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413 / 500 | iteration 10 / 30 | Total Loss: 1.0608344078063965 | KNN Loss: 6.226782321929932 | BCE Loss: 1.0608344078063965\n",
      "Epoch 413 / 500 | iteration 15 / 30 | Total Loss: 1.0264697074890137 | KNN Loss: 6.226752758026123 | BCE Loss: 1.0264697074890137\n",
      "Epoch 413 / 500 | iteration 20 / 30 | Total Loss: 1.0338995456695557 | KNN Loss: 6.226859092712402 | BCE Loss: 1.0338995456695557\n",
      "Epoch 413 / 500 | iteration 25 / 30 | Total Loss: 1.0504870414733887 | KNN Loss: 6.22652530670166 | BCE Loss: 1.0504870414733887\n",
      "Epoch   414: reducing learning rate of group 0 to 3.8655e-08.\n",
      "Epoch 414 / 500 | iteration 0 / 30 | Total Loss: 1.0361324548721313 | KNN Loss: 6.226386547088623 | BCE Loss: 1.0361324548721313\n",
      "Epoch 414 / 500 | iteration 5 / 30 | Total Loss: 1.0342727899551392 | KNN Loss: 6.227099895477295 | BCE Loss: 1.0342727899551392\n",
      "Epoch 414 / 500 | iteration 10 / 30 | Total Loss: 1.04404616355896 | KNN Loss: 6.226900577545166 | BCE Loss: 1.04404616355896\n",
      "Epoch 414 / 500 | iteration 15 / 30 | Total Loss: 1.0817608833312988 | KNN Loss: 6.2267584800720215 | BCE Loss: 1.0817608833312988\n",
      "Epoch 414 / 500 | iteration 20 / 30 | Total Loss: 1.016837239265442 | KNN Loss: 6.226799964904785 | BCE Loss: 1.016837239265442\n",
      "Epoch 414 / 500 | iteration 25 / 30 | Total Loss: 1.0487860441207886 | KNN Loss: 6.226657867431641 | BCE Loss: 1.0487860441207886\n",
      "Epoch 415 / 500 | iteration 0 / 30 | Total Loss: 1.0325154066085815 | KNN Loss: 6.22673225402832 | BCE Loss: 1.0325154066085815\n",
      "Epoch 415 / 500 | iteration 5 / 30 | Total Loss: 1.0637385845184326 | KNN Loss: 6.227278232574463 | BCE Loss: 1.0637385845184326\n",
      "Epoch 415 / 500 | iteration 10 / 30 | Total Loss: 1.027801275253296 | KNN Loss: 6.226840972900391 | BCE Loss: 1.027801275253296\n",
      "Epoch 415 / 500 | iteration 15 / 30 | Total Loss: 1.068267583847046 | KNN Loss: 6.226608753204346 | BCE Loss: 1.068267583847046\n",
      "Epoch 415 / 500 | iteration 20 / 30 | Total Loss: 1.049253225326538 | KNN Loss: 6.227023124694824 | BCE Loss: 1.049253225326538\n",
      "Epoch 415 / 500 | iteration 25 / 30 | Total Loss: 1.0696544647216797 | KNN Loss: 6.226756572723389 | BCE Loss: 1.0696544647216797\n",
      "Epoch 416 / 500 | iteration 0 / 30 | Total Loss: 1.0492357015609741 | KNN Loss: 6.226853370666504 | BCE Loss: 1.0492357015609741\n",
      "Epoch 416 / 500 | iteration 5 / 30 | Total Loss: 1.05179762840271 | KNN Loss: 6.227116107940674 | BCE Loss: 1.05179762840271\n",
      "Epoch 416 / 500 | iteration 10 / 30 | Total Loss: 1.0379295349121094 | KNN Loss: 6.227219581604004 | BCE Loss: 1.0379295349121094\n",
      "Epoch 416 / 500 | iteration 15 / 30 | Total Loss: 1.0545461177825928 | KNN Loss: 6.226850509643555 | BCE Loss: 1.0545461177825928\n",
      "Epoch 416 / 500 | iteration 20 / 30 | Total Loss: 1.0481114387512207 | KNN Loss: 6.2270379066467285 | BCE Loss: 1.0481114387512207\n",
      "Epoch 416 / 500 | iteration 25 / 30 | Total Loss: 1.0637975931167603 | KNN Loss: 6.227240085601807 | BCE Loss: 1.0637975931167603\n",
      "Epoch 417 / 500 | iteration 0 / 30 | Total Loss: 1.0521211624145508 | KNN Loss: 6.226972579956055 | BCE Loss: 1.0521211624145508\n",
      "Epoch 417 / 500 | iteration 5 / 30 | Total Loss: 1.0391409397125244 | KNN Loss: 6.226812839508057 | BCE Loss: 1.0391409397125244\n",
      "Epoch 417 / 500 | iteration 10 / 30 | Total Loss: 1.0715110301971436 | KNN Loss: 6.2267069816589355 | BCE Loss: 1.0715110301971436\n",
      "Epoch 417 / 500 | iteration 15 / 30 | Total Loss: 1.0628595352172852 | KNN Loss: 6.226491928100586 | BCE Loss: 1.0628595352172852\n",
      "Epoch 417 / 500 | iteration 20 / 30 | Total Loss: 1.056366205215454 | KNN Loss: 6.226954460144043 | BCE Loss: 1.056366205215454\n",
      "Epoch 417 / 500 | iteration 25 / 30 | Total Loss: 1.0539430379867554 | KNN Loss: 6.226800441741943 | BCE Loss: 1.0539430379867554\n",
      "Epoch 418 / 500 | iteration 0 / 30 | Total Loss: 1.0489557981491089 | KNN Loss: 6.227239608764648 | BCE Loss: 1.0489557981491089\n",
      "Epoch 418 / 500 | iteration 5 / 30 | Total Loss: 1.0457031726837158 | KNN Loss: 6.226961135864258 | BCE Loss: 1.0457031726837158\n",
      "Epoch 418 / 500 | iteration 10 / 30 | Total Loss: 1.0510972738265991 | KNN Loss: 6.226874828338623 | BCE Loss: 1.0510972738265991\n",
      "Epoch 418 / 500 | iteration 15 / 30 | Total Loss: 1.0528680086135864 | KNN Loss: 6.227025032043457 | BCE Loss: 1.0528680086135864\n",
      "Epoch 418 / 500 | iteration 20 / 30 | Total Loss: 1.0686309337615967 | KNN Loss: 6.226888179779053 | BCE Loss: 1.0686309337615967\n",
      "Epoch 418 / 500 | iteration 25 / 30 | Total Loss: 1.0377169847488403 | KNN Loss: 6.226972579956055 | BCE Loss: 1.0377169847488403\n",
      "Epoch 419 / 500 | iteration 0 / 30 | Total Loss: 1.059898853302002 | KNN Loss: 6.227261066436768 | BCE Loss: 1.059898853302002\n",
      "Epoch 419 / 500 | iteration 5 / 30 | Total Loss: 1.0657808780670166 | KNN Loss: 6.227063179016113 | BCE Loss: 1.0657808780670166\n",
      "Epoch 419 / 500 | iteration 10 / 30 | Total Loss: 1.060309886932373 | KNN Loss: 6.2270894050598145 | BCE Loss: 1.060309886932373\n",
      "Epoch 419 / 500 | iteration 15 / 30 | Total Loss: 1.055584192276001 | KNN Loss: 6.2269086837768555 | BCE Loss: 1.055584192276001\n",
      "Epoch 419 / 500 | iteration 20 / 30 | Total Loss: 1.0433189868927002 | KNN Loss: 6.226699352264404 | BCE Loss: 1.0433189868927002\n",
      "Epoch 419 / 500 | iteration 25 / 30 | Total Loss: 1.0474638938903809 | KNN Loss: 6.226808547973633 | BCE Loss: 1.0474638938903809\n",
      "Epoch 420 / 500 | iteration 0 / 30 | Total Loss: 1.0561232566833496 | KNN Loss: 6.226772785186768 | BCE Loss: 1.0561232566833496\n",
      "Epoch 420 / 500 | iteration 5 / 30 | Total Loss: 1.0318970680236816 | KNN Loss: 6.22676944732666 | BCE Loss: 1.0318970680236816\n",
      "Epoch 420 / 500 | iteration 10 / 30 | Total Loss: 1.0727646350860596 | KNN Loss: 6.227014541625977 | BCE Loss: 1.0727646350860596\n",
      "Epoch 420 / 500 | iteration 15 / 30 | Total Loss: 1.0603152513504028 | KNN Loss: 6.226619720458984 | BCE Loss: 1.0603152513504028\n",
      "Epoch 420 / 500 | iteration 20 / 30 | Total Loss: 1.054785966873169 | KNN Loss: 6.226565837860107 | BCE Loss: 1.054785966873169\n",
      "Epoch 420 / 500 | iteration 25 / 30 | Total Loss: 1.0458866357803345 | KNN Loss: 6.226984024047852 | BCE Loss: 1.0458866357803345\n",
      "Epoch 421 / 500 | iteration 0 / 30 | Total Loss: 1.0509271621704102 | KNN Loss: 6.226877689361572 | BCE Loss: 1.0509271621704102\n",
      "Epoch 421 / 500 | iteration 5 / 30 | Total Loss: 1.0358543395996094 | KNN Loss: 6.226931095123291 | BCE Loss: 1.0358543395996094\n",
      "Epoch 421 / 500 | iteration 10 / 30 | Total Loss: 1.0609906911849976 | KNN Loss: 6.226764678955078 | BCE Loss: 1.0609906911849976\n",
      "Epoch 421 / 500 | iteration 15 / 30 | Total Loss: 1.0845730304718018 | KNN Loss: 6.226766109466553 | BCE Loss: 1.0845730304718018\n",
      "Epoch 421 / 500 | iteration 20 / 30 | Total Loss: 1.0592193603515625 | KNN Loss: 6.227027893066406 | BCE Loss: 1.0592193603515625\n",
      "Epoch 421 / 500 | iteration 25 / 30 | Total Loss: 1.0361096858978271 | KNN Loss: 6.227006435394287 | BCE Loss: 1.0361096858978271\n",
      "Epoch 422 / 500 | iteration 0 / 30 | Total Loss: 1.074882984161377 | KNN Loss: 6.227147102355957 | BCE Loss: 1.074882984161377\n",
      "Epoch 422 / 500 | iteration 5 / 30 | Total Loss: 1.0234763622283936 | KNN Loss: 6.2269110679626465 | BCE Loss: 1.0234763622283936\n",
      "Epoch 422 / 500 | iteration 10 / 30 | Total Loss: 1.0438978672027588 | KNN Loss: 6.2271857261657715 | BCE Loss: 1.0438978672027588\n",
      "Epoch 422 / 500 | iteration 15 / 30 | Total Loss: 1.0439203977584839 | KNN Loss: 6.2265777587890625 | BCE Loss: 1.0439203977584839\n",
      "Epoch 422 / 500 | iteration 20 / 30 | Total Loss: 1.0522921085357666 | KNN Loss: 6.226629257202148 | BCE Loss: 1.0522921085357666\n",
      "Epoch 422 / 500 | iteration 25 / 30 | Total Loss: 1.0796053409576416 | KNN Loss: 6.226585865020752 | BCE Loss: 1.0796053409576416\n",
      "Epoch 423 / 500 | iteration 0 / 30 | Total Loss: 1.0279285907745361 | KNN Loss: 6.226991653442383 | BCE Loss: 1.0279285907745361\n",
      "Epoch 423 / 500 | iteration 5 / 30 | Total Loss: 1.0374336242675781 | KNN Loss: 6.226879596710205 | BCE Loss: 1.0374336242675781\n",
      "Epoch 423 / 500 | iteration 10 / 30 | Total Loss: 1.0967323780059814 | KNN Loss: 6.226744174957275 | BCE Loss: 1.0967323780059814\n",
      "Epoch 423 / 500 | iteration 15 / 30 | Total Loss: 1.0615191459655762 | KNN Loss: 6.226816177368164 | BCE Loss: 1.0615191459655762\n",
      "Epoch 423 / 500 | iteration 20 / 30 | Total Loss: 1.0227190256118774 | KNN Loss: 6.226864814758301 | BCE Loss: 1.0227190256118774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423 / 500 | iteration 25 / 30 | Total Loss: 1.0463674068450928 | KNN Loss: 6.227054595947266 | BCE Loss: 1.0463674068450928\n",
      "Epoch 424 / 500 | iteration 0 / 30 | Total Loss: 1.0453095436096191 | KNN Loss: 6.226705074310303 | BCE Loss: 1.0453095436096191\n",
      "Epoch 424 / 500 | iteration 5 / 30 | Total Loss: 1.033537745475769 | KNN Loss: 6.227057933807373 | BCE Loss: 1.033537745475769\n",
      "Epoch 424 / 500 | iteration 10 / 30 | Total Loss: 1.056617021560669 | KNN Loss: 6.226995944976807 | BCE Loss: 1.056617021560669\n",
      "Epoch 424 / 500 | iteration 15 / 30 | Total Loss: 1.0635597705841064 | KNN Loss: 6.226958751678467 | BCE Loss: 1.0635597705841064\n",
      "Epoch 424 / 500 | iteration 20 / 30 | Total Loss: 1.0578558444976807 | KNN Loss: 6.226738452911377 | BCE Loss: 1.0578558444976807\n",
      "Epoch 424 / 500 | iteration 25 / 30 | Total Loss: 1.0769426822662354 | KNN Loss: 6.226658821105957 | BCE Loss: 1.0769426822662354\n",
      "Epoch   425: reducing learning rate of group 0 to 2.7058e-08.\n",
      "Epoch 425 / 500 | iteration 0 / 30 | Total Loss: 1.0585856437683105 | KNN Loss: 6.226642608642578 | BCE Loss: 1.0585856437683105\n",
      "Epoch 425 / 500 | iteration 5 / 30 | Total Loss: 1.0554490089416504 | KNN Loss: 6.227071762084961 | BCE Loss: 1.0554490089416504\n",
      "Epoch 425 / 500 | iteration 10 / 30 | Total Loss: 1.0846879482269287 | KNN Loss: 6.226909637451172 | BCE Loss: 1.0846879482269287\n",
      "Epoch 425 / 500 | iteration 15 / 30 | Total Loss: 1.0431385040283203 | KNN Loss: 6.226840972900391 | BCE Loss: 1.0431385040283203\n",
      "Epoch 425 / 500 | iteration 20 / 30 | Total Loss: 1.0322599411010742 | KNN Loss: 6.226889610290527 | BCE Loss: 1.0322599411010742\n",
      "Epoch 425 / 500 | iteration 25 / 30 | Total Loss: 1.05299973487854 | KNN Loss: 6.226958274841309 | BCE Loss: 1.05299973487854\n",
      "Epoch 426 / 500 | iteration 0 / 30 | Total Loss: 1.0548062324523926 | KNN Loss: 6.226742267608643 | BCE Loss: 1.0548062324523926\n",
      "Epoch 426 / 500 | iteration 5 / 30 | Total Loss: 1.0450689792633057 | KNN Loss: 6.226904392242432 | BCE Loss: 1.0450689792633057\n",
      "Epoch 426 / 500 | iteration 10 / 30 | Total Loss: 1.0895678997039795 | KNN Loss: 6.227195739746094 | BCE Loss: 1.0895678997039795\n",
      "Epoch 426 / 500 | iteration 15 / 30 | Total Loss: 1.0555657148361206 | KNN Loss: 6.2266998291015625 | BCE Loss: 1.0555657148361206\n",
      "Epoch 426 / 500 | iteration 20 / 30 | Total Loss: 1.0347833633422852 | KNN Loss: 6.226857662200928 | BCE Loss: 1.0347833633422852\n",
      "Epoch 426 / 500 | iteration 25 / 30 | Total Loss: 1.0678448677062988 | KNN Loss: 6.227025508880615 | BCE Loss: 1.0678448677062988\n",
      "Epoch 427 / 500 | iteration 0 / 30 | Total Loss: 1.0622307062149048 | KNN Loss: 6.2269158363342285 | BCE Loss: 1.0622307062149048\n",
      "Epoch 427 / 500 | iteration 5 / 30 | Total Loss: 1.0582412481307983 | KNN Loss: 6.226898193359375 | BCE Loss: 1.0582412481307983\n",
      "Epoch 427 / 500 | iteration 10 / 30 | Total Loss: 1.0440337657928467 | KNN Loss: 6.226962089538574 | BCE Loss: 1.0440337657928467\n",
      "Epoch 427 / 500 | iteration 15 / 30 | Total Loss: 1.0677062273025513 | KNN Loss: 6.226881504058838 | BCE Loss: 1.0677062273025513\n",
      "Epoch 427 / 500 | iteration 20 / 30 | Total Loss: 1.0332266092300415 | KNN Loss: 6.226881980895996 | BCE Loss: 1.0332266092300415\n",
      "Epoch 427 / 500 | iteration 25 / 30 | Total Loss: 1.0105774402618408 | KNN Loss: 6.226737976074219 | BCE Loss: 1.0105774402618408\n",
      "Epoch 428 / 500 | iteration 0 / 30 | Total Loss: 1.022269368171692 | KNN Loss: 6.2268548011779785 | BCE Loss: 1.022269368171692\n",
      "Epoch 428 / 500 | iteration 5 / 30 | Total Loss: 1.0411899089813232 | KNN Loss: 6.226746559143066 | BCE Loss: 1.0411899089813232\n",
      "Epoch 428 / 500 | iteration 10 / 30 | Total Loss: 1.0707316398620605 | KNN Loss: 6.226560115814209 | BCE Loss: 1.0707316398620605\n",
      "Epoch 428 / 500 | iteration 15 / 30 | Total Loss: 1.061460018157959 | KNN Loss: 6.2270426750183105 | BCE Loss: 1.061460018157959\n",
      "Epoch 428 / 500 | iteration 20 / 30 | Total Loss: 1.0237059593200684 | KNN Loss: 6.226541996002197 | BCE Loss: 1.0237059593200684\n",
      "Epoch 428 / 500 | iteration 25 / 30 | Total Loss: 1.0401160717010498 | KNN Loss: 6.22653865814209 | BCE Loss: 1.0401160717010498\n",
      "Epoch 429 / 500 | iteration 0 / 30 | Total Loss: 1.0959876775741577 | KNN Loss: 6.226902961730957 | BCE Loss: 1.0959876775741577\n",
      "Epoch 429 / 500 | iteration 5 / 30 | Total Loss: 1.0511136054992676 | KNN Loss: 6.226866245269775 | BCE Loss: 1.0511136054992676\n",
      "Epoch 429 / 500 | iteration 10 / 30 | Total Loss: 1.0366662740707397 | KNN Loss: 6.226883411407471 | BCE Loss: 1.0366662740707397\n",
      "Epoch 429 / 500 | iteration 15 / 30 | Total Loss: 1.0696914196014404 | KNN Loss: 6.226832389831543 | BCE Loss: 1.0696914196014404\n",
      "Epoch 429 / 500 | iteration 20 / 30 | Total Loss: 1.057328462600708 | KNN Loss: 6.226813793182373 | BCE Loss: 1.057328462600708\n",
      "Epoch 429 / 500 | iteration 25 / 30 | Total Loss: 1.0669084787368774 | KNN Loss: 6.2270188331604 | BCE Loss: 1.0669084787368774\n",
      "Epoch 430 / 500 | iteration 0 / 30 | Total Loss: 1.0963038206100464 | KNN Loss: 6.227236747741699 | BCE Loss: 1.0963038206100464\n",
      "Epoch 430 / 500 | iteration 5 / 30 | Total Loss: 1.0572149753570557 | KNN Loss: 6.226983070373535 | BCE Loss: 1.0572149753570557\n",
      "Epoch 430 / 500 | iteration 10 / 30 | Total Loss: 1.0221045017242432 | KNN Loss: 6.226768970489502 | BCE Loss: 1.0221045017242432\n",
      "Epoch 430 / 500 | iteration 15 / 30 | Total Loss: 1.0682917833328247 | KNN Loss: 6.226663589477539 | BCE Loss: 1.0682917833328247\n",
      "Epoch 430 / 500 | iteration 20 / 30 | Total Loss: 1.0549486875534058 | KNN Loss: 6.226559162139893 | BCE Loss: 1.0549486875534058\n",
      "Epoch 430 / 500 | iteration 25 / 30 | Total Loss: 1.0280572175979614 | KNN Loss: 6.226882457733154 | BCE Loss: 1.0280572175979614\n",
      "Epoch 431 / 500 | iteration 0 / 30 | Total Loss: 1.0431830883026123 | KNN Loss: 6.226784706115723 | BCE Loss: 1.0431830883026123\n",
      "Epoch 431 / 500 | iteration 5 / 30 | Total Loss: 1.0583698749542236 | KNN Loss: 6.2269606590271 | BCE Loss: 1.0583698749542236\n",
      "Epoch 431 / 500 | iteration 10 / 30 | Total Loss: 1.0716090202331543 | KNN Loss: 6.2268195152282715 | BCE Loss: 1.0716090202331543\n",
      "Epoch 431 / 500 | iteration 15 / 30 | Total Loss: 1.0441899299621582 | KNN Loss: 6.2269206047058105 | BCE Loss: 1.0441899299621582\n",
      "Epoch 431 / 500 | iteration 20 / 30 | Total Loss: 1.0238243341445923 | KNN Loss: 6.22703218460083 | BCE Loss: 1.0238243341445923\n",
      "Epoch 431 / 500 | iteration 25 / 30 | Total Loss: 1.0524488687515259 | KNN Loss: 6.226762771606445 | BCE Loss: 1.0524488687515259\n",
      "Epoch 432 / 500 | iteration 0 / 30 | Total Loss: 1.0377825498580933 | KNN Loss: 6.2270941734313965 | BCE Loss: 1.0377825498580933\n",
      "Epoch 432 / 500 | iteration 5 / 30 | Total Loss: 1.021591067314148 | KNN Loss: 6.2268452644348145 | BCE Loss: 1.021591067314148\n",
      "Epoch 432 / 500 | iteration 10 / 30 | Total Loss: 1.0722521543502808 | KNN Loss: 6.226964473724365 | BCE Loss: 1.0722521543502808\n",
      "Epoch 432 / 500 | iteration 15 / 30 | Total Loss: 1.0370229482650757 | KNN Loss: 6.2270989418029785 | BCE Loss: 1.0370229482650757\n",
      "Epoch 432 / 500 | iteration 20 / 30 | Total Loss: 1.0796623229980469 | KNN Loss: 6.226690292358398 | BCE Loss: 1.0796623229980469\n",
      "Epoch 432 / 500 | iteration 25 / 30 | Total Loss: 1.0832812786102295 | KNN Loss: 6.226694583892822 | BCE Loss: 1.0832812786102295\n",
      "Epoch 433 / 500 | iteration 0 / 30 | Total Loss: 1.0711653232574463 | KNN Loss: 6.226700305938721 | BCE Loss: 1.0711653232574463\n",
      "Epoch 433 / 500 | iteration 5 / 30 | Total Loss: 1.0574619770050049 | KNN Loss: 6.226705074310303 | BCE Loss: 1.0574619770050049\n",
      "Epoch 433 / 500 | iteration 10 / 30 | Total Loss: 1.0427095890045166 | KNN Loss: 6.226860523223877 | BCE Loss: 1.0427095890045166\n",
      "Epoch 433 / 500 | iteration 15 / 30 | Total Loss: 1.0851352214813232 | KNN Loss: 6.226813793182373 | BCE Loss: 1.0851352214813232\n",
      "Epoch 433 / 500 | iteration 20 / 30 | Total Loss: 1.0382474660873413 | KNN Loss: 6.227176666259766 | BCE Loss: 1.0382474660873413\n",
      "Epoch 433 / 500 | iteration 25 / 30 | Total Loss: 1.0430824756622314 | KNN Loss: 6.226922512054443 | BCE Loss: 1.0430824756622314\n",
      "Epoch 434 / 500 | iteration 0 / 30 | Total Loss: 1.0100046396255493 | KNN Loss: 6.226696968078613 | BCE Loss: 1.0100046396255493\n",
      "Epoch 434 / 500 | iteration 5 / 30 | Total Loss: 1.0968115329742432 | KNN Loss: 6.226805210113525 | BCE Loss: 1.0968115329742432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434 / 500 | iteration 10 / 30 | Total Loss: 1.0547343492507935 | KNN Loss: 6.226904392242432 | BCE Loss: 1.0547343492507935\n",
      "Epoch 434 / 500 | iteration 15 / 30 | Total Loss: 1.0579932928085327 | KNN Loss: 6.226836681365967 | BCE Loss: 1.0579932928085327\n",
      "Epoch 434 / 500 | iteration 20 / 30 | Total Loss: 1.0171520709991455 | KNN Loss: 6.226900577545166 | BCE Loss: 1.0171520709991455\n",
      "Epoch 434 / 500 | iteration 25 / 30 | Total Loss: 1.0413484573364258 | KNN Loss: 6.226826190948486 | BCE Loss: 1.0413484573364258\n",
      "Epoch 435 / 500 | iteration 0 / 30 | Total Loss: 1.027597427368164 | KNN Loss: 6.2268853187561035 | BCE Loss: 1.027597427368164\n",
      "Epoch 435 / 500 | iteration 5 / 30 | Total Loss: 1.0344082117080688 | KNN Loss: 6.226993560791016 | BCE Loss: 1.0344082117080688\n",
      "Epoch 435 / 500 | iteration 10 / 30 | Total Loss: 1.0293371677398682 | KNN Loss: 6.226876258850098 | BCE Loss: 1.0293371677398682\n",
      "Epoch 435 / 500 | iteration 15 / 30 | Total Loss: 1.0478893518447876 | KNN Loss: 6.226809501647949 | BCE Loss: 1.0478893518447876\n",
      "Epoch 435 / 500 | iteration 20 / 30 | Total Loss: 1.0599240064620972 | KNN Loss: 6.227171897888184 | BCE Loss: 1.0599240064620972\n",
      "Epoch 435 / 500 | iteration 25 / 30 | Total Loss: 1.0368900299072266 | KNN Loss: 6.226768493652344 | BCE Loss: 1.0368900299072266\n",
      "Epoch 436 / 500 | iteration 0 / 30 | Total Loss: 1.0688340663909912 | KNN Loss: 6.226925373077393 | BCE Loss: 1.0688340663909912\n",
      "Epoch 436 / 500 | iteration 5 / 30 | Total Loss: 1.0512058734893799 | KNN Loss: 6.2269182205200195 | BCE Loss: 1.0512058734893799\n",
      "Epoch 436 / 500 | iteration 10 / 30 | Total Loss: 1.0646828413009644 | KNN Loss: 6.226922512054443 | BCE Loss: 1.0646828413009644\n",
      "Epoch 436 / 500 | iteration 15 / 30 | Total Loss: 1.0118176937103271 | KNN Loss: 6.227207660675049 | BCE Loss: 1.0118176937103271\n",
      "Epoch 436 / 500 | iteration 20 / 30 | Total Loss: 1.0415232181549072 | KNN Loss: 6.226460933685303 | BCE Loss: 1.0415232181549072\n",
      "Epoch 436 / 500 | iteration 25 / 30 | Total Loss: 1.0481529235839844 | KNN Loss: 6.226710319519043 | BCE Loss: 1.0481529235839844\n",
      "Epoch 437 / 500 | iteration 0 / 30 | Total Loss: 1.0529532432556152 | KNN Loss: 6.226987838745117 | BCE Loss: 1.0529532432556152\n",
      "Epoch 437 / 500 | iteration 5 / 30 | Total Loss: 1.0507631301879883 | KNN Loss: 6.227288246154785 | BCE Loss: 1.0507631301879883\n",
      "Epoch 437 / 500 | iteration 10 / 30 | Total Loss: 1.042647123336792 | KNN Loss: 6.226704120635986 | BCE Loss: 1.042647123336792\n",
      "Epoch 437 / 500 | iteration 15 / 30 | Total Loss: 1.0224103927612305 | KNN Loss: 6.226998329162598 | BCE Loss: 1.0224103927612305\n",
      "Epoch 437 / 500 | iteration 20 / 30 | Total Loss: 1.0240333080291748 | KNN Loss: 6.226851940155029 | BCE Loss: 1.0240333080291748\n",
      "Epoch 437 / 500 | iteration 25 / 30 | Total Loss: 1.0704764127731323 | KNN Loss: 6.226832866668701 | BCE Loss: 1.0704764127731323\n",
      "Epoch 438 / 500 | iteration 0 / 30 | Total Loss: 1.0536298751831055 | KNN Loss: 6.22679328918457 | BCE Loss: 1.0536298751831055\n",
      "Epoch 438 / 500 | iteration 5 / 30 | Total Loss: 1.0465022325515747 | KNN Loss: 6.227016448974609 | BCE Loss: 1.0465022325515747\n",
      "Epoch 438 / 500 | iteration 10 / 30 | Total Loss: 1.0605268478393555 | KNN Loss: 6.226757526397705 | BCE Loss: 1.0605268478393555\n",
      "Epoch 438 / 500 | iteration 15 / 30 | Total Loss: 1.044769048690796 | KNN Loss: 6.22697114944458 | BCE Loss: 1.044769048690796\n",
      "Epoch 438 / 500 | iteration 20 / 30 | Total Loss: 1.0226430892944336 | KNN Loss: 6.2270355224609375 | BCE Loss: 1.0226430892944336\n",
      "Epoch 438 / 500 | iteration 25 / 30 | Total Loss: 1.052944302558899 | KNN Loss: 6.227012634277344 | BCE Loss: 1.052944302558899\n",
      "Epoch 439 / 500 | iteration 0 / 30 | Total Loss: 1.060976266860962 | KNN Loss: 6.2269816398620605 | BCE Loss: 1.060976266860962\n",
      "Epoch 439 / 500 | iteration 5 / 30 | Total Loss: 1.0702464580535889 | KNN Loss: 6.22660493850708 | BCE Loss: 1.0702464580535889\n",
      "Epoch 439 / 500 | iteration 10 / 30 | Total Loss: 1.0508275032043457 | KNN Loss: 6.226721286773682 | BCE Loss: 1.0508275032043457\n",
      "Epoch 439 / 500 | iteration 15 / 30 | Total Loss: 1.0343350172042847 | KNN Loss: 6.227137088775635 | BCE Loss: 1.0343350172042847\n",
      "Epoch 439 / 500 | iteration 20 / 30 | Total Loss: 1.059035062789917 | KNN Loss: 6.226736545562744 | BCE Loss: 1.059035062789917\n",
      "Epoch 439 / 500 | iteration 25 / 30 | Total Loss: 1.0428473949432373 | KNN Loss: 6.22698974609375 | BCE Loss: 1.0428473949432373\n",
      "Epoch 440 / 500 | iteration 0 / 30 | Total Loss: 1.0569171905517578 | KNN Loss: 6.226851463317871 | BCE Loss: 1.0569171905517578\n",
      "Epoch 440 / 500 | iteration 5 / 30 | Total Loss: 1.0458641052246094 | KNN Loss: 6.226896286010742 | BCE Loss: 1.0458641052246094\n",
      "Epoch 440 / 500 | iteration 10 / 30 | Total Loss: 1.0599899291992188 | KNN Loss: 6.2267680168151855 | BCE Loss: 1.0599899291992188\n",
      "Epoch 440 / 500 | iteration 15 / 30 | Total Loss: 1.0475904941558838 | KNN Loss: 6.22702693939209 | BCE Loss: 1.0475904941558838\n",
      "Epoch 440 / 500 | iteration 20 / 30 | Total Loss: 1.033066987991333 | KNN Loss: 6.226770877838135 | BCE Loss: 1.033066987991333\n",
      "Epoch 440 / 500 | iteration 25 / 30 | Total Loss: 1.030156135559082 | KNN Loss: 6.226722717285156 | BCE Loss: 1.030156135559082\n",
      "Epoch 441 / 500 | iteration 0 / 30 | Total Loss: 1.0431604385375977 | KNN Loss: 6.227020263671875 | BCE Loss: 1.0431604385375977\n",
      "Epoch 441 / 500 | iteration 5 / 30 | Total Loss: 1.0452592372894287 | KNN Loss: 6.22700309753418 | BCE Loss: 1.0452592372894287\n",
      "Epoch 441 / 500 | iteration 10 / 30 | Total Loss: 1.073803424835205 | KNN Loss: 6.2269487380981445 | BCE Loss: 1.073803424835205\n",
      "Epoch 441 / 500 | iteration 15 / 30 | Total Loss: 1.0400245189666748 | KNN Loss: 6.226752758026123 | BCE Loss: 1.0400245189666748\n",
      "Epoch 441 / 500 | iteration 20 / 30 | Total Loss: 1.0409818887710571 | KNN Loss: 6.226934909820557 | BCE Loss: 1.0409818887710571\n",
      "Epoch 441 / 500 | iteration 25 / 30 | Total Loss: 1.0524067878723145 | KNN Loss: 6.2270050048828125 | BCE Loss: 1.0524067878723145\n",
      "Epoch 442 / 500 | iteration 0 / 30 | Total Loss: 1.0257561206817627 | KNN Loss: 6.226910591125488 | BCE Loss: 1.0257561206817627\n",
      "Epoch 442 / 500 | iteration 5 / 30 | Total Loss: 1.0724536180496216 | KNN Loss: 6.226762771606445 | BCE Loss: 1.0724536180496216\n",
      "Epoch 442 / 500 | iteration 10 / 30 | Total Loss: 1.0500519275665283 | KNN Loss: 6.226949691772461 | BCE Loss: 1.0500519275665283\n",
      "Epoch 442 / 500 | iteration 15 / 30 | Total Loss: 1.0428569316864014 | KNN Loss: 6.226546287536621 | BCE Loss: 1.0428569316864014\n",
      "Epoch 442 / 500 | iteration 20 / 30 | Total Loss: 1.0616891384124756 | KNN Loss: 6.22703742980957 | BCE Loss: 1.0616891384124756\n",
      "Epoch 442 / 500 | iteration 25 / 30 | Total Loss: 1.054141879081726 | KNN Loss: 6.226658344268799 | BCE Loss: 1.054141879081726\n",
      "Epoch 443 / 500 | iteration 0 / 30 | Total Loss: 1.0723668336868286 | KNN Loss: 6.2266130447387695 | BCE Loss: 1.0723668336868286\n",
      "Epoch 443 / 500 | iteration 5 / 30 | Total Loss: 1.060581922531128 | KNN Loss: 6.226890563964844 | BCE Loss: 1.060581922531128\n",
      "Epoch 443 / 500 | iteration 10 / 30 | Total Loss: 1.0316331386566162 | KNN Loss: 6.227202415466309 | BCE Loss: 1.0316331386566162\n",
      "Epoch 443 / 500 | iteration 15 / 30 | Total Loss: 1.0345306396484375 | KNN Loss: 6.2266998291015625 | BCE Loss: 1.0345306396484375\n",
      "Epoch 443 / 500 | iteration 20 / 30 | Total Loss: 1.064732313156128 | KNN Loss: 6.226973056793213 | BCE Loss: 1.064732313156128\n",
      "Epoch 443 / 500 | iteration 25 / 30 | Total Loss: 1.032605528831482 | KNN Loss: 6.226797103881836 | BCE Loss: 1.032605528831482\n",
      "Epoch 444 / 500 | iteration 0 / 30 | Total Loss: 1.0499017238616943 | KNN Loss: 6.226617336273193 | BCE Loss: 1.0499017238616943\n",
      "Epoch 444 / 500 | iteration 5 / 30 | Total Loss: 1.059463620185852 | KNN Loss: 6.2268195152282715 | BCE Loss: 1.059463620185852\n",
      "Epoch 444 / 500 | iteration 10 / 30 | Total Loss: 1.0824251174926758 | KNN Loss: 6.226900100708008 | BCE Loss: 1.0824251174926758\n",
      "Epoch 444 / 500 | iteration 15 / 30 | Total Loss: 1.0299183130264282 | KNN Loss: 6.22666597366333 | BCE Loss: 1.0299183130264282\n",
      "Epoch 444 / 500 | iteration 20 / 30 | Total Loss: 1.0417892932891846 | KNN Loss: 6.226949691772461 | BCE Loss: 1.0417892932891846\n",
      "Epoch 444 / 500 | iteration 25 / 30 | Total Loss: 1.0397577285766602 | KNN Loss: 6.226710796356201 | BCE Loss: 1.0397577285766602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445 / 500 | iteration 0 / 30 | Total Loss: 1.0739376544952393 | KNN Loss: 6.22672176361084 | BCE Loss: 1.0739376544952393\n",
      "Epoch 445 / 500 | iteration 5 / 30 | Total Loss: 1.0409018993377686 | KNN Loss: 6.226966857910156 | BCE Loss: 1.0409018993377686\n",
      "Epoch 445 / 500 | iteration 10 / 30 | Total Loss: 1.0651123523712158 | KNN Loss: 6.2271728515625 | BCE Loss: 1.0651123523712158\n",
      "Epoch 445 / 500 | iteration 15 / 30 | Total Loss: 1.0619744062423706 | KNN Loss: 6.2267913818359375 | BCE Loss: 1.0619744062423706\n",
      "Epoch 445 / 500 | iteration 20 / 30 | Total Loss: 1.0516583919525146 | KNN Loss: 6.226952075958252 | BCE Loss: 1.0516583919525146\n",
      "Epoch 445 / 500 | iteration 25 / 30 | Total Loss: 1.0842089653015137 | KNN Loss: 6.226693153381348 | BCE Loss: 1.0842089653015137\n",
      "Epoch 446 / 500 | iteration 0 / 30 | Total Loss: 1.0410763025283813 | KNN Loss: 6.226855278015137 | BCE Loss: 1.0410763025283813\n",
      "Epoch 446 / 500 | iteration 5 / 30 | Total Loss: 1.0736632347106934 | KNN Loss: 6.22697114944458 | BCE Loss: 1.0736632347106934\n",
      "Epoch 446 / 500 | iteration 10 / 30 | Total Loss: 1.053479790687561 | KNN Loss: 6.2268595695495605 | BCE Loss: 1.053479790687561\n",
      "Epoch 446 / 500 | iteration 15 / 30 | Total Loss: 1.031561017036438 | KNN Loss: 6.227022171020508 | BCE Loss: 1.031561017036438\n",
      "Epoch 446 / 500 | iteration 20 / 30 | Total Loss: 1.036458969116211 | KNN Loss: 6.227070331573486 | BCE Loss: 1.036458969116211\n",
      "Epoch 446 / 500 | iteration 25 / 30 | Total Loss: 1.0362396240234375 | KNN Loss: 6.2269768714904785 | BCE Loss: 1.0362396240234375\n",
      "Epoch 447 / 500 | iteration 0 / 30 | Total Loss: 1.0615241527557373 | KNN Loss: 6.2266974449157715 | BCE Loss: 1.0615241527557373\n",
      "Epoch 447 / 500 | iteration 5 / 30 | Total Loss: 1.0614031553268433 | KNN Loss: 6.226909637451172 | BCE Loss: 1.0614031553268433\n",
      "Epoch 447 / 500 | iteration 10 / 30 | Total Loss: 1.0579731464385986 | KNN Loss: 6.2267045974731445 | BCE Loss: 1.0579731464385986\n",
      "Epoch 447 / 500 | iteration 15 / 30 | Total Loss: 1.0458545684814453 | KNN Loss: 6.226879596710205 | BCE Loss: 1.0458545684814453\n",
      "Epoch 447 / 500 | iteration 20 / 30 | Total Loss: 1.0292541980743408 | KNN Loss: 6.226775646209717 | BCE Loss: 1.0292541980743408\n",
      "Epoch 447 / 500 | iteration 25 / 30 | Total Loss: 1.061322808265686 | KNN Loss: 6.226968288421631 | BCE Loss: 1.061322808265686\n",
      "Epoch 448 / 500 | iteration 0 / 30 | Total Loss: 1.058850884437561 | KNN Loss: 6.227039337158203 | BCE Loss: 1.058850884437561\n",
      "Epoch 448 / 500 | iteration 5 / 30 | Total Loss: 1.0232665538787842 | KNN Loss: 6.227122783660889 | BCE Loss: 1.0232665538787842\n",
      "Epoch 448 / 500 | iteration 10 / 30 | Total Loss: 1.043827772140503 | KNN Loss: 6.226499080657959 | BCE Loss: 1.043827772140503\n",
      "Epoch 448 / 500 | iteration 15 / 30 | Total Loss: 1.0589895248413086 | KNN Loss: 6.226842880249023 | BCE Loss: 1.0589895248413086\n",
      "Epoch 448 / 500 | iteration 20 / 30 | Total Loss: 1.0370399951934814 | KNN Loss: 6.226795673370361 | BCE Loss: 1.0370399951934814\n",
      "Epoch 448 / 500 | iteration 25 / 30 | Total Loss: 1.0411444902420044 | KNN Loss: 6.22700834274292 | BCE Loss: 1.0411444902420044\n",
      "Epoch 449 / 500 | iteration 0 / 30 | Total Loss: 1.0620917081832886 | KNN Loss: 6.2267560958862305 | BCE Loss: 1.0620917081832886\n",
      "Epoch 449 / 500 | iteration 5 / 30 | Total Loss: 1.02443528175354 | KNN Loss: 6.2267937660217285 | BCE Loss: 1.02443528175354\n",
      "Epoch 449 / 500 | iteration 10 / 30 | Total Loss: 1.0523401498794556 | KNN Loss: 6.227056503295898 | BCE Loss: 1.0523401498794556\n",
      "Epoch 449 / 500 | iteration 15 / 30 | Total Loss: 1.075387954711914 | KNN Loss: 6.226907253265381 | BCE Loss: 1.075387954711914\n",
      "Epoch 449 / 500 | iteration 20 / 30 | Total Loss: 1.0665829181671143 | KNN Loss: 6.226715564727783 | BCE Loss: 1.0665829181671143\n",
      "Epoch 449 / 500 | iteration 25 / 30 | Total Loss: 1.0692352056503296 | KNN Loss: 6.226874351501465 | BCE Loss: 1.0692352056503296\n",
      "Epoch 450 / 500 | iteration 0 / 30 | Total Loss: 1.052553653717041 | KNN Loss: 6.226926326751709 | BCE Loss: 1.052553653717041\n",
      "Epoch 450 / 500 | iteration 5 / 30 | Total Loss: 1.0633785724639893 | KNN Loss: 6.226957321166992 | BCE Loss: 1.0633785724639893\n",
      "Epoch 450 / 500 | iteration 10 / 30 | Total Loss: 1.0534467697143555 | KNN Loss: 6.227012634277344 | BCE Loss: 1.0534467697143555\n",
      "Epoch 450 / 500 | iteration 15 / 30 | Total Loss: 1.0519583225250244 | KNN Loss: 6.2270731925964355 | BCE Loss: 1.0519583225250244\n",
      "Epoch 450 / 500 | iteration 20 / 30 | Total Loss: 1.0455408096313477 | KNN Loss: 6.227077960968018 | BCE Loss: 1.0455408096313477\n",
      "Epoch 450 / 500 | iteration 25 / 30 | Total Loss: 1.006361961364746 | KNN Loss: 6.22672176361084 | BCE Loss: 1.006361961364746\n",
      "Epoch 451 / 500 | iteration 0 / 30 | Total Loss: 1.0722538232803345 | KNN Loss: 6.227257251739502 | BCE Loss: 1.0722538232803345\n",
      "Epoch 451 / 500 | iteration 5 / 30 | Total Loss: 1.0533089637756348 | KNN Loss: 6.226508140563965 | BCE Loss: 1.0533089637756348\n",
      "Epoch 451 / 500 | iteration 10 / 30 | Total Loss: 1.0508016347885132 | KNN Loss: 6.227031707763672 | BCE Loss: 1.0508016347885132\n",
      "Epoch 451 / 500 | iteration 15 / 30 | Total Loss: 1.0681087970733643 | KNN Loss: 6.227173328399658 | BCE Loss: 1.0681087970733643\n",
      "Epoch 451 / 500 | iteration 20 / 30 | Total Loss: 1.063380241394043 | KNN Loss: 6.226834297180176 | BCE Loss: 1.063380241394043\n",
      "Epoch 451 / 500 | iteration 25 / 30 | Total Loss: 1.0926554203033447 | KNN Loss: 6.226705074310303 | BCE Loss: 1.0926554203033447\n",
      "Epoch 452 / 500 | iteration 0 / 30 | Total Loss: 1.0659912824630737 | KNN Loss: 6.226999759674072 | BCE Loss: 1.0659912824630737\n",
      "Epoch 452 / 500 | iteration 5 / 30 | Total Loss: 1.0679429769515991 | KNN Loss: 6.226739406585693 | BCE Loss: 1.0679429769515991\n",
      "Epoch 452 / 500 | iteration 10 / 30 | Total Loss: 1.001294493675232 | KNN Loss: 6.226804256439209 | BCE Loss: 1.001294493675232\n",
      "Epoch 452 / 500 | iteration 15 / 30 | Total Loss: 1.0972352027893066 | KNN Loss: 6.226891994476318 | BCE Loss: 1.0972352027893066\n",
      "Epoch 452 / 500 | iteration 20 / 30 | Total Loss: 1.0277034044265747 | KNN Loss: 6.226808547973633 | BCE Loss: 1.0277034044265747\n",
      "Epoch 452 / 500 | iteration 25 / 30 | Total Loss: 1.0618679523468018 | KNN Loss: 6.226895809173584 | BCE Loss: 1.0618679523468018\n",
      "Epoch 453 / 500 | iteration 0 / 30 | Total Loss: 1.066373348236084 | KNN Loss: 6.226589202880859 | BCE Loss: 1.066373348236084\n",
      "Epoch 453 / 500 | iteration 5 / 30 | Total Loss: 1.0439467430114746 | KNN Loss: 6.226898670196533 | BCE Loss: 1.0439467430114746\n",
      "Epoch 453 / 500 | iteration 10 / 30 | Total Loss: 1.0238113403320312 | KNN Loss: 6.227211952209473 | BCE Loss: 1.0238113403320312\n",
      "Epoch 453 / 500 | iteration 15 / 30 | Total Loss: 1.0439738035202026 | KNN Loss: 6.226785659790039 | BCE Loss: 1.0439738035202026\n",
      "Epoch 453 / 500 | iteration 20 / 30 | Total Loss: 1.039865255355835 | KNN Loss: 6.227078914642334 | BCE Loss: 1.039865255355835\n",
      "Epoch 453 / 500 | iteration 25 / 30 | Total Loss: 1.069819450378418 | KNN Loss: 6.226884841918945 | BCE Loss: 1.069819450378418\n",
      "Epoch 454 / 500 | iteration 0 / 30 | Total Loss: 1.068467378616333 | KNN Loss: 6.226939678192139 | BCE Loss: 1.068467378616333\n",
      "Epoch 454 / 500 | iteration 5 / 30 | Total Loss: 1.0417866706848145 | KNN Loss: 6.226968765258789 | BCE Loss: 1.0417866706848145\n",
      "Epoch 454 / 500 | iteration 10 / 30 | Total Loss: 1.0609207153320312 | KNN Loss: 6.226921081542969 | BCE Loss: 1.0609207153320312\n",
      "Epoch 454 / 500 | iteration 15 / 30 | Total Loss: 1.0527832508087158 | KNN Loss: 6.226902484893799 | BCE Loss: 1.0527832508087158\n",
      "Epoch 454 / 500 | iteration 20 / 30 | Total Loss: 1.0493305921554565 | KNN Loss: 6.2271528244018555 | BCE Loss: 1.0493305921554565\n",
      "Epoch 454 / 500 | iteration 25 / 30 | Total Loss: 1.061761736869812 | KNN Loss: 6.226994037628174 | BCE Loss: 1.061761736869812\n",
      "Epoch 455 / 500 | iteration 0 / 30 | Total Loss: 1.0383789539337158 | KNN Loss: 6.227153778076172 | BCE Loss: 1.0383789539337158\n",
      "Epoch 455 / 500 | iteration 5 / 30 | Total Loss: 1.0462219715118408 | KNN Loss: 6.2266387939453125 | BCE Loss: 1.0462219715118408\n",
      "Epoch 455 / 500 | iteration 10 / 30 | Total Loss: 1.0600812435150146 | KNN Loss: 6.227189064025879 | BCE Loss: 1.0600812435150146\n",
      "Epoch 455 / 500 | iteration 15 / 30 | Total Loss: 1.0291426181793213 | KNN Loss: 6.226827144622803 | BCE Loss: 1.0291426181793213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455 / 500 | iteration 20 / 30 | Total Loss: 1.0498290061950684 | KNN Loss: 6.226836204528809 | BCE Loss: 1.0498290061950684\n",
      "Epoch 455 / 500 | iteration 25 / 30 | Total Loss: 1.0303428173065186 | KNN Loss: 6.227087497711182 | BCE Loss: 1.0303428173065186\n",
      "Epoch 456 / 500 | iteration 0 / 30 | Total Loss: 1.0508776903152466 | KNN Loss: 6.226822376251221 | BCE Loss: 1.0508776903152466\n",
      "Epoch 456 / 500 | iteration 5 / 30 | Total Loss: 1.0384671688079834 | KNN Loss: 6.2269062995910645 | BCE Loss: 1.0384671688079834\n",
      "Epoch 456 / 500 | iteration 10 / 30 | Total Loss: 1.049192190170288 | KNN Loss: 6.226996421813965 | BCE Loss: 1.049192190170288\n",
      "Epoch 456 / 500 | iteration 15 / 30 | Total Loss: 1.0369064807891846 | KNN Loss: 6.22691535949707 | BCE Loss: 1.0369064807891846\n",
      "Epoch 456 / 500 | iteration 20 / 30 | Total Loss: 1.0283255577087402 | KNN Loss: 6.226684093475342 | BCE Loss: 1.0283255577087402\n",
      "Epoch 456 / 500 | iteration 25 / 30 | Total Loss: 1.0855860710144043 | KNN Loss: 6.226513385772705 | BCE Loss: 1.0855860710144043\n",
      "Epoch 457 / 500 | iteration 0 / 30 | Total Loss: 1.034962773323059 | KNN Loss: 6.226850986480713 | BCE Loss: 1.034962773323059\n",
      "Epoch 457 / 500 | iteration 5 / 30 | Total Loss: 1.058347463607788 | KNN Loss: 6.226946830749512 | BCE Loss: 1.058347463607788\n",
      "Epoch 457 / 500 | iteration 10 / 30 | Total Loss: 1.0309367179870605 | KNN Loss: 6.226785182952881 | BCE Loss: 1.0309367179870605\n",
      "Epoch 457 / 500 | iteration 15 / 30 | Total Loss: 1.0425748825073242 | KNN Loss: 6.226944446563721 | BCE Loss: 1.0425748825073242\n",
      "Epoch 457 / 500 | iteration 20 / 30 | Total Loss: 1.0612870454788208 | KNN Loss: 6.226811408996582 | BCE Loss: 1.0612870454788208\n",
      "Epoch 457 / 500 | iteration 25 / 30 | Total Loss: 1.059767723083496 | KNN Loss: 6.226937294006348 | BCE Loss: 1.059767723083496\n",
      "Epoch 458 / 500 | iteration 0 / 30 | Total Loss: 1.0353891849517822 | KNN Loss: 6.22658634185791 | BCE Loss: 1.0353891849517822\n",
      "Epoch 458 / 500 | iteration 5 / 30 | Total Loss: 1.0398716926574707 | KNN Loss: 6.2269182205200195 | BCE Loss: 1.0398716926574707\n",
      "Epoch 458 / 500 | iteration 10 / 30 | Total Loss: 1.0621241331100464 | KNN Loss: 6.226510047912598 | BCE Loss: 1.0621241331100464\n",
      "Epoch 458 / 500 | iteration 15 / 30 | Total Loss: 1.0525916814804077 | KNN Loss: 6.226918697357178 | BCE Loss: 1.0525916814804077\n",
      "Epoch 458 / 500 | iteration 20 / 30 | Total Loss: 1.0392627716064453 | KNN Loss: 6.226672649383545 | BCE Loss: 1.0392627716064453\n",
      "Epoch 458 / 500 | iteration 25 / 30 | Total Loss: 1.0277998447418213 | KNN Loss: 6.2269673347473145 | BCE Loss: 1.0277998447418213\n",
      "Epoch 459 / 500 | iteration 0 / 30 | Total Loss: 1.0614173412322998 | KNN Loss: 6.226841449737549 | BCE Loss: 1.0614173412322998\n",
      "Epoch 459 / 500 | iteration 5 / 30 | Total Loss: 1.0744502544403076 | KNN Loss: 6.226916790008545 | BCE Loss: 1.0744502544403076\n",
      "Epoch 459 / 500 | iteration 10 / 30 | Total Loss: 1.0338563919067383 | KNN Loss: 6.226757526397705 | BCE Loss: 1.0338563919067383\n",
      "Epoch 459 / 500 | iteration 15 / 30 | Total Loss: 1.0711772441864014 | KNN Loss: 6.227096080780029 | BCE Loss: 1.0711772441864014\n",
      "Epoch 459 / 500 | iteration 20 / 30 | Total Loss: 1.0615618228912354 | KNN Loss: 6.226902484893799 | BCE Loss: 1.0615618228912354\n",
      "Epoch 459 / 500 | iteration 25 / 30 | Total Loss: 1.0457274913787842 | KNN Loss: 6.22688102722168 | BCE Loss: 1.0457274913787842\n",
      "Epoch 460 / 500 | iteration 0 / 30 | Total Loss: 1.0615432262420654 | KNN Loss: 6.226561546325684 | BCE Loss: 1.0615432262420654\n",
      "Epoch 460 / 500 | iteration 5 / 30 | Total Loss: 1.0629534721374512 | KNN Loss: 6.226799011230469 | BCE Loss: 1.0629534721374512\n",
      "Epoch 460 / 500 | iteration 10 / 30 | Total Loss: 1.0116629600524902 | KNN Loss: 6.226572513580322 | BCE Loss: 1.0116629600524902\n",
      "Epoch 460 / 500 | iteration 15 / 30 | Total Loss: 1.0177003145217896 | KNN Loss: 6.226955413818359 | BCE Loss: 1.0177003145217896\n",
      "Epoch 460 / 500 | iteration 20 / 30 | Total Loss: 1.0694864988327026 | KNN Loss: 6.227112293243408 | BCE Loss: 1.0694864988327026\n",
      "Epoch 460 / 500 | iteration 25 / 30 | Total Loss: 1.0598222017288208 | KNN Loss: 6.226950168609619 | BCE Loss: 1.0598222017288208\n",
      "Epoch 461 / 500 | iteration 0 / 30 | Total Loss: 1.053888201713562 | KNN Loss: 6.2267608642578125 | BCE Loss: 1.053888201713562\n",
      "Epoch 461 / 500 | iteration 5 / 30 | Total Loss: 1.0419808626174927 | KNN Loss: 6.2271409034729 | BCE Loss: 1.0419808626174927\n",
      "Epoch 461 / 500 | iteration 10 / 30 | Total Loss: 1.025339126586914 | KNN Loss: 6.226656913757324 | BCE Loss: 1.025339126586914\n",
      "Epoch 461 / 500 | iteration 15 / 30 | Total Loss: 1.044840931892395 | KNN Loss: 6.22662878036499 | BCE Loss: 1.044840931892395\n",
      "Epoch 461 / 500 | iteration 20 / 30 | Total Loss: 1.0504748821258545 | KNN Loss: 6.226778030395508 | BCE Loss: 1.0504748821258545\n",
      "Epoch 461 / 500 | iteration 25 / 30 | Total Loss: 1.0644842386245728 | KNN Loss: 6.2267937660217285 | BCE Loss: 1.0644842386245728\n",
      "Epoch 462 / 500 | iteration 0 / 30 | Total Loss: 1.039548397064209 | KNN Loss: 6.227084159851074 | BCE Loss: 1.039548397064209\n",
      "Epoch 462 / 500 | iteration 5 / 30 | Total Loss: 1.0766210556030273 | KNN Loss: 6.227187633514404 | BCE Loss: 1.0766210556030273\n",
      "Epoch 462 / 500 | iteration 10 / 30 | Total Loss: 1.0628204345703125 | KNN Loss: 6.226910591125488 | BCE Loss: 1.0628204345703125\n",
      "Epoch 462 / 500 | iteration 15 / 30 | Total Loss: 1.0746574401855469 | KNN Loss: 6.2269158363342285 | BCE Loss: 1.0746574401855469\n",
      "Epoch 462 / 500 | iteration 20 / 30 | Total Loss: 1.0461833477020264 | KNN Loss: 6.2267374992370605 | BCE Loss: 1.0461833477020264\n",
      "Epoch 462 / 500 | iteration 25 / 30 | Total Loss: 1.0547759532928467 | KNN Loss: 6.226966381072998 | BCE Loss: 1.0547759532928467\n",
      "Epoch 463 / 500 | iteration 0 / 30 | Total Loss: 1.0477428436279297 | KNN Loss: 6.227032661437988 | BCE Loss: 1.0477428436279297\n",
      "Epoch 463 / 500 | iteration 5 / 30 | Total Loss: 1.0577757358551025 | KNN Loss: 6.227174282073975 | BCE Loss: 1.0577757358551025\n",
      "Epoch 463 / 500 | iteration 10 / 30 | Total Loss: 1.037870168685913 | KNN Loss: 6.22663688659668 | BCE Loss: 1.037870168685913\n",
      "Epoch 463 / 500 | iteration 15 / 30 | Total Loss: 1.0693544149398804 | KNN Loss: 6.226924419403076 | BCE Loss: 1.0693544149398804\n",
      "Epoch 463 / 500 | iteration 20 / 30 | Total Loss: 1.040034294128418 | KNN Loss: 6.226922988891602 | BCE Loss: 1.040034294128418\n",
      "Epoch 463 / 500 | iteration 25 / 30 | Total Loss: 1.0544211864471436 | KNN Loss: 6.226836204528809 | BCE Loss: 1.0544211864471436\n",
      "Epoch 464 / 500 | iteration 0 / 30 | Total Loss: 1.060431957244873 | KNN Loss: 6.226855278015137 | BCE Loss: 1.060431957244873\n",
      "Epoch 464 / 500 | iteration 5 / 30 | Total Loss: 1.0398108959197998 | KNN Loss: 6.22693395614624 | BCE Loss: 1.0398108959197998\n",
      "Epoch 464 / 500 | iteration 10 / 30 | Total Loss: 1.0464198589324951 | KNN Loss: 6.227038383483887 | BCE Loss: 1.0464198589324951\n",
      "Epoch 464 / 500 | iteration 15 / 30 | Total Loss: 1.0464320182800293 | KNN Loss: 6.226596355438232 | BCE Loss: 1.0464320182800293\n",
      "Epoch 464 / 500 | iteration 20 / 30 | Total Loss: 1.0529398918151855 | KNN Loss: 6.226988792419434 | BCE Loss: 1.0529398918151855\n",
      "Epoch 464 / 500 | iteration 25 / 30 | Total Loss: 1.0650190114974976 | KNN Loss: 6.226950645446777 | BCE Loss: 1.0650190114974976\n",
      "Epoch 465 / 500 | iteration 0 / 30 | Total Loss: 1.0558571815490723 | KNN Loss: 6.226738929748535 | BCE Loss: 1.0558571815490723\n",
      "Epoch 465 / 500 | iteration 5 / 30 | Total Loss: 1.0309358835220337 | KNN Loss: 6.226904392242432 | BCE Loss: 1.0309358835220337\n",
      "Epoch 465 / 500 | iteration 10 / 30 | Total Loss: 1.0454285144805908 | KNN Loss: 6.2268900871276855 | BCE Loss: 1.0454285144805908\n",
      "Epoch 465 / 500 | iteration 15 / 30 | Total Loss: 1.0556485652923584 | KNN Loss: 6.226772785186768 | BCE Loss: 1.0556485652923584\n",
      "Epoch 465 / 500 | iteration 20 / 30 | Total Loss: 1.0512021780014038 | KNN Loss: 6.227083206176758 | BCE Loss: 1.0512021780014038\n",
      "Epoch 465 / 500 | iteration 25 / 30 | Total Loss: 1.045182228088379 | KNN Loss: 6.226877212524414 | BCE Loss: 1.045182228088379\n",
      "Epoch 466 / 500 | iteration 0 / 30 | Total Loss: 1.0409011840820312 | KNN Loss: 6.227041721343994 | BCE Loss: 1.0409011840820312\n",
      "Epoch 466 / 500 | iteration 5 / 30 | Total Loss: 1.0303282737731934 | KNN Loss: 6.226990699768066 | BCE Loss: 1.0303282737731934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466 / 500 | iteration 10 / 30 | Total Loss: 1.0367319583892822 | KNN Loss: 6.226821422576904 | BCE Loss: 1.0367319583892822\n",
      "Epoch 466 / 500 | iteration 15 / 30 | Total Loss: 1.0570251941680908 | KNN Loss: 6.2269287109375 | BCE Loss: 1.0570251941680908\n",
      "Epoch 466 / 500 | iteration 20 / 30 | Total Loss: 1.0570476055145264 | KNN Loss: 6.227108001708984 | BCE Loss: 1.0570476055145264\n",
      "Epoch 466 / 500 | iteration 25 / 30 | Total Loss: 1.0634664297103882 | KNN Loss: 6.22666072845459 | BCE Loss: 1.0634664297103882\n",
      "Epoch 467 / 500 | iteration 0 / 30 | Total Loss: 1.037036418914795 | KNN Loss: 6.226956844329834 | BCE Loss: 1.037036418914795\n",
      "Epoch 467 / 500 | iteration 5 / 30 | Total Loss: 1.06328547000885 | KNN Loss: 6.227017879486084 | BCE Loss: 1.06328547000885\n",
      "Epoch 467 / 500 | iteration 10 / 30 | Total Loss: 1.060294270515442 | KNN Loss: 6.226694107055664 | BCE Loss: 1.060294270515442\n",
      "Epoch 467 / 500 | iteration 15 / 30 | Total Loss: 1.04581618309021 | KNN Loss: 6.226778984069824 | BCE Loss: 1.04581618309021\n",
      "Epoch 467 / 500 | iteration 20 / 30 | Total Loss: 1.0885887145996094 | KNN Loss: 6.226805210113525 | BCE Loss: 1.0885887145996094\n",
      "Epoch 467 / 500 | iteration 25 / 30 | Total Loss: 1.041872262954712 | KNN Loss: 6.226919651031494 | BCE Loss: 1.041872262954712\n",
      "Epoch 468 / 500 | iteration 0 / 30 | Total Loss: 1.0436955690383911 | KNN Loss: 6.2270331382751465 | BCE Loss: 1.0436955690383911\n",
      "Epoch 468 / 500 | iteration 5 / 30 | Total Loss: 1.0268558263778687 | KNN Loss: 6.226868629455566 | BCE Loss: 1.0268558263778687\n",
      "Epoch 468 / 500 | iteration 10 / 30 | Total Loss: 1.0271632671356201 | KNN Loss: 6.227047920227051 | BCE Loss: 1.0271632671356201\n",
      "Epoch 468 / 500 | iteration 15 / 30 | Total Loss: 1.039576768875122 | KNN Loss: 6.227058410644531 | BCE Loss: 1.039576768875122\n",
      "Epoch 468 / 500 | iteration 20 / 30 | Total Loss: 1.061385154724121 | KNN Loss: 6.227096080780029 | BCE Loss: 1.061385154724121\n",
      "Epoch 468 / 500 | iteration 25 / 30 | Total Loss: 1.05684232711792 | KNN Loss: 6.226504802703857 | BCE Loss: 1.05684232711792\n",
      "Epoch 469 / 500 | iteration 0 / 30 | Total Loss: 1.0612715482711792 | KNN Loss: 6.227150917053223 | BCE Loss: 1.0612715482711792\n",
      "Epoch 469 / 500 | iteration 5 / 30 | Total Loss: 1.07957124710083 | KNN Loss: 6.227065563201904 | BCE Loss: 1.07957124710083\n",
      "Epoch 469 / 500 | iteration 10 / 30 | Total Loss: 1.0974990129470825 | KNN Loss: 6.226980209350586 | BCE Loss: 1.0974990129470825\n",
      "Epoch 469 / 500 | iteration 15 / 30 | Total Loss: 1.0617603063583374 | KNN Loss: 6.227055072784424 | BCE Loss: 1.0617603063583374\n",
      "Epoch 469 / 500 | iteration 20 / 30 | Total Loss: 1.0285611152648926 | KNN Loss: 6.226640224456787 | BCE Loss: 1.0285611152648926\n",
      "Epoch 469 / 500 | iteration 25 / 30 | Total Loss: 1.070568323135376 | KNN Loss: 6.227132320404053 | BCE Loss: 1.070568323135376\n",
      "Epoch 470 / 500 | iteration 0 / 30 | Total Loss: 1.018160343170166 | KNN Loss: 6.226747512817383 | BCE Loss: 1.018160343170166\n",
      "Epoch 470 / 500 | iteration 5 / 30 | Total Loss: 1.0493371486663818 | KNN Loss: 6.2265238761901855 | BCE Loss: 1.0493371486663818\n",
      "Epoch 470 / 500 | iteration 10 / 30 | Total Loss: 1.0173273086547852 | KNN Loss: 6.227041244506836 | BCE Loss: 1.0173273086547852\n",
      "Epoch 470 / 500 | iteration 15 / 30 | Total Loss: 1.0342891216278076 | KNN Loss: 6.226832866668701 | BCE Loss: 1.0342891216278076\n",
      "Epoch 470 / 500 | iteration 20 / 30 | Total Loss: 1.0346063375473022 | KNN Loss: 6.226850509643555 | BCE Loss: 1.0346063375473022\n",
      "Epoch 470 / 500 | iteration 25 / 30 | Total Loss: 1.0239019393920898 | KNN Loss: 6.226653575897217 | BCE Loss: 1.0239019393920898\n",
      "Epoch 471 / 500 | iteration 0 / 30 | Total Loss: 1.0464155673980713 | KNN Loss: 6.226708889007568 | BCE Loss: 1.0464155673980713\n",
      "Epoch 471 / 500 | iteration 5 / 30 | Total Loss: 1.0429954528808594 | KNN Loss: 6.226916790008545 | BCE Loss: 1.0429954528808594\n",
      "Epoch 471 / 500 | iteration 10 / 30 | Total Loss: 1.04221510887146 | KNN Loss: 6.226858615875244 | BCE Loss: 1.04221510887146\n",
      "Epoch 471 / 500 | iteration 15 / 30 | Total Loss: 1.0345673561096191 | KNN Loss: 6.226851463317871 | BCE Loss: 1.0345673561096191\n",
      "Epoch 471 / 500 | iteration 20 / 30 | Total Loss: 1.0730352401733398 | KNN Loss: 6.226629734039307 | BCE Loss: 1.0730352401733398\n",
      "Epoch 471 / 500 | iteration 25 / 30 | Total Loss: 1.0628306865692139 | KNN Loss: 6.227068901062012 | BCE Loss: 1.0628306865692139\n",
      "Epoch 472 / 500 | iteration 0 / 30 | Total Loss: 1.0613772869110107 | KNN Loss: 6.226747035980225 | BCE Loss: 1.0613772869110107\n",
      "Epoch 472 / 500 | iteration 5 / 30 | Total Loss: 1.0660579204559326 | KNN Loss: 6.227021217346191 | BCE Loss: 1.0660579204559326\n",
      "Epoch 472 / 500 | iteration 10 / 30 | Total Loss: 1.051184892654419 | KNN Loss: 6.226932525634766 | BCE Loss: 1.051184892654419\n",
      "Epoch 472 / 500 | iteration 15 / 30 | Total Loss: 1.0264475345611572 | KNN Loss: 6.2266926765441895 | BCE Loss: 1.0264475345611572\n",
      "Epoch 472 / 500 | iteration 20 / 30 | Total Loss: 1.064500093460083 | KNN Loss: 6.226779460906982 | BCE Loss: 1.064500093460083\n",
      "Epoch 472 / 500 | iteration 25 / 30 | Total Loss: 1.0581247806549072 | KNN Loss: 6.226757049560547 | BCE Loss: 1.0581247806549072\n",
      "Epoch 473 / 500 | iteration 0 / 30 | Total Loss: 1.040753960609436 | KNN Loss: 6.227024078369141 | BCE Loss: 1.040753960609436\n",
      "Epoch 473 / 500 | iteration 5 / 30 | Total Loss: 1.0622082948684692 | KNN Loss: 6.226809978485107 | BCE Loss: 1.0622082948684692\n",
      "Epoch 473 / 500 | iteration 10 / 30 | Total Loss: 1.0255143642425537 | KNN Loss: 6.2269158363342285 | BCE Loss: 1.0255143642425537\n",
      "Epoch 473 / 500 | iteration 15 / 30 | Total Loss: 1.0565929412841797 | KNN Loss: 6.227200031280518 | BCE Loss: 1.0565929412841797\n",
      "Epoch 473 / 500 | iteration 20 / 30 | Total Loss: 1.0391879081726074 | KNN Loss: 6.226827144622803 | BCE Loss: 1.0391879081726074\n",
      "Epoch 473 / 500 | iteration 25 / 30 | Total Loss: 1.088092565536499 | KNN Loss: 6.226735591888428 | BCE Loss: 1.088092565536499\n",
      "Epoch 474 / 500 | iteration 0 / 30 | Total Loss: 1.0533031225204468 | KNN Loss: 6.226919174194336 | BCE Loss: 1.0533031225204468\n",
      "Epoch 474 / 500 | iteration 5 / 30 | Total Loss: 1.0360857248306274 | KNN Loss: 6.226861953735352 | BCE Loss: 1.0360857248306274\n",
      "Epoch 474 / 500 | iteration 10 / 30 | Total Loss: 1.058462142944336 | KNN Loss: 6.226803779602051 | BCE Loss: 1.058462142944336\n",
      "Epoch 474 / 500 | iteration 15 / 30 | Total Loss: 1.0526280403137207 | KNN Loss: 6.2270965576171875 | BCE Loss: 1.0526280403137207\n",
      "Epoch 474 / 500 | iteration 20 / 30 | Total Loss: 1.0361733436584473 | KNN Loss: 6.226977825164795 | BCE Loss: 1.0361733436584473\n",
      "Epoch 474 / 500 | iteration 25 / 30 | Total Loss: 1.0430532693862915 | KNN Loss: 6.226873874664307 | BCE Loss: 1.0430532693862915\n",
      "Epoch 475 / 500 | iteration 0 / 30 | Total Loss: 1.0301628112792969 | KNN Loss: 6.226641654968262 | BCE Loss: 1.0301628112792969\n",
      "Epoch 475 / 500 | iteration 5 / 30 | Total Loss: 1.0613768100738525 | KNN Loss: 6.226749897003174 | BCE Loss: 1.0613768100738525\n",
      "Epoch 475 / 500 | iteration 10 / 30 | Total Loss: 1.0690118074417114 | KNN Loss: 6.226814270019531 | BCE Loss: 1.0690118074417114\n",
      "Epoch 475 / 500 | iteration 15 / 30 | Total Loss: 1.0476467609405518 | KNN Loss: 6.226995944976807 | BCE Loss: 1.0476467609405518\n",
      "Epoch 475 / 500 | iteration 20 / 30 | Total Loss: 1.0453299283981323 | KNN Loss: 6.227014541625977 | BCE Loss: 1.0453299283981323\n",
      "Epoch 475 / 500 | iteration 25 / 30 | Total Loss: 1.063204050064087 | KNN Loss: 6.226535320281982 | BCE Loss: 1.063204050064087\n",
      "Epoch 476 / 500 | iteration 0 / 30 | Total Loss: 1.0304421186447144 | KNN Loss: 6.226531505584717 | BCE Loss: 1.0304421186447144\n",
      "Epoch 476 / 500 | iteration 5 / 30 | Total Loss: 1.0583183765411377 | KNN Loss: 6.22705078125 | BCE Loss: 1.0583183765411377\n",
      "Epoch 476 / 500 | iteration 10 / 30 | Total Loss: 1.0681259632110596 | KNN Loss: 6.226752281188965 | BCE Loss: 1.0681259632110596\n",
      "Epoch 476 / 500 | iteration 15 / 30 | Total Loss: 1.033388614654541 | KNN Loss: 6.226469993591309 | BCE Loss: 1.033388614654541\n",
      "Epoch 476 / 500 | iteration 20 / 30 | Total Loss: 1.0437052249908447 | KNN Loss: 6.226653575897217 | BCE Loss: 1.0437052249908447\n",
      "Epoch 476 / 500 | iteration 25 / 30 | Total Loss: 1.0479083061218262 | KNN Loss: 6.226795673370361 | BCE Loss: 1.0479083061218262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477 / 500 | iteration 0 / 30 | Total Loss: 1.0306501388549805 | KNN Loss: 6.22696590423584 | BCE Loss: 1.0306501388549805\n",
      "Epoch 477 / 500 | iteration 5 / 30 | Total Loss: 1.0561633110046387 | KNN Loss: 6.226858615875244 | BCE Loss: 1.0561633110046387\n",
      "Epoch 477 / 500 | iteration 10 / 30 | Total Loss: 1.0134172439575195 | KNN Loss: 6.226982116699219 | BCE Loss: 1.0134172439575195\n",
      "Epoch 477 / 500 | iteration 15 / 30 | Total Loss: 1.048302173614502 | KNN Loss: 6.2264885902404785 | BCE Loss: 1.048302173614502\n",
      "Epoch 477 / 500 | iteration 20 / 30 | Total Loss: 1.075028419494629 | KNN Loss: 6.227017402648926 | BCE Loss: 1.075028419494629\n",
      "Epoch 477 / 500 | iteration 25 / 30 | Total Loss: 1.039601445198059 | KNN Loss: 6.227046012878418 | BCE Loss: 1.039601445198059\n",
      "Epoch 478 / 500 | iteration 0 / 30 | Total Loss: 1.0403178930282593 | KNN Loss: 6.226950168609619 | BCE Loss: 1.0403178930282593\n",
      "Epoch 478 / 500 | iteration 5 / 30 | Total Loss: 1.065673589706421 | KNN Loss: 6.226911544799805 | BCE Loss: 1.065673589706421\n",
      "Epoch 478 / 500 | iteration 10 / 30 | Total Loss: 1.0321378707885742 | KNN Loss: 6.226710796356201 | BCE Loss: 1.0321378707885742\n",
      "Epoch 478 / 500 | iteration 15 / 30 | Total Loss: 1.0629342794418335 | KNN Loss: 6.226655006408691 | BCE Loss: 1.0629342794418335\n",
      "Epoch 478 / 500 | iteration 20 / 30 | Total Loss: 1.072866678237915 | KNN Loss: 6.2269697189331055 | BCE Loss: 1.072866678237915\n",
      "Epoch 478 / 500 | iteration 25 / 30 | Total Loss: 1.0455749034881592 | KNN Loss: 6.226861000061035 | BCE Loss: 1.0455749034881592\n",
      "Epoch 479 / 500 | iteration 0 / 30 | Total Loss: 1.0292859077453613 | KNN Loss: 6.226693153381348 | BCE Loss: 1.0292859077453613\n",
      "Epoch 479 / 500 | iteration 5 / 30 | Total Loss: 1.0253167152404785 | KNN Loss: 6.226821422576904 | BCE Loss: 1.0253167152404785\n",
      "Epoch 479 / 500 | iteration 10 / 30 | Total Loss: 1.078285574913025 | KNN Loss: 6.22702693939209 | BCE Loss: 1.078285574913025\n",
      "Epoch 479 / 500 | iteration 15 / 30 | Total Loss: 1.0478544235229492 | KNN Loss: 6.226850986480713 | BCE Loss: 1.0478544235229492\n",
      "Epoch 479 / 500 | iteration 20 / 30 | Total Loss: 1.0231415033340454 | KNN Loss: 6.227073669433594 | BCE Loss: 1.0231415033340454\n",
      "Epoch 479 / 500 | iteration 25 / 30 | Total Loss: 1.0634262561798096 | KNN Loss: 6.226825714111328 | BCE Loss: 1.0634262561798096\n",
      "Epoch 480 / 500 | iteration 0 / 30 | Total Loss: 1.026003122329712 | KNN Loss: 6.226992607116699 | BCE Loss: 1.026003122329712\n",
      "Epoch 480 / 500 | iteration 5 / 30 | Total Loss: 1.050169587135315 | KNN Loss: 6.227351188659668 | BCE Loss: 1.050169587135315\n",
      "Epoch 480 / 500 | iteration 10 / 30 | Total Loss: 1.0213449001312256 | KNN Loss: 6.2266845703125 | BCE Loss: 1.0213449001312256\n",
      "Epoch 480 / 500 | iteration 15 / 30 | Total Loss: 1.0528907775878906 | KNN Loss: 6.2267231941223145 | BCE Loss: 1.0528907775878906\n",
      "Epoch 480 / 500 | iteration 20 / 30 | Total Loss: 1.0415546894073486 | KNN Loss: 6.226980209350586 | BCE Loss: 1.0415546894073486\n",
      "Epoch 480 / 500 | iteration 25 / 30 | Total Loss: 1.0615267753601074 | KNN Loss: 6.226589202880859 | BCE Loss: 1.0615267753601074\n",
      "Epoch 481 / 500 | iteration 0 / 30 | Total Loss: 1.0410840511322021 | KNN Loss: 6.226836681365967 | BCE Loss: 1.0410840511322021\n",
      "Epoch 481 / 500 | iteration 5 / 30 | Total Loss: 1.0577434301376343 | KNN Loss: 6.226964950561523 | BCE Loss: 1.0577434301376343\n",
      "Epoch 481 / 500 | iteration 10 / 30 | Total Loss: 1.0488736629486084 | KNN Loss: 6.226879119873047 | BCE Loss: 1.0488736629486084\n",
      "Epoch 481 / 500 | iteration 15 / 30 | Total Loss: 1.0553909540176392 | KNN Loss: 6.226948261260986 | BCE Loss: 1.0553909540176392\n",
      "Epoch 481 / 500 | iteration 20 / 30 | Total Loss: 1.0792471170425415 | KNN Loss: 6.226893901824951 | BCE Loss: 1.0792471170425415\n",
      "Epoch 481 / 500 | iteration 25 / 30 | Total Loss: 1.045870304107666 | KNN Loss: 6.2266459465026855 | BCE Loss: 1.045870304107666\n",
      "Epoch 482 / 500 | iteration 0 / 30 | Total Loss: 1.0653965473175049 | KNN Loss: 6.227196216583252 | BCE Loss: 1.0653965473175049\n",
      "Epoch 482 / 500 | iteration 5 / 30 | Total Loss: 1.0429797172546387 | KNN Loss: 6.22693395614624 | BCE Loss: 1.0429797172546387\n",
      "Epoch 482 / 500 | iteration 10 / 30 | Total Loss: 1.0529474020004272 | KNN Loss: 6.226871490478516 | BCE Loss: 1.0529474020004272\n",
      "Epoch 482 / 500 | iteration 15 / 30 | Total Loss: 1.0531535148620605 | KNN Loss: 6.22693395614624 | BCE Loss: 1.0531535148620605\n",
      "Epoch 482 / 500 | iteration 20 / 30 | Total Loss: 1.0484110116958618 | KNN Loss: 6.226771354675293 | BCE Loss: 1.0484110116958618\n",
      "Epoch 482 / 500 | iteration 25 / 30 | Total Loss: 1.0345170497894287 | KNN Loss: 6.226806163787842 | BCE Loss: 1.0345170497894287\n",
      "Epoch 483 / 500 | iteration 0 / 30 | Total Loss: 1.06221604347229 | KNN Loss: 6.226839065551758 | BCE Loss: 1.06221604347229\n",
      "Epoch 483 / 500 | iteration 5 / 30 | Total Loss: 1.0425825119018555 | KNN Loss: 6.22684907913208 | BCE Loss: 1.0425825119018555\n",
      "Epoch 483 / 500 | iteration 10 / 30 | Total Loss: 1.062185525894165 | KNN Loss: 6.226874351501465 | BCE Loss: 1.062185525894165\n",
      "Epoch 483 / 500 | iteration 15 / 30 | Total Loss: 1.062812089920044 | KNN Loss: 6.226852893829346 | BCE Loss: 1.062812089920044\n",
      "Epoch 483 / 500 | iteration 20 / 30 | Total Loss: 1.0383286476135254 | KNN Loss: 6.226864337921143 | BCE Loss: 1.0383286476135254\n",
      "Epoch 483 / 500 | iteration 25 / 30 | Total Loss: 1.0595678091049194 | KNN Loss: 6.226837635040283 | BCE Loss: 1.0595678091049194\n",
      "Epoch 484 / 500 | iteration 0 / 30 | Total Loss: 1.0570712089538574 | KNN Loss: 6.226561546325684 | BCE Loss: 1.0570712089538574\n",
      "Epoch 484 / 500 | iteration 5 / 30 | Total Loss: 1.0693061351776123 | KNN Loss: 6.227022647857666 | BCE Loss: 1.0693061351776123\n",
      "Epoch 484 / 500 | iteration 10 / 30 | Total Loss: 1.053968906402588 | KNN Loss: 6.226892948150635 | BCE Loss: 1.053968906402588\n",
      "Epoch 484 / 500 | iteration 15 / 30 | Total Loss: 1.0492253303527832 | KNN Loss: 6.226917266845703 | BCE Loss: 1.0492253303527832\n",
      "Epoch 484 / 500 | iteration 20 / 30 | Total Loss: 1.0481420755386353 | KNN Loss: 6.227178573608398 | BCE Loss: 1.0481420755386353\n",
      "Epoch 484 / 500 | iteration 25 / 30 | Total Loss: 1.0763858556747437 | KNN Loss: 6.226766109466553 | BCE Loss: 1.0763858556747437\n",
      "Epoch 485 / 500 | iteration 0 / 30 | Total Loss: 1.0402343273162842 | KNN Loss: 6.226802825927734 | BCE Loss: 1.0402343273162842\n",
      "Epoch 485 / 500 | iteration 5 / 30 | Total Loss: 1.0459086894989014 | KNN Loss: 6.227250099182129 | BCE Loss: 1.0459086894989014\n",
      "Epoch 485 / 500 | iteration 10 / 30 | Total Loss: 1.0631349086761475 | KNN Loss: 6.226940155029297 | BCE Loss: 1.0631349086761475\n",
      "Epoch 485 / 500 | iteration 15 / 30 | Total Loss: 1.0609633922576904 | KNN Loss: 6.226919174194336 | BCE Loss: 1.0609633922576904\n",
      "Epoch 485 / 500 | iteration 20 / 30 | Total Loss: 1.048311471939087 | KNN Loss: 6.227209091186523 | BCE Loss: 1.048311471939087\n",
      "Epoch 485 / 500 | iteration 25 / 30 | Total Loss: 1.0386483669281006 | KNN Loss: 6.2267045974731445 | BCE Loss: 1.0386483669281006\n",
      "Epoch 486 / 500 | iteration 0 / 30 | Total Loss: 1.078961968421936 | KNN Loss: 6.226867198944092 | BCE Loss: 1.078961968421936\n",
      "Epoch 486 / 500 | iteration 5 / 30 | Total Loss: 1.028169870376587 | KNN Loss: 6.226644515991211 | BCE Loss: 1.028169870376587\n",
      "Epoch 486 / 500 | iteration 10 / 30 | Total Loss: 1.0560725927352905 | KNN Loss: 6.226775169372559 | BCE Loss: 1.0560725927352905\n",
      "Epoch 486 / 500 | iteration 15 / 30 | Total Loss: 1.068257451057434 | KNN Loss: 6.226949691772461 | BCE Loss: 1.068257451057434\n",
      "Epoch 486 / 500 | iteration 20 / 30 | Total Loss: 1.0588438510894775 | KNN Loss: 6.227105617523193 | BCE Loss: 1.0588438510894775\n",
      "Epoch 486 / 500 | iteration 25 / 30 | Total Loss: 1.055471658706665 | KNN Loss: 6.2268452644348145 | BCE Loss: 1.055471658706665\n",
      "Epoch 487 / 500 | iteration 0 / 30 | Total Loss: 1.0392134189605713 | KNN Loss: 6.227152347564697 | BCE Loss: 1.0392134189605713\n",
      "Epoch 487 / 500 | iteration 5 / 30 | Total Loss: 1.0550445318222046 | KNN Loss: 6.227003574371338 | BCE Loss: 1.0550445318222046\n",
      "Epoch 487 / 500 | iteration 10 / 30 | Total Loss: 1.0472564697265625 | KNN Loss: 6.226916313171387 | BCE Loss: 1.0472564697265625\n",
      "Epoch 487 / 500 | iteration 15 / 30 | Total Loss: 1.0279231071472168 | KNN Loss: 6.227156162261963 | BCE Loss: 1.0279231071472168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487 / 500 | iteration 20 / 30 | Total Loss: 1.0551360845565796 | KNN Loss: 6.226767539978027 | BCE Loss: 1.0551360845565796\n",
      "Epoch 487 / 500 | iteration 25 / 30 | Total Loss: 1.0185307264328003 | KNN Loss: 6.226561546325684 | BCE Loss: 1.0185307264328003\n",
      "Epoch 488 / 500 | iteration 0 / 30 | Total Loss: 1.0295162200927734 | KNN Loss: 6.226572513580322 | BCE Loss: 1.0295162200927734\n",
      "Epoch 488 / 500 | iteration 5 / 30 | Total Loss: 1.0006952285766602 | KNN Loss: 6.226861953735352 | BCE Loss: 1.0006952285766602\n",
      "Epoch 488 / 500 | iteration 10 / 30 | Total Loss: 1.0619583129882812 | KNN Loss: 6.226715564727783 | BCE Loss: 1.0619583129882812\n",
      "Epoch 488 / 500 | iteration 15 / 30 | Total Loss: 1.0766658782958984 | KNN Loss: 6.226724147796631 | BCE Loss: 1.0766658782958984\n",
      "Epoch 488 / 500 | iteration 20 / 30 | Total Loss: 1.0658035278320312 | KNN Loss: 6.226887226104736 | BCE Loss: 1.0658035278320312\n",
      "Epoch 488 / 500 | iteration 25 / 30 | Total Loss: 1.0724034309387207 | KNN Loss: 6.226710319519043 | BCE Loss: 1.0724034309387207\n",
      "Epoch 489 / 500 | iteration 0 / 30 | Total Loss: 1.0655622482299805 | KNN Loss: 6.226714611053467 | BCE Loss: 1.0655622482299805\n",
      "Epoch 489 / 500 | iteration 5 / 30 | Total Loss: 1.0552234649658203 | KNN Loss: 6.22682523727417 | BCE Loss: 1.0552234649658203\n",
      "Epoch 489 / 500 | iteration 10 / 30 | Total Loss: 1.044466257095337 | KNN Loss: 6.226855278015137 | BCE Loss: 1.044466257095337\n",
      "Epoch 489 / 500 | iteration 15 / 30 | Total Loss: 1.0609902143478394 | KNN Loss: 6.226580619812012 | BCE Loss: 1.0609902143478394\n",
      "Epoch 489 / 500 | iteration 20 / 30 | Total Loss: 1.0495631694793701 | KNN Loss: 6.227049350738525 | BCE Loss: 1.0495631694793701\n",
      "Epoch 489 / 500 | iteration 25 / 30 | Total Loss: 1.0370475053787231 | KNN Loss: 6.227147579193115 | BCE Loss: 1.0370475053787231\n",
      "Epoch 490 / 500 | iteration 0 / 30 | Total Loss: 1.045438528060913 | KNN Loss: 6.226946830749512 | BCE Loss: 1.045438528060913\n",
      "Epoch 490 / 500 | iteration 5 / 30 | Total Loss: 1.0458295345306396 | KNN Loss: 6.226647853851318 | BCE Loss: 1.0458295345306396\n",
      "Epoch 490 / 500 | iteration 10 / 30 | Total Loss: 1.0337401628494263 | KNN Loss: 6.227166652679443 | BCE Loss: 1.0337401628494263\n",
      "Epoch 490 / 500 | iteration 15 / 30 | Total Loss: 1.0505247116088867 | KNN Loss: 6.226704120635986 | BCE Loss: 1.0505247116088867\n",
      "Epoch 490 / 500 | iteration 20 / 30 | Total Loss: 1.0281345844268799 | KNN Loss: 6.226711750030518 | BCE Loss: 1.0281345844268799\n",
      "Epoch 490 / 500 | iteration 25 / 30 | Total Loss: 1.0309799909591675 | KNN Loss: 6.226898670196533 | BCE Loss: 1.0309799909591675\n",
      "Epoch 491 / 500 | iteration 0 / 30 | Total Loss: 1.0466125011444092 | KNN Loss: 6.227099418640137 | BCE Loss: 1.0466125011444092\n",
      "Epoch 491 / 500 | iteration 5 / 30 | Total Loss: 1.0435631275177002 | KNN Loss: 6.226858615875244 | BCE Loss: 1.0435631275177002\n",
      "Epoch 491 / 500 | iteration 10 / 30 | Total Loss: 1.0448179244995117 | KNN Loss: 6.226961135864258 | BCE Loss: 1.0448179244995117\n",
      "Epoch 491 / 500 | iteration 15 / 30 | Total Loss: 1.059721827507019 | KNN Loss: 6.2270026206970215 | BCE Loss: 1.059721827507019\n",
      "Epoch 491 / 500 | iteration 20 / 30 | Total Loss: 1.0702996253967285 | KNN Loss: 6.226770877838135 | BCE Loss: 1.0702996253967285\n",
      "Epoch 491 / 500 | iteration 25 / 30 | Total Loss: 1.0657718181610107 | KNN Loss: 6.226710796356201 | BCE Loss: 1.0657718181610107\n",
      "Epoch 492 / 500 | iteration 0 / 30 | Total Loss: 1.0437242984771729 | KNN Loss: 6.2267656326293945 | BCE Loss: 1.0437242984771729\n",
      "Epoch 492 / 500 | iteration 5 / 30 | Total Loss: 1.0380194187164307 | KNN Loss: 6.2269086837768555 | BCE Loss: 1.0380194187164307\n",
      "Epoch 492 / 500 | iteration 10 / 30 | Total Loss: 1.0258853435516357 | KNN Loss: 6.226831436157227 | BCE Loss: 1.0258853435516357\n",
      "Epoch 492 / 500 | iteration 15 / 30 | Total Loss: 1.0615381002426147 | KNN Loss: 6.22678279876709 | BCE Loss: 1.0615381002426147\n",
      "Epoch 492 / 500 | iteration 20 / 30 | Total Loss: 1.0674363374710083 | KNN Loss: 6.226938247680664 | BCE Loss: 1.0674363374710083\n",
      "Epoch 492 / 500 | iteration 25 / 30 | Total Loss: 1.0628130435943604 | KNN Loss: 6.227062225341797 | BCE Loss: 1.0628130435943604\n",
      "Epoch 493 / 500 | iteration 0 / 30 | Total Loss: 1.0505492687225342 | KNN Loss: 6.226747035980225 | BCE Loss: 1.0505492687225342\n",
      "Epoch 493 / 500 | iteration 5 / 30 | Total Loss: 1.061861276626587 | KNN Loss: 6.226733207702637 | BCE Loss: 1.061861276626587\n",
      "Epoch 493 / 500 | iteration 10 / 30 | Total Loss: 1.0632424354553223 | KNN Loss: 6.226611137390137 | BCE Loss: 1.0632424354553223\n",
      "Epoch 493 / 500 | iteration 15 / 30 | Total Loss: 1.061151146888733 | KNN Loss: 6.226996421813965 | BCE Loss: 1.061151146888733\n",
      "Epoch 493 / 500 | iteration 20 / 30 | Total Loss: 1.0386306047439575 | KNN Loss: 6.227052211761475 | BCE Loss: 1.0386306047439575\n",
      "Epoch 493 / 500 | iteration 25 / 30 | Total Loss: 1.0572824478149414 | KNN Loss: 6.226582050323486 | BCE Loss: 1.0572824478149414\n",
      "Epoch 494 / 500 | iteration 0 / 30 | Total Loss: 1.0423083305358887 | KNN Loss: 6.226747035980225 | BCE Loss: 1.0423083305358887\n",
      "Epoch 494 / 500 | iteration 5 / 30 | Total Loss: 1.0230603218078613 | KNN Loss: 6.226882457733154 | BCE Loss: 1.0230603218078613\n",
      "Epoch 494 / 500 | iteration 10 / 30 | Total Loss: 1.044266700744629 | KNN Loss: 6.226961612701416 | BCE Loss: 1.044266700744629\n",
      "Epoch 494 / 500 | iteration 15 / 30 | Total Loss: 1.0203566551208496 | KNN Loss: 6.226861953735352 | BCE Loss: 1.0203566551208496\n",
      "Epoch 494 / 500 | iteration 20 / 30 | Total Loss: 1.0471047163009644 | KNN Loss: 6.2267560958862305 | BCE Loss: 1.0471047163009644\n",
      "Epoch 494 / 500 | iteration 25 / 30 | Total Loss: 1.047203540802002 | KNN Loss: 6.22637939453125 | BCE Loss: 1.047203540802002\n",
      "Epoch 495 / 500 | iteration 0 / 30 | Total Loss: 1.0623443126678467 | KNN Loss: 6.226716995239258 | BCE Loss: 1.0623443126678467\n",
      "Epoch 495 / 500 | iteration 5 / 30 | Total Loss: 1.03436279296875 | KNN Loss: 6.227193832397461 | BCE Loss: 1.03436279296875\n",
      "Epoch 495 / 500 | iteration 10 / 30 | Total Loss: 1.0326389074325562 | KNN Loss: 6.226802349090576 | BCE Loss: 1.0326389074325562\n",
      "Epoch 495 / 500 | iteration 15 / 30 | Total Loss: 1.041151523590088 | KNN Loss: 6.226901531219482 | BCE Loss: 1.041151523590088\n",
      "Epoch 495 / 500 | iteration 20 / 30 | Total Loss: 1.05769944190979 | KNN Loss: 6.226612091064453 | BCE Loss: 1.05769944190979\n",
      "Epoch 495 / 500 | iteration 25 / 30 | Total Loss: 1.031264305114746 | KNN Loss: 6.226785659790039 | BCE Loss: 1.031264305114746\n",
      "Epoch 496 / 500 | iteration 0 / 30 | Total Loss: 1.04335355758667 | KNN Loss: 6.226822376251221 | BCE Loss: 1.04335355758667\n",
      "Epoch 496 / 500 | iteration 5 / 30 | Total Loss: 1.0537807941436768 | KNN Loss: 6.22662353515625 | BCE Loss: 1.0537807941436768\n",
      "Epoch 496 / 500 | iteration 10 / 30 | Total Loss: 1.0445903539657593 | KNN Loss: 6.22686767578125 | BCE Loss: 1.0445903539657593\n",
      "Epoch 496 / 500 | iteration 15 / 30 | Total Loss: 1.0698962211608887 | KNN Loss: 6.226667404174805 | BCE Loss: 1.0698962211608887\n",
      "Epoch 496 / 500 | iteration 20 / 30 | Total Loss: 1.0605417490005493 | KNN Loss: 6.227065086364746 | BCE Loss: 1.0605417490005493\n",
      "Epoch 496 / 500 | iteration 25 / 30 | Total Loss: 1.0416088104248047 | KNN Loss: 6.226606845855713 | BCE Loss: 1.0416088104248047\n",
      "Epoch 497 / 500 | iteration 0 / 30 | Total Loss: 1.0238709449768066 | KNN Loss: 6.226682186126709 | BCE Loss: 1.0238709449768066\n",
      "Epoch 497 / 500 | iteration 5 / 30 | Total Loss: 1.0225352048873901 | KNN Loss: 6.227168560028076 | BCE Loss: 1.0225352048873901\n",
      "Epoch 497 / 500 | iteration 10 / 30 | Total Loss: 1.0594532489776611 | KNN Loss: 6.2266106605529785 | BCE Loss: 1.0594532489776611\n",
      "Epoch 497 / 500 | iteration 15 / 30 | Total Loss: 1.0359488725662231 | KNN Loss: 6.226646900177002 | BCE Loss: 1.0359488725662231\n",
      "Epoch 497 / 500 | iteration 20 / 30 | Total Loss: 1.0772554874420166 | KNN Loss: 6.226763725280762 | BCE Loss: 1.0772554874420166\n",
      "Epoch 497 / 500 | iteration 25 / 30 | Total Loss: 1.0480536222457886 | KNN Loss: 6.22709321975708 | BCE Loss: 1.0480536222457886\n",
      "Epoch 498 / 500 | iteration 0 / 30 | Total Loss: 1.0456948280334473 | KNN Loss: 6.226931571960449 | BCE Loss: 1.0456948280334473\n",
      "Epoch 498 / 500 | iteration 5 / 30 | Total Loss: 1.0609097480773926 | KNN Loss: 6.226589679718018 | BCE Loss: 1.0609097480773926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498 / 500 | iteration 10 / 30 | Total Loss: 1.0423955917358398 | KNN Loss: 6.226851463317871 | BCE Loss: 1.0423955917358398\n",
      "Epoch 498 / 500 | iteration 15 / 30 | Total Loss: 1.053356647491455 | KNN Loss: 6.227038860321045 | BCE Loss: 1.053356647491455\n",
      "Epoch 498 / 500 | iteration 20 / 30 | Total Loss: 1.0328301191329956 | KNN Loss: 6.2270331382751465 | BCE Loss: 1.0328301191329956\n",
      "Epoch 498 / 500 | iteration 25 / 30 | Total Loss: 1.0257878303527832 | KNN Loss: 6.226958274841309 | BCE Loss: 1.0257878303527832\n",
      "Epoch 499 / 500 | iteration 0 / 30 | Total Loss: 1.0898840427398682 | KNN Loss: 6.227123737335205 | BCE Loss: 1.0898840427398682\n",
      "Epoch 499 / 500 | iteration 5 / 30 | Total Loss: 1.0536696910858154 | KNN Loss: 6.226707935333252 | BCE Loss: 1.0536696910858154\n",
      "Epoch 499 / 500 | iteration 10 / 30 | Total Loss: 1.0438902378082275 | KNN Loss: 6.226748466491699 | BCE Loss: 1.0438902378082275\n",
      "Epoch 499 / 500 | iteration 15 / 30 | Total Loss: 1.0359838008880615 | KNN Loss: 6.226790904998779 | BCE Loss: 1.0359838008880615\n",
      "Epoch 499 / 500 | iteration 20 / 30 | Total Loss: 1.0515503883361816 | KNN Loss: 6.226998329162598 | BCE Loss: 1.0515503883361816\n",
      "Epoch 499 / 500 | iteration 25 / 30 | Total Loss: 1.0351202487945557 | KNN Loss: 6.226759910583496 | BCE Loss: 1.0351202487945557\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "data_iter = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=1,\n",
    "                                     pin_memory=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', verbose=True, factor=0.7, threshold=1e-4)\n",
    "knn_crt = KNNLoss(k=k).to(device)\n",
    "losses = []\n",
    "alpha = 10/170\n",
    "gamma = 2\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(data_iter):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, iterm = model(batch, return_intermidiate=True)\n",
    "        mse_loss = F.binary_cross_entropy_with_logits(outputs, target, reduction='none')\n",
    "        mask = torch.ones_like(mse_loss)\n",
    "        mask[target == 0] = alpha ** gamma\n",
    "        mask[target == 1] = (1 - alpha) ** gamma\n",
    "        mse_loss = (mse_loss * mask).sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(iterm)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = 0\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0)\n",
    "        loss = mse_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(data_iter)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | BCE Loss: {mse_loss.item()}\")\n",
    "    \n",
    "    scheduler.step(total_loss / (iteration + 1))\n",
    "    losses.append(total_loss / (iteration + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9260,  3.8751,  2.5815,  3.5753,  3.4575,  0.7073,  2.6673,  2.1985,\n",
      "          2.3084,  1.9959,  2.2377,  2.2015,  0.7877,  1.8225,  1.2886,  1.5240,\n",
      "          2.8093,  3.1821,  2.8012,  2.3064,  1.7457,  2.9548,  2.2895,  2.6397,\n",
      "          2.5373,  1.7417,  2.1251,  1.4121,  1.4929,  0.3215, -0.2411,  0.9961,\n",
      "          0.2093,  0.9268,  1.5295,  1.4739,  1.0045,  3.3175,  0.8013,  1.3213,\n",
      "          0.9638, -0.7019, -0.2381,  2.3380,  2.1909,  0.7373, -0.1839,  0.0959,\n",
      "          1.4636,  2.4984,  1.8227,  0.1449,  1.4272,  0.5246, -0.6349,  1.1086,\n",
      "          1.4808,  1.3742,  1.3425,  1.8266,  0.5733,  0.8346,  0.1406,  1.7248,\n",
      "          1.3218,  1.6694, -1.8264,  0.3082,  2.2918,  2.1461,  2.5514,  0.4280,\n",
      "          1.3545,  2.4628,  2.0004,  1.2954,  0.2204,  0.7366,  0.2152,  1.5899,\n",
      "          0.0288,  0.3820,  1.8390, -0.3779,  0.2434, -1.0678, -2.2868, -0.2612,\n",
      "          0.5480, -1.8348,  0.4684, -0.1306, -0.5724, -0.9397,  0.5634,  1.2697,\n",
      "         -0.6998, -0.6983,  0.3481,  1.1347,  0.6897, -1.2408,  0.9009,  1.1226,\n",
      "         -1.2339, -1.1159, -0.1503,  0.0277, -1.0267, -1.6709, -0.4273, -2.5523,\n",
      "         -0.3717,  1.7579,  1.5812, -0.2772, -0.6076,  0.0323,  1.5413, -2.3792,\n",
      "          0.1588, -0.1938,  0.4598, -0.7072,  0.0158, -0.7719, -0.9841,  0.9548,\n",
      "          0.2529, -0.5740,  0.3465, -0.6699, -1.3005, -0.3272, -0.5150,  0.8484,\n",
      "         -0.4541,  0.1274, -1.9463, -0.9753, -1.3437,  0.6048, -1.8368, -0.9777,\n",
      "         -1.0231, -0.6039, -1.5738, -1.0770, -2.3254, -0.9716, -1.3073, -0.3558,\n",
      "         -1.7343,  0.4582, -1.4955, -0.5408, -2.9806,  0.1689, -0.1704, -0.7628,\n",
      "         -2.1880, -1.6526, -1.2269, -1.3633, -2.2822, -2.2605, -2.9190]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor(-2.9806, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(3.8751, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "outputs, iterm = model(dataset[67][0].unsqueeze(0).to(device), return_intermidiate=True)\n",
    "print(outputs)\n",
    "print(outputs.min())\n",
    "print(outputs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a4dc1d911a48d9920b738843069ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform = torchvision.transforms.Compose([\n",
    "    BinaryEncodingTransform(mapping=dataset.items_to_idx),\n",
    "]\n",
    ")\n",
    "dataset.target_transform = torchvision.transforms.Compose([\n",
    "    BinaryEncodingTransform(mapping=dataset.items_to_idx),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = [d[0].cpu() for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [00:00<00:00, 78.51it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.eval().cpu()\n",
    "projections = model.calculate_intermidiate(dataset_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3871bebb3b4b4e4181edef67df66db93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fe97c76c594feea18e39ae6cf7dbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit DBSCAN and calculate indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=0.01, min_samples=80).fit_predict(projections)\n",
    "# scores = []\n",
    "# best_score = float('inf')\n",
    "# clusters = None\n",
    "# range_ = list(range(5, 20))\n",
    "# for k in tqdm(range_):\n",
    "#     y = GaussianMixture(n_components=k).fit_predict(projections)\n",
    "#     cur_score = davies_bouldin_score(projections, y)\n",
    "#     scores.append(cur_score)\n",
    "    \n",
    "#     if cur_score < best_score:\n",
    "#         best_score = cur_score\n",
    "#         clusters = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e076c485474f4f9f99cdcf9c98700582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn import tree\n",
    "# from sklearn.tree import _tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dataset = torch.stack(dataset_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = DecisionTreeClassifier(max_depth=200, min_samples_leaf=5)\n",
    "# clf = clf.fit(tensor_dataset[clusters!=-1], clusters[clusters != -1])\n",
    "# print(clf.score(tensor_dataset[clusters!=-1], clusters[clusters != -1]))\n",
    "# print(clf.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# for min_samples in range(1,50, 1):\n",
    "#     clf = DecisionTreeClassifier(max_depth=200, min_samples_leaf=min_samples)\n",
    "#     clf = clf.fit(tensor_dataset[clusters!=-1], clusters[clusters != -1])\n",
    "#     scores.append(clf.score(tensor_dataset[clusters!=-1], clusters[clusters != -1]))\n",
    "    \n",
    "# plt.figure()\n",
    "# plt.plot(list(range(1,50, 1)), scores)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rules(tree, feature_names, class_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "\n",
    "    paths = []\n",
    "    path = []\n",
    "    \n",
    "    def recurse(node, path, paths):\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            p1, p2 = list(path), list(path)\n",
    "#             p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
    "            p1 += [(name, '<=', np.round(threshold, 3))]\n",
    "            recurse(tree_.children_left[node], p1, paths)\n",
    "            p2 += [(name, '>', np.round(threshold, 3))]\n",
    "            recurse(tree_.children_right[node], p2, paths)\n",
    "        else:\n",
    "            path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
    "            paths += [path]\n",
    "            \n",
    "    recurse(0, path, paths)\n",
    "\n",
    "    # sort by samples count\n",
    "    samples_count = [p[-1][1] for p in paths]\n",
    "    ii = list(np.argsort(samples_count))\n",
    "    paths = [paths[i] for i in reversed(ii)]\n",
    "    \n",
    "    rules = []\n",
    "    for path in paths:\n",
    "        rule = []\n",
    "        \n",
    "        for p in path[:-1]:\n",
    "            rule += [p]\n",
    "        target = \" then \"\n",
    "        if class_names is None:\n",
    "            target += \"response: \"+str(np.round(path[-1][0][0][0],3))\n",
    "        else:\n",
    "            classes = path[-1][0][0]\n",
    "            l = np.argmax(classes)\n",
    "            target += f\"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)\"\n",
    "           \n",
    "        proba = np.round(100.0*classes[l]/np.sum(classes),2)\n",
    "        target += f\" | based on {path[-1][1]:,} samples\"\n",
    "        rule_wrapper = {'target': target, 'rule': rule, 'proba': proba}\n",
    "        rules += [rule_wrapper]\n",
    "        \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules = get_rules(clf, dataset.items, clusters[clusters != -1])\n",
    "\n",
    "# for rule in rules:\n",
    "#     n_pos = 0\n",
    "#     for c,p,v in rule['rule']:\n",
    "#         if p == '>':\n",
    "#             n_pos += 1\n",
    "#     rule['pos'] = n_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# probs = [r['proba'] for r in rules]\n",
    "# plt.hist(probs, bins = 100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules = sorted(rules, key=lambda x:x['pos'])\n",
    "# rules = [r for r in rules if r['proba'] > 50]\n",
    "# print(len(rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(17):\n",
    "#     r_i = rules[i]\n",
    "#     print(f\"------------- rule {i} length {len(r_i)} -------------\")\n",
    "#     print(r_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(tensor_dataset[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 100\n",
    "output_dim = len(set(clusters))\n",
    "log_interval = 1\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=tensor_dataset.shape[1], output_dim=len(clusters - 1), depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "Epoch: 00 | Batch: 000 / 030 | Total loss: 9.569 | Reg loss: 0.009 | Tree loss: 9.569 | Accuracy: 0.000000 | 0.307 sec/iter\n",
      "Epoch: 00 | Batch: 001 / 030 | Total loss: 9.549 | Reg loss: 0.009 | Tree loss: 9.549 | Accuracy: 0.000000 | 0.278 sec/iter\n",
      "Epoch: 00 | Batch: 002 / 030 | Total loss: 9.530 | Reg loss: 0.009 | Tree loss: 9.530 | Accuracy: 0.000000 | 0.263 sec/iter\n",
      "Epoch: 00 | Batch: 003 / 030 | Total loss: 9.511 | Reg loss: 0.008 | Tree loss: 9.511 | Accuracy: 0.000000 | 0.255 sec/iter\n",
      "Epoch: 00 | Batch: 004 / 030 | Total loss: 9.492 | Reg loss: 0.008 | Tree loss: 9.492 | Accuracy: 0.000000 | 0.251 sec/iter\n",
      "Epoch: 00 | Batch: 005 / 030 | Total loss: 9.472 | Reg loss: 0.008 | Tree loss: 9.472 | Accuracy: 0.000000 | 0.248 sec/iter\n",
      "Epoch: 00 | Batch: 006 / 030 | Total loss: 9.450 | Reg loss: 0.008 | Tree loss: 9.450 | Accuracy: 0.021484 | 0.249 sec/iter\n",
      "Epoch: 00 | Batch: 007 / 030 | Total loss: 9.432 | Reg loss: 0.008 | Tree loss: 9.432 | Accuracy: 0.019531 | 0.248 sec/iter\n",
      "Epoch: 00 | Batch: 008 / 030 | Total loss: 9.414 | Reg loss: 0.008 | Tree loss: 9.414 | Accuracy: 0.066406 | 0.245 sec/iter\n",
      "Epoch: 00 | Batch: 009 / 030 | Total loss: 9.398 | Reg loss: 0.009 | Tree loss: 9.398 | Accuracy: 0.119141 | 0.243 sec/iter\n",
      "Epoch: 00 | Batch: 010 / 030 | Total loss: 9.377 | Reg loss: 0.009 | Tree loss: 9.377 | Accuracy: 0.220703 | 0.241 sec/iter\n",
      "Epoch: 00 | Batch: 011 / 030 | Total loss: 9.359 | Reg loss: 0.009 | Tree loss: 9.359 | Accuracy: 0.296875 | 0.24 sec/iter\n",
      "Epoch: 00 | Batch: 012 / 030 | Total loss: 9.341 | Reg loss: 0.009 | Tree loss: 9.341 | Accuracy: 0.650391 | 0.239 sec/iter\n",
      "Epoch: 00 | Batch: 013 / 030 | Total loss: 9.318 | Reg loss: 0.010 | Tree loss: 9.318 | Accuracy: 0.898438 | 0.239 sec/iter\n",
      "Epoch: 00 | Batch: 014 / 030 | Total loss: 9.302 | Reg loss: 0.010 | Tree loss: 9.302 | Accuracy: 0.960938 | 0.238 sec/iter\n",
      "Epoch: 00 | Batch: 015 / 030 | Total loss: 9.282 | Reg loss: 0.011 | Tree loss: 9.282 | Accuracy: 0.984375 | 0.237 sec/iter\n",
      "Epoch: 00 | Batch: 016 / 030 | Total loss: 9.272 | Reg loss: 0.011 | Tree loss: 9.272 | Accuracy: 0.996094 | 0.236 sec/iter\n",
      "Epoch: 00 | Batch: 017 / 030 | Total loss: 9.250 | Reg loss: 0.011 | Tree loss: 9.250 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 00 | Batch: 018 / 030 | Total loss: 9.225 | Reg loss: 0.012 | Tree loss: 9.225 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 00 | Batch: 019 / 030 | Total loss: 9.214 | Reg loss: 0.012 | Tree loss: 9.214 | Accuracy: 1.000000 | 0.236 sec/iter\n",
      "Epoch: 00 | Batch: 020 / 030 | Total loss: 9.193 | Reg loss: 0.013 | Tree loss: 9.193 | Accuracy: 1.000000 | 0.236 sec/iter\n",
      "Epoch: 00 | Batch: 021 / 030 | Total loss: 9.173 | Reg loss: 0.013 | Tree loss: 9.173 | Accuracy: 1.000000 | 0.235 sec/iter\n",
      "Epoch: 00 | Batch: 022 / 030 | Total loss: 9.159 | Reg loss: 0.013 | Tree loss: 9.159 | Accuracy: 1.000000 | 0.235 sec/iter\n",
      "Epoch: 00 | Batch: 023 / 030 | Total loss: 9.145 | Reg loss: 0.014 | Tree loss: 9.145 | Accuracy: 1.000000 | 0.234 sec/iter\n",
      "Epoch: 00 | Batch: 024 / 030 | Total loss: 9.116 | Reg loss: 0.014 | Tree loss: 9.116 | Accuracy: 1.000000 | 0.234 sec/iter\n",
      "Epoch: 00 | Batch: 025 / 030 | Total loss: 9.104 | Reg loss: 0.015 | Tree loss: 9.104 | Accuracy: 1.000000 | 0.233 sec/iter\n",
      "Epoch: 00 | Batch: 026 / 030 | Total loss: 9.087 | Reg loss: 0.015 | Tree loss: 9.087 | Accuracy: 1.000000 | 0.233 sec/iter\n",
      "Epoch: 00 | Batch: 027 / 030 | Total loss: 9.066 | Reg loss: 0.016 | Tree loss: 9.066 | Accuracy: 1.000000 | 0.233 sec/iter\n",
      "Epoch: 00 | Batch: 028 / 030 | Total loss: 9.042 | Reg loss: 0.016 | Tree loss: 9.042 | Accuracy: 1.000000 | 0.233 sec/iter\n",
      "Epoch: 00 | Batch: 029 / 030 | Total loss: 9.038 | Reg loss: 0.016 | Tree loss: 9.038 | Accuracy: 1.000000 | 0.233 sec/iter\n",
      "Average sparseness: 0.9821428571428573\n",
      "layer 0: 0.9821428571428571\n",
      "layer 1: 0.9821428571428571\n",
      "layer 2: 0.9821428571428571\n",
      "layer 3: 0.9821428571428571\n",
      "layer 4: 0.9821428571428571\n",
      "layer 5: 0.9821428571428571\n",
      "layer 6: 0.982142857142857\n",
      "Epoch: 01 | Batch: 000 / 030 | Total loss: 9.357 | Reg loss: 0.005 | Tree loss: 9.357 | Accuracy: 0.867188 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 001 / 030 | Total loss: 9.341 | Reg loss: 0.005 | Tree loss: 9.341 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 002 / 030 | Total loss: 9.323 | Reg loss: 0.006 | Tree loss: 9.323 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 003 / 030 | Total loss: 9.308 | Reg loss: 0.006 | Tree loss: 9.308 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 004 / 030 | Total loss: 9.287 | Reg loss: 0.006 | Tree loss: 9.287 | Accuracy: 1.000000 | 0.236 sec/iter\n",
      "Epoch: 01 | Batch: 005 / 030 | Total loss: 9.266 | Reg loss: 0.006 | Tree loss: 9.266 | Accuracy: 1.000000 | 0.236 sec/iter\n",
      "Epoch: 01 | Batch: 006 / 030 | Total loss: 9.251 | Reg loss: 0.007 | Tree loss: 9.251 | Accuracy: 1.000000 | 0.236 sec/iter\n",
      "Epoch: 01 | Batch: 007 / 030 | Total loss: 9.228 | Reg loss: 0.007 | Tree loss: 9.228 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 008 / 030 | Total loss: 9.216 | Reg loss: 0.008 | Tree loss: 9.216 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 009 / 030 | Total loss: 9.192 | Reg loss: 0.008 | Tree loss: 9.192 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 010 / 030 | Total loss: 9.178 | Reg loss: 0.009 | Tree loss: 9.178 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 011 / 030 | Total loss: 9.154 | Reg loss: 0.009 | Tree loss: 9.154 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 012 / 030 | Total loss: 9.132 | Reg loss: 0.010 | Tree loss: 9.132 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 013 / 030 | Total loss: 9.116 | Reg loss: 0.010 | Tree loss: 9.116 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 014 / 030 | Total loss: 9.099 | Reg loss: 0.011 | Tree loss: 9.099 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 015 / 030 | Total loss: 9.073 | Reg loss: 0.011 | Tree loss: 9.073 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 016 / 030 | Total loss: 9.061 | Reg loss: 0.012 | Tree loss: 9.061 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 017 / 030 | Total loss: 9.042 | Reg loss: 0.012 | Tree loss: 9.042 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 018 / 030 | Total loss: 9.019 | Reg loss: 0.013 | Tree loss: 9.019 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 019 / 030 | Total loss: 8.998 | Reg loss: 0.013 | Tree loss: 8.998 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 020 / 030 | Total loss: 8.983 | Reg loss: 0.014 | Tree loss: 8.983 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 021 / 030 | Total loss: 8.969 | Reg loss: 0.014 | Tree loss: 8.969 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 022 / 030 | Total loss: 8.950 | Reg loss: 0.015 | Tree loss: 8.950 | Accuracy: 1.000000 | 0.237 sec/iter\n",
      "Epoch: 01 | Batch: 023 / 030 | Total loss: 8.931 | Reg loss: 0.016 | Tree loss: 8.931 | Accuracy: 1.000000 | 0.238 sec/iter\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-6d26925b67e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mavg_sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_sparseness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msparsity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_sp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-1942e5355f01>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, loader, device, log_interval, losses, accs, epoch, iteration)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mregularization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparsity_lamda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcompute_regularization_by_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-54afb0c8b2e2>\u001b[0m in \u001b[0;36mcompute_regularization_by_level\u001b[0;34m(tree)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcur_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mnode_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtotal_reg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcur_level\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnode_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = dataset.items\n",
    "\n",
    "# print(attr_names)\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    for cond in conds:\n",
    "        cond.weights = cond.weights / normalizers\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
