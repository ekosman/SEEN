{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.nn as nn\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from stream_generators.mit_bih import MITBIH\n",
    "from utils.MatplotlibUtils import reduce_dims_and_plot\n",
    "from network.auto_encoder import AutoEncoder\n",
    "from losses.knn_loss import KNNLoss, ClassificationKNNLoss\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from soft_decision_tree.sdt_model import SDT\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "tree_depth = 8\n",
    "batch_size = 512\n",
    "device = 'cuda'\n",
    "train_data_path = r'/mnt/qnap/ekosman/mitbih_train.csv'\n",
    "test_data_path = r'/mnt/qnap/ekosman/mitbih_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = torch.utils.data.DataLoader(MITBIH(train_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True,\n",
    "                                             drop_last=True)\n",
    "\n",
    "test_data_iter = torch.utils.data.DataLoader(MITBIH(test_data_path),\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=1,\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.conv1(y)\n",
    "        y = self.relu1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = y + x\n",
    "        y = self.relu2(y)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGModel, self).__init__()\n",
    "        self.conv = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=1)\n",
    "        self.block1 = ConvBlock()\n",
    "        self.block2 = ConvBlock()\n",
    "        self.block3 = ConvBlock()\n",
    "        self.block4 = ConvBlock()\n",
    "        self.block5 = ConvBlock()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 5)\n",
    "\n",
    "    def forward(self, x, return_interm=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        interm = x.flatten(1)\n",
    "        x = self.fc1(interm)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if return_interm:\n",
    "            return x, interm\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_crt = ClassificationKNNLoss(k=k).to(device)\n",
    "\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs, interm = model(batch, return_interm=True)\n",
    "        mse_loss = F.cross_entropy(outputs, target)\n",
    "        mse_loss = mse_loss.sum(dim=-1).mean()\n",
    "        try:\n",
    "            knn_loss = knn_crt(interm, target)\n",
    "            if torch.isinf(knn_loss):\n",
    "                knn_loss = torch.tensor(0).to(device)\n",
    "        except ValueError:\n",
    "            knn_loss = torch.tensor(0).to(device)\n",
    "        loss = mse_loss + knn_loss\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % log_every == 0:\n",
    "            print(f\"Epoch {epoch} / {epochs} | iteration {iteration} / {len(loader)} | Total Loss: {loss.item()} | KNN Loss: {knn_loss.item()} | CLS Loss: {mse_loss.item()}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for iteration, (batch, target) in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "        y_pred = model(batch).argmax(dim=-1)\n",
    "        correct += y_pred.eq(target.view(-1).data).sum()\n",
    "    \n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 53957\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "log_every = 10\n",
    "\n",
    "model = ECGModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'#Params: {num_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 200 | iteration 0 / 171 | Total Loss: 7.258726119995117 | KNN Loss: 5.58424711227417 | CLS Loss: 1.6744791269302368\n",
      "Epoch 1 / 200 | iteration 10 / 171 | Total Loss: 4.858896255493164 | KNN Loss: 4.17528772354126 | CLS Loss: 0.68360835313797\n",
      "Epoch 1 / 200 | iteration 20 / 171 | Total Loss: 3.323235511779785 | KNN Loss: 2.731367588043213 | CLS Loss: 0.5918678641319275\n",
      "Epoch 1 / 200 | iteration 30 / 171 | Total Loss: 3.1718411445617676 | KNN Loss: 2.56550669670105 | CLS Loss: 0.606334388256073\n",
      "Epoch 1 / 200 | iteration 40 / 171 | Total Loss: 3.0967538356781006 | KNN Loss: 2.5365593433380127 | CLS Loss: 0.5601944327354431\n",
      "Epoch 1 / 200 | iteration 50 / 171 | Total Loss: 2.9649579524993896 | KNN Loss: 2.501180410385132 | CLS Loss: 0.46377745270729065\n",
      "Epoch 1 / 200 | iteration 60 / 171 | Total Loss: 3.0078890323638916 | KNN Loss: 2.502568006515503 | CLS Loss: 0.5053209662437439\n",
      "Epoch 1 / 200 | iteration 70 / 171 | Total Loss: 2.9528684616088867 | KNN Loss: 2.4429826736450195 | CLS Loss: 0.5098857879638672\n",
      "Epoch 1 / 200 | iteration 80 / 171 | Total Loss: 2.9167733192443848 | KNN Loss: 2.4695351123809814 | CLS Loss: 0.44723811745643616\n",
      "Epoch 1 / 200 | iteration 90 / 171 | Total Loss: 2.913482189178467 | KNN Loss: 2.437004327774048 | CLS Loss: 0.47647780179977417\n",
      "Epoch 1 / 200 | iteration 100 / 171 | Total Loss: 2.871234893798828 | KNN Loss: 2.441478729248047 | CLS Loss: 0.429756224155426\n",
      "Epoch 1 / 200 | iteration 110 / 171 | Total Loss: 2.8428802490234375 | KNN Loss: 2.469350814819336 | CLS Loss: 0.373529314994812\n",
      "Epoch 1 / 200 | iteration 120 / 171 | Total Loss: 2.8281750679016113 | KNN Loss: 2.4868805408477783 | CLS Loss: 0.3412944972515106\n",
      "Epoch 1 / 200 | iteration 130 / 171 | Total Loss: 2.8138139247894287 | KNN Loss: 2.4448788166046143 | CLS Loss: 0.36893507838249207\n",
      "Epoch 1 / 200 | iteration 140 / 171 | Total Loss: 2.85322904586792 | KNN Loss: 2.479715347290039 | CLS Loss: 0.37351372838020325\n",
      "Epoch 1 / 200 | iteration 150 / 171 | Total Loss: 2.837175130844116 | KNN Loss: 2.5004684925079346 | CLS Loss: 0.33670660853385925\n",
      "Epoch 1 / 200 | iteration 160 / 171 | Total Loss: 2.821526050567627 | KNN Loss: 2.533519744873047 | CLS Loss: 0.28800633549690247\n",
      "Epoch 1 / 200 | iteration 170 / 171 | Total Loss: 2.788191795349121 | KNN Loss: 2.4965615272521973 | CLS Loss: 0.2916303873062134\n",
      "Epoch: 001, Loss: 3.2088, Train: 0.9272, Valid: 0.9257, Best: 0.9257\n",
      "Epoch 2 / 200 | iteration 0 / 171 | Total Loss: 2.8052568435668945 | KNN Loss: 2.5056896209716797 | CLS Loss: 0.2995672821998596\n",
      "Epoch 2 / 200 | iteration 10 / 171 | Total Loss: 2.755621910095215 | KNN Loss: 2.4491047859191895 | CLS Loss: 0.3065170347690582\n",
      "Epoch 2 / 200 | iteration 20 / 171 | Total Loss: 2.786264419555664 | KNN Loss: 2.4972357749938965 | CLS Loss: 0.2890285551548004\n",
      "Epoch 2 / 200 | iteration 30 / 171 | Total Loss: 2.766505002975464 | KNN Loss: 2.4824917316436768 | CLS Loss: 0.2840133309364319\n",
      "Epoch 2 / 200 | iteration 40 / 171 | Total Loss: 2.7035815715789795 | KNN Loss: 2.520387887954712 | CLS Loss: 0.183193638920784\n",
      "Epoch 2 / 200 | iteration 50 / 171 | Total Loss: 2.8015177249908447 | KNN Loss: 2.513486385345459 | CLS Loss: 0.2880314290523529\n",
      "Epoch 2 / 200 | iteration 60 / 171 | Total Loss: 2.752786874771118 | KNN Loss: 2.48349928855896 | CLS Loss: 0.26928749680519104\n",
      "Epoch 2 / 200 | iteration 70 / 171 | Total Loss: 2.7739665508270264 | KNN Loss: 2.4731218814849854 | CLS Loss: 0.300844669342041\n",
      "Epoch 2 / 200 | iteration 80 / 171 | Total Loss: 2.744250774383545 | KNN Loss: 2.413933277130127 | CLS Loss: 0.3303173780441284\n",
      "Epoch 2 / 200 | iteration 90 / 171 | Total Loss: 2.6949825286865234 | KNN Loss: 2.505655288696289 | CLS Loss: 0.1893271505832672\n",
      "Epoch 2 / 200 | iteration 100 / 171 | Total Loss: 2.7135186195373535 | KNN Loss: 2.497284173965454 | CLS Loss: 0.2162344604730606\n",
      "Epoch 2 / 200 | iteration 110 / 171 | Total Loss: 2.7122583389282227 | KNN Loss: 2.5124406814575195 | CLS Loss: 0.19981764256954193\n",
      "Epoch 2 / 200 | iteration 120 / 171 | Total Loss: 2.6910970211029053 | KNN Loss: 2.5145936012268066 | CLS Loss: 0.17650339007377625\n",
      "Epoch 2 / 200 | iteration 130 / 171 | Total Loss: 2.6955132484436035 | KNN Loss: 2.49479341506958 | CLS Loss: 0.20071987807750702\n",
      "Epoch 2 / 200 | iteration 140 / 171 | Total Loss: 2.6865782737731934 | KNN Loss: 2.49391508102417 | CLS Loss: 0.19266311824321747\n",
      "Epoch 2 / 200 | iteration 150 / 171 | Total Loss: 2.7361106872558594 | KNN Loss: 2.546604871749878 | CLS Loss: 0.18950583040714264\n",
      "Epoch 2 / 200 | iteration 160 / 171 | Total Loss: 2.6839818954467773 | KNN Loss: 2.508678674697876 | CLS Loss: 0.1753031313419342\n",
      "Epoch 2 / 200 | iteration 170 / 171 | Total Loss: 2.6720616817474365 | KNN Loss: 2.517399311065674 | CLS Loss: 0.1546623855829239\n",
      "Epoch: 002, Loss: 2.7252, Train: 0.9457, Valid: 0.9461, Best: 0.9461\n",
      "Epoch 3 / 200 | iteration 0 / 171 | Total Loss: 2.6980228424072266 | KNN Loss: 2.523224115371704 | CLS Loss: 0.174798846244812\n",
      "Epoch 3 / 200 | iteration 10 / 171 | Total Loss: 2.6515212059020996 | KNN Loss: 2.4907000064849854 | CLS Loss: 0.16082127392292023\n",
      "Epoch 3 / 200 | iteration 20 / 171 | Total Loss: 2.677889347076416 | KNN Loss: 2.5428524017333984 | CLS Loss: 0.13503701984882355\n",
      "Epoch 3 / 200 | iteration 30 / 171 | Total Loss: 2.7158336639404297 | KNN Loss: 2.5221378803253174 | CLS Loss: 0.19369584321975708\n",
      "Epoch 3 / 200 | iteration 40 / 171 | Total Loss: 2.6287760734558105 | KNN Loss: 2.5089166164398193 | CLS Loss: 0.11985953897237778\n",
      "Epoch 3 / 200 | iteration 50 / 171 | Total Loss: 2.6552846431732178 | KNN Loss: 2.511082172393799 | CLS Loss: 0.1442023664712906\n",
      "Epoch 3 / 200 | iteration 60 / 171 | Total Loss: 2.644613742828369 | KNN Loss: 2.494725227355957 | CLS Loss: 0.14988848567008972\n",
      "Epoch 3 / 200 | iteration 70 / 171 | Total Loss: 2.670990467071533 | KNN Loss: 2.516216993331909 | CLS Loss: 0.1547735333442688\n",
      "Epoch 3 / 200 | iteration 80 / 171 | Total Loss: 2.6521105766296387 | KNN Loss: 2.5041446685791016 | CLS Loss: 0.14796596765518188\n",
      "Epoch 3 / 200 | iteration 90 / 171 | Total Loss: 2.6092581748962402 | KNN Loss: 2.4933712482452393 | CLS Loss: 0.11588695645332336\n",
      "Epoch 3 / 200 | iteration 100 / 171 | Total Loss: 2.635770320892334 | KNN Loss: 2.501737356185913 | CLS Loss: 0.13403305411338806\n",
      "Epoch 3 / 200 | iteration 110 / 171 | Total Loss: 2.6913509368896484 | KNN Loss: 2.532831907272339 | CLS Loss: 0.15851910412311554\n",
      "Epoch 3 / 200 | iteration 120 / 171 | Total Loss: 2.6022255420684814 | KNN Loss: 2.4649784564971924 | CLS Loss: 0.13724708557128906\n",
      "Epoch 3 / 200 | iteration 130 / 171 | Total Loss: 2.643850803375244 | KNN Loss: 2.502081871032715 | CLS Loss: 0.14176902174949646\n",
      "Epoch 3 / 200 | iteration 140 / 171 | Total Loss: 2.60532283782959 | KNN Loss: 2.4504008293151855 | CLS Loss: 0.15492209792137146\n",
      "Epoch 3 / 200 | iteration 150 / 171 | Total Loss: 2.5974514484405518 | KNN Loss: 2.4599721431732178 | CLS Loss: 0.13747923076152802\n",
      "Epoch 3 / 200 | iteration 160 / 171 | Total Loss: 2.6206471920013428 | KNN Loss: 2.482081890106201 | CLS Loss: 0.13856522738933563\n",
      "Epoch 3 / 200 | iteration 170 / 171 | Total Loss: 2.6370480060577393 | KNN Loss: 2.500319004058838 | CLS Loss: 0.136728897690773\n",
      "Epoch: 003, Loss: 2.6432, Train: 0.9664, Valid: 0.9657, Best: 0.9657\n",
      "Epoch 4 / 200 | iteration 0 / 171 | Total Loss: 2.585824966430664 | KNN Loss: 2.4860360622406006 | CLS Loss: 0.09978886693716049\n",
      "Epoch 4 / 200 | iteration 10 / 171 | Total Loss: 2.5824975967407227 | KNN Loss: 2.479294776916504 | CLS Loss: 0.10320280492305756\n",
      "Epoch 4 / 200 | iteration 20 / 171 | Total Loss: 2.638970136642456 | KNN Loss: 2.5019800662994385 | CLS Loss: 0.1369900107383728\n",
      "Epoch 4 / 200 | iteration 30 / 171 | Total Loss: 2.643115758895874 | KNN Loss: 2.5270678997039795 | CLS Loss: 0.11604783684015274\n",
      "Epoch 4 / 200 | iteration 40 / 171 | Total Loss: 2.6401777267456055 | KNN Loss: 2.5072460174560547 | CLS Loss: 0.132931649684906\n",
      "Epoch 4 / 200 | iteration 50 / 171 | Total Loss: 2.6440954208374023 | KNN Loss: 2.4825022220611572 | CLS Loss: 0.16159315407276154\n",
      "Epoch 4 / 200 | iteration 60 / 171 | Total Loss: 2.6452083587646484 | KNN Loss: 2.4741294384002686 | CLS Loss: 0.17107896506786346\n",
      "Epoch 4 / 200 | iteration 70 / 171 | Total Loss: 2.6347100734710693 | KNN Loss: 2.5010597705841064 | CLS Loss: 0.1336502730846405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 200 | iteration 80 / 171 | Total Loss: 2.566361427307129 | KNN Loss: 2.463594675064087 | CLS Loss: 0.1027667224407196\n",
      "Epoch 4 / 200 | iteration 90 / 171 | Total Loss: 2.593855142593384 | KNN Loss: 2.463956356048584 | CLS Loss: 0.12989874184131622\n",
      "Epoch 4 / 200 | iteration 100 / 171 | Total Loss: 2.6004343032836914 | KNN Loss: 2.4911108016967773 | CLS Loss: 0.10932353138923645\n",
      "Epoch 4 / 200 | iteration 110 / 171 | Total Loss: 2.61438250541687 | KNN Loss: 2.477689266204834 | CLS Loss: 0.13669322431087494\n",
      "Epoch 4 / 200 | iteration 120 / 171 | Total Loss: 2.604036569595337 | KNN Loss: 2.478548049926758 | CLS Loss: 0.12548844516277313\n",
      "Epoch 4 / 200 | iteration 130 / 171 | Total Loss: 2.550182819366455 | KNN Loss: 2.457052230834961 | CLS Loss: 0.09313064813613892\n",
      "Epoch 4 / 200 | iteration 140 / 171 | Total Loss: 2.5695672035217285 | KNN Loss: 2.4919986724853516 | CLS Loss: 0.07756859809160233\n",
      "Epoch 4 / 200 | iteration 150 / 171 | Total Loss: 2.602182149887085 | KNN Loss: 2.46675968170166 | CLS Loss: 0.1354225128889084\n",
      "Epoch 4 / 200 | iteration 160 / 171 | Total Loss: 2.6014485359191895 | KNN Loss: 2.4701967239379883 | CLS Loss: 0.13125185668468475\n",
      "Epoch 4 / 200 | iteration 170 / 171 | Total Loss: 2.5576839447021484 | KNN Loss: 2.462627649307251 | CLS Loss: 0.09505636245012283\n",
      "Epoch: 004, Loss: 2.5979, Train: 0.9670, Valid: 0.9652, Best: 0.9657\n",
      "Epoch 5 / 200 | iteration 0 / 171 | Total Loss: 2.5915606021881104 | KNN Loss: 2.483469009399414 | CLS Loss: 0.10809167474508286\n",
      "Epoch 5 / 200 | iteration 10 / 171 | Total Loss: 2.5578105449676514 | KNN Loss: 2.461940288543701 | CLS Loss: 0.09587036073207855\n",
      "Epoch 5 / 200 | iteration 20 / 171 | Total Loss: 2.616903781890869 | KNN Loss: 2.442596673965454 | CLS Loss: 0.17430709302425385\n",
      "Epoch 5 / 200 | iteration 30 / 171 | Total Loss: 2.5997674465179443 | KNN Loss: 2.4468283653259277 | CLS Loss: 0.152939110994339\n",
      "Epoch 5 / 200 | iteration 40 / 171 | Total Loss: 2.58091402053833 | KNN Loss: 2.4856154918670654 | CLS Loss: 0.09529854357242584\n",
      "Epoch 5 / 200 | iteration 50 / 171 | Total Loss: 2.5965070724487305 | KNN Loss: 2.4462363719940186 | CLS Loss: 0.15027080476284027\n",
      "Epoch 5 / 200 | iteration 60 / 171 | Total Loss: 2.5556480884552 | KNN Loss: 2.4559664726257324 | CLS Loss: 0.09968169778585434\n",
      "Epoch 5 / 200 | iteration 70 / 171 | Total Loss: 2.5465152263641357 | KNN Loss: 2.4674103260040283 | CLS Loss: 0.07910479605197906\n",
      "Epoch 5 / 200 | iteration 80 / 171 | Total Loss: 2.569645404815674 | KNN Loss: 2.443472385406494 | CLS Loss: 0.1261729598045349\n",
      "Epoch 5 / 200 | iteration 90 / 171 | Total Loss: 2.5881597995758057 | KNN Loss: 2.4684245586395264 | CLS Loss: 0.1197352185845375\n",
      "Epoch 5 / 200 | iteration 100 / 171 | Total Loss: 2.5530457496643066 | KNN Loss: 2.4669747352600098 | CLS Loss: 0.08607106655836105\n",
      "Epoch 5 / 200 | iteration 110 / 171 | Total Loss: 2.568319797515869 | KNN Loss: 2.4656128883361816 | CLS Loss: 0.10270696878433228\n",
      "Epoch 5 / 200 | iteration 120 / 171 | Total Loss: 2.5988383293151855 | KNN Loss: 2.488936424255371 | CLS Loss: 0.10990189015865326\n",
      "Epoch 5 / 200 | iteration 130 / 171 | Total Loss: 2.540574073791504 | KNN Loss: 2.460705518722534 | CLS Loss: 0.07986863702535629\n",
      "Epoch 5 / 200 | iteration 140 / 171 | Total Loss: 2.552553653717041 | KNN Loss: 2.4557902812957764 | CLS Loss: 0.0967632606625557\n",
      "Epoch 5 / 200 | iteration 150 / 171 | Total Loss: 2.5417840480804443 | KNN Loss: 2.4770965576171875 | CLS Loss: 0.06468753516674042\n",
      "Epoch 5 / 200 | iteration 160 / 171 | Total Loss: 2.568310499191284 | KNN Loss: 2.4273102283477783 | CLS Loss: 0.14100033044815063\n",
      "Epoch 5 / 200 | iteration 170 / 171 | Total Loss: 2.574920415878296 | KNN Loss: 2.4910473823547363 | CLS Loss: 0.08387298136949539\n",
      "Epoch: 005, Loss: 2.5701, Train: 0.9766, Valid: 0.9740, Best: 0.9740\n",
      "Epoch 6 / 200 | iteration 0 / 171 | Total Loss: 2.5658748149871826 | KNN Loss: 2.4837844371795654 | CLS Loss: 0.08209028840065002\n",
      "Epoch 6 / 200 | iteration 10 / 171 | Total Loss: 2.550006151199341 | KNN Loss: 2.4493088722229004 | CLS Loss: 0.10069724172353745\n",
      "Epoch 6 / 200 | iteration 20 / 171 | Total Loss: 2.5190629959106445 | KNN Loss: 2.449395179748535 | CLS Loss: 0.06966779381036758\n",
      "Epoch 6 / 200 | iteration 30 / 171 | Total Loss: 2.5818185806274414 | KNN Loss: 2.4578192234039307 | CLS Loss: 0.12399931252002716\n",
      "Epoch 6 / 200 | iteration 40 / 171 | Total Loss: 2.5400257110595703 | KNN Loss: 2.4552972316741943 | CLS Loss: 0.08472856879234314\n",
      "Epoch 6 / 200 | iteration 50 / 171 | Total Loss: 2.557040214538574 | KNN Loss: 2.473308801651001 | CLS Loss: 0.08373130857944489\n",
      "Epoch 6 / 200 | iteration 60 / 171 | Total Loss: 2.5607430934906006 | KNN Loss: 2.431673526763916 | CLS Loss: 0.1290694773197174\n",
      "Epoch 6 / 200 | iteration 70 / 171 | Total Loss: 2.588573932647705 | KNN Loss: 2.4555394649505615 | CLS Loss: 0.1330343782901764\n",
      "Epoch 6 / 200 | iteration 80 / 171 | Total Loss: 2.555781126022339 | KNN Loss: 2.449014663696289 | CLS Loss: 0.1067664623260498\n",
      "Epoch 6 / 200 | iteration 90 / 171 | Total Loss: 2.5863749980926514 | KNN Loss: 2.4577999114990234 | CLS Loss: 0.12857510149478912\n",
      "Epoch 6 / 200 | iteration 100 / 171 | Total Loss: 2.556589126586914 | KNN Loss: 2.4278409481048584 | CLS Loss: 0.12874816358089447\n",
      "Epoch 6 / 200 | iteration 110 / 171 | Total Loss: 2.5573346614837646 | KNN Loss: 2.4418482780456543 | CLS Loss: 0.11548638343811035\n",
      "Epoch 6 / 200 | iteration 120 / 171 | Total Loss: 2.5690689086914062 | KNN Loss: 2.450052499771118 | CLS Loss: 0.1190163791179657\n",
      "Epoch 6 / 200 | iteration 130 / 171 | Total Loss: 2.4974355697631836 | KNN Loss: 2.397536277770996 | CLS Loss: 0.09989936649799347\n",
      "Epoch 6 / 200 | iteration 140 / 171 | Total Loss: 2.5574512481689453 | KNN Loss: 2.4552764892578125 | CLS Loss: 0.10217476636171341\n",
      "Epoch 6 / 200 | iteration 150 / 171 | Total Loss: 2.565903902053833 | KNN Loss: 2.429751396179199 | CLS Loss: 0.136152446269989\n",
      "Epoch 6 / 200 | iteration 160 / 171 | Total Loss: 2.5578691959381104 | KNN Loss: 2.4435389041900635 | CLS Loss: 0.11433020979166031\n",
      "Epoch 6 / 200 | iteration 170 / 171 | Total Loss: 2.5233891010284424 | KNN Loss: 2.4720728397369385 | CLS Loss: 0.051316287368535995\n",
      "Epoch: 006, Loss: 2.5575, Train: 0.9730, Valid: 0.9708, Best: 0.9740\n",
      "Epoch 7 / 200 | iteration 0 / 171 | Total Loss: 2.5363447666168213 | KNN Loss: 2.449662923812866 | CLS Loss: 0.08668188005685806\n",
      "Epoch 7 / 200 | iteration 10 / 171 | Total Loss: 2.5544371604919434 | KNN Loss: 2.473878860473633 | CLS Loss: 0.08055827021598816\n",
      "Epoch 7 / 200 | iteration 20 / 171 | Total Loss: 2.5275614261627197 | KNN Loss: 2.4524333477020264 | CLS Loss: 0.07512804865837097\n",
      "Epoch 7 / 200 | iteration 30 / 171 | Total Loss: 2.526359796524048 | KNN Loss: 2.4645378589630127 | CLS Loss: 0.06182202324271202\n",
      "Epoch 7 / 200 | iteration 40 / 171 | Total Loss: 2.5128164291381836 | KNN Loss: 2.40507435798645 | CLS Loss: 0.10774218291044235\n",
      "Epoch 7 / 200 | iteration 50 / 171 | Total Loss: 2.5285325050354004 | KNN Loss: 2.442352294921875 | CLS Loss: 0.0861801877617836\n",
      "Epoch 7 / 200 | iteration 60 / 171 | Total Loss: 2.5699920654296875 | KNN Loss: 2.451315402984619 | CLS Loss: 0.11867678165435791\n",
      "Epoch 7 / 200 | iteration 70 / 171 | Total Loss: 2.5426645278930664 | KNN Loss: 2.4788196086883545 | CLS Loss: 0.06384500861167908\n",
      "Epoch 7 / 200 | iteration 80 / 171 | Total Loss: 2.536869764328003 | KNN Loss: 2.4180400371551514 | CLS Loss: 0.11882979422807693\n",
      "Epoch 7 / 200 | iteration 90 / 171 | Total Loss: 2.5166351795196533 | KNN Loss: 2.4577105045318604 | CLS Loss: 0.05892461538314819\n",
      "Epoch 7 / 200 | iteration 100 / 171 | Total Loss: 2.5509891510009766 | KNN Loss: 2.4461565017700195 | CLS Loss: 0.10483258217573166\n",
      "Epoch 7 / 200 | iteration 110 / 171 | Total Loss: 2.5432310104370117 | KNN Loss: 2.4173197746276855 | CLS Loss: 0.12591122090816498\n",
      "Epoch 7 / 200 | iteration 120 / 171 | Total Loss: 2.546257734298706 | KNN Loss: 2.4399123191833496 | CLS Loss: 0.10634530335664749\n",
      "Epoch 7 / 200 | iteration 130 / 171 | Total Loss: 2.515458583831787 | KNN Loss: 2.42478609085083 | CLS Loss: 0.09067252278327942\n",
      "Epoch 7 / 200 | iteration 140 / 171 | Total Loss: 2.502992868423462 | KNN Loss: 2.422203302383423 | CLS Loss: 0.08078958839178085\n",
      "Epoch 7 / 200 | iteration 150 / 171 | Total Loss: 2.5416781902313232 | KNN Loss: 2.4342715740203857 | CLS Loss: 0.10740669816732407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 200 | iteration 160 / 171 | Total Loss: 2.5054526329040527 | KNN Loss: 2.4551796913146973 | CLS Loss: 0.050273049622774124\n",
      "Epoch 7 / 200 | iteration 170 / 171 | Total Loss: 2.5363872051239014 | KNN Loss: 2.4591224193573 | CLS Loss: 0.0772646889090538\n",
      "Epoch: 007, Loss: 2.5362, Train: 0.9793, Valid: 0.9762, Best: 0.9762\n",
      "Epoch 8 / 200 | iteration 0 / 171 | Total Loss: 2.514387607574463 | KNN Loss: 2.455143690109253 | CLS Loss: 0.05924391746520996\n",
      "Epoch 8 / 200 | iteration 10 / 171 | Total Loss: 2.5086286067962646 | KNN Loss: 2.436633348464966 | CLS Loss: 0.07199514657258987\n",
      "Epoch 8 / 200 | iteration 20 / 171 | Total Loss: 2.554171562194824 | KNN Loss: 2.47037935256958 | CLS Loss: 0.08379209041595459\n",
      "Epoch 8 / 200 | iteration 30 / 171 | Total Loss: 2.537275791168213 | KNN Loss: 2.4291815757751465 | CLS Loss: 0.10809414088726044\n",
      "Epoch 8 / 200 | iteration 40 / 171 | Total Loss: 2.5084729194641113 | KNN Loss: 2.450446367263794 | CLS Loss: 0.05802658945322037\n",
      "Epoch 8 / 200 | iteration 50 / 171 | Total Loss: 2.4997785091400146 | KNN Loss: 2.424550771713257 | CLS Loss: 0.07522770762443542\n",
      "Epoch 8 / 200 | iteration 60 / 171 | Total Loss: 2.557800531387329 | KNN Loss: 2.454012870788574 | CLS Loss: 0.1037876084446907\n",
      "Epoch 8 / 200 | iteration 70 / 171 | Total Loss: 2.5327491760253906 | KNN Loss: 2.4744091033935547 | CLS Loss: 0.058340009301900864\n",
      "Epoch 8 / 200 | iteration 80 / 171 | Total Loss: 2.5284552574157715 | KNN Loss: 2.404770612716675 | CLS Loss: 0.1236845999956131\n",
      "Epoch 8 / 200 | iteration 90 / 171 | Total Loss: 2.49546480178833 | KNN Loss: 2.3787624835968018 | CLS Loss: 0.1167023554444313\n",
      "Epoch 8 / 200 | iteration 100 / 171 | Total Loss: 2.496614456176758 | KNN Loss: 2.455056667327881 | CLS Loss: 0.041557677090168\n",
      "Epoch 8 / 200 | iteration 110 / 171 | Total Loss: 2.521003246307373 | KNN Loss: 2.4611876010894775 | CLS Loss: 0.05981563776731491\n",
      "Epoch 8 / 200 | iteration 120 / 171 | Total Loss: 2.526401996612549 | KNN Loss: 2.4516303539276123 | CLS Loss: 0.07477161288261414\n",
      "Epoch 8 / 200 | iteration 130 / 171 | Total Loss: 2.5464577674865723 | KNN Loss: 2.4567251205444336 | CLS Loss: 0.0897325724363327\n",
      "Epoch 8 / 200 | iteration 140 / 171 | Total Loss: 2.5387141704559326 | KNN Loss: 2.4700422286987305 | CLS Loss: 0.06867183744907379\n",
      "Epoch 8 / 200 | iteration 150 / 171 | Total Loss: 2.464782238006592 | KNN Loss: 2.3815836906433105 | CLS Loss: 0.08319847285747528\n",
      "Epoch 8 / 200 | iteration 160 / 171 | Total Loss: 2.5059592723846436 | KNN Loss: 2.476675271987915 | CLS Loss: 0.029284024611115456\n",
      "Epoch 8 / 200 | iteration 170 / 171 | Total Loss: 2.5162737369537354 | KNN Loss: 2.4162216186523438 | CLS Loss: 0.1000521183013916\n",
      "Epoch: 008, Loss: 2.5193, Train: 0.9806, Valid: 0.9784, Best: 0.9784\n",
      "Epoch 9 / 200 | iteration 0 / 171 | Total Loss: 2.502530574798584 | KNN Loss: 2.409698963165283 | CLS Loss: 0.09283164143562317\n",
      "Epoch 9 / 200 | iteration 10 / 171 | Total Loss: 2.516916275024414 | KNN Loss: 2.454843759536743 | CLS Loss: 0.06207241117954254\n",
      "Epoch 9 / 200 | iteration 20 / 171 | Total Loss: 2.526151657104492 | KNN Loss: 2.4534800052642822 | CLS Loss: 0.07267172634601593\n",
      "Epoch 9 / 200 | iteration 30 / 171 | Total Loss: 2.539020538330078 | KNN Loss: 2.4371747970581055 | CLS Loss: 0.10184572637081146\n",
      "Epoch 9 / 200 | iteration 40 / 171 | Total Loss: 2.5069780349731445 | KNN Loss: 2.409519672393799 | CLS Loss: 0.09745825082063675\n",
      "Epoch 9 / 200 | iteration 50 / 171 | Total Loss: 2.543383836746216 | KNN Loss: 2.453591823577881 | CLS Loss: 0.08979204297065735\n",
      "Epoch 9 / 200 | iteration 60 / 171 | Total Loss: 2.568125009536743 | KNN Loss: 2.4635608196258545 | CLS Loss: 0.10456427186727524\n",
      "Epoch 9 / 200 | iteration 70 / 171 | Total Loss: 2.535275936126709 | KNN Loss: 2.4632885456085205 | CLS Loss: 0.07198739796876907\n",
      "Epoch 9 / 200 | iteration 80 / 171 | Total Loss: 2.5024709701538086 | KNN Loss: 2.395291805267334 | CLS Loss: 0.10717906802892685\n",
      "Epoch 9 / 200 | iteration 90 / 171 | Total Loss: 2.47322154045105 | KNN Loss: 2.427706241607666 | CLS Loss: 0.04551537707448006\n",
      "Epoch 9 / 200 | iteration 100 / 171 | Total Loss: 2.5454089641571045 | KNN Loss: 2.45278263092041 | CLS Loss: 0.09262640029191971\n",
      "Epoch 9 / 200 | iteration 110 / 171 | Total Loss: 2.507814645767212 | KNN Loss: 2.425217866897583 | CLS Loss: 0.08259669691324234\n",
      "Epoch 9 / 200 | iteration 120 / 171 | Total Loss: 2.520663022994995 | KNN Loss: 2.465296506881714 | CLS Loss: 0.05536656081676483\n",
      "Epoch 9 / 200 | iteration 130 / 171 | Total Loss: 2.4839916229248047 | KNN Loss: 2.4135916233062744 | CLS Loss: 0.07039996981620789\n",
      "Epoch 9 / 200 | iteration 140 / 171 | Total Loss: 2.4751851558685303 | KNN Loss: 2.4372293949127197 | CLS Loss: 0.03795584291219711\n",
      "Epoch 9 / 200 | iteration 150 / 171 | Total Loss: 2.5090928077697754 | KNN Loss: 2.4204745292663574 | CLS Loss: 0.08861836791038513\n",
      "Epoch 9 / 200 | iteration 160 / 171 | Total Loss: 2.498506546020508 | KNN Loss: 2.4044995307922363 | CLS Loss: 0.09400700032711029\n",
      "Epoch 9 / 200 | iteration 170 / 171 | Total Loss: 2.5019195079803467 | KNN Loss: 2.4097554683685303 | CLS Loss: 0.09216392785310745\n",
      "Epoch: 009, Loss: 2.5127, Train: 0.9793, Valid: 0.9767, Best: 0.9784\n",
      "Epoch 10 / 200 | iteration 0 / 171 | Total Loss: 2.518388509750366 | KNN Loss: 2.4038116931915283 | CLS Loss: 0.11457688361406326\n",
      "Epoch 10 / 200 | iteration 10 / 171 | Total Loss: 2.4753201007843018 | KNN Loss: 2.4394590854644775 | CLS Loss: 0.03586110472679138\n",
      "Epoch 10 / 200 | iteration 20 / 171 | Total Loss: 2.4652371406555176 | KNN Loss: 2.3880186080932617 | CLS Loss: 0.07721853256225586\n",
      "Epoch 10 / 200 | iteration 30 / 171 | Total Loss: 2.488635540008545 | KNN Loss: 2.401836395263672 | CLS Loss: 0.08679907023906708\n",
      "Epoch 10 / 200 | iteration 40 / 171 | Total Loss: 2.517728805541992 | KNN Loss: 2.4234049320220947 | CLS Loss: 0.09432394802570343\n",
      "Epoch 10 / 200 | iteration 50 / 171 | Total Loss: 2.4804906845092773 | KNN Loss: 2.417419672012329 | CLS Loss: 0.06307089328765869\n",
      "Epoch 10 / 200 | iteration 60 / 171 | Total Loss: 2.500441074371338 | KNN Loss: 2.4325950145721436 | CLS Loss: 0.06784604489803314\n",
      "Epoch 10 / 200 | iteration 70 / 171 | Total Loss: 2.506268262863159 | KNN Loss: 2.447521924972534 | CLS Loss: 0.0587463304400444\n",
      "Epoch 10 / 200 | iteration 80 / 171 | Total Loss: 2.50879168510437 | KNN Loss: 2.405982494354248 | CLS Loss: 0.10280919820070267\n",
      "Epoch 10 / 200 | iteration 90 / 171 | Total Loss: 2.512145519256592 | KNN Loss: 2.466796875 | CLS Loss: 0.045348554849624634\n",
      "Epoch 10 / 200 | iteration 100 / 171 | Total Loss: 2.4536750316619873 | KNN Loss: 2.395941972732544 | CLS Loss: 0.05773301050066948\n",
      "Epoch 10 / 200 | iteration 110 / 171 | Total Loss: 2.488192558288574 | KNN Loss: 2.420630931854248 | CLS Loss: 0.06756160408258438\n",
      "Epoch 10 / 200 | iteration 120 / 171 | Total Loss: 2.528212308883667 | KNN Loss: 2.452364683151245 | CLS Loss: 0.07584765553474426\n",
      "Epoch 10 / 200 | iteration 130 / 171 | Total Loss: 2.5191214084625244 | KNN Loss: 2.417250156402588 | CLS Loss: 0.10187126696109772\n",
      "Epoch 10 / 200 | iteration 140 / 171 | Total Loss: 2.474722146987915 | KNN Loss: 2.4064459800720215 | CLS Loss: 0.06827627122402191\n",
      "Epoch 10 / 200 | iteration 150 / 171 | Total Loss: 2.5113332271575928 | KNN Loss: 2.401510715484619 | CLS Loss: 0.10982240736484528\n",
      "Epoch 10 / 200 | iteration 160 / 171 | Total Loss: 2.488607168197632 | KNN Loss: 2.4048962593078613 | CLS Loss: 0.08371090888977051\n",
      "Epoch 10 / 200 | iteration 170 / 171 | Total Loss: 2.4802122116088867 | KNN Loss: 2.413172721862793 | CLS Loss: 0.06703958660364151\n",
      "Epoch: 010, Loss: 2.5055, Train: 0.9816, Valid: 0.9785, Best: 0.9785\n",
      "Epoch 11 / 200 | iteration 0 / 171 | Total Loss: 2.5472166538238525 | KNN Loss: 2.4613821506500244 | CLS Loss: 0.08583451807498932\n",
      "Epoch 11 / 200 | iteration 10 / 171 | Total Loss: 2.4810400009155273 | KNN Loss: 2.406188726425171 | CLS Loss: 0.07485117018222809\n",
      "Epoch 11 / 200 | iteration 20 / 171 | Total Loss: 2.5189754962921143 | KNN Loss: 2.444230794906616 | CLS Loss: 0.07474469393491745\n",
      "Epoch 11 / 200 | iteration 30 / 171 | Total Loss: 2.4454503059387207 | KNN Loss: 2.4086248874664307 | CLS Loss: 0.03682546690106392\n",
      "Epoch 11 / 200 | iteration 40 / 171 | Total Loss: 2.488832473754883 | KNN Loss: 2.4229588508605957 | CLS Loss: 0.06587350368499756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 200 | iteration 50 / 171 | Total Loss: 2.452906370162964 | KNN Loss: 2.4076926708221436 | CLS Loss: 0.04521365463733673\n",
      "Epoch 11 / 200 | iteration 60 / 171 | Total Loss: 2.5393195152282715 | KNN Loss: 2.4924399852752686 | CLS Loss: 0.046879444271326065\n",
      "Epoch 11 / 200 | iteration 70 / 171 | Total Loss: 2.507828712463379 | KNN Loss: 2.4357590675354004 | CLS Loss: 0.07206976413726807\n",
      "Epoch 11 / 200 | iteration 80 / 171 | Total Loss: 2.4950079917907715 | KNN Loss: 2.415837287902832 | CLS Loss: 0.07917068898677826\n",
      "Epoch 11 / 200 | iteration 90 / 171 | Total Loss: 2.5553457736968994 | KNN Loss: 2.4509036540985107 | CLS Loss: 0.10444211214780807\n",
      "Epoch 11 / 200 | iteration 100 / 171 | Total Loss: 2.5299899578094482 | KNN Loss: 2.4251089096069336 | CLS Loss: 0.10488102585077286\n",
      "Epoch 11 / 200 | iteration 110 / 171 | Total Loss: 2.478713274002075 | KNN Loss: 2.441230297088623 | CLS Loss: 0.03748295456171036\n",
      "Epoch 11 / 200 | iteration 120 / 171 | Total Loss: 2.5011115074157715 | KNN Loss: 2.4056882858276367 | CLS Loss: 0.0954231321811676\n",
      "Epoch 11 / 200 | iteration 130 / 171 | Total Loss: 2.4798994064331055 | KNN Loss: 2.419590950012207 | CLS Loss: 0.06030852347612381\n",
      "Epoch 11 / 200 | iteration 140 / 171 | Total Loss: 2.479383945465088 | KNN Loss: 2.4265787601470947 | CLS Loss: 0.05280521139502525\n",
      "Epoch 11 / 200 | iteration 150 / 171 | Total Loss: 2.4836349487304688 | KNN Loss: 2.4214928150177 | CLS Loss: 0.06214213743805885\n",
      "Epoch 11 / 200 | iteration 160 / 171 | Total Loss: 2.485227346420288 | KNN Loss: 2.4381892681121826 | CLS Loss: 0.04703817516565323\n",
      "Epoch 11 / 200 | iteration 170 / 171 | Total Loss: 2.499505043029785 | KNN Loss: 2.422116279602051 | CLS Loss: 0.07738887518644333\n",
      "Epoch: 011, Loss: 2.4963, Train: 0.9833, Valid: 0.9803, Best: 0.9803\n",
      "Epoch 12 / 200 | iteration 0 / 171 | Total Loss: 2.5316460132598877 | KNN Loss: 2.4225499629974365 | CLS Loss: 0.1090959832072258\n",
      "Epoch 12 / 200 | iteration 10 / 171 | Total Loss: 2.4694104194641113 | KNN Loss: 2.421281576156616 | CLS Loss: 0.048128727823495865\n",
      "Epoch 12 / 200 | iteration 20 / 171 | Total Loss: 2.4884612560272217 | KNN Loss: 2.406752586364746 | CLS Loss: 0.08170861750841141\n",
      "Epoch 12 / 200 | iteration 30 / 171 | Total Loss: 2.4559571743011475 | KNN Loss: 2.4185690879821777 | CLS Loss: 0.03738810494542122\n",
      "Epoch 12 / 200 | iteration 40 / 171 | Total Loss: 2.5455520153045654 | KNN Loss: 2.4311845302581787 | CLS Loss: 0.11436747759580612\n",
      "Epoch 12 / 200 | iteration 50 / 171 | Total Loss: 2.507180690765381 | KNN Loss: 2.4080145359039307 | CLS Loss: 0.09916625916957855\n",
      "Epoch 12 / 200 | iteration 60 / 171 | Total Loss: 2.552624225616455 | KNN Loss: 2.4459292888641357 | CLS Loss: 0.10669499635696411\n",
      "Epoch 12 / 200 | iteration 70 / 171 | Total Loss: 2.4863667488098145 | KNN Loss: 2.3888955116271973 | CLS Loss: 0.09747127443552017\n",
      "Epoch 12 / 200 | iteration 80 / 171 | Total Loss: 2.487244129180908 | KNN Loss: 2.4267098903656006 | CLS Loss: 0.06053433567285538\n",
      "Epoch 12 / 200 | iteration 90 / 171 | Total Loss: 2.467005968093872 | KNN Loss: 2.4096012115478516 | CLS Loss: 0.05740469694137573\n",
      "Epoch 12 / 200 | iteration 100 / 171 | Total Loss: 2.477860450744629 | KNN Loss: 2.428499221801758 | CLS Loss: 0.04936126992106438\n",
      "Epoch 12 / 200 | iteration 110 / 171 | Total Loss: 2.486713171005249 | KNN Loss: 2.4242615699768066 | CLS Loss: 0.062451668083667755\n",
      "Epoch 12 / 200 | iteration 120 / 171 | Total Loss: 2.4839587211608887 | KNN Loss: 2.4234890937805176 | CLS Loss: 0.06046954169869423\n",
      "Epoch 12 / 200 | iteration 130 / 171 | Total Loss: 2.5232934951782227 | KNN Loss: 2.4603078365325928 | CLS Loss: 0.06298571079969406\n",
      "Epoch 12 / 200 | iteration 140 / 171 | Total Loss: 2.4793128967285156 | KNN Loss: 2.427825689315796 | CLS Loss: 0.05148722603917122\n",
      "Epoch 12 / 200 | iteration 150 / 171 | Total Loss: 2.5120537281036377 | KNN Loss: 2.441080331802368 | CLS Loss: 0.0709734633564949\n",
      "Epoch 12 / 200 | iteration 160 / 171 | Total Loss: 2.5130505561828613 | KNN Loss: 2.4424993991851807 | CLS Loss: 0.07055120915174484\n",
      "Epoch 12 / 200 | iteration 170 / 171 | Total Loss: 2.476736068725586 | KNN Loss: 2.4303438663482666 | CLS Loss: 0.04639219492673874\n",
      "Epoch: 012, Loss: 2.4895, Train: 0.9833, Valid: 0.9809, Best: 0.9809\n",
      "Epoch 13 / 200 | iteration 0 / 171 | Total Loss: 2.4836487770080566 | KNN Loss: 2.441350221633911 | CLS Loss: 0.042298514395952225\n",
      "Epoch 13 / 200 | iteration 10 / 171 | Total Loss: 2.4809329509735107 | KNN Loss: 2.4250457286834717 | CLS Loss: 0.05588715896010399\n",
      "Epoch 13 / 200 | iteration 20 / 171 | Total Loss: 2.4767165184020996 | KNN Loss: 2.4264910221099854 | CLS Loss: 0.050225406885147095\n",
      "Epoch 13 / 200 | iteration 30 / 171 | Total Loss: 2.456109046936035 | KNN Loss: 2.4027528762817383 | CLS Loss: 0.05335623770952225\n",
      "Epoch 13 / 200 | iteration 40 / 171 | Total Loss: 2.471609592437744 | KNN Loss: 2.4419443607330322 | CLS Loss: 0.029665155336260796\n",
      "Epoch 13 / 200 | iteration 50 / 171 | Total Loss: 2.485166072845459 | KNN Loss: 2.436934232711792 | CLS Loss: 0.04823173210024834\n",
      "Epoch 13 / 200 | iteration 60 / 171 | Total Loss: 2.4606878757476807 | KNN Loss: 2.427424192428589 | CLS Loss: 0.03326358646154404\n",
      "Epoch 13 / 200 | iteration 70 / 171 | Total Loss: 2.4542768001556396 | KNN Loss: 2.3977725505828857 | CLS Loss: 0.05650414898991585\n",
      "Epoch 13 / 200 | iteration 80 / 171 | Total Loss: 2.449713706970215 | KNN Loss: 2.3889992237091064 | CLS Loss: 0.060714419931173325\n",
      "Epoch 13 / 200 | iteration 90 / 171 | Total Loss: 2.463183879852295 | KNN Loss: 2.409142017364502 | CLS Loss: 0.05404197797179222\n",
      "Epoch 13 / 200 | iteration 100 / 171 | Total Loss: 2.463287591934204 | KNN Loss: 2.400258779525757 | CLS Loss: 0.06302881985902786\n",
      "Epoch 13 / 200 | iteration 110 / 171 | Total Loss: 2.468815565109253 | KNN Loss: 2.376441240310669 | CLS Loss: 0.09237441420555115\n",
      "Epoch 13 / 200 | iteration 120 / 171 | Total Loss: 2.506983518600464 | KNN Loss: 2.3616411685943604 | CLS Loss: 0.14534242451190948\n",
      "Epoch 13 / 200 | iteration 130 / 171 | Total Loss: 2.445345640182495 | KNN Loss: 2.3933515548706055 | CLS Loss: 0.05199411138892174\n",
      "Epoch 13 / 200 | iteration 140 / 171 | Total Loss: 2.4555704593658447 | KNN Loss: 2.430591344833374 | CLS Loss: 0.02497921697795391\n",
      "Epoch 13 / 200 | iteration 150 / 171 | Total Loss: 2.4737257957458496 | KNN Loss: 2.41579532623291 | CLS Loss: 0.05793047323822975\n",
      "Epoch 13 / 200 | iteration 160 / 171 | Total Loss: 2.463742733001709 | KNN Loss: 2.375783681869507 | CLS Loss: 0.0879591554403305\n",
      "Epoch 13 / 200 | iteration 170 / 171 | Total Loss: 2.4823544025421143 | KNN Loss: 2.442056894302368 | CLS Loss: 0.04029743745923042\n",
      "Epoch: 013, Loss: 2.4817, Train: 0.9830, Valid: 0.9798, Best: 0.9809\n",
      "Epoch 14 / 200 | iteration 0 / 171 | Total Loss: 2.463798999786377 | KNN Loss: 2.4140865802764893 | CLS Loss: 0.049712397158145905\n",
      "Epoch 14 / 200 | iteration 10 / 171 | Total Loss: 2.4953572750091553 | KNN Loss: 2.434321641921997 | CLS Loss: 0.06103553622961044\n",
      "Epoch 14 / 200 | iteration 20 / 171 | Total Loss: 2.4290294647216797 | KNN Loss: 2.4005157947540283 | CLS Loss: 0.028513671830296516\n",
      "Epoch 14 / 200 | iteration 30 / 171 | Total Loss: 2.486149787902832 | KNN Loss: 2.452317237854004 | CLS Loss: 0.03383244201540947\n",
      "Epoch 14 / 200 | iteration 40 / 171 | Total Loss: 2.475053310394287 | KNN Loss: 2.419572353363037 | CLS Loss: 0.05548100546002388\n",
      "Epoch 14 / 200 | iteration 50 / 171 | Total Loss: 2.500681161880493 | KNN Loss: 2.454037666320801 | CLS Loss: 0.04664355516433716\n",
      "Epoch 14 / 200 | iteration 60 / 171 | Total Loss: 2.5043840408325195 | KNN Loss: 2.4630239009857178 | CLS Loss: 0.04136008024215698\n",
      "Epoch 14 / 200 | iteration 70 / 171 | Total Loss: 2.4857146739959717 | KNN Loss: 2.443469762802124 | CLS Loss: 0.0422448106110096\n",
      "Epoch 14 / 200 | iteration 80 / 171 | Total Loss: 2.461239814758301 | KNN Loss: 2.4144041538238525 | CLS Loss: 0.046835631132125854\n",
      "Epoch 14 / 200 | iteration 90 / 171 | Total Loss: 2.508608341217041 | KNN Loss: 2.4173738956451416 | CLS Loss: 0.09123443067073822\n",
      "Epoch 14 / 200 | iteration 100 / 171 | Total Loss: 2.4913806915283203 | KNN Loss: 2.4312002658843994 | CLS Loss: 0.060180455446243286\n",
      "Epoch 14 / 200 | iteration 110 / 171 | Total Loss: 2.492180824279785 | KNN Loss: 2.394238233566284 | CLS Loss: 0.09794247150421143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 200 | iteration 120 / 171 | Total Loss: 2.450160503387451 | KNN Loss: 2.4191582202911377 | CLS Loss: 0.031002182513475418\n",
      "Epoch 14 / 200 | iteration 130 / 171 | Total Loss: 2.490746021270752 | KNN Loss: 2.4164295196533203 | CLS Loss: 0.0743165984749794\n",
      "Epoch 14 / 200 | iteration 140 / 171 | Total Loss: 2.510970115661621 | KNN Loss: 2.420605421066284 | CLS Loss: 0.09036476165056229\n",
      "Epoch 14 / 200 | iteration 150 / 171 | Total Loss: 2.470524311065674 | KNN Loss: 2.4175517559051514 | CLS Loss: 0.05297257751226425\n",
      "Epoch 14 / 200 | iteration 160 / 171 | Total Loss: 2.4557316303253174 | KNN Loss: 2.3701064586639404 | CLS Loss: 0.08562511205673218\n",
      "Epoch 14 / 200 | iteration 170 / 171 | Total Loss: 2.411316156387329 | KNN Loss: 2.3702523708343506 | CLS Loss: 0.04106369614601135\n",
      "Epoch: 014, Loss: 2.4797, Train: 0.9843, Valid: 0.9812, Best: 0.9812\n",
      "Epoch 15 / 200 | iteration 0 / 171 | Total Loss: 2.4774720668792725 | KNN Loss: 2.4158856868743896 | CLS Loss: 0.06158629059791565\n",
      "Epoch 15 / 200 | iteration 10 / 171 | Total Loss: 2.4748289585113525 | KNN Loss: 2.420968770980835 | CLS Loss: 0.05386016517877579\n",
      "Epoch 15 / 200 | iteration 20 / 171 | Total Loss: 2.4545722007751465 | KNN Loss: 2.3869028091430664 | CLS Loss: 0.0676693543791771\n",
      "Epoch 15 / 200 | iteration 30 / 171 | Total Loss: 2.4799184799194336 | KNN Loss: 2.436788320541382 | CLS Loss: 0.04313012957572937\n",
      "Epoch 15 / 200 | iteration 40 / 171 | Total Loss: 2.471954822540283 | KNN Loss: 2.41398549079895 | CLS Loss: 0.057969409972429276\n",
      "Epoch 15 / 200 | iteration 50 / 171 | Total Loss: 2.486032247543335 | KNN Loss: 2.412006378173828 | CLS Loss: 0.07402583211660385\n",
      "Epoch 15 / 200 | iteration 60 / 171 | Total Loss: 2.5030858516693115 | KNN Loss: 2.448617935180664 | CLS Loss: 0.05446799844503403\n",
      "Epoch 15 / 200 | iteration 70 / 171 | Total Loss: 2.4484875202178955 | KNN Loss: 2.3930611610412598 | CLS Loss: 0.055426400154829025\n",
      "Epoch 15 / 200 | iteration 80 / 171 | Total Loss: 2.4517693519592285 | KNN Loss: 2.3780934810638428 | CLS Loss: 0.0736759677529335\n",
      "Epoch 15 / 200 | iteration 90 / 171 | Total Loss: 2.454291343688965 | KNN Loss: 2.393660068511963 | CLS Loss: 0.060631174594163895\n",
      "Epoch 15 / 200 | iteration 100 / 171 | Total Loss: 2.46146559715271 | KNN Loss: 2.407280445098877 | CLS Loss: 0.054185058921575546\n",
      "Epoch 15 / 200 | iteration 110 / 171 | Total Loss: 2.514951705932617 | KNN Loss: 2.4145593643188477 | CLS Loss: 0.10039225965738297\n",
      "Epoch 15 / 200 | iteration 120 / 171 | Total Loss: 2.4659321308135986 | KNN Loss: 2.379795551300049 | CLS Loss: 0.08613654971122742\n",
      "Epoch 15 / 200 | iteration 130 / 171 | Total Loss: 2.453695058822632 | KNN Loss: 2.4256300926208496 | CLS Loss: 0.028064899146556854\n",
      "Epoch 15 / 200 | iteration 140 / 171 | Total Loss: 2.495349884033203 | KNN Loss: 2.4152581691741943 | CLS Loss: 0.080091692507267\n",
      "Epoch 15 / 200 | iteration 150 / 171 | Total Loss: 2.4428348541259766 | KNN Loss: 2.3804993629455566 | CLS Loss: 0.06233546882867813\n",
      "Epoch 15 / 200 | iteration 160 / 171 | Total Loss: 2.480088233947754 | KNN Loss: 2.4145450592041016 | CLS Loss: 0.06554310023784637\n",
      "Epoch 15 / 200 | iteration 170 / 171 | Total Loss: 2.4412777423858643 | KNN Loss: 2.4088852405548096 | CLS Loss: 0.03239244967699051\n",
      "Epoch: 015, Loss: 2.4705, Train: 0.9847, Valid: 0.9804, Best: 0.9812\n",
      "Epoch 16 / 200 | iteration 0 / 171 | Total Loss: 2.4952099323272705 | KNN Loss: 2.416508436203003 | CLS Loss: 0.07870156317949295\n",
      "Epoch 16 / 200 | iteration 10 / 171 | Total Loss: 2.484816312789917 | KNN Loss: 2.431260347366333 | CLS Loss: 0.05355604737997055\n",
      "Epoch 16 / 200 | iteration 20 / 171 | Total Loss: 2.463129997253418 | KNN Loss: 2.410238265991211 | CLS Loss: 0.05289177596569061\n",
      "Epoch 16 / 200 | iteration 30 / 171 | Total Loss: 2.4540586471557617 | KNN Loss: 2.3900609016418457 | CLS Loss: 0.06399763375520706\n",
      "Epoch 16 / 200 | iteration 40 / 171 | Total Loss: 2.458268165588379 | KNN Loss: 2.421030044555664 | CLS Loss: 0.03723817691206932\n",
      "Epoch 16 / 200 | iteration 50 / 171 | Total Loss: 2.466799020767212 | KNN Loss: 2.4368858337402344 | CLS Loss: 0.029913252219557762\n",
      "Epoch 16 / 200 | iteration 60 / 171 | Total Loss: 2.506289005279541 | KNN Loss: 2.473767042160034 | CLS Loss: 0.03252198174595833\n",
      "Epoch 16 / 200 | iteration 70 / 171 | Total Loss: 2.509942054748535 | KNN Loss: 2.427802801132202 | CLS Loss: 0.0821392685174942\n",
      "Epoch 16 / 200 | iteration 80 / 171 | Total Loss: 2.460853099822998 | KNN Loss: 2.404747724533081 | CLS Loss: 0.05610540509223938\n",
      "Epoch 16 / 200 | iteration 90 / 171 | Total Loss: 2.4643774032592773 | KNN Loss: 2.4167191982269287 | CLS Loss: 0.04765821248292923\n",
      "Epoch 16 / 200 | iteration 100 / 171 | Total Loss: 2.522083044052124 | KNN Loss: 2.4791910648345947 | CLS Loss: 0.0428919792175293\n",
      "Epoch 16 / 200 | iteration 110 / 171 | Total Loss: 2.4513866901397705 | KNN Loss: 2.3956098556518555 | CLS Loss: 0.0557769350707531\n",
      "Epoch 16 / 200 | iteration 120 / 171 | Total Loss: 2.4729788303375244 | KNN Loss: 2.427706480026245 | CLS Loss: 0.04527229815721512\n",
      "Epoch 16 / 200 | iteration 130 / 171 | Total Loss: 2.467367649078369 | KNN Loss: 2.42189621925354 | CLS Loss: 0.04547148570418358\n",
      "Epoch 16 / 200 | iteration 140 / 171 | Total Loss: 2.447378396987915 | KNN Loss: 2.3775634765625 | CLS Loss: 0.06981483101844788\n",
      "Epoch 16 / 200 | iteration 150 / 171 | Total Loss: 2.4402546882629395 | KNN Loss: 2.3694796562194824 | CLS Loss: 0.07077491283416748\n",
      "Epoch 16 / 200 | iteration 160 / 171 | Total Loss: 2.511148452758789 | KNN Loss: 2.4561920166015625 | CLS Loss: 0.05495641008019447\n",
      "Epoch 16 / 200 | iteration 170 / 171 | Total Loss: 2.4514410495758057 | KNN Loss: 2.3853919506073 | CLS Loss: 0.06604917347431183\n",
      "Epoch: 016, Loss: 2.4706, Train: 0.9845, Valid: 0.9817, Best: 0.9817\n",
      "Epoch 17 / 200 | iteration 0 / 171 | Total Loss: 2.4333865642547607 | KNN Loss: 2.4160985946655273 | CLS Loss: 0.0172879658639431\n",
      "Epoch 17 / 200 | iteration 10 / 171 | Total Loss: 2.456535816192627 | KNN Loss: 2.404448986053467 | CLS Loss: 0.0520867258310318\n",
      "Epoch 17 / 200 | iteration 20 / 171 | Total Loss: 2.473639965057373 | KNN Loss: 2.4231302738189697 | CLS Loss: 0.050509706139564514\n",
      "Epoch 17 / 200 | iteration 30 / 171 | Total Loss: 2.4838008880615234 | KNN Loss: 2.42568302154541 | CLS Loss: 0.0581178292632103\n",
      "Epoch 17 / 200 | iteration 40 / 171 | Total Loss: 2.452150583267212 | KNN Loss: 2.4288477897644043 | CLS Loss: 0.02330269105732441\n",
      "Epoch 17 / 200 | iteration 50 / 171 | Total Loss: 2.472921133041382 | KNN Loss: 2.4447638988494873 | CLS Loss: 0.028157232329249382\n",
      "Epoch 17 / 200 | iteration 60 / 171 | Total Loss: 2.4797253608703613 | KNN Loss: 2.439427375793457 | CLS Loss: 0.040297988802194595\n",
      "Epoch 17 / 200 | iteration 70 / 171 | Total Loss: 2.4828240871429443 | KNN Loss: 2.4044830799102783 | CLS Loss: 0.07834108918905258\n",
      "Epoch 17 / 200 | iteration 80 / 171 | Total Loss: 2.479465961456299 | KNN Loss: 2.407001495361328 | CLS Loss: 0.07246436178684235\n",
      "Epoch 17 / 200 | iteration 90 / 171 | Total Loss: 2.458690881729126 | KNN Loss: 2.3893396854400635 | CLS Loss: 0.06935128569602966\n",
      "Epoch 17 / 200 | iteration 100 / 171 | Total Loss: 2.4662277698516846 | KNN Loss: 2.428687334060669 | CLS Loss: 0.037540532648563385\n",
      "Epoch 17 / 200 | iteration 110 / 171 | Total Loss: 2.4276583194732666 | KNN Loss: 2.394181251525879 | CLS Loss: 0.03347701579332352\n",
      "Epoch 17 / 200 | iteration 120 / 171 | Total Loss: 2.509141683578491 | KNN Loss: 2.4513261318206787 | CLS Loss: 0.05781562626361847\n",
      "Epoch 17 / 200 | iteration 130 / 171 | Total Loss: 2.454867124557495 | KNN Loss: 2.414295196533203 | CLS Loss: 0.04057200253009796\n",
      "Epoch 17 / 200 | iteration 140 / 171 | Total Loss: 2.4620473384857178 | KNN Loss: 2.4064338207244873 | CLS Loss: 0.055613622069358826\n",
      "Epoch 17 / 200 | iteration 150 / 171 | Total Loss: 2.4822685718536377 | KNN Loss: 2.4227778911590576 | CLS Loss: 0.059490688145160675\n",
      "Epoch 17 / 200 | iteration 160 / 171 | Total Loss: 2.452305793762207 | KNN Loss: 2.4017910957336426 | CLS Loss: 0.0505145825445652\n",
      "Epoch 17 / 200 | iteration 170 / 171 | Total Loss: 2.478137731552124 | KNN Loss: 2.408482789993286 | CLS Loss: 0.06965485960245132\n",
      "Epoch: 017, Loss: 2.4702, Train: 0.9854, Valid: 0.9821, Best: 0.9821\n",
      "Epoch 18 / 200 | iteration 0 / 171 | Total Loss: 2.5016071796417236 | KNN Loss: 2.4767584800720215 | CLS Loss: 0.024848658591508865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 200 | iteration 10 / 171 | Total Loss: 2.4552762508392334 | KNN Loss: 2.4185264110565186 | CLS Loss: 0.03674991801381111\n",
      "Epoch 18 / 200 | iteration 20 / 171 | Total Loss: 2.494626998901367 | KNN Loss: 2.4380931854248047 | CLS Loss: 0.05653371661901474\n",
      "Epoch 18 / 200 | iteration 30 / 171 | Total Loss: 2.4752871990203857 | KNN Loss: 2.4012084007263184 | CLS Loss: 0.07407869398593903\n",
      "Epoch 18 / 200 | iteration 40 / 171 | Total Loss: 2.440117597579956 | KNN Loss: 2.378377914428711 | CLS Loss: 0.0617397204041481\n",
      "Epoch 18 / 200 | iteration 50 / 171 | Total Loss: 2.45060133934021 | KNN Loss: 2.3973543643951416 | CLS Loss: 0.05324699729681015\n",
      "Epoch 18 / 200 | iteration 60 / 171 | Total Loss: 2.4633748531341553 | KNN Loss: 2.388291597366333 | CLS Loss: 0.07508321106433868\n",
      "Epoch 18 / 200 | iteration 70 / 171 | Total Loss: 2.4639015197753906 | KNN Loss: 2.3991198539733887 | CLS Loss: 0.06478168070316315\n",
      "Epoch 18 / 200 | iteration 80 / 171 | Total Loss: 2.5040483474731445 | KNN Loss: 2.4319491386413574 | CLS Loss: 0.0720992237329483\n",
      "Epoch 18 / 200 | iteration 90 / 171 | Total Loss: 2.449326276779175 | KNN Loss: 2.4090561866760254 | CLS Loss: 0.040270086377859116\n",
      "Epoch 18 / 200 | iteration 100 / 171 | Total Loss: 2.4464197158813477 | KNN Loss: 2.3884780406951904 | CLS Loss: 0.05794178321957588\n",
      "Epoch 18 / 200 | iteration 110 / 171 | Total Loss: 2.4501235485076904 | KNN Loss: 2.3915905952453613 | CLS Loss: 0.05853283777832985\n",
      "Epoch 18 / 200 | iteration 120 / 171 | Total Loss: 2.4789843559265137 | KNN Loss: 2.4359843730926514 | CLS Loss: 0.04300006851553917\n",
      "Epoch 18 / 200 | iteration 130 / 171 | Total Loss: 2.4726674556732178 | KNN Loss: 2.439847230911255 | CLS Loss: 0.032820116728544235\n",
      "Epoch 18 / 200 | iteration 140 / 171 | Total Loss: 2.4663681983947754 | KNN Loss: 2.3843741416931152 | CLS Loss: 0.08199408650398254\n",
      "Epoch 18 / 200 | iteration 150 / 171 | Total Loss: 2.4816644191741943 | KNN Loss: 2.3979849815368652 | CLS Loss: 0.08367946743965149\n",
      "Epoch 18 / 200 | iteration 160 / 171 | Total Loss: 2.4838626384735107 | KNN Loss: 2.433640241622925 | CLS Loss: 0.050222452729940414\n",
      "Epoch 18 / 200 | iteration 170 / 171 | Total Loss: 2.4738173484802246 | KNN Loss: 2.3902781009674072 | CLS Loss: 0.08353926241397858\n",
      "Epoch: 018, Loss: 2.4646, Train: 0.9869, Valid: 0.9830, Best: 0.9830\n",
      "Epoch 19 / 200 | iteration 0 / 171 | Total Loss: 2.4728586673736572 | KNN Loss: 2.4186460971832275 | CLS Loss: 0.05421266704797745\n",
      "Epoch 19 / 200 | iteration 10 / 171 | Total Loss: 2.441432237625122 | KNN Loss: 2.388981819152832 | CLS Loss: 0.052450332790613174\n",
      "Epoch 19 / 200 | iteration 20 / 171 | Total Loss: 2.4539318084716797 | KNN Loss: 2.3855090141296387 | CLS Loss: 0.06842271238565445\n",
      "Epoch 19 / 200 | iteration 30 / 171 | Total Loss: 2.41511607170105 | KNN Loss: 2.4018118381500244 | CLS Loss: 0.013304281048476696\n",
      "Epoch 19 / 200 | iteration 40 / 171 | Total Loss: 2.438969373703003 | KNN Loss: 2.3758134841918945 | CLS Loss: 0.06315585225820541\n",
      "Epoch 19 / 200 | iteration 50 / 171 | Total Loss: 2.529773473739624 | KNN Loss: 2.4099788665771484 | CLS Loss: 0.11979465186595917\n",
      "Epoch 19 / 200 | iteration 60 / 171 | Total Loss: 2.5287697315216064 | KNN Loss: 2.4599287509918213 | CLS Loss: 0.06884105503559113\n",
      "Epoch 19 / 200 | iteration 70 / 171 | Total Loss: 2.4673616886138916 | KNN Loss: 2.442516803741455 | CLS Loss: 0.02484492026269436\n",
      "Epoch 19 / 200 | iteration 80 / 171 | Total Loss: 2.448880672454834 | KNN Loss: 2.420912742614746 | CLS Loss: 0.027968009933829308\n",
      "Epoch 19 / 200 | iteration 90 / 171 | Total Loss: 2.476789951324463 | KNN Loss: 2.419842481613159 | CLS Loss: 0.056947529315948486\n",
      "Epoch 19 / 200 | iteration 100 / 171 | Total Loss: 2.4369590282440186 | KNN Loss: 2.414742946624756 | CLS Loss: 0.02221607230603695\n",
      "Epoch 19 / 200 | iteration 110 / 171 | Total Loss: 2.4793050289154053 | KNN Loss: 2.404777765274048 | CLS Loss: 0.07452727109193802\n",
      "Epoch 19 / 200 | iteration 120 / 171 | Total Loss: 2.491672992706299 | KNN Loss: 2.4341647624969482 | CLS Loss: 0.05750823765993118\n",
      "Epoch 19 / 200 | iteration 130 / 171 | Total Loss: 2.4328231811523438 | KNN Loss: 2.386890172958374 | CLS Loss: 0.04593311622738838\n",
      "Epoch 19 / 200 | iteration 140 / 171 | Total Loss: 2.447690963745117 | KNN Loss: 2.4162728786468506 | CLS Loss: 0.03141811862587929\n",
      "Epoch 19 / 200 | iteration 150 / 171 | Total Loss: 2.475989818572998 | KNN Loss: 2.423752546310425 | CLS Loss: 0.0522373802959919\n",
      "Epoch 19 / 200 | iteration 160 / 171 | Total Loss: 2.4474241733551025 | KNN Loss: 2.3882553577423096 | CLS Loss: 0.05916886031627655\n",
      "Epoch 19 / 200 | iteration 170 / 171 | Total Loss: 2.501530170440674 | KNN Loss: 2.4497263431549072 | CLS Loss: 0.05180380120873451\n",
      "Epoch: 019, Loss: 2.4593, Train: 0.9879, Valid: 0.9831, Best: 0.9831\n",
      "Epoch 20 / 200 | iteration 0 / 171 | Total Loss: 2.459660053253174 | KNN Loss: 2.4035818576812744 | CLS Loss: 0.056078214198350906\n",
      "Epoch 20 / 200 | iteration 10 / 171 | Total Loss: 2.4813144207000732 | KNN Loss: 2.402010202407837 | CLS Loss: 0.07930411398410797\n",
      "Epoch 20 / 200 | iteration 20 / 171 | Total Loss: 2.4624650478363037 | KNN Loss: 2.422044038772583 | CLS Loss: 0.04042097553610802\n",
      "Epoch 20 / 200 | iteration 30 / 171 | Total Loss: 2.464958667755127 | KNN Loss: 2.431889295578003 | CLS Loss: 0.033069267868995667\n",
      "Epoch 20 / 200 | iteration 40 / 171 | Total Loss: 2.485386371612549 | KNN Loss: 2.3913509845733643 | CLS Loss: 0.09403544664382935\n",
      "Epoch 20 / 200 | iteration 50 / 171 | Total Loss: 2.448779582977295 | KNN Loss: 2.4164886474609375 | CLS Loss: 0.03229095786809921\n",
      "Epoch 20 / 200 | iteration 60 / 171 | Total Loss: 2.4579339027404785 | KNN Loss: 2.414976119995117 | CLS Loss: 0.04295775294303894\n",
      "Epoch 20 / 200 | iteration 70 / 171 | Total Loss: 2.465399742126465 | KNN Loss: 2.4232475757598877 | CLS Loss: 0.042152270674705505\n",
      "Epoch 20 / 200 | iteration 80 / 171 | Total Loss: 2.458993673324585 | KNN Loss: 2.3971059322357178 | CLS Loss: 0.06188773736357689\n",
      "Epoch 20 / 200 | iteration 90 / 171 | Total Loss: 2.4043281078338623 | KNN Loss: 2.371807336807251 | CLS Loss: 0.03252079337835312\n",
      "Epoch 20 / 200 | iteration 100 / 171 | Total Loss: 2.4740474224090576 | KNN Loss: 2.4150753021240234 | CLS Loss: 0.05897219479084015\n",
      "Epoch 20 / 200 | iteration 110 / 171 | Total Loss: 2.4816644191741943 | KNN Loss: 2.3977737426757812 | CLS Loss: 0.08389066159725189\n",
      "Epoch 20 / 200 | iteration 120 / 171 | Total Loss: 2.402355670928955 | KNN Loss: 2.3731088638305664 | CLS Loss: 0.029246876016259193\n",
      "Epoch 20 / 200 | iteration 130 / 171 | Total Loss: 2.457089900970459 | KNN Loss: 2.3912136554718018 | CLS Loss: 0.06587623059749603\n",
      "Epoch 20 / 200 | iteration 140 / 171 | Total Loss: 2.4553401470184326 | KNN Loss: 2.4109535217285156 | CLS Loss: 0.044386688619852066\n",
      "Epoch 20 / 200 | iteration 150 / 171 | Total Loss: 2.4581146240234375 | KNN Loss: 2.3916826248168945 | CLS Loss: 0.06643187999725342\n",
      "Epoch 20 / 200 | iteration 160 / 171 | Total Loss: 2.4799673557281494 | KNN Loss: 2.431378126144409 | CLS Loss: 0.048589304089546204\n",
      "Epoch 20 / 200 | iteration 170 / 171 | Total Loss: 2.4427900314331055 | KNN Loss: 2.3927416801452637 | CLS Loss: 0.050048407167196274\n",
      "Epoch: 020, Loss: 2.4591, Train: 0.9863, Valid: 0.9824, Best: 0.9831\n",
      "Epoch 21 / 200 | iteration 0 / 171 | Total Loss: 2.484079122543335 | KNN Loss: 2.4381263256073 | CLS Loss: 0.04595271870493889\n",
      "Epoch 21 / 200 | iteration 10 / 171 | Total Loss: 2.4454190731048584 | KNN Loss: 2.425326108932495 | CLS Loss: 0.020093031227588654\n",
      "Epoch 21 / 200 | iteration 20 / 171 | Total Loss: 2.4678454399108887 | KNN Loss: 2.3995649814605713 | CLS Loss: 0.06828039884567261\n",
      "Epoch 21 / 200 | iteration 30 / 171 | Total Loss: 2.4805092811584473 | KNN Loss: 2.417496919631958 | CLS Loss: 0.06301234662532806\n",
      "Epoch 21 / 200 | iteration 40 / 171 | Total Loss: 2.4414713382720947 | KNN Loss: 2.3946104049682617 | CLS Loss: 0.04686090722680092\n",
      "Epoch 21 / 200 | iteration 50 / 171 | Total Loss: 2.43635892868042 | KNN Loss: 2.3947103023529053 | CLS Loss: 0.04164860025048256\n",
      "Epoch 21 / 200 | iteration 60 / 171 | Total Loss: 2.40175461769104 | KNN Loss: 2.37701153755188 | CLS Loss: 0.02474319189786911\n",
      "Epoch 21 / 200 | iteration 70 / 171 | Total Loss: 2.438448667526245 | KNN Loss: 2.3614063262939453 | CLS Loss: 0.07704227417707443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 200 | iteration 80 / 171 | Total Loss: 2.4143147468566895 | KNN Loss: 2.367396116256714 | CLS Loss: 0.046918682754039764\n",
      "Epoch 21 / 200 | iteration 90 / 171 | Total Loss: 2.436619281768799 | KNN Loss: 2.3937363624572754 | CLS Loss: 0.04288286715745926\n",
      "Epoch 21 / 200 | iteration 100 / 171 | Total Loss: 2.466261386871338 | KNN Loss: 2.3826353549957275 | CLS Loss: 0.08362608402967453\n",
      "Epoch 21 / 200 | iteration 110 / 171 | Total Loss: 2.4562079906463623 | KNN Loss: 2.3994433879852295 | CLS Loss: 0.05676458030939102\n",
      "Epoch 21 / 200 | iteration 120 / 171 | Total Loss: 2.4521865844726562 | KNN Loss: 2.413733720779419 | CLS Loss: 0.03845291957259178\n",
      "Epoch 21 / 200 | iteration 130 / 171 | Total Loss: 2.427682638168335 | KNN Loss: 2.398148775100708 | CLS Loss: 0.02953382395207882\n",
      "Epoch 21 / 200 | iteration 140 / 171 | Total Loss: 2.4180171489715576 | KNN Loss: 2.356450319290161 | CLS Loss: 0.06156686693429947\n",
      "Epoch 21 / 200 | iteration 150 / 171 | Total Loss: 2.4465363025665283 | KNN Loss: 2.4161880016326904 | CLS Loss: 0.030348241329193115\n",
      "Epoch 21 / 200 | iteration 160 / 171 | Total Loss: 2.482931137084961 | KNN Loss: 2.42622971534729 | CLS Loss: 0.056701455265283585\n",
      "Epoch 21 / 200 | iteration 170 / 171 | Total Loss: 2.436396598815918 | KNN Loss: 2.4026248455047607 | CLS Loss: 0.03377177193760872\n",
      "Epoch: 021, Loss: 2.4556, Train: 0.9869, Valid: 0.9832, Best: 0.9832\n",
      "Epoch 22 / 200 | iteration 0 / 171 | Total Loss: 2.4379236698150635 | KNN Loss: 2.4157512187957764 | CLS Loss: 0.02217254787683487\n",
      "Epoch 22 / 200 | iteration 10 / 171 | Total Loss: 2.455667734146118 | KNN Loss: 2.4347341060638428 | CLS Loss: 0.020933717489242554\n",
      "Epoch 22 / 200 | iteration 20 / 171 | Total Loss: 2.439077854156494 | KNN Loss: 2.405142068862915 | CLS Loss: 0.03393574059009552\n",
      "Epoch 22 / 200 | iteration 30 / 171 | Total Loss: 2.481360912322998 | KNN Loss: 2.4500415325164795 | CLS Loss: 0.03131943196058273\n",
      "Epoch 22 / 200 | iteration 40 / 171 | Total Loss: 2.4530141353607178 | KNN Loss: 2.391887903213501 | CLS Loss: 0.06112612783908844\n",
      "Epoch 22 / 200 | iteration 50 / 171 | Total Loss: 2.443328380584717 | KNN Loss: 2.3889052867889404 | CLS Loss: 0.05442306771874428\n",
      "Epoch 22 / 200 | iteration 60 / 171 | Total Loss: 2.444711685180664 | KNN Loss: 2.4135994911193848 | CLS Loss: 0.03111215867102146\n",
      "Epoch 22 / 200 | iteration 70 / 171 | Total Loss: 2.467989206314087 | KNN Loss: 2.4104251861572266 | CLS Loss: 0.05756411328911781\n",
      "Epoch 22 / 200 | iteration 80 / 171 | Total Loss: 2.4712741374969482 | KNN Loss: 2.3853397369384766 | CLS Loss: 0.08593448251485825\n",
      "Epoch 22 / 200 | iteration 90 / 171 | Total Loss: 2.4452950954437256 | KNN Loss: 2.4053144454956055 | CLS Loss: 0.03998064249753952\n",
      "Epoch 22 / 200 | iteration 100 / 171 | Total Loss: 2.465630531311035 | KNN Loss: 2.4153542518615723 | CLS Loss: 0.0502762645483017\n",
      "Epoch 22 / 200 | iteration 110 / 171 | Total Loss: 2.479020595550537 | KNN Loss: 2.4219279289245605 | CLS Loss: 0.05709271505475044\n",
      "Epoch 22 / 200 | iteration 120 / 171 | Total Loss: 2.4404027462005615 | KNN Loss: 2.4077117443084717 | CLS Loss: 0.03269089385867119\n",
      "Epoch 22 / 200 | iteration 130 / 171 | Total Loss: 2.4271910190582275 | KNN Loss: 2.391530752182007 | CLS Loss: 0.03566034510731697\n",
      "Epoch 22 / 200 | iteration 140 / 171 | Total Loss: 2.447723388671875 | KNN Loss: 2.394622564315796 | CLS Loss: 0.0531008318066597\n",
      "Epoch 22 / 200 | iteration 150 / 171 | Total Loss: 2.4638571739196777 | KNN Loss: 2.3891289234161377 | CLS Loss: 0.07472816854715347\n",
      "Epoch 22 / 200 | iteration 160 / 171 | Total Loss: 2.4602553844451904 | KNN Loss: 2.391282558441162 | CLS Loss: 0.06897292286157608\n",
      "Epoch 22 / 200 | iteration 170 / 171 | Total Loss: 2.4880242347717285 | KNN Loss: 2.41467547416687 | CLS Loss: 0.073348768055439\n",
      "Epoch: 022, Loss: 2.4529, Train: 0.9878, Valid: 0.9831, Best: 0.9832\n",
      "Epoch 23 / 200 | iteration 0 / 171 | Total Loss: 2.4628050327301025 | KNN Loss: 2.4243226051330566 | CLS Loss: 0.03848234564065933\n",
      "Epoch 23 / 200 | iteration 10 / 171 | Total Loss: 2.479637861251831 | KNN Loss: 2.407655715942383 | CLS Loss: 0.07198222726583481\n",
      "Epoch 23 / 200 | iteration 20 / 171 | Total Loss: 2.443298816680908 | KNN Loss: 2.413668394088745 | CLS Loss: 0.029630325734615326\n",
      "Epoch 23 / 200 | iteration 30 / 171 | Total Loss: 2.4517877101898193 | KNN Loss: 2.4138121604919434 | CLS Loss: 0.0379755012691021\n",
      "Epoch 23 / 200 | iteration 40 / 171 | Total Loss: 2.4672627449035645 | KNN Loss: 2.408426523208618 | CLS Loss: 0.05883628875017166\n",
      "Epoch 23 / 200 | iteration 50 / 171 | Total Loss: 2.4683401584625244 | KNN Loss: 2.417628765106201 | CLS Loss: 0.050711508840322495\n",
      "Epoch 23 / 200 | iteration 60 / 171 | Total Loss: 2.413677215576172 | KNN Loss: 2.381627082824707 | CLS Loss: 0.032050177454948425\n",
      "Epoch 23 / 200 | iteration 70 / 171 | Total Loss: 2.409472703933716 | KNN Loss: 2.378779649734497 | CLS Loss: 0.03069305419921875\n",
      "Epoch 23 / 200 | iteration 80 / 171 | Total Loss: 2.4092180728912354 | KNN Loss: 2.356015920639038 | CLS Loss: 0.053202107548713684\n",
      "Epoch 23 / 200 | iteration 90 / 171 | Total Loss: 2.447262763977051 | KNN Loss: 2.378584623336792 | CLS Loss: 0.06867805868387222\n",
      "Epoch 23 / 200 | iteration 100 / 171 | Total Loss: 2.4656572341918945 | KNN Loss: 2.4219155311584473 | CLS Loss: 0.04374178126454353\n",
      "Epoch 23 / 200 | iteration 110 / 171 | Total Loss: 2.441007137298584 | KNN Loss: 2.3824732303619385 | CLS Loss: 0.05853397399187088\n",
      "Epoch 23 / 200 | iteration 120 / 171 | Total Loss: 2.4712135791778564 | KNN Loss: 2.426219940185547 | CLS Loss: 0.044993747025728226\n",
      "Epoch 23 / 200 | iteration 130 / 171 | Total Loss: 2.448458671569824 | KNN Loss: 2.405101776123047 | CLS Loss: 0.04335697367787361\n",
      "Epoch 23 / 200 | iteration 140 / 171 | Total Loss: 2.4594340324401855 | KNN Loss: 2.415595769882202 | CLS Loss: 0.04383831471204758\n",
      "Epoch 23 / 200 | iteration 150 / 171 | Total Loss: 2.4760091304779053 | KNN Loss: 2.4040660858154297 | CLS Loss: 0.07194309681653976\n",
      "Epoch 23 / 200 | iteration 160 / 171 | Total Loss: 2.4558517932891846 | KNN Loss: 2.399313449859619 | CLS Loss: 0.05653829127550125\n",
      "Epoch 23 / 200 | iteration 170 / 171 | Total Loss: 2.4657225608825684 | KNN Loss: 2.4286577701568604 | CLS Loss: 0.03706488758325577\n",
      "Epoch: 023, Loss: 2.4508, Train: 0.9877, Valid: 0.9841, Best: 0.9841\n",
      "Epoch 24 / 200 | iteration 0 / 171 | Total Loss: 2.480329751968384 | KNN Loss: 2.426983594894409 | CLS Loss: 0.053346142172813416\n",
      "Epoch 24 / 200 | iteration 10 / 171 | Total Loss: 2.4149587154388428 | KNN Loss: 2.377012014389038 | CLS Loss: 0.03794669359922409\n",
      "Epoch 24 / 200 | iteration 20 / 171 | Total Loss: 2.475363254547119 | KNN Loss: 2.4382402896881104 | CLS Loss: 0.03712284564971924\n",
      "Epoch 24 / 200 | iteration 30 / 171 | Total Loss: 2.4166557788848877 | KNN Loss: 2.378483772277832 | CLS Loss: 0.03817203268408775\n",
      "Epoch 24 / 200 | iteration 40 / 171 | Total Loss: 2.4561212062835693 | KNN Loss: 2.398364782333374 | CLS Loss: 0.057756319642066956\n",
      "Epoch 24 / 200 | iteration 50 / 171 | Total Loss: 2.474337100982666 | KNN Loss: 2.4034132957458496 | CLS Loss: 0.07092369347810745\n",
      "Epoch 24 / 200 | iteration 60 / 171 | Total Loss: 2.474513292312622 | KNN Loss: 2.4391863346099854 | CLS Loss: 0.035326987504959106\n",
      "Epoch 24 / 200 | iteration 70 / 171 | Total Loss: 2.4314751625061035 | KNN Loss: 2.3691577911376953 | CLS Loss: 0.06231747195124626\n",
      "Epoch 24 / 200 | iteration 80 / 171 | Total Loss: 2.4390928745269775 | KNN Loss: 2.4029715061187744 | CLS Loss: 0.03612127527594566\n",
      "Epoch 24 / 200 | iteration 90 / 171 | Total Loss: 2.425652027130127 | KNN Loss: 2.382294178009033 | CLS Loss: 0.043357767164707184\n",
      "Epoch 24 / 200 | iteration 100 / 171 | Total Loss: 2.4176108837127686 | KNN Loss: 2.3673834800720215 | CLS Loss: 0.050227418541908264\n",
      "Epoch 24 / 200 | iteration 110 / 171 | Total Loss: 2.434246301651001 | KNN Loss: 2.3950650691986084 | CLS Loss: 0.03918119892477989\n",
      "Epoch 24 / 200 | iteration 120 / 171 | Total Loss: 2.454075574874878 | KNN Loss: 2.403155565261841 | CLS Loss: 0.05091994255781174\n",
      "Epoch 24 / 200 | iteration 130 / 171 | Total Loss: 2.4581921100616455 | KNN Loss: 2.398491859436035 | CLS Loss: 0.05970028042793274\n",
      "Epoch 24 / 200 | iteration 140 / 171 | Total Loss: 2.4383351802825928 | KNN Loss: 2.373779058456421 | CLS Loss: 0.06455618143081665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 200 | iteration 150 / 171 | Total Loss: 2.4299185276031494 | KNN Loss: 2.367173671722412 | CLS Loss: 0.06274493783712387\n",
      "Epoch 24 / 200 | iteration 160 / 171 | Total Loss: 2.4671168327331543 | KNN Loss: 2.4222846031188965 | CLS Loss: 0.044832292944192886\n",
      "Epoch 24 / 200 | iteration 170 / 171 | Total Loss: 2.41422176361084 | KNN Loss: 2.390052556991577 | CLS Loss: 0.02416921779513359\n",
      "Epoch: 024, Loss: 2.4477, Train: 0.9889, Valid: 0.9840, Best: 0.9841\n",
      "Epoch 25 / 200 | iteration 0 / 171 | Total Loss: 2.4431638717651367 | KNN Loss: 2.4172558784484863 | CLS Loss: 0.025907965376973152\n",
      "Epoch 25 / 200 | iteration 10 / 171 | Total Loss: 2.4306464195251465 | KNN Loss: 2.3835816383361816 | CLS Loss: 0.04706469550728798\n",
      "Epoch 25 / 200 | iteration 20 / 171 | Total Loss: 2.469083547592163 | KNN Loss: 2.4303953647613525 | CLS Loss: 0.038688212633132935\n",
      "Epoch 25 / 200 | iteration 30 / 171 | Total Loss: 2.503422737121582 | KNN Loss: 2.439587354660034 | CLS Loss: 0.06383540481328964\n",
      "Epoch 25 / 200 | iteration 40 / 171 | Total Loss: 2.4536802768707275 | KNN Loss: 2.410264492034912 | CLS Loss: 0.04341568052768707\n",
      "Epoch 25 / 200 | iteration 50 / 171 | Total Loss: 2.5174314975738525 | KNN Loss: 2.4679951667785645 | CLS Loss: 0.0494362935423851\n",
      "Epoch 25 / 200 | iteration 60 / 171 | Total Loss: 2.412350654602051 | KNN Loss: 2.3603293895721436 | CLS Loss: 0.05202121287584305\n",
      "Epoch 25 / 200 | iteration 70 / 171 | Total Loss: 2.486492395401001 | KNN Loss: 2.4286978244781494 | CLS Loss: 0.05779449641704559\n",
      "Epoch 25 / 200 | iteration 80 / 171 | Total Loss: 2.42539381980896 | KNN Loss: 2.4014899730682373 | CLS Loss: 0.02390395849943161\n",
      "Epoch 25 / 200 | iteration 90 / 171 | Total Loss: 2.429196834564209 | KNN Loss: 2.4007110595703125 | CLS Loss: 0.028485743328928947\n",
      "Epoch 25 / 200 | iteration 100 / 171 | Total Loss: 2.4247612953186035 | KNN Loss: 2.379852533340454 | CLS Loss: 0.044908877462148666\n",
      "Epoch 25 / 200 | iteration 110 / 171 | Total Loss: 2.4033191204071045 | KNN Loss: 2.35915470123291 | CLS Loss: 0.044164519757032394\n",
      "Epoch 25 / 200 | iteration 120 / 171 | Total Loss: 2.4298267364501953 | KNN Loss: 2.3708276748657227 | CLS Loss: 0.05899909511208534\n",
      "Epoch 25 / 200 | iteration 130 / 171 | Total Loss: 2.4435408115386963 | KNN Loss: 2.4094228744506836 | CLS Loss: 0.03411799296736717\n",
      "Epoch 25 / 200 | iteration 140 / 171 | Total Loss: 2.4792027473449707 | KNN Loss: 2.4115865230560303 | CLS Loss: 0.06761612743139267\n",
      "Epoch 25 / 200 | iteration 150 / 171 | Total Loss: 2.4382596015930176 | KNN Loss: 2.3854706287384033 | CLS Loss: 0.05278902128338814\n",
      "Epoch 25 / 200 | iteration 160 / 171 | Total Loss: 2.456996202468872 | KNN Loss: 2.3883142471313477 | CLS Loss: 0.06868200749158859\n",
      "Epoch 25 / 200 | iteration 170 / 171 | Total Loss: 2.4243314266204834 | KNN Loss: 2.391467571258545 | CLS Loss: 0.032863907516002655\n",
      "Epoch: 025, Loss: 2.4502, Train: 0.9882, Valid: 0.9843, Best: 0.9843\n",
      "Epoch 26 / 200 | iteration 0 / 171 | Total Loss: 2.4119834899902344 | KNN Loss: 2.388730525970459 | CLS Loss: 0.023252924904227257\n",
      "Epoch 26 / 200 | iteration 10 / 171 | Total Loss: 2.4201951026916504 | KNN Loss: 2.3956820964813232 | CLS Loss: 0.02451302297413349\n",
      "Epoch 26 / 200 | iteration 20 / 171 | Total Loss: 2.4333598613739014 | KNN Loss: 2.4158833026885986 | CLS Loss: 0.017476534470915794\n",
      "Epoch 26 / 200 | iteration 30 / 171 | Total Loss: 2.5023162364959717 | KNN Loss: 2.4384925365448 | CLS Loss: 0.06382369250059128\n",
      "Epoch 26 / 200 | iteration 40 / 171 | Total Loss: 2.48539137840271 | KNN Loss: 2.419520616531372 | CLS Loss: 0.06587068736553192\n",
      "Epoch 26 / 200 | iteration 50 / 171 | Total Loss: 2.4626827239990234 | KNN Loss: 2.4083139896392822 | CLS Loss: 0.054368726909160614\n",
      "Epoch 26 / 200 | iteration 60 / 171 | Total Loss: 2.441289186477661 | KNN Loss: 2.3864874839782715 | CLS Loss: 0.05480170622467995\n",
      "Epoch 26 / 200 | iteration 70 / 171 | Total Loss: 2.433424711227417 | KNN Loss: 2.405978202819824 | CLS Loss: 0.027446461841464043\n",
      "Epoch 26 / 200 | iteration 80 / 171 | Total Loss: 2.437225580215454 | KNN Loss: 2.3873941898345947 | CLS Loss: 0.049831323325634\n",
      "Epoch 26 / 200 | iteration 90 / 171 | Total Loss: 2.4360971450805664 | KNN Loss: 2.4110820293426514 | CLS Loss: 0.02501513995230198\n",
      "Epoch 26 / 200 | iteration 100 / 171 | Total Loss: 2.4817240238189697 | KNN Loss: 2.4061787128448486 | CLS Loss: 0.07554523646831512\n",
      "Epoch 26 / 200 | iteration 110 / 171 | Total Loss: 2.4230709075927734 | KNN Loss: 2.3849968910217285 | CLS Loss: 0.03807399049401283\n",
      "Epoch 26 / 200 | iteration 120 / 171 | Total Loss: 2.435581684112549 | KNN Loss: 2.3749256134033203 | CLS Loss: 0.06065617874264717\n",
      "Epoch 26 / 200 | iteration 130 / 171 | Total Loss: 2.4205498695373535 | KNN Loss: 2.399517774581909 | CLS Loss: 0.02103198505938053\n",
      "Epoch 26 / 200 | iteration 140 / 171 | Total Loss: 2.447995185852051 | KNN Loss: 2.388582468032837 | CLS Loss: 0.05941268801689148\n",
      "Epoch 26 / 200 | iteration 150 / 171 | Total Loss: 2.4254722595214844 | KNN Loss: 2.386604070663452 | CLS Loss: 0.03886822611093521\n",
      "Epoch 26 / 200 | iteration 160 / 171 | Total Loss: 2.4440951347351074 | KNN Loss: 2.3978397846221924 | CLS Loss: 0.04625523090362549\n",
      "Epoch 26 / 200 | iteration 170 / 171 | Total Loss: 2.415618896484375 | KNN Loss: 2.385258197784424 | CLS Loss: 0.03036079742014408\n",
      "Epoch: 026, Loss: 2.4463, Train: 0.9882, Valid: 0.9846, Best: 0.9846\n",
      "Epoch 27 / 200 | iteration 0 / 171 | Total Loss: 2.444971799850464 | KNN Loss: 2.40704345703125 | CLS Loss: 0.03792830556631088\n",
      "Epoch 27 / 200 | iteration 10 / 171 | Total Loss: 2.4325201511383057 | KNN Loss: 2.3866982460021973 | CLS Loss: 0.04582188278436661\n",
      "Epoch 27 / 200 | iteration 20 / 171 | Total Loss: 2.424367666244507 | KNN Loss: 2.3886687755584717 | CLS Loss: 0.0356987789273262\n",
      "Epoch 27 / 200 | iteration 30 / 171 | Total Loss: 2.4568629264831543 | KNN Loss: 2.3803720474243164 | CLS Loss: 0.0764908641576767\n",
      "Epoch 27 / 200 | iteration 40 / 171 | Total Loss: 2.4392924308776855 | KNN Loss: 2.3804726600646973 | CLS Loss: 0.058819692581892014\n",
      "Epoch 27 / 200 | iteration 50 / 171 | Total Loss: 2.4498214721679688 | KNN Loss: 2.391766309738159 | CLS Loss: 0.05805515497922897\n",
      "Epoch 27 / 200 | iteration 60 / 171 | Total Loss: 2.447347640991211 | KNN Loss: 2.4140784740448 | CLS Loss: 0.033269062638282776\n",
      "Epoch 27 / 200 | iteration 70 / 171 | Total Loss: 2.4493789672851562 | KNN Loss: 2.406663656234741 | CLS Loss: 0.042715203016996384\n",
      "Epoch 27 / 200 | iteration 80 / 171 | Total Loss: 2.456112861633301 | KNN Loss: 2.4179494380950928 | CLS Loss: 0.038163430988788605\n",
      "Epoch 27 / 200 | iteration 90 / 171 | Total Loss: 2.4495534896850586 | KNN Loss: 2.4146642684936523 | CLS Loss: 0.034889329224824905\n",
      "Epoch 27 / 200 | iteration 100 / 171 | Total Loss: 2.4437832832336426 | KNN Loss: 2.414486885070801 | CLS Loss: 0.02929650992155075\n",
      "Epoch 27 / 200 | iteration 110 / 171 | Total Loss: 2.4404296875 | KNN Loss: 2.4005961418151855 | CLS Loss: 0.03983357921242714\n",
      "Epoch 27 / 200 | iteration 120 / 171 | Total Loss: 2.406151294708252 | KNN Loss: 2.3817708492279053 | CLS Loss: 0.02438053861260414\n",
      "Epoch 27 / 200 | iteration 130 / 171 | Total Loss: 2.4146647453308105 | KNN Loss: 2.380917549133301 | CLS Loss: 0.03374718502163887\n",
      "Epoch 27 / 200 | iteration 140 / 171 | Total Loss: 2.439659357070923 | KNN Loss: 2.382500410079956 | CLS Loss: 0.0571589432656765\n",
      "Epoch 27 / 200 | iteration 150 / 171 | Total Loss: 2.442903995513916 | KNN Loss: 2.4185678958892822 | CLS Loss: 0.02433609403669834\n",
      "Epoch 27 / 200 | iteration 160 / 171 | Total Loss: 2.40842866897583 | KNN Loss: 2.3797924518585205 | CLS Loss: 0.028636327013373375\n",
      "Epoch 27 / 200 | iteration 170 / 171 | Total Loss: 2.4372971057891846 | KNN Loss: 2.3907508850097656 | CLS Loss: 0.0465463362634182\n",
      "Epoch: 027, Loss: 2.4442, Train: 0.9889, Valid: 0.9839, Best: 0.9846\n",
      "Epoch 28 / 200 | iteration 0 / 171 | Total Loss: 2.44490909576416 | KNN Loss: 2.4193015098571777 | CLS Loss: 0.02560761198401451\n",
      "Epoch 28 / 200 | iteration 10 / 171 | Total Loss: 2.4471688270568848 | KNN Loss: 2.4280381202697754 | CLS Loss: 0.01913079060614109\n",
      "Epoch 28 / 200 | iteration 20 / 171 | Total Loss: 2.4639604091644287 | KNN Loss: 2.412304401397705 | CLS Loss: 0.05165607109665871\n",
      "Epoch 28 / 200 | iteration 30 / 171 | Total Loss: 2.460287094116211 | KNN Loss: 2.3917713165283203 | CLS Loss: 0.06851577013731003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 200 | iteration 40 / 171 | Total Loss: 2.4749159812927246 | KNN Loss: 2.421358585357666 | CLS Loss: 0.05355742946267128\n",
      "Epoch 28 / 200 | iteration 50 / 171 | Total Loss: 2.46362042427063 | KNN Loss: 2.4107449054718018 | CLS Loss: 0.05287555232644081\n",
      "Epoch 28 / 200 | iteration 60 / 171 | Total Loss: 2.4160211086273193 | KNN Loss: 2.3896467685699463 | CLS Loss: 0.02637444995343685\n",
      "Epoch 28 / 200 | iteration 70 / 171 | Total Loss: 2.4543700218200684 | KNN Loss: 2.4069278240203857 | CLS Loss: 0.04744216427206993\n",
      "Epoch 28 / 200 | iteration 80 / 171 | Total Loss: 2.4510867595672607 | KNN Loss: 2.4124388694763184 | CLS Loss: 0.03864789009094238\n",
      "Epoch 28 / 200 | iteration 90 / 171 | Total Loss: 2.469883918762207 | KNN Loss: 2.439171075820923 | CLS Loss: 0.030712760984897614\n",
      "Epoch 28 / 200 | iteration 100 / 171 | Total Loss: 2.4902870655059814 | KNN Loss: 2.364896535873413 | CLS Loss: 0.12539047002792358\n",
      "Epoch 28 / 200 | iteration 110 / 171 | Total Loss: 2.476637363433838 | KNN Loss: 2.4176928997039795 | CLS Loss: 0.058944541960954666\n",
      "Epoch 28 / 200 | iteration 120 / 171 | Total Loss: 2.4208245277404785 | KNN Loss: 2.3992464542388916 | CLS Loss: 0.02157812938094139\n",
      "Epoch 28 / 200 | iteration 130 / 171 | Total Loss: 2.4415173530578613 | KNN Loss: 2.414381742477417 | CLS Loss: 0.02713564597070217\n",
      "Epoch 28 / 200 | iteration 140 / 171 | Total Loss: 2.470351457595825 | KNN Loss: 2.3969013690948486 | CLS Loss: 0.07344997674226761\n",
      "Epoch 28 / 200 | iteration 150 / 171 | Total Loss: 2.416306972503662 | KNN Loss: 2.398874044418335 | CLS Loss: 0.017433015629649162\n",
      "Epoch 28 / 200 | iteration 160 / 171 | Total Loss: 2.478816509246826 | KNN Loss: 2.4425785541534424 | CLS Loss: 0.0362379364669323\n",
      "Epoch 28 / 200 | iteration 170 / 171 | Total Loss: 2.454261541366577 | KNN Loss: 2.4130985736846924 | CLS Loss: 0.04116290435194969\n",
      "Epoch: 028, Loss: 2.4491, Train: 0.9865, Valid: 0.9814, Best: 0.9846\n",
      "Epoch 29 / 200 | iteration 0 / 171 | Total Loss: 2.433103084564209 | KNN Loss: 2.3725082874298096 | CLS Loss: 0.06059480458498001\n",
      "Epoch 29 / 200 | iteration 10 / 171 | Total Loss: 2.4268689155578613 | KNN Loss: 2.3895864486694336 | CLS Loss: 0.037282586097717285\n",
      "Epoch 29 / 200 | iteration 20 / 171 | Total Loss: 2.4252097606658936 | KNN Loss: 2.3764500617980957 | CLS Loss: 0.04875972867012024\n",
      "Epoch 29 / 200 | iteration 30 / 171 | Total Loss: 2.391807794570923 | KNN Loss: 2.365394353866577 | CLS Loss: 0.026413483545184135\n",
      "Epoch 29 / 200 | iteration 40 / 171 | Total Loss: 2.517444610595703 | KNN Loss: 2.4350385665893555 | CLS Loss: 0.08240610361099243\n",
      "Epoch 29 / 200 | iteration 50 / 171 | Total Loss: 2.4216148853302 | KNN Loss: 2.3981025218963623 | CLS Loss: 0.0235124658793211\n",
      "Epoch 29 / 200 | iteration 60 / 171 | Total Loss: 2.439159870147705 | KNN Loss: 2.388840913772583 | CLS Loss: 0.050318896770477295\n",
      "Epoch 29 / 200 | iteration 70 / 171 | Total Loss: 2.426708936691284 | KNN Loss: 2.377720832824707 | CLS Loss: 0.04898817837238312\n",
      "Epoch 29 / 200 | iteration 80 / 171 | Total Loss: 2.4491374492645264 | KNN Loss: 2.412599802017212 | CLS Loss: 0.03653758019208908\n",
      "Epoch 29 / 200 | iteration 90 / 171 | Total Loss: 2.453063726425171 | KNN Loss: 2.4085724353790283 | CLS Loss: 0.044491302222013474\n",
      "Epoch 29 / 200 | iteration 100 / 171 | Total Loss: 2.4734010696411133 | KNN Loss: 2.404886245727539 | CLS Loss: 0.06851478666067123\n",
      "Epoch 29 / 200 | iteration 110 / 171 | Total Loss: 2.4456772804260254 | KNN Loss: 2.371757984161377 | CLS Loss: 0.07391934096813202\n",
      "Epoch 29 / 200 | iteration 120 / 171 | Total Loss: 2.507737874984741 | KNN Loss: 2.461317777633667 | CLS Loss: 0.04642002657055855\n",
      "Epoch 29 / 200 | iteration 130 / 171 | Total Loss: 2.4588465690612793 | KNN Loss: 2.390688180923462 | CLS Loss: 0.06815831363201141\n",
      "Epoch 29 / 200 | iteration 140 / 171 | Total Loss: 2.4245803356170654 | KNN Loss: 2.3839502334594727 | CLS Loss: 0.04063021019101143\n",
      "Epoch 29 / 200 | iteration 150 / 171 | Total Loss: 2.450103759765625 | KNN Loss: 2.401654005050659 | CLS Loss: 0.04844972863793373\n",
      "Epoch 29 / 200 | iteration 160 / 171 | Total Loss: 2.424189805984497 | KNN Loss: 2.374258279800415 | CLS Loss: 0.04993145167827606\n",
      "Epoch 29 / 200 | iteration 170 / 171 | Total Loss: 2.4377658367156982 | KNN Loss: 2.392141580581665 | CLS Loss: 0.045624155551195145\n",
      "Epoch: 029, Loss: 2.4435, Train: 0.9897, Valid: 0.9844, Best: 0.9846\n",
      "Epoch 30 / 200 | iteration 0 / 171 | Total Loss: 2.445342540740967 | KNN Loss: 2.413785457611084 | CLS Loss: 0.03155699744820595\n",
      "Epoch 30 / 200 | iteration 10 / 171 | Total Loss: 2.4812629222869873 | KNN Loss: 2.4286274909973145 | CLS Loss: 0.05263547599315643\n",
      "Epoch 30 / 200 | iteration 20 / 171 | Total Loss: 2.4632012844085693 | KNN Loss: 2.40299129486084 | CLS Loss: 0.06020990386605263\n",
      "Epoch 30 / 200 | iteration 30 / 171 | Total Loss: 2.413398027420044 | KNN Loss: 2.369335651397705 | CLS Loss: 0.04406237229704857\n",
      "Epoch 30 / 200 | iteration 40 / 171 | Total Loss: 2.4108622074127197 | KNN Loss: 2.374851942062378 | CLS Loss: 0.0360102578997612\n",
      "Epoch 30 / 200 | iteration 50 / 171 | Total Loss: 2.469803810119629 | KNN Loss: 2.456629753112793 | CLS Loss: 0.013174080289900303\n",
      "Epoch 30 / 200 | iteration 60 / 171 | Total Loss: 2.4500203132629395 | KNN Loss: 2.4141433238983154 | CLS Loss: 0.03587710112333298\n",
      "Epoch 30 / 200 | iteration 70 / 171 | Total Loss: 2.4010863304138184 | KNN Loss: 2.3659050464630127 | CLS Loss: 0.03518126904964447\n",
      "Epoch 30 / 200 | iteration 80 / 171 | Total Loss: 2.399329662322998 | KNN Loss: 2.374772787094116 | CLS Loss: 0.02455677092075348\n",
      "Epoch 30 / 200 | iteration 90 / 171 | Total Loss: 2.420970916748047 | KNN Loss: 2.4086971282958984 | CLS Loss: 0.01227388996630907\n",
      "Epoch 30 / 200 | iteration 100 / 171 | Total Loss: 2.4153013229370117 | KNN Loss: 2.3766043186187744 | CLS Loss: 0.038696903735399246\n",
      "Epoch 30 / 200 | iteration 110 / 171 | Total Loss: 2.4297804832458496 | KNN Loss: 2.3852808475494385 | CLS Loss: 0.04449966922402382\n",
      "Epoch 30 / 200 | iteration 120 / 171 | Total Loss: 2.4869391918182373 | KNN Loss: 2.460366725921631 | CLS Loss: 0.02657245844602585\n",
      "Epoch 30 / 200 | iteration 130 / 171 | Total Loss: 2.424152135848999 | KNN Loss: 2.3938236236572266 | CLS Loss: 0.030328478664159775\n",
      "Epoch 30 / 200 | iteration 140 / 171 | Total Loss: 2.4417479038238525 | KNN Loss: 2.3870606422424316 | CLS Loss: 0.05468736216425896\n",
      "Epoch 30 / 200 | iteration 150 / 171 | Total Loss: 2.457886219024658 | KNN Loss: 2.4194140434265137 | CLS Loss: 0.03847210854291916\n",
      "Epoch 30 / 200 | iteration 160 / 171 | Total Loss: 2.4857969284057617 | KNN Loss: 2.4393651485443115 | CLS Loss: 0.04643166437745094\n",
      "Epoch 30 / 200 | iteration 170 / 171 | Total Loss: 2.436450719833374 | KNN Loss: 2.3993568420410156 | CLS Loss: 0.0370938703417778\n",
      "Epoch: 030, Loss: 2.4405, Train: 0.9906, Valid: 0.9857, Best: 0.9857\n",
      "Epoch 31 / 200 | iteration 0 / 171 | Total Loss: 2.4399983882904053 | KNN Loss: 2.359820604324341 | CLS Loss: 0.08017789572477341\n",
      "Epoch 31 / 200 | iteration 10 / 171 | Total Loss: 2.423380136489868 | KNN Loss: 2.401709794998169 | CLS Loss: 0.02167043462395668\n",
      "Epoch 31 / 200 | iteration 20 / 171 | Total Loss: 2.481100082397461 | KNN Loss: 2.4146010875701904 | CLS Loss: 0.06649897992610931\n",
      "Epoch 31 / 200 | iteration 30 / 171 | Total Loss: 2.416470766067505 | KNN Loss: 2.3908731937408447 | CLS Loss: 0.0255975890904665\n",
      "Epoch 31 / 200 | iteration 40 / 171 | Total Loss: 2.440747022628784 | KNN Loss: 2.397233486175537 | CLS Loss: 0.043513454496860504\n",
      "Epoch 31 / 200 | iteration 50 / 171 | Total Loss: 2.4419729709625244 | KNN Loss: 2.382533073425293 | CLS Loss: 0.05943991616368294\n",
      "Epoch 31 / 200 | iteration 60 / 171 | Total Loss: 2.4157776832580566 | KNN Loss: 2.3785829544067383 | CLS Loss: 0.03719482570886612\n",
      "Epoch 31 / 200 | iteration 70 / 171 | Total Loss: 2.468170642852783 | KNN Loss: 2.3848226070404053 | CLS Loss: 0.0833481028676033\n",
      "Epoch 31 / 200 | iteration 80 / 171 | Total Loss: 2.4696497917175293 | KNN Loss: 2.4076712131500244 | CLS Loss: 0.06197863444685936\n",
      "Epoch 31 / 200 | iteration 90 / 171 | Total Loss: 2.4533095359802246 | KNN Loss: 2.430731773376465 | CLS Loss: 0.022577721625566483\n",
      "Epoch 31 / 200 | iteration 100 / 171 | Total Loss: 2.4186129570007324 | KNN Loss: 2.3832173347473145 | CLS Loss: 0.03539564087986946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 200 | iteration 110 / 171 | Total Loss: 2.4378864765167236 | KNN Loss: 2.408557415008545 | CLS Loss: 0.0293289665132761\n",
      "Epoch 31 / 200 | iteration 120 / 171 | Total Loss: 2.42397403717041 | KNN Loss: 2.4074039459228516 | CLS Loss: 0.016570014879107475\n",
      "Epoch 31 / 200 | iteration 130 / 171 | Total Loss: 2.4283604621887207 | KNN Loss: 2.373887538909912 | CLS Loss: 0.05447299778461456\n",
      "Epoch 31 / 200 | iteration 140 / 171 | Total Loss: 2.4238345623016357 | KNN Loss: 2.387714385986328 | CLS Loss: 0.03612016886472702\n",
      "Epoch 31 / 200 | iteration 150 / 171 | Total Loss: 2.3981339931488037 | KNN Loss: 2.3370521068573 | CLS Loss: 0.06108184903860092\n",
      "Epoch 31 / 200 | iteration 160 / 171 | Total Loss: 2.4838526248931885 | KNN Loss: 2.450967311859131 | CLS Loss: 0.032885342836380005\n",
      "Epoch 31 / 200 | iteration 170 / 171 | Total Loss: 2.430816411972046 | KNN Loss: 2.388277053833008 | CLS Loss: 0.04253930225968361\n",
      "Epoch: 031, Loss: 2.4371, Train: 0.9897, Valid: 0.9843, Best: 0.9857\n",
      "Epoch 32 / 200 | iteration 0 / 171 | Total Loss: 2.471235513687134 | KNN Loss: 2.4340174198150635 | CLS Loss: 0.0372181162238121\n",
      "Epoch 32 / 200 | iteration 10 / 171 | Total Loss: 2.461615562438965 | KNN Loss: 2.445502281188965 | CLS Loss: 0.016113251447677612\n",
      "Epoch 32 / 200 | iteration 20 / 171 | Total Loss: 2.4448647499084473 | KNN Loss: 2.399005651473999 | CLS Loss: 0.045859210193157196\n",
      "Epoch 32 / 200 | iteration 30 / 171 | Total Loss: 2.4775092601776123 | KNN Loss: 2.4276692867279053 | CLS Loss: 0.049840014427900314\n",
      "Epoch 32 / 200 | iteration 40 / 171 | Total Loss: 2.415255069732666 | KNN Loss: 2.402897596359253 | CLS Loss: 0.012357553467154503\n",
      "Epoch 32 / 200 | iteration 50 / 171 | Total Loss: 2.420154333114624 | KNN Loss: 2.3936665058135986 | CLS Loss: 0.026487916707992554\n",
      "Epoch 32 / 200 | iteration 60 / 171 | Total Loss: 2.4693143367767334 | KNN Loss: 2.4189651012420654 | CLS Loss: 0.050349242985248566\n",
      "Epoch 32 / 200 | iteration 70 / 171 | Total Loss: 2.4820220470428467 | KNN Loss: 2.437269926071167 | CLS Loss: 0.044752221554517746\n",
      "Epoch 32 / 200 | iteration 80 / 171 | Total Loss: 2.439856767654419 | KNN Loss: 2.406606912612915 | CLS Loss: 0.03324991837143898\n",
      "Epoch 32 / 200 | iteration 90 / 171 | Total Loss: 2.4168989658355713 | KNN Loss: 2.3914670944213867 | CLS Loss: 0.025431916117668152\n",
      "Epoch 32 / 200 | iteration 100 / 171 | Total Loss: 2.410829544067383 | KNN Loss: 2.380859613418579 | CLS Loss: 0.029970038682222366\n",
      "Epoch 32 / 200 | iteration 110 / 171 | Total Loss: 2.4046974182128906 | KNN Loss: 2.381645441055298 | CLS Loss: 0.023051990196108818\n",
      "Epoch 32 / 200 | iteration 120 / 171 | Total Loss: 2.449707508087158 | KNN Loss: 2.4334909915924072 | CLS Loss: 0.016216492280364037\n",
      "Epoch 32 / 200 | iteration 130 / 171 | Total Loss: 2.478452444076538 | KNN Loss: 2.442375421524048 | CLS Loss: 0.03607696667313576\n",
      "Epoch 32 / 200 | iteration 140 / 171 | Total Loss: 2.471043825149536 | KNN Loss: 2.42745041847229 | CLS Loss: 0.043593429028987885\n",
      "Epoch 32 / 200 | iteration 150 / 171 | Total Loss: 2.433397054672241 | KNN Loss: 2.3895797729492188 | CLS Loss: 0.04381731525063515\n",
      "Epoch 32 / 200 | iteration 160 / 171 | Total Loss: 2.46049427986145 | KNN Loss: 2.41750168800354 | CLS Loss: 0.04299264773726463\n",
      "Epoch 32 / 200 | iteration 170 / 171 | Total Loss: 2.4097957611083984 | KNN Loss: 2.3685901165008545 | CLS Loss: 0.04120559245347977\n",
      "Epoch: 032, Loss: 2.4388, Train: 0.9902, Valid: 0.9859, Best: 0.9859\n",
      "Epoch 33 / 200 | iteration 0 / 171 | Total Loss: 2.4119701385498047 | KNN Loss: 2.3807222843170166 | CLS Loss: 0.031247835606336594\n",
      "Epoch 33 / 200 | iteration 10 / 171 | Total Loss: 2.395190954208374 | KNN Loss: 2.3561043739318848 | CLS Loss: 0.03908658027648926\n",
      "Epoch 33 / 200 | iteration 20 / 171 | Total Loss: 2.4211697578430176 | KNN Loss: 2.3883328437805176 | CLS Loss: 0.03283701092004776\n",
      "Epoch 33 / 200 | iteration 30 / 171 | Total Loss: 2.4391093254089355 | KNN Loss: 2.3874030113220215 | CLS Loss: 0.051706425845623016\n",
      "Epoch 33 / 200 | iteration 40 / 171 | Total Loss: 2.4313135147094727 | KNN Loss: 2.3962814807891846 | CLS Loss: 0.035032086074352264\n",
      "Epoch 33 / 200 | iteration 50 / 171 | Total Loss: 2.4247679710388184 | KNN Loss: 2.4008960723876953 | CLS Loss: 0.02387196756899357\n",
      "Epoch 33 / 200 | iteration 60 / 171 | Total Loss: 2.4281046390533447 | KNN Loss: 2.388230085372925 | CLS Loss: 0.039874590933322906\n",
      "Epoch 33 / 200 | iteration 70 / 171 | Total Loss: 2.4929916858673096 | KNN Loss: 2.4800009727478027 | CLS Loss: 0.012990734539926052\n",
      "Epoch 33 / 200 | iteration 80 / 171 | Total Loss: 2.4643752574920654 | KNN Loss: 2.4361255168914795 | CLS Loss: 0.02824976108968258\n",
      "Epoch 33 / 200 | iteration 90 / 171 | Total Loss: 2.457024097442627 | KNN Loss: 2.4073057174682617 | CLS Loss: 0.049718305468559265\n",
      "Epoch 33 / 200 | iteration 100 / 171 | Total Loss: 2.401904582977295 | KNN Loss: 2.3685429096221924 | CLS Loss: 0.033361729234457016\n",
      "Epoch 33 / 200 | iteration 110 / 171 | Total Loss: 2.4528467655181885 | KNN Loss: 2.420539140701294 | CLS Loss: 0.03230762109160423\n",
      "Epoch 33 / 200 | iteration 120 / 171 | Total Loss: 2.4083285331726074 | KNN Loss: 2.3772501945495605 | CLS Loss: 0.031078264117240906\n",
      "Epoch 33 / 200 | iteration 130 / 171 | Total Loss: 2.4178214073181152 | KNN Loss: 2.3652117252349854 | CLS Loss: 0.05260959267616272\n",
      "Epoch 33 / 200 | iteration 140 / 171 | Total Loss: 2.4270453453063965 | KNN Loss: 2.4017066955566406 | CLS Loss: 0.025338735431432724\n",
      "Epoch 33 / 200 | iteration 150 / 171 | Total Loss: 2.4430782794952393 | KNN Loss: 2.418177366256714 | CLS Loss: 0.024900885298848152\n",
      "Epoch 33 / 200 | iteration 160 / 171 | Total Loss: 2.426408052444458 | KNN Loss: 2.3519983291625977 | CLS Loss: 0.07440964132547379\n",
      "Epoch 33 / 200 | iteration 170 / 171 | Total Loss: 2.448253631591797 | KNN Loss: 2.4082746505737305 | CLS Loss: 0.03997909650206566\n",
      "Epoch: 033, Loss: 2.4366, Train: 0.9895, Valid: 0.9852, Best: 0.9859\n",
      "Epoch 34 / 200 | iteration 0 / 171 | Total Loss: 2.399502992630005 | KNN Loss: 2.3488621711730957 | CLS Loss: 0.050640713423490524\n",
      "Epoch 34 / 200 | iteration 10 / 171 | Total Loss: 2.400766372680664 | KNN Loss: 2.388005256652832 | CLS Loss: 0.012761090882122517\n",
      "Epoch 34 / 200 | iteration 20 / 171 | Total Loss: 2.4750328063964844 | KNN Loss: 2.441617488861084 | CLS Loss: 0.03341522067785263\n",
      "Epoch 34 / 200 | iteration 30 / 171 | Total Loss: 2.4378597736358643 | KNN Loss: 2.390000104904175 | CLS Loss: 0.047859761863946915\n",
      "Epoch 34 / 200 | iteration 40 / 171 | Total Loss: 2.466428518295288 | KNN Loss: 2.414067029953003 | CLS Loss: 0.05236159265041351\n",
      "Epoch 34 / 200 | iteration 50 / 171 | Total Loss: 2.429767370223999 | KNN Loss: 2.400723695755005 | CLS Loss: 0.02904372476041317\n",
      "Epoch 34 / 200 | iteration 60 / 171 | Total Loss: 2.443995237350464 | KNN Loss: 2.4165658950805664 | CLS Loss: 0.027429237961769104\n",
      "Epoch 34 / 200 | iteration 70 / 171 | Total Loss: 2.4652645587921143 | KNN Loss: 2.4323031902313232 | CLS Loss: 0.03296143189072609\n",
      "Epoch 34 / 200 | iteration 80 / 171 | Total Loss: 2.4576303958892822 | KNN Loss: 2.4066476821899414 | CLS Loss: 0.050982750952243805\n",
      "Epoch 34 / 200 | iteration 90 / 171 | Total Loss: 2.4524295330047607 | KNN Loss: 2.3982784748077393 | CLS Loss: 0.05415105074644089\n",
      "Epoch 34 / 200 | iteration 100 / 171 | Total Loss: 2.4396560192108154 | KNN Loss: 2.423938512802124 | CLS Loss: 0.015717534348368645\n",
      "Epoch 34 / 200 | iteration 110 / 171 | Total Loss: 2.465461492538452 | KNN Loss: 2.3966023921966553 | CLS Loss: 0.06885915994644165\n",
      "Epoch 34 / 200 | iteration 120 / 171 | Total Loss: 2.4284191131591797 | KNN Loss: 2.38594388961792 | CLS Loss: 0.04247530177235603\n",
      "Epoch 34 / 200 | iteration 130 / 171 | Total Loss: 2.403167247772217 | KNN Loss: 2.3763844966888428 | CLS Loss: 0.026782844215631485\n",
      "Epoch 34 / 200 | iteration 140 / 171 | Total Loss: 2.4258642196655273 | KNN Loss: 2.375246047973633 | CLS Loss: 0.05061815306544304\n",
      "Epoch 34 / 200 | iteration 150 / 171 | Total Loss: 2.464853525161743 | KNN Loss: 2.4001224040985107 | CLS Loss: 0.0647311881184578\n",
      "Epoch 34 / 200 | iteration 160 / 171 | Total Loss: 2.4384801387786865 | KNN Loss: 2.393604278564453 | CLS Loss: 0.044875867664813995\n",
      "Epoch 34 / 200 | iteration 170 / 171 | Total Loss: 2.399862766265869 | KNN Loss: 2.3764984607696533 | CLS Loss: 0.023364242166280746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 034, Loss: 2.4354, Train: 0.9912, Valid: 0.9857, Best: 0.9859\n",
      "Epoch 35 / 200 | iteration 0 / 171 | Total Loss: 2.4314017295837402 | KNN Loss: 2.416856288909912 | CLS Loss: 0.014545371755957603\n",
      "Epoch 35 / 200 | iteration 10 / 171 | Total Loss: 2.416207790374756 | KNN Loss: 2.38043212890625 | CLS Loss: 0.035775549709796906\n",
      "Epoch 35 / 200 | iteration 20 / 171 | Total Loss: 2.4131674766540527 | KNN Loss: 2.3559951782226562 | CLS Loss: 0.05717229098081589\n",
      "Epoch 35 / 200 | iteration 30 / 171 | Total Loss: 2.433051586151123 | KNN Loss: 2.4058895111083984 | CLS Loss: 0.0271621011197567\n",
      "Epoch 35 / 200 | iteration 40 / 171 | Total Loss: 2.4639055728912354 | KNN Loss: 2.4469003677368164 | CLS Loss: 0.01700526475906372\n",
      "Epoch 35 / 200 | iteration 50 / 171 | Total Loss: 2.4514620304107666 | KNN Loss: 2.4148125648498535 | CLS Loss: 0.03664937987923622\n",
      "Epoch 35 / 200 | iteration 60 / 171 | Total Loss: 2.4326627254486084 | KNN Loss: 2.394394636154175 | CLS Loss: 0.03826816752552986\n",
      "Epoch 35 / 200 | iteration 70 / 171 | Total Loss: 2.458697557449341 | KNN Loss: 2.4131579399108887 | CLS Loss: 0.04553953930735588\n",
      "Epoch 35 / 200 | iteration 80 / 171 | Total Loss: 2.4305901527404785 | KNN Loss: 2.3903021812438965 | CLS Loss: 0.040288008749485016\n",
      "Epoch 35 / 200 | iteration 90 / 171 | Total Loss: 2.455338716506958 | KNN Loss: 2.3851981163024902 | CLS Loss: 0.07014051824808121\n",
      "Epoch 35 / 200 | iteration 100 / 171 | Total Loss: 2.4250991344451904 | KNN Loss: 2.394282579421997 | CLS Loss: 0.03081652522087097\n",
      "Epoch 35 / 200 | iteration 110 / 171 | Total Loss: 2.444967269897461 | KNN Loss: 2.398967742919922 | CLS Loss: 0.04599940776824951\n",
      "Epoch 35 / 200 | iteration 120 / 171 | Total Loss: 2.423196315765381 | KNN Loss: 2.3783628940582275 | CLS Loss: 0.044833336025476456\n",
      "Epoch 35 / 200 | iteration 130 / 171 | Total Loss: 2.4179766178131104 | KNN Loss: 2.408043146133423 | CLS Loss: 0.009933373890817165\n",
      "Epoch 35 / 200 | iteration 140 / 171 | Total Loss: 2.4147229194641113 | KNN Loss: 2.401062250137329 | CLS Loss: 0.0136605529114604\n",
      "Epoch 35 / 200 | iteration 150 / 171 | Total Loss: 2.4272820949554443 | KNN Loss: 2.388765573501587 | CLS Loss: 0.03851650282740593\n",
      "Epoch 35 / 200 | iteration 160 / 171 | Total Loss: 2.3986527919769287 | KNN Loss: 2.356609582901001 | CLS Loss: 0.042043205350637436\n",
      "Epoch 35 / 200 | iteration 170 / 171 | Total Loss: 2.395468235015869 | KNN Loss: 2.374783992767334 | CLS Loss: 0.0206841342151165\n",
      "Epoch: 035, Loss: 2.4340, Train: 0.9912, Valid: 0.9854, Best: 0.9859\n",
      "Epoch 36 / 200 | iteration 0 / 171 | Total Loss: 2.4329402446746826 | KNN Loss: 2.407089948654175 | CLS Loss: 0.0258502047508955\n",
      "Epoch 36 / 200 | iteration 10 / 171 | Total Loss: 2.4000203609466553 | KNN Loss: 2.3754096031188965 | CLS Loss: 0.02461085096001625\n",
      "Epoch 36 / 200 | iteration 20 / 171 | Total Loss: 2.41591215133667 | KNN Loss: 2.3636786937713623 | CLS Loss: 0.05223335325717926\n",
      "Epoch 36 / 200 | iteration 30 / 171 | Total Loss: 2.4341819286346436 | KNN Loss: 2.4034652709960938 | CLS Loss: 0.030716555193066597\n",
      "Epoch 36 / 200 | iteration 40 / 171 | Total Loss: 2.4327733516693115 | KNN Loss: 2.3616957664489746 | CLS Loss: 0.07107768207788467\n",
      "Epoch 36 / 200 | iteration 50 / 171 | Total Loss: 2.3952627182006836 | KNN Loss: 2.3698885440826416 | CLS Loss: 0.02537405863404274\n",
      "Epoch 36 / 200 | iteration 60 / 171 | Total Loss: 2.4259002208709717 | KNN Loss: 2.403038263320923 | CLS Loss: 0.02286205254495144\n",
      "Epoch 36 / 200 | iteration 70 / 171 | Total Loss: 2.4807496070861816 | KNN Loss: 2.4530608654022217 | CLS Loss: 0.027688829228281975\n",
      "Epoch 36 / 200 | iteration 80 / 171 | Total Loss: 2.4221932888031006 | KNN Loss: 2.389329671859741 | CLS Loss: 0.0328635536134243\n",
      "Epoch 36 / 200 | iteration 90 / 171 | Total Loss: 2.467910051345825 | KNN Loss: 2.4203314781188965 | CLS Loss: 0.047578681260347366\n",
      "Epoch 36 / 200 | iteration 100 / 171 | Total Loss: 2.38904070854187 | KNN Loss: 2.3649518489837646 | CLS Loss: 0.02408885397017002\n",
      "Epoch 36 / 200 | iteration 110 / 171 | Total Loss: 2.4427905082702637 | KNN Loss: 2.3669540882110596 | CLS Loss: 0.07583645731210709\n",
      "Epoch 36 / 200 | iteration 120 / 171 | Total Loss: 2.443027973175049 | KNN Loss: 2.4160518646240234 | CLS Loss: 0.026976095512509346\n",
      "Epoch 36 / 200 | iteration 130 / 171 | Total Loss: 2.466529369354248 | KNN Loss: 2.4334559440612793 | CLS Loss: 0.03307347372174263\n",
      "Epoch 36 / 200 | iteration 140 / 171 | Total Loss: 2.4442193508148193 | KNN Loss: 2.398758888244629 | CLS Loss: 0.0454605333507061\n",
      "Epoch 36 / 200 | iteration 150 / 171 | Total Loss: 2.410121202468872 | KNN Loss: 2.36826491355896 | CLS Loss: 0.04185623303055763\n",
      "Epoch 36 / 200 | iteration 160 / 171 | Total Loss: 2.4348251819610596 | KNN Loss: 2.3930749893188477 | CLS Loss: 0.041750092059373856\n",
      "Epoch 36 / 200 | iteration 170 / 171 | Total Loss: 2.4490017890930176 | KNN Loss: 2.399552583694458 | CLS Loss: 0.04944925382733345\n",
      "Epoch: 036, Loss: 2.4340, Train: 0.9914, Valid: 0.9859, Best: 0.9859\n",
      "Epoch 37 / 200 | iteration 0 / 171 | Total Loss: 2.4173216819763184 | KNN Loss: 2.393563985824585 | CLS Loss: 0.0237576961517334\n",
      "Epoch 37 / 200 | iteration 10 / 171 | Total Loss: 2.420217514038086 | KNN Loss: 2.394092082977295 | CLS Loss: 0.02612542361021042\n",
      "Epoch 37 / 200 | iteration 20 / 171 | Total Loss: 2.4247825145721436 | KNN Loss: 2.39280366897583 | CLS Loss: 0.03197894245386124\n",
      "Epoch 37 / 200 | iteration 30 / 171 | Total Loss: 2.460580825805664 | KNN Loss: 2.378704786300659 | CLS Loss: 0.08187603950500488\n",
      "Epoch 37 / 200 | iteration 40 / 171 | Total Loss: 2.4022724628448486 | KNN Loss: 2.3859472274780273 | CLS Loss: 0.016325119882822037\n",
      "Epoch 37 / 200 | iteration 50 / 171 | Total Loss: 2.4695699214935303 | KNN Loss: 2.413062810897827 | CLS Loss: 0.05650715529918671\n",
      "Epoch 37 / 200 | iteration 60 / 171 | Total Loss: 2.401329278945923 | KNN Loss: 2.358381986618042 | CLS Loss: 0.042947329580783844\n",
      "Epoch 37 / 200 | iteration 70 / 171 | Total Loss: 2.425816059112549 | KNN Loss: 2.4144270420074463 | CLS Loss: 0.011389080435037613\n",
      "Epoch 37 / 200 | iteration 80 / 171 | Total Loss: 2.444263219833374 | KNN Loss: 2.4069297313690186 | CLS Loss: 0.03733354061841965\n",
      "Epoch 37 / 200 | iteration 90 / 171 | Total Loss: 2.4560813903808594 | KNN Loss: 2.412306308746338 | CLS Loss: 0.04377497732639313\n",
      "Epoch 37 / 200 | iteration 100 / 171 | Total Loss: 2.4180898666381836 | KNN Loss: 2.402184009552002 | CLS Loss: 0.015905974432826042\n",
      "Epoch 37 / 200 | iteration 110 / 171 | Total Loss: 2.429706335067749 | KNN Loss: 2.4008164405822754 | CLS Loss: 0.028889821842312813\n",
      "Epoch 37 / 200 | iteration 120 / 171 | Total Loss: 2.4225027561187744 | KNN Loss: 2.4017202854156494 | CLS Loss: 0.02078256942331791\n",
      "Epoch 37 / 200 | iteration 130 / 171 | Total Loss: 2.431490659713745 | KNN Loss: 2.4158875942230225 | CLS Loss: 0.01560297328978777\n",
      "Epoch 37 / 200 | iteration 140 / 171 | Total Loss: 2.4841089248657227 | KNN Loss: 2.428293228149414 | CLS Loss: 0.05581574887037277\n",
      "Epoch 37 / 200 | iteration 150 / 171 | Total Loss: 2.4385485649108887 | KNN Loss: 2.3688390254974365 | CLS Loss: 0.06970953941345215\n",
      "Epoch 37 / 200 | iteration 160 / 171 | Total Loss: 2.4128990173339844 | KNN Loss: 2.3872170448303223 | CLS Loss: 0.025681905448436737\n",
      "Epoch 37 / 200 | iteration 170 / 171 | Total Loss: 2.448552370071411 | KNN Loss: 2.4001762866973877 | CLS Loss: 0.04837610945105553\n",
      "Epoch: 037, Loss: 2.4371, Train: 0.9910, Valid: 0.9848, Best: 0.9859\n",
      "Epoch 38 / 200 | iteration 0 / 171 | Total Loss: 2.43135142326355 | KNN Loss: 2.4195716381073 | CLS Loss: 0.011779889464378357\n",
      "Epoch 38 / 200 | iteration 10 / 171 | Total Loss: 2.3961007595062256 | KNN Loss: 2.367842197418213 | CLS Loss: 0.02825857512652874\n",
      "Epoch 38 / 200 | iteration 20 / 171 | Total Loss: 2.4599618911743164 | KNN Loss: 2.424983263015747 | CLS Loss: 0.034978512674570084\n",
      "Epoch 38 / 200 | iteration 30 / 171 | Total Loss: 2.4623944759368896 | KNN Loss: 2.406996011734009 | CLS Loss: 0.05539850518107414\n",
      "Epoch 38 / 200 | iteration 40 / 171 | Total Loss: 2.439744710922241 | KNN Loss: 2.4014742374420166 | CLS Loss: 0.038270559161901474\n",
      "Epoch 38 / 200 | iteration 50 / 171 | Total Loss: 2.4349684715270996 | KNN Loss: 2.4147799015045166 | CLS Loss: 0.020188534632325172\n",
      "Epoch 38 / 200 | iteration 60 / 171 | Total Loss: 2.4169201850891113 | KNN Loss: 2.393465042114258 | CLS Loss: 0.023455094546079636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 200 | iteration 70 / 171 | Total Loss: 2.418576717376709 | KNN Loss: 2.3969714641571045 | CLS Loss: 0.021605150774121284\n",
      "Epoch 38 / 200 | iteration 80 / 171 | Total Loss: 2.3996236324310303 | KNN Loss: 2.383439302444458 | CLS Loss: 0.016184283420443535\n",
      "Epoch 38 / 200 | iteration 90 / 171 | Total Loss: 2.386899948120117 | KNN Loss: 2.3661489486694336 | CLS Loss: 0.020750973373651505\n",
      "Epoch 38 / 200 | iteration 100 / 171 | Total Loss: 2.418302297592163 | KNN Loss: 2.3895363807678223 | CLS Loss: 0.028765907511115074\n",
      "Epoch 38 / 200 | iteration 110 / 171 | Total Loss: 2.4517104625701904 | KNN Loss: 2.4021573066711426 | CLS Loss: 0.04955307021737099\n",
      "Epoch 38 / 200 | iteration 120 / 171 | Total Loss: 2.427091360092163 | KNN Loss: 2.375933885574341 | CLS Loss: 0.05115745589137077\n",
      "Epoch 38 / 200 | iteration 130 / 171 | Total Loss: 2.4216666221618652 | KNN Loss: 2.3800528049468994 | CLS Loss: 0.04161386936903\n",
      "Epoch 38 / 200 | iteration 140 / 171 | Total Loss: 2.3962554931640625 | KNN Loss: 2.34934401512146 | CLS Loss: 0.04691155254840851\n",
      "Epoch 38 / 200 | iteration 150 / 171 | Total Loss: 2.4284214973449707 | KNN Loss: 2.3890860080718994 | CLS Loss: 0.03933542221784592\n",
      "Epoch 38 / 200 | iteration 160 / 171 | Total Loss: 2.422781229019165 | KNN Loss: 2.383293867111206 | CLS Loss: 0.03948744013905525\n",
      "Epoch 38 / 200 | iteration 170 / 171 | Total Loss: 2.4208908081054688 | KNN Loss: 2.405700445175171 | CLS Loss: 0.01519039273262024\n",
      "Epoch: 038, Loss: 2.4288, Train: 0.9900, Valid: 0.9839, Best: 0.9859\n",
      "Epoch 39 / 200 | iteration 0 / 171 | Total Loss: 2.4235897064208984 | KNN Loss: 2.3993923664093018 | CLS Loss: 0.024197254329919815\n",
      "Epoch 39 / 200 | iteration 10 / 171 | Total Loss: 2.4757766723632812 | KNN Loss: 2.4398353099823 | CLS Loss: 0.035941481590270996\n",
      "Epoch 39 / 200 | iteration 20 / 171 | Total Loss: 2.418133497238159 | KNN Loss: 2.3909363746643066 | CLS Loss: 0.02719711884856224\n",
      "Epoch 39 / 200 | iteration 30 / 171 | Total Loss: 2.46812105178833 | KNN Loss: 2.4173073768615723 | CLS Loss: 0.05081363022327423\n",
      "Epoch 39 / 200 | iteration 40 / 171 | Total Loss: 2.432587146759033 | KNN Loss: 2.3835620880126953 | CLS Loss: 0.049025095999240875\n",
      "Epoch 39 / 200 | iteration 50 / 171 | Total Loss: 2.4018707275390625 | KNN Loss: 2.3798835277557373 | CLS Loss: 0.021987231448292732\n",
      "Epoch 39 / 200 | iteration 60 / 171 | Total Loss: 2.44201922416687 | KNN Loss: 2.417710781097412 | CLS Loss: 0.02430855669081211\n",
      "Epoch 39 / 200 | iteration 70 / 171 | Total Loss: 2.456907272338867 | KNN Loss: 2.3727614879608154 | CLS Loss: 0.08414571732282639\n",
      "Epoch 39 / 200 | iteration 80 / 171 | Total Loss: 2.464358329772949 | KNN Loss: 2.4460206031799316 | CLS Loss: 0.018337756395339966\n",
      "Epoch 39 / 200 | iteration 90 / 171 | Total Loss: 2.476304531097412 | KNN Loss: 2.4001951217651367 | CLS Loss: 0.076109379529953\n",
      "Epoch 39 / 200 | iteration 100 / 171 | Total Loss: 2.407409906387329 | KNN Loss: 2.385395050048828 | CLS Loss: 0.02201497182250023\n",
      "Epoch 39 / 200 | iteration 110 / 171 | Total Loss: 2.458357095718384 | KNN Loss: 2.41093373298645 | CLS Loss: 0.04742330312728882\n",
      "Epoch 39 / 200 | iteration 120 / 171 | Total Loss: 2.4224436283111572 | KNN Loss: 2.388228416442871 | CLS Loss: 0.03421518951654434\n",
      "Epoch 39 / 200 | iteration 130 / 171 | Total Loss: 2.420966148376465 | KNN Loss: 2.361194133758545 | CLS Loss: 0.0597720742225647\n",
      "Epoch 39 / 200 | iteration 140 / 171 | Total Loss: 2.4230144023895264 | KNN Loss: 2.372199296951294 | CLS Loss: 0.05081518739461899\n",
      "Epoch 39 / 200 | iteration 150 / 171 | Total Loss: 2.461639404296875 | KNN Loss: 2.418346881866455 | CLS Loss: 0.043292563408613205\n",
      "Epoch 39 / 200 | iteration 160 / 171 | Total Loss: 2.4689390659332275 | KNN Loss: 2.4149043560028076 | CLS Loss: 0.054034799337387085\n",
      "Epoch 39 / 200 | iteration 170 / 171 | Total Loss: 2.468838930130005 | KNN Loss: 2.43668794631958 | CLS Loss: 0.03215102106332779\n",
      "Epoch: 039, Loss: 2.4341, Train: 0.9907, Valid: 0.9848, Best: 0.9859\n",
      "Epoch 40 / 200 | iteration 0 / 171 | Total Loss: 2.4570510387420654 | KNN Loss: 2.419356346130371 | CLS Loss: 0.03769458085298538\n",
      "Epoch 40 / 200 | iteration 10 / 171 | Total Loss: 2.4475371837615967 | KNN Loss: 2.408820629119873 | CLS Loss: 0.038716644048690796\n",
      "Epoch 40 / 200 | iteration 20 / 171 | Total Loss: 2.452918767929077 | KNN Loss: 2.4195995330810547 | CLS Loss: 0.03331926837563515\n",
      "Epoch 40 / 200 | iteration 30 / 171 | Total Loss: 2.46465802192688 | KNN Loss: 2.427422285079956 | CLS Loss: 0.03723582625389099\n",
      "Epoch 40 / 200 | iteration 40 / 171 | Total Loss: 2.4335885047912598 | KNN Loss: 2.420745372772217 | CLS Loss: 0.012843096628785133\n",
      "Epoch 40 / 200 | iteration 50 / 171 | Total Loss: 2.407517194747925 | KNN Loss: 2.382265090942383 | CLS Loss: 0.02525210939347744\n",
      "Epoch 40 / 200 | iteration 60 / 171 | Total Loss: 2.432368755340576 | KNN Loss: 2.410111665725708 | CLS Loss: 0.022257093340158463\n",
      "Epoch 40 / 200 | iteration 70 / 171 | Total Loss: 2.4715795516967773 | KNN Loss: 2.445322036743164 | CLS Loss: 0.026257485151290894\n",
      "Epoch 40 / 200 | iteration 80 / 171 | Total Loss: 2.465224266052246 | KNN Loss: 2.4324371814727783 | CLS Loss: 0.0327870137989521\n",
      "Epoch 40 / 200 | iteration 90 / 171 | Total Loss: 2.4366891384124756 | KNN Loss: 2.404236316680908 | CLS Loss: 0.032452818006277084\n",
      "Epoch 40 / 200 | iteration 100 / 171 | Total Loss: 2.454025983810425 | KNN Loss: 2.4144253730773926 | CLS Loss: 0.039600640535354614\n",
      "Epoch 40 / 200 | iteration 110 / 171 | Total Loss: 2.4071991443634033 | KNN Loss: 2.384223222732544 | CLS Loss: 0.022976022213697433\n",
      "Epoch 40 / 200 | iteration 120 / 171 | Total Loss: 2.4533095359802246 | KNN Loss: 2.4219045639038086 | CLS Loss: 0.031404901295900345\n",
      "Epoch 40 / 200 | iteration 130 / 171 | Total Loss: 2.452254295349121 | KNN Loss: 2.400916576385498 | CLS Loss: 0.051337823271751404\n",
      "Epoch 40 / 200 | iteration 140 / 171 | Total Loss: 2.4466567039489746 | KNN Loss: 2.411221981048584 | CLS Loss: 0.03543483838438988\n",
      "Epoch 40 / 200 | iteration 150 / 171 | Total Loss: 2.4058592319488525 | KNN Loss: 2.3783504962921143 | CLS Loss: 0.02750866673886776\n",
      "Epoch 40 / 200 | iteration 160 / 171 | Total Loss: 2.4302475452423096 | KNN Loss: 2.4084365367889404 | CLS Loss: 0.021811001002788544\n",
      "Epoch 40 / 200 | iteration 170 / 171 | Total Loss: 2.419647693634033 | KNN Loss: 2.3811028003692627 | CLS Loss: 0.0385449193418026\n",
      "Epoch: 040, Loss: 2.4323, Train: 0.9895, Valid: 0.9828, Best: 0.9859\n",
      "Epoch 41 / 200 | iteration 0 / 171 | Total Loss: 2.374833583831787 | KNN Loss: 2.340986728668213 | CLS Loss: 0.033846862614154816\n",
      "Epoch 41 / 200 | iteration 10 / 171 | Total Loss: 2.418001890182495 | KNN Loss: 2.381164789199829 | CLS Loss: 0.0368371456861496\n",
      "Epoch 41 / 200 | iteration 20 / 171 | Total Loss: 2.3896193504333496 | KNN Loss: 2.372448444366455 | CLS Loss: 0.017171017825603485\n",
      "Epoch 41 / 200 | iteration 30 / 171 | Total Loss: 2.4375603199005127 | KNN Loss: 2.414876937866211 | CLS Loss: 0.02268342301249504\n",
      "Epoch 41 / 200 | iteration 40 / 171 | Total Loss: 2.409757375717163 | KNN Loss: 2.3693461418151855 | CLS Loss: 0.040411192923784256\n",
      "Epoch 41 / 200 | iteration 50 / 171 | Total Loss: 2.455516815185547 | KNN Loss: 2.407885789871216 | CLS Loss: 0.04763094335794449\n",
      "Epoch 41 / 200 | iteration 60 / 171 | Total Loss: 2.466843605041504 | KNN Loss: 2.437955379486084 | CLS Loss: 0.028888266533613205\n",
      "Epoch 41 / 200 | iteration 70 / 171 | Total Loss: 2.475141763687134 | KNN Loss: 2.448718786239624 | CLS Loss: 0.026422932744026184\n",
      "Epoch 41 / 200 | iteration 80 / 171 | Total Loss: 2.4503631591796875 | KNN Loss: 2.409571409225464 | CLS Loss: 0.04079174995422363\n",
      "Epoch 41 / 200 | iteration 90 / 171 | Total Loss: 2.3952386379241943 | KNN Loss: 2.3629651069641113 | CLS Loss: 0.03227345272898674\n",
      "Epoch 41 / 200 | iteration 100 / 171 | Total Loss: 2.426419496536255 | KNN Loss: 2.38881778717041 | CLS Loss: 0.03760180249810219\n",
      "Epoch 41 / 200 | iteration 110 / 171 | Total Loss: 2.459226131439209 | KNN Loss: 2.375354290008545 | CLS Loss: 0.08387172222137451\n",
      "Epoch 41 / 200 | iteration 120 / 171 | Total Loss: 2.453160524368286 | KNN Loss: 2.422976493835449 | CLS Loss: 0.030184127390384674\n",
      "Epoch 41 / 200 | iteration 130 / 171 | Total Loss: 2.463125705718994 | KNN Loss: 2.4219603538513184 | CLS Loss: 0.04116538166999817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 200 | iteration 140 / 171 | Total Loss: 2.415483236312866 | KNN Loss: 2.398831844329834 | CLS Loss: 0.016651304438710213\n",
      "Epoch 41 / 200 | iteration 150 / 171 | Total Loss: 2.4473180770874023 | KNN Loss: 2.4126017093658447 | CLS Loss: 0.03471630439162254\n",
      "Epoch 41 / 200 | iteration 160 / 171 | Total Loss: 2.50728702545166 | KNN Loss: 2.4508509635925293 | CLS Loss: 0.05643594264984131\n",
      "Epoch 41 / 200 | iteration 170 / 171 | Total Loss: 2.430040121078491 | KNN Loss: 2.4011049270629883 | CLS Loss: 0.028935085982084274\n",
      "Epoch: 041, Loss: 2.4266, Train: 0.9927, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 42 / 200 | iteration 0 / 171 | Total Loss: 2.4634575843811035 | KNN Loss: 2.417475938796997 | CLS Loss: 0.04598162695765495\n",
      "Epoch 42 / 200 | iteration 10 / 171 | Total Loss: 2.409532308578491 | KNN Loss: 2.361368179321289 | CLS Loss: 0.04816414788365364\n",
      "Epoch 42 / 200 | iteration 20 / 171 | Total Loss: 2.414159059524536 | KNN Loss: 2.388326406478882 | CLS Loss: 0.025832761079072952\n",
      "Epoch 42 / 200 | iteration 30 / 171 | Total Loss: 2.438261032104492 | KNN Loss: 2.393010139465332 | CLS Loss: 0.045250922441482544\n",
      "Epoch 42 / 200 | iteration 40 / 171 | Total Loss: 2.411952018737793 | KNN Loss: 2.3542752265930176 | CLS Loss: 0.05767669901251793\n",
      "Epoch 42 / 200 | iteration 50 / 171 | Total Loss: 2.455202102661133 | KNN Loss: 2.3966102600097656 | CLS Loss: 0.058591924607753754\n",
      "Epoch 42 / 200 | iteration 60 / 171 | Total Loss: 2.4311838150024414 | KNN Loss: 2.400282144546509 | CLS Loss: 0.030901603400707245\n",
      "Epoch 42 / 200 | iteration 70 / 171 | Total Loss: 2.4193084239959717 | KNN Loss: 2.3668463230133057 | CLS Loss: 0.05246208980679512\n",
      "Epoch 42 / 200 | iteration 80 / 171 | Total Loss: 2.42822527885437 | KNN Loss: 2.4185731410980225 | CLS Loss: 0.00965220108628273\n",
      "Epoch 42 / 200 | iteration 90 / 171 | Total Loss: 2.391839027404785 | KNN Loss: 2.375265598297119 | CLS Loss: 0.016573451459407806\n",
      "Epoch 42 / 200 | iteration 100 / 171 | Total Loss: 2.5119645595550537 | KNN Loss: 2.4627175331115723 | CLS Loss: 0.049246981739997864\n",
      "Epoch 42 / 200 | iteration 110 / 171 | Total Loss: 2.4528963565826416 | KNN Loss: 2.39921498298645 | CLS Loss: 0.05368128791451454\n",
      "Epoch 42 / 200 | iteration 120 / 171 | Total Loss: 2.4309604167938232 | KNN Loss: 2.413745403289795 | CLS Loss: 0.01721492037177086\n",
      "Epoch 42 / 200 | iteration 130 / 171 | Total Loss: 2.451542854309082 | KNN Loss: 2.407667398452759 | CLS Loss: 0.04387553036212921\n",
      "Epoch 42 / 200 | iteration 140 / 171 | Total Loss: 2.4209201335906982 | KNN Loss: 2.389279842376709 | CLS Loss: 0.03164030984044075\n",
      "Epoch 42 / 200 | iteration 150 / 171 | Total Loss: 2.462099075317383 | KNN Loss: 2.420546054840088 | CLS Loss: 0.04155309125781059\n",
      "Epoch 42 / 200 | iteration 160 / 171 | Total Loss: 2.415281295776367 | KNN Loss: 2.393303155899048 | CLS Loss: 0.021978119388222694\n",
      "Epoch 42 / 200 | iteration 170 / 171 | Total Loss: 2.3967063426971436 | KNN Loss: 2.3748972415924072 | CLS Loss: 0.021809058263897896\n",
      "Epoch: 042, Loss: 2.4328, Train: 0.9911, Valid: 0.9851, Best: 0.9866\n",
      "Epoch 43 / 200 | iteration 0 / 171 | Total Loss: 2.4524478912353516 | KNN Loss: 2.423769474029541 | CLS Loss: 0.028678467497229576\n",
      "Epoch 43 / 200 | iteration 10 / 171 | Total Loss: 2.4129912853240967 | KNN Loss: 2.3551483154296875 | CLS Loss: 0.05784307420253754\n",
      "Epoch 43 / 200 | iteration 20 / 171 | Total Loss: 2.45487642288208 | KNN Loss: 2.4050793647766113 | CLS Loss: 0.04979713261127472\n",
      "Epoch 43 / 200 | iteration 30 / 171 | Total Loss: 2.4451639652252197 | KNN Loss: 2.3962342739105225 | CLS Loss: 0.04892969876527786\n",
      "Epoch 43 / 200 | iteration 40 / 171 | Total Loss: 2.433211326599121 | KNN Loss: 2.388978958129883 | CLS Loss: 0.044232327491045\n",
      "Epoch 43 / 200 | iteration 50 / 171 | Total Loss: 2.4444873332977295 | KNN Loss: 2.3616371154785156 | CLS Loss: 0.08285018801689148\n",
      "Epoch 43 / 200 | iteration 60 / 171 | Total Loss: 2.442333698272705 | KNN Loss: 2.4206459522247314 | CLS Loss: 0.021687639877200127\n",
      "Epoch 43 / 200 | iteration 70 / 171 | Total Loss: 2.442974328994751 | KNN Loss: 2.371927499771118 | CLS Loss: 0.0710468515753746\n",
      "Epoch 43 / 200 | iteration 80 / 171 | Total Loss: 2.4225854873657227 | KNN Loss: 2.3752293586730957 | CLS Loss: 0.047356124967336655\n",
      "Epoch 43 / 200 | iteration 90 / 171 | Total Loss: 2.4107024669647217 | KNN Loss: 2.3690340518951416 | CLS Loss: 0.0416683554649353\n",
      "Epoch 43 / 200 | iteration 100 / 171 | Total Loss: 2.4143316745758057 | KNN Loss: 2.3870866298675537 | CLS Loss: 0.027245156466960907\n",
      "Epoch 43 / 200 | iteration 110 / 171 | Total Loss: 2.440694570541382 | KNN Loss: 2.419548988342285 | CLS Loss: 0.021145541220903397\n",
      "Epoch 43 / 200 | iteration 120 / 171 | Total Loss: 2.4480836391448975 | KNN Loss: 2.3976969718933105 | CLS Loss: 0.050386734306812286\n",
      "Epoch 43 / 200 | iteration 130 / 171 | Total Loss: 2.4423470497131348 | KNN Loss: 2.401695489883423 | CLS Loss: 0.04065149649977684\n",
      "Epoch 43 / 200 | iteration 140 / 171 | Total Loss: 2.4135923385620117 | KNN Loss: 2.381410598754883 | CLS Loss: 0.03218170627951622\n",
      "Epoch 43 / 200 | iteration 150 / 171 | Total Loss: 2.437589406967163 | KNN Loss: 2.4095547199249268 | CLS Loss: 0.02803480066359043\n",
      "Epoch 43 / 200 | iteration 160 / 171 | Total Loss: 2.452382802963257 | KNN Loss: 2.431663990020752 | CLS Loss: 0.020718906074762344\n",
      "Epoch 43 / 200 | iteration 170 / 171 | Total Loss: 2.4253733158111572 | KNN Loss: 2.388278007507324 | CLS Loss: 0.03709527850151062\n",
      "Epoch: 043, Loss: 2.4341, Train: 0.9914, Valid: 0.9854, Best: 0.9866\n",
      "Epoch 44 / 200 | iteration 0 / 171 | Total Loss: 2.4591736793518066 | KNN Loss: 2.393838405609131 | CLS Loss: 0.06533525139093399\n",
      "Epoch 44 / 200 | iteration 10 / 171 | Total Loss: 2.4189038276672363 | KNN Loss: 2.37274169921875 | CLS Loss: 0.04616202041506767\n",
      "Epoch 44 / 200 | iteration 20 / 171 | Total Loss: 2.4276726245880127 | KNN Loss: 2.3851215839385986 | CLS Loss: 0.042551130056381226\n",
      "Epoch 44 / 200 | iteration 30 / 171 | Total Loss: 2.4918248653411865 | KNN Loss: 2.4222497940063477 | CLS Loss: 0.06957515329122543\n",
      "Epoch 44 / 200 | iteration 40 / 171 | Total Loss: 2.428335666656494 | KNN Loss: 2.393036127090454 | CLS Loss: 0.03529942035675049\n",
      "Epoch 44 / 200 | iteration 50 / 171 | Total Loss: 2.3983571529388428 | KNN Loss: 2.3901469707489014 | CLS Loss: 0.00821011047810316\n",
      "Epoch 44 / 200 | iteration 60 / 171 | Total Loss: 2.430877923965454 | KNN Loss: 2.4130280017852783 | CLS Loss: 0.01785000041127205\n",
      "Epoch 44 / 200 | iteration 70 / 171 | Total Loss: 2.4280388355255127 | KNN Loss: 2.3941292762756348 | CLS Loss: 0.03390951454639435\n",
      "Epoch 44 / 200 | iteration 80 / 171 | Total Loss: 2.4126977920532227 | KNN Loss: 2.398300886154175 | CLS Loss: 0.014396985061466694\n",
      "Epoch 44 / 200 | iteration 90 / 171 | Total Loss: 2.4178824424743652 | KNN Loss: 2.39158296585083 | CLS Loss: 0.026299530640244484\n",
      "Epoch 44 / 200 | iteration 100 / 171 | Total Loss: 2.477421522140503 | KNN Loss: 2.4525187015533447 | CLS Loss: 0.02490275353193283\n",
      "Epoch 44 / 200 | iteration 110 / 171 | Total Loss: 2.413311004638672 | KNN Loss: 2.3843021392822266 | CLS Loss: 0.02900885045528412\n",
      "Epoch 44 / 200 | iteration 120 / 171 | Total Loss: 2.4396188259124756 | KNN Loss: 2.427057981491089 | CLS Loss: 0.012560861185193062\n",
      "Epoch 44 / 200 | iteration 130 / 171 | Total Loss: 2.4195098876953125 | KNN Loss: 2.3790361881256104 | CLS Loss: 0.040473584085702896\n",
      "Epoch 44 / 200 | iteration 140 / 171 | Total Loss: 2.4447181224823 | KNN Loss: 2.3999812602996826 | CLS Loss: 0.044736865907907486\n",
      "Epoch 44 / 200 | iteration 150 / 171 | Total Loss: 2.4733734130859375 | KNN Loss: 2.414301633834839 | CLS Loss: 0.059071868658065796\n",
      "Epoch 44 / 200 | iteration 160 / 171 | Total Loss: 2.4538254737854004 | KNN Loss: 2.4085447788238525 | CLS Loss: 0.0452808141708374\n",
      "Epoch 44 / 200 | iteration 170 / 171 | Total Loss: 2.4057509899139404 | KNN Loss: 2.384700298309326 | CLS Loss: 0.021050618961453438\n",
      "Epoch: 044, Loss: 2.4319, Train: 0.9927, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 45 / 200 | iteration 0 / 171 | Total Loss: 2.4344892501831055 | KNN Loss: 2.42706036567688 | CLS Loss: 0.007428895216435194\n",
      "Epoch 45 / 200 | iteration 10 / 171 | Total Loss: 2.47965407371521 | KNN Loss: 2.4617671966552734 | CLS Loss: 0.017886821180582047\n",
      "Epoch 45 / 200 | iteration 20 / 171 | Total Loss: 2.4604947566986084 | KNN Loss: 2.4309704303741455 | CLS Loss: 0.029524285346269608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 200 | iteration 30 / 171 | Total Loss: 2.4263980388641357 | KNN Loss: 2.404324769973755 | CLS Loss: 0.02207331731915474\n",
      "Epoch 45 / 200 | iteration 40 / 171 | Total Loss: 2.4409589767456055 | KNN Loss: 2.4092812538146973 | CLS Loss: 0.0316777341067791\n",
      "Epoch 45 / 200 | iteration 50 / 171 | Total Loss: 2.444166898727417 | KNN Loss: 2.422528028488159 | CLS Loss: 0.02163882553577423\n",
      "Epoch 45 / 200 | iteration 60 / 171 | Total Loss: 2.437716007232666 | KNN Loss: 2.41519832611084 | CLS Loss: 0.022517703473567963\n",
      "Epoch 45 / 200 | iteration 70 / 171 | Total Loss: 2.4179019927978516 | KNN Loss: 2.3838284015655518 | CLS Loss: 0.034073520451784134\n",
      "Epoch 45 / 200 | iteration 80 / 171 | Total Loss: 2.4071106910705566 | KNN Loss: 2.3628339767456055 | CLS Loss: 0.04427679628133774\n",
      "Epoch 45 / 200 | iteration 90 / 171 | Total Loss: 2.4187171459198 | KNN Loss: 2.4087746143341064 | CLS Loss: 0.009942558594048023\n",
      "Epoch 45 / 200 | iteration 100 / 171 | Total Loss: 2.430152177810669 | KNN Loss: 2.3956620693206787 | CLS Loss: 0.0344901867210865\n",
      "Epoch 45 / 200 | iteration 110 / 171 | Total Loss: 2.4648680686950684 | KNN Loss: 2.43156361579895 | CLS Loss: 0.03330455720424652\n",
      "Epoch 45 / 200 | iteration 120 / 171 | Total Loss: 2.4443984031677246 | KNN Loss: 2.4063637256622314 | CLS Loss: 0.038034625351428986\n",
      "Epoch 45 / 200 | iteration 130 / 171 | Total Loss: 2.444183588027954 | KNN Loss: 2.419764995574951 | CLS Loss: 0.024418573826551437\n",
      "Epoch 45 / 200 | iteration 140 / 171 | Total Loss: 2.4525299072265625 | KNN Loss: 2.429044485092163 | CLS Loss: 0.023485537618398666\n",
      "Epoch 45 / 200 | iteration 150 / 171 | Total Loss: 2.4361908435821533 | KNN Loss: 2.401559352874756 | CLS Loss: 0.03463156521320343\n",
      "Epoch 45 / 200 | iteration 160 / 171 | Total Loss: 2.4206809997558594 | KNN Loss: 2.3861422538757324 | CLS Loss: 0.03453865647315979\n",
      "Epoch 45 / 200 | iteration 170 / 171 | Total Loss: 2.4206905364990234 | KNN Loss: 2.3885231018066406 | CLS Loss: 0.03216743469238281\n",
      "Epoch: 045, Loss: 2.4277, Train: 0.9886, Valid: 0.9811, Best: 0.9866\n",
      "Epoch 46 / 200 | iteration 0 / 171 | Total Loss: 2.442072868347168 | KNN Loss: 2.403761386871338 | CLS Loss: 0.03831137716770172\n",
      "Epoch 46 / 200 | iteration 10 / 171 | Total Loss: 2.4466726779937744 | KNN Loss: 2.4230892658233643 | CLS Loss: 0.023583466187119484\n",
      "Epoch 46 / 200 | iteration 20 / 171 | Total Loss: 2.4531900882720947 | KNN Loss: 2.4267098903656006 | CLS Loss: 0.02648019604384899\n",
      "Epoch 46 / 200 | iteration 30 / 171 | Total Loss: 2.4576241970062256 | KNN Loss: 2.428255558013916 | CLS Loss: 0.029368719086050987\n",
      "Epoch 46 / 200 | iteration 40 / 171 | Total Loss: 2.435767889022827 | KNN Loss: 2.409719705581665 | CLS Loss: 0.026048287749290466\n",
      "Epoch 46 / 200 | iteration 50 / 171 | Total Loss: 2.427825689315796 | KNN Loss: 2.3995847702026367 | CLS Loss: 0.02824086882174015\n",
      "Epoch 46 / 200 | iteration 60 / 171 | Total Loss: 2.4222142696380615 | KNN Loss: 2.3961150646209717 | CLS Loss: 0.02609928324818611\n",
      "Epoch 46 / 200 | iteration 70 / 171 | Total Loss: 2.4283461570739746 | KNN Loss: 2.3911566734313965 | CLS Loss: 0.037189412862062454\n",
      "Epoch 46 / 200 | iteration 80 / 171 | Total Loss: 2.436131477355957 | KNN Loss: 2.404315233230591 | CLS Loss: 0.03181631490588188\n",
      "Epoch 46 / 200 | iteration 90 / 171 | Total Loss: 2.4905455112457275 | KNN Loss: 2.4569621086120605 | CLS Loss: 0.03358348086476326\n",
      "Epoch 46 / 200 | iteration 100 / 171 | Total Loss: 2.454470634460449 | KNN Loss: 2.4273428916931152 | CLS Loss: 0.027127742767333984\n",
      "Epoch 46 / 200 | iteration 110 / 171 | Total Loss: 2.4264607429504395 | KNN Loss: 2.4063076972961426 | CLS Loss: 0.020153071731328964\n",
      "Epoch 46 / 200 | iteration 120 / 171 | Total Loss: 2.4619200229644775 | KNN Loss: 2.424665927886963 | CLS Loss: 0.03725414350628853\n",
      "Epoch 46 / 200 | iteration 130 / 171 | Total Loss: 2.4384894371032715 | KNN Loss: 2.409883737564087 | CLS Loss: 0.028605615720152855\n",
      "Epoch 46 / 200 | iteration 140 / 171 | Total Loss: 2.4629578590393066 | KNN Loss: 2.419489860534668 | CLS Loss: 0.04346789792180061\n",
      "Epoch 46 / 200 | iteration 150 / 171 | Total Loss: 2.402585744857788 | KNN Loss: 2.375236988067627 | CLS Loss: 0.027348823845386505\n",
      "Epoch 46 / 200 | iteration 160 / 171 | Total Loss: 2.4451773166656494 | KNN Loss: 2.4304518699645996 | CLS Loss: 0.01472536288201809\n",
      "Epoch 46 / 200 | iteration 170 / 171 | Total Loss: 2.410503625869751 | KNN Loss: 2.386341094970703 | CLS Loss: 0.024162430316209793\n",
      "Epoch: 046, Loss: 2.4330, Train: 0.9915, Valid: 0.9847, Best: 0.9866\n",
      "Epoch 47 / 200 | iteration 0 / 171 | Total Loss: 2.4420454502105713 | KNN Loss: 2.3982298374176025 | CLS Loss: 0.04381553828716278\n",
      "Epoch 47 / 200 | iteration 10 / 171 | Total Loss: 2.4566500186920166 | KNN Loss: 2.405909776687622 | CLS Loss: 0.050740260630846024\n",
      "Epoch 47 / 200 | iteration 20 / 171 | Total Loss: 2.464125871658325 | KNN Loss: 2.418368101119995 | CLS Loss: 0.045757658779621124\n",
      "Epoch 47 / 200 | iteration 30 / 171 | Total Loss: 2.415754795074463 | KNN Loss: 2.394606351852417 | CLS Loss: 0.021148448809981346\n",
      "Epoch 47 / 200 | iteration 40 / 171 | Total Loss: 2.490422010421753 | KNN Loss: 2.457078695297241 | CLS Loss: 0.03334343060851097\n",
      "Epoch 47 / 200 | iteration 50 / 171 | Total Loss: 2.4485137462615967 | KNN Loss: 2.421849489212036 | CLS Loss: 0.02666418068110943\n",
      "Epoch 47 / 200 | iteration 60 / 171 | Total Loss: 2.399885654449463 | KNN Loss: 2.3829150199890137 | CLS Loss: 0.016970736905932426\n",
      "Epoch 47 / 200 | iteration 70 / 171 | Total Loss: 2.4268810749053955 | KNN Loss: 2.395447015762329 | CLS Loss: 0.03143396973609924\n",
      "Epoch 47 / 200 | iteration 80 / 171 | Total Loss: 2.4572460651397705 | KNN Loss: 2.4186248779296875 | CLS Loss: 0.038621269166469574\n",
      "Epoch 47 / 200 | iteration 90 / 171 | Total Loss: 2.4497666358947754 | KNN Loss: 2.3949105739593506 | CLS Loss: 0.054856039583683014\n",
      "Epoch 47 / 200 | iteration 100 / 171 | Total Loss: 2.429698944091797 | KNN Loss: 2.3966879844665527 | CLS Loss: 0.03301098942756653\n",
      "Epoch 47 / 200 | iteration 110 / 171 | Total Loss: 2.4718687534332275 | KNN Loss: 2.42798113822937 | CLS Loss: 0.043887633830308914\n",
      "Epoch 47 / 200 | iteration 120 / 171 | Total Loss: 2.4980275630950928 | KNN Loss: 2.4851009845733643 | CLS Loss: 0.012926622293889523\n",
      "Epoch 47 / 200 | iteration 130 / 171 | Total Loss: 2.4224510192871094 | KNN Loss: 2.4017364978790283 | CLS Loss: 0.020714597776532173\n",
      "Epoch 47 / 200 | iteration 140 / 171 | Total Loss: 2.4413793087005615 | KNN Loss: 2.417443037033081 | CLS Loss: 0.023936355486512184\n",
      "Epoch 47 / 200 | iteration 150 / 171 | Total Loss: 2.46718430519104 | KNN Loss: 2.447162389755249 | CLS Loss: 0.020021952688694\n",
      "Epoch 47 / 200 | iteration 160 / 171 | Total Loss: 2.45882248878479 | KNN Loss: 2.4282383918762207 | CLS Loss: 0.03058411180973053\n",
      "Epoch 47 / 200 | iteration 170 / 171 | Total Loss: 2.455146074295044 | KNN Loss: 2.4211554527282715 | CLS Loss: 0.03399050980806351\n",
      "Epoch: 047, Loss: 2.4386, Train: 0.9921, Valid: 0.9860, Best: 0.9866\n",
      "Epoch 48 / 200 | iteration 0 / 171 | Total Loss: 2.479154109954834 | KNN Loss: 2.446564197540283 | CLS Loss: 0.03258990868926048\n",
      "Epoch 48 / 200 | iteration 10 / 171 | Total Loss: 2.444838047027588 | KNN Loss: 2.4238502979278564 | CLS Loss: 0.020987719297409058\n",
      "Epoch 48 / 200 | iteration 20 / 171 | Total Loss: 2.454064130783081 | KNN Loss: 2.4413607120513916 | CLS Loss: 0.01270337961614132\n",
      "Epoch 48 / 200 | iteration 30 / 171 | Total Loss: 2.4459972381591797 | KNN Loss: 2.4100263118743896 | CLS Loss: 0.03597104176878929\n",
      "Epoch 48 / 200 | iteration 40 / 171 | Total Loss: 2.4218826293945312 | KNN Loss: 2.381234645843506 | CLS Loss: 0.040647994726896286\n",
      "Epoch 48 / 200 | iteration 50 / 171 | Total Loss: 2.439514398574829 | KNN Loss: 2.420090436935425 | CLS Loss: 0.019423864781856537\n",
      "Epoch 48 / 200 | iteration 60 / 171 | Total Loss: 2.4120283126831055 | KNN Loss: 2.3895084857940674 | CLS Loss: 0.022519713267683983\n",
      "Epoch 48 / 200 | iteration 70 / 171 | Total Loss: 2.4225351810455322 | KNN Loss: 2.3947434425354004 | CLS Loss: 0.02779179997742176\n",
      "Epoch 48 / 200 | iteration 80 / 171 | Total Loss: 2.4320173263549805 | KNN Loss: 2.400007963180542 | CLS Loss: 0.032009247690439224\n",
      "Epoch 48 / 200 | iteration 90 / 171 | Total Loss: 2.41563081741333 | KNN Loss: 2.401785373687744 | CLS Loss: 0.013845475390553474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 200 | iteration 100 / 171 | Total Loss: 2.4047234058380127 | KNN Loss: 2.3777356147766113 | CLS Loss: 0.02698773890733719\n",
      "Epoch 48 / 200 | iteration 110 / 171 | Total Loss: 2.447726249694824 | KNN Loss: 2.37937068939209 | CLS Loss: 0.0683554857969284\n",
      "Epoch 48 / 200 | iteration 120 / 171 | Total Loss: 2.427299737930298 | KNN Loss: 2.411612033843994 | CLS Loss: 0.015687694773077965\n",
      "Epoch 48 / 200 | iteration 130 / 171 | Total Loss: 2.4396004676818848 | KNN Loss: 2.41352915763855 | CLS Loss: 0.026071222499012947\n",
      "Epoch 48 / 200 | iteration 140 / 171 | Total Loss: 2.4562788009643555 | KNN Loss: 2.431913137435913 | CLS Loss: 0.024365771561861038\n",
      "Epoch 48 / 200 | iteration 150 / 171 | Total Loss: 2.4486563205718994 | KNN Loss: 2.4196228981018066 | CLS Loss: 0.029033519327640533\n",
      "Epoch 48 / 200 | iteration 160 / 171 | Total Loss: 2.451486825942993 | KNN Loss: 2.4369468688964844 | CLS Loss: 0.01454001571983099\n",
      "Epoch 48 / 200 | iteration 170 / 171 | Total Loss: 2.422532320022583 | KNN Loss: 2.3744168281555176 | CLS Loss: 0.04811540246009827\n",
      "Epoch: 048, Loss: 2.4370, Train: 0.9928, Valid: 0.9861, Best: 0.9866\n",
      "Epoch 49 / 200 | iteration 0 / 171 | Total Loss: 2.436901807785034 | KNN Loss: 2.4040582180023193 | CLS Loss: 0.03284347802400589\n",
      "Epoch 49 / 200 | iteration 10 / 171 | Total Loss: 2.411492109298706 | KNN Loss: 2.379882335662842 | CLS Loss: 0.03160971403121948\n",
      "Epoch 49 / 200 | iteration 20 / 171 | Total Loss: 2.478856086730957 | KNN Loss: 2.4466164112091064 | CLS Loss: 0.03223961964249611\n",
      "Epoch 49 / 200 | iteration 30 / 171 | Total Loss: 2.3981401920318604 | KNN Loss: 2.380624771118164 | CLS Loss: 0.017515305429697037\n",
      "Epoch 49 / 200 | iteration 40 / 171 | Total Loss: 2.4422945976257324 | KNN Loss: 2.4171133041381836 | CLS Loss: 0.025181183591485023\n",
      "Epoch 49 / 200 | iteration 50 / 171 | Total Loss: 2.4200994968414307 | KNN Loss: 2.3589704036712646 | CLS Loss: 0.06112919747829437\n",
      "Epoch 49 / 200 | iteration 60 / 171 | Total Loss: 2.406940221786499 | KNN Loss: 2.4017200469970703 | CLS Loss: 0.0052202180959284306\n",
      "Epoch 49 / 200 | iteration 70 / 171 | Total Loss: 2.440737724304199 | KNN Loss: 2.4136650562286377 | CLS Loss: 0.027072645723819733\n",
      "Epoch 49 / 200 | iteration 80 / 171 | Total Loss: 2.446930408477783 | KNN Loss: 2.391814708709717 | CLS Loss: 0.055115777999162674\n",
      "Epoch 49 / 200 | iteration 90 / 171 | Total Loss: 2.460177183151245 | KNN Loss: 2.409092903137207 | CLS Loss: 0.05108419060707092\n",
      "Epoch 49 / 200 | iteration 100 / 171 | Total Loss: 2.458141326904297 | KNN Loss: 2.380894660949707 | CLS Loss: 0.07724655419588089\n",
      "Epoch 49 / 200 | iteration 110 / 171 | Total Loss: 2.424434185028076 | KNN Loss: 2.4094605445861816 | CLS Loss: 0.014973741956055164\n",
      "Epoch 49 / 200 | iteration 120 / 171 | Total Loss: 2.465667724609375 | KNN Loss: 2.4500651359558105 | CLS Loss: 0.01560257002711296\n",
      "Epoch 49 / 200 | iteration 130 / 171 | Total Loss: 2.50072979927063 | KNN Loss: 2.4545047283172607 | CLS Loss: 0.04622500389814377\n",
      "Epoch 49 / 200 | iteration 140 / 171 | Total Loss: 2.461054563522339 | KNN Loss: 2.438873291015625 | CLS Loss: 0.022181285545229912\n",
      "Epoch 49 / 200 | iteration 150 / 171 | Total Loss: 2.45957350730896 | KNN Loss: 2.4089417457580566 | CLS Loss: 0.05063179135322571\n",
      "Epoch 49 / 200 | iteration 160 / 171 | Total Loss: 2.4244086742401123 | KNN Loss: 2.4047415256500244 | CLS Loss: 0.01966720260679722\n",
      "Epoch 49 / 200 | iteration 170 / 171 | Total Loss: 2.490187883377075 | KNN Loss: 2.462510585784912 | CLS Loss: 0.027677349746227264\n",
      "Epoch: 049, Loss: 2.4388, Train: 0.9918, Valid: 0.9859, Best: 0.9866\n",
      "Epoch 50 / 200 | iteration 0 / 171 | Total Loss: 2.445345401763916 | KNN Loss: 2.41888165473938 | CLS Loss: 0.026463821530342102\n",
      "Epoch 50 / 200 | iteration 10 / 171 | Total Loss: 2.428983211517334 | KNN Loss: 2.3888001441955566 | CLS Loss: 0.04018300026655197\n",
      "Epoch 50 / 200 | iteration 20 / 171 | Total Loss: 2.4506638050079346 | KNN Loss: 2.4230103492736816 | CLS Loss: 0.027653463184833527\n",
      "Epoch 50 / 200 | iteration 30 / 171 | Total Loss: 2.4652087688446045 | KNN Loss: 2.415377616882324 | CLS Loss: 0.04983115941286087\n",
      "Epoch 50 / 200 | iteration 40 / 171 | Total Loss: 2.4118878841400146 | KNN Loss: 2.407712936401367 | CLS Loss: 0.004174999892711639\n",
      "Epoch 50 / 200 | iteration 50 / 171 | Total Loss: 2.4411990642547607 | KNN Loss: 2.3939943313598633 | CLS Loss: 0.04720463976264\n",
      "Epoch 50 / 200 | iteration 60 / 171 | Total Loss: 2.4148168563842773 | KNN Loss: 2.3970284461975098 | CLS Loss: 0.017788290977478027\n",
      "Epoch 50 / 200 | iteration 70 / 171 | Total Loss: 2.4401674270629883 | KNN Loss: 2.409001111984253 | CLS Loss: 0.031166212633252144\n",
      "Epoch 50 / 200 | iteration 80 / 171 | Total Loss: 2.468865394592285 | KNN Loss: 2.4438202381134033 | CLS Loss: 0.02504507265985012\n",
      "Epoch 50 / 200 | iteration 90 / 171 | Total Loss: 2.431180953979492 | KNN Loss: 2.398775815963745 | CLS Loss: 0.03240519016981125\n",
      "Epoch 50 / 200 | iteration 100 / 171 | Total Loss: 2.426954507827759 | KNN Loss: 2.403089761734009 | CLS Loss: 0.02386464551091194\n",
      "Epoch 50 / 200 | iteration 110 / 171 | Total Loss: 2.440469741821289 | KNN Loss: 2.4289073944091797 | CLS Loss: 0.011562460102140903\n",
      "Epoch 50 / 200 | iteration 120 / 171 | Total Loss: 2.3935256004333496 | KNN Loss: 2.3863284587860107 | CLS Loss: 0.007197041995823383\n",
      "Epoch 50 / 200 | iteration 130 / 171 | Total Loss: 2.460019111633301 | KNN Loss: 2.4123198986053467 | CLS Loss: 0.04769916087388992\n",
      "Epoch 50 / 200 | iteration 140 / 171 | Total Loss: 2.418757915496826 | KNN Loss: 2.4032907485961914 | CLS Loss: 0.015467253513634205\n",
      "Epoch 50 / 200 | iteration 150 / 171 | Total Loss: 2.4595396518707275 | KNN Loss: 2.4188148975372314 | CLS Loss: 0.0407247394323349\n",
      "Epoch 50 / 200 | iteration 160 / 171 | Total Loss: 2.4275875091552734 | KNN Loss: 2.38358736038208 | CLS Loss: 0.044000037014484406\n",
      "Epoch 50 / 200 | iteration 170 / 171 | Total Loss: 2.408716917037964 | KNN Loss: 2.384875535964966 | CLS Loss: 0.023841379210352898\n",
      "Epoch: 050, Loss: 2.4355, Train: 0.9932, Valid: 0.9857, Best: 0.9866\n",
      "Epoch 51 / 200 | iteration 0 / 171 | Total Loss: 2.4175474643707275 | KNN Loss: 2.38055419921875 | CLS Loss: 0.036993276327848434\n",
      "Epoch 51 / 200 | iteration 10 / 171 | Total Loss: 2.4538190364837646 | KNN Loss: 2.4467859268188477 | CLS Loss: 0.007033122703433037\n",
      "Epoch 51 / 200 | iteration 20 / 171 | Total Loss: 2.450410842895508 | KNN Loss: 2.430790424346924 | CLS Loss: 0.019620466977357864\n",
      "Epoch 51 / 200 | iteration 30 / 171 | Total Loss: 2.4124808311462402 | KNN Loss: 2.3962602615356445 | CLS Loss: 0.01622067578136921\n",
      "Epoch 51 / 200 | iteration 40 / 171 | Total Loss: 2.4178848266601562 | KNN Loss: 2.408425807952881 | CLS Loss: 0.009458952583372593\n",
      "Epoch 51 / 200 | iteration 50 / 171 | Total Loss: 2.4321887493133545 | KNN Loss: 2.410369873046875 | CLS Loss: 0.021818779408931732\n",
      "Epoch 51 / 200 | iteration 60 / 171 | Total Loss: 2.4103214740753174 | KNN Loss: 2.391756772994995 | CLS Loss: 0.018564652651548386\n",
      "Epoch 51 / 200 | iteration 70 / 171 | Total Loss: 2.4453072547912598 | KNN Loss: 2.406332015991211 | CLS Loss: 0.03897520899772644\n",
      "Epoch 51 / 200 | iteration 80 / 171 | Total Loss: 2.4728713035583496 | KNN Loss: 2.448188304901123 | CLS Loss: 0.024683093652129173\n",
      "Epoch 51 / 200 | iteration 90 / 171 | Total Loss: 2.4737050533294678 | KNN Loss: 2.4467475414276123 | CLS Loss: 0.026957612484693527\n",
      "Epoch 51 / 200 | iteration 100 / 171 | Total Loss: 2.420703411102295 | KNN Loss: 2.4091386795043945 | CLS Loss: 0.01156467106193304\n",
      "Epoch 51 / 200 | iteration 110 / 171 | Total Loss: 2.447871685028076 | KNN Loss: 2.4063851833343506 | CLS Loss: 0.041486527770757675\n",
      "Epoch 51 / 200 | iteration 120 / 171 | Total Loss: 2.429388999938965 | KNN Loss: 2.4171929359436035 | CLS Loss: 0.01219596341252327\n",
      "Epoch 51 / 200 | iteration 130 / 171 | Total Loss: 2.4542815685272217 | KNN Loss: 2.4136903285980225 | CLS Loss: 0.04059125483036041\n",
      "Epoch 51 / 200 | iteration 140 / 171 | Total Loss: 2.425841808319092 | KNN Loss: 2.411181688308716 | CLS Loss: 0.014660151675343513\n",
      "Epoch 51 / 200 | iteration 150 / 171 | Total Loss: 2.4157726764678955 | KNN Loss: 2.3936071395874023 | CLS Loss: 0.022165454924106598\n",
      "Epoch 51 / 200 | iteration 160 / 171 | Total Loss: 2.396178722381592 | KNN Loss: 2.386580467224121 | CLS Loss: 0.009598254226148129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 / 200 | iteration 170 / 171 | Total Loss: 2.4168429374694824 | KNN Loss: 2.3775289058685303 | CLS Loss: 0.03931400924921036\n",
      "Epoch: 051, Loss: 2.4350, Train: 0.9916, Valid: 0.9838, Best: 0.9866\n",
      "Epoch 52 / 200 | iteration 0 / 171 | Total Loss: 2.4293642044067383 | KNN Loss: 2.399405002593994 | CLS Loss: 0.02995912730693817\n",
      "Epoch 52 / 200 | iteration 10 / 171 | Total Loss: 2.453402280807495 | KNN Loss: 2.4334073066711426 | CLS Loss: 0.019994977861642838\n",
      "Epoch 52 / 200 | iteration 20 / 171 | Total Loss: 2.436356782913208 | KNN Loss: 2.418696165084839 | CLS Loss: 0.017660507932305336\n",
      "Epoch 52 / 200 | iteration 30 / 171 | Total Loss: 2.402538299560547 | KNN Loss: 2.3975844383239746 | CLS Loss: 0.004953878931701183\n",
      "Epoch 52 / 200 | iteration 40 / 171 | Total Loss: 2.4394915103912354 | KNN Loss: 2.405895709991455 | CLS Loss: 0.03359571099281311\n",
      "Epoch 52 / 200 | iteration 50 / 171 | Total Loss: 2.446819543838501 | KNN Loss: 2.406564474105835 | CLS Loss: 0.04025515168905258\n",
      "Epoch 52 / 200 | iteration 60 / 171 | Total Loss: 2.42236328125 | KNN Loss: 2.4010090827941895 | CLS Loss: 0.02135416679084301\n",
      "Epoch 52 / 200 | iteration 70 / 171 | Total Loss: 2.4126851558685303 | KNN Loss: 2.392352819442749 | CLS Loss: 0.020332233980298042\n",
      "Epoch 52 / 200 | iteration 80 / 171 | Total Loss: 2.452169895172119 | KNN Loss: 2.4385759830474854 | CLS Loss: 0.013593971729278564\n",
      "Epoch 52 / 200 | iteration 90 / 171 | Total Loss: 2.461115837097168 | KNN Loss: 2.434054374694824 | CLS Loss: 0.027061516419053078\n",
      "Epoch 52 / 200 | iteration 100 / 171 | Total Loss: 2.439682722091675 | KNN Loss: 2.41361141204834 | CLS Loss: 0.02607125975191593\n",
      "Epoch 52 / 200 | iteration 110 / 171 | Total Loss: 2.439924955368042 | KNN Loss: 2.4271838665008545 | CLS Loss: 0.01274099387228489\n",
      "Epoch 52 / 200 | iteration 120 / 171 | Total Loss: 2.430272102355957 | KNN Loss: 2.416684150695801 | CLS Loss: 0.01358805876225233\n",
      "Epoch 52 / 200 | iteration 130 / 171 | Total Loss: 2.425598621368408 | KNN Loss: 2.395850419998169 | CLS Loss: 0.02974819950759411\n",
      "Epoch 52 / 200 | iteration 140 / 171 | Total Loss: 2.446929454803467 | KNN Loss: 2.4385266304016113 | CLS Loss: 0.008402809500694275\n",
      "Epoch 52 / 200 | iteration 150 / 171 | Total Loss: 2.449922800064087 | KNN Loss: 2.422938108444214 | CLS Loss: 0.026984576135873795\n",
      "Epoch 52 / 200 | iteration 160 / 171 | Total Loss: 2.4600019454956055 | KNN Loss: 2.428511619567871 | CLS Loss: 0.031490251421928406\n",
      "Epoch 52 / 200 | iteration 170 / 171 | Total Loss: 2.427361488342285 | KNN Loss: 2.3886568546295166 | CLS Loss: 0.038704730570316315\n",
      "Epoch: 052, Loss: 2.4362, Train: 0.9935, Valid: 0.9864, Best: 0.9866\n",
      "Epoch 53 / 200 | iteration 0 / 171 | Total Loss: 2.4786267280578613 | KNN Loss: 2.451294422149658 | CLS Loss: 0.027332201600074768\n",
      "Epoch 53 / 200 | iteration 10 / 171 | Total Loss: 2.4786646366119385 | KNN Loss: 2.413689136505127 | CLS Loss: 0.06497538834810257\n",
      "Epoch 53 / 200 | iteration 20 / 171 | Total Loss: 2.417306900024414 | KNN Loss: 2.384922742843628 | CLS Loss: 0.03238414227962494\n",
      "Epoch 53 / 200 | iteration 30 / 171 | Total Loss: 2.48898983001709 | KNN Loss: 2.419468402862549 | CLS Loss: 0.06952135264873505\n",
      "Epoch 53 / 200 | iteration 40 / 171 | Total Loss: 2.4349234104156494 | KNN Loss: 2.3696348667144775 | CLS Loss: 0.06528858095407486\n",
      "Epoch 53 / 200 | iteration 50 / 171 | Total Loss: 2.417909622192383 | KNN Loss: 2.389988660812378 | CLS Loss: 0.027920985594391823\n",
      "Epoch 53 / 200 | iteration 60 / 171 | Total Loss: 2.459331512451172 | KNN Loss: 2.4271721839904785 | CLS Loss: 0.03215944394469261\n",
      "Epoch 53 / 200 | iteration 70 / 171 | Total Loss: 2.394803762435913 | KNN Loss: 2.384859085083008 | CLS Loss: 0.009944640100002289\n",
      "Epoch 53 / 200 | iteration 80 / 171 | Total Loss: 2.4588663578033447 | KNN Loss: 2.4272148609161377 | CLS Loss: 0.031651414930820465\n",
      "Epoch 53 / 200 | iteration 90 / 171 | Total Loss: 2.4217846393585205 | KNN Loss: 2.402540922164917 | CLS Loss: 0.019243653863668442\n",
      "Epoch 53 / 200 | iteration 100 / 171 | Total Loss: 2.424394130706787 | KNN Loss: 2.4145545959472656 | CLS Loss: 0.009839484468102455\n",
      "Epoch 53 / 200 | iteration 110 / 171 | Total Loss: 2.45412540435791 | KNN Loss: 2.408463954925537 | CLS Loss: 0.045661330223083496\n",
      "Epoch 53 / 200 | iteration 120 / 171 | Total Loss: 2.391345500946045 | KNN Loss: 2.3673653602600098 | CLS Loss: 0.02398017980158329\n",
      "Epoch 53 / 200 | iteration 130 / 171 | Total Loss: 2.424720048904419 | KNN Loss: 2.3933985233306885 | CLS Loss: 0.03132142126560211\n",
      "Epoch 53 / 200 | iteration 140 / 171 | Total Loss: 2.4175145626068115 | KNN Loss: 2.4016265869140625 | CLS Loss: 0.01588800549507141\n",
      "Epoch 53 / 200 | iteration 150 / 171 | Total Loss: 2.4427378177642822 | KNN Loss: 2.419759511947632 | CLS Loss: 0.022978419438004494\n",
      "Epoch 53 / 200 | iteration 160 / 171 | Total Loss: 2.429241895675659 | KNN Loss: 2.40911602973938 | CLS Loss: 0.020125791430473328\n",
      "Epoch 53 / 200 | iteration 170 / 171 | Total Loss: 2.4369075298309326 | KNN Loss: 2.4161324501037598 | CLS Loss: 0.020775167271494865\n",
      "Epoch: 053, Loss: 2.4332, Train: 0.9935, Valid: 0.9866, Best: 0.9866\n",
      "Epoch 54 / 200 | iteration 0 / 171 | Total Loss: 2.428847312927246 | KNN Loss: 2.4074769020080566 | CLS Loss: 0.021370504051446915\n",
      "Epoch 54 / 200 | iteration 10 / 171 | Total Loss: 2.483898162841797 | KNN Loss: 2.4584169387817383 | CLS Loss: 0.025481296703219414\n",
      "Epoch 54 / 200 | iteration 20 / 171 | Total Loss: 2.4737207889556885 | KNN Loss: 2.4448082447052 | CLS Loss: 0.02891244739294052\n",
      "Epoch 54 / 200 | iteration 30 / 171 | Total Loss: 2.424424171447754 | KNN Loss: 2.4041287899017334 | CLS Loss: 0.020295407623052597\n",
      "Epoch 54 / 200 | iteration 40 / 171 | Total Loss: 2.417539358139038 | KNN Loss: 2.3915185928344727 | CLS Loss: 0.026020817458629608\n",
      "Epoch 54 / 200 | iteration 50 / 171 | Total Loss: 2.3984527587890625 | KNN Loss: 2.3928000926971436 | CLS Loss: 0.0056527154520154\n",
      "Epoch 54 / 200 | iteration 60 / 171 | Total Loss: 2.4180588722229004 | KNN Loss: 2.3742923736572266 | CLS Loss: 0.04376659542322159\n",
      "Epoch 54 / 200 | iteration 70 / 171 | Total Loss: 2.4069488048553467 | KNN Loss: 2.3822174072265625 | CLS Loss: 0.02473137155175209\n",
      "Epoch 54 / 200 | iteration 80 / 171 | Total Loss: 2.4306106567382812 | KNN Loss: 2.409764528274536 | CLS Loss: 0.020846202969551086\n",
      "Epoch 54 / 200 | iteration 90 / 171 | Total Loss: 2.450521469116211 | KNN Loss: 2.4196135997772217 | CLS Loss: 0.030907874926924706\n",
      "Epoch 54 / 200 | iteration 100 / 171 | Total Loss: 2.424607515335083 | KNN Loss: 2.40438175201416 | CLS Loss: 0.020225804299116135\n",
      "Epoch 54 / 200 | iteration 110 / 171 | Total Loss: 2.419898509979248 | KNN Loss: 2.3796029090881348 | CLS Loss: 0.04029565304517746\n",
      "Epoch 54 / 200 | iteration 120 / 171 | Total Loss: 2.4291069507598877 | KNN Loss: 2.3890788555145264 | CLS Loss: 0.04002804681658745\n",
      "Epoch 54 / 200 | iteration 130 / 171 | Total Loss: 2.441209316253662 | KNN Loss: 2.4064648151397705 | CLS Loss: 0.0347445048391819\n",
      "Epoch 54 / 200 | iteration 140 / 171 | Total Loss: 2.4213359355926514 | KNN Loss: 2.4149577617645264 | CLS Loss: 0.006378180347383022\n",
      "Epoch 54 / 200 | iteration 150 / 171 | Total Loss: 2.4322750568389893 | KNN Loss: 2.3869404792785645 | CLS Loss: 0.045334674417972565\n",
      "Epoch 54 / 200 | iteration 160 / 171 | Total Loss: 2.401489496231079 | KNN Loss: 2.3730406761169434 | CLS Loss: 0.028448838740587234\n",
      "Epoch 54 / 200 | iteration 170 / 171 | Total Loss: 2.4167323112487793 | KNN Loss: 2.4085817337036133 | CLS Loss: 0.008150619454681873\n",
      "Epoch: 054, Loss: 2.4329, Train: 0.9934, Valid: 0.9852, Best: 0.9866\n",
      "Epoch 55 / 200 | iteration 0 / 171 | Total Loss: 2.407273769378662 | KNN Loss: 2.391188383102417 | CLS Loss: 0.016085484996438026\n",
      "Epoch 55 / 200 | iteration 10 / 171 | Total Loss: 2.405052900314331 | KNN Loss: 2.3866050243377686 | CLS Loss: 0.018447816371917725\n",
      "Epoch 55 / 200 | iteration 20 / 171 | Total Loss: 2.437668800354004 | KNN Loss: 2.3861169815063477 | CLS Loss: 0.05155180022120476\n",
      "Epoch 55 / 200 | iteration 30 / 171 | Total Loss: 2.428196668624878 | KNN Loss: 2.4009506702423096 | CLS Loss: 0.027246031910181046\n",
      "Epoch 55 / 200 | iteration 40 / 171 | Total Loss: 2.4169650077819824 | KNN Loss: 2.39764666557312 | CLS Loss: 0.01931835152208805\n",
      "Epoch 55 / 200 | iteration 50 / 171 | Total Loss: 2.4645369052886963 | KNN Loss: 2.4046521186828613 | CLS Loss: 0.05988485738635063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 / 200 | iteration 60 / 171 | Total Loss: 2.4255211353302 | KNN Loss: 2.4016261100769043 | CLS Loss: 0.02389501966536045\n",
      "Epoch 55 / 200 | iteration 70 / 171 | Total Loss: 2.4023327827453613 | KNN Loss: 2.3707354068756104 | CLS Loss: 0.031597379595041275\n",
      "Epoch 55 / 200 | iteration 80 / 171 | Total Loss: 2.4490511417388916 | KNN Loss: 2.4195799827575684 | CLS Loss: 0.02947109378874302\n",
      "Epoch 55 / 200 | iteration 90 / 171 | Total Loss: 2.3745996952056885 | KNN Loss: 2.3657288551330566 | CLS Loss: 0.008870908990502357\n",
      "Epoch 55 / 200 | iteration 100 / 171 | Total Loss: 2.4290733337402344 | KNN Loss: 2.396984338760376 | CLS Loss: 0.032088905572891235\n",
      "Epoch 55 / 200 | iteration 110 / 171 | Total Loss: 2.4100141525268555 | KNN Loss: 2.389298439025879 | CLS Loss: 0.020715629681944847\n",
      "Epoch 55 / 200 | iteration 120 / 171 | Total Loss: 2.4547533988952637 | KNN Loss: 2.4191441535949707 | CLS Loss: 0.03560929372906685\n",
      "Epoch 55 / 200 | iteration 130 / 171 | Total Loss: 2.51659893989563 | KNN Loss: 2.481203079223633 | CLS Loss: 0.03539575636386871\n",
      "Epoch 55 / 200 | iteration 140 / 171 | Total Loss: 2.4196701049804688 | KNN Loss: 2.408224582672119 | CLS Loss: 0.011445429176092148\n",
      "Epoch 55 / 200 | iteration 150 / 171 | Total Loss: 2.4471418857574463 | KNN Loss: 2.431401014328003 | CLS Loss: 0.01574091427028179\n",
      "Epoch 55 / 200 | iteration 160 / 171 | Total Loss: 2.47103214263916 | KNN Loss: 2.441528558731079 | CLS Loss: 0.02950354479253292\n",
      "Epoch 55 / 200 | iteration 170 / 171 | Total Loss: 2.4420814514160156 | KNN Loss: 2.3948395252227783 | CLS Loss: 0.04724182188510895\n",
      "Epoch: 055, Loss: 2.4380, Train: 0.9928, Valid: 0.9856, Best: 0.9866\n",
      "Epoch 56 / 200 | iteration 0 / 171 | Total Loss: 2.4362545013427734 | KNN Loss: 2.4284305572509766 | CLS Loss: 0.007823925465345383\n",
      "Epoch 56 / 200 | iteration 10 / 171 | Total Loss: 2.424177408218384 | KNN Loss: 2.401466131210327 | CLS Loss: 0.022711342200636864\n",
      "Epoch 56 / 200 | iteration 20 / 171 | Total Loss: 2.486189126968384 | KNN Loss: 2.4616901874542236 | CLS Loss: 0.024498838931322098\n",
      "Epoch 56 / 200 | iteration 30 / 171 | Total Loss: 2.442018985748291 | KNN Loss: 2.3931493759155273 | CLS Loss: 0.04886972904205322\n",
      "Epoch 56 / 200 | iteration 40 / 171 | Total Loss: 2.416126012802124 | KNN Loss: 2.4069972038269043 | CLS Loss: 0.009128757752478123\n",
      "Epoch 56 / 200 | iteration 50 / 171 | Total Loss: 2.454681396484375 | KNN Loss: 2.4316890239715576 | CLS Loss: 0.02299235574901104\n",
      "Epoch 56 / 200 | iteration 60 / 171 | Total Loss: 2.4784278869628906 | KNN Loss: 2.461266040802002 | CLS Loss: 0.017161820083856583\n",
      "Epoch 56 / 200 | iteration 70 / 171 | Total Loss: 2.452636241912842 | KNN Loss: 2.4131929874420166 | CLS Loss: 0.03944333270192146\n",
      "Epoch 56 / 200 | iteration 80 / 171 | Total Loss: 2.3878164291381836 | KNN Loss: 2.3717377185821533 | CLS Loss: 0.016078684478998184\n",
      "Epoch 56 / 200 | iteration 90 / 171 | Total Loss: 2.43731689453125 | KNN Loss: 2.391167640686035 | CLS Loss: 0.046149253845214844\n",
      "Epoch 56 / 200 | iteration 100 / 171 | Total Loss: 2.4273934364318848 | KNN Loss: 2.3957741260528564 | CLS Loss: 0.03161942958831787\n",
      "Epoch 56 / 200 | iteration 110 / 171 | Total Loss: 2.388209819793701 | KNN Loss: 2.3685879707336426 | CLS Loss: 0.019621750339865685\n",
      "Epoch 56 / 200 | iteration 120 / 171 | Total Loss: 2.442378282546997 | KNN Loss: 2.4215011596679688 | CLS Loss: 0.02087702974677086\n",
      "Epoch 56 / 200 | iteration 130 / 171 | Total Loss: 2.466571092605591 | KNN Loss: 2.431729793548584 | CLS Loss: 0.03484124690294266\n",
      "Epoch 56 / 200 | iteration 140 / 171 | Total Loss: 2.390925645828247 | KNN Loss: 2.3737075328826904 | CLS Loss: 0.01721806265413761\n",
      "Epoch 56 / 200 | iteration 150 / 171 | Total Loss: 2.434570789337158 | KNN Loss: 2.39497971534729 | CLS Loss: 0.03959115222096443\n",
      "Epoch 56 / 200 | iteration 160 / 171 | Total Loss: 2.389592409133911 | KNN Loss: 2.370685338973999 | CLS Loss: 0.018906980752944946\n",
      "Epoch 56 / 200 | iteration 170 / 171 | Total Loss: 2.429504871368408 | KNN Loss: 2.382753849029541 | CLS Loss: 0.046750932931900024\n",
      "Epoch: 056, Loss: 2.4313, Train: 0.9904, Valid: 0.9821, Best: 0.9866\n",
      "Epoch 57 / 200 | iteration 0 / 171 | Total Loss: 2.459308624267578 | KNN Loss: 2.4161741733551025 | CLS Loss: 0.04313437268137932\n",
      "Epoch 57 / 200 | iteration 10 / 171 | Total Loss: 2.434389352798462 | KNN Loss: 2.4047176837921143 | CLS Loss: 0.029671700671315193\n",
      "Epoch 57 / 200 | iteration 20 / 171 | Total Loss: 2.4404609203338623 | KNN Loss: 2.4134559631347656 | CLS Loss: 0.02700500376522541\n",
      "Epoch 57 / 200 | iteration 30 / 171 | Total Loss: 2.416179895401001 | KNN Loss: 2.3840277194976807 | CLS Loss: 0.03215210512280464\n",
      "Epoch 57 / 200 | iteration 40 / 171 | Total Loss: 2.4355294704437256 | KNN Loss: 2.4060208797454834 | CLS Loss: 0.029508531093597412\n",
      "Epoch 57 / 200 | iteration 50 / 171 | Total Loss: 2.439995288848877 | KNN Loss: 2.395287036895752 | CLS Loss: 0.04470815882086754\n",
      "Epoch 57 / 200 | iteration 60 / 171 | Total Loss: 2.4199578762054443 | KNN Loss: 2.3786098957061768 | CLS Loss: 0.041348014026880264\n",
      "Epoch 57 / 200 | iteration 70 / 171 | Total Loss: 2.420715570449829 | KNN Loss: 2.3964667320251465 | CLS Loss: 0.024248844012618065\n",
      "Epoch 57 / 200 | iteration 80 / 171 | Total Loss: 2.428708553314209 | KNN Loss: 2.3936033248901367 | CLS Loss: 0.03510522469878197\n",
      "Epoch 57 / 200 | iteration 90 / 171 | Total Loss: 2.4293601512908936 | KNN Loss: 2.408662796020508 | CLS Loss: 0.020697366446256638\n",
      "Epoch 57 / 200 | iteration 100 / 171 | Total Loss: 2.4233570098876953 | KNN Loss: 2.3805124759674072 | CLS Loss: 0.04284442588686943\n",
      "Epoch 57 / 200 | iteration 110 / 171 | Total Loss: 2.439768075942993 | KNN Loss: 2.383845090866089 | CLS Loss: 0.05592292547225952\n",
      "Epoch 57 / 200 | iteration 120 / 171 | Total Loss: 2.4231462478637695 | KNN Loss: 2.401932716369629 | CLS Loss: 0.021213503554463387\n",
      "Epoch 57 / 200 | iteration 130 / 171 | Total Loss: 2.418682098388672 | KNN Loss: 2.4096689224243164 | CLS Loss: 0.009013166651129723\n",
      "Epoch 57 / 200 | iteration 140 / 171 | Total Loss: 2.453867197036743 | KNN Loss: 2.439643383026123 | CLS Loss: 0.014223800972104073\n",
      "Epoch 57 / 200 | iteration 150 / 171 | Total Loss: 2.4483349323272705 | KNN Loss: 2.4166479110717773 | CLS Loss: 0.03168690949678421\n",
      "Epoch 57 / 200 | iteration 160 / 171 | Total Loss: 2.4711389541625977 | KNN Loss: 2.44425106048584 | CLS Loss: 0.02688780054450035\n",
      "Epoch 57 / 200 | iteration 170 / 171 | Total Loss: 2.432072162628174 | KNN Loss: 2.39851450920105 | CLS Loss: 0.03355756029486656\n",
      "Epoch: 057, Loss: 2.4327, Train: 0.9918, Valid: 0.9852, Best: 0.9866\n",
      "Epoch 58 / 200 | iteration 0 / 171 | Total Loss: 2.4289443492889404 | KNN Loss: 2.4183382987976074 | CLS Loss: 0.01060604676604271\n",
      "Epoch 58 / 200 | iteration 10 / 171 | Total Loss: 2.4237256050109863 | KNN Loss: 2.4085068702697754 | CLS Loss: 0.015218720771372318\n",
      "Epoch 58 / 200 | iteration 20 / 171 | Total Loss: 2.4566218852996826 | KNN Loss: 2.4161829948425293 | CLS Loss: 0.04043886810541153\n",
      "Epoch 58 / 200 | iteration 30 / 171 | Total Loss: 2.3954176902770996 | KNN Loss: 2.3799667358398438 | CLS Loss: 0.015451046638190746\n",
      "Epoch 58 / 200 | iteration 40 / 171 | Total Loss: 2.4065287113189697 | KNN Loss: 2.382291078567505 | CLS Loss: 0.024237526580691338\n",
      "Epoch 58 / 200 | iteration 50 / 171 | Total Loss: 2.413405656814575 | KNN Loss: 2.3887314796447754 | CLS Loss: 0.02467413805425167\n",
      "Epoch 58 / 200 | iteration 60 / 171 | Total Loss: 2.445496082305908 | KNN Loss: 2.4134066104888916 | CLS Loss: 0.03208936005830765\n",
      "Epoch 58 / 200 | iteration 70 / 171 | Total Loss: 2.438020944595337 | KNN Loss: 2.41805362701416 | CLS Loss: 0.019967254251241684\n",
      "Epoch 58 / 200 | iteration 80 / 171 | Total Loss: 2.4694318771362305 | KNN Loss: 2.452948570251465 | CLS Loss: 0.016483265906572342\n",
      "Epoch 58 / 200 | iteration 90 / 171 | Total Loss: 2.4304492473602295 | KNN Loss: 2.4012749195098877 | CLS Loss: 0.029174286872148514\n",
      "Epoch 58 / 200 | iteration 100 / 171 | Total Loss: 2.4321095943450928 | KNN Loss: 2.4009289741516113 | CLS Loss: 0.031180646270513535\n",
      "Epoch 58 / 200 | iteration 110 / 171 | Total Loss: 2.4359827041625977 | KNN Loss: 2.420560836791992 | CLS Loss: 0.015421813353896141\n",
      "Epoch 58 / 200 | iteration 120 / 171 | Total Loss: 2.4301838874816895 | KNN Loss: 2.4083683490753174 | CLS Loss: 0.02181554213166237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 / 200 | iteration 130 / 171 | Total Loss: 2.4260196685791016 | KNN Loss: 2.3995072841644287 | CLS Loss: 0.02651236578822136\n",
      "Epoch 58 / 200 | iteration 140 / 171 | Total Loss: 2.4658007621765137 | KNN Loss: 2.403367519378662 | CLS Loss: 0.06243321672081947\n",
      "Epoch 58 / 200 | iteration 150 / 171 | Total Loss: 2.4302268028259277 | KNN Loss: 2.4152133464813232 | CLS Loss: 0.015013477765023708\n",
      "Epoch 58 / 200 | iteration 160 / 171 | Total Loss: 2.4097259044647217 | KNN Loss: 2.390004873275757 | CLS Loss: 0.019720951095223427\n",
      "Epoch 58 / 200 | iteration 170 / 171 | Total Loss: 2.4610517024993896 | KNN Loss: 2.426239252090454 | CLS Loss: 0.03481238707900047\n",
      "Epoch: 058, Loss: 2.4313, Train: 0.9942, Valid: 0.9867, Best: 0.9867\n",
      "Epoch 59 / 200 | iteration 0 / 171 | Total Loss: 2.4272241592407227 | KNN Loss: 2.4211552143096924 | CLS Loss: 0.006068967282772064\n",
      "Epoch 59 / 200 | iteration 10 / 171 | Total Loss: 2.4456770420074463 | KNN Loss: 2.412442445755005 | CLS Loss: 0.033234648406505585\n",
      "Epoch 59 / 200 | iteration 20 / 171 | Total Loss: 2.3945817947387695 | KNN Loss: 2.3846395015716553 | CLS Loss: 0.00994239654392004\n",
      "Epoch 59 / 200 | iteration 30 / 171 | Total Loss: 2.3990743160247803 | KNN Loss: 2.36569881439209 | CLS Loss: 0.033375442028045654\n",
      "Epoch 59 / 200 | iteration 40 / 171 | Total Loss: 2.4336841106414795 | KNN Loss: 2.393172264099121 | CLS Loss: 0.04051195830106735\n",
      "Epoch 59 / 200 | iteration 50 / 171 | Total Loss: 2.4174153804779053 | KNN Loss: 2.413475513458252 | CLS Loss: 0.003939914982765913\n",
      "Epoch 59 / 200 | iteration 60 / 171 | Total Loss: 2.4350926876068115 | KNN Loss: 2.3896524906158447 | CLS Loss: 0.04544017091393471\n",
      "Epoch 59 / 200 | iteration 70 / 171 | Total Loss: 2.4407083988189697 | KNN Loss: 2.4172096252441406 | CLS Loss: 0.023498844355344772\n",
      "Epoch 59 / 200 | iteration 80 / 171 | Total Loss: 2.4355287551879883 | KNN Loss: 2.4158968925476074 | CLS Loss: 0.019631877541542053\n",
      "Epoch 59 / 200 | iteration 90 / 171 | Total Loss: 2.445878028869629 | KNN Loss: 2.429335355758667 | CLS Loss: 0.016542766243219376\n",
      "Epoch 59 / 200 | iteration 100 / 171 | Total Loss: 2.4403560161590576 | KNN Loss: 2.4169814586639404 | CLS Loss: 0.023374445736408234\n",
      "Epoch 59 / 200 | iteration 110 / 171 | Total Loss: 2.4269418716430664 | KNN Loss: 2.402423858642578 | CLS Loss: 0.024517979472875595\n",
      "Epoch 59 / 200 | iteration 120 / 171 | Total Loss: 2.3977856636047363 | KNN Loss: 2.3763890266418457 | CLS Loss: 0.02139672450721264\n",
      "Epoch 59 / 200 | iteration 130 / 171 | Total Loss: 2.4737167358398438 | KNN Loss: 2.387160539627075 | CLS Loss: 0.08655629307031631\n",
      "Epoch 59 / 200 | iteration 140 / 171 | Total Loss: 2.4248032569885254 | KNN Loss: 2.407745599746704 | CLS Loss: 0.01705777645111084\n",
      "Epoch 59 / 200 | iteration 150 / 171 | Total Loss: 2.463200569152832 | KNN Loss: 2.421159505844116 | CLS Loss: 0.042041003704071045\n",
      "Epoch 59 / 200 | iteration 160 / 171 | Total Loss: 2.4512319564819336 | KNN Loss: 2.41747784614563 | CLS Loss: 0.03375422954559326\n",
      "Epoch 59 / 200 | iteration 170 / 171 | Total Loss: 2.408757448196411 | KNN Loss: 2.3741092681884766 | CLS Loss: 0.03464815765619278\n",
      "Epoch: 059, Loss: 2.4339, Train: 0.9934, Valid: 0.9858, Best: 0.9867\n",
      "Epoch 60 / 200 | iteration 0 / 171 | Total Loss: 2.430856943130493 | KNN Loss: 2.400977849960327 | CLS Loss: 0.02987917885184288\n",
      "Epoch 60 / 200 | iteration 10 / 171 | Total Loss: 2.475726842880249 | KNN Loss: 2.4485933780670166 | CLS Loss: 0.027133403345942497\n",
      "Epoch 60 / 200 | iteration 20 / 171 | Total Loss: 2.4535646438598633 | KNN Loss: 2.413590431213379 | CLS Loss: 0.03997427970170975\n",
      "Epoch 60 / 200 | iteration 30 / 171 | Total Loss: 2.413255214691162 | KNN Loss: 2.4073572158813477 | CLS Loss: 0.005897980649024248\n",
      "Epoch 60 / 200 | iteration 40 / 171 | Total Loss: 2.4186809062957764 | KNN Loss: 2.411973237991333 | CLS Loss: 0.006707718130201101\n",
      "Epoch 60 / 200 | iteration 50 / 171 | Total Loss: 2.438643455505371 | KNN Loss: 2.4023189544677734 | CLS Loss: 0.036324381828308105\n",
      "Epoch 60 / 200 | iteration 60 / 171 | Total Loss: 2.4402225017547607 | KNN Loss: 2.4260401725769043 | CLS Loss: 0.0141824409365654\n",
      "Epoch 60 / 200 | iteration 70 / 171 | Total Loss: 2.452085494995117 | KNN Loss: 2.4133975505828857 | CLS Loss: 0.038687970489263535\n",
      "Epoch 60 / 200 | iteration 80 / 171 | Total Loss: 2.447286605834961 | KNN Loss: 2.4274380207061768 | CLS Loss: 0.019848551601171494\n",
      "Epoch 60 / 200 | iteration 90 / 171 | Total Loss: 2.409163236618042 | KNN Loss: 2.3892970085144043 | CLS Loss: 0.01986616849899292\n",
      "Epoch 60 / 200 | iteration 100 / 171 | Total Loss: 2.4328322410583496 | KNN Loss: 2.4104740619659424 | CLS Loss: 0.022358180955052376\n",
      "Epoch 60 / 200 | iteration 110 / 171 | Total Loss: 2.4111719131469727 | KNN Loss: 2.3974833488464355 | CLS Loss: 0.013688490726053715\n",
      "Epoch 60 / 200 | iteration 120 / 171 | Total Loss: 2.418243408203125 | KNN Loss: 2.3892030715942383 | CLS Loss: 0.029040329158306122\n",
      "Epoch 60 / 200 | iteration 130 / 171 | Total Loss: 2.4498744010925293 | KNN Loss: 2.4048385620117188 | CLS Loss: 0.045035917311906815\n",
      "Epoch 60 / 200 | iteration 140 / 171 | Total Loss: 2.504714250564575 | KNN Loss: 2.462902784347534 | CLS Loss: 0.04181140288710594\n",
      "Epoch 60 / 200 | iteration 150 / 171 | Total Loss: 2.431389093399048 | KNN Loss: 2.386000871658325 | CLS Loss: 0.04538816586136818\n",
      "Epoch 60 / 200 | iteration 160 / 171 | Total Loss: 2.434351682662964 | KNN Loss: 2.418851137161255 | CLS Loss: 0.015500662848353386\n",
      "Epoch 60 / 200 | iteration 170 / 171 | Total Loss: 2.442244291305542 | KNN Loss: 2.427628993988037 | CLS Loss: 0.014615296386182308\n",
      "Epoch: 060, Loss: 2.4345, Train: 0.9912, Valid: 0.9851, Best: 0.9867\n",
      "Epoch 61 / 200 | iteration 0 / 171 | Total Loss: 2.4455435276031494 | KNN Loss: 2.3993279933929443 | CLS Loss: 0.04621550813317299\n",
      "Epoch 61 / 200 | iteration 10 / 171 | Total Loss: 2.4765923023223877 | KNN Loss: 2.4371211528778076 | CLS Loss: 0.039471156895160675\n",
      "Epoch 61 / 200 | iteration 20 / 171 | Total Loss: 2.412503480911255 | KNN Loss: 2.372675657272339 | CLS Loss: 0.03982775658369064\n",
      "Epoch 61 / 200 | iteration 30 / 171 | Total Loss: 2.4350028038024902 | KNN Loss: 2.4213249683380127 | CLS Loss: 0.013677790760993958\n",
      "Epoch 61 / 200 | iteration 40 / 171 | Total Loss: 2.465674877166748 | KNN Loss: 2.4419281482696533 | CLS Loss: 0.0237466711550951\n",
      "Epoch 61 / 200 | iteration 50 / 171 | Total Loss: 2.4567878246307373 | KNN Loss: 2.4416515827178955 | CLS Loss: 0.015136322006583214\n",
      "Epoch 61 / 200 | iteration 60 / 171 | Total Loss: 2.4067704677581787 | KNN Loss: 2.3948941230773926 | CLS Loss: 0.011876347474753857\n",
      "Epoch 61 / 200 | iteration 70 / 171 | Total Loss: 2.42506742477417 | KNN Loss: 2.4096646308898926 | CLS Loss: 0.015402674674987793\n",
      "Epoch 61 / 200 | iteration 80 / 171 | Total Loss: 2.426175594329834 | KNN Loss: 2.4087412357330322 | CLS Loss: 0.017434366047382355\n",
      "Epoch 61 / 200 | iteration 90 / 171 | Total Loss: 2.4253058433532715 | KNN Loss: 2.3980071544647217 | CLS Loss: 0.027298642322421074\n",
      "Epoch 61 / 200 | iteration 100 / 171 | Total Loss: 2.4138383865356445 | KNN Loss: 2.3877923488616943 | CLS Loss: 0.02604600042104721\n",
      "Epoch 61 / 200 | iteration 110 / 171 | Total Loss: 2.385378122329712 | KNN Loss: 2.379855155944824 | CLS Loss: 0.00552301574498415\n",
      "Epoch 61 / 200 | iteration 120 / 171 | Total Loss: 2.457336664199829 | KNN Loss: 2.427786350250244 | CLS Loss: 0.029550369828939438\n",
      "Epoch 61 / 200 | iteration 130 / 171 | Total Loss: 2.436044931411743 | KNN Loss: 2.4186925888061523 | CLS Loss: 0.017352331429719925\n",
      "Epoch 61 / 200 | iteration 140 / 171 | Total Loss: 2.406038284301758 | KNN Loss: 2.400196075439453 | CLS Loss: 0.005842152051627636\n",
      "Epoch 61 / 200 | iteration 150 / 171 | Total Loss: 2.452974557876587 | KNN Loss: 2.424379348754883 | CLS Loss: 0.02859519049525261\n",
      "Epoch 61 / 200 | iteration 160 / 171 | Total Loss: 2.45269513130188 | KNN Loss: 2.4199492931365967 | CLS Loss: 0.03274582326412201\n",
      "Epoch 61 / 200 | iteration 170 / 171 | Total Loss: 2.4216699600219727 | KNN Loss: 2.405583381652832 | CLS Loss: 0.016086488962173462\n",
      "Epoch: 061, Loss: 2.4338, Train: 0.9939, Valid: 0.9858, Best: 0.9867\n",
      "Epoch 62 / 200 | iteration 0 / 171 | Total Loss: 2.4721217155456543 | KNN Loss: 2.4475536346435547 | CLS Loss: 0.024568136781454086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 / 200 | iteration 10 / 171 | Total Loss: 2.4671196937561035 | KNN Loss: 2.420119285583496 | CLS Loss: 0.04700038209557533\n",
      "Epoch 62 / 200 | iteration 20 / 171 | Total Loss: 2.437140941619873 | KNN Loss: 2.4040844440460205 | CLS Loss: 0.033056557178497314\n",
      "Epoch 62 / 200 | iteration 30 / 171 | Total Loss: 2.448408842086792 | KNN Loss: 2.420020818710327 | CLS Loss: 0.02838806062936783\n",
      "Epoch 62 / 200 | iteration 40 / 171 | Total Loss: 2.4199583530426025 | KNN Loss: 2.4121463298797607 | CLS Loss: 0.00781198451295495\n",
      "Epoch 62 / 200 | iteration 50 / 171 | Total Loss: 2.4052696228027344 | KNN Loss: 2.3479018211364746 | CLS Loss: 0.0573677234351635\n",
      "Epoch 62 / 200 | iteration 60 / 171 | Total Loss: 2.3793725967407227 | KNN Loss: 2.3718619346618652 | CLS Loss: 0.0075105950236320496\n",
      "Epoch 62 / 200 | iteration 70 / 171 | Total Loss: 2.468064785003662 | KNN Loss: 2.4284355640411377 | CLS Loss: 0.03962932154536247\n",
      "Epoch 62 / 200 | iteration 80 / 171 | Total Loss: 2.419922351837158 | KNN Loss: 2.4149794578552246 | CLS Loss: 0.004942798521369696\n",
      "Epoch 62 / 200 | iteration 90 / 171 | Total Loss: 2.413978338241577 | KNN Loss: 2.4106740951538086 | CLS Loss: 0.0033043217845261097\n",
      "Epoch 62 / 200 | iteration 100 / 171 | Total Loss: 2.45343017578125 | KNN Loss: 2.4087557792663574 | CLS Loss: 0.044674478471279144\n",
      "Epoch 62 / 200 | iteration 110 / 171 | Total Loss: 2.41621994972229 | KNN Loss: 2.3953306674957275 | CLS Loss: 0.02088925801217556\n",
      "Epoch 62 / 200 | iteration 120 / 171 | Total Loss: 2.4344475269317627 | KNN Loss: 2.408798933029175 | CLS Loss: 0.025648538023233414\n",
      "Epoch 62 / 200 | iteration 130 / 171 | Total Loss: 2.402913808822632 | KNN Loss: 2.3835110664367676 | CLS Loss: 0.01940285973250866\n",
      "Epoch 62 / 200 | iteration 140 / 171 | Total Loss: 2.4233601093292236 | KNN Loss: 2.402567148208618 | CLS Loss: 0.020792976021766663\n",
      "Epoch 62 / 200 | iteration 150 / 171 | Total Loss: 2.4625749588012695 | KNN Loss: 2.4256749153137207 | CLS Loss: 0.03690001368522644\n",
      "Epoch 62 / 200 | iteration 160 / 171 | Total Loss: 2.451568841934204 | KNN Loss: 2.4046146869659424 | CLS Loss: 0.04695414751768112\n",
      "Epoch 62 / 200 | iteration 170 / 171 | Total Loss: 2.4305152893066406 | KNN Loss: 2.4069297313690186 | CLS Loss: 0.02358551323413849\n",
      "Epoch: 062, Loss: 2.4296, Train: 0.9937, Valid: 0.9870, Best: 0.9870\n",
      "Epoch 63 / 200 | iteration 0 / 171 | Total Loss: 2.4040534496307373 | KNN Loss: 2.387592315673828 | CLS Loss: 0.016461189836263657\n",
      "Epoch 63 / 200 | iteration 10 / 171 | Total Loss: 2.4307334423065186 | KNN Loss: 2.3910090923309326 | CLS Loss: 0.03972427174448967\n",
      "Epoch 63 / 200 | iteration 20 / 171 | Total Loss: 2.485546112060547 | KNN Loss: 2.4254329204559326 | CLS Loss: 0.06011329963803291\n",
      "Epoch 63 / 200 | iteration 30 / 171 | Total Loss: 2.421839714050293 | KNN Loss: 2.408395290374756 | CLS Loss: 0.013444516807794571\n",
      "Epoch 63 / 200 | iteration 40 / 171 | Total Loss: 2.4254159927368164 | KNN Loss: 2.398862838745117 | CLS Loss: 0.02655326947569847\n",
      "Epoch 63 / 200 | iteration 50 / 171 | Total Loss: 2.461409330368042 | KNN Loss: 2.413193702697754 | CLS Loss: 0.048215534538030624\n",
      "Epoch 63 / 200 | iteration 60 / 171 | Total Loss: 2.4098262786865234 | KNN Loss: 2.391998529434204 | CLS Loss: 0.01782785728573799\n",
      "Epoch 63 / 200 | iteration 70 / 171 | Total Loss: 2.4443883895874023 | KNN Loss: 2.4035849571228027 | CLS Loss: 0.04080354794859886\n",
      "Epoch 63 / 200 | iteration 80 / 171 | Total Loss: 2.4449431896209717 | KNN Loss: 2.40592622756958 | CLS Loss: 0.03901692479848862\n",
      "Epoch 63 / 200 | iteration 90 / 171 | Total Loss: 2.3930416107177734 | KNN Loss: 2.362969160079956 | CLS Loss: 0.030072512105107307\n",
      "Epoch 63 / 200 | iteration 100 / 171 | Total Loss: 2.4524178504943848 | KNN Loss: 2.4298503398895264 | CLS Loss: 0.022567464038729668\n",
      "Epoch 63 / 200 | iteration 110 / 171 | Total Loss: 2.426745653152466 | KNN Loss: 2.3906595706939697 | CLS Loss: 0.03608618304133415\n",
      "Epoch 63 / 200 | iteration 120 / 171 | Total Loss: 2.4429492950439453 | KNN Loss: 2.4227981567382812 | CLS Loss: 0.020151237025856972\n",
      "Epoch 63 / 200 | iteration 130 / 171 | Total Loss: 2.407053232192993 | KNN Loss: 2.387838363647461 | CLS Loss: 0.019214870408177376\n",
      "Epoch 63 / 200 | iteration 140 / 171 | Total Loss: 2.419567346572876 | KNN Loss: 2.4099581241607666 | CLS Loss: 0.009609164670109749\n",
      "Epoch 63 / 200 | iteration 150 / 171 | Total Loss: 2.4256272315979004 | KNN Loss: 2.4167490005493164 | CLS Loss: 0.00887826457619667\n",
      "Epoch 63 / 200 | iteration 160 / 171 | Total Loss: 2.415475845336914 | KNN Loss: 2.3966336250305176 | CLS Loss: 0.018842164427042007\n",
      "Epoch 63 / 200 | iteration 170 / 171 | Total Loss: 2.424232244491577 | KNN Loss: 2.4114949703216553 | CLS Loss: 0.012737349607050419\n",
      "Epoch: 063, Loss: 2.4314, Train: 0.9929, Valid: 0.9860, Best: 0.9870\n",
      "Epoch 64 / 200 | iteration 0 / 171 | Total Loss: 2.3958945274353027 | KNN Loss: 2.3859176635742188 | CLS Loss: 0.009976970963180065\n",
      "Epoch 64 / 200 | iteration 10 / 171 | Total Loss: 2.3942201137542725 | KNN Loss: 2.386406421661377 | CLS Loss: 0.00781374704092741\n",
      "Epoch 64 / 200 | iteration 20 / 171 | Total Loss: 2.3908302783966064 | KNN Loss: 2.3787713050842285 | CLS Loss: 0.012058921158313751\n",
      "Epoch 64 / 200 | iteration 30 / 171 | Total Loss: 2.4288899898529053 | KNN Loss: 2.4034624099731445 | CLS Loss: 0.025427602231502533\n",
      "Epoch 64 / 200 | iteration 40 / 171 | Total Loss: 2.4233970642089844 | KNN Loss: 2.4080135822296143 | CLS Loss: 0.015383587218821049\n",
      "Epoch 64 / 200 | iteration 50 / 171 | Total Loss: 2.3827531337738037 | KNN Loss: 2.3703174591064453 | CLS Loss: 0.012435751967132092\n",
      "Epoch 64 / 200 | iteration 60 / 171 | Total Loss: 2.4247806072235107 | KNN Loss: 2.36698055267334 | CLS Loss: 0.05780014023184776\n",
      "Epoch 64 / 200 | iteration 70 / 171 | Total Loss: 2.422464370727539 | KNN Loss: 2.389763593673706 | CLS Loss: 0.032700855284929276\n",
      "Epoch 64 / 200 | iteration 80 / 171 | Total Loss: 2.4858193397521973 | KNN Loss: 2.446664571762085 | CLS Loss: 0.03915480151772499\n",
      "Epoch 64 / 200 | iteration 90 / 171 | Total Loss: 2.4224746227264404 | KNN Loss: 2.4022207260131836 | CLS Loss: 0.02025388553738594\n",
      "Epoch 64 / 200 | iteration 100 / 171 | Total Loss: 2.449859142303467 | KNN Loss: 2.4310646057128906 | CLS Loss: 0.0187945906072855\n",
      "Epoch 64 / 200 | iteration 110 / 171 | Total Loss: 2.448742628097534 | KNN Loss: 2.403881072998047 | CLS Loss: 0.04486151039600372\n",
      "Epoch 64 / 200 | iteration 120 / 171 | Total Loss: 2.4557604789733887 | KNN Loss: 2.4269797801971436 | CLS Loss: 0.028780698776245117\n",
      "Epoch 64 / 200 | iteration 130 / 171 | Total Loss: 2.4530606269836426 | KNN Loss: 2.3879950046539307 | CLS Loss: 0.0650656670331955\n",
      "Epoch 64 / 200 | iteration 140 / 171 | Total Loss: 2.4435551166534424 | KNN Loss: 2.415539026260376 | CLS Loss: 0.028016092255711555\n",
      "Epoch 64 / 200 | iteration 150 / 171 | Total Loss: 2.4399657249450684 | KNN Loss: 2.4233500957489014 | CLS Loss: 0.01661555841565132\n",
      "Epoch 64 / 200 | iteration 160 / 171 | Total Loss: 2.394981622695923 | KNN Loss: 2.37939190864563 | CLS Loss: 0.015589606016874313\n",
      "Epoch 64 / 200 | iteration 170 / 171 | Total Loss: 2.4556562900543213 | KNN Loss: 2.41552734375 | CLS Loss: 0.04012899100780487\n",
      "Epoch: 064, Loss: 2.4278, Train: 0.9934, Valid: 0.9850, Best: 0.9870\n",
      "Epoch 65 / 200 | iteration 0 / 171 | Total Loss: 2.4172794818878174 | KNN Loss: 2.3765060901641846 | CLS Loss: 0.040773484855890274\n",
      "Epoch 65 / 200 | iteration 10 / 171 | Total Loss: 2.4430289268493652 | KNN Loss: 2.4130022525787354 | CLS Loss: 0.030026603490114212\n",
      "Epoch 65 / 200 | iteration 20 / 171 | Total Loss: 2.4122958183288574 | KNN Loss: 2.406240701675415 | CLS Loss: 0.006055119913071394\n",
      "Epoch 65 / 200 | iteration 30 / 171 | Total Loss: 2.423651695251465 | KNN Loss: 2.4111530780792236 | CLS Loss: 0.012498700059950352\n",
      "Epoch 65 / 200 | iteration 40 / 171 | Total Loss: 2.395817518234253 | KNN Loss: 2.3858442306518555 | CLS Loss: 0.009973369538784027\n",
      "Epoch 65 / 200 | iteration 50 / 171 | Total Loss: 2.452899217605591 | KNN Loss: 2.422947883605957 | CLS Loss: 0.02995132841169834\n",
      "Epoch 65 / 200 | iteration 60 / 171 | Total Loss: 2.4375503063201904 | KNN Loss: 2.3939449787139893 | CLS Loss: 0.043605342507362366\n",
      "Epoch 65 / 200 | iteration 70 / 171 | Total Loss: 2.4231925010681152 | KNN Loss: 2.398074150085449 | CLS Loss: 0.025118300691246986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 / 200 | iteration 80 / 171 | Total Loss: 2.467092275619507 | KNN Loss: 2.4481406211853027 | CLS Loss: 0.01895175129175186\n",
      "Epoch 65 / 200 | iteration 90 / 171 | Total Loss: 2.4158260822296143 | KNN Loss: 2.3903536796569824 | CLS Loss: 0.02547239512205124\n",
      "Epoch 65 / 200 | iteration 100 / 171 | Total Loss: 2.458944797515869 | KNN Loss: 2.4195303916931152 | CLS Loss: 0.03941429406404495\n",
      "Epoch 65 / 200 | iteration 110 / 171 | Total Loss: 2.449298620223999 | KNN Loss: 2.4285452365875244 | CLS Loss: 0.02075330540537834\n",
      "Epoch 65 / 200 | iteration 120 / 171 | Total Loss: 2.4389209747314453 | KNN Loss: 2.3916969299316406 | CLS Loss: 0.047224123030900955\n",
      "Epoch 65 / 200 | iteration 130 / 171 | Total Loss: 2.41792368888855 | KNN Loss: 2.4040770530700684 | CLS Loss: 0.013846532441675663\n",
      "Epoch 65 / 200 | iteration 140 / 171 | Total Loss: 2.452256441116333 | KNN Loss: 2.4081647396087646 | CLS Loss: 0.044091612100601196\n",
      "Epoch 65 / 200 | iteration 150 / 171 | Total Loss: 2.452345132827759 | KNN Loss: 2.4320662021636963 | CLS Loss: 0.020278925076127052\n",
      "Epoch 65 / 200 | iteration 160 / 171 | Total Loss: 2.4293088912963867 | KNN Loss: 2.4142074584960938 | CLS Loss: 0.015101322904229164\n",
      "Epoch 65 / 200 | iteration 170 / 171 | Total Loss: 2.4133760929107666 | KNN Loss: 2.4072930812835693 | CLS Loss: 0.0060831052251160145\n",
      "Epoch: 065, Loss: 2.4283, Train: 0.9934, Valid: 0.9861, Best: 0.9870\n",
      "Epoch 66 / 200 | iteration 0 / 171 | Total Loss: 2.432945728302002 | KNN Loss: 2.4011800289154053 | CLS Loss: 0.031765591353178024\n",
      "Epoch 66 / 200 | iteration 10 / 171 | Total Loss: 2.4301843643188477 | KNN Loss: 2.409609794616699 | CLS Loss: 0.020574577152729034\n",
      "Epoch 66 / 200 | iteration 20 / 171 | Total Loss: 2.4246485233306885 | KNN Loss: 2.383540153503418 | CLS Loss: 0.041108280420303345\n",
      "Epoch 66 / 200 | iteration 30 / 171 | Total Loss: 2.4427757263183594 | KNN Loss: 2.3911428451538086 | CLS Loss: 0.05163292959332466\n",
      "Epoch 66 / 200 | iteration 40 / 171 | Total Loss: 2.4290032386779785 | KNN Loss: 2.4084808826446533 | CLS Loss: 0.02052241377532482\n",
      "Epoch 66 / 200 | iteration 50 / 171 | Total Loss: 2.3989768028259277 | KNN Loss: 2.3900673389434814 | CLS Loss: 0.008909393101930618\n",
      "Epoch 66 / 200 | iteration 60 / 171 | Total Loss: 2.412785291671753 | KNN Loss: 2.3916430473327637 | CLS Loss: 0.021142220124602318\n",
      "Epoch 66 / 200 | iteration 70 / 171 | Total Loss: 2.4052863121032715 | KNN Loss: 2.3687047958374023 | CLS Loss: 0.03658144176006317\n",
      "Epoch 66 / 200 | iteration 80 / 171 | Total Loss: 2.436462163925171 | KNN Loss: 2.413745880126953 | CLS Loss: 0.02271627075970173\n",
      "Epoch 66 / 200 | iteration 90 / 171 | Total Loss: 2.4278199672698975 | KNN Loss: 2.3947906494140625 | CLS Loss: 0.033029235899448395\n",
      "Epoch 66 / 200 | iteration 100 / 171 | Total Loss: 2.414074659347534 | KNN Loss: 2.3949484825134277 | CLS Loss: 0.019126154482364655\n",
      "Epoch 66 / 200 | iteration 110 / 171 | Total Loss: 2.423530101776123 | KNN Loss: 2.4090700149536133 | CLS Loss: 0.014460035599768162\n",
      "Epoch 66 / 200 | iteration 120 / 171 | Total Loss: 2.442108631134033 | KNN Loss: 2.4251132011413574 | CLS Loss: 0.016995392739772797\n",
      "Epoch 66 / 200 | iteration 130 / 171 | Total Loss: 2.4301064014434814 | KNN Loss: 2.399123191833496 | CLS Loss: 0.03098314441740513\n",
      "Epoch 66 / 200 | iteration 140 / 171 | Total Loss: 2.432258129119873 | KNN Loss: 2.418931007385254 | CLS Loss: 0.013327199965715408\n",
      "Epoch 66 / 200 | iteration 150 / 171 | Total Loss: 2.380265712738037 | KNN Loss: 2.3559818267822266 | CLS Loss: 0.024283932521939278\n",
      "Epoch 66 / 200 | iteration 160 / 171 | Total Loss: 2.419337272644043 | KNN Loss: 2.4011504650115967 | CLS Loss: 0.01818682625889778\n",
      "Epoch 66 / 200 | iteration 170 / 171 | Total Loss: 2.4127604961395264 | KNN Loss: 2.3986053466796875 | CLS Loss: 0.01415519043803215\n",
      "Epoch: 066, Loss: 2.4267, Train: 0.9937, Valid: 0.9860, Best: 0.9870\n",
      "Epoch 67 / 200 | iteration 0 / 171 | Total Loss: 2.4021475315093994 | KNN Loss: 2.3877344131469727 | CLS Loss: 0.014413118362426758\n",
      "Epoch 67 / 200 | iteration 10 / 171 | Total Loss: 2.4761433601379395 | KNN Loss: 2.449568510055542 | CLS Loss: 0.026574749499559402\n",
      "Epoch 67 / 200 | iteration 20 / 171 | Total Loss: 2.4215168952941895 | KNN Loss: 2.415518045425415 | CLS Loss: 0.005998852197080851\n",
      "Epoch 67 / 200 | iteration 30 / 171 | Total Loss: 2.4066805839538574 | KNN Loss: 2.390550136566162 | CLS Loss: 0.016130411997437477\n",
      "Epoch 67 / 200 | iteration 40 / 171 | Total Loss: 2.4262378215789795 | KNN Loss: 2.412633180618286 | CLS Loss: 0.01360458042472601\n",
      "Epoch 67 / 200 | iteration 50 / 171 | Total Loss: 2.476684331893921 | KNN Loss: 2.4468390941619873 | CLS Loss: 0.02984520234167576\n",
      "Epoch 67 / 200 | iteration 60 / 171 | Total Loss: 2.4237358570098877 | KNN Loss: 2.3852767944335938 | CLS Loss: 0.03845899924635887\n",
      "Epoch 67 / 200 | iteration 70 / 171 | Total Loss: 2.4010748863220215 | KNN Loss: 2.3636419773101807 | CLS Loss: 0.03743290901184082\n",
      "Epoch 67 / 200 | iteration 80 / 171 | Total Loss: 2.427109718322754 | KNN Loss: 2.3902127742767334 | CLS Loss: 0.036897044628858566\n",
      "Epoch 67 / 200 | iteration 90 / 171 | Total Loss: 2.4077603816986084 | KNN Loss: 2.393406629562378 | CLS Loss: 0.01435367576777935\n",
      "Epoch 67 / 200 | iteration 100 / 171 | Total Loss: 2.396519422531128 | KNN Loss: 2.3717916011810303 | CLS Loss: 0.024727938696742058\n",
      "Epoch 67 / 200 | iteration 110 / 171 | Total Loss: 2.42332124710083 | KNN Loss: 2.3950228691101074 | CLS Loss: 0.02829848788678646\n",
      "Epoch 67 / 200 | iteration 120 / 171 | Total Loss: 2.4137277603149414 | KNN Loss: 2.3924715518951416 | CLS Loss: 0.021256305277347565\n",
      "Epoch 67 / 200 | iteration 130 / 171 | Total Loss: 2.49200439453125 | KNN Loss: 2.4402143955230713 | CLS Loss: 0.05179010331630707\n",
      "Epoch 67 / 200 | iteration 140 / 171 | Total Loss: 2.388482093811035 | KNN Loss: 2.3644063472747803 | CLS Loss: 0.024075822904706\n",
      "Epoch 67 / 200 | iteration 150 / 171 | Total Loss: 2.4280076026916504 | KNN Loss: 2.387770175933838 | CLS Loss: 0.040237464010715485\n",
      "Epoch 67 / 200 | iteration 160 / 171 | Total Loss: 2.418520450592041 | KNN Loss: 2.4126198291778564 | CLS Loss: 0.0059005338698625565\n",
      "Epoch 67 / 200 | iteration 170 / 171 | Total Loss: 2.4545085430145264 | KNN Loss: 2.4444479942321777 | CLS Loss: 0.01006051991134882\n",
      "Epoch: 067, Loss: 2.4290, Train: 0.9949, Valid: 0.9870, Best: 0.9870\n",
      "Epoch 68 / 200 | iteration 0 / 171 | Total Loss: 2.39032244682312 | KNN Loss: 2.3803863525390625 | CLS Loss: 0.009936043061316013\n",
      "Epoch 68 / 200 | iteration 10 / 171 | Total Loss: 2.410944938659668 | KNN Loss: 2.3956680297851562 | CLS Loss: 0.01527692936360836\n",
      "Epoch 68 / 200 | iteration 20 / 171 | Total Loss: 2.4096596240997314 | KNN Loss: 2.3852782249450684 | CLS Loss: 0.02438148483633995\n",
      "Epoch 68 / 200 | iteration 30 / 171 | Total Loss: 2.4503865242004395 | KNN Loss: 2.433307647705078 | CLS Loss: 0.017078964039683342\n",
      "Epoch 68 / 200 | iteration 40 / 171 | Total Loss: 2.4188544750213623 | KNN Loss: 2.4027960300445557 | CLS Loss: 0.01605839841067791\n",
      "Epoch 68 / 200 | iteration 50 / 171 | Total Loss: 2.4189953804016113 | KNN Loss: 2.385233163833618 | CLS Loss: 0.03376217931509018\n",
      "Epoch 68 / 200 | iteration 60 / 171 | Total Loss: 2.4247307777404785 | KNN Loss: 2.3983688354492188 | CLS Loss: 0.02636193111538887\n",
      "Epoch 68 / 200 | iteration 70 / 171 | Total Loss: 2.4125707149505615 | KNN Loss: 2.381316661834717 | CLS Loss: 0.03125407546758652\n",
      "Epoch 68 / 200 | iteration 80 / 171 | Total Loss: 2.413675308227539 | KNN Loss: 2.4079701900482178 | CLS Loss: 0.005705060437321663\n",
      "Epoch 68 / 200 | iteration 90 / 171 | Total Loss: 2.4185125827789307 | KNN Loss: 2.384549140930176 | CLS Loss: 0.033963534981012344\n",
      "Epoch 68 / 200 | iteration 100 / 171 | Total Loss: 2.434018611907959 | KNN Loss: 2.406585454940796 | CLS Loss: 0.027433261275291443\n",
      "Epoch 68 / 200 | iteration 110 / 171 | Total Loss: 2.4398157596588135 | KNN Loss: 2.4074504375457764 | CLS Loss: 0.03236526995897293\n",
      "Epoch 68 / 200 | iteration 120 / 171 | Total Loss: 2.4248969554901123 | KNN Loss: 2.3928327560424805 | CLS Loss: 0.032064203172922134\n",
      "Epoch 68 / 200 | iteration 130 / 171 | Total Loss: 2.4358487129211426 | KNN Loss: 2.4069197177886963 | CLS Loss: 0.028929078951478004\n",
      "Epoch 68 / 200 | iteration 140 / 171 | Total Loss: 2.442549228668213 | KNN Loss: 2.4239561557769775 | CLS Loss: 0.018593095242977142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 / 200 | iteration 150 / 171 | Total Loss: 2.4085986614227295 | KNN Loss: 2.40266489982605 | CLS Loss: 0.005933693610131741\n",
      "Epoch 68 / 200 | iteration 160 / 171 | Total Loss: 2.4361820220947266 | KNN Loss: 2.4153876304626465 | CLS Loss: 0.020794417709112167\n",
      "Epoch 68 / 200 | iteration 170 / 171 | Total Loss: 2.4543840885162354 | KNN Loss: 2.407576084136963 | CLS Loss: 0.046807993203401566\n",
      "Epoch: 068, Loss: 2.4283, Train: 0.9928, Valid: 0.9839, Best: 0.9870\n",
      "Epoch 69 / 200 | iteration 0 / 171 | Total Loss: 2.431929349899292 | KNN Loss: 2.410444974899292 | CLS Loss: 0.02148429863154888\n",
      "Epoch 69 / 200 | iteration 10 / 171 | Total Loss: 2.4101815223693848 | KNN Loss: 2.3824336528778076 | CLS Loss: 0.027747903019189835\n",
      "Epoch 69 / 200 | iteration 20 / 171 | Total Loss: 2.4099998474121094 | KNN Loss: 2.38503098487854 | CLS Loss: 0.024968847632408142\n",
      "Epoch 69 / 200 | iteration 30 / 171 | Total Loss: 2.42826247215271 | KNN Loss: 2.411430597305298 | CLS Loss: 0.01683192141354084\n",
      "Epoch 69 / 200 | iteration 40 / 171 | Total Loss: 2.4230639934539795 | KNN Loss: 2.410160779953003 | CLS Loss: 0.012903315015137196\n",
      "Epoch 69 / 200 | iteration 50 / 171 | Total Loss: 2.468362331390381 | KNN Loss: 2.443650007247925 | CLS Loss: 0.024712443351745605\n",
      "Epoch 69 / 200 | iteration 60 / 171 | Total Loss: 2.4258477687835693 | KNN Loss: 2.3994412422180176 | CLS Loss: 0.026406479999423027\n",
      "Epoch 69 / 200 | iteration 70 / 171 | Total Loss: 2.419642925262451 | KNN Loss: 2.4029037952423096 | CLS Loss: 0.016739236190915108\n",
      "Epoch 69 / 200 | iteration 80 / 171 | Total Loss: 2.397287130355835 | KNN Loss: 2.374112129211426 | CLS Loss: 0.023174962028861046\n",
      "Epoch 69 / 200 | iteration 90 / 171 | Total Loss: 2.429875612258911 | KNN Loss: 2.4151806831359863 | CLS Loss: 0.01469491794705391\n",
      "Epoch 69 / 200 | iteration 100 / 171 | Total Loss: 2.4040613174438477 | KNN Loss: 2.385503053665161 | CLS Loss: 0.018558181822299957\n",
      "Epoch 69 / 200 | iteration 110 / 171 | Total Loss: 2.4179913997650146 | KNN Loss: 2.403468370437622 | CLS Loss: 0.014523014426231384\n",
      "Epoch 69 / 200 | iteration 120 / 171 | Total Loss: 2.4168355464935303 | KNN Loss: 2.4008734226226807 | CLS Loss: 0.015962181612849236\n",
      "Epoch 69 / 200 | iteration 130 / 171 | Total Loss: 2.5038950443267822 | KNN Loss: 2.4675350189208984 | CLS Loss: 0.036360010504722595\n",
      "Epoch 69 / 200 | iteration 140 / 171 | Total Loss: 2.450338363647461 | KNN Loss: 2.409939765930176 | CLS Loss: 0.040398627519607544\n",
      "Epoch 69 / 200 | iteration 150 / 171 | Total Loss: 2.471904754638672 | KNN Loss: 2.4402527809143066 | CLS Loss: 0.031652018427848816\n",
      "Epoch 69 / 200 | iteration 160 / 171 | Total Loss: 2.464334011077881 | KNN Loss: 2.4576375484466553 | CLS Loss: 0.006696478929370642\n",
      "Epoch 69 / 200 | iteration 170 / 171 | Total Loss: 2.4676387310028076 | KNN Loss: 2.4228556156158447 | CLS Loss: 0.04478314146399498\n",
      "Epoch: 069, Loss: 2.4287, Train: 0.9939, Valid: 0.9851, Best: 0.9870\n",
      "Epoch 70 / 200 | iteration 0 / 171 | Total Loss: 2.4425277709960938 | KNN Loss: 2.413736581802368 | CLS Loss: 0.0287911519408226\n",
      "Epoch 70 / 200 | iteration 10 / 171 | Total Loss: 2.4667420387268066 | KNN Loss: 2.442042589187622 | CLS Loss: 0.024699529632925987\n",
      "Epoch 70 / 200 | iteration 20 / 171 | Total Loss: 2.4162282943725586 | KNN Loss: 2.3997209072113037 | CLS Loss: 0.016507484018802643\n",
      "Epoch 70 / 200 | iteration 30 / 171 | Total Loss: 2.4057106971740723 | KNN Loss: 2.3943233489990234 | CLS Loss: 0.011387266218662262\n",
      "Epoch 70 / 200 | iteration 40 / 171 | Total Loss: 2.4313406944274902 | KNN Loss: 2.4161908626556396 | CLS Loss: 0.015149868093430996\n",
      "Epoch 70 / 200 | iteration 50 / 171 | Total Loss: 2.3995351791381836 | KNN Loss: 2.3932788372039795 | CLS Loss: 0.006256351247429848\n",
      "Epoch 70 / 200 | iteration 60 / 171 | Total Loss: 2.4550271034240723 | KNN Loss: 2.4113640785217285 | CLS Loss: 0.04366311430931091\n",
      "Epoch 70 / 200 | iteration 70 / 171 | Total Loss: 2.4122869968414307 | KNN Loss: 2.407073736190796 | CLS Loss: 0.0052133784629404545\n",
      "Epoch 70 / 200 | iteration 80 / 171 | Total Loss: 2.452817440032959 | KNN Loss: 2.430342197418213 | CLS Loss: 0.022475216537714005\n",
      "Epoch 70 / 200 | iteration 90 / 171 | Total Loss: 2.4686508178710938 | KNN Loss: 2.4480111598968506 | CLS Loss: 0.020639732480049133\n",
      "Epoch 70 / 200 | iteration 100 / 171 | Total Loss: 2.4116885662078857 | KNN Loss: 2.3944523334503174 | CLS Loss: 0.017236284911632538\n",
      "Epoch 70 / 200 | iteration 110 / 171 | Total Loss: 2.444636106491089 | KNN Loss: 2.425919771194458 | CLS Loss: 0.018716350197792053\n",
      "Epoch 70 / 200 | iteration 120 / 171 | Total Loss: 2.4294931888580322 | KNN Loss: 2.4007723331451416 | CLS Loss: 0.028720920905470848\n",
      "Epoch 70 / 200 | iteration 130 / 171 | Total Loss: 2.393404483795166 | KNN Loss: 2.3847992420196533 | CLS Loss: 0.008605203591287136\n",
      "Epoch 70 / 200 | iteration 140 / 171 | Total Loss: 2.4501776695251465 | KNN Loss: 2.4347426891326904 | CLS Loss: 0.015434898436069489\n",
      "Epoch 70 / 200 | iteration 150 / 171 | Total Loss: 2.461517572402954 | KNN Loss: 2.4375531673431396 | CLS Loss: 0.02396433614194393\n",
      "Epoch 70 / 200 | iteration 160 / 171 | Total Loss: 2.4099137783050537 | KNN Loss: 2.3764262199401855 | CLS Loss: 0.03348749503493309\n",
      "Epoch 70 / 200 | iteration 170 / 171 | Total Loss: 2.414379835128784 | KNN Loss: 2.390998601913452 | CLS Loss: 0.023381274193525314\n",
      "Epoch: 070, Loss: 2.4251, Train: 0.9934, Valid: 0.9848, Best: 0.9870\n",
      "Epoch 71 / 200 | iteration 0 / 171 | Total Loss: 2.4321584701538086 | KNN Loss: 2.388550281524658 | CLS Loss: 0.04360809922218323\n",
      "Epoch 71 / 200 | iteration 10 / 171 | Total Loss: 2.465477466583252 | KNN Loss: 2.4254865646362305 | CLS Loss: 0.03999093174934387\n",
      "Epoch 71 / 200 | iteration 20 / 171 | Total Loss: 2.4147655963897705 | KNN Loss: 2.398477554321289 | CLS Loss: 0.01628810539841652\n",
      "Epoch 71 / 200 | iteration 30 / 171 | Total Loss: 2.445061683654785 | KNN Loss: 2.419710874557495 | CLS Loss: 0.025350701063871384\n",
      "Epoch 71 / 200 | iteration 40 / 171 | Total Loss: 2.437567949295044 | KNN Loss: 2.4210894107818604 | CLS Loss: 0.016478579491376877\n",
      "Epoch 71 / 200 | iteration 50 / 171 | Total Loss: 2.4500372409820557 | KNN Loss: 2.435135841369629 | CLS Loss: 0.014901332557201385\n",
      "Epoch 71 / 200 | iteration 60 / 171 | Total Loss: 2.4191830158233643 | KNN Loss: 2.3914403915405273 | CLS Loss: 0.02774251252412796\n",
      "Epoch 71 / 200 | iteration 70 / 171 | Total Loss: 2.399991273880005 | KNN Loss: 2.383915662765503 | CLS Loss: 0.016075504943728447\n",
      "Epoch 71 / 200 | iteration 80 / 171 | Total Loss: 2.428765296936035 | KNN Loss: 2.421907424926758 | CLS Loss: 0.006857793312519789\n",
      "Epoch 71 / 200 | iteration 90 / 171 | Total Loss: 2.438056707382202 | KNN Loss: 2.4140219688415527 | CLS Loss: 0.024034686386585236\n",
      "Epoch 71 / 200 | iteration 100 / 171 | Total Loss: 2.409959077835083 | KNN Loss: 2.3825762271881104 | CLS Loss: 0.027382850646972656\n",
      "Epoch 71 / 200 | iteration 110 / 171 | Total Loss: 2.419710159301758 | KNN Loss: 2.387596845626831 | CLS Loss: 0.03211343288421631\n",
      "Epoch 71 / 200 | iteration 120 / 171 | Total Loss: 2.4172070026397705 | KNN Loss: 2.3948607444763184 | CLS Loss: 0.022346369922161102\n",
      "Epoch 71 / 200 | iteration 130 / 171 | Total Loss: 2.4083056449890137 | KNN Loss: 2.3983168601989746 | CLS Loss: 0.009988849051296711\n",
      "Epoch 71 / 200 | iteration 140 / 171 | Total Loss: 2.4065027236938477 | KNN Loss: 2.3962671756744385 | CLS Loss: 0.010235496796667576\n",
      "Epoch 71 / 200 | iteration 150 / 171 | Total Loss: 2.4271225929260254 | KNN Loss: 2.415666341781616 | CLS Loss: 0.0114562027156353\n",
      "Epoch 71 / 200 | iteration 160 / 171 | Total Loss: 2.456190824508667 | KNN Loss: 2.4287662506103516 | CLS Loss: 0.02742449939250946\n",
      "Epoch 71 / 200 | iteration 170 / 171 | Total Loss: 2.4060962200164795 | KNN Loss: 2.3910889625549316 | CLS Loss: 0.015007308684289455\n",
      "Epoch: 071, Loss: 2.4285, Train: 0.9948, Valid: 0.9871, Best: 0.9871\n",
      "Epoch 72 / 200 | iteration 0 / 171 | Total Loss: 2.403411388397217 | KNN Loss: 2.37760329246521 | CLS Loss: 0.025808097794651985\n",
      "Epoch 72 / 200 | iteration 10 / 171 | Total Loss: 2.4000637531280518 | KNN Loss: 2.3857738971710205 | CLS Loss: 0.014289970509707928\n",
      "Epoch 72 / 200 | iteration 20 / 171 | Total Loss: 2.4053947925567627 | KNN Loss: 2.3815860748291016 | CLS Loss: 0.023808710277080536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 / 200 | iteration 30 / 171 | Total Loss: 2.4147679805755615 | KNN Loss: 2.368011474609375 | CLS Loss: 0.046756573021411896\n",
      "Epoch 72 / 200 | iteration 40 / 171 | Total Loss: 2.403822422027588 | KNN Loss: 2.3975296020507812 | CLS Loss: 0.0062927803955972195\n",
      "Epoch 72 / 200 | iteration 50 / 171 | Total Loss: 2.426968574523926 | KNN Loss: 2.417637348175049 | CLS Loss: 0.00933121982961893\n",
      "Epoch 72 / 200 | iteration 60 / 171 | Total Loss: 2.448246955871582 | KNN Loss: 2.4361321926116943 | CLS Loss: 0.012114799581468105\n",
      "Epoch 72 / 200 | iteration 70 / 171 | Total Loss: 2.462702751159668 | KNN Loss: 2.4387154579162598 | CLS Loss: 0.02398722805082798\n",
      "Epoch 72 / 200 | iteration 80 / 171 | Total Loss: 2.41074275970459 | KNN Loss: 2.394761323928833 | CLS Loss: 0.015981456264853477\n",
      "Epoch 72 / 200 | iteration 90 / 171 | Total Loss: 2.4185707569122314 | KNN Loss: 2.3942296504974365 | CLS Loss: 0.02434120699763298\n",
      "Epoch 72 / 200 | iteration 100 / 171 | Total Loss: 2.431295156478882 | KNN Loss: 2.415280342102051 | CLS Loss: 0.01601484976708889\n",
      "Epoch 72 / 200 | iteration 110 / 171 | Total Loss: 2.4413673877716064 | KNN Loss: 2.428016424179077 | CLS Loss: 0.01335085928440094\n",
      "Epoch 72 / 200 | iteration 120 / 171 | Total Loss: 2.463477849960327 | KNN Loss: 2.443772077560425 | CLS Loss: 0.01970583200454712\n",
      "Epoch 72 / 200 | iteration 130 / 171 | Total Loss: 2.4027278423309326 | KNN Loss: 2.394129753112793 | CLS Loss: 0.008598176762461662\n",
      "Epoch 72 / 200 | iteration 140 / 171 | Total Loss: 2.42547607421875 | KNN Loss: 2.4023189544677734 | CLS Loss: 0.023157216608524323\n",
      "Epoch 72 / 200 | iteration 150 / 171 | Total Loss: 2.4203624725341797 | KNN Loss: 2.4082202911376953 | CLS Loss: 0.012142211198806763\n",
      "Epoch 72 / 200 | iteration 160 / 171 | Total Loss: 2.4139623641967773 | KNN Loss: 2.3893392086029053 | CLS Loss: 0.024623041972517967\n",
      "Epoch 72 / 200 | iteration 170 / 171 | Total Loss: 2.3946382999420166 | KNN Loss: 2.3897531032562256 | CLS Loss: 0.004885148722678423\n",
      "Epoch: 072, Loss: 2.4270, Train: 0.9940, Valid: 0.9855, Best: 0.9871\n",
      "Epoch 73 / 200 | iteration 0 / 171 | Total Loss: 2.402062177658081 | KNN Loss: 2.3902249336242676 | CLS Loss: 0.011837152764201164\n",
      "Epoch 73 / 200 | iteration 10 / 171 | Total Loss: 2.388965368270874 | KNN Loss: 2.3767049312591553 | CLS Loss: 0.01226047333329916\n",
      "Epoch 73 / 200 | iteration 20 / 171 | Total Loss: 2.418642997741699 | KNN Loss: 2.4029316902160645 | CLS Loss: 0.01571129821240902\n",
      "Epoch 73 / 200 | iteration 30 / 171 | Total Loss: 2.4322526454925537 | KNN Loss: 2.4114668369293213 | CLS Loss: 0.020785827189683914\n",
      "Epoch 73 / 200 | iteration 40 / 171 | Total Loss: 2.4566073417663574 | KNN Loss: 2.439305067062378 | CLS Loss: 0.01730216294527054\n",
      "Epoch 73 / 200 | iteration 50 / 171 | Total Loss: 2.431305408477783 | KNN Loss: 2.409536123275757 | CLS Loss: 0.021769404411315918\n",
      "Epoch 73 / 200 | iteration 60 / 171 | Total Loss: 2.4135901927948 | KNN Loss: 2.3909668922424316 | CLS Loss: 0.022623268887400627\n",
      "Epoch 73 / 200 | iteration 70 / 171 | Total Loss: 2.3851230144500732 | KNN Loss: 2.36946439743042 | CLS Loss: 0.015658680349588394\n",
      "Epoch 73 / 200 | iteration 80 / 171 | Total Loss: 2.41974139213562 | KNN Loss: 2.4073801040649414 | CLS Loss: 0.012361297383904457\n",
      "Epoch 73 / 200 | iteration 90 / 171 | Total Loss: 2.431130886077881 | KNN Loss: 2.4123477935791016 | CLS Loss: 0.018783066421747208\n",
      "Epoch 73 / 200 | iteration 100 / 171 | Total Loss: 2.381405830383301 | KNN Loss: 2.35686993598938 | CLS Loss: 0.024535909295082092\n",
      "Epoch 73 / 200 | iteration 110 / 171 | Total Loss: 2.4521265029907227 | KNN Loss: 2.4250245094299316 | CLS Loss: 0.02710196189582348\n",
      "Epoch 73 / 200 | iteration 120 / 171 | Total Loss: 2.428253412246704 | KNN Loss: 2.40270733833313 | CLS Loss: 0.025546057149767876\n",
      "Epoch 73 / 200 | iteration 130 / 171 | Total Loss: 2.4242494106292725 | KNN Loss: 2.394634962081909 | CLS Loss: 0.029614543542265892\n",
      "Epoch 73 / 200 | iteration 140 / 171 | Total Loss: 2.3884315490722656 | KNN Loss: 2.358717203140259 | CLS Loss: 0.029714373871684074\n",
      "Epoch 73 / 200 | iteration 150 / 171 | Total Loss: 2.423785924911499 | KNN Loss: 2.3914499282836914 | CLS Loss: 0.032336022704839706\n",
      "Epoch 73 / 200 | iteration 160 / 171 | Total Loss: 2.4240005016326904 | KNN Loss: 2.3992128372192383 | CLS Loss: 0.024787722155451775\n",
      "Epoch 73 / 200 | iteration 170 / 171 | Total Loss: 2.4352872371673584 | KNN Loss: 2.426976442337036 | CLS Loss: 0.008310789242386818\n",
      "Epoch: 073, Loss: 2.4248, Train: 0.9933, Valid: 0.9847, Best: 0.9871\n",
      "Epoch 74 / 200 | iteration 0 / 171 | Total Loss: 2.4520089626312256 | KNN Loss: 2.4289824962615967 | CLS Loss: 0.02302653342485428\n",
      "Epoch 74 / 200 | iteration 10 / 171 | Total Loss: 2.4214324951171875 | KNN Loss: 2.394592523574829 | CLS Loss: 0.026840006932616234\n",
      "Epoch 74 / 200 | iteration 20 / 171 | Total Loss: 2.4165070056915283 | KNN Loss: 2.3886585235595703 | CLS Loss: 0.027848556637763977\n",
      "Epoch 74 / 200 | iteration 30 / 171 | Total Loss: 2.4213197231292725 | KNN Loss: 2.4062201976776123 | CLS Loss: 0.015099581331014633\n",
      "Epoch 74 / 200 | iteration 40 / 171 | Total Loss: 2.4375269412994385 | KNN Loss: 2.400787591934204 | CLS Loss: 0.03673931956291199\n",
      "Epoch 74 / 200 | iteration 50 / 171 | Total Loss: 2.4127695560455322 | KNN Loss: 2.359259843826294 | CLS Loss: 0.05350978672504425\n",
      "Epoch 74 / 200 | iteration 60 / 171 | Total Loss: 2.4153144359588623 | KNN Loss: 2.413646697998047 | CLS Loss: 0.0016677363310009241\n",
      "Epoch 74 / 200 | iteration 70 / 171 | Total Loss: 2.4185123443603516 | KNN Loss: 2.3784995079040527 | CLS Loss: 0.04001293331384659\n",
      "Epoch 74 / 200 | iteration 80 / 171 | Total Loss: 2.450982093811035 | KNN Loss: 2.4372990131378174 | CLS Loss: 0.013683135621249676\n",
      "Epoch 74 / 200 | iteration 90 / 171 | Total Loss: 2.467292070388794 | KNN Loss: 2.4376916885375977 | CLS Loss: 0.02960028313100338\n",
      "Epoch 74 / 200 | iteration 100 / 171 | Total Loss: 2.4150266647338867 | KNN Loss: 2.3836934566497803 | CLS Loss: 0.03133312612771988\n",
      "Epoch 74 / 200 | iteration 110 / 171 | Total Loss: 2.421726703643799 | KNN Loss: 2.417947292327881 | CLS Loss: 0.0037794257514178753\n",
      "Epoch 74 / 200 | iteration 120 / 171 | Total Loss: 2.4145493507385254 | KNN Loss: 2.399643659591675 | CLS Loss: 0.014905791729688644\n",
      "Epoch 74 / 200 | iteration 130 / 171 | Total Loss: 2.4230644702911377 | KNN Loss: 2.3864805698394775 | CLS Loss: 0.03658399358391762\n",
      "Epoch 74 / 200 | iteration 140 / 171 | Total Loss: 2.419170379638672 | KNN Loss: 2.409296751022339 | CLS Loss: 0.00987351406365633\n",
      "Epoch 74 / 200 | iteration 150 / 171 | Total Loss: 2.4164230823516846 | KNN Loss: 2.4026098251342773 | CLS Loss: 0.013813161291182041\n",
      "Epoch 74 / 200 | iteration 160 / 171 | Total Loss: 2.4198529720306396 | KNN Loss: 2.392322301864624 | CLS Loss: 0.02753077819943428\n",
      "Epoch 74 / 200 | iteration 170 / 171 | Total Loss: 2.405606269836426 | KNN Loss: 2.3885321617126465 | CLS Loss: 0.01707421988248825\n",
      "Epoch: 074, Loss: 2.4271, Train: 0.9941, Valid: 0.9858, Best: 0.9871\n",
      "Epoch 75 / 200 | iteration 0 / 171 | Total Loss: 2.420449733734131 | KNN Loss: 2.400339126586914 | CLS Loss: 0.020110607147216797\n",
      "Epoch 75 / 200 | iteration 10 / 171 | Total Loss: 2.4065134525299072 | KNN Loss: 2.3822522163391113 | CLS Loss: 0.024261195212602615\n",
      "Epoch 75 / 200 | iteration 20 / 171 | Total Loss: 2.437678575515747 | KNN Loss: 2.420989513397217 | CLS Loss: 0.01668906770646572\n",
      "Epoch 75 / 200 | iteration 30 / 171 | Total Loss: 2.440988540649414 | KNN Loss: 2.4246222972869873 | CLS Loss: 0.01636619307100773\n",
      "Epoch 75 / 200 | iteration 40 / 171 | Total Loss: 2.4352142810821533 | KNN Loss: 2.4162092208862305 | CLS Loss: 0.0190050657838583\n",
      "Epoch 75 / 200 | iteration 50 / 171 | Total Loss: 2.4056787490844727 | KNN Loss: 2.3885891437530518 | CLS Loss: 0.01708967052400112\n",
      "Epoch 75 / 200 | iteration 60 / 171 | Total Loss: 2.3722944259643555 | KNN Loss: 2.3552064895629883 | CLS Loss: 0.017087969928979874\n",
      "Epoch 75 / 200 | iteration 70 / 171 | Total Loss: 2.428555727005005 | KNN Loss: 2.4091989994049072 | CLS Loss: 0.019356748089194298\n",
      "Epoch 75 / 200 | iteration 80 / 171 | Total Loss: 2.449869155883789 | KNN Loss: 2.4220526218414307 | CLS Loss: 0.02781658060848713\n",
      "Epoch 75 / 200 | iteration 90 / 171 | Total Loss: 2.4322123527526855 | KNN Loss: 2.408313512802124 | CLS Loss: 0.02389892376959324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 / 200 | iteration 100 / 171 | Total Loss: 2.4168057441711426 | KNN Loss: 2.3943166732788086 | CLS Loss: 0.022488955408334732\n",
      "Epoch 75 / 200 | iteration 110 / 171 | Total Loss: 2.412680149078369 | KNN Loss: 2.4000706672668457 | CLS Loss: 0.012609390541911125\n",
      "Epoch 75 / 200 | iteration 120 / 171 | Total Loss: 2.4174296855926514 | KNN Loss: 2.380970001220703 | CLS Loss: 0.036459799855947495\n",
      "Epoch 75 / 200 | iteration 130 / 171 | Total Loss: 2.468350648880005 | KNN Loss: 2.4354817867279053 | CLS Loss: 0.03286897391080856\n",
      "Epoch 75 / 200 | iteration 140 / 171 | Total Loss: 2.440643787384033 | KNN Loss: 2.392266273498535 | CLS Loss: 0.048377398401498795\n",
      "Epoch 75 / 200 | iteration 150 / 171 | Total Loss: 2.45760440826416 | KNN Loss: 2.4144065380096436 | CLS Loss: 0.04319782555103302\n",
      "Epoch 75 / 200 | iteration 160 / 171 | Total Loss: 2.4324522018432617 | KNN Loss: 2.4145588874816895 | CLS Loss: 0.017893211916089058\n",
      "Epoch 75 / 200 | iteration 170 / 171 | Total Loss: 2.4566662311553955 | KNN Loss: 2.4320929050445557 | CLS Loss: 0.02457326278090477\n",
      "Epoch: 075, Loss: 2.4268, Train: 0.9947, Valid: 0.9873, Best: 0.9873\n",
      "Epoch 76 / 200 | iteration 0 / 171 | Total Loss: 2.3982465267181396 | KNN Loss: 2.3831048011779785 | CLS Loss: 0.015141721814870834\n",
      "Epoch 76 / 200 | iteration 10 / 171 | Total Loss: 2.3960392475128174 | KNN Loss: 2.3697800636291504 | CLS Loss: 0.026259277015924454\n",
      "Epoch 76 / 200 | iteration 20 / 171 | Total Loss: 2.386664867401123 | KNN Loss: 2.372222661972046 | CLS Loss: 0.014442087151110172\n",
      "Epoch 76 / 200 | iteration 30 / 171 | Total Loss: 2.4080374240875244 | KNN Loss: 2.387904405593872 | CLS Loss: 0.02013290300965309\n",
      "Epoch 76 / 200 | iteration 40 / 171 | Total Loss: 2.4274020195007324 | KNN Loss: 2.409761905670166 | CLS Loss: 0.017640065401792526\n",
      "Epoch 76 / 200 | iteration 50 / 171 | Total Loss: 2.423962354660034 | KNN Loss: 2.4042084217071533 | CLS Loss: 0.019754016771912575\n",
      "Epoch 76 / 200 | iteration 60 / 171 | Total Loss: 2.409102439880371 | KNN Loss: 2.397411823272705 | CLS Loss: 0.011690517887473106\n",
      "Epoch 76 / 200 | iteration 70 / 171 | Total Loss: 2.4106247425079346 | KNN Loss: 2.4025096893310547 | CLS Loss: 0.00811510905623436\n",
      "Epoch 76 / 200 | iteration 80 / 171 | Total Loss: 2.449632406234741 | KNN Loss: 2.4208781719207764 | CLS Loss: 0.028754210099577904\n",
      "Epoch 76 / 200 | iteration 90 / 171 | Total Loss: 2.4146838188171387 | KNN Loss: 2.3874406814575195 | CLS Loss: 0.027243124321103096\n",
      "Epoch 76 / 200 | iteration 100 / 171 | Total Loss: 2.4340527057647705 | KNN Loss: 2.423002243041992 | CLS Loss: 0.011050362139940262\n",
      "Epoch 76 / 200 | iteration 110 / 171 | Total Loss: 2.4453678131103516 | KNN Loss: 2.3932297229766846 | CLS Loss: 0.052138105034828186\n",
      "Epoch 76 / 200 | iteration 120 / 171 | Total Loss: 2.394597291946411 | KNN Loss: 2.3842544555664062 | CLS Loss: 0.010342733934521675\n",
      "Epoch 76 / 200 | iteration 130 / 171 | Total Loss: 2.4078104496002197 | KNN Loss: 2.377876043319702 | CLS Loss: 0.029934510588645935\n",
      "Epoch 76 / 200 | iteration 140 / 171 | Total Loss: 2.4259486198425293 | KNN Loss: 2.4120655059814453 | CLS Loss: 0.013883214443922043\n",
      "Epoch 76 / 200 | iteration 150 / 171 | Total Loss: 2.3948755264282227 | KNN Loss: 2.380465507507324 | CLS Loss: 0.01440991647541523\n",
      "Epoch 76 / 200 | iteration 160 / 171 | Total Loss: 2.4393553733825684 | KNN Loss: 2.4054505825042725 | CLS Loss: 0.03390467166900635\n",
      "Epoch 76 / 200 | iteration 170 / 171 | Total Loss: 2.4291744232177734 | KNN Loss: 2.4119911193847656 | CLS Loss: 0.01718328148126602\n",
      "Epoch: 076, Loss: 2.4236, Train: 0.9942, Valid: 0.9852, Best: 0.9873\n",
      "Epoch 77 / 200 | iteration 0 / 171 | Total Loss: 2.404381513595581 | KNN Loss: 2.3875410556793213 | CLS Loss: 0.01684054359793663\n",
      "Epoch 77 / 200 | iteration 10 / 171 | Total Loss: 2.4320735931396484 | KNN Loss: 2.4129974842071533 | CLS Loss: 0.0190761536359787\n",
      "Epoch 77 / 200 | iteration 20 / 171 | Total Loss: 2.4566233158111572 | KNN Loss: 2.4372055530548096 | CLS Loss: 0.019417647272348404\n",
      "Epoch 77 / 200 | iteration 30 / 171 | Total Loss: 2.4088973999023438 | KNN Loss: 2.3972811698913574 | CLS Loss: 0.01161620020866394\n",
      "Epoch 77 / 200 | iteration 40 / 171 | Total Loss: 2.4052035808563232 | KNN Loss: 2.394291877746582 | CLS Loss: 0.010911687277257442\n",
      "Epoch 77 / 200 | iteration 50 / 171 | Total Loss: 2.3971099853515625 | KNN Loss: 2.3914992809295654 | CLS Loss: 0.0056108152493834496\n",
      "Epoch 77 / 200 | iteration 60 / 171 | Total Loss: 2.4307374954223633 | KNN Loss: 2.4008166790008545 | CLS Loss: 0.029920794069767\n",
      "Epoch 77 / 200 | iteration 70 / 171 | Total Loss: 2.4250292778015137 | KNN Loss: 2.4078369140625 | CLS Loss: 0.017192458733916283\n",
      "Epoch 77 / 200 | iteration 80 / 171 | Total Loss: 2.4079220294952393 | KNN Loss: 2.397966146469116 | CLS Loss: 0.009955923072993755\n",
      "Epoch 77 / 200 | iteration 90 / 171 | Total Loss: 2.4022417068481445 | KNN Loss: 2.392167568206787 | CLS Loss: 0.010074176825582981\n",
      "Epoch 77 / 200 | iteration 100 / 171 | Total Loss: 2.457470655441284 | KNN Loss: 2.440045118331909 | CLS Loss: 0.017425602301955223\n",
      "Epoch 77 / 200 | iteration 110 / 171 | Total Loss: 2.400853157043457 | KNN Loss: 2.371263265609741 | CLS Loss: 0.029589856043457985\n",
      "Epoch 77 / 200 | iteration 120 / 171 | Total Loss: 2.3991973400115967 | KNN Loss: 2.3940725326538086 | CLS Loss: 0.005124704912304878\n",
      "Epoch 77 / 200 | iteration 130 / 171 | Total Loss: 2.4061567783355713 | KNN Loss: 2.389758825302124 | CLS Loss: 0.01639803685247898\n",
      "Epoch 77 / 200 | iteration 140 / 171 | Total Loss: 2.4157814979553223 | KNN Loss: 2.393615961074829 | CLS Loss: 0.022165467962622643\n",
      "Epoch 77 / 200 | iteration 150 / 171 | Total Loss: 2.4268226623535156 | KNN Loss: 2.3870887756347656 | CLS Loss: 0.03973379358649254\n",
      "Epoch 77 / 200 | iteration 160 / 171 | Total Loss: 2.442683219909668 | KNN Loss: 2.413900852203369 | CLS Loss: 0.028782280161976814\n",
      "Epoch 77 / 200 | iteration 170 / 171 | Total Loss: 2.424182415008545 | KNN Loss: 2.393965005874634 | CLS Loss: 0.03021734207868576\n",
      "Epoch: 077, Loss: 2.4238, Train: 0.9954, Valid: 0.9864, Best: 0.9873\n",
      "Epoch 78 / 200 | iteration 0 / 171 | Total Loss: 2.4402990341186523 | KNN Loss: 2.427353620529175 | CLS Loss: 0.012945410795509815\n",
      "Epoch 78 / 200 | iteration 10 / 171 | Total Loss: 2.4092190265655518 | KNN Loss: 2.3939878940582275 | CLS Loss: 0.015231087803840637\n",
      "Epoch 78 / 200 | iteration 20 / 171 | Total Loss: 2.4227476119995117 | KNN Loss: 2.407160758972168 | CLS Loss: 0.015586864203214645\n",
      "Epoch 78 / 200 | iteration 30 / 171 | Total Loss: 2.440154552459717 | KNN Loss: 2.4264538288116455 | CLS Loss: 0.01370065938681364\n",
      "Epoch 78 / 200 | iteration 40 / 171 | Total Loss: 2.4223721027374268 | KNN Loss: 2.3952770233154297 | CLS Loss: 0.027095157653093338\n",
      "Epoch 78 / 200 | iteration 50 / 171 | Total Loss: 2.456139326095581 | KNN Loss: 2.4145090579986572 | CLS Loss: 0.041630178689956665\n",
      "Epoch 78 / 200 | iteration 60 / 171 | Total Loss: 2.4096808433532715 | KNN Loss: 2.3863465785980225 | CLS Loss: 0.02333415485918522\n",
      "Epoch 78 / 200 | iteration 70 / 171 | Total Loss: 2.4088592529296875 | KNN Loss: 2.4024670124053955 | CLS Loss: 0.006392260547727346\n",
      "Epoch 78 / 200 | iteration 80 / 171 | Total Loss: 2.398861885070801 | KNN Loss: 2.387768268585205 | CLS Loss: 0.011093671433627605\n",
      "Epoch 78 / 200 | iteration 90 / 171 | Total Loss: 2.4391472339630127 | KNN Loss: 2.4263076782226562 | CLS Loss: 0.012839443050324917\n",
      "Epoch 78 / 200 | iteration 100 / 171 | Total Loss: 2.456110715866089 | KNN Loss: 2.442744731903076 | CLS Loss: 0.013365893624722958\n",
      "Epoch 78 / 200 | iteration 110 / 171 | Total Loss: 2.3943793773651123 | KNN Loss: 2.378291130065918 | CLS Loss: 0.016088277101516724\n",
      "Epoch 78 / 200 | iteration 120 / 171 | Total Loss: 2.428171396255493 | KNN Loss: 2.4188947677612305 | CLS Loss: 0.009276597760617733\n",
      "Epoch 78 / 200 | iteration 130 / 171 | Total Loss: 2.402337074279785 | KNN Loss: 2.3835558891296387 | CLS Loss: 0.018781183287501335\n",
      "Epoch 78 / 200 | iteration 140 / 171 | Total Loss: 2.4266676902770996 | KNN Loss: 2.416940927505493 | CLS Loss: 0.009726646356284618\n",
      "Epoch 78 / 200 | iteration 150 / 171 | Total Loss: 2.461225986480713 | KNN Loss: 2.4263219833374023 | CLS Loss: 0.03490390628576279\n",
      "Epoch 78 / 200 | iteration 160 / 171 | Total Loss: 2.4305927753448486 | KNN Loss: 2.4061026573181152 | CLS Loss: 0.024490129202604294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 / 200 | iteration 170 / 171 | Total Loss: 2.4067165851593018 | KNN Loss: 2.3945562839508057 | CLS Loss: 0.012160374782979488\n",
      "Epoch: 078, Loss: 2.4245, Train: 0.9948, Valid: 0.9874, Best: 0.9874\n",
      "Epoch 79 / 200 | iteration 0 / 171 | Total Loss: 2.447366714477539 | KNN Loss: 2.4205687046051025 | CLS Loss: 0.026798121631145477\n",
      "Epoch 79 / 200 | iteration 10 / 171 | Total Loss: 2.417611837387085 | KNN Loss: 2.394016742706299 | CLS Loss: 0.023595081642270088\n",
      "Epoch 79 / 200 | iteration 20 / 171 | Total Loss: 2.380323886871338 | KNN Loss: 2.3669354915618896 | CLS Loss: 0.013388407416641712\n",
      "Epoch 79 / 200 | iteration 30 / 171 | Total Loss: 2.40809965133667 | KNN Loss: 2.401171922683716 | CLS Loss: 0.006927793379873037\n",
      "Epoch 79 / 200 | iteration 40 / 171 | Total Loss: 2.421306848526001 | KNN Loss: 2.4159114360809326 | CLS Loss: 0.0053954096511006355\n",
      "Epoch 79 / 200 | iteration 50 / 171 | Total Loss: 2.435999870300293 | KNN Loss: 2.3997762203216553 | CLS Loss: 0.036223605275154114\n",
      "Epoch 79 / 200 | iteration 60 / 171 | Total Loss: 2.4524052143096924 | KNN Loss: 2.4365334510803223 | CLS Loss: 0.015871647745370865\n",
      "Epoch 79 / 200 | iteration 70 / 171 | Total Loss: 2.3984997272491455 | KNN Loss: 2.365438222885132 | CLS Loss: 0.033061493188142776\n",
      "Epoch 79 / 200 | iteration 80 / 171 | Total Loss: 2.402071952819824 | KNN Loss: 2.3847603797912598 | CLS Loss: 0.01731147989630699\n",
      "Epoch 79 / 200 | iteration 90 / 171 | Total Loss: 2.4206011295318604 | KNN Loss: 2.409473419189453 | CLS Loss: 0.01112782396376133\n",
      "Epoch 79 / 200 | iteration 100 / 171 | Total Loss: 2.4115164279937744 | KNN Loss: 2.385347366333008 | CLS Loss: 0.026168959215283394\n",
      "Epoch 79 / 200 | iteration 110 / 171 | Total Loss: 2.4373743534088135 | KNN Loss: 2.4247655868530273 | CLS Loss: 0.01260876189917326\n",
      "Epoch 79 / 200 | iteration 120 / 171 | Total Loss: 2.4139556884765625 | KNN Loss: 2.3944220542907715 | CLS Loss: 0.019533533602952957\n",
      "Epoch 79 / 200 | iteration 130 / 171 | Total Loss: 2.4408462047576904 | KNN Loss: 2.4044461250305176 | CLS Loss: 0.036399971693754196\n",
      "Epoch 79 / 200 | iteration 140 / 171 | Total Loss: 2.44008207321167 | KNN Loss: 2.4083988666534424 | CLS Loss: 0.03168325126171112\n",
      "Epoch 79 / 200 | iteration 150 / 171 | Total Loss: 2.432396411895752 | KNN Loss: 2.419329881668091 | CLS Loss: 0.013066571205854416\n",
      "Epoch 79 / 200 | iteration 160 / 171 | Total Loss: 2.4228975772857666 | KNN Loss: 2.376671552658081 | CLS Loss: 0.04622597247362137\n",
      "Epoch 79 / 200 | iteration 170 / 171 | Total Loss: 2.401705026626587 | KNN Loss: 2.389228105545044 | CLS Loss: 0.012476831674575806\n",
      "Epoch: 079, Loss: 2.4217, Train: 0.9963, Valid: 0.9865, Best: 0.9874\n",
      "Epoch 80 / 200 | iteration 0 / 171 | Total Loss: 2.417750597000122 | KNN Loss: 2.3996729850769043 | CLS Loss: 0.018077708780765533\n",
      "Epoch 80 / 200 | iteration 10 / 171 | Total Loss: 2.429478406906128 | KNN Loss: 2.4216296672821045 | CLS Loss: 0.007848761975765228\n",
      "Epoch 80 / 200 | iteration 20 / 171 | Total Loss: 2.406467914581299 | KNN Loss: 2.387495756149292 | CLS Loss: 0.018972188234329224\n",
      "Epoch 80 / 200 | iteration 30 / 171 | Total Loss: 2.431565761566162 | KNN Loss: 2.406602621078491 | CLS Loss: 0.0249631404876709\n",
      "Epoch 80 / 200 | iteration 40 / 171 | Total Loss: 2.47426700592041 | KNN Loss: 2.4538626670837402 | CLS Loss: 0.02040431834757328\n",
      "Epoch 80 / 200 | iteration 50 / 171 | Total Loss: 2.436886787414551 | KNN Loss: 2.4049699306488037 | CLS Loss: 0.03191692382097244\n",
      "Epoch 80 / 200 | iteration 60 / 171 | Total Loss: 2.427565336227417 | KNN Loss: 2.4207406044006348 | CLS Loss: 0.006824614014476538\n",
      "Epoch 80 / 200 | iteration 70 / 171 | Total Loss: 2.42729115486145 | KNN Loss: 2.4031543731689453 | CLS Loss: 0.02413678541779518\n",
      "Epoch 80 / 200 | iteration 80 / 171 | Total Loss: 2.427354097366333 | KNN Loss: 2.4144887924194336 | CLS Loss: 0.0128652174025774\n",
      "Epoch 80 / 200 | iteration 90 / 171 | Total Loss: 2.3880112171173096 | KNN Loss: 2.3818156719207764 | CLS Loss: 0.006195596419274807\n",
      "Epoch 80 / 200 | iteration 100 / 171 | Total Loss: 2.416926622390747 | KNN Loss: 2.38958477973938 | CLS Loss: 0.027341781184077263\n",
      "Epoch 80 / 200 | iteration 110 / 171 | Total Loss: 2.4038033485412598 | KNN Loss: 2.3891818523406982 | CLS Loss: 0.014621440321207047\n",
      "Epoch 80 / 200 | iteration 120 / 171 | Total Loss: 2.4207775592803955 | KNN Loss: 2.398376703262329 | CLS Loss: 0.022400949150323868\n",
      "Epoch 80 / 200 | iteration 130 / 171 | Total Loss: 2.449306011199951 | KNN Loss: 2.439074993133545 | CLS Loss: 0.010231070220470428\n",
      "Epoch 80 / 200 | iteration 140 / 171 | Total Loss: 2.4147989749908447 | KNN Loss: 2.396010398864746 | CLS Loss: 0.018788563087582588\n",
      "Epoch 80 / 200 | iteration 150 / 171 | Total Loss: 2.3979434967041016 | KNN Loss: 2.3862240314483643 | CLS Loss: 0.011719408445060253\n",
      "Epoch 80 / 200 | iteration 160 / 171 | Total Loss: 2.4312703609466553 | KNN Loss: 2.408160448074341 | CLS Loss: 0.023109856992959976\n",
      "Epoch 80 / 200 | iteration 170 / 171 | Total Loss: 2.4107601642608643 | KNN Loss: 2.399646520614624 | CLS Loss: 0.011113679967820644\n",
      "Epoch: 080, Loss: 2.4271, Train: 0.9947, Valid: 0.9872, Best: 0.9874\n",
      "Epoch 81 / 200 | iteration 0 / 171 | Total Loss: 2.417151927947998 | KNN Loss: 2.401901960372925 | CLS Loss: 0.01524996105581522\n",
      "Epoch 81 / 200 | iteration 10 / 171 | Total Loss: 2.4248385429382324 | KNN Loss: 2.407054901123047 | CLS Loss: 0.017783688381314278\n",
      "Epoch 81 / 200 | iteration 20 / 171 | Total Loss: 2.411435604095459 | KNN Loss: 2.3810176849365234 | CLS Loss: 0.030418002977967262\n",
      "Epoch 81 / 200 | iteration 30 / 171 | Total Loss: 2.4231626987457275 | KNN Loss: 2.4025516510009766 | CLS Loss: 0.020611027255654335\n",
      "Epoch 81 / 200 | iteration 40 / 171 | Total Loss: 2.41690993309021 | KNN Loss: 2.389063835144043 | CLS Loss: 0.0278461966663599\n",
      "Epoch 81 / 200 | iteration 50 / 171 | Total Loss: 2.371554136276245 | KNN Loss: 2.369567632675171 | CLS Loss: 0.001986536430194974\n",
      "Epoch 81 / 200 | iteration 60 / 171 | Total Loss: 2.4233174324035645 | KNN Loss: 2.4179205894470215 | CLS Loss: 0.005396755412220955\n",
      "Epoch 81 / 200 | iteration 70 / 171 | Total Loss: 2.430455446243286 | KNN Loss: 2.4279091358184814 | CLS Loss: 0.002546323463320732\n",
      "Epoch 81 / 200 | iteration 80 / 171 | Total Loss: 2.389129877090454 | KNN Loss: 2.3761496543884277 | CLS Loss: 0.01298016682267189\n",
      "Epoch 81 / 200 | iteration 90 / 171 | Total Loss: 2.408674716949463 | KNN Loss: 2.3870484828948975 | CLS Loss: 0.02162628434598446\n",
      "Epoch 81 / 200 | iteration 100 / 171 | Total Loss: 2.3966352939605713 | KNN Loss: 2.3729817867279053 | CLS Loss: 0.02365340106189251\n",
      "Epoch 81 / 200 | iteration 110 / 171 | Total Loss: 2.4188108444213867 | KNN Loss: 2.399141550064087 | CLS Loss: 0.01966940425336361\n",
      "Epoch 81 / 200 | iteration 120 / 171 | Total Loss: 2.468191146850586 | KNN Loss: 2.430636405944824 | CLS Loss: 0.037554796785116196\n",
      "Epoch 81 / 200 | iteration 130 / 171 | Total Loss: 2.401754379272461 | KNN Loss: 2.373873472213745 | CLS Loss: 0.027880847454071045\n",
      "Epoch 81 / 200 | iteration 140 / 171 | Total Loss: 2.4293055534362793 | KNN Loss: 2.3873236179351807 | CLS Loss: 0.041981860995292664\n",
      "Epoch 81 / 200 | iteration 150 / 171 | Total Loss: 2.436960220336914 | KNN Loss: 2.4278149604797363 | CLS Loss: 0.009145285002887249\n",
      "Epoch 81 / 200 | iteration 160 / 171 | Total Loss: 2.415818214416504 | KNN Loss: 2.397130012512207 | CLS Loss: 0.01868809014558792\n",
      "Epoch 81 / 200 | iteration 170 / 171 | Total Loss: 2.4258713722229004 | KNN Loss: 2.4169578552246094 | CLS Loss: 0.008913489058613777\n",
      "Epoch: 081, Loss: 2.4236, Train: 0.9943, Valid: 0.9858, Best: 0.9874\n",
      "Epoch 82 / 200 | iteration 0 / 171 | Total Loss: 2.443108558654785 | KNN Loss: 2.4275107383728027 | CLS Loss: 0.015597861260175705\n",
      "Epoch 82 / 200 | iteration 10 / 171 | Total Loss: 2.424049139022827 | KNN Loss: 2.3893232345581055 | CLS Loss: 0.03472596034407616\n",
      "Epoch 82 / 200 | iteration 20 / 171 | Total Loss: 2.4380061626434326 | KNN Loss: 2.4296374320983887 | CLS Loss: 0.008368688635528088\n",
      "Epoch 82 / 200 | iteration 30 / 171 | Total Loss: 2.4524214267730713 | KNN Loss: 2.4256560802459717 | CLS Loss: 0.026765251532197\n",
      "Epoch 82 / 200 | iteration 40 / 171 | Total Loss: 2.4472172260284424 | KNN Loss: 2.425454616546631 | CLS Loss: 0.021762704476714134\n",
      "Epoch 82 / 200 | iteration 50 / 171 | Total Loss: 2.436028003692627 | KNN Loss: 2.406405448913574 | CLS Loss: 0.02962261438369751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 / 200 | iteration 60 / 171 | Total Loss: 2.464536190032959 | KNN Loss: 2.4517765045166016 | CLS Loss: 0.012759581208229065\n",
      "Epoch 82 / 200 | iteration 70 / 171 | Total Loss: 2.3993563652038574 | KNN Loss: 2.390620231628418 | CLS Loss: 0.008736107498407364\n",
      "Epoch 82 / 200 | iteration 80 / 171 | Total Loss: 2.4322257041931152 | KNN Loss: 2.407219648361206 | CLS Loss: 0.025006145238876343\n",
      "Epoch 82 / 200 | iteration 90 / 171 | Total Loss: 2.423063278198242 | KNN Loss: 2.3959202766418457 | CLS Loss: 0.02714288979768753\n",
      "Epoch 82 / 200 | iteration 100 / 171 | Total Loss: 2.4190518856048584 | KNN Loss: 2.3951735496520996 | CLS Loss: 0.023878393694758415\n",
      "Epoch 82 / 200 | iteration 110 / 171 | Total Loss: 2.4245893955230713 | KNN Loss: 2.4150545597076416 | CLS Loss: 0.009534938260912895\n",
      "Epoch 82 / 200 | iteration 120 / 171 | Total Loss: 2.4484574794769287 | KNN Loss: 2.4385032653808594 | CLS Loss: 0.009954111650586128\n",
      "Epoch 82 / 200 | iteration 130 / 171 | Total Loss: 2.3965511322021484 | KNN Loss: 2.387490749359131 | CLS Loss: 0.00906035490334034\n",
      "Epoch 82 / 200 | iteration 140 / 171 | Total Loss: 2.419686794281006 | KNN Loss: 2.4069480895996094 | CLS Loss: 0.012738761492073536\n",
      "Epoch 82 / 200 | iteration 150 / 171 | Total Loss: 2.4536445140838623 | KNN Loss: 2.4466934204101562 | CLS Loss: 0.006950981914997101\n",
      "Epoch 82 / 200 | iteration 160 / 171 | Total Loss: 2.453974723815918 | KNN Loss: 2.4342968463897705 | CLS Loss: 0.019677821546792984\n",
      "Epoch 82 / 200 | iteration 170 / 171 | Total Loss: 2.4201817512512207 | KNN Loss: 2.3886892795562744 | CLS Loss: 0.031492434442043304\n",
      "Epoch: 082, Loss: 2.4255, Train: 0.9943, Valid: 0.9867, Best: 0.9874\n",
      "Epoch 83 / 200 | iteration 0 / 171 | Total Loss: 2.4195141792297363 | KNN Loss: 2.4071695804595947 | CLS Loss: 0.012344680726528168\n",
      "Epoch 83 / 200 | iteration 10 / 171 | Total Loss: 2.4068636894226074 | KNN Loss: 2.373197078704834 | CLS Loss: 0.033666640520095825\n",
      "Epoch 83 / 200 | iteration 20 / 171 | Total Loss: 2.3925654888153076 | KNN Loss: 2.3806681632995605 | CLS Loss: 0.011897395364940166\n",
      "Epoch 83 / 200 | iteration 30 / 171 | Total Loss: 2.4414074420928955 | KNN Loss: 2.4278645515441895 | CLS Loss: 0.013542952947318554\n",
      "Epoch 83 / 200 | iteration 40 / 171 | Total Loss: 2.44968581199646 | KNN Loss: 2.439298391342163 | CLS Loss: 0.01038746815174818\n",
      "Epoch 83 / 200 | iteration 50 / 171 | Total Loss: 2.4172873497009277 | KNN Loss: 2.4042162895202637 | CLS Loss: 0.013071099296212196\n",
      "Epoch 83 / 200 | iteration 60 / 171 | Total Loss: 2.4465227127075195 | KNN Loss: 2.4227113723754883 | CLS Loss: 0.023811450228095055\n",
      "Epoch 83 / 200 | iteration 70 / 171 | Total Loss: 2.4034993648529053 | KNN Loss: 2.388948917388916 | CLS Loss: 0.014550432562828064\n",
      "Epoch 83 / 200 | iteration 80 / 171 | Total Loss: 2.41554594039917 | KNN Loss: 2.395130157470703 | CLS Loss: 0.02041585184633732\n",
      "Epoch 83 / 200 | iteration 90 / 171 | Total Loss: 2.421142101287842 | KNN Loss: 2.3935511112213135 | CLS Loss: 0.027591098099946976\n",
      "Epoch 83 / 200 | iteration 100 / 171 | Total Loss: 2.438866376876831 | KNN Loss: 2.4134109020233154 | CLS Loss: 0.02545546367764473\n",
      "Epoch 83 / 200 | iteration 110 / 171 | Total Loss: 2.4213528633117676 | KNN Loss: 2.4122419357299805 | CLS Loss: 0.009110892191529274\n",
      "Epoch 83 / 200 | iteration 120 / 171 | Total Loss: 2.4201014041900635 | KNN Loss: 2.397066831588745 | CLS Loss: 0.023034635931253433\n",
      "Epoch 83 / 200 | iteration 130 / 171 | Total Loss: 2.4578912258148193 | KNN Loss: 2.4344615936279297 | CLS Loss: 0.02342962473630905\n",
      "Epoch 83 / 200 | iteration 140 / 171 | Total Loss: 2.387087821960449 | KNN Loss: 2.375046968460083 | CLS Loss: 0.012040906585752964\n",
      "Epoch 83 / 200 | iteration 150 / 171 | Total Loss: 2.4673008918762207 | KNN Loss: 2.4273557662963867 | CLS Loss: 0.03994511812925339\n",
      "Epoch 83 / 200 | iteration 160 / 171 | Total Loss: 2.418836832046509 | KNN Loss: 2.3819987773895264 | CLS Loss: 0.03683808818459511\n",
      "Epoch 83 / 200 | iteration 170 / 171 | Total Loss: 2.381632089614868 | KNN Loss: 2.3774335384368896 | CLS Loss: 0.004198636393994093\n",
      "Epoch: 083, Loss: 2.4233, Train: 0.9940, Valid: 0.9853, Best: 0.9874\n",
      "Epoch 84 / 200 | iteration 0 / 171 | Total Loss: 2.418666124343872 | KNN Loss: 2.3955373764038086 | CLS Loss: 0.023128675296902657\n",
      "Epoch 84 / 200 | iteration 10 / 171 | Total Loss: 2.3952014446258545 | KNN Loss: 2.3784267902374268 | CLS Loss: 0.016774725168943405\n",
      "Epoch 84 / 200 | iteration 20 / 171 | Total Loss: 2.427765130996704 | KNN Loss: 2.4109036922454834 | CLS Loss: 0.01686144806444645\n",
      "Epoch 84 / 200 | iteration 30 / 171 | Total Loss: 2.4351160526275635 | KNN Loss: 2.432039499282837 | CLS Loss: 0.0030765566043555737\n",
      "Epoch 84 / 200 | iteration 40 / 171 | Total Loss: 2.411574363708496 | KNN Loss: 2.3951151371002197 | CLS Loss: 0.016459273174405098\n",
      "Epoch 84 / 200 | iteration 50 / 171 | Total Loss: 2.398310422897339 | KNN Loss: 2.387928009033203 | CLS Loss: 0.010382313281297684\n",
      "Epoch 84 / 200 | iteration 60 / 171 | Total Loss: 2.445906400680542 | KNN Loss: 2.425396203994751 | CLS Loss: 0.020510131493210793\n",
      "Epoch 84 / 200 | iteration 70 / 171 | Total Loss: 2.39760160446167 | KNN Loss: 2.3787331581115723 | CLS Loss: 0.0188683420419693\n",
      "Epoch 84 / 200 | iteration 80 / 171 | Total Loss: 2.3990800380706787 | KNN Loss: 2.3808400630950928 | CLS Loss: 0.018239879980683327\n",
      "Epoch 84 / 200 | iteration 90 / 171 | Total Loss: 2.428757429122925 | KNN Loss: 2.3776931762695312 | CLS Loss: 0.05106415972113609\n",
      "Epoch 84 / 200 | iteration 100 / 171 | Total Loss: 2.39804744720459 | KNN Loss: 2.3798792362213135 | CLS Loss: 0.018168199807405472\n",
      "Epoch 84 / 200 | iteration 110 / 171 | Total Loss: 2.3993821144104004 | KNN Loss: 2.390824556350708 | CLS Loss: 0.008557561784982681\n",
      "Epoch 84 / 200 | iteration 120 / 171 | Total Loss: 2.4097135066986084 | KNN Loss: 2.4002177715301514 | CLS Loss: 0.009495803155004978\n",
      "Epoch 84 / 200 | iteration 130 / 171 | Total Loss: 2.41837215423584 | KNN Loss: 2.404710054397583 | CLS Loss: 0.01366205420345068\n",
      "Epoch 84 / 200 | iteration 140 / 171 | Total Loss: 2.4201157093048096 | KNN Loss: 2.3868587017059326 | CLS Loss: 0.03325706347823143\n",
      "Epoch 84 / 200 | iteration 150 / 171 | Total Loss: 2.40183687210083 | KNN Loss: 2.3829803466796875 | CLS Loss: 0.01885657012462616\n",
      "Epoch 84 / 200 | iteration 160 / 171 | Total Loss: 2.4331605434417725 | KNN Loss: 2.4159247875213623 | CLS Loss: 0.017235679551959038\n",
      "Epoch 84 / 200 | iteration 170 / 171 | Total Loss: 2.419445514678955 | KNN Loss: 2.4110100269317627 | CLS Loss: 0.00843559019267559\n",
      "Epoch: 084, Loss: 2.4217, Train: 0.9952, Valid: 0.9865, Best: 0.9874\n",
      "Epoch 85 / 200 | iteration 0 / 171 | Total Loss: 2.4079763889312744 | KNN Loss: 2.388979196548462 | CLS Loss: 0.018997276201844215\n",
      "Epoch 85 / 200 | iteration 10 / 171 | Total Loss: 2.408236026763916 | KNN Loss: 2.4028570652008057 | CLS Loss: 0.005378857720643282\n",
      "Epoch 85 / 200 | iteration 20 / 171 | Total Loss: 2.4729766845703125 | KNN Loss: 2.4347939491271973 | CLS Loss: 0.03818277269601822\n",
      "Epoch 85 / 200 | iteration 30 / 171 | Total Loss: 2.444740056991577 | KNN Loss: 2.4332611560821533 | CLS Loss: 0.011478962376713753\n",
      "Epoch 85 / 200 | iteration 40 / 171 | Total Loss: 2.45628023147583 | KNN Loss: 2.437065362930298 | CLS Loss: 0.019214875996112823\n",
      "Epoch 85 / 200 | iteration 50 / 171 | Total Loss: 2.380074977874756 | KNN Loss: 2.374699354171753 | CLS Loss: 0.005375732202082872\n",
      "Epoch 85 / 200 | iteration 60 / 171 | Total Loss: 2.376206159591675 | KNN Loss: 2.3612992763519287 | CLS Loss: 0.014906843192875385\n",
      "Epoch 85 / 200 | iteration 70 / 171 | Total Loss: 2.4147427082061768 | KNN Loss: 2.394336700439453 | CLS Loss: 0.02040611021220684\n",
      "Epoch 85 / 200 | iteration 80 / 171 | Total Loss: 2.4073801040649414 | KNN Loss: 2.3924083709716797 | CLS Loss: 0.014971776865422726\n",
      "Epoch 85 / 200 | iteration 90 / 171 | Total Loss: 2.4150502681732178 | KNN Loss: 2.4056830406188965 | CLS Loss: 0.009367221035063267\n",
      "Epoch 85 / 200 | iteration 100 / 171 | Total Loss: 2.3965134620666504 | KNN Loss: 2.3744149208068848 | CLS Loss: 0.022098543122410774\n",
      "Epoch 85 / 200 | iteration 110 / 171 | Total Loss: 2.4112730026245117 | KNN Loss: 2.401155948638916 | CLS Loss: 0.010117029771208763\n",
      "Epoch 85 / 200 | iteration 120 / 171 | Total Loss: 2.444092035293579 | KNN Loss: 2.421901226043701 | CLS Loss: 0.02219071425497532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 / 200 | iteration 130 / 171 | Total Loss: 2.414275884628296 | KNN Loss: 2.3914177417755127 | CLS Loss: 0.02285817824304104\n",
      "Epoch 85 / 200 | iteration 140 / 171 | Total Loss: 2.4685890674591064 | KNN Loss: 2.4525399208068848 | CLS Loss: 0.016049187630414963\n",
      "Epoch 85 / 200 | iteration 150 / 171 | Total Loss: 2.4019265174865723 | KNN Loss: 2.3910160064697266 | CLS Loss: 0.010910623706877232\n",
      "Epoch 85 / 200 | iteration 160 / 171 | Total Loss: 2.4272024631500244 | KNN Loss: 2.4029476642608643 | CLS Loss: 0.024254851043224335\n",
      "Epoch 85 / 200 | iteration 170 / 171 | Total Loss: 2.4302279949188232 | KNN Loss: 2.3954596519470215 | CLS Loss: 0.03476835414767265\n",
      "Epoch: 085, Loss: 2.4203, Train: 0.9946, Valid: 0.9865, Best: 0.9874\n",
      "Epoch 86 / 200 | iteration 0 / 171 | Total Loss: 2.4484245777130127 | KNN Loss: 2.4126083850860596 | CLS Loss: 0.0358162522315979\n",
      "Epoch 86 / 200 | iteration 10 / 171 | Total Loss: 2.4568562507629395 | KNN Loss: 2.4447968006134033 | CLS Loss: 0.012059363536536694\n",
      "Epoch 86 / 200 | iteration 20 / 171 | Total Loss: 2.4391024112701416 | KNN Loss: 2.4239814281463623 | CLS Loss: 0.015121076256036758\n",
      "Epoch 86 / 200 | iteration 30 / 171 | Total Loss: 2.378748655319214 | KNN Loss: 2.3734426498413086 | CLS Loss: 0.005306001752614975\n",
      "Epoch 86 / 200 | iteration 40 / 171 | Total Loss: 2.416369915008545 | KNN Loss: 2.3961758613586426 | CLS Loss: 0.02019416354596615\n",
      "Epoch 86 / 200 | iteration 50 / 171 | Total Loss: 2.404320478439331 | KNN Loss: 2.390632390975952 | CLS Loss: 0.013688117265701294\n",
      "Epoch 86 / 200 | iteration 60 / 171 | Total Loss: 2.429509162902832 | KNN Loss: 2.400822639465332 | CLS Loss: 0.028686465695500374\n",
      "Epoch 86 / 200 | iteration 70 / 171 | Total Loss: 2.4923598766326904 | KNN Loss: 2.444352149963379 | CLS Loss: 0.048007719218730927\n",
      "Epoch 86 / 200 | iteration 80 / 171 | Total Loss: 2.4347312450408936 | KNN Loss: 2.428483247756958 | CLS Loss: 0.00624806946143508\n",
      "Epoch 86 / 200 | iteration 90 / 171 | Total Loss: 2.434307813644409 | KNN Loss: 2.417102575302124 | CLS Loss: 0.017205296084284782\n",
      "Epoch 86 / 200 | iteration 100 / 171 | Total Loss: 2.4437949657440186 | KNN Loss: 2.3910038471221924 | CLS Loss: 0.052791088819503784\n",
      "Epoch 86 / 200 | iteration 110 / 171 | Total Loss: 2.4299137592315674 | KNN Loss: 2.3994057178497314 | CLS Loss: 0.030508093535900116\n",
      "Epoch 86 / 200 | iteration 120 / 171 | Total Loss: 2.4228358268737793 | KNN Loss: 2.4051756858825684 | CLS Loss: 0.017660241574048996\n",
      "Epoch 86 / 200 | iteration 130 / 171 | Total Loss: 2.376671075820923 | KNN Loss: 2.354292154312134 | CLS Loss: 0.022379033267498016\n",
      "Epoch 86 / 200 | iteration 140 / 171 | Total Loss: 2.4220142364501953 | KNN Loss: 2.4024248123168945 | CLS Loss: 0.019589383155107498\n",
      "Epoch 86 / 200 | iteration 150 / 171 | Total Loss: 2.412750244140625 | KNN Loss: 2.400867462158203 | CLS Loss: 0.011882742866873741\n",
      "Epoch 86 / 200 | iteration 160 / 171 | Total Loss: 2.4108827114105225 | KNN Loss: 2.396730661392212 | CLS Loss: 0.014151936396956444\n",
      "Epoch 86 / 200 | iteration 170 / 171 | Total Loss: 2.4383368492126465 | KNN Loss: 2.418055295944214 | CLS Loss: 0.020281575620174408\n",
      "Epoch: 086, Loss: 2.4224, Train: 0.9953, Valid: 0.9869, Best: 0.9874\n",
      "Epoch 87 / 200 | iteration 0 / 171 | Total Loss: 2.413043975830078 | KNN Loss: 2.406341075897217 | CLS Loss: 0.006702819839119911\n",
      "Epoch 87 / 200 | iteration 10 / 171 | Total Loss: 2.3700718879699707 | KNN Loss: 2.364995002746582 | CLS Loss: 0.005076864268630743\n",
      "Epoch 87 / 200 | iteration 20 / 171 | Total Loss: 2.4389007091522217 | KNN Loss: 2.4228131771087646 | CLS Loss: 0.016087494790554047\n",
      "Epoch 87 / 200 | iteration 30 / 171 | Total Loss: 2.412252902984619 | KNN Loss: 2.4059226512908936 | CLS Loss: 0.006330322474241257\n",
      "Epoch 87 / 200 | iteration 40 / 171 | Total Loss: 2.396031379699707 | KNN Loss: 2.3854403495788574 | CLS Loss: 0.010591022670269012\n",
      "Epoch 87 / 200 | iteration 50 / 171 | Total Loss: 2.4068093299865723 | KNN Loss: 2.3982746601104736 | CLS Loss: 0.008534654043614864\n",
      "Epoch 87 / 200 | iteration 60 / 171 | Total Loss: 2.412168264389038 | KNN Loss: 2.3709986209869385 | CLS Loss: 0.04116972163319588\n",
      "Epoch 87 / 200 | iteration 70 / 171 | Total Loss: 2.423513650894165 | KNN Loss: 2.419857978820801 | CLS Loss: 0.0036556595005095005\n",
      "Epoch 87 / 200 | iteration 80 / 171 | Total Loss: 2.4410808086395264 | KNN Loss: 2.4223570823669434 | CLS Loss: 0.018723761662840843\n",
      "Epoch 87 / 200 | iteration 90 / 171 | Total Loss: 2.3999502658843994 | KNN Loss: 2.386549711227417 | CLS Loss: 0.013400662690401077\n",
      "Epoch 87 / 200 | iteration 100 / 171 | Total Loss: 2.4170730113983154 | KNN Loss: 2.3867669105529785 | CLS Loss: 0.030306117609143257\n",
      "Epoch 87 / 200 | iteration 110 / 171 | Total Loss: 2.376383066177368 | KNN Loss: 2.3701393604278564 | CLS Loss: 0.006243701558560133\n",
      "Epoch 87 / 200 | iteration 120 / 171 | Total Loss: 2.4184303283691406 | KNN Loss: 2.3943445682525635 | CLS Loss: 0.02408580295741558\n",
      "Epoch 87 / 200 | iteration 130 / 171 | Total Loss: 2.4289615154266357 | KNN Loss: 2.4163944721221924 | CLS Loss: 0.012567122466862202\n",
      "Epoch 87 / 200 | iteration 140 / 171 | Total Loss: 2.409424066543579 | KNN Loss: 2.3761441707611084 | CLS Loss: 0.033279985189437866\n",
      "Epoch 87 / 200 | iteration 150 / 171 | Total Loss: 2.4093523025512695 | KNN Loss: 2.3889036178588867 | CLS Loss: 0.0204487144947052\n",
      "Epoch 87 / 200 | iteration 160 / 171 | Total Loss: 2.411587715148926 | KNN Loss: 2.3989195823669434 | CLS Loss: 0.012668016366660595\n",
      "Epoch 87 / 200 | iteration 170 / 171 | Total Loss: 2.416752576828003 | KNN Loss: 2.3938498497009277 | CLS Loss: 0.02290269546210766\n",
      "Epoch: 087, Loss: 2.4212, Train: 0.9958, Valid: 0.9868, Best: 0.9874\n",
      "Epoch 88 / 200 | iteration 0 / 171 | Total Loss: 2.3876795768737793 | KNN Loss: 2.3824658393859863 | CLS Loss: 0.005213814787566662\n",
      "Epoch 88 / 200 | iteration 10 / 171 | Total Loss: 2.401970624923706 | KNN Loss: 2.3826968669891357 | CLS Loss: 0.019273655489087105\n",
      "Epoch 88 / 200 | iteration 20 / 171 | Total Loss: 2.4031150341033936 | KNN Loss: 2.380180597305298 | CLS Loss: 0.022934526205062866\n",
      "Epoch 88 / 200 | iteration 30 / 171 | Total Loss: 2.4090874195098877 | KNN Loss: 2.372292995452881 | CLS Loss: 0.03679441660642624\n",
      "Epoch 88 / 200 | iteration 40 / 171 | Total Loss: 2.417661190032959 | KNN Loss: 2.3967702388763428 | CLS Loss: 0.020890947431325912\n",
      "Epoch 88 / 200 | iteration 50 / 171 | Total Loss: 2.4188523292541504 | KNN Loss: 2.416940927505493 | CLS Loss: 0.001911398023366928\n",
      "Epoch 88 / 200 | iteration 60 / 171 | Total Loss: 2.409533977508545 | KNN Loss: 2.3972561359405518 | CLS Loss: 0.012277808040380478\n",
      "Epoch 88 / 200 | iteration 70 / 171 | Total Loss: 2.4504270553588867 | KNN Loss: 2.396108627319336 | CLS Loss: 0.05431842431426048\n",
      "Epoch 88 / 200 | iteration 80 / 171 | Total Loss: 2.385702610015869 | KNN Loss: 2.3670766353607178 | CLS Loss: 0.018625985831022263\n",
      "Epoch 88 / 200 | iteration 90 / 171 | Total Loss: 2.379591226577759 | KNN Loss: 2.3741631507873535 | CLS Loss: 0.005427990108728409\n",
      "Epoch 88 / 200 | iteration 100 / 171 | Total Loss: 2.4413435459136963 | KNN Loss: 2.4092607498168945 | CLS Loss: 0.03208288550376892\n",
      "Epoch 88 / 200 | iteration 110 / 171 | Total Loss: 2.4381840229034424 | KNN Loss: 2.402789831161499 | CLS Loss: 0.0353940911591053\n",
      "Epoch 88 / 200 | iteration 120 / 171 | Total Loss: 2.4215667247772217 | KNN Loss: 2.4147684574127197 | CLS Loss: 0.006798288784921169\n",
      "Epoch 88 / 200 | iteration 130 / 171 | Total Loss: 2.425640344619751 | KNN Loss: 2.4135782718658447 | CLS Loss: 0.012062073685228825\n",
      "Epoch 88 / 200 | iteration 140 / 171 | Total Loss: 2.4001271724700928 | KNN Loss: 2.377171039581299 | CLS Loss: 0.022956088185310364\n",
      "Epoch 88 / 200 | iteration 150 / 171 | Total Loss: 2.403225898742676 | KNN Loss: 2.3943395614624023 | CLS Loss: 0.008886397816240788\n",
      "Epoch 88 / 200 | iteration 160 / 171 | Total Loss: 2.4432785511016846 | KNN Loss: 2.429225444793701 | CLS Loss: 0.014052992686629295\n",
      "Epoch 88 / 200 | iteration 170 / 171 | Total Loss: 2.4225597381591797 | KNN Loss: 2.39715313911438 | CLS Loss: 0.025406649336218834\n",
      "Epoch: 088, Loss: 2.4216, Train: 0.9956, Valid: 0.9860, Best: 0.9874\n",
      "Epoch 89 / 200 | iteration 0 / 171 | Total Loss: 2.438632011413574 | KNN Loss: 2.4289064407348633 | CLS Loss: 0.009725509211421013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 / 200 | iteration 10 / 171 | Total Loss: 2.3781630992889404 | KNN Loss: 2.3645365238189697 | CLS Loss: 0.01362649817019701\n",
      "Epoch 89 / 200 | iteration 20 / 171 | Total Loss: 2.42268443107605 | KNN Loss: 2.4082818031311035 | CLS Loss: 0.01440261397510767\n",
      "Epoch 89 / 200 | iteration 30 / 171 | Total Loss: 2.4165287017822266 | KNN Loss: 2.4078850746154785 | CLS Loss: 0.008643708191812038\n",
      "Epoch 89 / 200 | iteration 40 / 171 | Total Loss: 2.432921886444092 | KNN Loss: 2.3960483074188232 | CLS Loss: 0.036873478442430496\n",
      "Epoch 89 / 200 | iteration 50 / 171 | Total Loss: 2.4538512229919434 | KNN Loss: 2.4281489849090576 | CLS Loss: 0.025702303275465965\n",
      "Epoch 89 / 200 | iteration 60 / 171 | Total Loss: 2.4155359268188477 | KNN Loss: 2.406480073928833 | CLS Loss: 0.009055943228304386\n",
      "Epoch 89 / 200 | iteration 70 / 171 | Total Loss: 2.4191620349884033 | KNN Loss: 2.4032602310180664 | CLS Loss: 0.015901880338788033\n",
      "Epoch 89 / 200 | iteration 80 / 171 | Total Loss: 2.419233798980713 | KNN Loss: 2.4023513793945312 | CLS Loss: 0.016882317140698433\n",
      "Epoch 89 / 200 | iteration 90 / 171 | Total Loss: 2.446779251098633 | KNN Loss: 2.4282922744750977 | CLS Loss: 0.018486877903342247\n",
      "Epoch 89 / 200 | iteration 100 / 171 | Total Loss: 2.429906129837036 | KNN Loss: 2.4082956314086914 | CLS Loss: 0.021610405296087265\n",
      "Epoch 89 / 200 | iteration 110 / 171 | Total Loss: 2.475539207458496 | KNN Loss: 2.458216428756714 | CLS Loss: 0.01732274889945984\n",
      "Epoch 89 / 200 | iteration 120 / 171 | Total Loss: 2.402874708175659 | KNN Loss: 2.393141269683838 | CLS Loss: 0.009733344428241253\n",
      "Epoch 89 / 200 | iteration 130 / 171 | Total Loss: 2.377624273300171 | KNN Loss: 2.363617181777954 | CLS Loss: 0.014007161371409893\n",
      "Epoch 89 / 200 | iteration 140 / 171 | Total Loss: 2.43691349029541 | KNN Loss: 2.4085280895233154 | CLS Loss: 0.028385423123836517\n",
      "Epoch 89 / 200 | iteration 150 / 171 | Total Loss: 2.417999267578125 | KNN Loss: 2.4081459045410156 | CLS Loss: 0.009853377938270569\n",
      "Epoch 89 / 200 | iteration 160 / 171 | Total Loss: 2.400995969772339 | KNN Loss: 2.3884620666503906 | CLS Loss: 0.012533849105238914\n",
      "Epoch 89 / 200 | iteration 170 / 171 | Total Loss: 2.4192183017730713 | KNN Loss: 2.402711868286133 | CLS Loss: 0.016506377607584\n",
      "Epoch: 089, Loss: 2.4215, Train: 0.9924, Valid: 0.9823, Best: 0.9874\n",
      "Epoch 90 / 200 | iteration 0 / 171 | Total Loss: 2.4132063388824463 | KNN Loss: 2.397763252258301 | CLS Loss: 0.015442971140146255\n",
      "Epoch 90 / 200 | iteration 10 / 171 | Total Loss: 2.4474620819091797 | KNN Loss: 2.426945686340332 | CLS Loss: 0.02051643654704094\n",
      "Epoch 90 / 200 | iteration 20 / 171 | Total Loss: 2.4282896518707275 | KNN Loss: 2.3933346271514893 | CLS Loss: 0.03495491296052933\n",
      "Epoch 90 / 200 | iteration 30 / 171 | Total Loss: 2.414341688156128 | KNN Loss: 2.402003526687622 | CLS Loss: 0.012338075786828995\n",
      "Epoch 90 / 200 | iteration 40 / 171 | Total Loss: 2.4300754070281982 | KNN Loss: 2.422488212585449 | CLS Loss: 0.007587302941828966\n",
      "Epoch 90 / 200 | iteration 50 / 171 | Total Loss: 2.396286725997925 | KNN Loss: 2.386333465576172 | CLS Loss: 0.009953290224075317\n",
      "Epoch 90 / 200 | iteration 60 / 171 | Total Loss: 2.4380667209625244 | KNN Loss: 2.42057728767395 | CLS Loss: 0.01748940348625183\n",
      "Epoch 90 / 200 | iteration 70 / 171 | Total Loss: 2.4372825622558594 | KNN Loss: 2.425852060317993 | CLS Loss: 0.01143060065805912\n",
      "Epoch 90 / 200 | iteration 80 / 171 | Total Loss: 2.420433759689331 | KNN Loss: 2.398900032043457 | CLS Loss: 0.02153376117348671\n",
      "Epoch 90 / 200 | iteration 90 / 171 | Total Loss: 2.419529676437378 | KNN Loss: 2.4025585651397705 | CLS Loss: 0.016971131786704063\n",
      "Epoch 90 / 200 | iteration 100 / 171 | Total Loss: 2.4247007369995117 | KNN Loss: 2.4017109870910645 | CLS Loss: 0.022989682853221893\n",
      "Epoch 90 / 200 | iteration 110 / 171 | Total Loss: 2.466357469558716 | KNN Loss: 2.4476234912872314 | CLS Loss: 0.018733961507678032\n",
      "Epoch 90 / 200 | iteration 120 / 171 | Total Loss: 2.4119231700897217 | KNN Loss: 2.3867743015289307 | CLS Loss: 0.025148769840598106\n",
      "Epoch 90 / 200 | iteration 130 / 171 | Total Loss: 2.4435479640960693 | KNN Loss: 2.4290926456451416 | CLS Loss: 0.014455309137701988\n",
      "Epoch 90 / 200 | iteration 140 / 171 | Total Loss: 2.404324769973755 | KNN Loss: 2.3973262310028076 | CLS Loss: 0.006998446770012379\n",
      "Epoch 90 / 200 | iteration 150 / 171 | Total Loss: 2.4078457355499268 | KNN Loss: 2.392338514328003 | CLS Loss: 0.015507147647440434\n",
      "Epoch 90 / 200 | iteration 160 / 171 | Total Loss: 2.438145637512207 | KNN Loss: 2.4235477447509766 | CLS Loss: 0.01459782849997282\n",
      "Epoch 90 / 200 | iteration 170 / 171 | Total Loss: 2.4331395626068115 | KNN Loss: 2.418095350265503 | CLS Loss: 0.0150441350415349\n",
      "Epoch: 090, Loss: 2.4230, Train: 0.9957, Valid: 0.9872, Best: 0.9874\n",
      "Epoch 91 / 200 | iteration 0 / 171 | Total Loss: 2.38662052154541 | KNN Loss: 2.384340286254883 | CLS Loss: 0.002280206186696887\n",
      "Epoch 91 / 200 | iteration 10 / 171 | Total Loss: 2.416572093963623 | KNN Loss: 2.4056992530822754 | CLS Loss: 0.010872939601540565\n",
      "Epoch 91 / 200 | iteration 20 / 171 | Total Loss: 2.3895034790039062 | KNN Loss: 2.3713343143463135 | CLS Loss: 0.018169088289141655\n",
      "Epoch 91 / 200 | iteration 30 / 171 | Total Loss: 2.4072234630584717 | KNN Loss: 2.3930304050445557 | CLS Loss: 0.0141930365934968\n",
      "Epoch 91 / 200 | iteration 40 / 171 | Total Loss: 2.42651629447937 | KNN Loss: 2.412946939468384 | CLS Loss: 0.013569390401244164\n",
      "Epoch 91 / 200 | iteration 50 / 171 | Total Loss: 2.4196770191192627 | KNN Loss: 2.4075729846954346 | CLS Loss: 0.012104121036827564\n",
      "Epoch 91 / 200 | iteration 60 / 171 | Total Loss: 2.4496657848358154 | KNN Loss: 2.434218406677246 | CLS Loss: 0.01544738095253706\n",
      "Epoch 91 / 200 | iteration 70 / 171 | Total Loss: 2.409529685974121 | KNN Loss: 2.3787457942962646 | CLS Loss: 0.030783845111727715\n",
      "Epoch 91 / 200 | iteration 80 / 171 | Total Loss: 2.410621166229248 | KNN Loss: 2.3887126445770264 | CLS Loss: 0.021908534690737724\n",
      "Epoch 91 / 200 | iteration 90 / 171 | Total Loss: 2.446951150894165 | KNN Loss: 2.4087302684783936 | CLS Loss: 0.03822077438235283\n",
      "Epoch 91 / 200 | iteration 100 / 171 | Total Loss: 2.397920608520508 | KNN Loss: 2.374160051345825 | CLS Loss: 0.02376057580113411\n",
      "Epoch 91 / 200 | iteration 110 / 171 | Total Loss: 2.4077320098876953 | KNN Loss: 2.3929920196533203 | CLS Loss: 0.014739871956408024\n",
      "Epoch 91 / 200 | iteration 120 / 171 | Total Loss: 2.447659730911255 | KNN Loss: 2.4106271266937256 | CLS Loss: 0.037032488733530045\n",
      "Epoch 91 / 200 | iteration 130 / 171 | Total Loss: 2.4185733795166016 | KNN Loss: 2.4063010215759277 | CLS Loss: 0.012272425927221775\n",
      "Epoch 91 / 200 | iteration 140 / 171 | Total Loss: 2.4235424995422363 | KNN Loss: 2.4145240783691406 | CLS Loss: 0.009018384851515293\n",
      "Epoch 91 / 200 | iteration 150 / 171 | Total Loss: 2.4561731815338135 | KNN Loss: 2.4516918659210205 | CLS Loss: 0.004481412936002016\n",
      "Epoch 91 / 200 | iteration 160 / 171 | Total Loss: 2.414820909500122 | KNN Loss: 2.4037039279937744 | CLS Loss: 0.011117012239992619\n",
      "Epoch 91 / 200 | iteration 170 / 171 | Total Loss: 2.402273178100586 | KNN Loss: 2.3633289337158203 | CLS Loss: 0.03894424065947533\n",
      "Epoch: 091, Loss: 2.4221, Train: 0.9952, Valid: 0.9869, Best: 0.9874\n",
      "Epoch 92 / 200 | iteration 0 / 171 | Total Loss: 2.399454116821289 | KNN Loss: 2.3919143676757812 | CLS Loss: 0.007539692800492048\n",
      "Epoch 92 / 200 | iteration 10 / 171 | Total Loss: 2.419865131378174 | KNN Loss: 2.4114389419555664 | CLS Loss: 0.008426095359027386\n",
      "Epoch 92 / 200 | iteration 20 / 171 | Total Loss: 2.423712968826294 | KNN Loss: 2.410454750061035 | CLS Loss: 0.013258160091936588\n",
      "Epoch 92 / 200 | iteration 30 / 171 | Total Loss: 2.435755491256714 | KNN Loss: 2.411203145980835 | CLS Loss: 0.02455238252878189\n",
      "Epoch 92 / 200 | iteration 40 / 171 | Total Loss: 2.405825614929199 | KNN Loss: 2.3842575550079346 | CLS Loss: 0.021568166092038155\n",
      "Epoch 92 / 200 | iteration 50 / 171 | Total Loss: 2.4325225353240967 | KNN Loss: 2.410338878631592 | CLS Loss: 0.022183550521731377\n",
      "Epoch 92 / 200 | iteration 60 / 171 | Total Loss: 2.451240062713623 | KNN Loss: 2.432514190673828 | CLS Loss: 0.01872595027089119\n",
      "Epoch 92 / 200 | iteration 70 / 171 | Total Loss: 2.4153988361358643 | KNN Loss: 2.3961923122406006 | CLS Loss: 0.019206447526812553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 / 200 | iteration 80 / 171 | Total Loss: 2.4104998111724854 | KNN Loss: 2.3926427364349365 | CLS Loss: 0.017856977880001068\n",
      "Epoch 92 / 200 | iteration 90 / 171 | Total Loss: 2.4327399730682373 | KNN Loss: 2.4046895503997803 | CLS Loss: 0.028050504624843597\n",
      "Epoch 92 / 200 | iteration 100 / 171 | Total Loss: 2.405285358428955 | KNN Loss: 2.3821730613708496 | CLS Loss: 0.023112183436751366\n",
      "Epoch 92 / 200 | iteration 110 / 171 | Total Loss: 2.4403703212738037 | KNN Loss: 2.4008705615997314 | CLS Loss: 0.03949976712465286\n",
      "Epoch 92 / 200 | iteration 120 / 171 | Total Loss: 2.4379982948303223 | KNN Loss: 2.42527174949646 | CLS Loss: 0.012726476415991783\n",
      "Epoch 92 / 200 | iteration 130 / 171 | Total Loss: 2.4200901985168457 | KNN Loss: 2.4034669399261475 | CLS Loss: 0.016623152419924736\n",
      "Epoch 92 / 200 | iteration 140 / 171 | Total Loss: 2.4229533672332764 | KNN Loss: 2.396937131881714 | CLS Loss: 0.02601628005504608\n",
      "Epoch 92 / 200 | iteration 150 / 171 | Total Loss: 2.4088377952575684 | KNN Loss: 2.4060113430023193 | CLS Loss: 0.0028263679705560207\n",
      "Epoch 92 / 200 | iteration 160 / 171 | Total Loss: 2.4250338077545166 | KNN Loss: 2.368072509765625 | CLS Loss: 0.05696140229701996\n",
      "Epoch 92 / 200 | iteration 170 / 171 | Total Loss: 2.4402177333831787 | KNN Loss: 2.426142692565918 | CLS Loss: 0.014075031504034996\n",
      "Epoch: 092, Loss: 2.4253, Train: 0.9957, Valid: 0.9869, Best: 0.9874\n",
      "Epoch 93 / 200 | iteration 0 / 171 | Total Loss: 2.441622257232666 | KNN Loss: 2.4173760414123535 | CLS Loss: 0.02424623630940914\n",
      "Epoch 93 / 200 | iteration 10 / 171 | Total Loss: 2.3977043628692627 | KNN Loss: 2.3910059928894043 | CLS Loss: 0.006698471028357744\n",
      "Epoch 93 / 200 | iteration 20 / 171 | Total Loss: 2.460142135620117 | KNN Loss: 2.445228338241577 | CLS Loss: 0.014913786202669144\n",
      "Epoch 93 / 200 | iteration 30 / 171 | Total Loss: 2.4200499057769775 | KNN Loss: 2.4028480052948 | CLS Loss: 0.01720186322927475\n",
      "Epoch 93 / 200 | iteration 40 / 171 | Total Loss: 2.4263522624969482 | KNN Loss: 2.395920991897583 | CLS Loss: 0.030431341379880905\n",
      "Epoch 93 / 200 | iteration 50 / 171 | Total Loss: 2.455505609512329 | KNN Loss: 2.4303154945373535 | CLS Loss: 0.025190016254782677\n",
      "Epoch 93 / 200 | iteration 60 / 171 | Total Loss: 2.4056687355041504 | KNN Loss: 2.389911651611328 | CLS Loss: 0.015757005661725998\n",
      "Epoch 93 / 200 | iteration 70 / 171 | Total Loss: 2.4232938289642334 | KNN Loss: 2.392505407333374 | CLS Loss: 0.030788345262408257\n",
      "Epoch 93 / 200 | iteration 80 / 171 | Total Loss: 2.418602466583252 | KNN Loss: 2.4008331298828125 | CLS Loss: 0.01776927150785923\n",
      "Epoch 93 / 200 | iteration 90 / 171 | Total Loss: 2.433243989944458 | KNN Loss: 2.4267046451568604 | CLS Loss: 0.0065394118428230286\n",
      "Epoch 93 / 200 | iteration 100 / 171 | Total Loss: 2.4161906242370605 | KNN Loss: 2.4037275314331055 | CLS Loss: 0.012463030405342579\n",
      "Epoch 93 / 200 | iteration 110 / 171 | Total Loss: 2.3981268405914307 | KNN Loss: 2.3890373706817627 | CLS Loss: 0.00908947829157114\n",
      "Epoch 93 / 200 | iteration 120 / 171 | Total Loss: 2.431631326675415 | KNN Loss: 2.422502040863037 | CLS Loss: 0.00912920106202364\n",
      "Epoch 93 / 200 | iteration 130 / 171 | Total Loss: 2.4139564037323 | KNN Loss: 2.401884078979492 | CLS Loss: 0.012072348967194557\n",
      "Epoch 93 / 200 | iteration 140 / 171 | Total Loss: 2.417327404022217 | KNN Loss: 2.407996416091919 | CLS Loss: 0.009330879896879196\n",
      "Epoch 93 / 200 | iteration 150 / 171 | Total Loss: 2.4149134159088135 | KNN Loss: 2.3998894691467285 | CLS Loss: 0.015023862943053246\n",
      "Epoch 93 / 200 | iteration 160 / 171 | Total Loss: 2.436657190322876 | KNN Loss: 2.391533136367798 | CLS Loss: 0.04512404650449753\n",
      "Epoch 93 / 200 | iteration 170 / 171 | Total Loss: 2.4377152919769287 | KNN Loss: 2.382692337036133 | CLS Loss: 0.055023062974214554\n",
      "Epoch: 093, Loss: 2.4196, Train: 0.9960, Valid: 0.9878, Best: 0.9878\n",
      "Epoch 94 / 200 | iteration 0 / 171 | Total Loss: 2.4318127632141113 | KNN Loss: 2.401245594024658 | CLS Loss: 0.030567264184355736\n",
      "Epoch 94 / 200 | iteration 10 / 171 | Total Loss: 2.4052083492279053 | KNN Loss: 2.383354425430298 | CLS Loss: 0.021853873506188393\n",
      "Epoch 94 / 200 | iteration 20 / 171 | Total Loss: 2.4099509716033936 | KNN Loss: 2.40010404586792 | CLS Loss: 0.009846885688602924\n",
      "Epoch 94 / 200 | iteration 30 / 171 | Total Loss: 2.403474807739258 | KNN Loss: 2.3893778324127197 | CLS Loss: 0.01409688126295805\n",
      "Epoch 94 / 200 | iteration 40 / 171 | Total Loss: 2.4644124507904053 | KNN Loss: 2.441014528274536 | CLS Loss: 0.023397844284772873\n",
      "Epoch 94 / 200 | iteration 50 / 171 | Total Loss: 2.390810012817383 | KNN Loss: 2.3639965057373047 | CLS Loss: 0.02681344747543335\n",
      "Epoch 94 / 200 | iteration 60 / 171 | Total Loss: 2.4063515663146973 | KNN Loss: 2.3933534622192383 | CLS Loss: 0.012998065911233425\n",
      "Epoch 94 / 200 | iteration 70 / 171 | Total Loss: 2.4105384349823 | KNN Loss: 2.4004790782928467 | CLS Loss: 0.010059356689453125\n",
      "Epoch 94 / 200 | iteration 80 / 171 | Total Loss: 2.3889482021331787 | KNN Loss: 2.3862953186035156 | CLS Loss: 0.0026529820170253515\n",
      "Epoch 94 / 200 | iteration 90 / 171 | Total Loss: 2.4055941104888916 | KNN Loss: 2.4037978649139404 | CLS Loss: 0.0017962774727493525\n",
      "Epoch 94 / 200 | iteration 100 / 171 | Total Loss: 2.3982455730438232 | KNN Loss: 2.3864457607269287 | CLS Loss: 0.011799768544733524\n",
      "Epoch 94 / 200 | iteration 110 / 171 | Total Loss: 2.4429173469543457 | KNN Loss: 2.4233314990997314 | CLS Loss: 0.01958577334880829\n",
      "Epoch 94 / 200 | iteration 120 / 171 | Total Loss: 2.4055874347686768 | KNN Loss: 2.389331340789795 | CLS Loss: 0.016256049275398254\n",
      "Epoch 94 / 200 | iteration 130 / 171 | Total Loss: 2.4382541179656982 | KNN Loss: 2.4066238403320312 | CLS Loss: 0.03163027763366699\n",
      "Epoch 94 / 200 | iteration 140 / 171 | Total Loss: 2.415393352508545 | KNN Loss: 2.4052810668945312 | CLS Loss: 0.010112214833498001\n",
      "Epoch 94 / 200 | iteration 150 / 171 | Total Loss: 2.3943047523498535 | KNN Loss: 2.369739532470703 | CLS Loss: 0.024565132334828377\n",
      "Epoch 94 / 200 | iteration 160 / 171 | Total Loss: 2.394865036010742 | KNN Loss: 2.3819730281829834 | CLS Loss: 0.012892012484371662\n",
      "Epoch 94 / 200 | iteration 170 / 171 | Total Loss: 2.4335336685180664 | KNN Loss: 2.4123103618621826 | CLS Loss: 0.0212234016507864\n",
      "Epoch: 094, Loss: 2.4169, Train: 0.9962, Valid: 0.9875, Best: 0.9878\n",
      "Epoch 95 / 200 | iteration 0 / 171 | Total Loss: 2.4178316593170166 | KNN Loss: 2.4117393493652344 | CLS Loss: 0.006092339754104614\n",
      "Epoch 95 / 200 | iteration 10 / 171 | Total Loss: 2.3762683868408203 | KNN Loss: 2.3644931316375732 | CLS Loss: 0.01177532784640789\n",
      "Epoch 95 / 200 | iteration 20 / 171 | Total Loss: 2.4058001041412354 | KNN Loss: 2.3963983058929443 | CLS Loss: 0.00940179917961359\n",
      "Epoch 95 / 200 | iteration 30 / 171 | Total Loss: 2.398578643798828 | KNN Loss: 2.3782083988189697 | CLS Loss: 0.020370176061987877\n",
      "Epoch 95 / 200 | iteration 40 / 171 | Total Loss: 2.428511381149292 | KNN Loss: 2.411806344985962 | CLS Loss: 0.01670507714152336\n",
      "Epoch 95 / 200 | iteration 50 / 171 | Total Loss: 2.433781385421753 | KNN Loss: 2.4257314205169678 | CLS Loss: 0.008050047792494297\n",
      "Epoch 95 / 200 | iteration 60 / 171 | Total Loss: 2.372512102127075 | KNN Loss: 2.3491251468658447 | CLS Loss: 0.02338692545890808\n",
      "Epoch 95 / 200 | iteration 70 / 171 | Total Loss: 2.4178967475891113 | KNN Loss: 2.3972108364105225 | CLS Loss: 0.020685797557234764\n",
      "Epoch 95 / 200 | iteration 80 / 171 | Total Loss: 2.411059856414795 | KNN Loss: 2.403994083404541 | CLS Loss: 0.007065828889608383\n",
      "Epoch 95 / 200 | iteration 90 / 171 | Total Loss: 2.4296376705169678 | KNN Loss: 2.426964521408081 | CLS Loss: 0.0026731432881206274\n",
      "Epoch 95 / 200 | iteration 100 / 171 | Total Loss: 2.440032720565796 | KNN Loss: 2.4281065464019775 | CLS Loss: 0.011926218867301941\n",
      "Epoch 95 / 200 | iteration 110 / 171 | Total Loss: 2.4181504249572754 | KNN Loss: 2.411348581314087 | CLS Loss: 0.006801825016736984\n",
      "Epoch 95 / 200 | iteration 120 / 171 | Total Loss: 2.4213461875915527 | KNN Loss: 2.4099183082580566 | CLS Loss: 0.011427807621657848\n",
      "Epoch 95 / 200 | iteration 130 / 171 | Total Loss: 2.3914294242858887 | KNN Loss: 2.3727493286132812 | CLS Loss: 0.01868007518351078\n",
      "Epoch 95 / 200 | iteration 140 / 171 | Total Loss: 2.4360785484313965 | KNN Loss: 2.4276914596557617 | CLS Loss: 0.008387017995119095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 / 200 | iteration 150 / 171 | Total Loss: 2.4187397956848145 | KNN Loss: 2.4157168865203857 | CLS Loss: 0.0030228826217353344\n",
      "Epoch 95 / 200 | iteration 160 / 171 | Total Loss: 2.4157612323760986 | KNN Loss: 2.3981504440307617 | CLS Loss: 0.017610689625144005\n",
      "Epoch 95 / 200 | iteration 170 / 171 | Total Loss: 2.4149396419525146 | KNN Loss: 2.4077906608581543 | CLS Loss: 0.007148889359086752\n",
      "Epoch: 095, Loss: 2.4165, Train: 0.9965, Valid: 0.9876, Best: 0.9878\n",
      "Epoch 96 / 200 | iteration 0 / 171 | Total Loss: 2.4604711532592773 | KNN Loss: 2.4448139667510986 | CLS Loss: 0.01565719209611416\n",
      "Epoch 96 / 200 | iteration 10 / 171 | Total Loss: 2.384208917617798 | KNN Loss: 2.3568758964538574 | CLS Loss: 0.027333088219165802\n",
      "Epoch 96 / 200 | iteration 20 / 171 | Total Loss: 2.4307100772857666 | KNN Loss: 2.411741018295288 | CLS Loss: 0.018969163298606873\n",
      "Epoch 96 / 200 | iteration 30 / 171 | Total Loss: 2.4435362815856934 | KNN Loss: 2.4034769535064697 | CLS Loss: 0.04005931317806244\n",
      "Epoch 96 / 200 | iteration 40 / 171 | Total Loss: 2.410252571105957 | KNN Loss: 2.4042372703552246 | CLS Loss: 0.006015367805957794\n",
      "Epoch 96 / 200 | iteration 50 / 171 | Total Loss: 2.3612372875213623 | KNN Loss: 2.357637405395508 | CLS Loss: 0.003599764546379447\n",
      "Epoch 96 / 200 | iteration 60 / 171 | Total Loss: 2.392005205154419 | KNN Loss: 2.3850958347320557 | CLS Loss: 0.006909445393830538\n",
      "Epoch 96 / 200 | iteration 70 / 171 | Total Loss: 2.426130771636963 | KNN Loss: 2.3899600505828857 | CLS Loss: 0.0361706018447876\n",
      "Epoch 96 / 200 | iteration 80 / 171 | Total Loss: 2.3988046646118164 | KNN Loss: 2.3943979740142822 | CLS Loss: 0.004406772553920746\n",
      "Epoch 96 / 200 | iteration 90 / 171 | Total Loss: 2.4129621982574463 | KNN Loss: 2.4087789058685303 | CLS Loss: 0.004183237906545401\n",
      "Epoch 96 / 200 | iteration 100 / 171 | Total Loss: 2.437947988510132 | KNN Loss: 2.42934250831604 | CLS Loss: 0.008605537936091423\n",
      "Epoch 96 / 200 | iteration 110 / 171 | Total Loss: 2.4033968448638916 | KNN Loss: 2.400380849838257 | CLS Loss: 0.003015948925167322\n",
      "Epoch 96 / 200 | iteration 120 / 171 | Total Loss: 2.4212076663970947 | KNN Loss: 2.404998302459717 | CLS Loss: 0.016209248453378677\n",
      "Epoch 96 / 200 | iteration 130 / 171 | Total Loss: 2.407663583755493 | KNN Loss: 2.3935017585754395 | CLS Loss: 0.014161909930408001\n",
      "Epoch 96 / 200 | iteration 140 / 171 | Total Loss: 2.421112298965454 | KNN Loss: 2.4065239429473877 | CLS Loss: 0.014588418416678905\n",
      "Epoch 96 / 200 | iteration 150 / 171 | Total Loss: 2.420840263366699 | KNN Loss: 2.3992252349853516 | CLS Loss: 0.021615037694573402\n",
      "Epoch 96 / 200 | iteration 160 / 171 | Total Loss: 2.4613935947418213 | KNN Loss: 2.4190096855163574 | CLS Loss: 0.04238387197256088\n",
      "Epoch 96 / 200 | iteration 170 / 171 | Total Loss: 2.42678165435791 | KNN Loss: 2.414215087890625 | CLS Loss: 0.012566521763801575\n",
      "Epoch: 096, Loss: 2.4172, Train: 0.9960, Valid: 0.9853, Best: 0.9878\n",
      "Epoch 97 / 200 | iteration 0 / 171 | Total Loss: 2.4078261852264404 | KNN Loss: 2.3954076766967773 | CLS Loss: 0.012418394908308983\n",
      "Epoch 97 / 200 | iteration 10 / 171 | Total Loss: 2.4504411220550537 | KNN Loss: 2.4203412532806396 | CLS Loss: 0.03009979799389839\n",
      "Epoch 97 / 200 | iteration 20 / 171 | Total Loss: 2.417266607284546 | KNN Loss: 2.4142963886260986 | CLS Loss: 0.002970134373754263\n",
      "Epoch 97 / 200 | iteration 30 / 171 | Total Loss: 2.4079349040985107 | KNN Loss: 2.381784439086914 | CLS Loss: 0.02615051530301571\n",
      "Epoch 97 / 200 | iteration 40 / 171 | Total Loss: 2.449573516845703 | KNN Loss: 2.4218151569366455 | CLS Loss: 0.02775835059583187\n",
      "Epoch 97 / 200 | iteration 50 / 171 | Total Loss: 2.4247584342956543 | KNN Loss: 2.3931310176849365 | CLS Loss: 0.031627509742975235\n",
      "Epoch 97 / 200 | iteration 60 / 171 | Total Loss: 2.4007997512817383 | KNN Loss: 2.39365816116333 | CLS Loss: 0.007141672074794769\n",
      "Epoch 97 / 200 | iteration 70 / 171 | Total Loss: 2.4074859619140625 | KNN Loss: 2.394547939300537 | CLS Loss: 0.012938115745782852\n",
      "Epoch 97 / 200 | iteration 80 / 171 | Total Loss: 2.414466381072998 | KNN Loss: 2.408398151397705 | CLS Loss: 0.006068135146051645\n",
      "Epoch 97 / 200 | iteration 90 / 171 | Total Loss: 2.4205899238586426 | KNN Loss: 2.410984992980957 | CLS Loss: 0.00960502028465271\n",
      "Epoch 97 / 200 | iteration 100 / 171 | Total Loss: 2.3862199783325195 | KNN Loss: 2.3791723251342773 | CLS Loss: 0.007047648541629314\n",
      "Epoch 97 / 200 | iteration 110 / 171 | Total Loss: 2.3694822788238525 | KNN Loss: 2.3617568016052246 | CLS Loss: 0.007725514937192202\n",
      "Epoch 97 / 200 | iteration 120 / 171 | Total Loss: 2.3981873989105225 | KNN Loss: 2.3846993446350098 | CLS Loss: 0.013488007709383965\n",
      "Epoch 97 / 200 | iteration 130 / 171 | Total Loss: 2.432218074798584 | KNN Loss: 2.412360906600952 | CLS Loss: 0.019857244566082954\n",
      "Epoch 97 / 200 | iteration 140 / 171 | Total Loss: 2.4474618434906006 | KNN Loss: 2.3869779109954834 | CLS Loss: 0.06048387661576271\n",
      "Epoch 97 / 200 | iteration 150 / 171 | Total Loss: 2.420940637588501 | KNN Loss: 2.404721736907959 | CLS Loss: 0.01621880568563938\n",
      "Epoch 97 / 200 | iteration 160 / 171 | Total Loss: 2.4464070796966553 | KNN Loss: 2.4113035202026367 | CLS Loss: 0.035103488713502884\n",
      "Epoch 97 / 200 | iteration 170 / 171 | Total Loss: 2.413139581680298 | KNN Loss: 2.394113063812256 | CLS Loss: 0.01902640052139759\n",
      "Epoch: 097, Loss: 2.4168, Train: 0.9953, Valid: 0.9865, Best: 0.9878\n",
      "Epoch 98 / 200 | iteration 0 / 171 | Total Loss: 2.404048442840576 | KNN Loss: 2.3958215713500977 | CLS Loss: 0.008226823061704636\n",
      "Epoch 98 / 200 | iteration 10 / 171 | Total Loss: 2.4332897663116455 | KNN Loss: 2.411201000213623 | CLS Loss: 0.022088708356022835\n",
      "Epoch 98 / 200 | iteration 20 / 171 | Total Loss: 2.4158875942230225 | KNN Loss: 2.4131340980529785 | CLS Loss: 0.0027535248082131147\n",
      "Epoch 98 / 200 | iteration 30 / 171 | Total Loss: 2.3782148361206055 | KNN Loss: 2.3698225021362305 | CLS Loss: 0.008392407558858395\n",
      "Epoch 98 / 200 | iteration 40 / 171 | Total Loss: 2.415342092514038 | KNN Loss: 2.4111382961273193 | CLS Loss: 0.004203782416880131\n",
      "Epoch 98 / 200 | iteration 50 / 171 | Total Loss: 2.411799192428589 | KNN Loss: 2.3928256034851074 | CLS Loss: 0.018973611295223236\n",
      "Epoch 98 / 200 | iteration 60 / 171 | Total Loss: 2.3851938247680664 | KNN Loss: 2.362384796142578 | CLS Loss: 0.022808922454714775\n",
      "Epoch 98 / 200 | iteration 70 / 171 | Total Loss: 2.4096171855926514 | KNN Loss: 2.400601387023926 | CLS Loss: 0.009015792980790138\n",
      "Epoch 98 / 200 | iteration 80 / 171 | Total Loss: 2.38517689704895 | KNN Loss: 2.379967451095581 | CLS Loss: 0.005209542345255613\n",
      "Epoch 98 / 200 | iteration 90 / 171 | Total Loss: 2.435250759124756 | KNN Loss: 2.414534568786621 | CLS Loss: 0.020716223865747452\n",
      "Epoch 98 / 200 | iteration 100 / 171 | Total Loss: 2.37790846824646 | KNN Loss: 2.371220827102661 | CLS Loss: 0.006687558721750975\n",
      "Epoch 98 / 200 | iteration 110 / 171 | Total Loss: 2.4321625232696533 | KNN Loss: 2.421867609024048 | CLS Loss: 0.010295003652572632\n",
      "Epoch 98 / 200 | iteration 120 / 171 | Total Loss: 2.424762487411499 | KNN Loss: 2.4140851497650146 | CLS Loss: 0.01067732460796833\n",
      "Epoch 98 / 200 | iteration 130 / 171 | Total Loss: 2.4173686504364014 | KNN Loss: 2.3965444564819336 | CLS Loss: 0.020824160426855087\n",
      "Epoch 98 / 200 | iteration 140 / 171 | Total Loss: 2.389282703399658 | KNN Loss: 2.360527276992798 | CLS Loss: 0.028755487874150276\n",
      "Epoch 98 / 200 | iteration 150 / 171 | Total Loss: 2.4217042922973633 | KNN Loss: 2.405794382095337 | CLS Loss: 0.015909921377897263\n",
      "Epoch 98 / 200 | iteration 160 / 171 | Total Loss: 2.3833258152008057 | KNN Loss: 2.364945411682129 | CLS Loss: 0.01838049665093422\n",
      "Epoch 98 / 200 | iteration 170 / 171 | Total Loss: 2.399653196334839 | KNN Loss: 2.3825695514678955 | CLS Loss: 0.017083628103137016\n",
      "Epoch: 098, Loss: 2.4147, Train: 0.9962, Valid: 0.9864, Best: 0.9878\n",
      "Epoch 99 / 200 | iteration 0 / 171 | Total Loss: 2.4180498123168945 | KNN Loss: 2.4082794189453125 | CLS Loss: 0.009770354256033897\n",
      "Epoch 99 / 200 | iteration 10 / 171 | Total Loss: 2.408390998840332 | KNN Loss: 2.3896656036376953 | CLS Loss: 0.018725508823990822\n",
      "Epoch 99 / 200 | iteration 20 / 171 | Total Loss: 2.392101287841797 | KNN Loss: 2.3859057426452637 | CLS Loss: 0.0061955321580171585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 / 200 | iteration 30 / 171 | Total Loss: 2.4090805053710938 | KNN Loss: 2.3818883895874023 | CLS Loss: 0.027192117646336555\n",
      "Epoch 99 / 200 | iteration 40 / 171 | Total Loss: 2.4093453884124756 | KNN Loss: 2.4031081199645996 | CLS Loss: 0.006237211171537638\n",
      "Epoch 99 / 200 | iteration 50 / 171 | Total Loss: 2.411881923675537 | KNN Loss: 2.4073455333709717 | CLS Loss: 0.004536332096904516\n",
      "Epoch 99 / 200 | iteration 60 / 171 | Total Loss: 2.406984806060791 | KNN Loss: 2.3789916038513184 | CLS Loss: 0.02799312025308609\n",
      "Epoch 99 / 200 | iteration 70 / 171 | Total Loss: 2.417468786239624 | KNN Loss: 2.405515670776367 | CLS Loss: 0.011953094974160194\n",
      "Epoch 99 / 200 | iteration 80 / 171 | Total Loss: 2.3962228298187256 | KNN Loss: 2.3719875812530518 | CLS Loss: 0.024235185235738754\n",
      "Epoch 99 / 200 | iteration 90 / 171 | Total Loss: 2.397979497909546 | KNN Loss: 2.3949782848358154 | CLS Loss: 0.003001247765496373\n",
      "Epoch 99 / 200 | iteration 100 / 171 | Total Loss: 2.3935914039611816 | KNN Loss: 2.3684186935424805 | CLS Loss: 0.025172827765345573\n",
      "Epoch 99 / 200 | iteration 110 / 171 | Total Loss: 2.435094118118286 | KNN Loss: 2.412621021270752 | CLS Loss: 0.022473169490695\n",
      "Epoch 99 / 200 | iteration 120 / 171 | Total Loss: 2.396667242050171 | KNN Loss: 2.3767635822296143 | CLS Loss: 0.019903745502233505\n",
      "Epoch 99 / 200 | iteration 130 / 171 | Total Loss: 2.4218387603759766 | KNN Loss: 2.4170498847961426 | CLS Loss: 0.004788912367075682\n",
      "Epoch 99 / 200 | iteration 140 / 171 | Total Loss: 2.3802826404571533 | KNN Loss: 2.374356508255005 | CLS Loss: 0.0059260157868266106\n",
      "Epoch 99 / 200 | iteration 150 / 171 | Total Loss: 2.3925914764404297 | KNN Loss: 2.3840925693511963 | CLS Loss: 0.008498809300363064\n",
      "Epoch 99 / 200 | iteration 160 / 171 | Total Loss: 2.4310104846954346 | KNN Loss: 2.418206214904785 | CLS Loss: 0.0128043657168746\n",
      "Epoch 99 / 200 | iteration 170 / 171 | Total Loss: 2.4417002201080322 | KNN Loss: 2.412698268890381 | CLS Loss: 0.029001956805586815\n",
      "Epoch: 099, Loss: 2.4177, Train: 0.9934, Valid: 0.9857, Best: 0.9878\n",
      "Epoch 100 / 200 | iteration 0 / 171 | Total Loss: 2.4295434951782227 | KNN Loss: 2.4047060012817383 | CLS Loss: 0.02483752742409706\n",
      "Epoch 100 / 200 | iteration 10 / 171 | Total Loss: 2.4003894329071045 | KNN Loss: 2.396580219268799 | CLS Loss: 0.003809264861047268\n",
      "Epoch 100 / 200 | iteration 20 / 171 | Total Loss: 2.4220402240753174 | KNN Loss: 2.4084298610687256 | CLS Loss: 0.013610251247882843\n",
      "Epoch 100 / 200 | iteration 30 / 171 | Total Loss: 2.4544122219085693 | KNN Loss: 2.4356257915496826 | CLS Loss: 0.01878632791340351\n",
      "Epoch 100 / 200 | iteration 40 / 171 | Total Loss: 2.4670016765594482 | KNN Loss: 2.4264817237854004 | CLS Loss: 0.040519922971725464\n",
      "Epoch 100 / 200 | iteration 50 / 171 | Total Loss: 2.4271836280822754 | KNN Loss: 2.4087319374084473 | CLS Loss: 0.018451731652021408\n",
      "Epoch 100 / 200 | iteration 60 / 171 | Total Loss: 2.409498453140259 | KNN Loss: 2.393279552459717 | CLS Loss: 0.01621897704899311\n",
      "Epoch 100 / 200 | iteration 70 / 171 | Total Loss: 2.4423270225524902 | KNN Loss: 2.42218279838562 | CLS Loss: 0.020144259557127953\n",
      "Epoch 100 / 200 | iteration 80 / 171 | Total Loss: 2.426086664199829 | KNN Loss: 2.4005684852600098 | CLS Loss: 0.025518294423818588\n",
      "Epoch 100 / 200 | iteration 90 / 171 | Total Loss: 2.380514144897461 | KNN Loss: 2.3727476596832275 | CLS Loss: 0.007766508497297764\n",
      "Epoch 100 / 200 | iteration 100 / 171 | Total Loss: 2.4328651428222656 | KNN Loss: 2.422252893447876 | CLS Loss: 0.01061223540455103\n",
      "Epoch 100 / 200 | iteration 110 / 171 | Total Loss: 2.43851637840271 | KNN Loss: 2.4178614616394043 | CLS Loss: 0.020654883235692978\n",
      "Epoch 100 / 200 | iteration 120 / 171 | Total Loss: 2.419820785522461 | KNN Loss: 2.4087297916412354 | CLS Loss: 0.011091052554547787\n",
      "Epoch 100 / 200 | iteration 130 / 171 | Total Loss: 2.422503709793091 | KNN Loss: 2.415071725845337 | CLS Loss: 0.007431980222463608\n",
      "Epoch 100 / 200 | iteration 140 / 171 | Total Loss: 2.4137609004974365 | KNN Loss: 2.4051084518432617 | CLS Loss: 0.008652535267174244\n",
      "Epoch 100 / 200 | iteration 150 / 171 | Total Loss: 2.4108190536499023 | KNN Loss: 2.4032626152038574 | CLS Loss: 0.007556452415883541\n",
      "Epoch 100 / 200 | iteration 160 / 171 | Total Loss: 2.4115283489227295 | KNN Loss: 2.3993589878082275 | CLS Loss: 0.012169296853244305\n",
      "Epoch 100 / 200 | iteration 170 / 171 | Total Loss: 2.4378182888031006 | KNN Loss: 2.412386655807495 | CLS Loss: 0.025431601330637932\n",
      "Epoch: 100, Loss: 2.4174, Train: 0.9964, Valid: 0.9866, Best: 0.9878\n",
      "Epoch 101 / 200 | iteration 0 / 171 | Total Loss: 2.408051013946533 | KNN Loss: 2.3833935260772705 | CLS Loss: 0.024657554924488068\n",
      "Epoch 101 / 200 | iteration 10 / 171 | Total Loss: 2.456394672393799 | KNN Loss: 2.427729606628418 | CLS Loss: 0.02866508439183235\n",
      "Epoch 101 / 200 | iteration 20 / 171 | Total Loss: 2.454303741455078 | KNN Loss: 2.401028633117676 | CLS Loss: 0.05327513813972473\n",
      "Epoch 101 / 200 | iteration 30 / 171 | Total Loss: 2.452876091003418 | KNN Loss: 2.4439456462860107 | CLS Loss: 0.008930481038987637\n",
      "Epoch 101 / 200 | iteration 40 / 171 | Total Loss: 2.4552741050720215 | KNN Loss: 2.4275619983673096 | CLS Loss: 0.027712034061551094\n",
      "Epoch 101 / 200 | iteration 50 / 171 | Total Loss: 2.413544178009033 | KNN Loss: 2.39853835105896 | CLS Loss: 0.015005809254944324\n",
      "Epoch 101 / 200 | iteration 60 / 171 | Total Loss: 2.446320056915283 | KNN Loss: 2.4302711486816406 | CLS Loss: 0.0160489771515131\n",
      "Epoch 101 / 200 | iteration 70 / 171 | Total Loss: 2.4384095668792725 | KNN Loss: 2.4298830032348633 | CLS Loss: 0.008526554331183434\n",
      "Epoch 101 / 200 | iteration 80 / 171 | Total Loss: 2.4163801670074463 | KNN Loss: 2.4007670879364014 | CLS Loss: 0.015612969174981117\n",
      "Epoch 101 / 200 | iteration 90 / 171 | Total Loss: 2.421663284301758 | KNN Loss: 2.4072282314300537 | CLS Loss: 0.01443504448980093\n",
      "Epoch 101 / 200 | iteration 100 / 171 | Total Loss: 2.422314405441284 | KNN Loss: 2.4087889194488525 | CLS Loss: 0.013525598682463169\n",
      "Epoch 101 / 200 | iteration 110 / 171 | Total Loss: 2.403270959854126 | KNN Loss: 2.4008140563964844 | CLS Loss: 0.002456876216456294\n",
      "Epoch 101 / 200 | iteration 120 / 171 | Total Loss: 2.4064865112304688 | KNN Loss: 2.3838515281677246 | CLS Loss: 0.022634902969002724\n",
      "Epoch 101 / 200 | iteration 130 / 171 | Total Loss: 2.4302539825439453 | KNN Loss: 2.4156084060668945 | CLS Loss: 0.01464560255408287\n",
      "Epoch 101 / 200 | iteration 140 / 171 | Total Loss: 2.4031569957733154 | KNN Loss: 2.3981282711029053 | CLS Loss: 0.0050288098864257336\n",
      "Epoch 101 / 200 | iteration 150 / 171 | Total Loss: 2.3843026161193848 | KNN Loss: 2.3831422328948975 | CLS Loss: 0.001160276704467833\n",
      "Epoch 101 / 200 | iteration 160 / 171 | Total Loss: 2.425238847732544 | KNN Loss: 2.418471574783325 | CLS Loss: 0.006767387967556715\n",
      "Epoch 101 / 200 | iteration 170 / 171 | Total Loss: 2.396667957305908 | KNN Loss: 2.3884732723236084 | CLS Loss: 0.00819476880133152\n",
      "Epoch: 101, Loss: 2.4177, Train: 0.9966, Valid: 0.9872, Best: 0.9878\n",
      "Epoch 102 / 200 | iteration 0 / 171 | Total Loss: 2.398613452911377 | KNN Loss: 2.3940348625183105 | CLS Loss: 0.00457859318703413\n",
      "Epoch 102 / 200 | iteration 10 / 171 | Total Loss: 2.422555685043335 | KNN Loss: 2.394531488418579 | CLS Loss: 0.02802429534494877\n",
      "Epoch 102 / 200 | iteration 20 / 171 | Total Loss: 2.4190640449523926 | KNN Loss: 2.4011974334716797 | CLS Loss: 0.017866572365164757\n",
      "Epoch 102 / 200 | iteration 30 / 171 | Total Loss: 2.4383351802825928 | KNN Loss: 2.4076120853424072 | CLS Loss: 0.030723009258508682\n",
      "Epoch 102 / 200 | iteration 40 / 171 | Total Loss: 2.4577455520629883 | KNN Loss: 2.4248530864715576 | CLS Loss: 0.03289255127310753\n",
      "Epoch 102 / 200 | iteration 50 / 171 | Total Loss: 2.419059991836548 | KNN Loss: 2.3960304260253906 | CLS Loss: 0.023029450327157974\n",
      "Epoch 102 / 200 | iteration 60 / 171 | Total Loss: 2.403224468231201 | KNN Loss: 2.4004828929901123 | CLS Loss: 0.002741557313129306\n",
      "Epoch 102 / 200 | iteration 70 / 171 | Total Loss: 2.4189343452453613 | KNN Loss: 2.4154202938079834 | CLS Loss: 0.0035139676183462143\n",
      "Epoch 102 / 200 | iteration 80 / 171 | Total Loss: 2.382584810256958 | KNN Loss: 2.37737774848938 | CLS Loss: 0.005206963047385216\n",
      "Epoch 102 / 200 | iteration 90 / 171 | Total Loss: 2.424345016479492 | KNN Loss: 2.4163708686828613 | CLS Loss: 0.00797419622540474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 / 200 | iteration 100 / 171 | Total Loss: 2.4281089305877686 | KNN Loss: 2.401885747909546 | CLS Loss: 0.026223143562674522\n",
      "Epoch 102 / 200 | iteration 110 / 171 | Total Loss: 2.4158198833465576 | KNN Loss: 2.399688720703125 | CLS Loss: 0.016131170094013214\n",
      "Epoch 102 / 200 | iteration 120 / 171 | Total Loss: 2.4092230796813965 | KNN Loss: 2.4031050205230713 | CLS Loss: 0.006118148099631071\n",
      "Epoch 102 / 200 | iteration 130 / 171 | Total Loss: 2.4101831912994385 | KNN Loss: 2.404726505279541 | CLS Loss: 0.0054567172192037106\n",
      "Epoch 102 / 200 | iteration 140 / 171 | Total Loss: 2.4063880443573 | KNN Loss: 2.4006831645965576 | CLS Loss: 0.005704963114112616\n",
      "Epoch 102 / 200 | iteration 150 / 171 | Total Loss: 2.4285666942596436 | KNN Loss: 2.38278865814209 | CLS Loss: 0.04577803984284401\n",
      "Epoch 102 / 200 | iteration 160 / 171 | Total Loss: 2.440495491027832 | KNN Loss: 2.4072861671447754 | CLS Loss: 0.03320937231183052\n",
      "Epoch 102 / 200 | iteration 170 / 171 | Total Loss: 2.4141623973846436 | KNN Loss: 2.397789239883423 | CLS Loss: 0.016373099759221077\n",
      "Epoch: 102, Loss: 2.4176, Train: 0.9953, Valid: 0.9852, Best: 0.9878\n",
      "Epoch 103 / 200 | iteration 0 / 171 | Total Loss: 2.4101362228393555 | KNN Loss: 2.4031403064727783 | CLS Loss: 0.006995872128754854\n",
      "Epoch 103 / 200 | iteration 10 / 171 | Total Loss: 2.423403739929199 | KNN Loss: 2.418961763381958 | CLS Loss: 0.0044418806210160255\n",
      "Epoch 103 / 200 | iteration 20 / 171 | Total Loss: 2.3973097801208496 | KNN Loss: 2.375983953475952 | CLS Loss: 0.021325889974832535\n",
      "Epoch 103 / 200 | iteration 30 / 171 | Total Loss: 2.3887112140655518 | KNN Loss: 2.37996244430542 | CLS Loss: 0.008748702704906464\n",
      "Epoch 103 / 200 | iteration 40 / 171 | Total Loss: 2.4081320762634277 | KNN Loss: 2.3916428089141846 | CLS Loss: 0.016489308327436447\n",
      "Epoch 103 / 200 | iteration 50 / 171 | Total Loss: 2.4107723236083984 | KNN Loss: 2.4027974605560303 | CLS Loss: 0.007974958047270775\n",
      "Epoch 103 / 200 | iteration 60 / 171 | Total Loss: 2.4130444526672363 | KNN Loss: 2.4110267162323 | CLS Loss: 0.0020178204867988825\n",
      "Epoch 103 / 200 | iteration 70 / 171 | Total Loss: 2.418635129928589 | KNN Loss: 2.3986763954162598 | CLS Loss: 0.0199586171656847\n",
      "Epoch 103 / 200 | iteration 80 / 171 | Total Loss: 2.4407176971435547 | KNN Loss: 2.4380359649658203 | CLS Loss: 0.002681744983419776\n",
      "Epoch 103 / 200 | iteration 90 / 171 | Total Loss: 2.4509856700897217 | KNN Loss: 2.4226295948028564 | CLS Loss: 0.028356127440929413\n",
      "Epoch 103 / 200 | iteration 100 / 171 | Total Loss: 2.400723934173584 | KNN Loss: 2.3947157859802246 | CLS Loss: 0.00600803317502141\n",
      "Epoch 103 / 200 | iteration 110 / 171 | Total Loss: 2.380905866622925 | KNN Loss: 2.364968776702881 | CLS Loss: 0.01593713089823723\n",
      "Epoch 103 / 200 | iteration 120 / 171 | Total Loss: 2.3941597938537598 | KNN Loss: 2.3828718662261963 | CLS Loss: 0.011287936009466648\n",
      "Epoch 103 / 200 | iteration 130 / 171 | Total Loss: 2.4154605865478516 | KNN Loss: 2.4111218452453613 | CLS Loss: 0.004338626749813557\n",
      "Epoch 103 / 200 | iteration 140 / 171 | Total Loss: 2.4059345722198486 | KNN Loss: 2.402189016342163 | CLS Loss: 0.003745641093701124\n",
      "Epoch 103 / 200 | iteration 150 / 171 | Total Loss: 2.4538238048553467 | KNN Loss: 2.377610206604004 | CLS Loss: 0.07621348649263382\n",
      "Epoch 103 / 200 | iteration 160 / 171 | Total Loss: 2.4233531951904297 | KNN Loss: 2.4098799228668213 | CLS Loss: 0.013473260216414928\n",
      "Epoch 103 / 200 | iteration 170 / 171 | Total Loss: 2.426382541656494 | KNN Loss: 2.422795295715332 | CLS Loss: 0.0035871544387191534\n",
      "Epoch: 103, Loss: 2.4156, Train: 0.9961, Valid: 0.9859, Best: 0.9878\n",
      "Epoch 104 / 200 | iteration 0 / 171 | Total Loss: 2.3755507469177246 | KNN Loss: 2.366027355194092 | CLS Loss: 0.009523468092083931\n",
      "Epoch 104 / 200 | iteration 10 / 171 | Total Loss: 2.384990692138672 | KNN Loss: 2.366525650024414 | CLS Loss: 0.018465103581547737\n",
      "Epoch 104 / 200 | iteration 20 / 171 | Total Loss: 2.395914316177368 | KNN Loss: 2.3862297534942627 | CLS Loss: 0.009684600867331028\n",
      "Epoch 104 / 200 | iteration 30 / 171 | Total Loss: 2.444873094558716 | KNN Loss: 2.4229629039764404 | CLS Loss: 0.021910151466727257\n",
      "Epoch 104 / 200 | iteration 40 / 171 | Total Loss: 2.406140089035034 | KNN Loss: 2.384615421295166 | CLS Loss: 0.021524563431739807\n",
      "Epoch 104 / 200 | iteration 50 / 171 | Total Loss: 2.396362781524658 | KNN Loss: 2.385002374649048 | CLS Loss: 0.011360473930835724\n",
      "Epoch 104 / 200 | iteration 60 / 171 | Total Loss: 2.448760509490967 | KNN Loss: 2.3993618488311768 | CLS Loss: 0.04939859360456467\n",
      "Epoch 104 / 200 | iteration 70 / 171 | Total Loss: 2.4234976768493652 | KNN Loss: 2.413264751434326 | CLS Loss: 0.010232868604362011\n",
      "Epoch 104 / 200 | iteration 80 / 171 | Total Loss: 2.3974597454071045 | KNN Loss: 2.3895785808563232 | CLS Loss: 0.007881148718297482\n",
      "Epoch 104 / 200 | iteration 90 / 171 | Total Loss: 2.432976007461548 | KNN Loss: 2.410991907119751 | CLS Loss: 0.021984122693538666\n",
      "Epoch 104 / 200 | iteration 100 / 171 | Total Loss: 2.4192006587982178 | KNN Loss: 2.4080400466918945 | CLS Loss: 0.011160558089613914\n",
      "Epoch 104 / 200 | iteration 110 / 171 | Total Loss: 2.365718126296997 | KNN Loss: 2.3634238243103027 | CLS Loss: 0.0022944107186049223\n",
      "Epoch 104 / 200 | iteration 120 / 171 | Total Loss: 2.4098429679870605 | KNN Loss: 2.3903322219848633 | CLS Loss: 0.019510716199874878\n",
      "Epoch 104 / 200 | iteration 130 / 171 | Total Loss: 2.427398443222046 | KNN Loss: 2.4229650497436523 | CLS Loss: 0.004433458670973778\n",
      "Epoch 104 / 200 | iteration 140 / 171 | Total Loss: 2.420135021209717 | KNN Loss: 2.418266534805298 | CLS Loss: 0.0018684359965845942\n",
      "Epoch 104 / 200 | iteration 150 / 171 | Total Loss: 2.4010868072509766 | KNN Loss: 2.3928637504577637 | CLS Loss: 0.008223099634051323\n",
      "Epoch 104 / 200 | iteration 160 / 171 | Total Loss: 2.423116683959961 | KNN Loss: 2.4177279472351074 | CLS Loss: 0.005388755351305008\n",
      "Epoch 104 / 200 | iteration 170 / 171 | Total Loss: 2.3967843055725098 | KNN Loss: 2.3837637901306152 | CLS Loss: 0.013020607642829418\n",
      "Epoch: 104, Loss: 2.4167, Train: 0.9964, Valid: 0.9872, Best: 0.9878\n",
      "Epoch 105 / 200 | iteration 0 / 171 | Total Loss: 2.403252124786377 | KNN Loss: 2.3986823558807373 | CLS Loss: 0.0045697856694459915\n",
      "Epoch 105 / 200 | iteration 10 / 171 | Total Loss: 2.412250280380249 | KNN Loss: 2.403169631958008 | CLS Loss: 0.009080763906240463\n",
      "Epoch 105 / 200 | iteration 20 / 171 | Total Loss: 2.3957836627960205 | KNN Loss: 2.388899803161621 | CLS Loss: 0.006883847061544657\n",
      "Epoch 105 / 200 | iteration 30 / 171 | Total Loss: 2.4172780513763428 | KNN Loss: 2.4110031127929688 | CLS Loss: 0.006274848710745573\n",
      "Epoch 105 / 200 | iteration 40 / 171 | Total Loss: 2.4840168952941895 | KNN Loss: 2.472937822341919 | CLS Loss: 0.011079116724431515\n",
      "Epoch 105 / 200 | iteration 50 / 171 | Total Loss: 2.410238265991211 | KNN Loss: 2.395535707473755 | CLS Loss: 0.014702660962939262\n",
      "Epoch 105 / 200 | iteration 60 / 171 | Total Loss: 2.4191243648529053 | KNN Loss: 2.4075584411621094 | CLS Loss: 0.011565880849957466\n",
      "Epoch 105 / 200 | iteration 70 / 171 | Total Loss: 2.402221441268921 | KNN Loss: 2.3859288692474365 | CLS Loss: 0.01629246585071087\n",
      "Epoch 105 / 200 | iteration 80 / 171 | Total Loss: 2.3935787677764893 | KNN Loss: 2.3830394744873047 | CLS Loss: 0.010539188049733639\n",
      "Epoch 105 / 200 | iteration 90 / 171 | Total Loss: 2.3856332302093506 | KNN Loss: 2.369784116744995 | CLS Loss: 0.015849152579903603\n",
      "Epoch 105 / 200 | iteration 100 / 171 | Total Loss: 2.4142565727233887 | KNN Loss: 2.392115592956543 | CLS Loss: 0.02214096486568451\n",
      "Epoch 105 / 200 | iteration 110 / 171 | Total Loss: 2.43088436126709 | KNN Loss: 2.4157357215881348 | CLS Loss: 0.015148565173149109\n",
      "Epoch 105 / 200 | iteration 120 / 171 | Total Loss: 2.417297840118408 | KNN Loss: 2.3889455795288086 | CLS Loss: 0.02835230529308319\n",
      "Epoch 105 / 200 | iteration 130 / 171 | Total Loss: 2.426201820373535 | KNN Loss: 2.423677921295166 | CLS Loss: 0.0025238364469259977\n",
      "Epoch 105 / 200 | iteration 140 / 171 | Total Loss: 2.426934242248535 | KNN Loss: 2.4117913246154785 | CLS Loss: 0.01514297816902399\n",
      "Epoch 105 / 200 | iteration 150 / 171 | Total Loss: 2.4148178100585938 | KNN Loss: 2.390361785888672 | CLS Loss: 0.02445594221353531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 / 200 | iteration 160 / 171 | Total Loss: 2.4261093139648438 | KNN Loss: 2.40960693359375 | CLS Loss: 0.016502458602190018\n",
      "Epoch 105 / 200 | iteration 170 / 171 | Total Loss: 2.4165689945220947 | KNN Loss: 2.402536392211914 | CLS Loss: 0.014032592065632343\n",
      "Epoch: 105, Loss: 2.4133, Train: 0.9949, Valid: 0.9855, Best: 0.9878\n",
      "Epoch 106 / 200 | iteration 0 / 171 | Total Loss: 2.4064979553222656 | KNN Loss: 2.3946051597595215 | CLS Loss: 0.011892887763679028\n",
      "Epoch 106 / 200 | iteration 10 / 171 | Total Loss: 2.4008901119232178 | KNN Loss: 2.387813091278076 | CLS Loss: 0.013077130541205406\n",
      "Epoch 106 / 200 | iteration 20 / 171 | Total Loss: 2.3920645713806152 | KNN Loss: 2.3680689334869385 | CLS Loss: 0.02399558201432228\n",
      "Epoch 106 / 200 | iteration 30 / 171 | Total Loss: 2.384657144546509 | KNN Loss: 2.3551809787750244 | CLS Loss: 0.02947618067264557\n",
      "Epoch 106 / 200 | iteration 40 / 171 | Total Loss: 2.411860466003418 | KNN Loss: 2.399411916732788 | CLS Loss: 0.012448485940694809\n",
      "Epoch 106 / 200 | iteration 50 / 171 | Total Loss: 2.413010597229004 | KNN Loss: 2.408787488937378 | CLS Loss: 0.004223139490932226\n",
      "Epoch 106 / 200 | iteration 60 / 171 | Total Loss: 2.439884901046753 | KNN Loss: 2.4323630332946777 | CLS Loss: 0.0075218891724944115\n",
      "Epoch 106 / 200 | iteration 70 / 171 | Total Loss: 2.420611619949341 | KNN Loss: 2.4074087142944336 | CLS Loss: 0.013202909380197525\n",
      "Epoch 106 / 200 | iteration 80 / 171 | Total Loss: 2.4207980632781982 | KNN Loss: 2.4126813411712646 | CLS Loss: 0.008116686716675758\n",
      "Epoch 106 / 200 | iteration 90 / 171 | Total Loss: 2.377547025680542 | KNN Loss: 2.3752026557922363 | CLS Loss: 0.0023444006219506264\n",
      "Epoch 106 / 200 | iteration 100 / 171 | Total Loss: 2.4436702728271484 | KNN Loss: 2.430084705352783 | CLS Loss: 0.01358551625162363\n",
      "Epoch 106 / 200 | iteration 110 / 171 | Total Loss: 2.459979772567749 | KNN Loss: 2.44032883644104 | CLS Loss: 0.019650960341095924\n",
      "Epoch 106 / 200 | iteration 120 / 171 | Total Loss: 2.430082321166992 | KNN Loss: 2.40297532081604 | CLS Loss: 0.027107061818242073\n",
      "Epoch 106 / 200 | iteration 130 / 171 | Total Loss: 2.4722254276275635 | KNN Loss: 2.4644651412963867 | CLS Loss: 0.007760268170386553\n",
      "Epoch 106 / 200 | iteration 140 / 171 | Total Loss: 2.4149038791656494 | KNN Loss: 2.3901193141937256 | CLS Loss: 0.024784598499536514\n",
      "Epoch 106 / 200 | iteration 150 / 171 | Total Loss: 2.4279680252075195 | KNN Loss: 2.4203782081604004 | CLS Loss: 0.007589821238070726\n",
      "Epoch 106 / 200 | iteration 160 / 171 | Total Loss: 2.422344923019409 | KNN Loss: 2.4034500122070312 | CLS Loss: 0.018894841894507408\n",
      "Epoch 106 / 200 | iteration 170 / 171 | Total Loss: 2.431788682937622 | KNN Loss: 2.39923357963562 | CLS Loss: 0.032555218786001205\n",
      "Epoch: 106, Loss: 2.4178, Train: 0.9961, Valid: 0.9850, Best: 0.9878\n",
      "Epoch 107 / 200 | iteration 0 / 171 | Total Loss: 2.437814950942993 | KNN Loss: 2.4207046031951904 | CLS Loss: 0.01711023971438408\n",
      "Epoch 107 / 200 | iteration 10 / 171 | Total Loss: 2.3945982456207275 | KNN Loss: 2.3742904663085938 | CLS Loss: 0.020307807251811028\n",
      "Epoch 107 / 200 | iteration 20 / 171 | Total Loss: 2.3991708755493164 | KNN Loss: 2.3898324966430664 | CLS Loss: 0.009338460862636566\n",
      "Epoch 107 / 200 | iteration 30 / 171 | Total Loss: 2.398897171020508 | KNN Loss: 2.3797106742858887 | CLS Loss: 0.019186602905392647\n",
      "Epoch 107 / 200 | iteration 40 / 171 | Total Loss: 2.4389846324920654 | KNN Loss: 2.435189962387085 | CLS Loss: 0.0037946547381579876\n",
      "Epoch 107 / 200 | iteration 50 / 171 | Total Loss: 2.4270927906036377 | KNN Loss: 2.415022611618042 | CLS Loss: 0.01207025721669197\n",
      "Epoch 107 / 200 | iteration 60 / 171 | Total Loss: 2.39497709274292 | KNN Loss: 2.39316987991333 | CLS Loss: 0.001807151478715241\n",
      "Epoch 107 / 200 | iteration 70 / 171 | Total Loss: 2.418774127960205 | KNN Loss: 2.403390407562256 | CLS Loss: 0.015383618883788586\n",
      "Epoch 107 / 200 | iteration 80 / 171 | Total Loss: 2.4233009815216064 | KNN Loss: 2.413429021835327 | CLS Loss: 0.009872018359601498\n",
      "Epoch 107 / 200 | iteration 90 / 171 | Total Loss: 2.467721939086914 | KNN Loss: 2.436687469482422 | CLS Loss: 0.03103449195623398\n",
      "Epoch 107 / 200 | iteration 100 / 171 | Total Loss: 2.4243216514587402 | KNN Loss: 2.387364387512207 | CLS Loss: 0.03695732355117798\n",
      "Epoch 107 / 200 | iteration 110 / 171 | Total Loss: 2.411494731903076 | KNN Loss: 2.3892931938171387 | CLS Loss: 0.02220158278942108\n",
      "Epoch 107 / 200 | iteration 120 / 171 | Total Loss: 2.408757209777832 | KNN Loss: 2.3930764198303223 | CLS Loss: 0.015680719166994095\n",
      "Epoch 107 / 200 | iteration 130 / 171 | Total Loss: 2.4926998615264893 | KNN Loss: 2.462871551513672 | CLS Loss: 0.029828328639268875\n",
      "Epoch 107 / 200 | iteration 140 / 171 | Total Loss: 2.425410509109497 | KNN Loss: 2.4161927700042725 | CLS Loss: 0.00921772699803114\n",
      "Epoch 107 / 200 | iteration 150 / 171 | Total Loss: 2.4233450889587402 | KNN Loss: 2.408527135848999 | CLS Loss: 0.01481806579977274\n",
      "Epoch 107 / 200 | iteration 160 / 171 | Total Loss: 2.4580118656158447 | KNN Loss: 2.4337856769561768 | CLS Loss: 0.024226229637861252\n",
      "Epoch 107 / 200 | iteration 170 / 171 | Total Loss: 2.3959403038024902 | KNN Loss: 2.383086681365967 | CLS Loss: 0.012853667140007019\n",
      "Epoch: 107, Loss: 2.4201, Train: 0.9951, Valid: 0.9861, Best: 0.9878\n",
      "Epoch 108 / 200 | iteration 0 / 171 | Total Loss: 2.4447710514068604 | KNN Loss: 2.4100546836853027 | CLS Loss: 0.03471642732620239\n",
      "Epoch 108 / 200 | iteration 10 / 171 | Total Loss: 2.4284112453460693 | KNN Loss: 2.402834177017212 | CLS Loss: 0.025577016174793243\n",
      "Epoch 108 / 200 | iteration 20 / 171 | Total Loss: 2.3953733444213867 | KNN Loss: 2.3777143955230713 | CLS Loss: 0.017659001052379608\n",
      "Epoch 108 / 200 | iteration 30 / 171 | Total Loss: 2.3870699405670166 | KNN Loss: 2.375361680984497 | CLS Loss: 0.011708175763487816\n",
      "Epoch 108 / 200 | iteration 40 / 171 | Total Loss: 2.3559813499450684 | KNN Loss: 2.3544256687164307 | CLS Loss: 0.0015556649304926395\n",
      "Epoch 108 / 200 | iteration 50 / 171 | Total Loss: 2.3906538486480713 | KNN Loss: 2.3805670738220215 | CLS Loss: 0.010086869820952415\n",
      "Epoch 108 / 200 | iteration 60 / 171 | Total Loss: 2.3600058555603027 | KNN Loss: 2.3482275009155273 | CLS Loss: 0.011778336018323898\n",
      "Epoch 108 / 200 | iteration 70 / 171 | Total Loss: 2.4603660106658936 | KNN Loss: 2.4441139698028564 | CLS Loss: 0.016251923516392708\n",
      "Epoch 108 / 200 | iteration 80 / 171 | Total Loss: 2.4263832569122314 | KNN Loss: 2.4185361862182617 | CLS Loss: 0.00784700084477663\n",
      "Epoch 108 / 200 | iteration 90 / 171 | Total Loss: 2.3972232341766357 | KNN Loss: 2.371103525161743 | CLS Loss: 0.02611972950398922\n",
      "Epoch 108 / 200 | iteration 100 / 171 | Total Loss: 2.400327682495117 | KNN Loss: 2.388712167739868 | CLS Loss: 0.01161557249724865\n",
      "Epoch 108 / 200 | iteration 110 / 171 | Total Loss: 2.4060168266296387 | KNN Loss: 2.401770830154419 | CLS Loss: 0.004246011842042208\n",
      "Epoch 108 / 200 | iteration 120 / 171 | Total Loss: 2.425337791442871 | KNN Loss: 2.416628122329712 | CLS Loss: 0.008709651418030262\n",
      "Epoch 108 / 200 | iteration 130 / 171 | Total Loss: 2.4172489643096924 | KNN Loss: 2.402411460876465 | CLS Loss: 0.014837618917226791\n",
      "Epoch 108 / 200 | iteration 140 / 171 | Total Loss: 2.4177122116088867 | KNN Loss: 2.4036707878112793 | CLS Loss: 0.014041418209671974\n",
      "Epoch 108 / 200 | iteration 150 / 171 | Total Loss: 2.412367105484009 | KNN Loss: 2.391941547393799 | CLS Loss: 0.020425667986273766\n",
      "Epoch 108 / 200 | iteration 160 / 171 | Total Loss: 2.424762725830078 | KNN Loss: 2.3982789516448975 | CLS Loss: 0.026483749970793724\n",
      "Epoch 108 / 200 | iteration 170 / 171 | Total Loss: 2.380342483520508 | KNN Loss: 2.3709828853607178 | CLS Loss: 0.009359481744468212\n",
      "Epoch: 108, Loss: 2.4166, Train: 0.9967, Valid: 0.9859, Best: 0.9878\n",
      "Epoch 109 / 200 | iteration 0 / 171 | Total Loss: 2.4181880950927734 | KNN Loss: 2.41135311126709 | CLS Loss: 0.006835009437054396\n",
      "Epoch 109 / 200 | iteration 10 / 171 | Total Loss: 2.3837392330169678 | KNN Loss: 2.370844841003418 | CLS Loss: 0.012894438579678535\n",
      "Epoch 109 / 200 | iteration 20 / 171 | Total Loss: 2.4370346069335938 | KNN Loss: 2.423948287963867 | CLS Loss: 0.0130862882360816\n",
      "Epoch 109 / 200 | iteration 30 / 171 | Total Loss: 2.4163260459899902 | KNN Loss: 2.411705732345581 | CLS Loss: 0.004620267543941736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 / 200 | iteration 40 / 171 | Total Loss: 2.414196491241455 | KNN Loss: 2.396958589553833 | CLS Loss: 0.01723797619342804\n",
      "Epoch 109 / 200 | iteration 50 / 171 | Total Loss: 2.3666443824768066 | KNN Loss: 2.3635504245758057 | CLS Loss: 0.0030940205324441195\n",
      "Epoch 109 / 200 | iteration 60 / 171 | Total Loss: 2.4171595573425293 | KNN Loss: 2.409950017929077 | CLS Loss: 0.007209639996290207\n",
      "Epoch 109 / 200 | iteration 70 / 171 | Total Loss: 2.4189882278442383 | KNN Loss: 2.4077250957489014 | CLS Loss: 0.011263096705079079\n",
      "Epoch 109 / 200 | iteration 80 / 171 | Total Loss: 2.394908905029297 | KNN Loss: 2.386657238006592 | CLS Loss: 0.008251691237092018\n",
      "Epoch 109 / 200 | iteration 90 / 171 | Total Loss: 2.4291090965270996 | KNN Loss: 2.406256914138794 | CLS Loss: 0.02285226620733738\n",
      "Epoch 109 / 200 | iteration 100 / 171 | Total Loss: 2.4501631259918213 | KNN Loss: 2.4087367057800293 | CLS Loss: 0.0414264015853405\n",
      "Epoch 109 / 200 | iteration 110 / 171 | Total Loss: 2.443814516067505 | KNN Loss: 2.4173583984375 | CLS Loss: 0.026456225663423538\n",
      "Epoch 109 / 200 | iteration 120 / 171 | Total Loss: 2.4471185207366943 | KNN Loss: 2.423994779586792 | CLS Loss: 0.02312364988029003\n",
      "Epoch 109 / 200 | iteration 130 / 171 | Total Loss: 2.4039645195007324 | KNN Loss: 2.392822504043579 | CLS Loss: 0.011141904629766941\n",
      "Epoch 109 / 200 | iteration 140 / 171 | Total Loss: 2.4033358097076416 | KNN Loss: 2.3783340454101562 | CLS Loss: 0.025001786649227142\n",
      "Epoch 109 / 200 | iteration 150 / 171 | Total Loss: 2.435607433319092 | KNN Loss: 2.415220260620117 | CLS Loss: 0.02038726769387722\n",
      "Epoch 109 / 200 | iteration 160 / 171 | Total Loss: 2.38822340965271 | KNN Loss: 2.3579342365264893 | CLS Loss: 0.030289262533187866\n",
      "Epoch 109 / 200 | iteration 170 / 171 | Total Loss: 2.419961929321289 | KNN Loss: 2.411654472351074 | CLS Loss: 0.00830754078924656\n",
      "Epoch: 109, Loss: 2.4146, Train: 0.9966, Valid: 0.9863, Best: 0.9878\n",
      "Epoch 110 / 200 | iteration 0 / 171 | Total Loss: 2.403041124343872 | KNN Loss: 2.392143726348877 | CLS Loss: 0.01089744083583355\n",
      "Epoch 110 / 200 | iteration 10 / 171 | Total Loss: 2.451758623123169 | KNN Loss: 2.4435818195343018 | CLS Loss: 0.008176787756383419\n",
      "Epoch 110 / 200 | iteration 20 / 171 | Total Loss: 2.4362168312072754 | KNN Loss: 2.401019334793091 | CLS Loss: 0.03519754111766815\n",
      "Epoch 110 / 200 | iteration 30 / 171 | Total Loss: 2.437190294265747 | KNN Loss: 2.4221551418304443 | CLS Loss: 0.015035182237625122\n",
      "Epoch 110 / 200 | iteration 40 / 171 | Total Loss: 2.4491052627563477 | KNN Loss: 2.4369750022888184 | CLS Loss: 0.012130266055464745\n",
      "Epoch 110 / 200 | iteration 50 / 171 | Total Loss: 2.3807647228240967 | KNN Loss: 2.3643293380737305 | CLS Loss: 0.016435395926237106\n",
      "Epoch 110 / 200 | iteration 60 / 171 | Total Loss: 2.3952109813690186 | KNN Loss: 2.3776164054870605 | CLS Loss: 0.017594492062926292\n",
      "Epoch 110 / 200 | iteration 70 / 171 | Total Loss: 2.378343343734741 | KNN Loss: 2.37318754196167 | CLS Loss: 0.005155706778168678\n",
      "Epoch 110 / 200 | iteration 80 / 171 | Total Loss: 2.4125027656555176 | KNN Loss: 2.3954288959503174 | CLS Loss: 0.01707387901842594\n",
      "Epoch 110 / 200 | iteration 90 / 171 | Total Loss: 2.4041666984558105 | KNN Loss: 2.388791799545288 | CLS Loss: 0.015374845825135708\n",
      "Epoch 110 / 200 | iteration 100 / 171 | Total Loss: 2.4315218925476074 | KNN Loss: 2.4121758937835693 | CLS Loss: 0.019346024841070175\n",
      "Epoch 110 / 200 | iteration 110 / 171 | Total Loss: 2.3801441192626953 | KNN Loss: 2.363604784011841 | CLS Loss: 0.016539279371500015\n",
      "Epoch 110 / 200 | iteration 120 / 171 | Total Loss: 2.4220898151397705 | KNN Loss: 2.3961732387542725 | CLS Loss: 0.02591664157807827\n",
      "Epoch 110 / 200 | iteration 130 / 171 | Total Loss: 2.4343388080596924 | KNN Loss: 2.410845994949341 | CLS Loss: 0.02349272556602955\n",
      "Epoch 110 / 200 | iteration 140 / 171 | Total Loss: 2.431265354156494 | KNN Loss: 2.4103212356567383 | CLS Loss: 0.020944079384207726\n",
      "Epoch 110 / 200 | iteration 150 / 171 | Total Loss: 2.4181735515594482 | KNN Loss: 2.394144058227539 | CLS Loss: 0.024029534310102463\n",
      "Epoch 110 / 200 | iteration 160 / 171 | Total Loss: 2.427844524383545 | KNN Loss: 2.4210710525512695 | CLS Loss: 0.006773568689823151\n",
      "Epoch 110 / 200 | iteration 170 / 171 | Total Loss: 2.382327079772949 | KNN Loss: 2.3716418743133545 | CLS Loss: 0.010685250163078308\n",
      "Epoch: 110, Loss: 2.4189, Train: 0.9959, Valid: 0.9850, Best: 0.9878\n",
      "Epoch 111 / 200 | iteration 0 / 171 | Total Loss: 2.46437931060791 | KNN Loss: 2.4328582286834717 | CLS Loss: 0.031521014869213104\n",
      "Epoch 111 / 200 | iteration 10 / 171 | Total Loss: 2.4528653621673584 | KNN Loss: 2.4359705448150635 | CLS Loss: 0.016894729807972908\n",
      "Epoch 111 / 200 | iteration 20 / 171 | Total Loss: 2.400508165359497 | KNN Loss: 2.3890597820281982 | CLS Loss: 0.011448291130363941\n",
      "Epoch 111 / 200 | iteration 30 / 171 | Total Loss: 2.39388370513916 | KNN Loss: 2.3811159133911133 | CLS Loss: 0.012767874635756016\n",
      "Epoch 111 / 200 | iteration 40 / 171 | Total Loss: 2.4043455123901367 | KNN Loss: 2.3864383697509766 | CLS Loss: 0.017907138913869858\n",
      "Epoch 111 / 200 | iteration 50 / 171 | Total Loss: 2.389815092086792 | KNN Loss: 2.3792104721069336 | CLS Loss: 0.01060471497476101\n",
      "Epoch 111 / 200 | iteration 60 / 171 | Total Loss: 2.4254350662231445 | KNN Loss: 2.413052558898926 | CLS Loss: 0.01238257996737957\n",
      "Epoch 111 / 200 | iteration 70 / 171 | Total Loss: 2.367964267730713 | KNN Loss: 2.355868101119995 | CLS Loss: 0.012096249498426914\n",
      "Epoch 111 / 200 | iteration 80 / 171 | Total Loss: 2.4139254093170166 | KNN Loss: 2.411614418029785 | CLS Loss: 0.0023110981564968824\n",
      "Epoch 111 / 200 | iteration 90 / 171 | Total Loss: 2.4197821617126465 | KNN Loss: 2.407140016555786 | CLS Loss: 0.01264217123389244\n",
      "Epoch 111 / 200 | iteration 100 / 171 | Total Loss: 2.435945510864258 | KNN Loss: 2.4245243072509766 | CLS Loss: 0.011421101167798042\n",
      "Epoch 111 / 200 | iteration 110 / 171 | Total Loss: 2.435093641281128 | KNN Loss: 2.4131195545196533 | CLS Loss: 0.021974094212055206\n",
      "Epoch 111 / 200 | iteration 120 / 171 | Total Loss: 2.3876876831054688 | KNN Loss: 2.3747262954711914 | CLS Loss: 0.012961502186954021\n",
      "Epoch 111 / 200 | iteration 130 / 171 | Total Loss: 2.403156280517578 | KNN Loss: 2.396218776702881 | CLS Loss: 0.0069376141764223576\n",
      "Epoch 111 / 200 | iteration 140 / 171 | Total Loss: 2.417245388031006 | KNN Loss: 2.4095089435577393 | CLS Loss: 0.007736442144960165\n",
      "Epoch 111 / 200 | iteration 150 / 171 | Total Loss: 2.404775857925415 | KNN Loss: 2.385066032409668 | CLS Loss: 0.019709715619683266\n",
      "Epoch 111 / 200 | iteration 160 / 171 | Total Loss: 2.3855555057525635 | KNN Loss: 2.35223126411438 | CLS Loss: 0.033324286341667175\n",
      "Epoch 111 / 200 | iteration 170 / 171 | Total Loss: 2.422395944595337 | KNN Loss: 2.398630142211914 | CLS Loss: 0.02376573346555233\n",
      "Epoch: 111, Loss: 2.4154, Train: 0.9963, Valid: 0.9854, Best: 0.9878\n",
      "Epoch 112 / 200 | iteration 0 / 171 | Total Loss: 2.4369685649871826 | KNN Loss: 2.426180839538574 | CLS Loss: 0.01078774407505989\n",
      "Epoch 112 / 200 | iteration 10 / 171 | Total Loss: 2.4077553749084473 | KNN Loss: 2.3900351524353027 | CLS Loss: 0.017720285803079605\n",
      "Epoch 112 / 200 | iteration 20 / 171 | Total Loss: 2.4249134063720703 | KNN Loss: 2.394186019897461 | CLS Loss: 0.030727272853255272\n",
      "Epoch 112 / 200 | iteration 30 / 171 | Total Loss: 2.449321746826172 | KNN Loss: 2.4449081420898438 | CLS Loss: 0.004413648508489132\n",
      "Epoch 112 / 200 | iteration 40 / 171 | Total Loss: 2.401902198791504 | KNN Loss: 2.388526439666748 | CLS Loss: 0.013375727459788322\n",
      "Epoch 112 / 200 | iteration 50 / 171 | Total Loss: 2.4360740184783936 | KNN Loss: 2.4107558727264404 | CLS Loss: 0.025318119674921036\n",
      "Epoch 112 / 200 | iteration 60 / 171 | Total Loss: 2.4501938819885254 | KNN Loss: 2.4387829303741455 | CLS Loss: 0.011410953477025032\n",
      "Epoch 112 / 200 | iteration 70 / 171 | Total Loss: 2.420602798461914 | KNN Loss: 2.388603687286377 | CLS Loss: 0.03199920803308487\n",
      "Epoch 112 / 200 | iteration 80 / 171 | Total Loss: 2.435683250427246 | KNN Loss: 2.407029390335083 | CLS Loss: 0.028653940185904503\n",
      "Epoch 112 / 200 | iteration 90 / 171 | Total Loss: 2.429229497909546 | KNN Loss: 2.4058897495269775 | CLS Loss: 0.02333967015147209\n",
      "Epoch 112 / 200 | iteration 100 / 171 | Total Loss: 2.4136953353881836 | KNN Loss: 2.406038522720337 | CLS Loss: 0.007656765170395374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 / 200 | iteration 110 / 171 | Total Loss: 2.4357142448425293 | KNN Loss: 2.4121744632720947 | CLS Loss: 0.02353987656533718\n",
      "Epoch 112 / 200 | iteration 120 / 171 | Total Loss: 2.403343915939331 | KNN Loss: 2.3875319957733154 | CLS Loss: 0.015811841934919357\n",
      "Epoch 112 / 200 | iteration 130 / 171 | Total Loss: 2.3748886585235596 | KNN Loss: 2.356793165206909 | CLS Loss: 0.018095415085554123\n",
      "Epoch 112 / 200 | iteration 140 / 171 | Total Loss: 2.41402530670166 | KNN Loss: 2.3978939056396484 | CLS Loss: 0.016131456941366196\n",
      "Epoch 112 / 200 | iteration 150 / 171 | Total Loss: 2.4091620445251465 | KNN Loss: 2.3824219703674316 | CLS Loss: 0.026739979162812233\n",
      "Epoch 112 / 200 | iteration 160 / 171 | Total Loss: 2.3840346336364746 | KNN Loss: 2.365967035293579 | CLS Loss: 0.01806754246354103\n",
      "Epoch 112 / 200 | iteration 170 / 171 | Total Loss: 2.439099073410034 | KNN Loss: 2.4266445636749268 | CLS Loss: 0.012454397976398468\n",
      "Epoch: 112, Loss: 2.4169, Train: 0.9960, Valid: 0.9865, Best: 0.9878\n",
      "Epoch 113 / 200 | iteration 0 / 171 | Total Loss: 2.4321811199188232 | KNN Loss: 2.4160046577453613 | CLS Loss: 0.016176432371139526\n",
      "Epoch 113 / 200 | iteration 10 / 171 | Total Loss: 2.427429676055908 | KNN Loss: 2.4179844856262207 | CLS Loss: 0.00944530963897705\n",
      "Epoch 113 / 200 | iteration 20 / 171 | Total Loss: 2.4267866611480713 | KNN Loss: 2.40409779548645 | CLS Loss: 0.02268889546394348\n",
      "Epoch 113 / 200 | iteration 30 / 171 | Total Loss: 2.4057180881500244 | KNN Loss: 2.3917081356048584 | CLS Loss: 0.014009930193424225\n",
      "Epoch 113 / 200 | iteration 40 / 171 | Total Loss: 2.4121806621551514 | KNN Loss: 2.3977859020233154 | CLS Loss: 0.014394836500287056\n",
      "Epoch 113 / 200 | iteration 50 / 171 | Total Loss: 2.424933910369873 | KNN Loss: 2.416186571121216 | CLS Loss: 0.008747297339141369\n",
      "Epoch 113 / 200 | iteration 60 / 171 | Total Loss: 2.401695489883423 | KNN Loss: 2.3666319847106934 | CLS Loss: 0.035063568502664566\n",
      "Epoch 113 / 200 | iteration 70 / 171 | Total Loss: 2.3894588947296143 | KNN Loss: 2.380894660949707 | CLS Loss: 0.008564330637454987\n",
      "Epoch 113 / 200 | iteration 80 / 171 | Total Loss: 2.4323227405548096 | KNN Loss: 2.419581413269043 | CLS Loss: 0.012741325423121452\n",
      "Epoch 113 / 200 | iteration 90 / 171 | Total Loss: 2.439598798751831 | KNN Loss: 2.431156873703003 | CLS Loss: 0.008441859856247902\n",
      "Epoch 113 / 200 | iteration 100 / 171 | Total Loss: 2.4178762435913086 | KNN Loss: 2.385399580001831 | CLS Loss: 0.03247666358947754\n",
      "Epoch 113 / 200 | iteration 110 / 171 | Total Loss: 2.4204797744750977 | KNN Loss: 2.4047491550445557 | CLS Loss: 0.01573069766163826\n",
      "Epoch 113 / 200 | iteration 120 / 171 | Total Loss: 2.4324207305908203 | KNN Loss: 2.4235928058624268 | CLS Loss: 0.00882796011865139\n",
      "Epoch 113 / 200 | iteration 130 / 171 | Total Loss: 2.4207401275634766 | KNN Loss: 2.3871614933013916 | CLS Loss: 0.033578719943761826\n",
      "Epoch 113 / 200 | iteration 140 / 171 | Total Loss: 2.433340311050415 | KNN Loss: 2.4305951595306396 | CLS Loss: 0.0027451065834611654\n",
      "Epoch 113 / 200 | iteration 150 / 171 | Total Loss: 2.403130292892456 | KNN Loss: 2.383552074432373 | CLS Loss: 0.019578179344534874\n",
      "Epoch 113 / 200 | iteration 160 / 171 | Total Loss: 2.4091219902038574 | KNN Loss: 2.3934271335601807 | CLS Loss: 0.01569487899541855\n",
      "Epoch 113 / 200 | iteration 170 / 171 | Total Loss: 2.419658660888672 | KNN Loss: 2.404528856277466 | CLS Loss: 0.015129702165722847\n",
      "Epoch: 113, Loss: 2.4155, Train: 0.9962, Valid: 0.9859, Best: 0.9878\n",
      "Epoch 114 / 200 | iteration 0 / 171 | Total Loss: 2.3906078338623047 | KNN Loss: 2.385037660598755 | CLS Loss: 0.0055701457895338535\n",
      "Epoch 114 / 200 | iteration 10 / 171 | Total Loss: 2.393476963043213 | KNN Loss: 2.3848042488098145 | CLS Loss: 0.008672699332237244\n",
      "Epoch 114 / 200 | iteration 20 / 171 | Total Loss: 2.3978967666625977 | KNN Loss: 2.395698308944702 | CLS Loss: 0.0021984537597745657\n",
      "Epoch 114 / 200 | iteration 30 / 171 | Total Loss: 2.4056708812713623 | KNN Loss: 2.3929574489593506 | CLS Loss: 0.012713518925011158\n",
      "Epoch 114 / 200 | iteration 40 / 171 | Total Loss: 2.4258689880371094 | KNN Loss: 2.4013638496398926 | CLS Loss: 0.024505246430635452\n",
      "Epoch 114 / 200 | iteration 50 / 171 | Total Loss: 2.47025203704834 | KNN Loss: 2.4392669200897217 | CLS Loss: 0.03098510578274727\n",
      "Epoch 114 / 200 | iteration 60 / 171 | Total Loss: 2.4069559574127197 | KNN Loss: 2.3865771293640137 | CLS Loss: 0.02037893980741501\n",
      "Epoch 114 / 200 | iteration 70 / 171 | Total Loss: 2.4240236282348633 | KNN Loss: 2.4112343788146973 | CLS Loss: 0.012789244763553143\n",
      "Epoch 114 / 200 | iteration 80 / 171 | Total Loss: 2.429222345352173 | KNN Loss: 2.411639451980591 | CLS Loss: 0.01758289523422718\n",
      "Epoch 114 / 200 | iteration 90 / 171 | Total Loss: 2.422071695327759 | KNN Loss: 2.4078097343444824 | CLS Loss: 0.014262060634791851\n",
      "Epoch 114 / 200 | iteration 100 / 171 | Total Loss: 2.4143192768096924 | KNN Loss: 2.4074971675872803 | CLS Loss: 0.0068221865221858025\n",
      "Epoch 114 / 200 | iteration 110 / 171 | Total Loss: 2.4510486125946045 | KNN Loss: 2.4464380741119385 | CLS Loss: 0.0046104248613119125\n",
      "Epoch 114 / 200 | iteration 120 / 171 | Total Loss: 2.405388832092285 | KNN Loss: 2.402097463607788 | CLS Loss: 0.003291270462796092\n",
      "Epoch 114 / 200 | iteration 130 / 171 | Total Loss: 2.430166006088257 | KNN Loss: 2.4138946533203125 | CLS Loss: 0.016271237283945084\n",
      "Epoch 114 / 200 | iteration 140 / 171 | Total Loss: 2.4135262966156006 | KNN Loss: 2.404639720916748 | CLS Loss: 0.008886601775884628\n",
      "Epoch 114 / 200 | iteration 150 / 171 | Total Loss: 2.4390034675598145 | KNN Loss: 2.423672914505005 | CLS Loss: 0.015330485068261623\n",
      "Epoch 114 / 200 | iteration 160 / 171 | Total Loss: 2.436741828918457 | KNN Loss: 2.407792568206787 | CLS Loss: 0.02894926257431507\n",
      "Epoch 114 / 200 | iteration 170 / 171 | Total Loss: 2.426609992980957 | KNN Loss: 2.4155960083007812 | CLS Loss: 0.011014082469046116\n",
      "Epoch: 114, Loss: 2.4189, Train: 0.9967, Valid: 0.9869, Best: 0.9878\n",
      "Epoch 115 / 200 | iteration 0 / 171 | Total Loss: 2.4141860008239746 | KNN Loss: 2.4125452041625977 | CLS Loss: 0.0016407868824899197\n",
      "Epoch 115 / 200 | iteration 10 / 171 | Total Loss: 2.454274892807007 | KNN Loss: 2.417212963104248 | CLS Loss: 0.037062011659145355\n",
      "Epoch 115 / 200 | iteration 20 / 171 | Total Loss: 2.396908760070801 | KNN Loss: 2.3819944858551025 | CLS Loss: 0.01491433847695589\n",
      "Epoch 115 / 200 | iteration 30 / 171 | Total Loss: 2.3873026371002197 | KNN Loss: 2.374025821685791 | CLS Loss: 0.013276783749461174\n",
      "Epoch 115 / 200 | iteration 40 / 171 | Total Loss: 2.437079668045044 | KNN Loss: 2.4356369972229004 | CLS Loss: 0.001442568376660347\n",
      "Epoch 115 / 200 | iteration 50 / 171 | Total Loss: 2.406627893447876 | KNN Loss: 2.395552396774292 | CLS Loss: 0.011075431481003761\n",
      "Epoch 115 / 200 | iteration 60 / 171 | Total Loss: 2.4310269355773926 | KNN Loss: 2.411105155944824 | CLS Loss: 0.019921880215406418\n",
      "Epoch 115 / 200 | iteration 70 / 171 | Total Loss: 2.41585636138916 | KNN Loss: 2.4129600524902344 | CLS Loss: 0.002896195277571678\n",
      "Epoch 115 / 200 | iteration 80 / 171 | Total Loss: 2.4022603034973145 | KNN Loss: 2.396846294403076 | CLS Loss: 0.005414018873125315\n",
      "Epoch 115 / 200 | iteration 90 / 171 | Total Loss: 2.412923812866211 | KNN Loss: 2.4089584350585938 | CLS Loss: 0.003965290728956461\n",
      "Epoch 115 / 200 | iteration 100 / 171 | Total Loss: 2.4275922775268555 | KNN Loss: 2.4131534099578857 | CLS Loss: 0.01443884801119566\n",
      "Epoch 115 / 200 | iteration 110 / 171 | Total Loss: 2.4094784259796143 | KNN Loss: 2.3912293910980225 | CLS Loss: 0.018248962238430977\n",
      "Epoch 115 / 200 | iteration 120 / 171 | Total Loss: 2.432821750640869 | KNN Loss: 2.418065309524536 | CLS Loss: 0.01475649792701006\n",
      "Epoch 115 / 200 | iteration 130 / 171 | Total Loss: 2.4221959114074707 | KNN Loss: 2.4100759029388428 | CLS Loss: 0.012120101600885391\n",
      "Epoch 115 / 200 | iteration 140 / 171 | Total Loss: 2.4423818588256836 | KNN Loss: 2.402935743331909 | CLS Loss: 0.039446018636226654\n",
      "Epoch 115 / 200 | iteration 150 / 171 | Total Loss: 2.406480550765991 | KNN Loss: 2.385023355484009 | CLS Loss: 0.021457210183143616\n",
      "Epoch 115 / 200 | iteration 160 / 171 | Total Loss: 2.374380350112915 | KNN Loss: 2.3708345890045166 | CLS Loss: 0.0035457771737128496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 / 200 | iteration 170 / 171 | Total Loss: 2.438997507095337 | KNN Loss: 2.4319984912872314 | CLS Loss: 0.006999124772846699\n",
      "Epoch: 115, Loss: 2.4173, Train: 0.9968, Valid: 0.9862, Best: 0.9878\n",
      "Epoch 116 / 200 | iteration 0 / 171 | Total Loss: 2.3950066566467285 | KNN Loss: 2.376633882522583 | CLS Loss: 0.01837271638214588\n",
      "Epoch 116 / 200 | iteration 10 / 171 | Total Loss: 2.406200408935547 | KNN Loss: 2.4019083976745605 | CLS Loss: 0.004291938152164221\n",
      "Epoch 116 / 200 | iteration 20 / 171 | Total Loss: 2.3948638439178467 | KNN Loss: 2.391629457473755 | CLS Loss: 0.003234376199543476\n",
      "Epoch 116 / 200 | iteration 30 / 171 | Total Loss: 2.4062178134918213 | KNN Loss: 2.4028382301330566 | CLS Loss: 0.003379630157724023\n",
      "Epoch 116 / 200 | iteration 40 / 171 | Total Loss: 2.3929810523986816 | KNN Loss: 2.386455535888672 | CLS Loss: 0.006525494623929262\n",
      "Epoch 116 / 200 | iteration 50 / 171 | Total Loss: 2.4133455753326416 | KNN Loss: 2.404627799987793 | CLS Loss: 0.008717675693333149\n",
      "Epoch 116 / 200 | iteration 60 / 171 | Total Loss: 2.4217615127563477 | KNN Loss: 2.390166997909546 | CLS Loss: 0.03159454092383385\n",
      "Epoch 116 / 200 | iteration 70 / 171 | Total Loss: 2.3878698348999023 | KNN Loss: 2.372772216796875 | CLS Loss: 0.015097656287252903\n",
      "Epoch 116 / 200 | iteration 80 / 171 | Total Loss: 2.463883876800537 | KNN Loss: 2.4203531742095947 | CLS Loss: 0.043530724942684174\n",
      "Epoch 116 / 200 | iteration 90 / 171 | Total Loss: 2.4298274517059326 | KNN Loss: 2.4048430919647217 | CLS Loss: 0.024984261021018028\n",
      "Epoch 116 / 200 | iteration 100 / 171 | Total Loss: 2.426206588745117 | KNN Loss: 2.400787830352783 | CLS Loss: 0.025418760254979134\n",
      "Epoch 116 / 200 | iteration 110 / 171 | Total Loss: 2.3985514640808105 | KNN Loss: 2.3935863971710205 | CLS Loss: 0.004965051077306271\n",
      "Epoch 116 / 200 | iteration 120 / 171 | Total Loss: 2.417389392852783 | KNN Loss: 2.4116573333740234 | CLS Loss: 0.005732141435146332\n",
      "Epoch 116 / 200 | iteration 130 / 171 | Total Loss: 2.4009945392608643 | KNN Loss: 2.3823440074920654 | CLS Loss: 0.01865055412054062\n",
      "Epoch 116 / 200 | iteration 140 / 171 | Total Loss: 2.411865711212158 | KNN Loss: 2.393584728240967 | CLS Loss: 0.018281064927577972\n",
      "Epoch 116 / 200 | iteration 150 / 171 | Total Loss: 2.437978982925415 | KNN Loss: 2.4340450763702393 | CLS Loss: 0.0039338041096925735\n",
      "Epoch 116 / 200 | iteration 160 / 171 | Total Loss: 2.44274640083313 | KNN Loss: 2.418361186981201 | CLS Loss: 0.024385133758187294\n",
      "Epoch 116 / 200 | iteration 170 / 171 | Total Loss: 2.4236643314361572 | KNN Loss: 2.392890453338623 | CLS Loss: 0.030773881822824478\n",
      "Epoch: 116, Loss: 2.4152, Train: 0.9943, Valid: 0.9827, Best: 0.9878\n",
      "Epoch 117 / 200 | iteration 0 / 171 | Total Loss: 2.425715684890747 | KNN Loss: 2.415224552154541 | CLS Loss: 0.010491042397916317\n",
      "Epoch 117 / 200 | iteration 10 / 171 | Total Loss: 2.4170429706573486 | KNN Loss: 2.4056131839752197 | CLS Loss: 0.011429832316935062\n",
      "Epoch 117 / 200 | iteration 20 / 171 | Total Loss: 2.4000463485717773 | KNN Loss: 2.385359287261963 | CLS Loss: 0.01468714140355587\n",
      "Epoch 117 / 200 | iteration 30 / 171 | Total Loss: 2.4072601795196533 | KNN Loss: 2.3915789127349854 | CLS Loss: 0.01568116620182991\n",
      "Epoch 117 / 200 | iteration 40 / 171 | Total Loss: 2.407583236694336 | KNN Loss: 2.4029598236083984 | CLS Loss: 0.0046233381144702435\n",
      "Epoch 117 / 200 | iteration 50 / 171 | Total Loss: 2.396811008453369 | KNN Loss: 2.3926708698272705 | CLS Loss: 0.004140225239098072\n",
      "Epoch 117 / 200 | iteration 60 / 171 | Total Loss: 2.4294376373291016 | KNN Loss: 2.428354501724243 | CLS Loss: 0.0010831835679709911\n",
      "Epoch 117 / 200 | iteration 70 / 171 | Total Loss: 2.4057815074920654 | KNN Loss: 2.378984212875366 | CLS Loss: 0.026797380298376083\n",
      "Epoch 117 / 200 | iteration 80 / 171 | Total Loss: 2.41031551361084 | KNN Loss: 2.4031972885131836 | CLS Loss: 0.007118147797882557\n",
      "Epoch 117 / 200 | iteration 90 / 171 | Total Loss: 2.39089298248291 | KNN Loss: 2.382392406463623 | CLS Loss: 0.008500480093061924\n",
      "Epoch 117 / 200 | iteration 100 / 171 | Total Loss: 2.4876155853271484 | KNN Loss: 2.4706645011901855 | CLS Loss: 0.016951078549027443\n",
      "Epoch 117 / 200 | iteration 110 / 171 | Total Loss: 2.4019553661346436 | KNN Loss: 2.3902628421783447 | CLS Loss: 0.011692502535879612\n",
      "Epoch 117 / 200 | iteration 120 / 171 | Total Loss: 2.406207323074341 | KNN Loss: 2.395871162414551 | CLS Loss: 0.010336192324757576\n",
      "Epoch 117 / 200 | iteration 130 / 171 | Total Loss: 2.3961639404296875 | KNN Loss: 2.3703064918518066 | CLS Loss: 0.02585756778717041\n",
      "Epoch 117 / 200 | iteration 140 / 171 | Total Loss: 2.4320068359375 | KNN Loss: 2.4158010482788086 | CLS Loss: 0.016205748543143272\n",
      "Epoch 117 / 200 | iteration 150 / 171 | Total Loss: 2.4368205070495605 | KNN Loss: 2.433505058288574 | CLS Loss: 0.003315393580123782\n",
      "Epoch 117 / 200 | iteration 160 / 171 | Total Loss: 2.4084346294403076 | KNN Loss: 2.3937923908233643 | CLS Loss: 0.014642174355685711\n",
      "Epoch 117 / 200 | iteration 170 / 171 | Total Loss: 2.4264373779296875 | KNN Loss: 2.4228780269622803 | CLS Loss: 0.0035593470092862844\n",
      "Epoch: 117, Loss: 2.4156, Train: 0.9973, Valid: 0.9865, Best: 0.9878\n",
      "Epoch 118 / 200 | iteration 0 / 171 | Total Loss: 2.4296648502349854 | KNN Loss: 2.4139161109924316 | CLS Loss: 0.015748808160424232\n",
      "Epoch 118 / 200 | iteration 10 / 171 | Total Loss: 2.4024715423583984 | KNN Loss: 2.3819243907928467 | CLS Loss: 0.020547032356262207\n",
      "Epoch 118 / 200 | iteration 20 / 171 | Total Loss: 2.443329334259033 | KNN Loss: 2.428628444671631 | CLS Loss: 0.014700907282531261\n",
      "Epoch 118 / 200 | iteration 30 / 171 | Total Loss: 2.3859634399414062 | KNN Loss: 2.3647353649139404 | CLS Loss: 0.021228106692433357\n",
      "Epoch 118 / 200 | iteration 40 / 171 | Total Loss: 2.4476847648620605 | KNN Loss: 2.4302310943603516 | CLS Loss: 0.017453620210289955\n",
      "Epoch 118 / 200 | iteration 50 / 171 | Total Loss: 2.377305030822754 | KNN Loss: 2.357823610305786 | CLS Loss: 0.019481519237160683\n",
      "Epoch 118 / 200 | iteration 60 / 171 | Total Loss: 2.4264214038848877 | KNN Loss: 2.407952070236206 | CLS Loss: 0.01846943609416485\n",
      "Epoch 118 / 200 | iteration 70 / 171 | Total Loss: 2.3998124599456787 | KNN Loss: 2.3911030292510986 | CLS Loss: 0.008709408342838287\n",
      "Epoch 118 / 200 | iteration 80 / 171 | Total Loss: 2.4155194759368896 | KNN Loss: 2.390342950820923 | CLS Loss: 0.02517651580274105\n",
      "Epoch 118 / 200 | iteration 90 / 171 | Total Loss: 2.38444185256958 | KNN Loss: 2.363708972930908 | CLS Loss: 0.020732777193188667\n",
      "Epoch 118 / 200 | iteration 100 / 171 | Total Loss: 2.3609986305236816 | KNN Loss: 2.3572018146514893 | CLS Loss: 0.0037967078387737274\n",
      "Epoch 118 / 200 | iteration 110 / 171 | Total Loss: 2.4517016410827637 | KNN Loss: 2.4233505725860596 | CLS Loss: 0.02835107035934925\n",
      "Epoch 118 / 200 | iteration 120 / 171 | Total Loss: 2.41627836227417 | KNN Loss: 2.413494825363159 | CLS Loss: 0.002783465664833784\n",
      "Epoch 118 / 200 | iteration 130 / 171 | Total Loss: 2.3844385147094727 | KNN Loss: 2.3798961639404297 | CLS Loss: 0.004542314913123846\n",
      "Epoch 118 / 200 | iteration 140 / 171 | Total Loss: 2.4167404174804688 | KNN Loss: 2.4135937690734863 | CLS Loss: 0.003146698232740164\n",
      "Epoch 118 / 200 | iteration 150 / 171 | Total Loss: 2.456523895263672 | KNN Loss: 2.447654962539673 | CLS Loss: 0.008868876844644547\n",
      "Epoch 118 / 200 | iteration 160 / 171 | Total Loss: 2.419957399368286 | KNN Loss: 2.406280994415283 | CLS Loss: 0.013676373288035393\n",
      "Epoch 118 / 200 | iteration 170 / 171 | Total Loss: 2.3730742931365967 | KNN Loss: 2.369170665740967 | CLS Loss: 0.003903590375557542\n",
      "Epoch: 118, Loss: 2.4133, Train: 0.9961, Valid: 0.9872, Best: 0.9878\n",
      "Epoch 119 / 200 | iteration 0 / 171 | Total Loss: 2.418238878250122 | KNN Loss: 2.3932149410247803 | CLS Loss: 0.02502387948334217\n",
      "Epoch 119 / 200 | iteration 10 / 171 | Total Loss: 2.392411470413208 | KNN Loss: 2.383108139038086 | CLS Loss: 0.009303421713411808\n",
      "Epoch 119 / 200 | iteration 20 / 171 | Total Loss: 2.4108705520629883 | KNN Loss: 2.402700185775757 | CLS Loss: 0.00817034114152193\n",
      "Epoch 119 / 200 | iteration 30 / 171 | Total Loss: 2.408705711364746 | KNN Loss: 2.4030137062072754 | CLS Loss: 0.005692009814083576\n",
      "Epoch 119 / 200 | iteration 40 / 171 | Total Loss: 2.417457342147827 | KNN Loss: 2.3918187618255615 | CLS Loss: 0.025638526305556297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 / 200 | iteration 50 / 171 | Total Loss: 2.4119420051574707 | KNN Loss: 2.399339199066162 | CLS Loss: 0.012602746486663818\n",
      "Epoch 119 / 200 | iteration 60 / 171 | Total Loss: 2.445822238922119 | KNN Loss: 2.4344425201416016 | CLS Loss: 0.011379708535969257\n",
      "Epoch 119 / 200 | iteration 70 / 171 | Total Loss: 2.4564578533172607 | KNN Loss: 2.422043800354004 | CLS Loss: 0.03441406041383743\n",
      "Epoch 119 / 200 | iteration 80 / 171 | Total Loss: 2.399264335632324 | KNN Loss: 2.3899075984954834 | CLS Loss: 0.009356831200420856\n",
      "Epoch 119 / 200 | iteration 90 / 171 | Total Loss: 2.4069035053253174 | KNN Loss: 2.396620512008667 | CLS Loss: 0.010282972827553749\n",
      "Epoch 119 / 200 | iteration 100 / 171 | Total Loss: 2.428077220916748 | KNN Loss: 2.419060707092285 | CLS Loss: 0.009016572497785091\n",
      "Epoch 119 / 200 | iteration 110 / 171 | Total Loss: 2.4236481189727783 | KNN Loss: 2.4158525466918945 | CLS Loss: 0.007795600686222315\n",
      "Epoch 119 / 200 | iteration 120 / 171 | Total Loss: 2.41658091545105 | KNN Loss: 2.412991762161255 | CLS Loss: 0.00358912767842412\n",
      "Epoch 119 / 200 | iteration 130 / 171 | Total Loss: 2.4484400749206543 | KNN Loss: 2.4406344890594482 | CLS Loss: 0.007805629633367062\n",
      "Epoch 119 / 200 | iteration 140 / 171 | Total Loss: 2.400510311126709 | KNN Loss: 2.3954379558563232 | CLS Loss: 0.005072306841611862\n",
      "Epoch 119 / 200 | iteration 150 / 171 | Total Loss: 2.4115185737609863 | KNN Loss: 2.4041526317596436 | CLS Loss: 0.00736603420227766\n",
      "Epoch 119 / 200 | iteration 160 / 171 | Total Loss: 2.4224143028259277 | KNN Loss: 2.4159464836120605 | CLS Loss: 0.006467776373028755\n",
      "Epoch 119 / 200 | iteration 170 / 171 | Total Loss: 2.4164841175079346 | KNN Loss: 2.3968002796173096 | CLS Loss: 0.019683782011270523\n",
      "Epoch: 119, Loss: 2.4149, Train: 0.9954, Valid: 0.9859, Best: 0.9878\n",
      "Epoch 120 / 200 | iteration 0 / 171 | Total Loss: 2.4127562046051025 | KNN Loss: 2.3857579231262207 | CLS Loss: 0.02699827402830124\n",
      "Epoch 120 / 200 | iteration 10 / 171 | Total Loss: 2.402087688446045 | KNN Loss: 2.398224115371704 | CLS Loss: 0.003863674122840166\n",
      "Epoch 120 / 200 | iteration 20 / 171 | Total Loss: 2.428718090057373 | KNN Loss: 2.3969128131866455 | CLS Loss: 0.03180525079369545\n",
      "Epoch 120 / 200 | iteration 30 / 171 | Total Loss: 2.4405713081359863 | KNN Loss: 2.4257571697235107 | CLS Loss: 0.014814055524766445\n",
      "Epoch 120 / 200 | iteration 40 / 171 | Total Loss: 2.3786821365356445 | KNN Loss: 2.3772664070129395 | CLS Loss: 0.0014156601391732693\n",
      "Epoch 120 / 200 | iteration 50 / 171 | Total Loss: 2.411684513092041 | KNN Loss: 2.398641586303711 | CLS Loss: 0.013042904436588287\n",
      "Epoch 120 / 200 | iteration 60 / 171 | Total Loss: 2.3685302734375 | KNN Loss: 2.3591501712799072 | CLS Loss: 0.009380215778946877\n",
      "Epoch 120 / 200 | iteration 70 / 171 | Total Loss: 2.412994384765625 | KNN Loss: 2.3879101276397705 | CLS Loss: 0.02508433535695076\n",
      "Epoch 120 / 200 | iteration 80 / 171 | Total Loss: 2.4110519886016846 | KNN Loss: 2.3954529762268066 | CLS Loss: 0.015599053353071213\n",
      "Epoch 120 / 200 | iteration 90 / 171 | Total Loss: 2.4232981204986572 | KNN Loss: 2.412173271179199 | CLS Loss: 0.011124897748231888\n",
      "Epoch 120 / 200 | iteration 100 / 171 | Total Loss: 2.406580924987793 | KNN Loss: 2.4031076431274414 | CLS Loss: 0.0034733284264802933\n",
      "Epoch 120 / 200 | iteration 110 / 171 | Total Loss: 2.3952512741088867 | KNN Loss: 2.3913254737854004 | CLS Loss: 0.0039257812313735485\n",
      "Epoch 120 / 200 | iteration 120 / 171 | Total Loss: 2.3927128314971924 | KNN Loss: 2.3753859996795654 | CLS Loss: 0.017326824367046356\n",
      "Epoch 120 / 200 | iteration 130 / 171 | Total Loss: 2.407503128051758 | KNN Loss: 2.374300718307495 | CLS Loss: 0.03320249915122986\n",
      "Epoch 120 / 200 | iteration 140 / 171 | Total Loss: 2.4046032428741455 | KNN Loss: 2.3992316722869873 | CLS Loss: 0.005371576640754938\n",
      "Epoch 120 / 200 | iteration 150 / 171 | Total Loss: 2.3819403648376465 | KNN Loss: 2.377927780151367 | CLS Loss: 0.0040126279927790165\n",
      "Epoch 120 / 200 | iteration 160 / 171 | Total Loss: 2.4489986896514893 | KNN Loss: 2.4358577728271484 | CLS Loss: 0.013140923343598843\n",
      "Epoch 120 / 200 | iteration 170 / 171 | Total Loss: 2.450800895690918 | KNN Loss: 2.4457597732543945 | CLS Loss: 0.005041069351136684\n",
      "Epoch: 120, Loss: 2.4117, Train: 0.9962, Valid: 0.9862, Best: 0.9878\n",
      "Epoch 121 / 200 | iteration 0 / 171 | Total Loss: 2.398472547531128 | KNN Loss: 2.3946127891540527 | CLS Loss: 0.003859730903059244\n",
      "Epoch 121 / 200 | iteration 10 / 171 | Total Loss: 2.4325029850006104 | KNN Loss: 2.4181020259857178 | CLS Loss: 0.014401042833924294\n",
      "Epoch 121 / 200 | iteration 20 / 171 | Total Loss: 2.4293253421783447 | KNN Loss: 2.411241054534912 | CLS Loss: 0.018084364011883736\n",
      "Epoch 121 / 200 | iteration 30 / 171 | Total Loss: 2.423243999481201 | KNN Loss: 2.4198811054229736 | CLS Loss: 0.0033629077952355146\n",
      "Epoch 121 / 200 | iteration 40 / 171 | Total Loss: 2.3773343563079834 | KNN Loss: 2.3645377159118652 | CLS Loss: 0.0127965547144413\n",
      "Epoch 121 / 200 | iteration 50 / 171 | Total Loss: 2.3836586475372314 | KNN Loss: 2.367992877960205 | CLS Loss: 0.015665752813220024\n",
      "Epoch 121 / 200 | iteration 60 / 171 | Total Loss: 2.4124915599823 | KNN Loss: 2.403109073638916 | CLS Loss: 0.009382513351738453\n",
      "Epoch 121 / 200 | iteration 70 / 171 | Total Loss: 2.3691890239715576 | KNN Loss: 2.35711932182312 | CLS Loss: 0.012069737538695335\n",
      "Epoch 121 / 200 | iteration 80 / 171 | Total Loss: 2.3866281509399414 | KNN Loss: 2.364090919494629 | CLS Loss: 0.02253727987408638\n",
      "Epoch 121 / 200 | iteration 90 / 171 | Total Loss: 2.412316083908081 | KNN Loss: 2.3943593502044678 | CLS Loss: 0.017956797033548355\n",
      "Epoch 121 / 200 | iteration 100 / 171 | Total Loss: 2.419447422027588 | KNN Loss: 2.4023280143737793 | CLS Loss: 0.017119400203227997\n",
      "Epoch 121 / 200 | iteration 110 / 171 | Total Loss: 2.396378517150879 | KNN Loss: 2.391051769256592 | CLS Loss: 0.005326839163899422\n",
      "Epoch 121 / 200 | iteration 120 / 171 | Total Loss: 2.3697474002838135 | KNN Loss: 2.3591222763061523 | CLS Loss: 0.010625009424984455\n",
      "Epoch 121 / 200 | iteration 130 / 171 | Total Loss: 2.442429304122925 | KNN Loss: 2.42734432220459 | CLS Loss: 0.015084953047335148\n",
      "Epoch 121 / 200 | iteration 140 / 171 | Total Loss: 2.4467906951904297 | KNN Loss: 2.4422338008880615 | CLS Loss: 0.004556913394480944\n",
      "Epoch 121 / 200 | iteration 150 / 171 | Total Loss: 2.4387154579162598 | KNN Loss: 2.432816743850708 | CLS Loss: 0.005898651666939259\n",
      "Epoch 121 / 200 | iteration 160 / 171 | Total Loss: 2.4099433422088623 | KNN Loss: 2.399620294570923 | CLS Loss: 0.010323163121938705\n",
      "Epoch 121 / 200 | iteration 170 / 171 | Total Loss: 2.3878824710845947 | KNN Loss: 2.3811140060424805 | CLS Loss: 0.006768400315195322\n",
      "Epoch: 121, Loss: 2.4135, Train: 0.9964, Valid: 0.9859, Best: 0.9878\n",
      "Epoch 122 / 200 | iteration 0 / 171 | Total Loss: 2.40067720413208 | KNN Loss: 2.398125648498535 | CLS Loss: 0.002551484853029251\n",
      "Epoch 122 / 200 | iteration 10 / 171 | Total Loss: 2.3787660598754883 | KNN Loss: 2.3755712509155273 | CLS Loss: 0.0031946927774697542\n",
      "Epoch 122 / 200 | iteration 20 / 171 | Total Loss: 2.412909746170044 | KNN Loss: 2.400334358215332 | CLS Loss: 0.012575416825711727\n",
      "Epoch 122 / 200 | iteration 30 / 171 | Total Loss: 2.4135634899139404 | KNN Loss: 2.405836582183838 | CLS Loss: 0.007726817391812801\n",
      "Epoch 122 / 200 | iteration 40 / 171 | Total Loss: 2.417914867401123 | KNN Loss: 2.3908779621124268 | CLS Loss: 0.02703680470585823\n",
      "Epoch 122 / 200 | iteration 50 / 171 | Total Loss: 2.438098669052124 | KNN Loss: 2.43650221824646 | CLS Loss: 0.00159639201592654\n",
      "Epoch 122 / 200 | iteration 60 / 171 | Total Loss: 2.4380481243133545 | KNN Loss: 2.42632794380188 | CLS Loss: 0.011720189824700356\n",
      "Epoch 122 / 200 | iteration 70 / 171 | Total Loss: 2.4111170768737793 | KNN Loss: 2.401756763458252 | CLS Loss: 0.009360253810882568\n",
      "Epoch 122 / 200 | iteration 80 / 171 | Total Loss: 2.4027934074401855 | KNN Loss: 2.393529176712036 | CLS Loss: 0.00926412083208561\n",
      "Epoch 122 / 200 | iteration 90 / 171 | Total Loss: 2.4602184295654297 | KNN Loss: 2.4441823959350586 | CLS Loss: 0.016035938635468483\n",
      "Epoch 122 / 200 | iteration 100 / 171 | Total Loss: 2.4027304649353027 | KNN Loss: 2.386981964111328 | CLS Loss: 0.01574854552745819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 / 200 | iteration 110 / 171 | Total Loss: 2.38179087638855 | KNN Loss: 2.376298666000366 | CLS Loss: 0.005492095369845629\n",
      "Epoch 122 / 200 | iteration 120 / 171 | Total Loss: 2.4388599395751953 | KNN Loss: 2.428873300552368 | CLS Loss: 0.00998655054718256\n",
      "Epoch 122 / 200 | iteration 130 / 171 | Total Loss: 2.4287333488464355 | KNN Loss: 2.421967029571533 | CLS Loss: 0.006766209844499826\n",
      "Epoch 122 / 200 | iteration 140 / 171 | Total Loss: 2.4204506874084473 | KNN Loss: 2.393866777420044 | CLS Loss: 0.026583993807435036\n",
      "Epoch 122 / 200 | iteration 150 / 171 | Total Loss: 2.4248270988464355 | KNN Loss: 2.4154984951019287 | CLS Loss: 0.009328568354249\n",
      "Epoch 122 / 200 | iteration 160 / 171 | Total Loss: 2.423283100128174 | KNN Loss: 2.4173009395599365 | CLS Loss: 0.005982252303510904\n",
      "Epoch 122 / 200 | iteration 170 / 171 | Total Loss: 2.3937227725982666 | KNN Loss: 2.3762879371643066 | CLS Loss: 0.017434820532798767\n",
      "Epoch: 122, Loss: 2.4127, Train: 0.9970, Valid: 0.9874, Best: 0.9878\n",
      "Epoch 123 / 200 | iteration 0 / 171 | Total Loss: 2.4337494373321533 | KNN Loss: 2.420815944671631 | CLS Loss: 0.012933416292071342\n",
      "Epoch 123 / 200 | iteration 10 / 171 | Total Loss: 2.412022352218628 | KNN Loss: 2.4017927646636963 | CLS Loss: 0.010229654610157013\n",
      "Epoch 123 / 200 | iteration 20 / 171 | Total Loss: 2.4229400157928467 | KNN Loss: 2.40566086769104 | CLS Loss: 0.01727905496954918\n",
      "Epoch 123 / 200 | iteration 30 / 171 | Total Loss: 2.4321110248565674 | KNN Loss: 2.418862819671631 | CLS Loss: 0.013248165138065815\n",
      "Epoch 123 / 200 | iteration 40 / 171 | Total Loss: 2.4039390087127686 | KNN Loss: 2.3882319927215576 | CLS Loss: 0.01570695824921131\n",
      "Epoch 123 / 200 | iteration 50 / 171 | Total Loss: 2.4453794956207275 | KNN Loss: 2.43798828125 | CLS Loss: 0.007391131948679686\n",
      "Epoch 123 / 200 | iteration 60 / 171 | Total Loss: 2.39961314201355 | KNN Loss: 2.396606922149658 | CLS Loss: 0.0030061956495046616\n",
      "Epoch 123 / 200 | iteration 70 / 171 | Total Loss: 2.425366163253784 | KNN Loss: 2.4076883792877197 | CLS Loss: 0.017677759751677513\n",
      "Epoch 123 / 200 | iteration 80 / 171 | Total Loss: 2.4135122299194336 | KNN Loss: 2.38832426071167 | CLS Loss: 0.02518790401518345\n",
      "Epoch 123 / 200 | iteration 90 / 171 | Total Loss: 2.4059417247772217 | KNN Loss: 2.3983709812164307 | CLS Loss: 0.007570771500468254\n",
      "Epoch 123 / 200 | iteration 100 / 171 | Total Loss: 2.404670238494873 | KNN Loss: 2.3981828689575195 | CLS Loss: 0.006487487815320492\n",
      "Epoch 123 / 200 | iteration 110 / 171 | Total Loss: 2.4318184852600098 | KNN Loss: 2.4205801486968994 | CLS Loss: 0.011238262057304382\n",
      "Epoch 123 / 200 | iteration 120 / 171 | Total Loss: 2.4215893745422363 | KNN Loss: 2.4015328884124756 | CLS Loss: 0.0200565904378891\n",
      "Epoch 123 / 200 | iteration 130 / 171 | Total Loss: 2.3798882961273193 | KNN Loss: 2.373257637023926 | CLS Loss: 0.006630656309425831\n",
      "Epoch 123 / 200 | iteration 140 / 171 | Total Loss: 2.408787250518799 | KNN Loss: 2.3995614051818848 | CLS Loss: 0.009225950576364994\n",
      "Epoch 123 / 200 | iteration 150 / 171 | Total Loss: 2.4032058715820312 | KNN Loss: 2.395536184310913 | CLS Loss: 0.0076697650365531445\n",
      "Epoch 123 / 200 | iteration 160 / 171 | Total Loss: 2.4095795154571533 | KNN Loss: 2.39876389503479 | CLS Loss: 0.010815603658556938\n",
      "Epoch 123 / 200 | iteration 170 / 171 | Total Loss: 2.4316909313201904 | KNN Loss: 2.4249229431152344 | CLS Loss: 0.006768097169697285\n",
      "Epoch: 123, Loss: 2.4113, Train: 0.9959, Valid: 0.9860, Best: 0.9878\n",
      "Epoch 124 / 200 | iteration 0 / 171 | Total Loss: 2.412602424621582 | KNN Loss: 2.391756057739258 | CLS Loss: 0.020846432074904442\n",
      "Epoch 124 / 200 | iteration 10 / 171 | Total Loss: 2.4721262454986572 | KNN Loss: 2.439953565597534 | CLS Loss: 0.032172586768865585\n",
      "Epoch 124 / 200 | iteration 20 / 171 | Total Loss: 2.4087555408477783 | KNN Loss: 2.398831367492676 | CLS Loss: 0.009924112819135189\n",
      "Epoch 124 / 200 | iteration 30 / 171 | Total Loss: 2.397644281387329 | KNN Loss: 2.387761354446411 | CLS Loss: 0.009882998652756214\n",
      "Epoch 124 / 200 | iteration 40 / 171 | Total Loss: 2.4521737098693848 | KNN Loss: 2.4199907779693604 | CLS Loss: 0.03218301385641098\n",
      "Epoch 124 / 200 | iteration 50 / 171 | Total Loss: 2.4204914569854736 | KNN Loss: 2.3875224590301514 | CLS Loss: 0.03296894580125809\n",
      "Epoch 124 / 200 | iteration 60 / 171 | Total Loss: 2.4016661643981934 | KNN Loss: 2.393664598464966 | CLS Loss: 0.008001618087291718\n",
      "Epoch 124 / 200 | iteration 70 / 171 | Total Loss: 2.4122750759124756 | KNN Loss: 2.3964085578918457 | CLS Loss: 0.015866538509726524\n",
      "Epoch 124 / 200 | iteration 80 / 171 | Total Loss: 2.4158706665039062 | KNN Loss: 2.3902971744537354 | CLS Loss: 0.025573382154107094\n",
      "Epoch 124 / 200 | iteration 90 / 171 | Total Loss: 2.3868966102600098 | KNN Loss: 2.380180597305298 | CLS Loss: 0.0067160893231630325\n",
      "Epoch 124 / 200 | iteration 100 / 171 | Total Loss: 2.4185571670532227 | KNN Loss: 2.4042181968688965 | CLS Loss: 0.014338932931423187\n",
      "Epoch 124 / 200 | iteration 110 / 171 | Total Loss: 2.4245738983154297 | KNN Loss: 2.4104561805725098 | CLS Loss: 0.014117631129920483\n",
      "Epoch 124 / 200 | iteration 120 / 171 | Total Loss: 2.4734675884246826 | KNN Loss: 2.4496917724609375 | CLS Loss: 0.023775702342391014\n",
      "Epoch 124 / 200 | iteration 130 / 171 | Total Loss: 2.3938941955566406 | KNN Loss: 2.3899343013763428 | CLS Loss: 0.003959895111620426\n",
      "Epoch 124 / 200 | iteration 140 / 171 | Total Loss: 2.408442974090576 | KNN Loss: 2.3809890747070312 | CLS Loss: 0.02745400369167328\n",
      "Epoch 124 / 200 | iteration 150 / 171 | Total Loss: 2.442237377166748 | KNN Loss: 2.414900779724121 | CLS Loss: 0.02733655273914337\n",
      "Epoch 124 / 200 | iteration 160 / 171 | Total Loss: 2.4439642429351807 | KNN Loss: 2.414760112762451 | CLS Loss: 0.029204050078988075\n",
      "Epoch 124 / 200 | iteration 170 / 171 | Total Loss: 2.412550210952759 | KNN Loss: 2.4032514095306396 | CLS Loss: 0.009298720397055149\n",
      "Epoch: 124, Loss: 2.4136, Train: 0.9962, Valid: 0.9868, Best: 0.9878\n",
      "Epoch 125 / 200 | iteration 0 / 171 | Total Loss: 2.3724844455718994 | KNN Loss: 2.3672611713409424 | CLS Loss: 0.005223235115408897\n",
      "Epoch 125 / 200 | iteration 10 / 171 | Total Loss: 2.3933684825897217 | KNN Loss: 2.3882808685302734 | CLS Loss: 0.005087567027658224\n",
      "Epoch 125 / 200 | iteration 20 / 171 | Total Loss: 2.424203395843506 | KNN Loss: 2.4115564823150635 | CLS Loss: 0.012646885588765144\n",
      "Epoch 125 / 200 | iteration 30 / 171 | Total Loss: 2.4102461338043213 | KNN Loss: 2.401772975921631 | CLS Loss: 0.00847325287759304\n",
      "Epoch 125 / 200 | iteration 40 / 171 | Total Loss: 2.391450881958008 | KNN Loss: 2.3692705631256104 | CLS Loss: 0.022180380299687386\n",
      "Epoch 125 / 200 | iteration 50 / 171 | Total Loss: 2.394211769104004 | KNN Loss: 2.3736400604248047 | CLS Loss: 0.02057182788848877\n",
      "Epoch 125 / 200 | iteration 60 / 171 | Total Loss: 2.4136993885040283 | KNN Loss: 2.402108907699585 | CLS Loss: 0.011590403504669666\n",
      "Epoch 125 / 200 | iteration 70 / 171 | Total Loss: 2.3785269260406494 | KNN Loss: 2.373270273208618 | CLS Loss: 0.005256604868918657\n",
      "Epoch 125 / 200 | iteration 80 / 171 | Total Loss: 2.392434597015381 | KNN Loss: 2.383530855178833 | CLS Loss: 0.008903740905225277\n",
      "Epoch 125 / 200 | iteration 90 / 171 | Total Loss: 2.4012506008148193 | KNN Loss: 2.3820297718048096 | CLS Loss: 0.019220901653170586\n",
      "Epoch 125 / 200 | iteration 100 / 171 | Total Loss: 2.422396183013916 | KNN Loss: 2.4062306880950928 | CLS Loss: 0.01616540551185608\n",
      "Epoch 125 / 200 | iteration 110 / 171 | Total Loss: 2.40516996383667 | KNN Loss: 2.4022469520568848 | CLS Loss: 0.0029229263309389353\n",
      "Epoch 125 / 200 | iteration 120 / 171 | Total Loss: 2.3834657669067383 | KNN Loss: 2.3683154582977295 | CLS Loss: 0.015150223858654499\n",
      "Epoch 125 / 200 | iteration 130 / 171 | Total Loss: 2.382120132446289 | KNN Loss: 2.3782050609588623 | CLS Loss: 0.003915064036846161\n",
      "Epoch 125 / 200 | iteration 140 / 171 | Total Loss: 2.4179229736328125 | KNN Loss: 2.411576271057129 | CLS Loss: 0.006346669048070908\n",
      "Epoch 125 / 200 | iteration 150 / 171 | Total Loss: 2.352112293243408 | KNN Loss: 2.3493528366088867 | CLS Loss: 0.0027594859711825848\n",
      "Epoch 125 / 200 | iteration 160 / 171 | Total Loss: 2.437326669692993 | KNN Loss: 2.4325222969055176 | CLS Loss: 0.00480425450950861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 / 200 | iteration 170 / 171 | Total Loss: 2.4161996841430664 | KNN Loss: 2.414077043533325 | CLS Loss: 0.002122635720297694\n",
      "Epoch: 125, Loss: 2.4119, Train: 0.9972, Valid: 0.9874, Best: 0.9878\n",
      "Epoch 126 / 200 | iteration 0 / 171 | Total Loss: 2.3918304443359375 | KNN Loss: 2.3797755241394043 | CLS Loss: 0.012054921127855778\n",
      "Epoch 126 / 200 | iteration 10 / 171 | Total Loss: 2.408883571624756 | KNN Loss: 2.3956170082092285 | CLS Loss: 0.01326647587120533\n",
      "Epoch 126 / 200 | iteration 20 / 171 | Total Loss: 2.454699754714966 | KNN Loss: 2.4398210048675537 | CLS Loss: 0.014878763817250729\n",
      "Epoch 126 / 200 | iteration 30 / 171 | Total Loss: 2.405946731567383 | KNN Loss: 2.4010908603668213 | CLS Loss: 0.0048558032140135765\n",
      "Epoch 126 / 200 | iteration 40 / 171 | Total Loss: 2.395657777786255 | KNN Loss: 2.3926138877868652 | CLS Loss: 0.0030439484398812056\n",
      "Epoch 126 / 200 | iteration 50 / 171 | Total Loss: 2.428980588912964 | KNN Loss: 2.418198585510254 | CLS Loss: 0.01078200712800026\n",
      "Epoch 126 / 200 | iteration 60 / 171 | Total Loss: 2.419938325881958 | KNN Loss: 2.4106175899505615 | CLS Loss: 0.009320753626525402\n",
      "Epoch 126 / 200 | iteration 70 / 171 | Total Loss: 2.4384984970092773 | KNN Loss: 2.4212372303009033 | CLS Loss: 0.017261380329728127\n",
      "Epoch 126 / 200 | iteration 80 / 171 | Total Loss: 2.4263856410980225 | KNN Loss: 2.3995563983917236 | CLS Loss: 0.02682933211326599\n",
      "Epoch 126 / 200 | iteration 90 / 171 | Total Loss: 2.4349241256713867 | KNN Loss: 2.4289066791534424 | CLS Loss: 0.006017481442540884\n",
      "Epoch 126 / 200 | iteration 100 / 171 | Total Loss: 2.4191720485687256 | KNN Loss: 2.4055726528167725 | CLS Loss: 0.013599470257759094\n",
      "Epoch 126 / 200 | iteration 110 / 171 | Total Loss: 2.406158208847046 | KNN Loss: 2.389247417449951 | CLS Loss: 0.01691087894141674\n",
      "Epoch 126 / 200 | iteration 120 / 171 | Total Loss: 2.4503135681152344 | KNN Loss: 2.434047222137451 | CLS Loss: 0.01626639813184738\n",
      "Epoch 126 / 200 | iteration 130 / 171 | Total Loss: 2.3895325660705566 | KNN Loss: 2.369826555252075 | CLS Loss: 0.019706128165125847\n",
      "Epoch 126 / 200 | iteration 140 / 171 | Total Loss: 2.396742582321167 | KNN Loss: 2.389357328414917 | CLS Loss: 0.0073852939531207085\n",
      "Epoch 126 / 200 | iteration 150 / 171 | Total Loss: 2.3999810218811035 | KNN Loss: 2.3785581588745117 | CLS Loss: 0.021422844380140305\n",
      "Epoch 126 / 200 | iteration 160 / 171 | Total Loss: 2.453979015350342 | KNN Loss: 2.446937322616577 | CLS Loss: 0.007041702046990395\n",
      "Epoch 126 / 200 | iteration 170 / 171 | Total Loss: 2.413547992706299 | KNN Loss: 2.3952441215515137 | CLS Loss: 0.01830378547310829\n",
      "Epoch: 126, Loss: 2.4141, Train: 0.9971, Valid: 0.9863, Best: 0.9878\n",
      "Epoch 127 / 200 | iteration 0 / 171 | Total Loss: 2.435992956161499 | KNN Loss: 2.4183547496795654 | CLS Loss: 0.017638320103287697\n",
      "Epoch 127 / 200 | iteration 10 / 171 | Total Loss: 2.4305877685546875 | KNN Loss: 2.4121930599212646 | CLS Loss: 0.018394626677036285\n",
      "Epoch 127 / 200 | iteration 20 / 171 | Total Loss: 2.426358938217163 | KNN Loss: 2.4211509227752686 | CLS Loss: 0.0052080522291362286\n",
      "Epoch 127 / 200 | iteration 30 / 171 | Total Loss: 2.406311511993408 | KNN Loss: 2.4043734073638916 | CLS Loss: 0.0019381605088710785\n",
      "Epoch 127 / 200 | iteration 40 / 171 | Total Loss: 2.3832039833068848 | KNN Loss: 2.3743772506713867 | CLS Loss: 0.008826710283756256\n",
      "Epoch 127 / 200 | iteration 50 / 171 | Total Loss: 2.4288418292999268 | KNN Loss: 2.410355567932129 | CLS Loss: 0.018486225977540016\n",
      "Epoch 127 / 200 | iteration 60 / 171 | Total Loss: 2.3979694843292236 | KNN Loss: 2.3937931060791016 | CLS Loss: 0.004176467191427946\n",
      "Epoch 127 / 200 | iteration 70 / 171 | Total Loss: 2.3742470741271973 | KNN Loss: 2.354475498199463 | CLS Loss: 0.01977163925766945\n",
      "Epoch 127 / 200 | iteration 80 / 171 | Total Loss: 2.3940017223358154 | KNN Loss: 2.3827927112579346 | CLS Loss: 0.011209097690880299\n",
      "Epoch 127 / 200 | iteration 90 / 171 | Total Loss: 2.4039018154144287 | KNN Loss: 2.389946937561035 | CLS Loss: 0.013954817317426205\n",
      "Epoch 127 / 200 | iteration 100 / 171 | Total Loss: 2.3769404888153076 | KNN Loss: 2.372318744659424 | CLS Loss: 0.0046216342598199844\n",
      "Epoch 127 / 200 | iteration 110 / 171 | Total Loss: 2.3836898803710938 | KNN Loss: 2.381150960922241 | CLS Loss: 0.002538910135626793\n",
      "Epoch 127 / 200 | iteration 120 / 171 | Total Loss: 2.4122259616851807 | KNN Loss: 2.4069137573242188 | CLS Loss: 0.005312278401106596\n",
      "Epoch 127 / 200 | iteration 130 / 171 | Total Loss: 2.4021856784820557 | KNN Loss: 2.3976118564605713 | CLS Loss: 0.004573851358145475\n",
      "Epoch 127 / 200 | iteration 140 / 171 | Total Loss: 2.428335189819336 | KNN Loss: 2.4145474433898926 | CLS Loss: 0.013787692412734032\n",
      "Epoch 127 / 200 | iteration 150 / 171 | Total Loss: 2.4332029819488525 | KNN Loss: 2.4149861335754395 | CLS Loss: 0.01821686513721943\n",
      "Epoch 127 / 200 | iteration 160 / 171 | Total Loss: 2.4299428462982178 | KNN Loss: 2.418118953704834 | CLS Loss: 0.011824003420770168\n",
      "Epoch 127 / 200 | iteration 170 / 171 | Total Loss: 2.404463291168213 | KNN Loss: 2.3996663093566895 | CLS Loss: 0.00479705398902297\n",
      "Epoch: 127, Loss: 2.4107, Train: 0.9960, Valid: 0.9849, Best: 0.9878\n",
      "Epoch 128 / 200 | iteration 0 / 171 | Total Loss: 2.417490243911743 | KNN Loss: 2.404792308807373 | CLS Loss: 0.012697835452854633\n",
      "Epoch 128 / 200 | iteration 10 / 171 | Total Loss: 2.4107651710510254 | KNN Loss: 2.395336151123047 | CLS Loss: 0.015429116785526276\n",
      "Epoch 128 / 200 | iteration 20 / 171 | Total Loss: 2.416564702987671 | KNN Loss: 2.406909942626953 | CLS Loss: 0.009654846042394638\n",
      "Epoch 128 / 200 | iteration 30 / 171 | Total Loss: 2.377171277999878 | KNN Loss: 2.373387098312378 | CLS Loss: 0.003784251632168889\n",
      "Epoch 128 / 200 | iteration 40 / 171 | Total Loss: 2.453928232192993 | KNN Loss: 2.422922372817993 | CLS Loss: 0.031005965545773506\n",
      "Epoch 128 / 200 | iteration 50 / 171 | Total Loss: 2.4005656242370605 | KNN Loss: 2.389497995376587 | CLS Loss: 0.011067633517086506\n",
      "Epoch 128 / 200 | iteration 60 / 171 | Total Loss: 2.413649797439575 | KNN Loss: 2.404762029647827 | CLS Loss: 0.008887864649295807\n",
      "Epoch 128 / 200 | iteration 70 / 171 | Total Loss: 2.3921656608581543 | KNN Loss: 2.3863296508789062 | CLS Loss: 0.005835934542119503\n",
      "Epoch 128 / 200 | iteration 80 / 171 | Total Loss: 2.414597511291504 | KNN Loss: 2.3946690559387207 | CLS Loss: 0.01992836222052574\n",
      "Epoch 128 / 200 | iteration 90 / 171 | Total Loss: 2.37628173828125 | KNN Loss: 2.3650567531585693 | CLS Loss: 0.011225050315260887\n",
      "Epoch 128 / 200 | iteration 100 / 171 | Total Loss: 2.412018299102783 | KNN Loss: 2.389309883117676 | CLS Loss: 0.022708479315042496\n",
      "Epoch 128 / 200 | iteration 110 / 171 | Total Loss: 2.3729825019836426 | KNN Loss: 2.3708133697509766 | CLS Loss: 0.0021691976580768824\n",
      "Epoch 128 / 200 | iteration 120 / 171 | Total Loss: 2.417921781539917 | KNN Loss: 2.406689405441284 | CLS Loss: 0.011232439428567886\n",
      "Epoch 128 / 200 | iteration 130 / 171 | Total Loss: 2.4038026332855225 | KNN Loss: 2.3893868923187256 | CLS Loss: 0.014415645971894264\n",
      "Epoch 128 / 200 | iteration 140 / 171 | Total Loss: 2.420344352722168 | KNN Loss: 2.4168782234191895 | CLS Loss: 0.0034661840181797743\n",
      "Epoch 128 / 200 | iteration 150 / 171 | Total Loss: 2.451115846633911 | KNN Loss: 2.435265064239502 | CLS Loss: 0.015850776806473732\n",
      "Epoch 128 / 200 | iteration 160 / 171 | Total Loss: 2.4140310287475586 | KNN Loss: 2.3907713890075684 | CLS Loss: 0.023259568959474564\n",
      "Epoch 128 / 200 | iteration 170 / 171 | Total Loss: 2.3956542015075684 | KNN Loss: 2.3804378509521484 | CLS Loss: 0.015216357074677944\n",
      "Epoch: 128, Loss: 2.4099, Train: 0.9964, Valid: 0.9866, Best: 0.9878\n",
      "Epoch 129 / 200 | iteration 0 / 171 | Total Loss: 2.402303457260132 | KNN Loss: 2.398426055908203 | CLS Loss: 0.0038774802815169096\n",
      "Epoch 129 / 200 | iteration 10 / 171 | Total Loss: 2.4118144512176514 | KNN Loss: 2.400522232055664 | CLS Loss: 0.011292196810245514\n",
      "Epoch 129 / 200 | iteration 20 / 171 | Total Loss: 2.398383855819702 | KNN Loss: 2.376589298248291 | CLS Loss: 0.021794499829411507\n",
      "Epoch 129 / 200 | iteration 30 / 171 | Total Loss: 2.3991763591766357 | KNN Loss: 2.389533519744873 | CLS Loss: 0.009642860852181911\n",
      "Epoch 129 / 200 | iteration 40 / 171 | Total Loss: 2.4084420204162598 | KNN Loss: 2.3962392807006836 | CLS Loss: 0.012202770449221134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 / 200 | iteration 50 / 171 | Total Loss: 2.4026544094085693 | KNN Loss: 2.378816604614258 | CLS Loss: 0.02383785881102085\n",
      "Epoch 129 / 200 | iteration 60 / 171 | Total Loss: 2.40240478515625 | KNN Loss: 2.398435115814209 | CLS Loss: 0.00396970147266984\n",
      "Epoch 129 / 200 | iteration 70 / 171 | Total Loss: 2.393235683441162 | KNN Loss: 2.3899266719818115 | CLS Loss: 0.0033089183270931244\n",
      "Epoch 129 / 200 | iteration 80 / 171 | Total Loss: 2.403447389602661 | KNN Loss: 2.400646686553955 | CLS Loss: 0.0028006487991660833\n",
      "Epoch 129 / 200 | iteration 90 / 171 | Total Loss: 2.392164945602417 | KNN Loss: 2.3875296115875244 | CLS Loss: 0.004635377787053585\n",
      "Epoch 129 / 200 | iteration 100 / 171 | Total Loss: 2.400472402572632 | KNN Loss: 2.3831539154052734 | CLS Loss: 0.01731852814555168\n",
      "Epoch 129 / 200 | iteration 110 / 171 | Total Loss: 2.411667585372925 | KNN Loss: 2.401001214981079 | CLS Loss: 0.01066632755100727\n",
      "Epoch 129 / 200 | iteration 120 / 171 | Total Loss: 2.4276723861694336 | KNN Loss: 2.4110522270202637 | CLS Loss: 0.016620224341750145\n",
      "Epoch 129 / 200 | iteration 130 / 171 | Total Loss: 2.463015556335449 | KNN Loss: 2.427487373352051 | CLS Loss: 0.03552829101681709\n",
      "Epoch 129 / 200 | iteration 140 / 171 | Total Loss: 2.368260383605957 | KNN Loss: 2.3498830795288086 | CLS Loss: 0.01837719790637493\n",
      "Epoch 129 / 200 | iteration 150 / 171 | Total Loss: 2.433556318283081 | KNN Loss: 2.4012622833251953 | CLS Loss: 0.03229396045207977\n",
      "Epoch 129 / 200 | iteration 160 / 171 | Total Loss: 2.3856723308563232 | KNN Loss: 2.3632261753082275 | CLS Loss: 0.0224461667239666\n",
      "Epoch 129 / 200 | iteration 170 / 171 | Total Loss: 2.433258533477783 | KNN Loss: 2.417160987854004 | CLS Loss: 0.01609763503074646\n",
      "Epoch: 129, Loss: 2.4140, Train: 0.9945, Valid: 0.9854, Best: 0.9878\n",
      "Epoch 130 / 200 | iteration 0 / 171 | Total Loss: 2.46555233001709 | KNN Loss: 2.4048705101013184 | CLS Loss: 0.060681864619255066\n",
      "Epoch 130 / 200 | iteration 10 / 171 | Total Loss: 2.404505968093872 | KNN Loss: 2.3918159008026123 | CLS Loss: 0.012690114788711071\n",
      "Epoch 130 / 200 | iteration 20 / 171 | Total Loss: 2.4016759395599365 | KNN Loss: 2.386244058609009 | CLS Loss: 0.015431806445121765\n",
      "Epoch 130 / 200 | iteration 30 / 171 | Total Loss: 2.4090802669525146 | KNN Loss: 2.3885607719421387 | CLS Loss: 0.020519452169537544\n",
      "Epoch 130 / 200 | iteration 40 / 171 | Total Loss: 2.4192633628845215 | KNN Loss: 2.4120688438415527 | CLS Loss: 0.0071945711970329285\n",
      "Epoch 130 / 200 | iteration 50 / 171 | Total Loss: 2.3738090991973877 | KNN Loss: 2.3590176105499268 | CLS Loss: 0.014791435562074184\n",
      "Epoch 130 / 200 | iteration 60 / 171 | Total Loss: 2.397797107696533 | KNN Loss: 2.37933087348938 | CLS Loss: 0.018466278910636902\n",
      "Epoch 130 / 200 | iteration 70 / 171 | Total Loss: 2.45131778717041 | KNN Loss: 2.4340593814849854 | CLS Loss: 0.017258305102586746\n",
      "Epoch 130 / 200 | iteration 80 / 171 | Total Loss: 2.4026520252227783 | KNN Loss: 2.380743980407715 | CLS Loss: 0.021907970309257507\n",
      "Epoch 130 / 200 | iteration 90 / 171 | Total Loss: 2.408687114715576 | KNN Loss: 2.3872053623199463 | CLS Loss: 0.021481869742274284\n",
      "Epoch 130 / 200 | iteration 100 / 171 | Total Loss: 2.3965296745300293 | KNN Loss: 2.370361566543579 | CLS Loss: 0.026168186217546463\n",
      "Epoch 130 / 200 | iteration 110 / 171 | Total Loss: 2.42488956451416 | KNN Loss: 2.418396234512329 | CLS Loss: 0.006493253167718649\n",
      "Epoch 130 / 200 | iteration 120 / 171 | Total Loss: 2.429910898208618 | KNN Loss: 2.399332284927368 | CLS Loss: 0.03057868219912052\n",
      "Epoch 130 / 200 | iteration 130 / 171 | Total Loss: 2.3765108585357666 | KNN Loss: 2.3698484897613525 | CLS Loss: 0.0066624595783650875\n",
      "Epoch 130 / 200 | iteration 140 / 171 | Total Loss: 2.393785238265991 | KNN Loss: 2.3792335987091064 | CLS Loss: 0.01455152127891779\n",
      "Epoch 130 / 200 | iteration 150 / 171 | Total Loss: 2.436812400817871 | KNN Loss: 2.4120538234710693 | CLS Loss: 0.024758681654930115\n",
      "Epoch 130 / 200 | iteration 160 / 171 | Total Loss: 2.4053971767425537 | KNN Loss: 2.3735852241516113 | CLS Loss: 0.031811971217393875\n",
      "Epoch 130 / 200 | iteration 170 / 171 | Total Loss: 2.4201245307922363 | KNN Loss: 2.4015891551971436 | CLS Loss: 0.018535375595092773\n",
      "Epoch: 130, Loss: 2.4127, Train: 0.9960, Valid: 0.9862, Best: 0.9878\n",
      "Epoch 131 / 200 | iteration 0 / 171 | Total Loss: 2.4219648838043213 | KNN Loss: 2.4071853160858154 | CLS Loss: 0.014779595658183098\n",
      "Epoch 131 / 200 | iteration 10 / 171 | Total Loss: 2.402963161468506 | KNN Loss: 2.39015531539917 | CLS Loss: 0.012807896360754967\n",
      "Epoch 131 / 200 | iteration 20 / 171 | Total Loss: 2.368363618850708 | KNN Loss: 2.359147787094116 | CLS Loss: 0.009215927682816982\n",
      "Epoch 131 / 200 | iteration 30 / 171 | Total Loss: 2.424562692642212 | KNN Loss: 2.4077134132385254 | CLS Loss: 0.016849175095558167\n",
      "Epoch 131 / 200 | iteration 40 / 171 | Total Loss: 2.4048633575439453 | KNN Loss: 2.389861822128296 | CLS Loss: 0.015001559630036354\n",
      "Epoch 131 / 200 | iteration 50 / 171 | Total Loss: 2.4084062576293945 | KNN Loss: 2.402324914932251 | CLS Loss: 0.006081440486013889\n",
      "Epoch 131 / 200 | iteration 60 / 171 | Total Loss: 2.4468955993652344 | KNN Loss: 2.437591075897217 | CLS Loss: 0.009304610081017017\n",
      "Epoch 131 / 200 | iteration 70 / 171 | Total Loss: 2.423084259033203 | KNN Loss: 2.4110019207000732 | CLS Loss: 0.012082329019904137\n",
      "Epoch 131 / 200 | iteration 80 / 171 | Total Loss: 2.391897439956665 | KNN Loss: 2.3705766201019287 | CLS Loss: 0.021320875734090805\n",
      "Epoch 131 / 200 | iteration 90 / 171 | Total Loss: 2.383875846862793 | KNN Loss: 2.366757869720459 | CLS Loss: 0.017117921262979507\n",
      "Epoch 131 / 200 | iteration 100 / 171 | Total Loss: 2.4226722717285156 | KNN Loss: 2.403526544570923 | CLS Loss: 0.019145742058753967\n",
      "Epoch 131 / 200 | iteration 110 / 171 | Total Loss: 2.414447069168091 | KNN Loss: 2.4056930541992188 | CLS Loss: 0.008754042908549309\n",
      "Epoch 131 / 200 | iteration 120 / 171 | Total Loss: 2.4022367000579834 | KNN Loss: 2.3977174758911133 | CLS Loss: 0.004519299603998661\n",
      "Epoch 131 / 200 | iteration 130 / 171 | Total Loss: 2.4364542961120605 | KNN Loss: 2.4335498809814453 | CLS Loss: 0.0029043012764304876\n",
      "Epoch 131 / 200 | iteration 140 / 171 | Total Loss: 2.4080069065093994 | KNN Loss: 2.3909902572631836 | CLS Loss: 0.017016585916280746\n",
      "Epoch 131 / 200 | iteration 150 / 171 | Total Loss: 2.3989405632019043 | KNN Loss: 2.3796427249908447 | CLS Loss: 0.01929778978228569\n",
      "Epoch 131 / 200 | iteration 160 / 171 | Total Loss: 2.435225009918213 | KNN Loss: 2.4045517444610596 | CLS Loss: 0.030673300847411156\n",
      "Epoch 131 / 200 | iteration 170 / 171 | Total Loss: 2.413163661956787 | KNN Loss: 2.384951114654541 | CLS Loss: 0.028212647885084152\n",
      "Epoch: 131, Loss: 2.4097, Train: 0.9967, Valid: 0.9869, Best: 0.9878\n",
      "Epoch 132 / 200 | iteration 0 / 171 | Total Loss: 2.4239301681518555 | KNN Loss: 2.403477668762207 | CLS Loss: 0.02045254595577717\n",
      "Epoch 132 / 200 | iteration 10 / 171 | Total Loss: 2.4541282653808594 | KNN Loss: 2.4490554332733154 | CLS Loss: 0.005072728265076876\n",
      "Epoch 132 / 200 | iteration 20 / 171 | Total Loss: 2.452721357345581 | KNN Loss: 2.449796438217163 | CLS Loss: 0.002925012493506074\n",
      "Epoch 132 / 200 | iteration 30 / 171 | Total Loss: 2.4068188667297363 | KNN Loss: 2.4005181789398193 | CLS Loss: 0.006300655659288168\n",
      "Epoch 132 / 200 | iteration 40 / 171 | Total Loss: 2.4283249378204346 | KNN Loss: 2.4221856594085693 | CLS Loss: 0.006139224395155907\n",
      "Epoch 132 / 200 | iteration 50 / 171 | Total Loss: 2.405611038208008 | KNN Loss: 2.398444652557373 | CLS Loss: 0.00716647133231163\n",
      "Epoch 132 / 200 | iteration 60 / 171 | Total Loss: 2.37687087059021 | KNN Loss: 2.3700411319732666 | CLS Loss: 0.0068296631798148155\n",
      "Epoch 132 / 200 | iteration 70 / 171 | Total Loss: 2.393862009048462 | KNN Loss: 2.3814857006073 | CLS Loss: 0.012376347556710243\n",
      "Epoch 132 / 200 | iteration 80 / 171 | Total Loss: 2.438558578491211 | KNN Loss: 2.428231716156006 | CLS Loss: 0.010326895862817764\n",
      "Epoch 132 / 200 | iteration 90 / 171 | Total Loss: 2.4584884643554688 | KNN Loss: 2.437570810317993 | CLS Loss: 0.020917631685733795\n",
      "Epoch 132 / 200 | iteration 100 / 171 | Total Loss: 2.392955780029297 | KNN Loss: 2.3859708309173584 | CLS Loss: 0.006985019892454147\n",
      "Epoch 132 / 200 | iteration 110 / 171 | Total Loss: 2.3969085216522217 | KNN Loss: 2.3820931911468506 | CLS Loss: 0.014815226197242737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 / 200 | iteration 120 / 171 | Total Loss: 2.390885591506958 | KNN Loss: 2.3725316524505615 | CLS Loss: 0.01835402473807335\n",
      "Epoch 132 / 200 | iteration 130 / 171 | Total Loss: 2.434852361679077 | KNN Loss: 2.430737257003784 | CLS Loss: 0.004115118645131588\n",
      "Epoch 132 / 200 | iteration 140 / 171 | Total Loss: 2.4231197834014893 | KNN Loss: 2.4098620414733887 | CLS Loss: 0.013257824815809727\n",
      "Epoch 132 / 200 | iteration 150 / 171 | Total Loss: 2.4707040786743164 | KNN Loss: 2.4606776237487793 | CLS Loss: 0.010026425123214722\n",
      "Epoch 132 / 200 | iteration 160 / 171 | Total Loss: 2.430321455001831 | KNN Loss: 2.4128646850585938 | CLS Loss: 0.01745671033859253\n",
      "Epoch 132 / 200 | iteration 170 / 171 | Total Loss: 2.4235169887542725 | KNN Loss: 2.395570993423462 | CLS Loss: 0.02794599160552025\n",
      "Epoch: 132, Loss: 2.4201, Train: 0.9955, Valid: 0.9851, Best: 0.9878\n",
      "Epoch 133 / 200 | iteration 0 / 171 | Total Loss: 2.4560294151306152 | KNN Loss: 2.437328338623047 | CLS Loss: 0.018701042979955673\n",
      "Epoch 133 / 200 | iteration 10 / 171 | Total Loss: 2.3947134017944336 | KNN Loss: 2.386059284210205 | CLS Loss: 0.008654026314616203\n",
      "Epoch 133 / 200 | iteration 20 / 171 | Total Loss: 2.447608470916748 | KNN Loss: 2.433931827545166 | CLS Loss: 0.013676667585968971\n",
      "Epoch 133 / 200 | iteration 30 / 171 | Total Loss: 2.406127452850342 | KNN Loss: 2.404651165008545 | CLS Loss: 0.001476385979913175\n",
      "Epoch 133 / 200 | iteration 40 / 171 | Total Loss: 2.445141077041626 | KNN Loss: 2.4306845664978027 | CLS Loss: 0.01445644162595272\n",
      "Epoch 133 / 200 | iteration 50 / 171 | Total Loss: 2.4090373516082764 | KNN Loss: 2.395646333694458 | CLS Loss: 0.013390995562076569\n",
      "Epoch 133 / 200 | iteration 60 / 171 | Total Loss: 2.4218766689300537 | KNN Loss: 2.414771795272827 | CLS Loss: 0.007104928605258465\n",
      "Epoch 133 / 200 | iteration 70 / 171 | Total Loss: 2.4668102264404297 | KNN Loss: 2.444934844970703 | CLS Loss: 0.021875284612178802\n",
      "Epoch 133 / 200 | iteration 80 / 171 | Total Loss: 2.429605484008789 | KNN Loss: 2.4044172763824463 | CLS Loss: 0.025188269093632698\n",
      "Epoch 133 / 200 | iteration 90 / 171 | Total Loss: 2.3612775802612305 | KNN Loss: 2.3500678539276123 | CLS Loss: 0.011209649965167046\n",
      "Epoch 133 / 200 | iteration 100 / 171 | Total Loss: 2.4411654472351074 | KNN Loss: 2.421149969100952 | CLS Loss: 0.020015504211187363\n",
      "Epoch 133 / 200 | iteration 110 / 171 | Total Loss: 2.3676583766937256 | KNN Loss: 2.3613336086273193 | CLS Loss: 0.0063248323276638985\n",
      "Epoch 133 / 200 | iteration 120 / 171 | Total Loss: 2.412369728088379 | KNN Loss: 2.3953733444213867 | CLS Loss: 0.016996322199702263\n",
      "Epoch 133 / 200 | iteration 130 / 171 | Total Loss: 2.3510570526123047 | KNN Loss: 2.3472788333892822 | CLS Loss: 0.0037782806903123856\n",
      "Epoch 133 / 200 | iteration 140 / 171 | Total Loss: 2.449185848236084 | KNN Loss: 2.4164295196533203 | CLS Loss: 0.03275622799992561\n",
      "Epoch 133 / 200 | iteration 150 / 171 | Total Loss: 2.4730052947998047 | KNN Loss: 2.4612877368927 | CLS Loss: 0.011717522516846657\n",
      "Epoch 133 / 200 | iteration 160 / 171 | Total Loss: 2.434887409210205 | KNN Loss: 2.417980670928955 | CLS Loss: 0.016906701028347015\n",
      "Epoch 133 / 200 | iteration 170 / 171 | Total Loss: 2.4235780239105225 | KNN Loss: 2.4091684818267822 | CLS Loss: 0.014409568160772324\n",
      "Epoch: 133, Loss: 2.4151, Train: 0.9958, Valid: 0.9847, Best: 0.9878\n",
      "Epoch 134 / 200 | iteration 0 / 171 | Total Loss: 2.397282361984253 | KNN Loss: 2.3871026039123535 | CLS Loss: 0.010179863311350346\n",
      "Epoch 134 / 200 | iteration 10 / 171 | Total Loss: 2.380894184112549 | KNN Loss: 2.349260091781616 | CLS Loss: 0.03163415566086769\n",
      "Epoch 134 / 200 | iteration 20 / 171 | Total Loss: 2.3871586322784424 | KNN Loss: 2.376655101776123 | CLS Loss: 0.010503591038286686\n",
      "Epoch 134 / 200 | iteration 30 / 171 | Total Loss: 2.3937275409698486 | KNN Loss: 2.386733055114746 | CLS Loss: 0.00699445279315114\n",
      "Epoch 134 / 200 | iteration 40 / 171 | Total Loss: 2.385955572128296 | KNN Loss: 2.3690953254699707 | CLS Loss: 0.016860226169228554\n",
      "Epoch 134 / 200 | iteration 50 / 171 | Total Loss: 2.4710185527801514 | KNN Loss: 2.4507265090942383 | CLS Loss: 0.02029198780655861\n",
      "Epoch 134 / 200 | iteration 60 / 171 | Total Loss: 2.4566855430603027 | KNN Loss: 2.405620813369751 | CLS Loss: 0.05106478929519653\n",
      "Epoch 134 / 200 | iteration 70 / 171 | Total Loss: 2.391252040863037 | KNN Loss: 2.36824107170105 | CLS Loss: 0.023011023178696632\n",
      "Epoch 134 / 200 | iteration 80 / 171 | Total Loss: 2.383873462677002 | KNN Loss: 2.375692367553711 | CLS Loss: 0.008181159384548664\n",
      "Epoch 134 / 200 | iteration 90 / 171 | Total Loss: 2.4146130084991455 | KNN Loss: 2.398134708404541 | CLS Loss: 0.016478337347507477\n",
      "Epoch 134 / 200 | iteration 100 / 171 | Total Loss: 2.390040874481201 | KNN Loss: 2.3822741508483887 | CLS Loss: 0.00776682049036026\n",
      "Epoch 134 / 200 | iteration 110 / 171 | Total Loss: 2.3724255561828613 | KNN Loss: 2.3624978065490723 | CLS Loss: 0.009927830658853054\n",
      "Epoch 134 / 200 | iteration 120 / 171 | Total Loss: 2.413508653640747 | KNN Loss: 2.3950388431549072 | CLS Loss: 0.018469717353582382\n",
      "Epoch 134 / 200 | iteration 130 / 171 | Total Loss: 2.428504705429077 | KNN Loss: 2.416018486022949 | CLS Loss: 0.0124861104413867\n",
      "Epoch 134 / 200 | iteration 140 / 171 | Total Loss: 2.3994181156158447 | KNN Loss: 2.389167547225952 | CLS Loss: 0.010250573046505451\n",
      "Epoch 134 / 200 | iteration 150 / 171 | Total Loss: 2.4206981658935547 | KNN Loss: 2.4066715240478516 | CLS Loss: 0.01402655802667141\n",
      "Epoch 134 / 200 | iteration 160 / 171 | Total Loss: 2.3724820613861084 | KNN Loss: 2.3638174533843994 | CLS Loss: 0.008664587512612343\n",
      "Epoch 134 / 200 | iteration 170 / 171 | Total Loss: 2.3897929191589355 | KNN Loss: 2.381842613220215 | CLS Loss: 0.007950413972139359\n",
      "Epoch: 134, Loss: 2.4099, Train: 0.9965, Valid: 0.9868, Best: 0.9878\n",
      "Epoch 135 / 200 | iteration 0 / 171 | Total Loss: 2.4027113914489746 | KNN Loss: 2.382459878921509 | CLS Loss: 0.020251531153917313\n",
      "Epoch 135 / 200 | iteration 10 / 171 | Total Loss: 2.4440970420837402 | KNN Loss: 2.435708522796631 | CLS Loss: 0.008388533256947994\n",
      "Epoch 135 / 200 | iteration 20 / 171 | Total Loss: 2.3996994495391846 | KNN Loss: 2.3948886394500732 | CLS Loss: 0.004810727667063475\n",
      "Epoch 135 / 200 | iteration 30 / 171 | Total Loss: 2.428478479385376 | KNN Loss: 2.421921730041504 | CLS Loss: 0.006556778680533171\n",
      "Epoch 135 / 200 | iteration 40 / 171 | Total Loss: 2.4058663845062256 | KNN Loss: 2.37650728225708 | CLS Loss: 0.0293591246008873\n",
      "Epoch 135 / 200 | iteration 50 / 171 | Total Loss: 2.3884236812591553 | KNN Loss: 2.3788487911224365 | CLS Loss: 0.009574852883815765\n",
      "Epoch 135 / 200 | iteration 60 / 171 | Total Loss: 2.379817247390747 | KNN Loss: 2.3584158420562744 | CLS Loss: 0.021401340141892433\n",
      "Epoch 135 / 200 | iteration 70 / 171 | Total Loss: 2.4046926498413086 | KNN Loss: 2.397608757019043 | CLS Loss: 0.007083858363330364\n",
      "Epoch 135 / 200 | iteration 80 / 171 | Total Loss: 2.38971209526062 | KNN Loss: 2.383803129196167 | CLS Loss: 0.005908872466534376\n",
      "Epoch 135 / 200 | iteration 90 / 171 | Total Loss: 2.431122303009033 | KNN Loss: 2.4276833534240723 | CLS Loss: 0.0034390310756862164\n",
      "Epoch 135 / 200 | iteration 100 / 171 | Total Loss: 2.4237842559814453 | KNN Loss: 2.3976006507873535 | CLS Loss: 0.026183487847447395\n",
      "Epoch 135 / 200 | iteration 110 / 171 | Total Loss: 2.415996789932251 | KNN Loss: 2.3878748416900635 | CLS Loss: 0.02812187932431698\n",
      "Epoch 135 / 200 | iteration 120 / 171 | Total Loss: 2.43741774559021 | KNN Loss: 2.4114484786987305 | CLS Loss: 0.025969207286834717\n",
      "Epoch 135 / 200 | iteration 130 / 171 | Total Loss: 2.475651264190674 | KNN Loss: 2.4425833225250244 | CLS Loss: 0.03306792303919792\n",
      "Epoch 135 / 200 | iteration 140 / 171 | Total Loss: 2.4103920459747314 | KNN Loss: 2.405409812927246 | CLS Loss: 0.004982274491339922\n",
      "Epoch 135 / 200 | iteration 150 / 171 | Total Loss: 2.504549980163574 | KNN Loss: 2.47263240814209 | CLS Loss: 0.03191746398806572\n",
      "Epoch 135 / 200 | iteration 160 / 171 | Total Loss: 2.4520483016967773 | KNN Loss: 2.4442508220672607 | CLS Loss: 0.0077974689193069935\n",
      "Epoch 135 / 200 | iteration 170 / 171 | Total Loss: 2.408205986022949 | KNN Loss: 2.404006004333496 | CLS Loss: 0.004199933260679245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135, Loss: 2.4134, Train: 0.9968, Valid: 0.9870, Best: 0.9878\n",
      "Epoch 136 / 200 | iteration 0 / 171 | Total Loss: 2.4188365936279297 | KNN Loss: 2.412299871444702 | CLS Loss: 0.006536669097840786\n",
      "Epoch 136 / 200 | iteration 10 / 171 | Total Loss: 2.473193407058716 | KNN Loss: 2.445981025695801 | CLS Loss: 0.027212362736463547\n",
      "Epoch 136 / 200 | iteration 20 / 171 | Total Loss: 2.404040813446045 | KNN Loss: 2.3996236324310303 | CLS Loss: 0.004417239222675562\n",
      "Epoch 136 / 200 | iteration 30 / 171 | Total Loss: 2.3975908756256104 | KNN Loss: 2.381883382797241 | CLS Loss: 0.015707453712821007\n",
      "Epoch 136 / 200 | iteration 40 / 171 | Total Loss: 2.4638140201568604 | KNN Loss: 2.456021547317505 | CLS Loss: 0.0077923936769366264\n",
      "Epoch 136 / 200 | iteration 50 / 171 | Total Loss: 2.3968091011047363 | KNN Loss: 2.3684298992156982 | CLS Loss: 0.02837924100458622\n",
      "Epoch 136 / 200 | iteration 60 / 171 | Total Loss: 2.415238618850708 | KNN Loss: 2.3944485187530518 | CLS Loss: 0.020790155977010727\n",
      "Epoch 136 / 200 | iteration 70 / 171 | Total Loss: 2.38381028175354 | KNN Loss: 2.3693432807922363 | CLS Loss: 0.014467058703303337\n",
      "Epoch 136 / 200 | iteration 80 / 171 | Total Loss: 2.390437364578247 | KNN Loss: 2.384180784225464 | CLS Loss: 0.006256470922380686\n",
      "Epoch 136 / 200 | iteration 90 / 171 | Total Loss: 2.399106502532959 | KNN Loss: 2.3868072032928467 | CLS Loss: 0.012299375608563423\n",
      "Epoch 136 / 200 | iteration 100 / 171 | Total Loss: 2.4417672157287598 | KNN Loss: 2.439277172088623 | CLS Loss: 0.002490123501047492\n",
      "Epoch 136 / 200 | iteration 110 / 171 | Total Loss: 2.3892300128936768 | KNN Loss: 2.3727457523345947 | CLS Loss: 0.016484249383211136\n",
      "Epoch 136 / 200 | iteration 120 / 171 | Total Loss: 2.391977071762085 | KNN Loss: 2.388152599334717 | CLS Loss: 0.003824501531198621\n",
      "Epoch 136 / 200 | iteration 130 / 171 | Total Loss: 2.4203169345855713 | KNN Loss: 2.395108938217163 | CLS Loss: 0.025208065286278725\n",
      "Epoch 136 / 200 | iteration 140 / 171 | Total Loss: 2.401437997817993 | KNN Loss: 2.391383647918701 | CLS Loss: 0.010054455138742924\n",
      "Epoch 136 / 200 | iteration 150 / 171 | Total Loss: 2.4333853721618652 | KNN Loss: 2.4168994426727295 | CLS Loss: 0.016485899686813354\n",
      "Epoch 136 / 200 | iteration 160 / 171 | Total Loss: 2.4073374271392822 | KNN Loss: 2.3919687271118164 | CLS Loss: 0.015368812717497349\n",
      "Epoch 136 / 200 | iteration 170 / 171 | Total Loss: 2.434318780899048 | KNN Loss: 2.4146595001220703 | CLS Loss: 0.01965932548046112\n",
      "Epoch: 136, Loss: 2.4191, Train: 0.9965, Valid: 0.9862, Best: 0.9878\n",
      "Epoch 137 / 200 | iteration 0 / 171 | Total Loss: 2.4063732624053955 | KNN Loss: 2.398852825164795 | CLS Loss: 0.0075204321183264256\n",
      "Epoch 137 / 200 | iteration 10 / 171 | Total Loss: 2.413339376449585 | KNN Loss: 2.3986499309539795 | CLS Loss: 0.014689491130411625\n",
      "Epoch 137 / 200 | iteration 20 / 171 | Total Loss: 2.399806499481201 | KNN Loss: 2.3985438346862793 | CLS Loss: 0.0012627335963770747\n",
      "Epoch 137 / 200 | iteration 30 / 171 | Total Loss: 2.3896496295928955 | KNN Loss: 2.383517265319824 | CLS Loss: 0.006132281385362148\n",
      "Epoch 137 / 200 | iteration 40 / 171 | Total Loss: 2.42769455909729 | KNN Loss: 2.410738706588745 | CLS Loss: 0.016955967992544174\n",
      "Epoch 137 / 200 | iteration 50 / 171 | Total Loss: 2.440661907196045 | KNN Loss: 2.4281837940216064 | CLS Loss: 0.012478016316890717\n",
      "Epoch 137 / 200 | iteration 60 / 171 | Total Loss: 2.4132721424102783 | KNN Loss: 2.4089038372039795 | CLS Loss: 0.004368242342025042\n",
      "Epoch 137 / 200 | iteration 70 / 171 | Total Loss: 2.4458420276641846 | KNN Loss: 2.4396910667419434 | CLS Loss: 0.0061509632505476475\n",
      "Epoch 137 / 200 | iteration 80 / 171 | Total Loss: 2.408134937286377 | KNN Loss: 2.3911290168762207 | CLS Loss: 0.017005952075123787\n",
      "Epoch 137 / 200 | iteration 90 / 171 | Total Loss: 2.4162230491638184 | KNN Loss: 2.411952018737793 | CLS Loss: 0.004271034151315689\n",
      "Epoch 137 / 200 | iteration 100 / 171 | Total Loss: 2.3832523822784424 | KNN Loss: 2.380133628845215 | CLS Loss: 0.0031188721768558025\n",
      "Epoch 137 / 200 | iteration 110 / 171 | Total Loss: 2.412360668182373 | KNN Loss: 2.4004180431365967 | CLS Loss: 0.011942586861550808\n",
      "Epoch 137 / 200 | iteration 120 / 171 | Total Loss: 2.3961362838745117 | KNN Loss: 2.3732635974884033 | CLS Loss: 0.02287258207798004\n",
      "Epoch 137 / 200 | iteration 130 / 171 | Total Loss: 2.403535842895508 | KNN Loss: 2.4009292125701904 | CLS Loss: 0.0026067092549055815\n",
      "Epoch 137 / 200 | iteration 140 / 171 | Total Loss: 2.411205768585205 | KNN Loss: 2.408653497695923 | CLS Loss: 0.0025522224605083466\n",
      "Epoch 137 / 200 | iteration 150 / 171 | Total Loss: 2.3983187675476074 | KNN Loss: 2.3900136947631836 | CLS Loss: 0.008305143564939499\n",
      "Epoch 137 / 200 | iteration 160 / 171 | Total Loss: 2.4731385707855225 | KNN Loss: 2.4569807052612305 | CLS Loss: 0.01615794003009796\n",
      "Epoch 137 / 200 | iteration 170 / 171 | Total Loss: 2.4032671451568604 | KNN Loss: 2.3900537490844727 | CLS Loss: 0.013213420286774635\n",
      "Epoch: 137, Loss: 2.4143, Train: 0.9961, Valid: 0.9861, Best: 0.9878\n",
      "Epoch 138 / 200 | iteration 0 / 171 | Total Loss: 2.4481701850891113 | KNN Loss: 2.4409544467926025 | CLS Loss: 0.0072157434187829494\n",
      "Epoch 138 / 200 | iteration 10 / 171 | Total Loss: 2.398437976837158 | KNN Loss: 2.3842689990997314 | CLS Loss: 0.01416899636387825\n",
      "Epoch 138 / 200 | iteration 20 / 171 | Total Loss: 2.4273273944854736 | KNN Loss: 2.413792133331299 | CLS Loss: 0.013535370118916035\n",
      "Epoch 138 / 200 | iteration 30 / 171 | Total Loss: 2.4178669452667236 | KNN Loss: 2.402431011199951 | CLS Loss: 0.015436007641255856\n",
      "Epoch 138 / 200 | iteration 40 / 171 | Total Loss: 2.3486874103546143 | KNN Loss: 2.345747232437134 | CLS Loss: 0.002940151374787092\n",
      "Epoch 138 / 200 | iteration 50 / 171 | Total Loss: 2.411355495452881 | KNN Loss: 2.4091804027557373 | CLS Loss: 0.0021751495078206062\n",
      "Epoch 138 / 200 | iteration 60 / 171 | Total Loss: 2.404602527618408 | KNN Loss: 2.380106210708618 | CLS Loss: 0.0244962889701128\n",
      "Epoch 138 / 200 | iteration 70 / 171 | Total Loss: 2.3623664379119873 | KNN Loss: 2.3593990802764893 | CLS Loss: 0.0029673336539417505\n",
      "Epoch 138 / 200 | iteration 80 / 171 | Total Loss: 2.394204616546631 | KNN Loss: 2.388068437576294 | CLS Loss: 0.006136083044111729\n",
      "Epoch 138 / 200 | iteration 90 / 171 | Total Loss: 2.444042682647705 | KNN Loss: 2.4139020442962646 | CLS Loss: 0.0301405880600214\n",
      "Epoch 138 / 200 | iteration 100 / 171 | Total Loss: 2.402869701385498 | KNN Loss: 2.3886358737945557 | CLS Loss: 0.014233754947781563\n",
      "Epoch 138 / 200 | iteration 110 / 171 | Total Loss: 2.3870034217834473 | KNN Loss: 2.3841922283172607 | CLS Loss: 0.0028111643623560667\n",
      "Epoch 138 / 200 | iteration 120 / 171 | Total Loss: 2.41161847114563 | KNN Loss: 2.403055429458618 | CLS Loss: 0.008563004434108734\n",
      "Epoch 138 / 200 | iteration 130 / 171 | Total Loss: 2.4321460723876953 | KNN Loss: 2.426363706588745 | CLS Loss: 0.005782251711934805\n",
      "Epoch 138 / 200 | iteration 140 / 171 | Total Loss: 2.3995025157928467 | KNN Loss: 2.3940682411193848 | CLS Loss: 0.005434361752122641\n",
      "Epoch 138 / 200 | iteration 150 / 171 | Total Loss: 2.3985133171081543 | KNN Loss: 2.3817131519317627 | CLS Loss: 0.016800111159682274\n",
      "Epoch 138 / 200 | iteration 160 / 171 | Total Loss: 2.389028549194336 | KNN Loss: 2.3818068504333496 | CLS Loss: 0.0072217364795506\n",
      "Epoch 138 / 200 | iteration 170 / 171 | Total Loss: 2.4265127182006836 | KNN Loss: 2.405776262283325 | CLS Loss: 0.02073642984032631\n",
      "Epoch: 138, Loss: 2.4133, Train: 0.9951, Valid: 0.9860, Best: 0.9878\n",
      "Epoch 139 / 200 | iteration 0 / 171 | Total Loss: 2.393305540084839 | KNN Loss: 2.3859755992889404 | CLS Loss: 0.007329858839511871\n",
      "Epoch 139 / 200 | iteration 10 / 171 | Total Loss: 2.4248621463775635 | KNN Loss: 2.398059844970703 | CLS Loss: 0.02680233307182789\n",
      "Epoch 139 / 200 | iteration 20 / 171 | Total Loss: 2.44193434715271 | KNN Loss: 2.4356658458709717 | CLS Loss: 0.0062684565782547\n",
      "Epoch 139 / 200 | iteration 30 / 171 | Total Loss: 2.3926610946655273 | KNN Loss: 2.382943868637085 | CLS Loss: 0.00971715897321701\n",
      "Epoch 139 / 200 | iteration 40 / 171 | Total Loss: 2.4049265384674072 | KNN Loss: 2.3976151943206787 | CLS Loss: 0.007311259396374226\n",
      "Epoch 139 / 200 | iteration 50 / 171 | Total Loss: 2.4077634811401367 | KNN Loss: 2.3881218433380127 | CLS Loss: 0.019641641527414322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 / 200 | iteration 60 / 171 | Total Loss: 2.4090769290924072 | KNN Loss: 2.384261131286621 | CLS Loss: 0.02481582760810852\n",
      "Epoch 139 / 200 | iteration 70 / 171 | Total Loss: 2.4444634914398193 | KNN Loss: 2.430837869644165 | CLS Loss: 0.013625568710267544\n",
      "Epoch 139 / 200 | iteration 80 / 171 | Total Loss: 2.4055309295654297 | KNN Loss: 2.3918895721435547 | CLS Loss: 0.01364132296293974\n",
      "Epoch 139 / 200 | iteration 90 / 171 | Total Loss: 2.460820436477661 | KNN Loss: 2.4348654747009277 | CLS Loss: 0.025955067947506905\n",
      "Epoch 139 / 200 | iteration 100 / 171 | Total Loss: 2.405714511871338 | KNN Loss: 2.402527332305908 | CLS Loss: 0.003187081078067422\n",
      "Epoch 139 / 200 | iteration 110 / 171 | Total Loss: 2.469928741455078 | KNN Loss: 2.4643123149871826 | CLS Loss: 0.00561648840084672\n",
      "Epoch 139 / 200 | iteration 120 / 171 | Total Loss: 2.440058946609497 | KNN Loss: 2.41267728805542 | CLS Loss: 0.027381733059883118\n",
      "Epoch 139 / 200 | iteration 130 / 171 | Total Loss: 2.4092459678649902 | KNN Loss: 2.3801205158233643 | CLS Loss: 0.029125571250915527\n",
      "Epoch 139 / 200 | iteration 140 / 171 | Total Loss: 2.4172425270080566 | KNN Loss: 2.4072086811065674 | CLS Loss: 0.01003394927829504\n",
      "Epoch 139 / 200 | iteration 150 / 171 | Total Loss: 2.4298973083496094 | KNN Loss: 2.3963046073913574 | CLS Loss: 0.033592820167541504\n",
      "Epoch 139 / 200 | iteration 160 / 171 | Total Loss: 2.4164485931396484 | KNN Loss: 2.4013638496398926 | CLS Loss: 0.01508485060185194\n",
      "Epoch 139 / 200 | iteration 170 / 171 | Total Loss: 2.4337399005889893 | KNN Loss: 2.4106366634368896 | CLS Loss: 0.023103291168808937\n",
      "Epoch: 139, Loss: 2.4167, Train: 0.9964, Valid: 0.9847, Best: 0.9878\n",
      "Epoch 140 / 200 | iteration 0 / 171 | Total Loss: 2.397787570953369 | KNN Loss: 2.3855223655700684 | CLS Loss: 0.012265126220881939\n",
      "Epoch 140 / 200 | iteration 10 / 171 | Total Loss: 2.4493043422698975 | KNN Loss: 2.438192367553711 | CLS Loss: 0.011112039908766747\n",
      "Epoch 140 / 200 | iteration 20 / 171 | Total Loss: 2.4192793369293213 | KNN Loss: 2.417267322540283 | CLS Loss: 0.0020121147390455008\n",
      "Epoch 140 / 200 | iteration 30 / 171 | Total Loss: 2.389507532119751 | KNN Loss: 2.3645801544189453 | CLS Loss: 0.024927424266934395\n",
      "Epoch 140 / 200 | iteration 40 / 171 | Total Loss: 2.3795788288116455 | KNN Loss: 2.372225046157837 | CLS Loss: 0.007353703025728464\n",
      "Epoch 140 / 200 | iteration 50 / 171 | Total Loss: 2.4095616340637207 | KNN Loss: 2.3985743522644043 | CLS Loss: 0.01098736934363842\n",
      "Epoch 140 / 200 | iteration 60 / 171 | Total Loss: 2.427095890045166 | KNN Loss: 2.397002696990967 | CLS Loss: 0.030093220993876457\n",
      "Epoch 140 / 200 | iteration 70 / 171 | Total Loss: 2.425668478012085 | KNN Loss: 2.421633720397949 | CLS Loss: 0.004034753888845444\n",
      "Epoch 140 / 200 | iteration 80 / 171 | Total Loss: 2.405406951904297 | KNN Loss: 2.3871335983276367 | CLS Loss: 0.018273428082466125\n",
      "Epoch 140 / 200 | iteration 90 / 171 | Total Loss: 2.387890577316284 | KNN Loss: 2.3785979747772217 | CLS Loss: 0.009292565286159515\n",
      "Epoch 140 / 200 | iteration 100 / 171 | Total Loss: 2.4135937690734863 | KNN Loss: 2.394987106323242 | CLS Loss: 0.018606670200824738\n",
      "Epoch 140 / 200 | iteration 110 / 171 | Total Loss: 2.4010586738586426 | KNN Loss: 2.3922736644744873 | CLS Loss: 0.008784949779510498\n",
      "Epoch 140 / 200 | iteration 120 / 171 | Total Loss: 2.409186840057373 | KNN Loss: 2.400123119354248 | CLS Loss: 0.009063811972737312\n",
      "Epoch 140 / 200 | iteration 130 / 171 | Total Loss: 2.4152450561523438 | KNN Loss: 2.412241220474243 | CLS Loss: 0.003003926482051611\n",
      "Epoch 140 / 200 | iteration 140 / 171 | Total Loss: 2.408632516860962 | KNN Loss: 2.3983206748962402 | CLS Loss: 0.010311762802302837\n",
      "Epoch 140 / 200 | iteration 150 / 171 | Total Loss: 2.4480490684509277 | KNN Loss: 2.436213254928589 | CLS Loss: 0.011835751123726368\n",
      "Epoch 140 / 200 | iteration 160 / 171 | Total Loss: 2.413062810897827 | KNN Loss: 2.4062588214874268 | CLS Loss: 0.0068040830083191395\n",
      "Epoch 140 / 200 | iteration 170 / 171 | Total Loss: 2.427642583847046 | KNN Loss: 2.4142210483551025 | CLS Loss: 0.013421510346233845\n",
      "Epoch: 140, Loss: 2.4091, Train: 0.9966, Valid: 0.9867, Best: 0.9878\n",
      "Epoch 141 / 200 | iteration 0 / 171 | Total Loss: 2.390329360961914 | KNN Loss: 2.368166923522949 | CLS Loss: 0.022162459790706635\n",
      "Epoch 141 / 200 | iteration 10 / 171 | Total Loss: 2.3913562297821045 | KNN Loss: 2.388237714767456 | CLS Loss: 0.0031184412073343992\n",
      "Epoch 141 / 200 | iteration 20 / 171 | Total Loss: 2.4002511501312256 | KNN Loss: 2.3960824012756348 | CLS Loss: 0.004168677143752575\n",
      "Epoch 141 / 200 | iteration 30 / 171 | Total Loss: 2.4179515838623047 | KNN Loss: 2.4122674465179443 | CLS Loss: 0.005684180650860071\n",
      "Epoch 141 / 200 | iteration 40 / 171 | Total Loss: 2.4094674587249756 | KNN Loss: 2.4011926651000977 | CLS Loss: 0.008274821564555168\n",
      "Epoch 141 / 200 | iteration 50 / 171 | Total Loss: 2.425481081008911 | KNN Loss: 2.4207518100738525 | CLS Loss: 0.004729323089122772\n",
      "Epoch 141 / 200 | iteration 60 / 171 | Total Loss: 2.365898847579956 | KNN Loss: 2.3618085384368896 | CLS Loss: 0.004090350586920977\n",
      "Epoch 141 / 200 | iteration 70 / 171 | Total Loss: 2.4381182193756104 | KNN Loss: 2.4210195541381836 | CLS Loss: 0.017098726704716682\n",
      "Epoch 141 / 200 | iteration 80 / 171 | Total Loss: 2.4219908714294434 | KNN Loss: 2.41984486579895 | CLS Loss: 0.0021460792049765587\n",
      "Epoch 141 / 200 | iteration 90 / 171 | Total Loss: 2.3872263431549072 | KNN Loss: 2.380814790725708 | CLS Loss: 0.006411542650312185\n",
      "Epoch 141 / 200 | iteration 100 / 171 | Total Loss: 2.402890920639038 | KNN Loss: 2.3871614933013916 | CLS Loss: 0.01572933793067932\n",
      "Epoch 141 / 200 | iteration 110 / 171 | Total Loss: 2.3754754066467285 | KNN Loss: 2.3721234798431396 | CLS Loss: 0.0033518855925649405\n",
      "Epoch 141 / 200 | iteration 120 / 171 | Total Loss: 2.37333083152771 | KNN Loss: 2.3576931953430176 | CLS Loss: 0.01563757099211216\n",
      "Epoch 141 / 200 | iteration 130 / 171 | Total Loss: 2.4020915031433105 | KNN Loss: 2.3886523246765137 | CLS Loss: 0.01343910489231348\n",
      "Epoch 141 / 200 | iteration 140 / 171 | Total Loss: 2.370899200439453 | KNN Loss: 2.367119312286377 | CLS Loss: 0.0037799219135195017\n",
      "Epoch 141 / 200 | iteration 150 / 171 | Total Loss: 2.3867692947387695 | KNN Loss: 2.3746657371520996 | CLS Loss: 0.012103530578315258\n",
      "Epoch 141 / 200 | iteration 160 / 171 | Total Loss: 2.399775505065918 | KNN Loss: 2.3955891132354736 | CLS Loss: 0.0041864481754601\n",
      "Epoch 141 / 200 | iteration 170 / 171 | Total Loss: 2.4079997539520264 | KNN Loss: 2.4062654972076416 | CLS Loss: 0.0017343107610940933\n",
      "Epoch: 141, Loss: 2.4085, Train: 0.9972, Valid: 0.9853, Best: 0.9878\n",
      "Epoch 142 / 200 | iteration 0 / 171 | Total Loss: 2.4380953311920166 | KNN Loss: 2.432130813598633 | CLS Loss: 0.005964476149529219\n",
      "Epoch 142 / 200 | iteration 10 / 171 | Total Loss: 2.3825950622558594 | KNN Loss: 2.3689181804656982 | CLS Loss: 0.013676922768354416\n",
      "Epoch 142 / 200 | iteration 20 / 171 | Total Loss: 2.3580799102783203 | KNN Loss: 2.345975875854492 | CLS Loss: 0.0121039729565382\n",
      "Epoch 142 / 200 | iteration 30 / 171 | Total Loss: 2.4003653526306152 | KNN Loss: 2.3980722427368164 | CLS Loss: 0.0022930169943720102\n",
      "Epoch 142 / 200 | iteration 40 / 171 | Total Loss: 2.417785882949829 | KNN Loss: 2.413363218307495 | CLS Loss: 0.004422654863446951\n",
      "Epoch 142 / 200 | iteration 50 / 171 | Total Loss: 2.390986919403076 | KNN Loss: 2.36824107170105 | CLS Loss: 0.022745871916413307\n",
      "Epoch 142 / 200 | iteration 60 / 171 | Total Loss: 2.368053436279297 | KNN Loss: 2.363539934158325 | CLS Loss: 0.004513580817729235\n",
      "Epoch 142 / 200 | iteration 70 / 171 | Total Loss: 2.3684933185577393 | KNN Loss: 2.3661751747131348 | CLS Loss: 0.002318174112588167\n",
      "Epoch 142 / 200 | iteration 80 / 171 | Total Loss: 2.3980422019958496 | KNN Loss: 2.3947978019714355 | CLS Loss: 0.0032444745302200317\n",
      "Epoch 142 / 200 | iteration 90 / 171 | Total Loss: 2.4618606567382812 | KNN Loss: 2.4359076023101807 | CLS Loss: 0.025953173637390137\n",
      "Epoch 142 / 200 | iteration 100 / 171 | Total Loss: 2.3924717903137207 | KNN Loss: 2.380703926086426 | CLS Loss: 0.011767960153520107\n",
      "Epoch 142 / 200 | iteration 110 / 171 | Total Loss: 2.373565196990967 | KNN Loss: 2.3705437183380127 | CLS Loss: 0.003021453507244587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 / 200 | iteration 120 / 171 | Total Loss: 2.3910398483276367 | KNN Loss: 2.3744266033172607 | CLS Loss: 0.016613297164440155\n",
      "Epoch 142 / 200 | iteration 130 / 171 | Total Loss: 2.3794608116149902 | KNN Loss: 2.372133493423462 | CLS Loss: 0.0073273335583508015\n",
      "Epoch 142 / 200 | iteration 140 / 171 | Total Loss: 2.412013530731201 | KNN Loss: 2.398181676864624 | CLS Loss: 0.013831904157996178\n",
      "Epoch 142 / 200 | iteration 150 / 171 | Total Loss: 2.4066977500915527 | KNN Loss: 2.3948781490325928 | CLS Loss: 0.011819511651992798\n",
      "Epoch 142 / 200 | iteration 160 / 171 | Total Loss: 2.4306023120880127 | KNN Loss: 2.4174585342407227 | CLS Loss: 0.013143709860742092\n",
      "Epoch 142 / 200 | iteration 170 / 171 | Total Loss: 2.4174110889434814 | KNN Loss: 2.392571210861206 | CLS Loss: 0.024839825928211212\n",
      "Epoch: 142, Loss: 2.4072, Train: 0.9970, Valid: 0.9860, Best: 0.9878\n",
      "Epoch 143 / 200 | iteration 0 / 171 | Total Loss: 2.4113452434539795 | KNN Loss: 2.397935390472412 | CLS Loss: 0.013409864157438278\n",
      "Epoch 143 / 200 | iteration 10 / 171 | Total Loss: 2.401832103729248 | KNN Loss: 2.3938894271850586 | CLS Loss: 0.007942607626318932\n",
      "Epoch 143 / 200 | iteration 20 / 171 | Total Loss: 2.387028932571411 | KNN Loss: 2.3762500286102295 | CLS Loss: 0.01077898871153593\n",
      "Epoch 143 / 200 | iteration 30 / 171 | Total Loss: 2.4070932865142822 | KNN Loss: 2.3989572525024414 | CLS Loss: 0.008135955780744553\n",
      "Epoch 143 / 200 | iteration 40 / 171 | Total Loss: 2.3776493072509766 | KNN Loss: 2.374497890472412 | CLS Loss: 0.0031515180598944426\n",
      "Epoch 143 / 200 | iteration 50 / 171 | Total Loss: 2.4148175716400146 | KNN Loss: 2.413257122039795 | CLS Loss: 0.0015604981454089284\n",
      "Epoch 143 / 200 | iteration 60 / 171 | Total Loss: 2.398270845413208 | KNN Loss: 2.3758859634399414 | CLS Loss: 0.022384772077202797\n",
      "Epoch 143 / 200 | iteration 70 / 171 | Total Loss: 2.3954665660858154 | KNN Loss: 2.3804497718811035 | CLS Loss: 0.01501681748777628\n",
      "Epoch 143 / 200 | iteration 80 / 171 | Total Loss: 2.41082763671875 | KNN Loss: 2.4047913551330566 | CLS Loss: 0.006036302540451288\n",
      "Epoch 143 / 200 | iteration 90 / 171 | Total Loss: 2.4185831546783447 | KNN Loss: 2.4019601345062256 | CLS Loss: 0.01662299409508705\n",
      "Epoch 143 / 200 | iteration 100 / 171 | Total Loss: 2.4306752681732178 | KNN Loss: 2.4283318519592285 | CLS Loss: 0.0023433873429894447\n",
      "Epoch 143 / 200 | iteration 110 / 171 | Total Loss: 2.4184932708740234 | KNN Loss: 2.3896262645721436 | CLS Loss: 0.028867073357105255\n",
      "Epoch 143 / 200 | iteration 120 / 171 | Total Loss: 2.420656442642212 | KNN Loss: 2.4173996448516846 | CLS Loss: 0.0032567838206887245\n",
      "Epoch 143 / 200 | iteration 130 / 171 | Total Loss: 2.4324426651000977 | KNN Loss: 2.402904510498047 | CLS Loss: 0.029538191854953766\n",
      "Epoch 143 / 200 | iteration 140 / 171 | Total Loss: 2.4207136631011963 | KNN Loss: 2.4112021923065186 | CLS Loss: 0.009511501528322697\n",
      "Epoch 143 / 200 | iteration 150 / 171 | Total Loss: 2.397984027862549 | KNN Loss: 2.3841500282287598 | CLS Loss: 0.013834086246788502\n",
      "Epoch 143 / 200 | iteration 160 / 171 | Total Loss: 2.4065921306610107 | KNN Loss: 2.3953537940979004 | CLS Loss: 0.011238230392336845\n",
      "Epoch 143 / 200 | iteration 170 / 171 | Total Loss: 2.4413418769836426 | KNN Loss: 2.4298744201660156 | CLS Loss: 0.011467423290014267\n",
      "Epoch: 143, Loss: 2.4138, Train: 0.9969, Valid: 0.9864, Best: 0.9878\n",
      "Epoch 144 / 200 | iteration 0 / 171 | Total Loss: 2.4041430950164795 | KNN Loss: 2.39530873298645 | CLS Loss: 0.008834459818899632\n",
      "Epoch 144 / 200 | iteration 10 / 171 | Total Loss: 2.4005513191223145 | KNN Loss: 2.3862223625183105 | CLS Loss: 0.014328934252262115\n",
      "Epoch 144 / 200 | iteration 20 / 171 | Total Loss: 2.4291696548461914 | KNN Loss: 2.410503625869751 | CLS Loss: 0.018666038289666176\n",
      "Epoch 144 / 200 | iteration 30 / 171 | Total Loss: 2.4123544692993164 | KNN Loss: 2.403916597366333 | CLS Loss: 0.008437921293079853\n",
      "Epoch 144 / 200 | iteration 40 / 171 | Total Loss: 2.449075222015381 | KNN Loss: 2.436502695083618 | CLS Loss: 0.012572507373988628\n",
      "Epoch 144 / 200 | iteration 50 / 171 | Total Loss: 2.4393322467803955 | KNN Loss: 2.404813766479492 | CLS Loss: 0.034518446773290634\n",
      "Epoch 144 / 200 | iteration 60 / 171 | Total Loss: 2.4571399688720703 | KNN Loss: 2.4401073455810547 | CLS Loss: 0.017032595351338387\n",
      "Epoch 144 / 200 | iteration 70 / 171 | Total Loss: 2.4100615978240967 | KNN Loss: 2.408383846282959 | CLS Loss: 0.0016778369899839163\n",
      "Epoch 144 / 200 | iteration 80 / 171 | Total Loss: 2.3856406211853027 | KNN Loss: 2.379948616027832 | CLS Loss: 0.005691905971616507\n",
      "Epoch 144 / 200 | iteration 90 / 171 | Total Loss: 2.4347450733184814 | KNN Loss: 2.3981640338897705 | CLS Loss: 0.03658096864819527\n",
      "Epoch 144 / 200 | iteration 100 / 171 | Total Loss: 2.3936190605163574 | KNN Loss: 2.385913848876953 | CLS Loss: 0.0077052488923072815\n",
      "Epoch 144 / 200 | iteration 110 / 171 | Total Loss: 2.3928210735321045 | KNN Loss: 2.38846755027771 | CLS Loss: 0.004353510681539774\n",
      "Epoch 144 / 200 | iteration 120 / 171 | Total Loss: 2.392172336578369 | KNN Loss: 2.3789491653442383 | CLS Loss: 0.013223194517195225\n",
      "Epoch 144 / 200 | iteration 130 / 171 | Total Loss: 2.415858507156372 | KNN Loss: 2.3983802795410156 | CLS Loss: 0.01747828535735607\n",
      "Epoch 144 / 200 | iteration 140 / 171 | Total Loss: 2.411918878555298 | KNN Loss: 2.405865430831909 | CLS Loss: 0.006053419318050146\n",
      "Epoch 144 / 200 | iteration 150 / 171 | Total Loss: 2.435161590576172 | KNN Loss: 2.4233286380767822 | CLS Loss: 0.011832918971776962\n",
      "Epoch 144 / 200 | iteration 160 / 171 | Total Loss: 2.4031031131744385 | KNN Loss: 2.397263288497925 | CLS Loss: 0.005839857738465071\n",
      "Epoch 144 / 200 | iteration 170 / 171 | Total Loss: 2.3720381259918213 | KNN Loss: 2.358853340148926 | CLS Loss: 0.013184863142669201\n",
      "Epoch: 144, Loss: 2.4074, Train: 0.9968, Valid: 0.9859, Best: 0.9878\n",
      "Epoch 145 / 200 | iteration 0 / 171 | Total Loss: 2.40967059135437 | KNN Loss: 2.3866376876831055 | CLS Loss: 0.02303299866616726\n",
      "Epoch 145 / 200 | iteration 10 / 171 | Total Loss: 2.413882255554199 | KNN Loss: 2.4001550674438477 | CLS Loss: 0.013727194629609585\n",
      "Epoch 145 / 200 | iteration 20 / 171 | Total Loss: 2.4351441860198975 | KNN Loss: 2.4291493892669678 | CLS Loss: 0.005994799546897411\n",
      "Epoch 145 / 200 | iteration 30 / 171 | Total Loss: 2.4468376636505127 | KNN Loss: 2.4166808128356934 | CLS Loss: 0.03015681728720665\n",
      "Epoch 145 / 200 | iteration 40 / 171 | Total Loss: 2.396059513092041 | KNN Loss: 2.3944263458251953 | CLS Loss: 0.0016330837970599532\n",
      "Epoch 145 / 200 | iteration 50 / 171 | Total Loss: 2.443014621734619 | KNN Loss: 2.4309771060943604 | CLS Loss: 0.012037512846291065\n",
      "Epoch 145 / 200 | iteration 60 / 171 | Total Loss: 2.4004366397857666 | KNN Loss: 2.397702932357788 | CLS Loss: 0.0027337290812283754\n",
      "Epoch 145 / 200 | iteration 70 / 171 | Total Loss: 2.394008159637451 | KNN Loss: 2.3917934894561768 | CLS Loss: 0.00221457751467824\n",
      "Epoch 145 / 200 | iteration 80 / 171 | Total Loss: 2.385952949523926 | KNN Loss: 2.3818187713623047 | CLS Loss: 0.004134161397814751\n",
      "Epoch 145 / 200 | iteration 90 / 171 | Total Loss: 2.417830228805542 | KNN Loss: 2.39182186126709 | CLS Loss: 0.02600836381316185\n",
      "Epoch 145 / 200 | iteration 100 / 171 | Total Loss: 2.3778841495513916 | KNN Loss: 2.3740663528442383 | CLS Loss: 0.0038178686518222094\n",
      "Epoch 145 / 200 | iteration 110 / 171 | Total Loss: 2.3990395069122314 | KNN Loss: 2.3856475353240967 | CLS Loss: 0.013391949236392975\n",
      "Epoch 145 / 200 | iteration 120 / 171 | Total Loss: 2.4390029907226562 | KNN Loss: 2.4152863025665283 | CLS Loss: 0.023716649040579796\n",
      "Epoch 145 / 200 | iteration 130 / 171 | Total Loss: 2.426910400390625 | KNN Loss: 2.3920938968658447 | CLS Loss: 0.03481656685471535\n",
      "Epoch 145 / 200 | iteration 140 / 171 | Total Loss: 2.402174949645996 | KNN Loss: 2.3948488235473633 | CLS Loss: 0.007326064165681601\n",
      "Epoch 145 / 200 | iteration 150 / 171 | Total Loss: 2.38220477104187 | KNN Loss: 2.3752801418304443 | CLS Loss: 0.006924580782651901\n",
      "Epoch 145 / 200 | iteration 160 / 171 | Total Loss: 2.4013381004333496 | KNN Loss: 2.3993213176727295 | CLS Loss: 0.002016764832660556\n",
      "Epoch 145 / 200 | iteration 170 / 171 | Total Loss: 2.4061343669891357 | KNN Loss: 2.392104148864746 | CLS Loss: 0.014030156657099724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145, Loss: 2.4103, Train: 0.9968, Valid: 0.9858, Best: 0.9878\n",
      "Epoch 146 / 200 | iteration 0 / 171 | Total Loss: 2.3801896572113037 | KNN Loss: 2.3722307682037354 | CLS Loss: 0.007958979345858097\n",
      "Epoch 146 / 200 | iteration 10 / 171 | Total Loss: 2.4068245887756348 | KNN Loss: 2.3983242511749268 | CLS Loss: 0.008500367403030396\n",
      "Epoch 146 / 200 | iteration 20 / 171 | Total Loss: 2.4224398136138916 | KNN Loss: 2.4152138233184814 | CLS Loss: 0.0072260363958776\n",
      "Epoch 146 / 200 | iteration 30 / 171 | Total Loss: 2.438340902328491 | KNN Loss: 2.4358150959014893 | CLS Loss: 0.0025257994420826435\n",
      "Epoch 146 / 200 | iteration 40 / 171 | Total Loss: 2.3999216556549072 | KNN Loss: 2.389310359954834 | CLS Loss: 0.010611379519104958\n",
      "Epoch 146 / 200 | iteration 50 / 171 | Total Loss: 2.450612783432007 | KNN Loss: 2.4282572269439697 | CLS Loss: 0.022355644032359123\n",
      "Epoch 146 / 200 | iteration 60 / 171 | Total Loss: 2.3785080909729004 | KNN Loss: 2.375030755996704 | CLS Loss: 0.003477226011455059\n",
      "Epoch 146 / 200 | iteration 70 / 171 | Total Loss: 2.4341061115264893 | KNN Loss: 2.402757167816162 | CLS Loss: 0.03134898841381073\n",
      "Epoch 146 / 200 | iteration 80 / 171 | Total Loss: 2.379469633102417 | KNN Loss: 2.375798463821411 | CLS Loss: 0.0036710945423692465\n",
      "Epoch 146 / 200 | iteration 90 / 171 | Total Loss: 2.441664218902588 | KNN Loss: 2.4361305236816406 | CLS Loss: 0.0055336556397378445\n",
      "Epoch 146 / 200 | iteration 100 / 171 | Total Loss: 2.4370315074920654 | KNN Loss: 2.42301869392395 | CLS Loss: 0.014012801460921764\n",
      "Epoch 146 / 200 | iteration 110 / 171 | Total Loss: 2.438373565673828 | KNN Loss: 2.4294490814208984 | CLS Loss: 0.008924483321607113\n",
      "Epoch 146 / 200 | iteration 120 / 171 | Total Loss: 2.39772891998291 | KNN Loss: 2.3892581462860107 | CLS Loss: 0.008470836095511913\n",
      "Epoch 146 / 200 | iteration 130 / 171 | Total Loss: 2.3745601177215576 | KNN Loss: 2.366821527481079 | CLS Loss: 0.007738638203591108\n",
      "Epoch 146 / 200 | iteration 140 / 171 | Total Loss: 2.4312667846679688 | KNN Loss: 2.4029619693756104 | CLS Loss: 0.028304792940616608\n",
      "Epoch 146 / 200 | iteration 150 / 171 | Total Loss: 2.4233481884002686 | KNN Loss: 2.3946540355682373 | CLS Loss: 0.02869412861764431\n",
      "Epoch 146 / 200 | iteration 160 / 171 | Total Loss: 2.427839994430542 | KNN Loss: 2.41936993598938 | CLS Loss: 0.008469966240227222\n",
      "Epoch 146 / 200 | iteration 170 / 171 | Total Loss: 2.405982255935669 | KNN Loss: 2.3945960998535156 | CLS Loss: 0.011386205442249775\n",
      "Epoch: 146, Loss: 2.4126, Train: 0.9969, Valid: 0.9869, Best: 0.9878\n",
      "Epoch 147 / 200 | iteration 0 / 171 | Total Loss: 2.404982566833496 | KNN Loss: 2.3963334560394287 | CLS Loss: 0.008648994378745556\n",
      "Epoch 147 / 200 | iteration 10 / 171 | Total Loss: 2.432342290878296 | KNN Loss: 2.4226815700531006 | CLS Loss: 0.009660694748163223\n",
      "Epoch 147 / 200 | iteration 20 / 171 | Total Loss: 2.4079079627990723 | KNN Loss: 2.3835535049438477 | CLS Loss: 0.02435433864593506\n",
      "Epoch 147 / 200 | iteration 30 / 171 | Total Loss: 2.4047586917877197 | KNN Loss: 2.387491464614868 | CLS Loss: 0.017267201095819473\n",
      "Epoch 147 / 200 | iteration 40 / 171 | Total Loss: 2.4408509731292725 | KNN Loss: 2.4250075817108154 | CLS Loss: 0.015843313187360764\n",
      "Epoch 147 / 200 | iteration 50 / 171 | Total Loss: 2.4530043601989746 | KNN Loss: 2.432316541671753 | CLS Loss: 0.020687811076641083\n",
      "Epoch 147 / 200 | iteration 60 / 171 | Total Loss: 2.415093183517456 | KNN Loss: 2.39054799079895 | CLS Loss: 0.024545151740312576\n",
      "Epoch 147 / 200 | iteration 70 / 171 | Total Loss: 2.385225534439087 | KNN Loss: 2.3815929889678955 | CLS Loss: 0.003632513340562582\n",
      "Epoch 147 / 200 | iteration 80 / 171 | Total Loss: 2.409803628921509 | KNN Loss: 2.4017248153686523 | CLS Loss: 0.008078759536147118\n",
      "Epoch 147 / 200 | iteration 90 / 171 | Total Loss: 2.3850257396698 | KNN Loss: 2.3775475025177 | CLS Loss: 0.0074782767333090305\n",
      "Epoch 147 / 200 | iteration 100 / 171 | Total Loss: 2.387223958969116 | KNN Loss: 2.379385471343994 | CLS Loss: 0.007838449440896511\n",
      "Epoch 147 / 200 | iteration 110 / 171 | Total Loss: 2.4188146591186523 | KNN Loss: 2.413623094558716 | CLS Loss: 0.005191543139517307\n",
      "Epoch 147 / 200 | iteration 120 / 171 | Total Loss: 2.426520586013794 | KNN Loss: 2.4029369354248047 | CLS Loss: 0.02358355186879635\n",
      "Epoch 147 / 200 | iteration 130 / 171 | Total Loss: 2.376495838165283 | KNN Loss: 2.3749303817749023 | CLS Loss: 0.0015654218150302768\n",
      "Epoch 147 / 200 | iteration 140 / 171 | Total Loss: 2.400773048400879 | KNN Loss: 2.3980560302734375 | CLS Loss: 0.002716907998546958\n",
      "Epoch 147 / 200 | iteration 150 / 171 | Total Loss: 2.367499589920044 | KNN Loss: 2.365105628967285 | CLS Loss: 0.00239386735484004\n",
      "Epoch 147 / 200 | iteration 160 / 171 | Total Loss: 2.402921199798584 | KNN Loss: 2.3985965251922607 | CLS Loss: 0.004324756097048521\n",
      "Epoch 147 / 200 | iteration 170 / 171 | Total Loss: 2.3929920196533203 | KNN Loss: 2.3681082725524902 | CLS Loss: 0.024883778765797615\n",
      "Epoch: 147, Loss: 2.4125, Train: 0.9966, Valid: 0.9866, Best: 0.9878\n",
      "Epoch 148 / 200 | iteration 0 / 171 | Total Loss: 2.411496162414551 | KNN Loss: 2.402665853500366 | CLS Loss: 0.008830232545733452\n",
      "Epoch 148 / 200 | iteration 10 / 171 | Total Loss: 2.3906092643737793 | KNN Loss: 2.38442063331604 | CLS Loss: 0.00618865666911006\n",
      "Epoch 148 / 200 | iteration 20 / 171 | Total Loss: 2.4105212688446045 | KNN Loss: 2.385451078414917 | CLS Loss: 0.0250703077763319\n",
      "Epoch 148 / 200 | iteration 30 / 171 | Total Loss: 2.399930238723755 | KNN Loss: 2.389336109161377 | CLS Loss: 0.010594046674668789\n",
      "Epoch 148 / 200 | iteration 40 / 171 | Total Loss: 2.4085276126861572 | KNN Loss: 2.3952627182006836 | CLS Loss: 0.013264891691505909\n",
      "Epoch 148 / 200 | iteration 50 / 171 | Total Loss: 2.4206390380859375 | KNN Loss: 2.4064483642578125 | CLS Loss: 0.014190666377544403\n",
      "Epoch 148 / 200 | iteration 60 / 171 | Total Loss: 2.388218879699707 | KNN Loss: 2.37544584274292 | CLS Loss: 0.012772924266755581\n",
      "Epoch 148 / 200 | iteration 70 / 171 | Total Loss: 2.45344877243042 | KNN Loss: 2.4268798828125 | CLS Loss: 0.026568960398435593\n",
      "Epoch 148 / 200 | iteration 80 / 171 | Total Loss: 2.4110143184661865 | KNN Loss: 2.3996994495391846 | CLS Loss: 0.011314913630485535\n",
      "Epoch 148 / 200 | iteration 90 / 171 | Total Loss: 2.423490524291992 | KNN Loss: 2.406851291656494 | CLS Loss: 0.016639139503240585\n",
      "Epoch 148 / 200 | iteration 100 / 171 | Total Loss: 2.3931057453155518 | KNN Loss: 2.375898599624634 | CLS Loss: 0.017207084223628044\n",
      "Epoch 148 / 200 | iteration 110 / 171 | Total Loss: 2.389859437942505 | KNN Loss: 2.3705625534057617 | CLS Loss: 0.01929694041609764\n",
      "Epoch 148 / 200 | iteration 120 / 171 | Total Loss: 2.424088478088379 | KNN Loss: 2.4197838306427 | CLS Loss: 0.004304605536162853\n",
      "Epoch 148 / 200 | iteration 130 / 171 | Total Loss: 2.419323205947876 | KNN Loss: 2.404292345046997 | CLS Loss: 0.01503082551062107\n",
      "Epoch 148 / 200 | iteration 140 / 171 | Total Loss: 2.3552563190460205 | KNN Loss: 2.35153865814209 | CLS Loss: 0.0037175521720200777\n",
      "Epoch 148 / 200 | iteration 150 / 171 | Total Loss: 2.405987024307251 | KNN Loss: 2.400623083114624 | CLS Loss: 0.00536394352093339\n",
      "Epoch 148 / 200 | iteration 160 / 171 | Total Loss: 2.4129245281219482 | KNN Loss: 2.4011595249176025 | CLS Loss: 0.01176503673195839\n",
      "Epoch 148 / 200 | iteration 170 / 171 | Total Loss: 2.412034749984741 | KNN Loss: 2.4011476039886475 | CLS Loss: 0.010887188836932182\n",
      "Epoch: 148, Loss: 2.4106, Train: 0.9970, Valid: 0.9863, Best: 0.9878\n",
      "Epoch 149 / 200 | iteration 0 / 171 | Total Loss: 2.409478187561035 | KNN Loss: 2.398325204849243 | CLS Loss: 0.011152929626405239\n",
      "Epoch 149 / 200 | iteration 10 / 171 | Total Loss: 2.4056358337402344 | KNN Loss: 2.392800807952881 | CLS Loss: 0.012835035100579262\n",
      "Epoch 149 / 200 | iteration 20 / 171 | Total Loss: 2.395749092102051 | KNN Loss: 2.37976336479187 | CLS Loss: 0.015985682606697083\n",
      "Epoch 149 / 200 | iteration 30 / 171 | Total Loss: 2.396503448486328 | KNN Loss: 2.3776614665985107 | CLS Loss: 0.018842076882719994\n",
      "Epoch 149 / 200 | iteration 40 / 171 | Total Loss: 2.3999836444854736 | KNN Loss: 2.3825924396514893 | CLS Loss: 0.01739114709198475\n",
      "Epoch 149 / 200 | iteration 50 / 171 | Total Loss: 2.4035911560058594 | KNN Loss: 2.399678945541382 | CLS Loss: 0.003912325017154217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 / 200 | iteration 60 / 171 | Total Loss: 2.403106927871704 | KNN Loss: 2.396996259689331 | CLS Loss: 0.006110745016485453\n",
      "Epoch 149 / 200 | iteration 70 / 171 | Total Loss: 2.418189525604248 | KNN Loss: 2.41595196723938 | CLS Loss: 0.002237651264294982\n",
      "Epoch 149 / 200 | iteration 80 / 171 | Total Loss: 2.4031460285186768 | KNN Loss: 2.3978588581085205 | CLS Loss: 0.005287060979753733\n",
      "Epoch 149 / 200 | iteration 90 / 171 | Total Loss: 2.4220457077026367 | KNN Loss: 2.394346237182617 | CLS Loss: 0.027699587866663933\n",
      "Epoch 149 / 200 | iteration 100 / 171 | Total Loss: 2.3865294456481934 | KNN Loss: 2.363023042678833 | CLS Loss: 0.023506473749876022\n",
      "Epoch 149 / 200 | iteration 110 / 171 | Total Loss: 2.3946444988250732 | KNN Loss: 2.391211748123169 | CLS Loss: 0.0034327416215091944\n",
      "Epoch 149 / 200 | iteration 120 / 171 | Total Loss: 2.3653595447540283 | KNN Loss: 2.3491673469543457 | CLS Loss: 0.01619214005768299\n",
      "Epoch 149 / 200 | iteration 130 / 171 | Total Loss: 2.4121408462524414 | KNN Loss: 2.406489849090576 | CLS Loss: 0.005650878418236971\n",
      "Epoch 149 / 200 | iteration 140 / 171 | Total Loss: 2.388113498687744 | KNN Loss: 2.371994972229004 | CLS Loss: 0.01611841283738613\n",
      "Epoch 149 / 200 | iteration 150 / 171 | Total Loss: 2.4089646339416504 | KNN Loss: 2.3982582092285156 | CLS Loss: 0.0107064638286829\n",
      "Epoch 149 / 200 | iteration 160 / 171 | Total Loss: 2.4382433891296387 | KNN Loss: 2.432079315185547 | CLS Loss: 0.006164125632494688\n",
      "Epoch 149 / 200 | iteration 170 / 171 | Total Loss: 2.409036159515381 | KNN Loss: 2.405661106109619 | CLS Loss: 0.0033751027658581734\n",
      "Epoch: 149, Loss: 2.4066, Train: 0.9972, Valid: 0.9867, Best: 0.9878\n",
      "Epoch 150 / 200 | iteration 0 / 171 | Total Loss: 2.3940436840057373 | KNN Loss: 2.3900275230407715 | CLS Loss: 0.0040160613134503365\n",
      "Epoch 150 / 200 | iteration 10 / 171 | Total Loss: 2.4044055938720703 | KNN Loss: 2.3888022899627686 | CLS Loss: 0.015603232197463512\n",
      "Epoch 150 / 200 | iteration 20 / 171 | Total Loss: 2.3961431980133057 | KNN Loss: 2.3894567489624023 | CLS Loss: 0.006686567794531584\n",
      "Epoch 150 / 200 | iteration 30 / 171 | Total Loss: 2.3979010581970215 | KNN Loss: 2.392561912536621 | CLS Loss: 0.005339181981980801\n",
      "Epoch 150 / 200 | iteration 40 / 171 | Total Loss: 2.3807380199432373 | KNN Loss: 2.366142988204956 | CLS Loss: 0.014595103450119495\n",
      "Epoch 150 / 200 | iteration 50 / 171 | Total Loss: 2.4171321392059326 | KNN Loss: 2.3889360427856445 | CLS Loss: 0.028196029365062714\n",
      "Epoch 150 / 200 | iteration 60 / 171 | Total Loss: 2.399571657180786 | KNN Loss: 2.394763469696045 | CLS Loss: 0.004808077123016119\n",
      "Epoch 150 / 200 | iteration 70 / 171 | Total Loss: 2.4198150634765625 | KNN Loss: 2.4120888710021973 | CLS Loss: 0.0077261729165911674\n",
      "Epoch 150 / 200 | iteration 80 / 171 | Total Loss: 2.398216962814331 | KNN Loss: 2.3910915851593018 | CLS Loss: 0.007125428412109613\n",
      "Epoch 150 / 200 | iteration 90 / 171 | Total Loss: 2.3857948780059814 | KNN Loss: 2.374026298522949 | CLS Loss: 0.011768465861678123\n",
      "Epoch 150 / 200 | iteration 100 / 171 | Total Loss: 2.4275081157684326 | KNN Loss: 2.420959711074829 | CLS Loss: 0.006548435892909765\n",
      "Epoch 150 / 200 | iteration 110 / 171 | Total Loss: 2.3902759552001953 | KNN Loss: 2.3840103149414062 | CLS Loss: 0.006265594623982906\n",
      "Epoch 150 / 200 | iteration 120 / 171 | Total Loss: 2.417576313018799 | KNN Loss: 2.4081473350524902 | CLS Loss: 0.009429006837308407\n",
      "Epoch 150 / 200 | iteration 130 / 171 | Total Loss: 2.4177117347717285 | KNN Loss: 2.4100289344787598 | CLS Loss: 0.007682877592742443\n",
      "Epoch 150 / 200 | iteration 140 / 171 | Total Loss: 2.4111368656158447 | KNN Loss: 2.3969900608062744 | CLS Loss: 0.014146910049021244\n",
      "Epoch 150 / 200 | iteration 150 / 171 | Total Loss: 2.392315149307251 | KNN Loss: 2.38403058052063 | CLS Loss: 0.008284634910523891\n",
      "Epoch 150 / 200 | iteration 160 / 171 | Total Loss: 2.4266679286956787 | KNN Loss: 2.400472640991211 | CLS Loss: 0.026195231825113297\n",
      "Epoch 150 / 200 | iteration 170 / 171 | Total Loss: 2.397189140319824 | KNN Loss: 2.3903634548187256 | CLS Loss: 0.006825773045420647\n",
      "Epoch: 150, Loss: 2.4101, Train: 0.9972, Valid: 0.9870, Best: 0.9878\n",
      "Epoch 151 / 200 | iteration 0 / 171 | Total Loss: 2.4104671478271484 | KNN Loss: 2.385448932647705 | CLS Loss: 0.025018125772476196\n",
      "Epoch 151 / 200 | iteration 10 / 171 | Total Loss: 2.3836472034454346 | KNN Loss: 2.376767158508301 | CLS Loss: 0.006879950407892466\n",
      "Epoch 151 / 200 | iteration 20 / 171 | Total Loss: 2.4131553173065186 | KNN Loss: 2.4105658531188965 | CLS Loss: 0.002589527517557144\n",
      "Epoch 151 / 200 | iteration 30 / 171 | Total Loss: 2.417738437652588 | KNN Loss: 2.4092297554016113 | CLS Loss: 0.008508702740073204\n",
      "Epoch 151 / 200 | iteration 40 / 171 | Total Loss: 2.3947346210479736 | KNN Loss: 2.381377935409546 | CLS Loss: 0.013356744311749935\n",
      "Epoch 151 / 200 | iteration 50 / 171 | Total Loss: 2.4112324714660645 | KNN Loss: 2.406813859939575 | CLS Loss: 0.004418561235070229\n",
      "Epoch 151 / 200 | iteration 60 / 171 | Total Loss: 2.391525983810425 | KNN Loss: 2.3858988285064697 | CLS Loss: 0.005627071019262075\n",
      "Epoch 151 / 200 | iteration 70 / 171 | Total Loss: 2.3926074504852295 | KNN Loss: 2.380260705947876 | CLS Loss: 0.012346697971224785\n",
      "Epoch 151 / 200 | iteration 80 / 171 | Total Loss: 2.412912130355835 | KNN Loss: 2.398867607116699 | CLS Loss: 0.014044605195522308\n",
      "Epoch 151 / 200 | iteration 90 / 171 | Total Loss: 2.4231693744659424 | KNN Loss: 2.407106876373291 | CLS Loss: 0.016062429174780846\n",
      "Epoch 151 / 200 | iteration 100 / 171 | Total Loss: 2.4042768478393555 | KNN Loss: 2.4022505283355713 | CLS Loss: 0.002026384463533759\n",
      "Epoch 151 / 200 | iteration 110 / 171 | Total Loss: 2.46390962600708 | KNN Loss: 2.4329376220703125 | CLS Loss: 0.030971983447670937\n",
      "Epoch 151 / 200 | iteration 120 / 171 | Total Loss: 2.383859395980835 | KNN Loss: 2.3799965381622314 | CLS Loss: 0.0038628727197647095\n",
      "Epoch 151 / 200 | iteration 130 / 171 | Total Loss: 2.438385248184204 | KNN Loss: 2.415114641189575 | CLS Loss: 0.02327069826424122\n",
      "Epoch 151 / 200 | iteration 140 / 171 | Total Loss: 2.3855953216552734 | KNN Loss: 2.3765885829925537 | CLS Loss: 0.009006811305880547\n",
      "Epoch 151 / 200 | iteration 150 / 171 | Total Loss: 2.3919591903686523 | KNN Loss: 2.3859732151031494 | CLS Loss: 0.005986025556921959\n",
      "Epoch 151 / 200 | iteration 160 / 171 | Total Loss: 2.3986408710479736 | KNN Loss: 2.391874074935913 | CLS Loss: 0.006766769103705883\n",
      "Epoch 151 / 200 | iteration 170 / 171 | Total Loss: 2.4816184043884277 | KNN Loss: 2.4366614818573 | CLS Loss: 0.04495682939887047\n",
      "Epoch: 151, Loss: 2.4124, Train: 0.9974, Valid: 0.9869, Best: 0.9878\n",
      "Epoch 152 / 200 | iteration 0 / 171 | Total Loss: 2.4397828578948975 | KNN Loss: 2.43137788772583 | CLS Loss: 0.008405040018260479\n",
      "Epoch 152 / 200 | iteration 10 / 171 | Total Loss: 2.4116060733795166 | KNN Loss: 2.391648292541504 | CLS Loss: 0.019957827404141426\n",
      "Epoch 152 / 200 | iteration 20 / 171 | Total Loss: 2.3821940422058105 | KNN Loss: 2.3806374073028564 | CLS Loss: 0.0015565365320071578\n",
      "Epoch 152 / 200 | iteration 30 / 171 | Total Loss: 2.3988847732543945 | KNN Loss: 2.383666515350342 | CLS Loss: 0.015218201093375683\n",
      "Epoch 152 / 200 | iteration 40 / 171 | Total Loss: 2.4394805431365967 | KNN Loss: 2.4224512577056885 | CLS Loss: 0.017029307782649994\n",
      "Epoch 152 / 200 | iteration 50 / 171 | Total Loss: 2.437448263168335 | KNN Loss: 2.430124521255493 | CLS Loss: 0.007323626894503832\n",
      "Epoch 152 / 200 | iteration 60 / 171 | Total Loss: 2.408836603164673 | KNN Loss: 2.3677074909210205 | CLS Loss: 0.04112919420003891\n",
      "Epoch 152 / 200 | iteration 70 / 171 | Total Loss: 2.430654287338257 | KNN Loss: 2.4182887077331543 | CLS Loss: 0.012365679256618023\n",
      "Epoch 152 / 200 | iteration 80 / 171 | Total Loss: 2.3989100456237793 | KNN Loss: 2.391857624053955 | CLS Loss: 0.00705253379419446\n",
      "Epoch 152 / 200 | iteration 90 / 171 | Total Loss: 2.437488555908203 | KNN Loss: 2.4193572998046875 | CLS Loss: 0.018131334334611893\n",
      "Epoch 152 / 200 | iteration 100 / 171 | Total Loss: 2.4167981147766113 | KNN Loss: 2.3963780403137207 | CLS Loss: 0.020420076325535774\n",
      "Epoch 152 / 200 | iteration 110 / 171 | Total Loss: 2.4227561950683594 | KNN Loss: 2.4154810905456543 | CLS Loss: 0.007275055628269911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 / 200 | iteration 120 / 171 | Total Loss: 2.4020724296569824 | KNN Loss: 2.3929545879364014 | CLS Loss: 0.009117750450968742\n",
      "Epoch 152 / 200 | iteration 130 / 171 | Total Loss: 2.4267237186431885 | KNN Loss: 2.4099233150482178 | CLS Loss: 0.01680043153464794\n",
      "Epoch 152 / 200 | iteration 140 / 171 | Total Loss: 2.4244234561920166 | KNN Loss: 2.3945634365081787 | CLS Loss: 0.02985996939241886\n",
      "Epoch 152 / 200 | iteration 150 / 171 | Total Loss: 2.40876841545105 | KNN Loss: 2.4021267890930176 | CLS Loss: 0.006641555577516556\n",
      "Epoch 152 / 200 | iteration 160 / 171 | Total Loss: 2.4401607513427734 | KNN Loss: 2.437626361846924 | CLS Loss: 0.0025343128945678473\n",
      "Epoch 152 / 200 | iteration 170 / 171 | Total Loss: 2.4408645629882812 | KNN Loss: 2.4125330448150635 | CLS Loss: 0.028331534937024117\n",
      "Epoch: 152, Loss: 2.4121, Train: 0.9971, Valid: 0.9864, Best: 0.9878\n",
      "Epoch 153 / 200 | iteration 0 / 171 | Total Loss: 2.415532112121582 | KNN Loss: 2.4092495441436768 | CLS Loss: 0.006282678339630365\n",
      "Epoch 153 / 200 | iteration 10 / 171 | Total Loss: 2.384167194366455 | KNN Loss: 2.3834991455078125 | CLS Loss: 0.0006681576487608254\n",
      "Epoch 153 / 200 | iteration 20 / 171 | Total Loss: 2.4047625064849854 | KNN Loss: 2.403048276901245 | CLS Loss: 0.001714219688437879\n",
      "Epoch 153 / 200 | iteration 30 / 171 | Total Loss: 2.388540267944336 | KNN Loss: 2.3847529888153076 | CLS Loss: 0.003787166438996792\n",
      "Epoch 153 / 200 | iteration 40 / 171 | Total Loss: 2.3653273582458496 | KNN Loss: 2.3595821857452393 | CLS Loss: 0.005745068658143282\n",
      "Epoch 153 / 200 | iteration 50 / 171 | Total Loss: 2.4352359771728516 | KNN Loss: 2.4314329624176025 | CLS Loss: 0.003803055267781019\n",
      "Epoch 153 / 200 | iteration 60 / 171 | Total Loss: 2.3967912197113037 | KNN Loss: 2.374983072280884 | CLS Loss: 0.021808186545968056\n",
      "Epoch 153 / 200 | iteration 70 / 171 | Total Loss: 2.43192982673645 | KNN Loss: 2.422058343887329 | CLS Loss: 0.009871398098766804\n",
      "Epoch 153 / 200 | iteration 80 / 171 | Total Loss: 2.381169557571411 | KNN Loss: 2.369960069656372 | CLS Loss: 0.011209575459361076\n",
      "Epoch 153 / 200 | iteration 90 / 171 | Total Loss: 2.4184741973876953 | KNN Loss: 2.416586399078369 | CLS Loss: 0.0018877842230722308\n",
      "Epoch 153 / 200 | iteration 100 / 171 | Total Loss: 2.4025614261627197 | KNN Loss: 2.38763165473938 | CLS Loss: 0.014929861761629581\n",
      "Epoch 153 / 200 | iteration 110 / 171 | Total Loss: 2.409536838531494 | KNN Loss: 2.3922653198242188 | CLS Loss: 0.017271429300308228\n",
      "Epoch 153 / 200 | iteration 120 / 171 | Total Loss: 2.373440742492676 | KNN Loss: 2.366971731185913 | CLS Loss: 0.006469103042036295\n",
      "Epoch 153 / 200 | iteration 130 / 171 | Total Loss: 2.4461495876312256 | KNN Loss: 2.4189672470092773 | CLS Loss: 0.027182266116142273\n",
      "Epoch 153 / 200 | iteration 140 / 171 | Total Loss: 2.4148659706115723 | KNN Loss: 2.4040322303771973 | CLS Loss: 0.010833647102117538\n",
      "Epoch 153 / 200 | iteration 150 / 171 | Total Loss: 2.387951135635376 | KNN Loss: 2.3749375343322754 | CLS Loss: 0.013013510033488274\n",
      "Epoch 153 / 200 | iteration 160 / 171 | Total Loss: 2.428771734237671 | KNN Loss: 2.4188268184661865 | CLS Loss: 0.009944948367774487\n",
      "Epoch 153 / 200 | iteration 170 / 171 | Total Loss: 2.392564535140991 | KNN Loss: 2.384500026702881 | CLS Loss: 0.008064446970820427\n",
      "Epoch: 153, Loss: 2.4085, Train: 0.9973, Valid: 0.9866, Best: 0.9878\n",
      "Epoch 154 / 200 | iteration 0 / 171 | Total Loss: 2.420217275619507 | KNN Loss: 2.4061124324798584 | CLS Loss: 0.01410488598048687\n",
      "Epoch 154 / 200 | iteration 10 / 171 | Total Loss: 2.4108827114105225 | KNN Loss: 2.4020416736602783 | CLS Loss: 0.008841054514050484\n",
      "Epoch 154 / 200 | iteration 20 / 171 | Total Loss: 2.386732816696167 | KNN Loss: 2.363807201385498 | CLS Loss: 0.02292560413479805\n",
      "Epoch 154 / 200 | iteration 30 / 171 | Total Loss: 2.4301300048828125 | KNN Loss: 2.419861078262329 | CLS Loss: 0.010269036516547203\n",
      "Epoch 154 / 200 | iteration 40 / 171 | Total Loss: 2.385800361633301 | KNN Loss: 2.3599889278411865 | CLS Loss: 0.025811534374952316\n",
      "Epoch 154 / 200 | iteration 50 / 171 | Total Loss: 2.3942785263061523 | KNN Loss: 2.3879880905151367 | CLS Loss: 0.006290331482887268\n",
      "Epoch 154 / 200 | iteration 60 / 171 | Total Loss: 2.383265495300293 | KNN Loss: 2.3756511211395264 | CLS Loss: 0.007614473812282085\n",
      "Epoch 154 / 200 | iteration 70 / 171 | Total Loss: 2.452763080596924 | KNN Loss: 2.4323697090148926 | CLS Loss: 0.020393330603837967\n",
      "Epoch 154 / 200 | iteration 80 / 171 | Total Loss: 2.386051654815674 | KNN Loss: 2.381157875061035 | CLS Loss: 0.004893776495009661\n",
      "Epoch 154 / 200 | iteration 90 / 171 | Total Loss: 2.425180435180664 | KNN Loss: 2.419173002243042 | CLS Loss: 0.006007461808621883\n",
      "Epoch 154 / 200 | iteration 100 / 171 | Total Loss: 2.440764904022217 | KNN Loss: 2.4279065132141113 | CLS Loss: 0.01285834051668644\n",
      "Epoch 154 / 200 | iteration 110 / 171 | Total Loss: 2.4084084033966064 | KNN Loss: 2.390516757965088 | CLS Loss: 0.017891662195324898\n",
      "Epoch 154 / 200 | iteration 120 / 171 | Total Loss: 2.3863134384155273 | KNN Loss: 2.379681348800659 | CLS Loss: 0.006632100325077772\n",
      "Epoch 154 / 200 | iteration 130 / 171 | Total Loss: 2.4180171489715576 | KNN Loss: 2.414672374725342 | CLS Loss: 0.0033447272144258022\n",
      "Epoch 154 / 200 | iteration 140 / 171 | Total Loss: 2.410120964050293 | KNN Loss: 2.3955297470092773 | CLS Loss: 0.014591130428016186\n",
      "Epoch 154 / 200 | iteration 150 / 171 | Total Loss: 2.3824141025543213 | KNN Loss: 2.376052141189575 | CLS Loss: 0.006361952051520348\n",
      "Epoch 154 / 200 | iteration 160 / 171 | Total Loss: 2.40065598487854 | KNN Loss: 2.37935209274292 | CLS Loss: 0.021303970366716385\n",
      "Epoch 154 / 200 | iteration 170 / 171 | Total Loss: 2.4377405643463135 | KNN Loss: 2.4178459644317627 | CLS Loss: 0.019894717261195183\n",
      "Epoch: 154, Loss: 2.4072, Train: 0.9977, Valid: 0.9867, Best: 0.9878\n",
      "Epoch 155 / 200 | iteration 0 / 171 | Total Loss: 2.381527900695801 | KNN Loss: 2.3576605319976807 | CLS Loss: 0.023867346346378326\n",
      "Epoch 155 / 200 | iteration 10 / 171 | Total Loss: 2.4140758514404297 | KNN Loss: 2.410649299621582 | CLS Loss: 0.0034265145659446716\n",
      "Epoch 155 / 200 | iteration 20 / 171 | Total Loss: 2.3931870460510254 | KNN Loss: 2.390993356704712 | CLS Loss: 0.002193656750023365\n",
      "Epoch 155 / 200 | iteration 30 / 171 | Total Loss: 2.4183847904205322 | KNN Loss: 2.4147756099700928 | CLS Loss: 0.0036090996582061052\n",
      "Epoch 155 / 200 | iteration 40 / 171 | Total Loss: 2.400801420211792 | KNN Loss: 2.3903419971466064 | CLS Loss: 0.010459374636411667\n",
      "Epoch 155 / 200 | iteration 50 / 171 | Total Loss: 2.407318353652954 | KNN Loss: 2.401123523712158 | CLS Loss: 0.006194839719682932\n",
      "Epoch 155 / 200 | iteration 60 / 171 | Total Loss: 2.3641083240509033 | KNN Loss: 2.3608486652374268 | CLS Loss: 0.003259599208831787\n",
      "Epoch 155 / 200 | iteration 70 / 171 | Total Loss: 2.395085334777832 | KNN Loss: 2.3895487785339355 | CLS Loss: 0.005536471493542194\n",
      "Epoch 155 / 200 | iteration 80 / 171 | Total Loss: 2.40108585357666 | KNN Loss: 2.393122911453247 | CLS Loss: 0.007962909527122974\n",
      "Epoch 155 / 200 | iteration 90 / 171 | Total Loss: 2.3991317749023438 | KNN Loss: 2.3795971870422363 | CLS Loss: 0.01953447423875332\n",
      "Epoch 155 / 200 | iteration 100 / 171 | Total Loss: 2.385089874267578 | KNN Loss: 2.3696844577789307 | CLS Loss: 0.015405436977744102\n",
      "Epoch 155 / 200 | iteration 110 / 171 | Total Loss: 2.389286994934082 | KNN Loss: 2.372736930847168 | CLS Loss: 0.01655006967484951\n",
      "Epoch 155 / 200 | iteration 120 / 171 | Total Loss: 2.4295403957366943 | KNN Loss: 2.424260377883911 | CLS Loss: 0.005279966164380312\n",
      "Epoch 155 / 200 | iteration 130 / 171 | Total Loss: 2.4207236766815186 | KNN Loss: 2.4189860820770264 | CLS Loss: 0.0017374982126057148\n",
      "Epoch 155 / 200 | iteration 140 / 171 | Total Loss: 2.390416383743286 | KNN Loss: 2.3850090503692627 | CLS Loss: 0.005407221149653196\n",
      "Epoch 155 / 200 | iteration 150 / 171 | Total Loss: 2.4062438011169434 | KNN Loss: 2.3942642211914062 | CLS Loss: 0.011979592964053154\n",
      "Epoch 155 / 200 | iteration 160 / 171 | Total Loss: 2.410086154937744 | KNN Loss: 2.4046719074249268 | CLS Loss: 0.005414216313511133\n",
      "Epoch 155 / 200 | iteration 170 / 171 | Total Loss: 2.4105007648468018 | KNN Loss: 2.399387836456299 | CLS Loss: 0.01111283153295517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 155, Loss: 2.4068, Train: 0.9959, Valid: 0.9858, Best: 0.9878\n",
      "Epoch 156 / 200 | iteration 0 / 171 | Total Loss: 2.4301488399505615 | KNN Loss: 2.416956663131714 | CLS Loss: 0.013192208483815193\n",
      "Epoch 156 / 200 | iteration 10 / 171 | Total Loss: 2.4006025791168213 | KNN Loss: 2.384650230407715 | CLS Loss: 0.01595238409936428\n",
      "Epoch 156 / 200 | iteration 20 / 171 | Total Loss: 2.3919906616210938 | KNN Loss: 2.382678270339966 | CLS Loss: 0.009312466718256474\n",
      "Epoch 156 / 200 | iteration 30 / 171 | Total Loss: 2.41636061668396 | KNN Loss: 2.3836965560913086 | CLS Loss: 0.03266414627432823\n",
      "Epoch 156 / 200 | iteration 40 / 171 | Total Loss: 2.413684844970703 | KNN Loss: 2.409841775894165 | CLS Loss: 0.0038430080749094486\n",
      "Epoch 156 / 200 | iteration 50 / 171 | Total Loss: 2.449755907058716 | KNN Loss: 2.4446308612823486 | CLS Loss: 0.005125163588672876\n",
      "Epoch 156 / 200 | iteration 60 / 171 | Total Loss: 2.3922030925750732 | KNN Loss: 2.387766122817993 | CLS Loss: 0.004436911549419165\n",
      "Epoch 156 / 200 | iteration 70 / 171 | Total Loss: 2.404703378677368 | KNN Loss: 2.3970041275024414 | CLS Loss: 0.0076991720125079155\n",
      "Epoch 156 / 200 | iteration 80 / 171 | Total Loss: 2.416010856628418 | KNN Loss: 2.408850908279419 | CLS Loss: 0.00715983472764492\n",
      "Epoch 156 / 200 | iteration 90 / 171 | Total Loss: 2.3936214447021484 | KNN Loss: 2.36966872215271 | CLS Loss: 0.02395262010395527\n",
      "Epoch 156 / 200 | iteration 100 / 171 | Total Loss: 2.3998935222625732 | KNN Loss: 2.3832855224609375 | CLS Loss: 0.016608113422989845\n",
      "Epoch 156 / 200 | iteration 110 / 171 | Total Loss: 2.3918581008911133 | KNN Loss: 2.386094331741333 | CLS Loss: 0.005763833411037922\n",
      "Epoch 156 / 200 | iteration 120 / 171 | Total Loss: 2.3987958431243896 | KNN Loss: 2.39501690864563 | CLS Loss: 0.0037789621856063604\n",
      "Epoch 156 / 200 | iteration 130 / 171 | Total Loss: 2.4028520584106445 | KNN Loss: 2.397292375564575 | CLS Loss: 0.005559626035392284\n",
      "Epoch 156 / 200 | iteration 140 / 171 | Total Loss: 2.436347484588623 | KNN Loss: 2.422630548477173 | CLS Loss: 0.013716830871999264\n",
      "Epoch 156 / 200 | iteration 150 / 171 | Total Loss: 2.3982765674591064 | KNN Loss: 2.3917276859283447 | CLS Loss: 0.006548927165567875\n",
      "Epoch 156 / 200 | iteration 160 / 171 | Total Loss: 2.419218063354492 | KNN Loss: 2.4026143550872803 | CLS Loss: 0.016603775322437286\n",
      "Epoch 156 / 200 | iteration 170 / 171 | Total Loss: 2.3771233558654785 | KNN Loss: 2.3639652729034424 | CLS Loss: 0.013158155605196953\n",
      "Epoch: 156, Loss: 2.4107, Train: 0.9955, Valid: 0.9843, Best: 0.9878\n",
      "Epoch 157 / 200 | iteration 0 / 171 | Total Loss: 2.4158732891082764 | KNN Loss: 2.395176649093628 | CLS Loss: 0.020696671679615974\n",
      "Epoch 157 / 200 | iteration 10 / 171 | Total Loss: 2.3912250995635986 | KNN Loss: 2.3727121353149414 | CLS Loss: 0.018512917682528496\n",
      "Epoch 157 / 200 | iteration 20 / 171 | Total Loss: 2.379490852355957 | KNN Loss: 2.3653948307037354 | CLS Loss: 0.014095956459641457\n",
      "Epoch 157 / 200 | iteration 30 / 171 | Total Loss: 2.408628463745117 | KNN Loss: 2.3865468502044678 | CLS Loss: 0.022081514820456505\n",
      "Epoch 157 / 200 | iteration 40 / 171 | Total Loss: 2.3939003944396973 | KNN Loss: 2.3788669109344482 | CLS Loss: 0.015033449046313763\n",
      "Epoch 157 / 200 | iteration 50 / 171 | Total Loss: 2.4152815341949463 | KNN Loss: 2.4022834300994873 | CLS Loss: 0.012998214922845364\n",
      "Epoch 157 / 200 | iteration 60 / 171 | Total Loss: 2.4453084468841553 | KNN Loss: 2.422959804534912 | CLS Loss: 0.02234857715666294\n",
      "Epoch 157 / 200 | iteration 70 / 171 | Total Loss: 2.432079792022705 | KNN Loss: 2.3901805877685547 | CLS Loss: 0.041899099946022034\n",
      "Epoch 157 / 200 | iteration 80 / 171 | Total Loss: 2.4053165912628174 | KNN Loss: 2.401928186416626 | CLS Loss: 0.003388311481103301\n",
      "Epoch 157 / 200 | iteration 90 / 171 | Total Loss: 2.4245283603668213 | KNN Loss: 2.4139890670776367 | CLS Loss: 0.010539321228861809\n",
      "Epoch 157 / 200 | iteration 100 / 171 | Total Loss: 2.407701015472412 | KNN Loss: 2.402320146560669 | CLS Loss: 0.005380932707339525\n",
      "Epoch 157 / 200 | iteration 110 / 171 | Total Loss: 2.380784511566162 | KNN Loss: 2.373349189758301 | CLS Loss: 0.007435415871441364\n",
      "Epoch 157 / 200 | iteration 120 / 171 | Total Loss: 2.382580518722534 | KNN Loss: 2.371724843978882 | CLS Loss: 0.010855590924620628\n",
      "Epoch 157 / 200 | iteration 130 / 171 | Total Loss: 2.4135210514068604 | KNN Loss: 2.4122121334075928 | CLS Loss: 0.0013089266140013933\n",
      "Epoch 157 / 200 | iteration 140 / 171 | Total Loss: 2.392986297607422 | KNN Loss: 2.383563995361328 | CLS Loss: 0.0094224214553833\n",
      "Epoch 157 / 200 | iteration 150 / 171 | Total Loss: 2.409146308898926 | KNN Loss: 2.40157413482666 | CLS Loss: 0.0075722020119428635\n",
      "Epoch 157 / 200 | iteration 160 / 171 | Total Loss: 2.400120735168457 | KNN Loss: 2.384178638458252 | CLS Loss: 0.01594218611717224\n",
      "Epoch 157 / 200 | iteration 170 / 171 | Total Loss: 2.4529402256011963 | KNN Loss: 2.4480278491973877 | CLS Loss: 0.004912491887807846\n",
      "Epoch: 157, Loss: 2.4091, Train: 0.9972, Valid: 0.9854, Best: 0.9878\n",
      "Epoch 158 / 200 | iteration 0 / 171 | Total Loss: 2.412257671356201 | KNN Loss: 2.4029340744018555 | CLS Loss: 0.00932367704808712\n",
      "Epoch 158 / 200 | iteration 10 / 171 | Total Loss: 2.403726100921631 | KNN Loss: 2.3906381130218506 | CLS Loss: 0.013087878935039043\n",
      "Epoch 158 / 200 | iteration 20 / 171 | Total Loss: 2.4298763275146484 | KNN Loss: 2.41475510597229 | CLS Loss: 0.015121221542358398\n",
      "Epoch 158 / 200 | iteration 30 / 171 | Total Loss: 2.409575939178467 | KNN Loss: 2.408773183822632 | CLS Loss: 0.000802765367552638\n",
      "Epoch 158 / 200 | iteration 40 / 171 | Total Loss: 2.3915159702301025 | KNN Loss: 2.3797171115875244 | CLS Loss: 0.011798867955803871\n",
      "Epoch 158 / 200 | iteration 50 / 171 | Total Loss: 2.4185423851013184 | KNN Loss: 2.409696102142334 | CLS Loss: 0.008846274577081203\n",
      "Epoch 158 / 200 | iteration 60 / 171 | Total Loss: 2.4139628410339355 | KNN Loss: 2.4092917442321777 | CLS Loss: 0.004671168513596058\n",
      "Epoch 158 / 200 | iteration 70 / 171 | Total Loss: 2.4044179916381836 | KNN Loss: 2.3919601440429688 | CLS Loss: 0.012457759119570255\n",
      "Epoch 158 / 200 | iteration 80 / 171 | Total Loss: 2.3776254653930664 | KNN Loss: 2.362151861190796 | CLS Loss: 0.01547370757907629\n",
      "Epoch 158 / 200 | iteration 90 / 171 | Total Loss: 2.435884475708008 | KNN Loss: 2.427917957305908 | CLS Loss: 0.007966580800712109\n",
      "Epoch 158 / 200 | iteration 100 / 171 | Total Loss: 2.4285378456115723 | KNN Loss: 2.4179019927978516 | CLS Loss: 0.01063588447868824\n",
      "Epoch 158 / 200 | iteration 110 / 171 | Total Loss: 2.4000163078308105 | KNN Loss: 2.3990981578826904 | CLS Loss: 0.0009180905180983245\n",
      "Epoch 158 / 200 | iteration 120 / 171 | Total Loss: 2.3963170051574707 | KNN Loss: 2.382140874862671 | CLS Loss: 0.014176071621477604\n",
      "Epoch 158 / 200 | iteration 130 / 171 | Total Loss: 2.406590223312378 | KNN Loss: 2.391909122467041 | CLS Loss: 0.014681175351142883\n",
      "Epoch 158 / 200 | iteration 140 / 171 | Total Loss: 2.427568197250366 | KNN Loss: 2.4237029552459717 | CLS Loss: 0.003865156089887023\n",
      "Epoch 158 / 200 | iteration 150 / 171 | Total Loss: 2.4279472827911377 | KNN Loss: 2.4177627563476562 | CLS Loss: 0.01018447708338499\n",
      "Epoch 158 / 200 | iteration 160 / 171 | Total Loss: 2.4301187992095947 | KNN Loss: 2.4263765811920166 | CLS Loss: 0.0037422801833599806\n",
      "Epoch 158 / 200 | iteration 170 / 171 | Total Loss: 2.4395124912261963 | KNN Loss: 2.4137582778930664 | CLS Loss: 0.02575429528951645\n",
      "Epoch: 158, Loss: 2.4051, Train: 0.9967, Valid: 0.9867, Best: 0.9878\n",
      "Epoch 159 / 200 | iteration 0 / 171 | Total Loss: 2.422482490539551 | KNN Loss: 2.411762237548828 | CLS Loss: 0.010720213875174522\n",
      "Epoch 159 / 200 | iteration 10 / 171 | Total Loss: 2.41677188873291 | KNN Loss: 2.4096481800079346 | CLS Loss: 0.007123653776943684\n",
      "Epoch 159 / 200 | iteration 20 / 171 | Total Loss: 2.4051601886749268 | KNN Loss: 2.3906166553497314 | CLS Loss: 0.014543485827744007\n",
      "Epoch 159 / 200 | iteration 30 / 171 | Total Loss: 2.4141693115234375 | KNN Loss: 2.408649206161499 | CLS Loss: 0.005520041100680828\n",
      "Epoch 159 / 200 | iteration 40 / 171 | Total Loss: 2.406139373779297 | KNN Loss: 2.4041669368743896 | CLS Loss: 0.0019723563455045223\n",
      "Epoch 159 / 200 | iteration 50 / 171 | Total Loss: 2.4321181774139404 | KNN Loss: 2.4306089878082275 | CLS Loss: 0.0015093076508492231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159 / 200 | iteration 60 / 171 | Total Loss: 2.3926849365234375 | KNN Loss: 2.371378183364868 | CLS Loss: 0.021306656301021576\n",
      "Epoch 159 / 200 | iteration 70 / 171 | Total Loss: 2.419893503189087 | KNN Loss: 2.403132915496826 | CLS Loss: 0.01676054857671261\n",
      "Epoch 159 / 200 | iteration 80 / 171 | Total Loss: 2.416393756866455 | KNN Loss: 2.4046285152435303 | CLS Loss: 0.011765331961214542\n",
      "Epoch 159 / 200 | iteration 90 / 171 | Total Loss: 2.4224112033843994 | KNN Loss: 2.420743465423584 | CLS Loss: 0.0016677876701578498\n",
      "Epoch 159 / 200 | iteration 100 / 171 | Total Loss: 2.430586576461792 | KNN Loss: 2.415789842605591 | CLS Loss: 0.014796807430684566\n",
      "Epoch 159 / 200 | iteration 110 / 171 | Total Loss: 2.4244868755340576 | KNN Loss: 2.408724308013916 | CLS Loss: 0.01576252467930317\n",
      "Epoch 159 / 200 | iteration 120 / 171 | Total Loss: 2.384993314743042 | KNN Loss: 2.3762307167053223 | CLS Loss: 0.008762693032622337\n",
      "Epoch 159 / 200 | iteration 130 / 171 | Total Loss: 2.359407424926758 | KNN Loss: 2.350574016571045 | CLS Loss: 0.0088333860039711\n",
      "Epoch 159 / 200 | iteration 140 / 171 | Total Loss: 2.373671770095825 | KNN Loss: 2.3673582077026367 | CLS Loss: 0.006313564721494913\n",
      "Epoch 159 / 200 | iteration 150 / 171 | Total Loss: 2.3949413299560547 | KNN Loss: 2.3887131214141846 | CLS Loss: 0.006228127051144838\n",
      "Epoch 159 / 200 | iteration 160 / 171 | Total Loss: 2.4243485927581787 | KNN Loss: 2.4135396480560303 | CLS Loss: 0.01080887671560049\n",
      "Epoch 159 / 200 | iteration 170 / 171 | Total Loss: 2.4374279975891113 | KNN Loss: 2.4258179664611816 | CLS Loss: 0.011610056273639202\n",
      "Epoch: 159, Loss: 2.4083, Train: 0.9968, Valid: 0.9860, Best: 0.9878\n",
      "Epoch 160 / 200 | iteration 0 / 171 | Total Loss: 2.379067897796631 | KNN Loss: 2.3720521926879883 | CLS Loss: 0.007015795912593603\n",
      "Epoch 160 / 200 | iteration 10 / 171 | Total Loss: 2.392543077468872 | KNN Loss: 2.391782760620117 | CLS Loss: 0.0007602923433296382\n",
      "Epoch 160 / 200 | iteration 20 / 171 | Total Loss: 2.3730123043060303 | KNN Loss: 2.364954710006714 | CLS Loss: 0.008057656697928905\n",
      "Epoch 160 / 200 | iteration 30 / 171 | Total Loss: 2.428102493286133 | KNN Loss: 2.42642879486084 | CLS Loss: 0.0016737787518650293\n",
      "Epoch 160 / 200 | iteration 40 / 171 | Total Loss: 2.40971302986145 | KNN Loss: 2.3918519020080566 | CLS Loss: 0.01786118373274803\n",
      "Epoch 160 / 200 | iteration 50 / 171 | Total Loss: 2.403493642807007 | KNN Loss: 2.3773343563079834 | CLS Loss: 0.02615923434495926\n",
      "Epoch 160 / 200 | iteration 60 / 171 | Total Loss: 2.42846941947937 | KNN Loss: 2.4214911460876465 | CLS Loss: 0.006978336721658707\n",
      "Epoch 160 / 200 | iteration 70 / 171 | Total Loss: 2.4669454097747803 | KNN Loss: 2.450913906097412 | CLS Loss: 0.01603151671588421\n",
      "Epoch 160 / 200 | iteration 80 / 171 | Total Loss: 2.4366555213928223 | KNN Loss: 2.4087817668914795 | CLS Loss: 0.027873648330569267\n",
      "Epoch 160 / 200 | iteration 90 / 171 | Total Loss: 2.4138131141662598 | KNN Loss: 2.385615110397339 | CLS Loss: 0.028198009356856346\n",
      "Epoch 160 / 200 | iteration 100 / 171 | Total Loss: 2.421751022338867 | KNN Loss: 2.4152092933654785 | CLS Loss: 0.006541847251355648\n",
      "Epoch 160 / 200 | iteration 110 / 171 | Total Loss: 2.412140130996704 | KNN Loss: 2.4041500091552734 | CLS Loss: 0.00799008458852768\n",
      "Epoch 160 / 200 | iteration 120 / 171 | Total Loss: 2.4159767627716064 | KNN Loss: 2.4008681774139404 | CLS Loss: 0.015108538791537285\n",
      "Epoch 160 / 200 | iteration 130 / 171 | Total Loss: 2.394939422607422 | KNN Loss: 2.393873453140259 | CLS Loss: 0.001066038734279573\n",
      "Epoch 160 / 200 | iteration 140 / 171 | Total Loss: 2.466094493865967 | KNN Loss: 2.4395089149475098 | CLS Loss: 0.026585614308714867\n",
      "Epoch 160 / 200 | iteration 150 / 171 | Total Loss: 2.444113254547119 | KNN Loss: 2.4119842052459717 | CLS Loss: 0.03212897107005119\n",
      "Epoch 160 / 200 | iteration 160 / 171 | Total Loss: 2.3970189094543457 | KNN Loss: 2.384212017059326 | CLS Loss: 0.012806952930986881\n",
      "Epoch 160 / 200 | iteration 170 / 171 | Total Loss: 2.382899761199951 | KNN Loss: 2.3739664554595947 | CLS Loss: 0.00893320981413126\n",
      "Epoch: 160, Loss: 2.4121, Train: 0.9972, Valid: 0.9873, Best: 0.9878\n",
      "Epoch 161 / 200 | iteration 0 / 171 | Total Loss: 2.3928122520446777 | KNN Loss: 2.3905551433563232 | CLS Loss: 0.0022569922730326653\n",
      "Epoch 161 / 200 | iteration 10 / 171 | Total Loss: 2.421725034713745 | KNN Loss: 2.4200456142425537 | CLS Loss: 0.0016795344417914748\n",
      "Epoch 161 / 200 | iteration 20 / 171 | Total Loss: 2.411550521850586 | KNN Loss: 2.400298595428467 | CLS Loss: 0.011251970194280148\n",
      "Epoch 161 / 200 | iteration 30 / 171 | Total Loss: 2.430983304977417 | KNN Loss: 2.426818609237671 | CLS Loss: 0.0041647315956652164\n",
      "Epoch 161 / 200 | iteration 40 / 171 | Total Loss: 2.432497024536133 | KNN Loss: 2.429837465286255 | CLS Loss: 0.0026595655363053083\n",
      "Epoch 161 / 200 | iteration 50 / 171 | Total Loss: 2.420799970626831 | KNN Loss: 2.418760061264038 | CLS Loss: 0.002039903774857521\n",
      "Epoch 161 / 200 | iteration 60 / 171 | Total Loss: 2.4018383026123047 | KNN Loss: 2.393756151199341 | CLS Loss: 0.00808223057538271\n",
      "Epoch 161 / 200 | iteration 70 / 171 | Total Loss: 2.4348931312561035 | KNN Loss: 2.427739143371582 | CLS Loss: 0.007153946440666914\n",
      "Epoch 161 / 200 | iteration 80 / 171 | Total Loss: 2.455021858215332 | KNN Loss: 2.4380929470062256 | CLS Loss: 0.01692883111536503\n",
      "Epoch 161 / 200 | iteration 90 / 171 | Total Loss: 2.431522846221924 | KNN Loss: 2.413266658782959 | CLS Loss: 0.018256140872836113\n",
      "Epoch 161 / 200 | iteration 100 / 171 | Total Loss: 2.3922245502471924 | KNN Loss: 2.3907647132873535 | CLS Loss: 0.0014597445260733366\n",
      "Epoch 161 / 200 | iteration 110 / 171 | Total Loss: 2.367321252822876 | KNN Loss: 2.3557801246643066 | CLS Loss: 0.011541222222149372\n",
      "Epoch 161 / 200 | iteration 120 / 171 | Total Loss: 2.430858850479126 | KNN Loss: 2.394277334213257 | CLS Loss: 0.03658156096935272\n",
      "Epoch 161 / 200 | iteration 130 / 171 | Total Loss: 2.415958881378174 | KNN Loss: 2.4124557971954346 | CLS Loss: 0.003503090003505349\n",
      "Epoch 161 / 200 | iteration 140 / 171 | Total Loss: 2.398646831512451 | KNN Loss: 2.3951632976531982 | CLS Loss: 0.0034835997503250837\n",
      "Epoch 161 / 200 | iteration 150 / 171 | Total Loss: 2.4097647666931152 | KNN Loss: 2.401937484741211 | CLS Loss: 0.007827220484614372\n",
      "Epoch 161 / 200 | iteration 160 / 171 | Total Loss: 2.4523632526397705 | KNN Loss: 2.434798002243042 | CLS Loss: 0.017565293237566948\n",
      "Epoch 161 / 200 | iteration 170 / 171 | Total Loss: 2.4249494075775146 | KNN Loss: 2.4204516410827637 | CLS Loss: 0.004497791640460491\n",
      "Epoch: 161, Loss: 2.4115, Train: 0.9969, Valid: 0.9871, Best: 0.9878\n",
      "Epoch 162 / 200 | iteration 0 / 171 | Total Loss: 2.415076971054077 | KNN Loss: 2.4083104133605957 | CLS Loss: 0.006766676437109709\n",
      "Epoch 162 / 200 | iteration 10 / 171 | Total Loss: 2.4119250774383545 | KNN Loss: 2.4048025608062744 | CLS Loss: 0.007122513838112354\n",
      "Epoch 162 / 200 | iteration 20 / 171 | Total Loss: 2.4337615966796875 | KNN Loss: 2.4288413524627686 | CLS Loss: 0.00492024514824152\n",
      "Epoch 162 / 200 | iteration 30 / 171 | Total Loss: 2.420470952987671 | KNN Loss: 2.406996726989746 | CLS Loss: 0.01347413845360279\n",
      "Epoch 162 / 200 | iteration 40 / 171 | Total Loss: 2.3829386234283447 | KNN Loss: 2.382054567337036 | CLS Loss: 0.0008841255912557244\n",
      "Epoch 162 / 200 | iteration 50 / 171 | Total Loss: 2.395690679550171 | KNN Loss: 2.372871160507202 | CLS Loss: 0.02281963638961315\n",
      "Epoch 162 / 200 | iteration 60 / 171 | Total Loss: 2.4045636653900146 | KNN Loss: 2.3986148834228516 | CLS Loss: 0.005948697682470083\n",
      "Epoch 162 / 200 | iteration 70 / 171 | Total Loss: 2.4188284873962402 | KNN Loss: 2.4129021167755127 | CLS Loss: 0.0059264893643558025\n",
      "Epoch 162 / 200 | iteration 80 / 171 | Total Loss: 2.4001901149749756 | KNN Loss: 2.3958487510681152 | CLS Loss: 0.004341354593634605\n",
      "Epoch 162 / 200 | iteration 90 / 171 | Total Loss: 2.406911611557007 | KNN Loss: 2.4015917778015137 | CLS Loss: 0.0053198984824121\n",
      "Epoch 162 / 200 | iteration 100 / 171 | Total Loss: 2.4023141860961914 | KNN Loss: 2.395247220993042 | CLS Loss: 0.0070668598636984825\n",
      "Epoch 162 / 200 | iteration 110 / 171 | Total Loss: 2.4255499839782715 | KNN Loss: 2.404029607772827 | CLS Loss: 0.021520452573895454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162 / 200 | iteration 120 / 171 | Total Loss: 2.4279768466949463 | KNN Loss: 2.416605234146118 | CLS Loss: 0.011371677741408348\n",
      "Epoch 162 / 200 | iteration 130 / 171 | Total Loss: 2.3861067295074463 | KNN Loss: 2.3776297569274902 | CLS Loss: 0.008476980961859226\n",
      "Epoch 162 / 200 | iteration 140 / 171 | Total Loss: 2.4356577396392822 | KNN Loss: 2.4158670902252197 | CLS Loss: 0.01979055628180504\n",
      "Epoch 162 / 200 | iteration 150 / 171 | Total Loss: 2.4314465522766113 | KNN Loss: 2.4183788299560547 | CLS Loss: 0.013067708350718021\n",
      "Epoch 162 / 200 | iteration 160 / 171 | Total Loss: 2.4127767086029053 | KNN Loss: 2.4097578525543213 | CLS Loss: 0.0030187482479959726\n",
      "Epoch 162 / 200 | iteration 170 / 171 | Total Loss: 2.4368746280670166 | KNN Loss: 2.4188387393951416 | CLS Loss: 0.018035883083939552\n",
      "Epoch: 162, Loss: 2.4079, Train: 0.9969, Valid: 0.9867, Best: 0.9878\n",
      "Epoch 163 / 200 | iteration 0 / 171 | Total Loss: 2.3787312507629395 | KNN Loss: 2.3642079830169678 | CLS Loss: 0.014523287303745747\n",
      "Epoch 163 / 200 | iteration 10 / 171 | Total Loss: 2.40596079826355 | KNN Loss: 2.3887577056884766 | CLS Loss: 0.017203159630298615\n",
      "Epoch 163 / 200 | iteration 20 / 171 | Total Loss: 2.417163848876953 | KNN Loss: 2.413220167160034 | CLS Loss: 0.003943787422031164\n",
      "Epoch 163 / 200 | iteration 30 / 171 | Total Loss: 2.406630516052246 | KNN Loss: 2.398599147796631 | CLS Loss: 0.008031325414776802\n",
      "Epoch 163 / 200 | iteration 40 / 171 | Total Loss: 2.415790319442749 | KNN Loss: 2.4081175327301025 | CLS Loss: 0.007672710344195366\n",
      "Epoch 163 / 200 | iteration 50 / 171 | Total Loss: 2.3996145725250244 | KNN Loss: 2.3816535472869873 | CLS Loss: 0.01796107180416584\n",
      "Epoch 163 / 200 | iteration 60 / 171 | Total Loss: 2.4171833992004395 | KNN Loss: 2.406733512878418 | CLS Loss: 0.010449769906699657\n",
      "Epoch 163 / 200 | iteration 70 / 171 | Total Loss: 2.3835837841033936 | KNN Loss: 2.3768200874328613 | CLS Loss: 0.00676371855661273\n",
      "Epoch 163 / 200 | iteration 80 / 171 | Total Loss: 2.3607161045074463 | KNN Loss: 2.3597500324249268 | CLS Loss: 0.0009660545620135963\n",
      "Epoch 163 / 200 | iteration 90 / 171 | Total Loss: 2.4179954528808594 | KNN Loss: 2.4057552814483643 | CLS Loss: 0.012240252457559109\n",
      "Epoch 163 / 200 | iteration 100 / 171 | Total Loss: 2.418778419494629 | KNN Loss: 2.4115421772003174 | CLS Loss: 0.007236241362988949\n",
      "Epoch 163 / 200 | iteration 110 / 171 | Total Loss: 2.425554037094116 | KNN Loss: 2.421051025390625 | CLS Loss: 0.004502900410443544\n",
      "Epoch 163 / 200 | iteration 120 / 171 | Total Loss: 2.3866090774536133 | KNN Loss: 2.3774030208587646 | CLS Loss: 0.009206175804138184\n",
      "Epoch 163 / 200 | iteration 130 / 171 | Total Loss: 2.424750328063965 | KNN Loss: 2.4040231704711914 | CLS Loss: 0.020727254450321198\n",
      "Epoch 163 / 200 | iteration 140 / 171 | Total Loss: 2.434394598007202 | KNN Loss: 2.4303817749023438 | CLS Loss: 0.004012914374470711\n",
      "Epoch 163 / 200 | iteration 150 / 171 | Total Loss: 2.423020362854004 | KNN Loss: 2.3965163230895996 | CLS Loss: 0.026504138484597206\n",
      "Epoch 163 / 200 | iteration 160 / 171 | Total Loss: 2.3778388500213623 | KNN Loss: 2.366849422454834 | CLS Loss: 0.01098947785794735\n",
      "Epoch 163 / 200 | iteration 170 / 171 | Total Loss: 2.417008876800537 | KNN Loss: 2.3926172256469727 | CLS Loss: 0.024391764774918556\n",
      "Epoch: 163, Loss: 2.4055, Train: 0.9964, Valid: 0.9865, Best: 0.9878\n",
      "Epoch 164 / 200 | iteration 0 / 171 | Total Loss: 2.3954880237579346 | KNN Loss: 2.386608123779297 | CLS Loss: 0.008879870176315308\n",
      "Epoch 164 / 200 | iteration 10 / 171 | Total Loss: 2.4132211208343506 | KNN Loss: 2.391655206680298 | CLS Loss: 0.021565837785601616\n",
      "Epoch 164 / 200 | iteration 20 / 171 | Total Loss: 2.419511556625366 | KNN Loss: 2.4040088653564453 | CLS Loss: 0.01550265122205019\n",
      "Epoch 164 / 200 | iteration 30 / 171 | Total Loss: 2.3875038623809814 | KNN Loss: 2.3837053775787354 | CLS Loss: 0.0037984454538673162\n",
      "Epoch 164 / 200 | iteration 40 / 171 | Total Loss: 2.4249348640441895 | KNN Loss: 2.4161393642425537 | CLS Loss: 0.008795597590506077\n",
      "Epoch 164 / 200 | iteration 50 / 171 | Total Loss: 2.4285008907318115 | KNN Loss: 2.424014091491699 | CLS Loss: 0.004486775491386652\n",
      "Epoch 164 / 200 | iteration 60 / 171 | Total Loss: 2.4137213230133057 | KNN Loss: 2.4104864597320557 | CLS Loss: 0.0032347836531698704\n",
      "Epoch 164 / 200 | iteration 70 / 171 | Total Loss: 2.424010992050171 | KNN Loss: 2.4178929328918457 | CLS Loss: 0.006118082907050848\n",
      "Epoch 164 / 200 | iteration 80 / 171 | Total Loss: 2.403473138809204 | KNN Loss: 2.3972370624542236 | CLS Loss: 0.006236185319721699\n",
      "Epoch 164 / 200 | iteration 90 / 171 | Total Loss: 2.406128168106079 | KNN Loss: 2.4028337001800537 | CLS Loss: 0.003294349880889058\n",
      "Epoch 164 / 200 | iteration 100 / 171 | Total Loss: 2.3919081687927246 | KNN Loss: 2.3843462467193604 | CLS Loss: 0.007561826147139072\n",
      "Epoch 164 / 200 | iteration 110 / 171 | Total Loss: 2.4333643913269043 | KNN Loss: 2.419635772705078 | CLS Loss: 0.01372867077589035\n",
      "Epoch 164 / 200 | iteration 120 / 171 | Total Loss: 2.417372703552246 | KNN Loss: 2.4076297283172607 | CLS Loss: 0.009742865338921547\n",
      "Epoch 164 / 200 | iteration 130 / 171 | Total Loss: 2.445848226547241 | KNN Loss: 2.432680368423462 | CLS Loss: 0.013167837634682655\n",
      "Epoch 164 / 200 | iteration 140 / 171 | Total Loss: 2.4380688667297363 | KNN Loss: 2.4173834323883057 | CLS Loss: 0.020685458555817604\n",
      "Epoch 164 / 200 | iteration 150 / 171 | Total Loss: 2.4530868530273438 | KNN Loss: 2.3985936641693115 | CLS Loss: 0.05449307709932327\n",
      "Epoch 164 / 200 | iteration 160 / 171 | Total Loss: 2.3869576454162598 | KNN Loss: 2.382500171661377 | CLS Loss: 0.004457483999431133\n",
      "Epoch 164 / 200 | iteration 170 / 171 | Total Loss: 2.398712635040283 | KNN Loss: 2.3879194259643555 | CLS Loss: 0.010793117806315422\n",
      "Epoch: 164, Loss: 2.4125, Train: 0.9970, Valid: 0.9862, Best: 0.9878\n",
      "Epoch 165 / 200 | iteration 0 / 171 | Total Loss: 2.38608455657959 | KNN Loss: 2.3818960189819336 | CLS Loss: 0.004188614897429943\n",
      "Epoch 165 / 200 | iteration 10 / 171 | Total Loss: 2.387532949447632 | KNN Loss: 2.370918035507202 | CLS Loss: 0.01661486178636551\n",
      "Epoch 165 / 200 | iteration 20 / 171 | Total Loss: 2.390428066253662 | KNN Loss: 2.387960910797119 | CLS Loss: 0.0024671282153576612\n",
      "Epoch 165 / 200 | iteration 30 / 171 | Total Loss: 2.413301944732666 | KNN Loss: 2.4095425605773926 | CLS Loss: 0.0037594428285956383\n",
      "Epoch 165 / 200 | iteration 40 / 171 | Total Loss: 2.450056314468384 | KNN Loss: 2.426942825317383 | CLS Loss: 0.02311352826654911\n",
      "Epoch 165 / 200 | iteration 50 / 171 | Total Loss: 2.3928041458129883 | KNN Loss: 2.389460802078247 | CLS Loss: 0.003343297401443124\n",
      "Epoch 165 / 200 | iteration 60 / 171 | Total Loss: 2.3763844966888428 | KNN Loss: 2.358241081237793 | CLS Loss: 0.018143318593502045\n",
      "Epoch 165 / 200 | iteration 70 / 171 | Total Loss: 2.4055421352386475 | KNN Loss: 2.402005434036255 | CLS Loss: 0.0035368003882467747\n",
      "Epoch 165 / 200 | iteration 80 / 171 | Total Loss: 2.4458818435668945 | KNN Loss: 2.439073324203491 | CLS Loss: 0.006808508653193712\n",
      "Epoch 165 / 200 | iteration 90 / 171 | Total Loss: 2.406963348388672 | KNN Loss: 2.4040632247924805 | CLS Loss: 0.002900131046772003\n",
      "Epoch 165 / 200 | iteration 100 / 171 | Total Loss: 2.454115390777588 | KNN Loss: 2.4449656009674072 | CLS Loss: 0.009149688296020031\n",
      "Epoch 165 / 200 | iteration 110 / 171 | Total Loss: 2.3965234756469727 | KNN Loss: 2.3857762813568115 | CLS Loss: 0.010747301392257214\n",
      "Epoch 165 / 200 | iteration 120 / 171 | Total Loss: 2.3782026767730713 | KNN Loss: 2.3760781288146973 | CLS Loss: 0.002124558202922344\n",
      "Epoch 165 / 200 | iteration 130 / 171 | Total Loss: 2.412320137023926 | KNN Loss: 2.3982994556427 | CLS Loss: 0.014020588248968124\n",
      "Epoch 165 / 200 | iteration 140 / 171 | Total Loss: 2.416578531265259 | KNN Loss: 2.4148495197296143 | CLS Loss: 0.001728951232507825\n",
      "Epoch 165 / 200 | iteration 150 / 171 | Total Loss: 2.4327452182769775 | KNN Loss: 2.4222142696380615 | CLS Loss: 0.01053091511130333\n",
      "Epoch 165 / 200 | iteration 160 / 171 | Total Loss: 2.393059730529785 | KNN Loss: 2.390202760696411 | CLS Loss: 0.0028569973073899746\n",
      "Epoch 165 / 200 | iteration 170 / 171 | Total Loss: 2.462472438812256 | KNN Loss: 2.4496512413024902 | CLS Loss: 0.012821177951991558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165, Loss: 2.4091, Train: 0.9971, Valid: 0.9860, Best: 0.9878\n",
      "Epoch 166 / 200 | iteration 0 / 171 | Total Loss: 2.4372200965881348 | KNN Loss: 2.4259555339813232 | CLS Loss: 0.011264658533036709\n",
      "Epoch 166 / 200 | iteration 10 / 171 | Total Loss: 2.3875250816345215 | KNN Loss: 2.3857245445251465 | CLS Loss: 0.0018005723832175136\n",
      "Epoch 166 / 200 | iteration 20 / 171 | Total Loss: 2.3904170989990234 | KNN Loss: 2.385345220565796 | CLS Loss: 0.005071794148534536\n",
      "Epoch 166 / 200 | iteration 30 / 171 | Total Loss: 2.3754959106445312 | KNN Loss: 2.371304750442505 | CLS Loss: 0.00419115275144577\n",
      "Epoch 166 / 200 | iteration 40 / 171 | Total Loss: 2.4166958332061768 | KNN Loss: 2.409127712249756 | CLS Loss: 0.007568098604679108\n",
      "Epoch 166 / 200 | iteration 50 / 171 | Total Loss: 2.421764612197876 | KNN Loss: 2.4106554985046387 | CLS Loss: 0.011109111830592155\n",
      "Epoch 166 / 200 | iteration 60 / 171 | Total Loss: 2.3961334228515625 | KNN Loss: 2.3910839557647705 | CLS Loss: 0.005049497354775667\n",
      "Epoch 166 / 200 | iteration 70 / 171 | Total Loss: 2.378633737564087 | KNN Loss: 2.3724398612976074 | CLS Loss: 0.006193757522851229\n",
      "Epoch 166 / 200 | iteration 80 / 171 | Total Loss: 2.4283552169799805 | KNN Loss: 2.424499273300171 | CLS Loss: 0.0038559662643820047\n",
      "Epoch 166 / 200 | iteration 90 / 171 | Total Loss: 2.3753104209899902 | KNN Loss: 2.371070384979248 | CLS Loss: 0.004240046255290508\n",
      "Epoch 166 / 200 | iteration 100 / 171 | Total Loss: 2.371565818786621 | KNN Loss: 2.3692169189453125 | CLS Loss: 0.0023490190505981445\n",
      "Epoch 166 / 200 | iteration 110 / 171 | Total Loss: 2.3888473510742188 | KNN Loss: 2.3869705200195312 | CLS Loss: 0.0018768367590382695\n",
      "Epoch 166 / 200 | iteration 120 / 171 | Total Loss: 2.4348855018615723 | KNN Loss: 2.4178128242492676 | CLS Loss: 0.01707262173295021\n",
      "Epoch 166 / 200 | iteration 130 / 171 | Total Loss: 2.3845467567443848 | KNN Loss: 2.378828287124634 | CLS Loss: 0.005718565545976162\n",
      "Epoch 166 / 200 | iteration 140 / 171 | Total Loss: 2.418625593185425 | KNN Loss: 2.4090359210968018 | CLS Loss: 0.009589594788849354\n",
      "Epoch 166 / 200 | iteration 150 / 171 | Total Loss: 2.411713123321533 | KNN Loss: 2.4101674556732178 | CLS Loss: 0.0015456974506378174\n",
      "Epoch 166 / 200 | iteration 160 / 171 | Total Loss: 2.458848237991333 | KNN Loss: 2.4500224590301514 | CLS Loss: 0.00882580317556858\n",
      "Epoch 166 / 200 | iteration 170 / 171 | Total Loss: 2.4268088340759277 | KNN Loss: 2.4076991081237793 | CLS Loss: 0.019109657034277916\n",
      "Epoch: 166, Loss: 2.4076, Train: 0.9971, Valid: 0.9863, Best: 0.9878\n",
      "Epoch 167 / 200 | iteration 0 / 171 | Total Loss: 2.4416210651397705 | KNN Loss: 2.4336585998535156 | CLS Loss: 0.007962523959577084\n",
      "Epoch 167 / 200 | iteration 10 / 171 | Total Loss: 2.4090869426727295 | KNN Loss: 2.3988335132598877 | CLS Loss: 0.010253360494971275\n",
      "Epoch 167 / 200 | iteration 20 / 171 | Total Loss: 2.408815622329712 | KNN Loss: 2.387935161590576 | CLS Loss: 0.020880404859781265\n",
      "Epoch 167 / 200 | iteration 30 / 171 | Total Loss: 2.451519727706909 | KNN Loss: 2.4328951835632324 | CLS Loss: 0.018624529242515564\n",
      "Epoch 167 / 200 | iteration 40 / 171 | Total Loss: 2.359567403793335 | KNN Loss: 2.357093095779419 | CLS Loss: 0.0024744162801653147\n",
      "Epoch 167 / 200 | iteration 50 / 171 | Total Loss: 2.4092226028442383 | KNN Loss: 2.377223491668701 | CLS Loss: 0.031998999416828156\n",
      "Epoch 167 / 200 | iteration 60 / 171 | Total Loss: 2.407031536102295 | KNN Loss: 2.3968160152435303 | CLS Loss: 0.010215440765023232\n",
      "Epoch 167 / 200 | iteration 70 / 171 | Total Loss: 2.4205195903778076 | KNN Loss: 2.411271572113037 | CLS Loss: 0.009248021058738232\n",
      "Epoch 167 / 200 | iteration 80 / 171 | Total Loss: 2.374541759490967 | KNN Loss: 2.3649797439575195 | CLS Loss: 0.009562091901898384\n",
      "Epoch 167 / 200 | iteration 90 / 171 | Total Loss: 2.402578115463257 | KNN Loss: 2.3831160068511963 | CLS Loss: 0.019462017342448235\n",
      "Epoch 167 / 200 | iteration 100 / 171 | Total Loss: 2.4172050952911377 | KNN Loss: 2.3996987342834473 | CLS Loss: 0.017506329342722893\n",
      "Epoch 167 / 200 | iteration 110 / 171 | Total Loss: 2.389374017715454 | KNN Loss: 2.380540132522583 | CLS Loss: 0.00883398950099945\n",
      "Epoch 167 / 200 | iteration 120 / 171 | Total Loss: 2.4128963947296143 | KNN Loss: 2.3964240550994873 | CLS Loss: 0.016472259536385536\n",
      "Epoch 167 / 200 | iteration 130 / 171 | Total Loss: 2.404019594192505 | KNN Loss: 2.3975820541381836 | CLS Loss: 0.006437537260353565\n",
      "Epoch 167 / 200 | iteration 140 / 171 | Total Loss: 2.365851879119873 | KNN Loss: 2.352583169937134 | CLS Loss: 0.013268821872770786\n",
      "Epoch 167 / 200 | iteration 150 / 171 | Total Loss: 2.3879382610321045 | KNN Loss: 2.3782689571380615 | CLS Loss: 0.009669357910752296\n",
      "Epoch 167 / 200 | iteration 160 / 171 | Total Loss: 2.404346227645874 | KNN Loss: 2.3952198028564453 | CLS Loss: 0.009126531891524792\n",
      "Epoch 167 / 200 | iteration 170 / 171 | Total Loss: 2.419252634048462 | KNN Loss: 2.400197744369507 | CLS Loss: 0.0190549548715353\n",
      "Epoch: 167, Loss: 2.4094, Train: 0.9962, Valid: 0.9862, Best: 0.9878\n",
      "Epoch 168 / 200 | iteration 0 / 171 | Total Loss: 2.3847427368164062 | KNN Loss: 2.3709568977355957 | CLS Loss: 0.013785920105874538\n",
      "Epoch 168 / 200 | iteration 10 / 171 | Total Loss: 2.4317626953125 | KNN Loss: 2.4212024211883545 | CLS Loss: 0.010560252703726292\n",
      "Epoch 168 / 200 | iteration 20 / 171 | Total Loss: 2.4205076694488525 | KNN Loss: 2.4141390323638916 | CLS Loss: 0.006368592381477356\n",
      "Epoch 168 / 200 | iteration 30 / 171 | Total Loss: 2.405168056488037 | KNN Loss: 2.3790478706359863 | CLS Loss: 0.02612016163766384\n",
      "Epoch 168 / 200 | iteration 40 / 171 | Total Loss: 2.400150775909424 | KNN Loss: 2.3854339122772217 | CLS Loss: 0.014716851525008678\n",
      "Epoch 168 / 200 | iteration 50 / 171 | Total Loss: 2.3753814697265625 | KNN Loss: 2.3682701587677 | CLS Loss: 0.007111320737749338\n",
      "Epoch 168 / 200 | iteration 60 / 171 | Total Loss: 2.4127297401428223 | KNN Loss: 2.398463010787964 | CLS Loss: 0.014266704209148884\n",
      "Epoch 168 / 200 | iteration 70 / 171 | Total Loss: 2.4205663204193115 | KNN Loss: 2.4095089435577393 | CLS Loss: 0.011057321913540363\n",
      "Epoch 168 / 200 | iteration 80 / 171 | Total Loss: 2.4170734882354736 | KNN Loss: 2.4033780097961426 | CLS Loss: 0.013695591129362583\n",
      "Epoch 168 / 200 | iteration 90 / 171 | Total Loss: 2.436889886856079 | KNN Loss: 2.4245219230651855 | CLS Loss: 0.012368068099021912\n",
      "Epoch 168 / 200 | iteration 100 / 171 | Total Loss: 2.389368772506714 | KNN Loss: 2.3773579597473145 | CLS Loss: 0.012010732665657997\n",
      "Epoch 168 / 200 | iteration 110 / 171 | Total Loss: 2.395217180252075 | KNN Loss: 2.388150215148926 | CLS Loss: 0.00706707825884223\n",
      "Epoch 168 / 200 | iteration 120 / 171 | Total Loss: 2.3912696838378906 | KNN Loss: 2.373727321624756 | CLS Loss: 0.017542263492941856\n",
      "Epoch 168 / 200 | iteration 130 / 171 | Total Loss: 2.372735023498535 | KNN Loss: 2.3712801933288574 | CLS Loss: 0.001454716781154275\n",
      "Epoch 168 / 200 | iteration 140 / 171 | Total Loss: 2.402202606201172 | KNN Loss: 2.382509469985962 | CLS Loss: 0.019693227484822273\n",
      "Epoch 168 / 200 | iteration 150 / 171 | Total Loss: 2.4212377071380615 | KNN Loss: 2.4117953777313232 | CLS Loss: 0.009442326612770557\n",
      "Epoch 168 / 200 | iteration 160 / 171 | Total Loss: 2.4501900672912598 | KNN Loss: 2.440507650375366 | CLS Loss: 0.009682347066700459\n",
      "Epoch 168 / 200 | iteration 170 / 171 | Total Loss: 2.403149366378784 | KNN Loss: 2.3965091705322266 | CLS Loss: 0.006640089210122824\n",
      "Epoch: 168, Loss: 2.4080, Train: 0.9967, Valid: 0.9867, Best: 0.9878\n",
      "Epoch 169 / 200 | iteration 0 / 171 | Total Loss: 2.4171016216278076 | KNN Loss: 2.404768705368042 | CLS Loss: 0.012332874350249767\n",
      "Epoch 169 / 200 | iteration 10 / 171 | Total Loss: 2.422273874282837 | KNN Loss: 2.4118905067443848 | CLS Loss: 0.010383469052612782\n",
      "Epoch 169 / 200 | iteration 20 / 171 | Total Loss: 2.4203152656555176 | KNN Loss: 2.412721872329712 | CLS Loss: 0.007593417074531317\n",
      "Epoch 169 / 200 | iteration 30 / 171 | Total Loss: 2.3903000354766846 | KNN Loss: 2.3800148963928223 | CLS Loss: 0.01028513628989458\n",
      "Epoch 169 / 200 | iteration 40 / 171 | Total Loss: 2.3752031326293945 | KNN Loss: 2.3720881938934326 | CLS Loss: 0.003114979714155197\n",
      "Epoch 169 / 200 | iteration 50 / 171 | Total Loss: 2.3702807426452637 | KNN Loss: 2.3583984375 | CLS Loss: 0.011882190592586994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 / 200 | iteration 60 / 171 | Total Loss: 2.4314417839050293 | KNN Loss: 2.4178848266601562 | CLS Loss: 0.013556952588260174\n",
      "Epoch 169 / 200 | iteration 70 / 171 | Total Loss: 2.3991620540618896 | KNN Loss: 2.3952479362487793 | CLS Loss: 0.003914100117981434\n",
      "Epoch 169 / 200 | iteration 80 / 171 | Total Loss: 2.413848876953125 | KNN Loss: 2.4015579223632812 | CLS Loss: 0.012291026301681995\n",
      "Epoch 169 / 200 | iteration 90 / 171 | Total Loss: 2.384444236755371 | KNN Loss: 2.3831424713134766 | CLS Loss: 0.001301768934354186\n",
      "Epoch 169 / 200 | iteration 100 / 171 | Total Loss: 2.3608477115631104 | KNN Loss: 2.343308448791504 | CLS Loss: 0.01753917522728443\n",
      "Epoch 169 / 200 | iteration 110 / 171 | Total Loss: 2.402322292327881 | KNN Loss: 2.399563789367676 | CLS Loss: 0.0027585593052208424\n",
      "Epoch 169 / 200 | iteration 120 / 171 | Total Loss: 2.3921091556549072 | KNN Loss: 2.3855252265930176 | CLS Loss: 0.006583996117115021\n",
      "Epoch 169 / 200 | iteration 130 / 171 | Total Loss: 2.3984954357147217 | KNN Loss: 2.397080421447754 | CLS Loss: 0.0014150821371003985\n",
      "Epoch 169 / 200 | iteration 140 / 171 | Total Loss: 2.4195444583892822 | KNN Loss: 2.3974616527557373 | CLS Loss: 0.022082868963479996\n",
      "Epoch 169 / 200 | iteration 150 / 171 | Total Loss: 2.394745111465454 | KNN Loss: 2.3839235305786133 | CLS Loss: 0.010821552015841007\n",
      "Epoch 169 / 200 | iteration 160 / 171 | Total Loss: 2.397892951965332 | KNN Loss: 2.396019697189331 | CLS Loss: 0.001873317756690085\n",
      "Epoch 169 / 200 | iteration 170 / 171 | Total Loss: 2.3788037300109863 | KNN Loss: 2.369588613510132 | CLS Loss: 0.009215006604790688\n",
      "Epoch: 169, Loss: 2.4081, Train: 0.9978, Valid: 0.9872, Best: 0.9878\n",
      "Epoch 170 / 200 | iteration 0 / 171 | Total Loss: 2.397667169570923 | KNN Loss: 2.394009590148926 | CLS Loss: 0.0036576958373188972\n",
      "Epoch 170 / 200 | iteration 10 / 171 | Total Loss: 2.4259326457977295 | KNN Loss: 2.406018018722534 | CLS Loss: 0.019914548844099045\n",
      "Epoch 170 / 200 | iteration 20 / 171 | Total Loss: 2.376002788543701 | KNN Loss: 2.363689422607422 | CLS Loss: 0.012313412502408028\n",
      "Epoch 170 / 200 | iteration 30 / 171 | Total Loss: 2.4152889251708984 | KNN Loss: 2.4134881496429443 | CLS Loss: 0.0018007043981924653\n",
      "Epoch 170 / 200 | iteration 40 / 171 | Total Loss: 2.423647880554199 | KNN Loss: 2.4083056449890137 | CLS Loss: 0.01534227468073368\n",
      "Epoch 170 / 200 | iteration 50 / 171 | Total Loss: 2.39056134223938 | KNN Loss: 2.385258913040161 | CLS Loss: 0.00530242407694459\n",
      "Epoch 170 / 200 | iteration 60 / 171 | Total Loss: 2.415128469467163 | KNN Loss: 2.3964133262634277 | CLS Loss: 0.018715063109993935\n",
      "Epoch 170 / 200 | iteration 70 / 171 | Total Loss: 2.3975508213043213 | KNN Loss: 2.3952434062957764 | CLS Loss: 0.002307530492544174\n",
      "Epoch 170 / 200 | iteration 80 / 171 | Total Loss: 2.394583225250244 | KNN Loss: 2.3903872966766357 | CLS Loss: 0.004195935092866421\n",
      "Epoch 170 / 200 | iteration 90 / 171 | Total Loss: 2.40695858001709 | KNN Loss: 2.381131887435913 | CLS Loss: 0.02582678571343422\n",
      "Epoch 170 / 200 | iteration 100 / 171 | Total Loss: 2.415276527404785 | KNN Loss: 2.3993701934814453 | CLS Loss: 0.015906358137726784\n",
      "Epoch 170 / 200 | iteration 110 / 171 | Total Loss: 2.437201499938965 | KNN Loss: 2.4135632514953613 | CLS Loss: 0.023638354614377022\n",
      "Epoch 170 / 200 | iteration 120 / 171 | Total Loss: 2.4211161136627197 | KNN Loss: 2.41845965385437 | CLS Loss: 0.0026563641149550676\n",
      "Epoch 170 / 200 | iteration 130 / 171 | Total Loss: 2.4291305541992188 | KNN Loss: 2.401163339614868 | CLS Loss: 0.027967188507318497\n",
      "Epoch 170 / 200 | iteration 140 / 171 | Total Loss: 2.3825302124023438 | KNN Loss: 2.3744664192199707 | CLS Loss: 0.008063765242695808\n",
      "Epoch 170 / 200 | iteration 150 / 171 | Total Loss: 2.4352073669433594 | KNN Loss: 2.4190423488616943 | CLS Loss: 0.016164956614375114\n",
      "Epoch 170 / 200 | iteration 160 / 171 | Total Loss: 2.4034676551818848 | KNN Loss: 2.3884437084198 | CLS Loss: 0.015024060383439064\n",
      "Epoch 170 / 200 | iteration 170 / 171 | Total Loss: 2.3775157928466797 | KNN Loss: 2.3561251163482666 | CLS Loss: 0.021390579640865326\n",
      "Epoch: 170, Loss: 2.4064, Train: 0.9975, Valid: 0.9869, Best: 0.9878\n",
      "Epoch 171 / 200 | iteration 0 / 171 | Total Loss: 2.421006679534912 | KNN Loss: 2.4191296100616455 | CLS Loss: 0.0018769840244203806\n",
      "Epoch 171 / 200 | iteration 10 / 171 | Total Loss: 2.4500300884246826 | KNN Loss: 2.4427859783172607 | CLS Loss: 0.007244075648486614\n",
      "Epoch 171 / 200 | iteration 20 / 171 | Total Loss: 2.36386775970459 | KNN Loss: 2.3596646785736084 | CLS Loss: 0.004202976822853088\n",
      "Epoch 171 / 200 | iteration 30 / 171 | Total Loss: 2.3829236030578613 | KNN Loss: 2.368062973022461 | CLS Loss: 0.014860537834465504\n",
      "Epoch 171 / 200 | iteration 40 / 171 | Total Loss: 2.441157817840576 | KNN Loss: 2.4041035175323486 | CLS Loss: 0.03705430030822754\n",
      "Epoch 171 / 200 | iteration 50 / 171 | Total Loss: 2.391148328781128 | KNN Loss: 2.3831276893615723 | CLS Loss: 0.008020743727684021\n",
      "Epoch 171 / 200 | iteration 60 / 171 | Total Loss: 2.3805410861968994 | KNN Loss: 2.373086929321289 | CLS Loss: 0.007454256992787123\n",
      "Epoch 171 / 200 | iteration 70 / 171 | Total Loss: 2.4044294357299805 | KNN Loss: 2.3976352214813232 | CLS Loss: 0.006794122513383627\n",
      "Epoch 171 / 200 | iteration 80 / 171 | Total Loss: 2.3915815353393555 | KNN Loss: 2.388472318649292 | CLS Loss: 0.003109309822320938\n",
      "Epoch 171 / 200 | iteration 90 / 171 | Total Loss: 2.4057719707489014 | KNN Loss: 2.4033985137939453 | CLS Loss: 0.0023734536953270435\n",
      "Epoch 171 / 200 | iteration 100 / 171 | Total Loss: 2.4185423851013184 | KNN Loss: 2.4142942428588867 | CLS Loss: 0.004248186945915222\n",
      "Epoch 171 / 200 | iteration 110 / 171 | Total Loss: 2.434723377227783 | KNN Loss: 2.420790195465088 | CLS Loss: 0.013933269307017326\n",
      "Epoch 171 / 200 | iteration 120 / 171 | Total Loss: 2.3930695056915283 | KNN Loss: 2.386384963989258 | CLS Loss: 0.006684586871415377\n",
      "Epoch 171 / 200 | iteration 130 / 171 | Total Loss: 2.419139862060547 | KNN Loss: 2.4111783504486084 | CLS Loss: 0.007961559109389782\n",
      "Epoch 171 / 200 | iteration 140 / 171 | Total Loss: 2.462700605392456 | KNN Loss: 2.450808525085449 | CLS Loss: 0.011892021633684635\n",
      "Epoch 171 / 200 | iteration 150 / 171 | Total Loss: 2.40946626663208 | KNN Loss: 2.4031217098236084 | CLS Loss: 0.00634459313005209\n",
      "Epoch 171 / 200 | iteration 160 / 171 | Total Loss: 2.40274715423584 | KNN Loss: 2.394507646560669 | CLS Loss: 0.00823962315917015\n",
      "Epoch 171 / 200 | iteration 170 / 171 | Total Loss: 2.43375301361084 | KNN Loss: 2.429863929748535 | CLS Loss: 0.0038891537114977837\n",
      "Epoch: 171, Loss: 2.4074, Train: 0.9970, Valid: 0.9861, Best: 0.9878\n",
      "Epoch 172 / 200 | iteration 0 / 171 | Total Loss: 2.3890247344970703 | KNN Loss: 2.381939649581909 | CLS Loss: 0.0070850299671292305\n",
      "Epoch 172 / 200 | iteration 10 / 171 | Total Loss: 2.4043469429016113 | KNN Loss: 2.3999276161193848 | CLS Loss: 0.0044194115325808525\n",
      "Epoch 172 / 200 | iteration 20 / 171 | Total Loss: 2.427975654602051 | KNN Loss: 2.3903725147247314 | CLS Loss: 0.037603121250867844\n",
      "Epoch 172 / 200 | iteration 30 / 171 | Total Loss: 2.433459758758545 | KNN Loss: 2.4291155338287354 | CLS Loss: 0.004344338551163673\n",
      "Epoch 172 / 200 | iteration 40 / 171 | Total Loss: 2.397982120513916 | KNN Loss: 2.39396071434021 | CLS Loss: 0.0040213135071098804\n",
      "Epoch 172 / 200 | iteration 50 / 171 | Total Loss: 2.3979387283325195 | KNN Loss: 2.3939428329467773 | CLS Loss: 0.003995899111032486\n",
      "Epoch 172 / 200 | iteration 60 / 171 | Total Loss: 2.43306827545166 | KNN Loss: 2.4255058765411377 | CLS Loss: 0.0075623393058776855\n",
      "Epoch 172 / 200 | iteration 70 / 171 | Total Loss: 2.4273273944854736 | KNN Loss: 2.4246058464050293 | CLS Loss: 0.002721531316637993\n",
      "Epoch 172 / 200 | iteration 80 / 171 | Total Loss: 2.439258575439453 | KNN Loss: 2.3992819786071777 | CLS Loss: 0.03997667878866196\n",
      "Epoch 172 / 200 | iteration 90 / 171 | Total Loss: 2.3958871364593506 | KNN Loss: 2.3877551555633545 | CLS Loss: 0.008132033050060272\n",
      "Epoch 172 / 200 | iteration 100 / 171 | Total Loss: 2.4311177730560303 | KNN Loss: 2.4182581901550293 | CLS Loss: 0.012859559617936611\n",
      "Epoch 172 / 200 | iteration 110 / 171 | Total Loss: 2.4631857872009277 | KNN Loss: 2.4425158500671387 | CLS Loss: 0.020670035853981972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 / 200 | iteration 120 / 171 | Total Loss: 2.4095072746276855 | KNN Loss: 2.4025354385375977 | CLS Loss: 0.006971778813749552\n",
      "Epoch 172 / 200 | iteration 130 / 171 | Total Loss: 2.3734593391418457 | KNN Loss: 2.3647592067718506 | CLS Loss: 0.008700129576027393\n",
      "Epoch 172 / 200 | iteration 140 / 171 | Total Loss: 2.3498165607452393 | KNN Loss: 2.349445104598999 | CLS Loss: 0.00037140410859137774\n",
      "Epoch 172 / 200 | iteration 150 / 171 | Total Loss: 2.417059898376465 | KNN Loss: 2.4098212718963623 | CLS Loss: 0.007238606456667185\n",
      "Epoch 172 / 200 | iteration 160 / 171 | Total Loss: 2.4199373722076416 | KNN Loss: 2.3972558975219727 | CLS Loss: 0.02268156222999096\n",
      "Epoch 172 / 200 | iteration 170 / 171 | Total Loss: 2.4041714668273926 | KNN Loss: 2.395745038986206 | CLS Loss: 0.008426348678767681\n",
      "Epoch: 172, Loss: 2.4085, Train: 0.9965, Valid: 0.9865, Best: 0.9878\n",
      "Epoch 173 / 200 | iteration 0 / 171 | Total Loss: 2.405426025390625 | KNN Loss: 2.402008056640625 | CLS Loss: 0.0034179931972175837\n",
      "Epoch 173 / 200 | iteration 10 / 171 | Total Loss: 2.4343795776367188 | KNN Loss: 2.4274661540985107 | CLS Loss: 0.0069133443757891655\n",
      "Epoch 173 / 200 | iteration 20 / 171 | Total Loss: 2.3833119869232178 | KNN Loss: 2.370753049850464 | CLS Loss: 0.012558878399431705\n",
      "Epoch 173 / 200 | iteration 30 / 171 | Total Loss: 2.4053895473480225 | KNN Loss: 2.403022527694702 | CLS Loss: 0.0023669619113206863\n",
      "Epoch 173 / 200 | iteration 40 / 171 | Total Loss: 2.422940492630005 | KNN Loss: 2.419435739517212 | CLS Loss: 0.003504800610244274\n",
      "Epoch 173 / 200 | iteration 50 / 171 | Total Loss: 2.379715919494629 | KNN Loss: 2.3669638633728027 | CLS Loss: 0.0127521688118577\n",
      "Epoch 173 / 200 | iteration 60 / 171 | Total Loss: 2.41984486579895 | KNN Loss: 2.41209077835083 | CLS Loss: 0.007754095364362001\n",
      "Epoch 173 / 200 | iteration 70 / 171 | Total Loss: 2.364834785461426 | KNN Loss: 2.3576772212982178 | CLS Loss: 0.0071574607864022255\n",
      "Epoch 173 / 200 | iteration 80 / 171 | Total Loss: 2.4391376972198486 | KNN Loss: 2.433199882507324 | CLS Loss: 0.0059378547593951225\n",
      "Epoch 173 / 200 | iteration 90 / 171 | Total Loss: 2.4044058322906494 | KNN Loss: 2.382582187652588 | CLS Loss: 0.021823598071932793\n",
      "Epoch 173 / 200 | iteration 100 / 171 | Total Loss: 2.3894588947296143 | KNN Loss: 2.372546911239624 | CLS Loss: 0.016911974176764488\n",
      "Epoch 173 / 200 | iteration 110 / 171 | Total Loss: 2.4132392406463623 | KNN Loss: 2.3953795433044434 | CLS Loss: 0.017859691753983498\n",
      "Epoch 173 / 200 | iteration 120 / 171 | Total Loss: 2.4311270713806152 | KNN Loss: 2.4266860485076904 | CLS Loss: 0.004440917633473873\n",
      "Epoch 173 / 200 | iteration 130 / 171 | Total Loss: 2.379359245300293 | KNN Loss: 2.371825695037842 | CLS Loss: 0.007533582858741283\n",
      "Epoch 173 / 200 | iteration 140 / 171 | Total Loss: 2.430302143096924 | KNN Loss: 2.4234189987182617 | CLS Loss: 0.00688311317935586\n",
      "Epoch 173 / 200 | iteration 150 / 171 | Total Loss: 2.4036550521850586 | KNN Loss: 2.3910422325134277 | CLS Loss: 0.012612864375114441\n",
      "Epoch 173 / 200 | iteration 160 / 171 | Total Loss: 2.416156768798828 | KNN Loss: 2.413114547729492 | CLS Loss: 0.003042251570150256\n",
      "Epoch 173 / 200 | iteration 170 / 171 | Total Loss: 2.452324151992798 | KNN Loss: 2.441467761993408 | CLS Loss: 0.010856369510293007\n",
      "Epoch: 173, Loss: 2.4084, Train: 0.9954, Valid: 0.9837, Best: 0.9878\n",
      "Epoch 174 / 200 | iteration 0 / 171 | Total Loss: 2.3922834396362305 | KNN Loss: 2.385558605194092 | CLS Loss: 0.006724742241203785\n",
      "Epoch 174 / 200 | iteration 10 / 171 | Total Loss: 2.4037885665893555 | KNN Loss: 2.386293649673462 | CLS Loss: 0.017495013773441315\n",
      "Epoch 174 / 200 | iteration 20 / 171 | Total Loss: 2.3931849002838135 | KNN Loss: 2.3885419368743896 | CLS Loss: 0.00464286282658577\n",
      "Epoch 174 / 200 | iteration 30 / 171 | Total Loss: 2.4596216678619385 | KNN Loss: 2.458529472351074 | CLS Loss: 0.0010921170469373465\n",
      "Epoch 174 / 200 | iteration 40 / 171 | Total Loss: 2.392077684402466 | KNN Loss: 2.3751657009124756 | CLS Loss: 0.01691199652850628\n",
      "Epoch 174 / 200 | iteration 50 / 171 | Total Loss: 2.411672592163086 | KNN Loss: 2.396233558654785 | CLS Loss: 0.015439064241945744\n",
      "Epoch 174 / 200 | iteration 60 / 171 | Total Loss: 2.404386281967163 | KNN Loss: 2.3955297470092773 | CLS Loss: 0.00885646790266037\n",
      "Epoch 174 / 200 | iteration 70 / 171 | Total Loss: 2.4140870571136475 | KNN Loss: 2.411379098892212 | CLS Loss: 0.0027080306317657232\n",
      "Epoch 174 / 200 | iteration 80 / 171 | Total Loss: 2.382472276687622 | KNN Loss: 2.3630452156066895 | CLS Loss: 0.019427167251706123\n",
      "Epoch 174 / 200 | iteration 90 / 171 | Total Loss: 2.3518450260162354 | KNN Loss: 2.349188804626465 | CLS Loss: 0.0026561045087873936\n",
      "Epoch 174 / 200 | iteration 100 / 171 | Total Loss: 2.363248348236084 | KNN Loss: 2.3570022583007812 | CLS Loss: 0.006245980970561504\n",
      "Epoch 174 / 200 | iteration 110 / 171 | Total Loss: 2.382050037384033 | KNN Loss: 2.3782832622528076 | CLS Loss: 0.0037667308934032917\n",
      "Epoch 174 / 200 | iteration 120 / 171 | Total Loss: 2.3858940601348877 | KNN Loss: 2.38407039642334 | CLS Loss: 0.0018237229669466615\n",
      "Epoch 174 / 200 | iteration 130 / 171 | Total Loss: 2.421945810317993 | KNN Loss: 2.4044294357299805 | CLS Loss: 0.01751626655459404\n",
      "Epoch 174 / 200 | iteration 140 / 171 | Total Loss: 2.379331588745117 | KNN Loss: 2.377960443496704 | CLS Loss: 0.0013712639920413494\n",
      "Epoch 174 / 200 | iteration 150 / 171 | Total Loss: 2.375795364379883 | KNN Loss: 2.3742289543151855 | CLS Loss: 0.0015663005178794265\n",
      "Epoch 174 / 200 | iteration 160 / 171 | Total Loss: 2.3696253299713135 | KNN Loss: 2.362950086593628 | CLS Loss: 0.006675236392766237\n",
      "Epoch 174 / 200 | iteration 170 / 171 | Total Loss: 2.3851945400238037 | KNN Loss: 2.3640859127044678 | CLS Loss: 0.021108653396368027\n",
      "Epoch: 174, Loss: 2.4064, Train: 0.9976, Valid: 0.9869, Best: 0.9878\n",
      "Epoch 175 / 200 | iteration 0 / 171 | Total Loss: 2.382451057434082 | KNN Loss: 2.377446174621582 | CLS Loss: 0.005004911217838526\n",
      "Epoch 175 / 200 | iteration 10 / 171 | Total Loss: 2.3922290802001953 | KNN Loss: 2.38138484954834 | CLS Loss: 0.010844186879694462\n",
      "Epoch 175 / 200 | iteration 20 / 171 | Total Loss: 2.365969181060791 | KNN Loss: 2.363544464111328 | CLS Loss: 0.002424724865704775\n",
      "Epoch 175 / 200 | iteration 30 / 171 | Total Loss: 2.4033191204071045 | KNN Loss: 2.3990695476531982 | CLS Loss: 0.00424957275390625\n",
      "Epoch 175 / 200 | iteration 40 / 171 | Total Loss: 2.38735294342041 | KNN Loss: 2.3831284046173096 | CLS Loss: 0.004224544856697321\n",
      "Epoch 175 / 200 | iteration 50 / 171 | Total Loss: 2.394235134124756 | KNN Loss: 2.384222984313965 | CLS Loss: 0.01001205574721098\n",
      "Epoch 175 / 200 | iteration 60 / 171 | Total Loss: 2.418158769607544 | KNN Loss: 2.416231393814087 | CLS Loss: 0.001927344361320138\n",
      "Epoch 175 / 200 | iteration 70 / 171 | Total Loss: 2.4092626571655273 | KNN Loss: 2.394803524017334 | CLS Loss: 0.01445918157696724\n",
      "Epoch 175 / 200 | iteration 80 / 171 | Total Loss: 2.4295992851257324 | KNN Loss: 2.4217324256896973 | CLS Loss: 0.007866921834647655\n",
      "Epoch 175 / 200 | iteration 90 / 171 | Total Loss: 2.415130138397217 | KNN Loss: 2.414522647857666 | CLS Loss: 0.0006073966505937278\n",
      "Epoch 175 / 200 | iteration 100 / 171 | Total Loss: 2.3875179290771484 | KNN Loss: 2.3827786445617676 | CLS Loss: 0.004739167168736458\n",
      "Epoch 175 / 200 | iteration 110 / 171 | Total Loss: 2.3969197273254395 | KNN Loss: 2.394623041152954 | CLS Loss: 0.0022967446129769087\n",
      "Epoch 175 / 200 | iteration 120 / 171 | Total Loss: 2.4533584117889404 | KNN Loss: 2.442260503768921 | CLS Loss: 0.011097952723503113\n",
      "Epoch 175 / 200 | iteration 130 / 171 | Total Loss: 2.4124972820281982 | KNN Loss: 2.3997137546539307 | CLS Loss: 0.012783541344106197\n",
      "Epoch 175 / 200 | iteration 140 / 171 | Total Loss: 2.405576705932617 | KNN Loss: 2.40248441696167 | CLS Loss: 0.0030921725556254387\n",
      "Epoch 175 / 200 | iteration 150 / 171 | Total Loss: 2.420001268386841 | KNN Loss: 2.398448944091797 | CLS Loss: 0.021552329882979393\n",
      "Epoch 175 / 200 | iteration 160 / 171 | Total Loss: 2.4253649711608887 | KNN Loss: 2.414928436279297 | CLS Loss: 0.010436649434268475\n",
      "Epoch 175 / 200 | iteration 170 / 171 | Total Loss: 2.435270071029663 | KNN Loss: 2.4310503005981445 | CLS Loss: 0.004219717346131802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175, Loss: 2.4089, Train: 0.9960, Valid: 0.9861, Best: 0.9878\n",
      "Epoch 176 / 200 | iteration 0 / 171 | Total Loss: 2.439706563949585 | KNN Loss: 2.423344373703003 | CLS Loss: 0.016362294554710388\n",
      "Epoch 176 / 200 | iteration 10 / 171 | Total Loss: 2.419208288192749 | KNN Loss: 2.417212963104248 | CLS Loss: 0.001995422877371311\n",
      "Epoch 176 / 200 | iteration 20 / 171 | Total Loss: 2.444315195083618 | KNN Loss: 2.436753749847412 | CLS Loss: 0.007561384234577417\n",
      "Epoch 176 / 200 | iteration 30 / 171 | Total Loss: 2.398893356323242 | KNN Loss: 2.3881239891052246 | CLS Loss: 0.010769395157694817\n",
      "Epoch 176 / 200 | iteration 40 / 171 | Total Loss: 2.390425205230713 | KNN Loss: 2.3878254890441895 | CLS Loss: 0.0025998326018452644\n",
      "Epoch 176 / 200 | iteration 50 / 171 | Total Loss: 2.384436845779419 | KNN Loss: 2.3731329441070557 | CLS Loss: 0.011303821578621864\n",
      "Epoch 176 / 200 | iteration 60 / 171 | Total Loss: 2.397850275039673 | KNN Loss: 2.38834285736084 | CLS Loss: 0.009507318027317524\n",
      "Epoch 176 / 200 | iteration 70 / 171 | Total Loss: 2.3927547931671143 | KNN Loss: 2.379697561264038 | CLS Loss: 0.013057125732302666\n",
      "Epoch 176 / 200 | iteration 80 / 171 | Total Loss: 2.4232800006866455 | KNN Loss: 2.4071898460388184 | CLS Loss: 0.016090048477053642\n",
      "Epoch 176 / 200 | iteration 90 / 171 | Total Loss: 2.4238052368164062 | KNN Loss: 2.3971331119537354 | CLS Loss: 0.02667221985757351\n",
      "Epoch 176 / 200 | iteration 100 / 171 | Total Loss: 2.3851397037506104 | KNN Loss: 2.366809368133545 | CLS Loss: 0.01833023875951767\n",
      "Epoch 176 / 200 | iteration 110 / 171 | Total Loss: 2.3943991661071777 | KNN Loss: 2.3911798000335693 | CLS Loss: 0.0032192524522542953\n",
      "Epoch 176 / 200 | iteration 120 / 171 | Total Loss: 2.4409024715423584 | KNN Loss: 2.4305362701416016 | CLS Loss: 0.010366139002144337\n",
      "Epoch 176 / 200 | iteration 130 / 171 | Total Loss: 2.4017510414123535 | KNN Loss: 2.3908286094665527 | CLS Loss: 0.010922402143478394\n",
      "Epoch 176 / 200 | iteration 140 / 171 | Total Loss: 2.4200751781463623 | KNN Loss: 2.3953359127044678 | CLS Loss: 0.024739179760217667\n",
      "Epoch 176 / 200 | iteration 150 / 171 | Total Loss: 2.390500545501709 | KNN Loss: 2.373091459274292 | CLS Loss: 0.017409201711416245\n",
      "Epoch 176 / 200 | iteration 160 / 171 | Total Loss: 2.412909507751465 | KNN Loss: 2.4024815559387207 | CLS Loss: 0.010428013280034065\n",
      "Epoch 176 / 200 | iteration 170 / 171 | Total Loss: 2.3886332511901855 | KNN Loss: 2.3756818771362305 | CLS Loss: 0.012951434589922428\n",
      "Epoch: 176, Loss: 2.4108, Train: 0.9971, Valid: 0.9863, Best: 0.9878\n",
      "Epoch 177 / 200 | iteration 0 / 171 | Total Loss: 2.3911776542663574 | KNN Loss: 2.38713002204895 | CLS Loss: 0.0040476201102137566\n",
      "Epoch 177 / 200 | iteration 10 / 171 | Total Loss: 2.3949191570281982 | KNN Loss: 2.382462739944458 | CLS Loss: 0.012456385418772697\n",
      "Epoch 177 / 200 | iteration 20 / 171 | Total Loss: 2.410616874694824 | KNN Loss: 2.4027464389801025 | CLS Loss: 0.007870483212172985\n",
      "Epoch 177 / 200 | iteration 30 / 171 | Total Loss: 2.404294967651367 | KNN Loss: 2.403639793395996 | CLS Loss: 0.0006551368278451264\n",
      "Epoch 177 / 200 | iteration 40 / 171 | Total Loss: 2.410698890686035 | KNN Loss: 2.4017839431762695 | CLS Loss: 0.008915005251765251\n",
      "Epoch 177 / 200 | iteration 50 / 171 | Total Loss: 2.4343574047088623 | KNN Loss: 2.4086198806762695 | CLS Loss: 0.02573763020336628\n",
      "Epoch 177 / 200 | iteration 60 / 171 | Total Loss: 2.416903257369995 | KNN Loss: 2.4094810485839844 | CLS Loss: 0.007422232534736395\n",
      "Epoch 177 / 200 | iteration 70 / 171 | Total Loss: 2.400005340576172 | KNN Loss: 2.395228385925293 | CLS Loss: 0.004777011927217245\n",
      "Epoch 177 / 200 | iteration 80 / 171 | Total Loss: 2.377924680709839 | KNN Loss: 2.359783887863159 | CLS Loss: 0.01814088597893715\n",
      "Epoch 177 / 200 | iteration 90 / 171 | Total Loss: 2.433872699737549 | KNN Loss: 2.4188525676727295 | CLS Loss: 0.015020185150206089\n",
      "Epoch 177 / 200 | iteration 100 / 171 | Total Loss: 2.4334545135498047 | KNN Loss: 2.413717031478882 | CLS Loss: 0.019737429916858673\n",
      "Epoch 177 / 200 | iteration 110 / 171 | Total Loss: 2.4356024265289307 | KNN Loss: 2.4125113487243652 | CLS Loss: 0.02309104986488819\n",
      "Epoch 177 / 200 | iteration 120 / 171 | Total Loss: 2.4250850677490234 | KNN Loss: 2.4212403297424316 | CLS Loss: 0.0038448190316557884\n",
      "Epoch 177 / 200 | iteration 130 / 171 | Total Loss: 2.39973783493042 | KNN Loss: 2.392113208770752 | CLS Loss: 0.0076245809905231\n",
      "Epoch 177 / 200 | iteration 140 / 171 | Total Loss: 2.4243688583374023 | KNN Loss: 2.4134511947631836 | CLS Loss: 0.010917662642896175\n",
      "Epoch 177 / 200 | iteration 150 / 171 | Total Loss: 2.399759531021118 | KNN Loss: 2.3905527591705322 | CLS Loss: 0.009206748567521572\n",
      "Epoch 177 / 200 | iteration 160 / 171 | Total Loss: 2.3781518936157227 | KNN Loss: 2.3691787719726562 | CLS Loss: 0.008973101153969765\n",
      "Epoch 177 / 200 | iteration 170 / 171 | Total Loss: 2.399901866912842 | KNN Loss: 2.3920860290527344 | CLS Loss: 0.007815743796527386\n",
      "Epoch: 177, Loss: 2.4106, Train: 0.9964, Valid: 0.9857, Best: 0.9878\n",
      "Epoch 178 / 200 | iteration 0 / 171 | Total Loss: 2.400238513946533 | KNN Loss: 2.3908910751342773 | CLS Loss: 0.009347446262836456\n",
      "Epoch 178 / 200 | iteration 10 / 171 | Total Loss: 2.4121742248535156 | KNN Loss: 2.4013612270355225 | CLS Loss: 0.01081298291683197\n",
      "Epoch 178 / 200 | iteration 20 / 171 | Total Loss: 2.3819496631622314 | KNN Loss: 2.379147529602051 | CLS Loss: 0.0028022450860589743\n",
      "Epoch 178 / 200 | iteration 30 / 171 | Total Loss: 2.38706636428833 | KNN Loss: 2.377225399017334 | CLS Loss: 0.009840864688158035\n",
      "Epoch 178 / 200 | iteration 40 / 171 | Total Loss: 2.39768385887146 | KNN Loss: 2.385376453399658 | CLS Loss: 0.012307507917284966\n",
      "Epoch 178 / 200 | iteration 50 / 171 | Total Loss: 2.390636444091797 | KNN Loss: 2.3873143196105957 | CLS Loss: 0.003322144504636526\n",
      "Epoch 178 / 200 | iteration 60 / 171 | Total Loss: 2.4358646869659424 | KNN Loss: 2.417208433151245 | CLS Loss: 0.018656255677342415\n",
      "Epoch 178 / 200 | iteration 70 / 171 | Total Loss: 2.42445707321167 | KNN Loss: 2.404224157333374 | CLS Loss: 0.020232895389199257\n",
      "Epoch 178 / 200 | iteration 80 / 171 | Total Loss: 2.4116663932800293 | KNN Loss: 2.4038259983062744 | CLS Loss: 0.007840330712497234\n",
      "Epoch 178 / 200 | iteration 90 / 171 | Total Loss: 2.3981611728668213 | KNN Loss: 2.3892436027526855 | CLS Loss: 0.00891767255961895\n",
      "Epoch 178 / 200 | iteration 100 / 171 | Total Loss: 2.3987326622009277 | KNN Loss: 2.3955600261688232 | CLS Loss: 0.003172747790813446\n",
      "Epoch 178 / 200 | iteration 110 / 171 | Total Loss: 2.4048056602478027 | KNN Loss: 2.381632089614868 | CLS Loss: 0.02317366935312748\n",
      "Epoch 178 / 200 | iteration 120 / 171 | Total Loss: 2.4513237476348877 | KNN Loss: 2.429260492324829 | CLS Loss: 0.0220632404088974\n",
      "Epoch 178 / 200 | iteration 130 / 171 | Total Loss: 2.428666353225708 | KNN Loss: 2.4170734882354736 | CLS Loss: 0.011592750437557697\n",
      "Epoch 178 / 200 | iteration 140 / 171 | Total Loss: 2.39436674118042 | KNN Loss: 2.360353946685791 | CLS Loss: 0.034012723714113235\n",
      "Epoch 178 / 200 | iteration 150 / 171 | Total Loss: 2.417685031890869 | KNN Loss: 2.412130117416382 | CLS Loss: 0.00555500527843833\n",
      "Epoch 178 / 200 | iteration 160 / 171 | Total Loss: 2.3965983390808105 | KNN Loss: 2.3887736797332764 | CLS Loss: 0.007824612781405449\n",
      "Epoch 178 / 200 | iteration 170 / 171 | Total Loss: 2.4115664958953857 | KNN Loss: 2.3996191024780273 | CLS Loss: 0.011947336606681347\n",
      "Epoch: 178, Loss: 2.4126, Train: 0.9962, Valid: 0.9859, Best: 0.9878\n",
      "Epoch 179 / 200 | iteration 0 / 171 | Total Loss: 2.433295726776123 | KNN Loss: 2.416978120803833 | CLS Loss: 0.016317693516612053\n",
      "Epoch 179 / 200 | iteration 10 / 171 | Total Loss: 2.396881580352783 | KNN Loss: 2.3813726902008057 | CLS Loss: 0.01550889853388071\n",
      "Epoch 179 / 200 | iteration 20 / 171 | Total Loss: 2.38045597076416 | KNN Loss: 2.3677806854248047 | CLS Loss: 0.012675223872065544\n",
      "Epoch 179 / 200 | iteration 30 / 171 | Total Loss: 2.433669090270996 | KNN Loss: 2.4044747352600098 | CLS Loss: 0.029194265604019165\n",
      "Epoch 179 / 200 | iteration 40 / 171 | Total Loss: 2.434720516204834 | KNN Loss: 2.4177417755126953 | CLS Loss: 0.01697874814271927\n",
      "Epoch 179 / 200 | iteration 50 / 171 | Total Loss: 2.4757654666900635 | KNN Loss: 2.4608891010284424 | CLS Loss: 0.014876315370202065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 / 200 | iteration 60 / 171 | Total Loss: 2.4312684535980225 | KNN Loss: 2.418348550796509 | CLS Loss: 0.012919902801513672\n",
      "Epoch 179 / 200 | iteration 70 / 171 | Total Loss: 2.4015331268310547 | KNN Loss: 2.3825480937957764 | CLS Loss: 0.018984949216246605\n",
      "Epoch 179 / 200 | iteration 80 / 171 | Total Loss: 2.4184584617614746 | KNN Loss: 2.4028100967407227 | CLS Loss: 0.015648363158106804\n",
      "Epoch 179 / 200 | iteration 90 / 171 | Total Loss: 2.387951374053955 | KNN Loss: 2.377260446548462 | CLS Loss: 0.010690818540751934\n",
      "Epoch 179 / 200 | iteration 100 / 171 | Total Loss: 2.431504726409912 | KNN Loss: 2.4227287769317627 | CLS Loss: 0.008775957860052586\n",
      "Epoch 179 / 200 | iteration 110 / 171 | Total Loss: 2.378124237060547 | KNN Loss: 2.37115478515625 | CLS Loss: 0.006969396956264973\n",
      "Epoch 179 / 200 | iteration 120 / 171 | Total Loss: 2.417039632797241 | KNN Loss: 2.4109106063842773 | CLS Loss: 0.006128915119916201\n",
      "Epoch 179 / 200 | iteration 130 / 171 | Total Loss: 2.3768625259399414 | KNN Loss: 2.364131212234497 | CLS Loss: 0.01273133885115385\n",
      "Epoch 179 / 200 | iteration 140 / 171 | Total Loss: 2.412593364715576 | KNN Loss: 2.403865337371826 | CLS Loss: 0.008728091605007648\n",
      "Epoch 179 / 200 | iteration 150 / 171 | Total Loss: 2.413651704788208 | KNN Loss: 2.405236005783081 | CLS Loss: 0.008415811695158482\n",
      "Epoch 179 / 200 | iteration 160 / 171 | Total Loss: 2.4335899353027344 | KNN Loss: 2.410301685333252 | CLS Loss: 0.023288264870643616\n",
      "Epoch 179 / 200 | iteration 170 / 171 | Total Loss: 2.400637626647949 | KNN Loss: 2.389204740524292 | CLS Loss: 0.011432814411818981\n",
      "Epoch: 179, Loss: 2.4138, Train: 0.9964, Valid: 0.9868, Best: 0.9878\n",
      "Epoch 180 / 200 | iteration 0 / 171 | Total Loss: 2.415370225906372 | KNN Loss: 2.4080471992492676 | CLS Loss: 0.007323017343878746\n",
      "Epoch 180 / 200 | iteration 10 / 171 | Total Loss: 2.425153970718384 | KNN Loss: 2.4197163581848145 | CLS Loss: 0.005437588784843683\n",
      "Epoch 180 / 200 | iteration 20 / 171 | Total Loss: 2.4018795490264893 | KNN Loss: 2.387922525405884 | CLS Loss: 0.013956987299025059\n",
      "Epoch 180 / 200 | iteration 30 / 171 | Total Loss: 2.4382123947143555 | KNN Loss: 2.4256253242492676 | CLS Loss: 0.012587129138410091\n",
      "Epoch 180 / 200 | iteration 40 / 171 | Total Loss: 2.386678695678711 | KNN Loss: 2.3816826343536377 | CLS Loss: 0.004995958413928747\n",
      "Epoch 180 / 200 | iteration 50 / 171 | Total Loss: 2.416003704071045 | KNN Loss: 2.408668041229248 | CLS Loss: 0.007335627917200327\n",
      "Epoch 180 / 200 | iteration 60 / 171 | Total Loss: 2.410529613494873 | KNN Loss: 2.404452085494995 | CLS Loss: 0.006077418103814125\n",
      "Epoch 180 / 200 | iteration 70 / 171 | Total Loss: 2.4641501903533936 | KNN Loss: 2.441847324371338 | CLS Loss: 0.02230294607579708\n",
      "Epoch 180 / 200 | iteration 80 / 171 | Total Loss: 2.4389162063598633 | KNN Loss: 2.4089860916137695 | CLS Loss: 0.02993009053170681\n",
      "Epoch 180 / 200 | iteration 90 / 171 | Total Loss: 2.4110186100006104 | KNN Loss: 2.4089314937591553 | CLS Loss: 0.002087051048874855\n",
      "Epoch 180 / 200 | iteration 100 / 171 | Total Loss: 2.4663805961608887 | KNN Loss: 2.4640376567840576 | CLS Loss: 0.00234287534840405\n",
      "Epoch 180 / 200 | iteration 110 / 171 | Total Loss: 2.4149043560028076 | KNN Loss: 2.4014885425567627 | CLS Loss: 0.013415866531431675\n",
      "Epoch 180 / 200 | iteration 120 / 171 | Total Loss: 2.4007086753845215 | KNN Loss: 2.3948590755462646 | CLS Loss: 0.005849698558449745\n",
      "Epoch 180 / 200 | iteration 130 / 171 | Total Loss: 2.4542555809020996 | KNN Loss: 2.435889959335327 | CLS Loss: 0.018365684896707535\n",
      "Epoch 180 / 200 | iteration 140 / 171 | Total Loss: 2.485304355621338 | KNN Loss: 2.40942645072937 | CLS Loss: 0.07587778568267822\n",
      "Epoch 180 / 200 | iteration 150 / 171 | Total Loss: 2.4378559589385986 | KNN Loss: 2.392866849899292 | CLS Loss: 0.044989123940467834\n",
      "Epoch 180 / 200 | iteration 160 / 171 | Total Loss: 2.4114556312561035 | KNN Loss: 2.4000420570373535 | CLS Loss: 0.011413653381168842\n",
      "Epoch 180 / 200 | iteration 170 / 171 | Total Loss: 2.4171369075775146 | KNN Loss: 2.4086451530456543 | CLS Loss: 0.008491836488246918\n",
      "Epoch: 180, Loss: 2.4228, Train: 0.9971, Valid: 0.9868, Best: 0.9878\n",
      "Epoch 181 / 200 | iteration 0 / 171 | Total Loss: 2.412329912185669 | KNN Loss: 2.4077117443084717 | CLS Loss: 0.004618281032890081\n",
      "Epoch 181 / 200 | iteration 10 / 171 | Total Loss: 2.414578437805176 | KNN Loss: 2.406822919845581 | CLS Loss: 0.007755607832223177\n",
      "Epoch 181 / 200 | iteration 20 / 171 | Total Loss: 2.4257726669311523 | KNN Loss: 2.403853416442871 | CLS Loss: 0.02191918157041073\n",
      "Epoch 181 / 200 | iteration 30 / 171 | Total Loss: 2.389481782913208 | KNN Loss: 2.3792724609375 | CLS Loss: 0.010209336876869202\n",
      "Epoch 181 / 200 | iteration 40 / 171 | Total Loss: 2.4107518196105957 | KNN Loss: 2.3825483322143555 | CLS Loss: 0.028203502297401428\n",
      "Epoch 181 / 200 | iteration 50 / 171 | Total Loss: 2.4304189682006836 | KNN Loss: 2.428117275238037 | CLS Loss: 0.0023017870262265205\n",
      "Epoch 181 / 200 | iteration 60 / 171 | Total Loss: 2.419161796569824 | KNN Loss: 2.415111780166626 | CLS Loss: 0.004049953538924456\n",
      "Epoch 181 / 200 | iteration 70 / 171 | Total Loss: 2.39027738571167 | KNN Loss: 2.3778181076049805 | CLS Loss: 0.01245918869972229\n",
      "Epoch 181 / 200 | iteration 80 / 171 | Total Loss: 2.4422643184661865 | KNN Loss: 2.431252956390381 | CLS Loss: 0.011011363938450813\n",
      "Epoch 181 / 200 | iteration 90 / 171 | Total Loss: 2.412872552871704 | KNN Loss: 2.4090492725372314 | CLS Loss: 0.0038232007063925266\n",
      "Epoch 181 / 200 | iteration 100 / 171 | Total Loss: 2.4037532806396484 | KNN Loss: 2.401657819747925 | CLS Loss: 0.0020955237559974194\n",
      "Epoch 181 / 200 | iteration 110 / 171 | Total Loss: 2.405024290084839 | KNN Loss: 2.378920793533325 | CLS Loss: 0.026103593409061432\n",
      "Epoch 181 / 200 | iteration 120 / 171 | Total Loss: 2.435347318649292 | KNN Loss: 2.4018521308898926 | CLS Loss: 0.03349517285823822\n",
      "Epoch 181 / 200 | iteration 130 / 171 | Total Loss: 2.4130799770355225 | KNN Loss: 2.3955893516540527 | CLS Loss: 0.01749071106314659\n",
      "Epoch 181 / 200 | iteration 140 / 171 | Total Loss: 2.3861019611358643 | KNN Loss: 2.37774658203125 | CLS Loss: 0.00835547037422657\n",
      "Epoch 181 / 200 | iteration 150 / 171 | Total Loss: 2.405623435974121 | KNN Loss: 2.400407552719116 | CLS Loss: 0.005215772427618504\n",
      "Epoch 181 / 200 | iteration 160 / 171 | Total Loss: 2.407445192337036 | KNN Loss: 2.378488302230835 | CLS Loss: 0.028957005590200424\n",
      "Epoch 181 / 200 | iteration 170 / 171 | Total Loss: 2.416083812713623 | KNN Loss: 2.4003355503082275 | CLS Loss: 0.015748361125588417\n",
      "Epoch: 181, Loss: 2.4126, Train: 0.9956, Valid: 0.9851, Best: 0.9878\n",
      "Epoch 182 / 200 | iteration 0 / 171 | Total Loss: 2.399031162261963 | KNN Loss: 2.3930716514587402 | CLS Loss: 0.005959527567028999\n",
      "Epoch 182 / 200 | iteration 10 / 171 | Total Loss: 2.4162614345550537 | KNN Loss: 2.413113594055176 | CLS Loss: 0.003147795796394348\n",
      "Epoch 182 / 200 | iteration 20 / 171 | Total Loss: 2.374140739440918 | KNN Loss: 2.3626224994659424 | CLS Loss: 0.011518154293298721\n",
      "Epoch 182 / 200 | iteration 30 / 171 | Total Loss: 2.410411834716797 | KNN Loss: 2.409208297729492 | CLS Loss: 0.0012035215040668845\n",
      "Epoch 182 / 200 | iteration 40 / 171 | Total Loss: 2.376329183578491 | KNN Loss: 2.3729336261749268 | CLS Loss: 0.0033954507671296597\n",
      "Epoch 182 / 200 | iteration 50 / 171 | Total Loss: 2.373051643371582 | KNN Loss: 2.3665199279785156 | CLS Loss: 0.006531682331115007\n",
      "Epoch 182 / 200 | iteration 60 / 171 | Total Loss: 2.3883872032165527 | KNN Loss: 2.3797991275787354 | CLS Loss: 0.008588085882365704\n",
      "Epoch 182 / 200 | iteration 70 / 171 | Total Loss: 2.4072275161743164 | KNN Loss: 2.3891570568084717 | CLS Loss: 0.018070431426167488\n",
      "Epoch 182 / 200 | iteration 80 / 171 | Total Loss: 2.4008266925811768 | KNN Loss: 2.3742728233337402 | CLS Loss: 0.026553841307759285\n",
      "Epoch 182 / 200 | iteration 90 / 171 | Total Loss: 2.4140610694885254 | KNN Loss: 2.3962135314941406 | CLS Loss: 0.017847459763288498\n",
      "Epoch 182 / 200 | iteration 100 / 171 | Total Loss: 2.3635761737823486 | KNN Loss: 2.3521950244903564 | CLS Loss: 0.01138122845441103\n",
      "Epoch 182 / 200 | iteration 110 / 171 | Total Loss: 2.3759915828704834 | KNN Loss: 2.371004343032837 | CLS Loss: 0.0049873534590005875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182 / 200 | iteration 120 / 171 | Total Loss: 2.3971948623657227 | KNN Loss: 2.3941457271575928 | CLS Loss: 0.0030491214711219072\n",
      "Epoch 182 / 200 | iteration 130 / 171 | Total Loss: 2.3931772708892822 | KNN Loss: 2.3886098861694336 | CLS Loss: 0.004567311145365238\n",
      "Epoch 182 / 200 | iteration 140 / 171 | Total Loss: 2.3916101455688477 | KNN Loss: 2.3841545581817627 | CLS Loss: 0.007455611135810614\n",
      "Epoch 182 / 200 | iteration 150 / 171 | Total Loss: 2.417396068572998 | KNN Loss: 2.413971424102783 | CLS Loss: 0.0034247359726577997\n",
      "Epoch 182 / 200 | iteration 160 / 171 | Total Loss: 2.421266555786133 | KNN Loss: 2.402632236480713 | CLS Loss: 0.018634293228387833\n",
      "Epoch 182 / 200 | iteration 170 / 171 | Total Loss: 2.395117998123169 | KNN Loss: 2.388073444366455 | CLS Loss: 0.007044651545584202\n",
      "Epoch: 182, Loss: 2.4079, Train: 0.9971, Valid: 0.9868, Best: 0.9878\n",
      "Epoch 183 / 200 | iteration 0 / 171 | Total Loss: 2.4373679161071777 | KNN Loss: 2.4256834983825684 | CLS Loss: 0.011684314347803593\n",
      "Epoch 183 / 200 | iteration 10 / 171 | Total Loss: 2.3703014850616455 | KNN Loss: 2.3676323890686035 | CLS Loss: 0.0026690028607845306\n",
      "Epoch 183 / 200 | iteration 20 / 171 | Total Loss: 2.407552480697632 | KNN Loss: 2.397099018096924 | CLS Loss: 0.010453441180288792\n",
      "Epoch 183 / 200 | iteration 30 / 171 | Total Loss: 2.443849563598633 | KNN Loss: 2.4168615341186523 | CLS Loss: 0.026987982913851738\n",
      "Epoch 183 / 200 | iteration 40 / 171 | Total Loss: 2.396589517593384 | KNN Loss: 2.393054485321045 | CLS Loss: 0.003535082098096609\n",
      "Epoch 183 / 200 | iteration 50 / 171 | Total Loss: 2.451317071914673 | KNN Loss: 2.435521364212036 | CLS Loss: 0.01579580083489418\n",
      "Epoch 183 / 200 | iteration 60 / 171 | Total Loss: 2.4152097702026367 | KNN Loss: 2.4115116596221924 | CLS Loss: 0.003698179265484214\n",
      "Epoch 183 / 200 | iteration 70 / 171 | Total Loss: 2.4348793029785156 | KNN Loss: 2.4250683784484863 | CLS Loss: 0.009810985997319221\n",
      "Epoch 183 / 200 | iteration 80 / 171 | Total Loss: 2.3897078037261963 | KNN Loss: 2.384073257446289 | CLS Loss: 0.00563449552282691\n",
      "Epoch 183 / 200 | iteration 90 / 171 | Total Loss: 2.4510281085968018 | KNN Loss: 2.4125518798828125 | CLS Loss: 0.0384761206805706\n",
      "Epoch 183 / 200 | iteration 100 / 171 | Total Loss: 2.389180898666382 | KNN Loss: 2.3864166736602783 | CLS Loss: 0.0027641302440315485\n",
      "Epoch 183 / 200 | iteration 110 / 171 | Total Loss: 2.4139580726623535 | KNN Loss: 2.407193183898926 | CLS Loss: 0.006764864549040794\n",
      "Epoch 183 / 200 | iteration 120 / 171 | Total Loss: 2.3990390300750732 | KNN Loss: 2.3939034938812256 | CLS Loss: 0.005135528743267059\n",
      "Epoch 183 / 200 | iteration 130 / 171 | Total Loss: 2.4728848934173584 | KNN Loss: 2.460400342941284 | CLS Loss: 0.012484658509492874\n",
      "Epoch 183 / 200 | iteration 140 / 171 | Total Loss: 2.4122114181518555 | KNN Loss: 2.403989553451538 | CLS Loss: 0.008221780881285667\n",
      "Epoch 183 / 200 | iteration 150 / 171 | Total Loss: 2.4240291118621826 | KNN Loss: 2.409313678741455 | CLS Loss: 0.014715426601469517\n",
      "Epoch 183 / 200 | iteration 160 / 171 | Total Loss: 2.437086343765259 | KNN Loss: 2.4214723110198975 | CLS Loss: 0.015614068135619164\n",
      "Epoch 183 / 200 | iteration 170 / 171 | Total Loss: 2.398956060409546 | KNN Loss: 2.3911080360412598 | CLS Loss: 0.007847953587770462\n",
      "Epoch: 183, Loss: 2.4111, Train: 0.9973, Valid: 0.9877, Best: 0.9878\n",
      "Epoch 184 / 200 | iteration 0 / 171 | Total Loss: 2.3757731914520264 | KNN Loss: 2.35921573638916 | CLS Loss: 0.0165573600679636\n",
      "Epoch 184 / 200 | iteration 10 / 171 | Total Loss: 2.4142913818359375 | KNN Loss: 2.4058480262756348 | CLS Loss: 0.008443471975624561\n",
      "Epoch 184 / 200 | iteration 20 / 171 | Total Loss: 2.398805856704712 | KNN Loss: 2.391838550567627 | CLS Loss: 0.006967345718294382\n",
      "Epoch 184 / 200 | iteration 30 / 171 | Total Loss: 2.3814637660980225 | KNN Loss: 2.3710110187530518 | CLS Loss: 0.010452745482325554\n",
      "Epoch 184 / 200 | iteration 40 / 171 | Total Loss: 2.426044464111328 | KNN Loss: 2.4183335304260254 | CLS Loss: 0.007710867561399937\n",
      "Epoch 184 / 200 | iteration 50 / 171 | Total Loss: 2.380492925643921 | KNN Loss: 2.368656873703003 | CLS Loss: 0.01183603797107935\n",
      "Epoch 184 / 200 | iteration 60 / 171 | Total Loss: 2.41168212890625 | KNN Loss: 2.3966925144195557 | CLS Loss: 0.014989560469985008\n",
      "Epoch 184 / 200 | iteration 70 / 171 | Total Loss: 2.385620355606079 | KNN Loss: 2.379545211791992 | CLS Loss: 0.006075073033571243\n",
      "Epoch 184 / 200 | iteration 80 / 171 | Total Loss: 2.4106340408325195 | KNN Loss: 2.398541212081909 | CLS Loss: 0.01209275983273983\n",
      "Epoch 184 / 200 | iteration 90 / 171 | Total Loss: 2.443922758102417 | KNN Loss: 2.432565450668335 | CLS Loss: 0.011357355862855911\n",
      "Epoch 184 / 200 | iteration 100 / 171 | Total Loss: 2.413508176803589 | KNN Loss: 2.406461715698242 | CLS Loss: 0.007046365179121494\n",
      "Epoch 184 / 200 | iteration 110 / 171 | Total Loss: 2.410399913787842 | KNN Loss: 2.3994827270507812 | CLS Loss: 0.010917090810835361\n",
      "Epoch 184 / 200 | iteration 120 / 171 | Total Loss: 2.412858486175537 | KNN Loss: 2.410266876220703 | CLS Loss: 0.002591613447293639\n",
      "Epoch 184 / 200 | iteration 130 / 171 | Total Loss: 2.3958590030670166 | KNN Loss: 2.3623013496398926 | CLS Loss: 0.0335577130317688\n",
      "Epoch 184 / 200 | iteration 140 / 171 | Total Loss: 2.401344060897827 | KNN Loss: 2.385446548461914 | CLS Loss: 0.015897607430815697\n",
      "Epoch 184 / 200 | iteration 150 / 171 | Total Loss: 2.431398868560791 | KNN Loss: 2.426981210708618 | CLS Loss: 0.004417581483721733\n",
      "Epoch 184 / 200 | iteration 160 / 171 | Total Loss: 2.378990411758423 | KNN Loss: 2.3619396686553955 | CLS Loss: 0.01705082692205906\n",
      "Epoch 184 / 200 | iteration 170 / 171 | Total Loss: 2.4237570762634277 | KNN Loss: 2.4182093143463135 | CLS Loss: 0.005547672975808382\n",
      "Epoch: 184, Loss: 2.4092, Train: 0.9971, Valid: 0.9862, Best: 0.9878\n",
      "Epoch 185 / 200 | iteration 0 / 171 | Total Loss: 2.416119337081909 | KNN Loss: 2.4091551303863525 | CLS Loss: 0.006964090280234814\n",
      "Epoch 185 / 200 | iteration 10 / 171 | Total Loss: 2.376085042953491 | KNN Loss: 2.375335454940796 | CLS Loss: 0.0007495642057619989\n",
      "Epoch 185 / 200 | iteration 20 / 171 | Total Loss: 2.4077603816986084 | KNN Loss: 2.393749475479126 | CLS Loss: 0.014011019840836525\n",
      "Epoch 185 / 200 | iteration 30 / 171 | Total Loss: 2.4565629959106445 | KNN Loss: 2.4413514137268066 | CLS Loss: 0.015211586840450764\n",
      "Epoch 185 / 200 | iteration 40 / 171 | Total Loss: 2.3972556591033936 | KNN Loss: 2.386054277420044 | CLS Loss: 0.011201469227671623\n",
      "Epoch 185 / 200 | iteration 50 / 171 | Total Loss: 2.3865842819213867 | KNN Loss: 2.3669724464416504 | CLS Loss: 0.019611887633800507\n",
      "Epoch 185 / 200 | iteration 60 / 171 | Total Loss: 2.392364978790283 | KNN Loss: 2.3798067569732666 | CLS Loss: 0.01255819108337164\n",
      "Epoch 185 / 200 | iteration 70 / 171 | Total Loss: 2.395321846008301 | KNN Loss: 2.37971830368042 | CLS Loss: 0.015603492967784405\n",
      "Epoch 185 / 200 | iteration 80 / 171 | Total Loss: 2.4294166564941406 | KNN Loss: 2.404064893722534 | CLS Loss: 0.025351760908961296\n",
      "Epoch 185 / 200 | iteration 90 / 171 | Total Loss: 2.4335832595825195 | KNN Loss: 2.4267098903656006 | CLS Loss: 0.006873374804854393\n",
      "Epoch 185 / 200 | iteration 100 / 171 | Total Loss: 2.396671772003174 | KNN Loss: 2.383668899536133 | CLS Loss: 0.013002926483750343\n",
      "Epoch 185 / 200 | iteration 110 / 171 | Total Loss: 2.4292960166931152 | KNN Loss: 2.4002280235290527 | CLS Loss: 0.029068034142255783\n",
      "Epoch 185 / 200 | iteration 120 / 171 | Total Loss: 2.420017957687378 | KNN Loss: 2.4038615226745605 | CLS Loss: 0.0161563940346241\n",
      "Epoch 185 / 200 | iteration 130 / 171 | Total Loss: 2.4215123653411865 | KNN Loss: 2.3959147930145264 | CLS Loss: 0.02559761144220829\n",
      "Epoch 185 / 200 | iteration 140 / 171 | Total Loss: 2.4222118854522705 | KNN Loss: 2.4199109077453613 | CLS Loss: 0.0023010200820863247\n",
      "Epoch 185 / 200 | iteration 150 / 171 | Total Loss: 2.417137861251831 | KNN Loss: 2.3882393836975098 | CLS Loss: 0.028898417949676514\n",
      "Epoch 185 / 200 | iteration 160 / 171 | Total Loss: 2.437572479248047 | KNN Loss: 2.431112289428711 | CLS Loss: 0.006460118107497692\n",
      "Epoch 185 / 200 | iteration 170 / 171 | Total Loss: 2.4059536457061768 | KNN Loss: 2.397005796432495 | CLS Loss: 0.008947854861617088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185, Loss: 2.4103, Train: 0.9980, Valid: 0.9878, Best: 0.9878\n",
      "Epoch 186 / 200 | iteration 0 / 171 | Total Loss: 2.4008283615112305 | KNN Loss: 2.385937213897705 | CLS Loss: 0.014891088008880615\n",
      "Epoch 186 / 200 | iteration 10 / 171 | Total Loss: 2.3708126544952393 | KNN Loss: 2.3694918155670166 | CLS Loss: 0.001320941955782473\n",
      "Epoch 186 / 200 | iteration 20 / 171 | Total Loss: 2.4096171855926514 | KNN Loss: 2.3974850177764893 | CLS Loss: 0.012132060714066029\n",
      "Epoch 186 / 200 | iteration 30 / 171 | Total Loss: 2.3881924152374268 | KNN Loss: 2.38106107711792 | CLS Loss: 0.007131386548280716\n",
      "Epoch 186 / 200 | iteration 40 / 171 | Total Loss: 2.362730026245117 | KNN Loss: 2.3547840118408203 | CLS Loss: 0.00794593058526516\n",
      "Epoch 186 / 200 | iteration 50 / 171 | Total Loss: 2.391960382461548 | KNN Loss: 2.387556314468384 | CLS Loss: 0.004404039587825537\n",
      "Epoch 186 / 200 | iteration 60 / 171 | Total Loss: 2.3919930458068848 | KNN Loss: 2.3834145069122314 | CLS Loss: 0.008578580804169178\n",
      "Epoch 186 / 200 | iteration 70 / 171 | Total Loss: 2.3837733268737793 | KNN Loss: 2.377260208129883 | CLS Loss: 0.0065131415612995625\n",
      "Epoch 186 / 200 | iteration 80 / 171 | Total Loss: 2.4288723468780518 | KNN Loss: 2.426050901412964 | CLS Loss: 0.0028213700279593468\n",
      "Epoch 186 / 200 | iteration 90 / 171 | Total Loss: 2.38932204246521 | KNN Loss: 2.3710360527038574 | CLS Loss: 0.018285885453224182\n",
      "Epoch 186 / 200 | iteration 100 / 171 | Total Loss: 2.4137589931488037 | KNN Loss: 2.412395477294922 | CLS Loss: 0.0013635860523208976\n",
      "Epoch 186 / 200 | iteration 110 / 171 | Total Loss: 2.440291404724121 | KNN Loss: 2.4358861446380615 | CLS Loss: 0.00440537603572011\n",
      "Epoch 186 / 200 | iteration 120 / 171 | Total Loss: 2.418450355529785 | KNN Loss: 2.403225898742676 | CLS Loss: 0.015224558301270008\n",
      "Epoch 186 / 200 | iteration 130 / 171 | Total Loss: 2.414834499359131 | KNN Loss: 2.4082627296447754 | CLS Loss: 0.0065717073157429695\n",
      "Epoch 186 / 200 | iteration 140 / 171 | Total Loss: 2.3882288932800293 | KNN Loss: 2.3778676986694336 | CLS Loss: 0.010361111722886562\n",
      "Epoch 186 / 200 | iteration 150 / 171 | Total Loss: 2.3793838024139404 | KNN Loss: 2.3694756031036377 | CLS Loss: 0.00990812573581934\n",
      "Epoch 186 / 200 | iteration 160 / 171 | Total Loss: 2.443758726119995 | KNN Loss: 2.422178268432617 | CLS Loss: 0.02158050239086151\n",
      "Epoch 186 / 200 | iteration 170 / 171 | Total Loss: 2.42496919631958 | KNN Loss: 2.412057876586914 | CLS Loss: 0.012911365367472172\n",
      "Epoch: 186, Loss: 2.4068, Train: 0.9974, Valid: 0.9864, Best: 0.9878\n",
      "Epoch 187 / 200 | iteration 0 / 171 | Total Loss: 2.4004921913146973 | KNN Loss: 2.392031192779541 | CLS Loss: 0.008460937067866325\n",
      "Epoch 187 / 200 | iteration 10 / 171 | Total Loss: 2.4400041103363037 | KNN Loss: 2.4385576248168945 | CLS Loss: 0.0014464309206232429\n",
      "Epoch 187 / 200 | iteration 20 / 171 | Total Loss: 2.404268264770508 | KNN Loss: 2.3967809677124023 | CLS Loss: 0.0074872118420898914\n",
      "Epoch 187 / 200 | iteration 30 / 171 | Total Loss: 2.3882956504821777 | KNN Loss: 2.3854246139526367 | CLS Loss: 0.0028710118494927883\n",
      "Epoch 187 / 200 | iteration 40 / 171 | Total Loss: 2.4091079235076904 | KNN Loss: 2.397106170654297 | CLS Loss: 0.012001768685877323\n",
      "Epoch 187 / 200 | iteration 50 / 171 | Total Loss: 2.460749864578247 | KNN Loss: 2.445606231689453 | CLS Loss: 0.015143624506890774\n",
      "Epoch 187 / 200 | iteration 60 / 171 | Total Loss: 2.4047043323516846 | KNN Loss: 2.4022769927978516 | CLS Loss: 0.0024274419993162155\n",
      "Epoch 187 / 200 | iteration 70 / 171 | Total Loss: 2.3771860599517822 | KNN Loss: 2.370908498764038 | CLS Loss: 0.006277515087276697\n",
      "Epoch 187 / 200 | iteration 80 / 171 | Total Loss: 2.430661678314209 | KNN Loss: 2.4200971126556396 | CLS Loss: 0.0105646513402462\n",
      "Epoch 187 / 200 | iteration 90 / 171 | Total Loss: 2.4263296127319336 | KNN Loss: 2.402128219604492 | CLS Loss: 0.024201486259698868\n",
      "Epoch 187 / 200 | iteration 100 / 171 | Total Loss: 2.39323353767395 | KNN Loss: 2.3781380653381348 | CLS Loss: 0.015095504932105541\n",
      "Epoch 187 / 200 | iteration 110 / 171 | Total Loss: 2.375303268432617 | KNN Loss: 2.372990846633911 | CLS Loss: 0.002312436467036605\n",
      "Epoch 187 / 200 | iteration 120 / 171 | Total Loss: 2.3880155086517334 | KNN Loss: 2.3778014183044434 | CLS Loss: 0.010214054025709629\n",
      "Epoch 187 / 200 | iteration 130 / 171 | Total Loss: 2.4068596363067627 | KNN Loss: 2.375403642654419 | CLS Loss: 0.03145596757531166\n",
      "Epoch 187 / 200 | iteration 140 / 171 | Total Loss: 2.425168752670288 | KNN Loss: 2.4208149909973145 | CLS Loss: 0.004353830590844154\n",
      "Epoch 187 / 200 | iteration 150 / 171 | Total Loss: 2.3759772777557373 | KNN Loss: 2.3714306354522705 | CLS Loss: 0.004546529613435268\n",
      "Epoch 187 / 200 | iteration 160 / 171 | Total Loss: 2.4173052310943604 | KNN Loss: 2.4045779705047607 | CLS Loss: 0.012727233581244946\n",
      "Epoch 187 / 200 | iteration 170 / 171 | Total Loss: 2.425658702850342 | KNN Loss: 2.4212486743927 | CLS Loss: 0.004409925080835819\n",
      "Epoch: 187, Loss: 2.4086, Train: 0.9969, Valid: 0.9870, Best: 0.9878\n",
      "Epoch 188 / 200 | iteration 0 / 171 | Total Loss: 2.406219482421875 | KNN Loss: 2.40425181388855 | CLS Loss: 0.0019676366355270147\n",
      "Epoch 188 / 200 | iteration 10 / 171 | Total Loss: 2.4060001373291016 | KNN Loss: 2.390700340270996 | CLS Loss: 0.015299799852073193\n",
      "Epoch 188 / 200 | iteration 20 / 171 | Total Loss: 2.4059035778045654 | KNN Loss: 2.38984751701355 | CLS Loss: 0.016056101769208908\n",
      "Epoch 188 / 200 | iteration 30 / 171 | Total Loss: 2.3817808628082275 | KNN Loss: 2.373664379119873 | CLS Loss: 0.008116575889289379\n",
      "Epoch 188 / 200 | iteration 40 / 171 | Total Loss: 2.4244821071624756 | KNN Loss: 2.4136903285980225 | CLS Loss: 0.010791841894388199\n",
      "Epoch 188 / 200 | iteration 50 / 171 | Total Loss: 2.464536666870117 | KNN Loss: 2.459198236465454 | CLS Loss: 0.005338447168469429\n",
      "Epoch 188 / 200 | iteration 60 / 171 | Total Loss: 2.373190402984619 | KNN Loss: 2.3695461750030518 | CLS Loss: 0.0036441318225115538\n",
      "Epoch 188 / 200 | iteration 70 / 171 | Total Loss: 2.408139944076538 | KNN Loss: 2.388995409011841 | CLS Loss: 0.019144419580698013\n",
      "Epoch 188 / 200 | iteration 80 / 171 | Total Loss: 2.4128410816192627 | KNN Loss: 2.4042739868164062 | CLS Loss: 0.008567136712372303\n",
      "Epoch 188 / 200 | iteration 90 / 171 | Total Loss: 2.362109661102295 | KNN Loss: 2.356882095336914 | CLS Loss: 0.005227573215961456\n",
      "Epoch 188 / 200 | iteration 100 / 171 | Total Loss: 2.395080804824829 | KNN Loss: 2.384138822555542 | CLS Loss: 0.010941995307803154\n",
      "Epoch 188 / 200 | iteration 110 / 171 | Total Loss: 2.4282445907592773 | KNN Loss: 2.4183566570281982 | CLS Loss: 0.009887815453112125\n",
      "Epoch 188 / 200 | iteration 120 / 171 | Total Loss: 2.3728415966033936 | KNN Loss: 2.3653550148010254 | CLS Loss: 0.007486696820706129\n",
      "Epoch 188 / 200 | iteration 130 / 171 | Total Loss: 2.4258909225463867 | KNN Loss: 2.4137535095214844 | CLS Loss: 0.012137317098677158\n",
      "Epoch 188 / 200 | iteration 140 / 171 | Total Loss: 2.4106736183166504 | KNN Loss: 2.4028432369232178 | CLS Loss: 0.007830355316400528\n",
      "Epoch 188 / 200 | iteration 150 / 171 | Total Loss: 2.389000415802002 | KNN Loss: 2.38645339012146 | CLS Loss: 0.0025469656102359295\n",
      "Epoch 188 / 200 | iteration 160 / 171 | Total Loss: 2.407057046890259 | KNN Loss: 2.3977372646331787 | CLS Loss: 0.009319877251982689\n",
      "Epoch 188 / 200 | iteration 170 / 171 | Total Loss: 2.40224027633667 | KNN Loss: 2.398136854171753 | CLS Loss: 0.004103455692529678\n",
      "Epoch: 188, Loss: 2.4010, Train: 0.9968, Valid: 0.9871, Best: 0.9878\n",
      "Epoch 189 / 200 | iteration 0 / 171 | Total Loss: 2.3982889652252197 | KNN Loss: 2.381326198577881 | CLS Loss: 0.01696266606450081\n",
      "Epoch 189 / 200 | iteration 10 / 171 | Total Loss: 2.402024030685425 | KNN Loss: 2.4004077911376953 | CLS Loss: 0.0016162918182089925\n",
      "Epoch 189 / 200 | iteration 20 / 171 | Total Loss: 2.388254165649414 | KNN Loss: 2.3738908767700195 | CLS Loss: 0.014363182708621025\n",
      "Epoch 189 / 200 | iteration 30 / 171 | Total Loss: 2.3379032611846924 | KNN Loss: 2.332601308822632 | CLS Loss: 0.005302059929817915\n",
      "Epoch 189 / 200 | iteration 40 / 171 | Total Loss: 2.3964812755584717 | KNN Loss: 2.3826920986175537 | CLS Loss: 0.013789207674562931\n",
      "Epoch 189 / 200 | iteration 50 / 171 | Total Loss: 2.411830425262451 | KNN Loss: 2.398527145385742 | CLS Loss: 0.013303201645612717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 / 200 | iteration 60 / 171 | Total Loss: 2.425607681274414 | KNN Loss: 2.422868013381958 | CLS Loss: 0.00273971538990736\n",
      "Epoch 189 / 200 | iteration 70 / 171 | Total Loss: 2.403491258621216 | KNN Loss: 2.3969478607177734 | CLS Loss: 0.006543281488120556\n",
      "Epoch 189 / 200 | iteration 80 / 171 | Total Loss: 2.3887836933135986 | KNN Loss: 2.3818166255950928 | CLS Loss: 0.006966956425458193\n",
      "Epoch 189 / 200 | iteration 90 / 171 | Total Loss: 2.432523012161255 | KNN Loss: 2.4093360900878906 | CLS Loss: 0.023186897858977318\n",
      "Epoch 189 / 200 | iteration 100 / 171 | Total Loss: 2.386491537094116 | KNN Loss: 2.3740074634552 | CLS Loss: 0.012484166771173477\n",
      "Epoch 189 / 200 | iteration 110 / 171 | Total Loss: 2.426100492477417 | KNN Loss: 2.4050347805023193 | CLS Loss: 0.021065719425678253\n",
      "Epoch 189 / 200 | iteration 120 / 171 | Total Loss: 2.386218309402466 | KNN Loss: 2.384631872177124 | CLS Loss: 0.0015865350142121315\n",
      "Epoch 189 / 200 | iteration 130 / 171 | Total Loss: 2.4077579975128174 | KNN Loss: 2.3995821475982666 | CLS Loss: 0.008175792172551155\n",
      "Epoch 189 / 200 | iteration 140 / 171 | Total Loss: 2.399675130844116 | KNN Loss: 2.3944687843322754 | CLS Loss: 0.005206269212067127\n",
      "Epoch 189 / 200 | iteration 150 / 171 | Total Loss: 2.368637800216675 | KNN Loss: 2.3562707901000977 | CLS Loss: 0.01236698217689991\n",
      "Epoch 189 / 200 | iteration 160 / 171 | Total Loss: 2.442805767059326 | KNN Loss: 2.426891803741455 | CLS Loss: 0.01591399684548378\n",
      "Epoch 189 / 200 | iteration 170 / 171 | Total Loss: 2.4553136825561523 | KNN Loss: 2.443160057067871 | CLS Loss: 0.01215355284512043\n",
      "Epoch: 189, Loss: 2.4061, Train: 0.9968, Valid: 0.9855, Best: 0.9878\n",
      "Epoch 190 / 200 | iteration 0 / 171 | Total Loss: 2.4087607860565186 | KNN Loss: 2.3980438709259033 | CLS Loss: 0.010717013850808144\n",
      "Epoch 190 / 200 | iteration 10 / 171 | Total Loss: 2.406388282775879 | KNN Loss: 2.405029535293579 | CLS Loss: 0.001358752022497356\n",
      "Epoch 190 / 200 | iteration 20 / 171 | Total Loss: 2.417513847351074 | KNN Loss: 2.4038736820220947 | CLS Loss: 0.013640067540109158\n",
      "Epoch 190 / 200 | iteration 30 / 171 | Total Loss: 2.43045711517334 | KNN Loss: 2.419445276260376 | CLS Loss: 0.0110118817538023\n",
      "Epoch 190 / 200 | iteration 40 / 171 | Total Loss: 2.3830461502075195 | KNN Loss: 2.378434896469116 | CLS Loss: 0.004611184820532799\n",
      "Epoch 190 / 200 | iteration 50 / 171 | Total Loss: 2.3977410793304443 | KNN Loss: 2.390526533126831 | CLS Loss: 0.007214576005935669\n",
      "Epoch 190 / 200 | iteration 60 / 171 | Total Loss: 2.415290594100952 | KNN Loss: 2.408698558807373 | CLS Loss: 0.006592149380594492\n",
      "Epoch 190 / 200 | iteration 70 / 171 | Total Loss: 2.4225282669067383 | KNN Loss: 2.414698600769043 | CLS Loss: 0.007829729467630386\n",
      "Epoch 190 / 200 | iteration 80 / 171 | Total Loss: 2.439785957336426 | KNN Loss: 2.4282851219177246 | CLS Loss: 0.011500849388539791\n",
      "Epoch 190 / 200 | iteration 90 / 171 | Total Loss: 2.3853695392608643 | KNN Loss: 2.3834595680236816 | CLS Loss: 0.0019099974306300282\n",
      "Epoch 190 / 200 | iteration 100 / 171 | Total Loss: 2.430166244506836 | KNN Loss: 2.415438652038574 | CLS Loss: 0.014727613888680935\n",
      "Epoch 190 / 200 | iteration 110 / 171 | Total Loss: 2.3898985385894775 | KNN Loss: 2.383382797241211 | CLS Loss: 0.0065156808122992516\n",
      "Epoch 190 / 200 | iteration 120 / 171 | Total Loss: 2.418558359146118 | KNN Loss: 2.401759386062622 | CLS Loss: 0.01679886505007744\n",
      "Epoch 190 / 200 | iteration 130 / 171 | Total Loss: 2.377441167831421 | KNN Loss: 2.366847276687622 | CLS Loss: 0.010593874379992485\n",
      "Epoch 190 / 200 | iteration 140 / 171 | Total Loss: 2.4296088218688965 | KNN Loss: 2.418602705001831 | CLS Loss: 0.011006226763129234\n",
      "Epoch 190 / 200 | iteration 150 / 171 | Total Loss: 2.407498836517334 | KNN Loss: 2.3758039474487305 | CLS Loss: 0.031694792211055756\n",
      "Epoch 190 / 200 | iteration 160 / 171 | Total Loss: 2.4303295612335205 | KNN Loss: 2.417191982269287 | CLS Loss: 0.013137595728039742\n",
      "Epoch 190 / 200 | iteration 170 / 171 | Total Loss: 2.3989877700805664 | KNN Loss: 2.389993190765381 | CLS Loss: 0.008994470350444317\n",
      "Epoch: 190, Loss: 2.4045, Train: 0.9971, Valid: 0.9873, Best: 0.9878\n",
      "Epoch 191 / 200 | iteration 0 / 171 | Total Loss: 2.388725996017456 | KNN Loss: 2.381314516067505 | CLS Loss: 0.0074114007875323296\n",
      "Epoch 191 / 200 | iteration 10 / 171 | Total Loss: 2.4330825805664062 | KNN Loss: 2.4255197048187256 | CLS Loss: 0.0075628506019711494\n",
      "Epoch 191 / 200 | iteration 20 / 171 | Total Loss: 2.424443483352661 | KNN Loss: 2.4219274520874023 | CLS Loss: 0.002516074338927865\n",
      "Epoch 191 / 200 | iteration 30 / 171 | Total Loss: 2.3703389167785645 | KNN Loss: 2.3608524799346924 | CLS Loss: 0.009486440569162369\n",
      "Epoch 191 / 200 | iteration 40 / 171 | Total Loss: 2.4016685485839844 | KNN Loss: 2.3985300064086914 | CLS Loss: 0.003138482104986906\n",
      "Epoch 191 / 200 | iteration 50 / 171 | Total Loss: 2.4147393703460693 | KNN Loss: 2.3930275440216064 | CLS Loss: 0.021711939945816994\n",
      "Epoch 191 / 200 | iteration 60 / 171 | Total Loss: 2.361845016479492 | KNN Loss: 2.3566343784332275 | CLS Loss: 0.005210653878748417\n",
      "Epoch 191 / 200 | iteration 70 / 171 | Total Loss: 2.433882713317871 | KNN Loss: 2.4211387634277344 | CLS Loss: 0.012744024395942688\n",
      "Epoch 191 / 200 | iteration 80 / 171 | Total Loss: 2.3749468326568604 | KNN Loss: 2.372040033340454 | CLS Loss: 0.0029066884890198708\n",
      "Epoch 191 / 200 | iteration 90 / 171 | Total Loss: 2.471734046936035 | KNN Loss: 2.4582154750823975 | CLS Loss: 0.01351860910654068\n",
      "Epoch 191 / 200 | iteration 100 / 171 | Total Loss: 2.4330625534057617 | KNN Loss: 2.429616689682007 | CLS Loss: 0.003445879090577364\n",
      "Epoch 191 / 200 | iteration 110 / 171 | Total Loss: 2.376896858215332 | KNN Loss: 2.3655524253845215 | CLS Loss: 0.011344443075358868\n",
      "Epoch 191 / 200 | iteration 120 / 171 | Total Loss: 2.392568826675415 | KNN Loss: 2.3791301250457764 | CLS Loss: 0.013438737951219082\n",
      "Epoch 191 / 200 | iteration 130 / 171 | Total Loss: 2.420111894607544 | KNN Loss: 2.4037368297576904 | CLS Loss: 0.016375014558434486\n",
      "Epoch 191 / 200 | iteration 140 / 171 | Total Loss: 2.4180848598480225 | KNN Loss: 2.403578281402588 | CLS Loss: 0.014506560750305653\n",
      "Epoch 191 / 200 | iteration 150 / 171 | Total Loss: 2.39617657661438 | KNN Loss: 2.3886117935180664 | CLS Loss: 0.00756471324712038\n",
      "Epoch 191 / 200 | iteration 160 / 171 | Total Loss: 2.4005186557769775 | KNN Loss: 2.387786626815796 | CLS Loss: 0.012732051312923431\n",
      "Epoch 191 / 200 | iteration 170 / 171 | Total Loss: 2.428553819656372 | KNN Loss: 2.391963243484497 | CLS Loss: 0.036590587347745895\n",
      "Epoch: 191, Loss: 2.4095, Train: 0.9970, Valid: 0.9861, Best: 0.9878\n",
      "Epoch 192 / 200 | iteration 0 / 171 | Total Loss: 2.4391064643859863 | KNN Loss: 2.428894281387329 | CLS Loss: 0.010212165303528309\n",
      "Epoch 192 / 200 | iteration 10 / 171 | Total Loss: 2.4229416847229004 | KNN Loss: 2.406783103942871 | CLS Loss: 0.016158539801836014\n",
      "Epoch 192 / 200 | iteration 20 / 171 | Total Loss: 2.4103970527648926 | KNN Loss: 2.3890912532806396 | CLS Loss: 0.02130586840212345\n",
      "Epoch 192 / 200 | iteration 30 / 171 | Total Loss: 2.4047303199768066 | KNN Loss: 2.4015183448791504 | CLS Loss: 0.0032119194511324167\n",
      "Epoch 192 / 200 | iteration 40 / 171 | Total Loss: 2.4047865867614746 | KNN Loss: 2.3855643272399902 | CLS Loss: 0.01922214962542057\n",
      "Epoch 192 / 200 | iteration 50 / 171 | Total Loss: 2.371324062347412 | KNN Loss: 2.369631290435791 | CLS Loss: 0.0016927863471210003\n",
      "Epoch 192 / 200 | iteration 60 / 171 | Total Loss: 2.410482883453369 | KNN Loss: 2.408548355102539 | CLS Loss: 0.0019345309119671583\n",
      "Epoch 192 / 200 | iteration 70 / 171 | Total Loss: 2.413933753967285 | KNN Loss: 2.397150754928589 | CLS Loss: 0.0167829692363739\n",
      "Epoch 192 / 200 | iteration 80 / 171 | Total Loss: 2.400398015975952 | KNN Loss: 2.3798954486846924 | CLS Loss: 0.020502595230937004\n",
      "Epoch 192 / 200 | iteration 90 / 171 | Total Loss: 2.384204626083374 | KNN Loss: 2.374985694885254 | CLS Loss: 0.00921887531876564\n",
      "Epoch 192 / 200 | iteration 100 / 171 | Total Loss: 2.40372371673584 | KNN Loss: 2.3895316123962402 | CLS Loss: 0.014192022383213043\n",
      "Epoch 192 / 200 | iteration 110 / 171 | Total Loss: 2.42256236076355 | KNN Loss: 2.3846640586853027 | CLS Loss: 0.03789832442998886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192 / 200 | iteration 120 / 171 | Total Loss: 2.3859593868255615 | KNN Loss: 2.378988742828369 | CLS Loss: 0.006970677059143782\n",
      "Epoch 192 / 200 | iteration 130 / 171 | Total Loss: 2.409832715988159 | KNN Loss: 2.38132905960083 | CLS Loss: 0.028503581881523132\n",
      "Epoch 192 / 200 | iteration 140 / 171 | Total Loss: 2.4100027084350586 | KNN Loss: 2.4044291973114014 | CLS Loss: 0.005573393311351538\n",
      "Epoch 192 / 200 | iteration 150 / 171 | Total Loss: 2.433279514312744 | KNN Loss: 2.4250168800354004 | CLS Loss: 0.00826265662908554\n",
      "Epoch 192 / 200 | iteration 160 / 171 | Total Loss: 2.4009337425231934 | KNN Loss: 2.390872001647949 | CLS Loss: 0.010061747394502163\n",
      "Epoch 192 / 200 | iteration 170 / 171 | Total Loss: 2.368534564971924 | KNN Loss: 2.3657431602478027 | CLS Loss: 0.0027914096135646105\n",
      "Epoch: 192, Loss: 2.4036, Train: 0.9964, Valid: 0.9853, Best: 0.9878\n",
      "Epoch 193 / 200 | iteration 0 / 171 | Total Loss: 2.4220030307769775 | KNN Loss: 2.418938159942627 | CLS Loss: 0.0030649604741483927\n",
      "Epoch 193 / 200 | iteration 10 / 171 | Total Loss: 2.4091897010803223 | KNN Loss: 2.3768086433410645 | CLS Loss: 0.032380957156419754\n",
      "Epoch 193 / 200 | iteration 20 / 171 | Total Loss: 2.4175336360931396 | KNN Loss: 2.400268316268921 | CLS Loss: 0.01726532354950905\n",
      "Epoch 193 / 200 | iteration 30 / 171 | Total Loss: 2.4121387004852295 | KNN Loss: 2.4015653133392334 | CLS Loss: 0.01057346910238266\n",
      "Epoch 193 / 200 | iteration 40 / 171 | Total Loss: 2.3606598377227783 | KNN Loss: 2.35465407371521 | CLS Loss: 0.006005726754665375\n",
      "Epoch 193 / 200 | iteration 50 / 171 | Total Loss: 2.445544719696045 | KNN Loss: 2.41404390335083 | CLS Loss: 0.03150082752108574\n",
      "Epoch 193 / 200 | iteration 60 / 171 | Total Loss: 2.3824894428253174 | KNN Loss: 2.377798557281494 | CLS Loss: 0.004690923728048801\n",
      "Epoch 193 / 200 | iteration 70 / 171 | Total Loss: 2.407017946243286 | KNN Loss: 2.3891186714172363 | CLS Loss: 0.017899200320243835\n",
      "Epoch 193 / 200 | iteration 80 / 171 | Total Loss: 2.38116717338562 | KNN Loss: 2.37843918800354 | CLS Loss: 0.002727874554693699\n",
      "Epoch 193 / 200 | iteration 90 / 171 | Total Loss: 2.3646938800811768 | KNN Loss: 2.3545100688934326 | CLS Loss: 0.01018388569355011\n",
      "Epoch 193 / 200 | iteration 100 / 171 | Total Loss: 2.391789674758911 | KNN Loss: 2.384556770324707 | CLS Loss: 0.007232795935124159\n",
      "Epoch 193 / 200 | iteration 110 / 171 | Total Loss: 2.4029200077056885 | KNN Loss: 2.3925700187683105 | CLS Loss: 0.010349917225539684\n",
      "Epoch 193 / 200 | iteration 120 / 171 | Total Loss: 2.3757710456848145 | KNN Loss: 2.3715882301330566 | CLS Loss: 0.004182848148047924\n",
      "Epoch 193 / 200 | iteration 130 / 171 | Total Loss: 2.4438769817352295 | KNN Loss: 2.4212913513183594 | CLS Loss: 0.022585604339838028\n",
      "Epoch 193 / 200 | iteration 140 / 171 | Total Loss: 2.4346749782562256 | KNN Loss: 2.410438299179077 | CLS Loss: 0.024236787110567093\n",
      "Epoch 193 / 200 | iteration 150 / 171 | Total Loss: 2.3722808361053467 | KNN Loss: 2.370903968811035 | CLS Loss: 0.0013767934869974852\n",
      "Epoch 193 / 200 | iteration 160 / 171 | Total Loss: 2.372910499572754 | KNN Loss: 2.3675153255462646 | CLS Loss: 0.005395140033215284\n",
      "Epoch 193 / 200 | iteration 170 / 171 | Total Loss: 2.387324333190918 | KNN Loss: 2.380704641342163 | CLS Loss: 0.00661960244178772\n",
      "Epoch: 193, Loss: 2.4048, Train: 0.9972, Valid: 0.9871, Best: 0.9878\n",
      "Epoch 194 / 200 | iteration 0 / 171 | Total Loss: 2.391401767730713 | KNN Loss: 2.387566089630127 | CLS Loss: 0.0038355723954737186\n",
      "Epoch 194 / 200 | iteration 10 / 171 | Total Loss: 2.4336748123168945 | KNN Loss: 2.424464702606201 | CLS Loss: 0.009210213087499142\n",
      "Epoch 194 / 200 | iteration 20 / 171 | Total Loss: 2.409336566925049 | KNN Loss: 2.4081687927246094 | CLS Loss: 0.0011678015580400825\n",
      "Epoch 194 / 200 | iteration 30 / 171 | Total Loss: 2.4542605876922607 | KNN Loss: 2.4397313594818115 | CLS Loss: 0.014529185369610786\n",
      "Epoch 194 / 200 | iteration 40 / 171 | Total Loss: 2.4579989910125732 | KNN Loss: 2.4439573287963867 | CLS Loss: 0.014041612856090069\n",
      "Epoch 194 / 200 | iteration 50 / 171 | Total Loss: 2.418696641921997 | KNN Loss: 2.3985118865966797 | CLS Loss: 0.020184718072414398\n",
      "Epoch 194 / 200 | iteration 60 / 171 | Total Loss: 2.404322624206543 | KNN Loss: 2.4016294479370117 | CLS Loss: 0.002693187678232789\n",
      "Epoch 194 / 200 | iteration 70 / 171 | Total Loss: 2.402804374694824 | KNN Loss: 2.393263101577759 | CLS Loss: 0.009541312232613564\n",
      "Epoch 194 / 200 | iteration 80 / 171 | Total Loss: 2.4172520637512207 | KNN Loss: 2.404808521270752 | CLS Loss: 0.012443648651242256\n",
      "Epoch 194 / 200 | iteration 90 / 171 | Total Loss: 2.401427984237671 | KNN Loss: 2.3886754512786865 | CLS Loss: 0.012752577662467957\n",
      "Epoch 194 / 200 | iteration 100 / 171 | Total Loss: 2.3768370151519775 | KNN Loss: 2.3749899864196777 | CLS Loss: 0.0018470686627551913\n",
      "Epoch 194 / 200 | iteration 110 / 171 | Total Loss: 2.4018101692199707 | KNN Loss: 2.399901866912842 | CLS Loss: 0.001908398699015379\n",
      "Epoch 194 / 200 | iteration 120 / 171 | Total Loss: 2.4398159980773926 | KNN Loss: 2.435945510864258 | CLS Loss: 0.003870472777634859\n",
      "Epoch 194 / 200 | iteration 130 / 171 | Total Loss: 2.3914437294006348 | KNN Loss: 2.386791944503784 | CLS Loss: 0.004651795141398907\n",
      "Epoch 194 / 200 | iteration 140 / 171 | Total Loss: 2.395739793777466 | KNN Loss: 2.3940882682800293 | CLS Loss: 0.0016514539020135999\n",
      "Epoch 194 / 200 | iteration 150 / 171 | Total Loss: 2.4069204330444336 | KNN Loss: 2.4028542041778564 | CLS Loss: 0.00406624935567379\n",
      "Epoch 194 / 200 | iteration 160 / 171 | Total Loss: 2.4060726165771484 | KNN Loss: 2.4029455184936523 | CLS Loss: 0.00312718003988266\n",
      "Epoch 194 / 200 | iteration 170 / 171 | Total Loss: 2.4382972717285156 | KNN Loss: 2.4357213973999023 | CLS Loss: 0.0025758089032024145\n",
      "Epoch: 194, Loss: 2.4071, Train: 0.9973, Valid: 0.9860, Best: 0.9878\n",
      "Epoch 195 / 200 | iteration 0 / 171 | Total Loss: 2.4222843647003174 | KNN Loss: 2.4182138442993164 | CLS Loss: 0.004070558585226536\n",
      "Epoch 195 / 200 | iteration 10 / 171 | Total Loss: 2.391780138015747 | KNN Loss: 2.3813843727111816 | CLS Loss: 0.010395663790404797\n",
      "Epoch 195 / 200 | iteration 20 / 171 | Total Loss: 2.4079489707946777 | KNN Loss: 2.3909003734588623 | CLS Loss: 0.017048560082912445\n",
      "Epoch 195 / 200 | iteration 30 / 171 | Total Loss: 2.363912582397461 | KNN Loss: 2.3616788387298584 | CLS Loss: 0.002233838429674506\n",
      "Epoch 195 / 200 | iteration 40 / 171 | Total Loss: 2.4367311000823975 | KNN Loss: 2.403837203979492 | CLS Loss: 0.032893985509872437\n",
      "Epoch 195 / 200 | iteration 50 / 171 | Total Loss: 2.405318021774292 | KNN Loss: 2.398454189300537 | CLS Loss: 0.006863865070044994\n",
      "Epoch 195 / 200 | iteration 60 / 171 | Total Loss: 2.375960350036621 | KNN Loss: 2.371887683868408 | CLS Loss: 0.0040725599974393845\n",
      "Epoch 195 / 200 | iteration 70 / 171 | Total Loss: 2.390552520751953 | KNN Loss: 2.3749349117279053 | CLS Loss: 0.01561767514795065\n",
      "Epoch 195 / 200 | iteration 80 / 171 | Total Loss: 2.392324686050415 | KNN Loss: 2.3829476833343506 | CLS Loss: 0.009377055801451206\n",
      "Epoch 195 / 200 | iteration 90 / 171 | Total Loss: 2.4201056957244873 | KNN Loss: 2.400731086730957 | CLS Loss: 0.01937454752624035\n",
      "Epoch 195 / 200 | iteration 100 / 171 | Total Loss: 2.3969621658325195 | KNN Loss: 2.3923048973083496 | CLS Loss: 0.004657325334846973\n",
      "Epoch 195 / 200 | iteration 110 / 171 | Total Loss: 2.422847270965576 | KNN Loss: 2.403055429458618 | CLS Loss: 0.019791865721344948\n",
      "Epoch 195 / 200 | iteration 120 / 171 | Total Loss: 2.364088535308838 | KNN Loss: 2.362990617752075 | CLS Loss: 0.0010980330407619476\n",
      "Epoch 195 / 200 | iteration 130 / 171 | Total Loss: 2.443659782409668 | KNN Loss: 2.41133975982666 | CLS Loss: 0.032319922000169754\n",
      "Epoch 195 / 200 | iteration 140 / 171 | Total Loss: 2.4213695526123047 | KNN Loss: 2.402937889099121 | CLS Loss: 0.018431609496474266\n",
      "Epoch 195 / 200 | iteration 150 / 171 | Total Loss: 2.3804850578308105 | KNN Loss: 2.3706588745117188 | CLS Loss: 0.009826097637414932\n",
      "Epoch 195 / 200 | iteration 160 / 171 | Total Loss: 2.428936004638672 | KNN Loss: 2.412280321121216 | CLS Loss: 0.01665576919913292\n",
      "Epoch 195 / 200 | iteration 170 / 171 | Total Loss: 2.386317729949951 | KNN Loss: 2.3824729919433594 | CLS Loss: 0.003844622988253832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195, Loss: 2.4044, Train: 0.9959, Valid: 0.9861, Best: 0.9878\n",
      "Epoch 196 / 200 | iteration 0 / 171 | Total Loss: 2.382582664489746 | KNN Loss: 2.3770408630371094 | CLS Loss: 0.005541868507862091\n",
      "Epoch 196 / 200 | iteration 10 / 171 | Total Loss: 2.387298345565796 | KNN Loss: 2.3784537315368652 | CLS Loss: 0.008844670839607716\n",
      "Epoch 196 / 200 | iteration 20 / 171 | Total Loss: 2.4020190238952637 | KNN Loss: 2.400002956390381 | CLS Loss: 0.0020159974228590727\n",
      "Epoch 196 / 200 | iteration 30 / 171 | Total Loss: 2.4295778274536133 | KNN Loss: 2.4134514331817627 | CLS Loss: 0.016126492992043495\n",
      "Epoch 196 / 200 | iteration 40 / 171 | Total Loss: 2.3838071823120117 | KNN Loss: 2.369483709335327 | CLS Loss: 0.014323582872748375\n",
      "Epoch 196 / 200 | iteration 50 / 171 | Total Loss: 2.4163501262664795 | KNN Loss: 2.4147579669952393 | CLS Loss: 0.0015922078164294362\n",
      "Epoch 196 / 200 | iteration 60 / 171 | Total Loss: 2.3970820903778076 | KNN Loss: 2.391136884689331 | CLS Loss: 0.005945255048573017\n",
      "Epoch 196 / 200 | iteration 70 / 171 | Total Loss: 2.4272515773773193 | KNN Loss: 2.4091904163360596 | CLS Loss: 0.01806114986538887\n",
      "Epoch 196 / 200 | iteration 80 / 171 | Total Loss: 2.4576034545898438 | KNN Loss: 2.435751438140869 | CLS Loss: 0.021851995959877968\n",
      "Epoch 196 / 200 | iteration 90 / 171 | Total Loss: 2.4133493900299072 | KNN Loss: 2.410280227661133 | CLS Loss: 0.00306911114603281\n",
      "Epoch 196 / 200 | iteration 100 / 171 | Total Loss: 2.419898509979248 | KNN Loss: 2.418410539627075 | CLS Loss: 0.0014879523077979684\n",
      "Epoch 196 / 200 | iteration 110 / 171 | Total Loss: 2.4007699489593506 | KNN Loss: 2.3949248790740967 | CLS Loss: 0.0058450414799153805\n",
      "Epoch 196 / 200 | iteration 120 / 171 | Total Loss: 2.3914010524749756 | KNN Loss: 2.363417863845825 | CLS Loss: 0.027983304113149643\n",
      "Epoch 196 / 200 | iteration 130 / 171 | Total Loss: 2.4097654819488525 | KNN Loss: 2.3995819091796875 | CLS Loss: 0.010183533653616905\n",
      "Epoch 196 / 200 | iteration 140 / 171 | Total Loss: 2.401447057723999 | KNN Loss: 2.3934154510498047 | CLS Loss: 0.008031714707612991\n",
      "Epoch 196 / 200 | iteration 150 / 171 | Total Loss: 2.377563238143921 | KNN Loss: 2.3521463871002197 | CLS Loss: 0.02541692927479744\n",
      "Epoch 196 / 200 | iteration 160 / 171 | Total Loss: 2.3725192546844482 | KNN Loss: 2.3694241046905518 | CLS Loss: 0.0030951884109526873\n",
      "Epoch 196 / 200 | iteration 170 / 171 | Total Loss: 2.3984649181365967 | KNN Loss: 2.3863649368286133 | CLS Loss: 0.01210001204162836\n",
      "Epoch: 196, Loss: 2.4083, Train: 0.9973, Valid: 0.9862, Best: 0.9878\n",
      "Epoch 197 / 200 | iteration 0 / 171 | Total Loss: 2.40683650970459 | KNN Loss: 2.403216600418091 | CLS Loss: 0.003619840834289789\n",
      "Epoch 197 / 200 | iteration 10 / 171 | Total Loss: 2.3961844444274902 | KNN Loss: 2.3722620010375977 | CLS Loss: 0.023922542110085487\n",
      "Epoch 197 / 200 | iteration 20 / 171 | Total Loss: 2.4222335815429688 | KNN Loss: 2.415410280227661 | CLS Loss: 0.006823220290243626\n",
      "Epoch 197 / 200 | iteration 30 / 171 | Total Loss: 2.4133012294769287 | KNN Loss: 2.381831169128418 | CLS Loss: 0.031470175832509995\n",
      "Epoch 197 / 200 | iteration 40 / 171 | Total Loss: 2.391953706741333 | KNN Loss: 2.3822824954986572 | CLS Loss: 0.009671240113675594\n",
      "Epoch 197 / 200 | iteration 50 / 171 | Total Loss: 2.3842833042144775 | KNN Loss: 2.3792829513549805 | CLS Loss: 0.005000338889658451\n",
      "Epoch 197 / 200 | iteration 60 / 171 | Total Loss: 2.3891754150390625 | KNN Loss: 2.3839404582977295 | CLS Loss: 0.005235002841800451\n",
      "Epoch 197 / 200 | iteration 70 / 171 | Total Loss: 2.4197819232940674 | KNN Loss: 2.392190933227539 | CLS Loss: 0.027591004967689514\n",
      "Epoch 197 / 200 | iteration 80 / 171 | Total Loss: 2.4136297702789307 | KNN Loss: 2.409700870513916 | CLS Loss: 0.003928893245756626\n",
      "Epoch 197 / 200 | iteration 90 / 171 | Total Loss: 2.401401996612549 | KNN Loss: 2.385847330093384 | CLS Loss: 0.015554646961390972\n",
      "Epoch 197 / 200 | iteration 100 / 171 | Total Loss: 2.3885302543640137 | KNN Loss: 2.385920524597168 | CLS Loss: 0.002609614050015807\n",
      "Epoch 197 / 200 | iteration 110 / 171 | Total Loss: 2.4193942546844482 | KNN Loss: 2.3939340114593506 | CLS Loss: 0.02546023391187191\n",
      "Epoch 197 / 200 | iteration 120 / 171 | Total Loss: 2.425957679748535 | KNN Loss: 2.4104862213134766 | CLS Loss: 0.015471507795155048\n",
      "Epoch 197 / 200 | iteration 130 / 171 | Total Loss: 2.422224283218384 | KNN Loss: 2.416764497756958 | CLS Loss: 0.005459885112941265\n",
      "Epoch 197 / 200 | iteration 140 / 171 | Total Loss: 2.4262402057647705 | KNN Loss: 2.4235689640045166 | CLS Loss: 0.0026713234838098288\n",
      "Epoch 197 / 200 | iteration 150 / 171 | Total Loss: 2.379265069961548 | KNN Loss: 2.370978593826294 | CLS Loss: 0.008286457508802414\n",
      "Epoch 197 / 200 | iteration 160 / 171 | Total Loss: 2.3927347660064697 | KNN Loss: 2.389669895172119 | CLS Loss: 0.003064903896301985\n",
      "Epoch 197 / 200 | iteration 170 / 171 | Total Loss: 2.416975259780884 | KNN Loss: 2.403010845184326 | CLS Loss: 0.013964475132524967\n",
      "Epoch: 197, Loss: 2.4064, Train: 0.9970, Valid: 0.9871, Best: 0.9878\n",
      "Epoch 198 / 200 | iteration 0 / 171 | Total Loss: 2.4306116104125977 | KNN Loss: 2.429137706756592 | CLS Loss: 0.0014739702455699444\n",
      "Epoch 198 / 200 | iteration 10 / 171 | Total Loss: 2.4351913928985596 | KNN Loss: 2.405318260192871 | CLS Loss: 0.02987312339246273\n",
      "Epoch 198 / 200 | iteration 20 / 171 | Total Loss: 2.4108240604400635 | KNN Loss: 2.4084386825561523 | CLS Loss: 0.0023853101301938295\n",
      "Epoch 198 / 200 | iteration 30 / 171 | Total Loss: 2.420314311981201 | KNN Loss: 2.4182207584381104 | CLS Loss: 0.002093532122671604\n",
      "Epoch 198 / 200 | iteration 40 / 171 | Total Loss: 2.411630868911743 | KNN Loss: 2.3929312229156494 | CLS Loss: 0.018699629232287407\n",
      "Epoch 198 / 200 | iteration 50 / 171 | Total Loss: 2.4021682739257812 | KNN Loss: 2.39316463470459 | CLS Loss: 0.009003537707030773\n",
      "Epoch 198 / 200 | iteration 60 / 171 | Total Loss: 2.416689872741699 | KNN Loss: 2.4060964584350586 | CLS Loss: 0.010593414306640625\n",
      "Epoch 198 / 200 | iteration 70 / 171 | Total Loss: 2.4254910945892334 | KNN Loss: 2.4076523780822754 | CLS Loss: 0.01783880405128002\n",
      "Epoch 198 / 200 | iteration 80 / 171 | Total Loss: 2.39613676071167 | KNN Loss: 2.3883261680603027 | CLS Loss: 0.007810676470398903\n",
      "Epoch 198 / 200 | iteration 90 / 171 | Total Loss: 2.3706777095794678 | KNN Loss: 2.3680810928344727 | CLS Loss: 0.0025967289693653584\n",
      "Epoch 198 / 200 | iteration 100 / 171 | Total Loss: 2.381434679031372 | KNN Loss: 2.3730411529541016 | CLS Loss: 0.008393516764044762\n",
      "Epoch 198 / 200 | iteration 110 / 171 | Total Loss: 2.4299709796905518 | KNN Loss: 2.4262444972991943 | CLS Loss: 0.0037265028804540634\n",
      "Epoch 198 / 200 | iteration 120 / 171 | Total Loss: 2.413485288619995 | KNN Loss: 2.4054410457611084 | CLS Loss: 0.008044355548918247\n",
      "Epoch 198 / 200 | iteration 130 / 171 | Total Loss: 2.438042402267456 | KNN Loss: 2.4236371517181396 | CLS Loss: 0.014405294321477413\n",
      "Epoch 198 / 200 | iteration 140 / 171 | Total Loss: 2.3971760272979736 | KNN Loss: 2.389116048812866 | CLS Loss: 0.008059985004365444\n",
      "Epoch 198 / 200 | iteration 150 / 171 | Total Loss: 2.431370496749878 | KNN Loss: 2.4277994632720947 | CLS Loss: 0.003571067238226533\n",
      "Epoch 198 / 200 | iteration 160 / 171 | Total Loss: 2.3991377353668213 | KNN Loss: 2.3877902030944824 | CLS Loss: 0.01134757325053215\n",
      "Epoch 198 / 200 | iteration 170 / 171 | Total Loss: 2.4018447399139404 | KNN Loss: 2.396871566772461 | CLS Loss: 0.0049731857143342495\n",
      "Epoch: 198, Loss: 2.4091, Train: 0.9971, Valid: 0.9865, Best: 0.9878\n",
      "Epoch 199 / 200 | iteration 0 / 171 | Total Loss: 2.4113755226135254 | KNN Loss: 2.407386302947998 | CLS Loss: 0.0039891754277050495\n",
      "Epoch 199 / 200 | iteration 10 / 171 | Total Loss: 2.439523935317993 | KNN Loss: 2.419654607772827 | CLS Loss: 0.019869258627295494\n",
      "Epoch 199 / 200 | iteration 20 / 171 | Total Loss: 2.4111857414245605 | KNN Loss: 2.3861045837402344 | CLS Loss: 0.025081051513552666\n",
      "Epoch 199 / 200 | iteration 30 / 171 | Total Loss: 2.431673765182495 | KNN Loss: 2.4156970977783203 | CLS Loss: 0.015976557508111\n",
      "Epoch 199 / 200 | iteration 40 / 171 | Total Loss: 2.4212141036987305 | KNN Loss: 2.4112422466278076 | CLS Loss: 0.009971868246793747\n",
      "Epoch 199 / 200 | iteration 50 / 171 | Total Loss: 2.432544231414795 | KNN Loss: 2.428232192993164 | CLS Loss: 0.004312119446694851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 / 200 | iteration 60 / 171 | Total Loss: 2.4184951782226562 | KNN Loss: 2.4127755165100098 | CLS Loss: 0.005719643551856279\n",
      "Epoch 199 / 200 | iteration 70 / 171 | Total Loss: 2.3907227516174316 | KNN Loss: 2.373054027557373 | CLS Loss: 0.017668629065155983\n",
      "Epoch 199 / 200 | iteration 80 / 171 | Total Loss: 2.435577392578125 | KNN Loss: 2.432734966278076 | CLS Loss: 0.002842331537976861\n",
      "Epoch 199 / 200 | iteration 90 / 171 | Total Loss: 2.37748384475708 | KNN Loss: 2.372047185897827 | CLS Loss: 0.005436714738607407\n",
      "Epoch 199 / 200 | iteration 100 / 171 | Total Loss: 2.427713632583618 | KNN Loss: 2.4072234630584717 | CLS Loss: 0.02049008198082447\n",
      "Epoch 199 / 200 | iteration 110 / 171 | Total Loss: 2.403379440307617 | KNN Loss: 2.3833584785461426 | CLS Loss: 0.020020943135023117\n",
      "Epoch 199 / 200 | iteration 120 / 171 | Total Loss: 2.404508113861084 | KNN Loss: 2.400773286819458 | CLS Loss: 0.0037347835022956133\n",
      "Epoch 199 / 200 | iteration 130 / 171 | Total Loss: 2.395252227783203 | KNN Loss: 2.3822860717773438 | CLS Loss: 0.012966262176632881\n",
      "Epoch 199 / 200 | iteration 140 / 171 | Total Loss: 2.4702441692352295 | KNN Loss: 2.4429590702056885 | CLS Loss: 0.02728521078824997\n",
      "Epoch 199 / 200 | iteration 150 / 171 | Total Loss: 2.41566801071167 | KNN Loss: 2.411090135574341 | CLS Loss: 0.0045779370702803135\n",
      "Epoch 199 / 200 | iteration 160 / 171 | Total Loss: 2.4055380821228027 | KNN Loss: 2.4011905193328857 | CLS Loss: 0.004347669426351786\n",
      "Epoch 199 / 200 | iteration 170 / 171 | Total Loss: 2.4018425941467285 | KNN Loss: 2.3921754360198975 | CLS Loss: 0.00966713484376669\n",
      "Epoch: 199, Loss: 2.4084, Train: 0.9976, Valid: 0.9864, Best: 0.9878\n",
      "Epoch 200 / 200 | iteration 0 / 171 | Total Loss: 2.4123432636260986 | KNN Loss: 2.4078991413116455 | CLS Loss: 0.00444411626085639\n",
      "Epoch 200 / 200 | iteration 10 / 171 | Total Loss: 2.3826208114624023 | KNN Loss: 2.376631736755371 | CLS Loss: 0.005989153869450092\n",
      "Epoch 200 / 200 | iteration 20 / 171 | Total Loss: 2.4116644859313965 | KNN Loss: 2.4021055698394775 | CLS Loss: 0.009558845311403275\n",
      "Epoch 200 / 200 | iteration 30 / 171 | Total Loss: 2.413892984390259 | KNN Loss: 2.409230947494507 | CLS Loss: 0.004662032704800367\n",
      "Epoch 200 / 200 | iteration 40 / 171 | Total Loss: 2.3905348777770996 | KNN Loss: 2.3853111267089844 | CLS Loss: 0.005223780870437622\n",
      "Epoch 200 / 200 | iteration 50 / 171 | Total Loss: 2.40543794631958 | KNN Loss: 2.400778293609619 | CLS Loss: 0.004659575410187244\n",
      "Epoch 200 / 200 | iteration 60 / 171 | Total Loss: 2.4096450805664062 | KNN Loss: 2.403714179992676 | CLS Loss: 0.005930961575359106\n",
      "Epoch 200 / 200 | iteration 70 / 171 | Total Loss: 2.3820083141326904 | KNN Loss: 2.3759303092956543 | CLS Loss: 0.006078019738197327\n",
      "Epoch 200 / 200 | iteration 80 / 171 | Total Loss: 2.379878044128418 | KNN Loss: 2.36582088470459 | CLS Loss: 0.014057151973247528\n",
      "Epoch 200 / 200 | iteration 90 / 171 | Total Loss: 2.4212584495544434 | KNN Loss: 2.413329601287842 | CLS Loss: 0.007928879000246525\n",
      "Epoch 200 / 200 | iteration 100 / 171 | Total Loss: 2.3886520862579346 | KNN Loss: 2.367798089981079 | CLS Loss: 0.020853960886597633\n",
      "Epoch 200 / 200 | iteration 110 / 171 | Total Loss: 2.4447379112243652 | KNN Loss: 2.41697359085083 | CLS Loss: 0.027764322236180305\n",
      "Epoch 200 / 200 | iteration 120 / 171 | Total Loss: 2.409686803817749 | KNN Loss: 2.3863465785980225 | CLS Loss: 0.02334027923643589\n",
      "Epoch 200 / 200 | iteration 130 / 171 | Total Loss: 2.3819973468780518 | KNN Loss: 2.378950595855713 | CLS Loss: 0.003046676516532898\n",
      "Epoch 200 / 200 | iteration 140 / 171 | Total Loss: 2.3701236248016357 | KNN Loss: 2.360947608947754 | CLS Loss: 0.009176020510494709\n",
      "Epoch 200 / 200 | iteration 150 / 171 | Total Loss: 2.3812255859375 | KNN Loss: 2.378560781478882 | CLS Loss: 0.002664686879143119\n",
      "Epoch 200 / 200 | iteration 160 / 171 | Total Loss: 2.391111135482788 | KNN Loss: 2.387716293334961 | CLS Loss: 0.003394795348867774\n",
      "Epoch 200 / 200 | iteration 170 / 171 | Total Loss: 2.4581871032714844 | KNN Loss: 2.437595844268799 | CLS Loss: 0.02059122733771801\n",
      "Epoch: 200, Loss: 2.4067, Train: 0.9972, Valid: 0.9863, Best: 0.9878\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0\n",
    "losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(model, train_data_iter, optimizer, device)\n",
    "#     print(f\"Loss: {loss} =============================\")\n",
    "    losses.append(loss)\n",
    "    train_acc = test(model, train_data_iter, device)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_acc = test(model, test_data_iter, device)\n",
    "    val_accs.append(valid_acc)\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "              f'Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, '\n",
    "              f'Best: {best_valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9863, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_data_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7913183b4b9d44c188b6f5e9ff14857a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7785e21762f4f7299e516c066ce8946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_accs, label='train accuracy')\n",
    "plt.plot(val_accs, label='validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3597830d20a4f4b869c4df4f6bfd9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = torch.tensor([])\n",
    "projections = torch.tensor([])\n",
    "labels = torch.tensor([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_data_iter):\n",
    "        test_samples = torch.cat([test_samples, x])\n",
    "        labels = torch.cat([labels, y])\n",
    "        x = x.to(device)\n",
    "        _, interm = model(x, True)\n",
    "        projections = torch.cat([projections, interm.detach().cpu().flatten(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee83789976b403f8451da0ca5fbcc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b11f31bc1e40f498ba5a80bcd79366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distances = pairwise_distances(projections)\n",
    "# distances = np.triu(distances)\n",
    "distances_f = distances.flatten()\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.hist(distances_f[distances_f > 0], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = DBSCAN(eps=2, min_samples=10).fit_predict(projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inliers: 0.9101457219862044\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of inliers: {sum(clusters != -1) / len(clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d0b42da2e94b7b8e557e43e966289c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perplexity = 100\n",
    "p = reduce_dims_and_plot(projections[clusters != -1],\n",
    "                         y=clusters[clusters != -1],\n",
    "                         title=f'perplexity: {perplexity}',\n",
    "                         file_name=None,\n",
    "                         perplexity=perplexity,\n",
    "                         library='Multicore-TSNE',\n",
    "                         perform_PCA=False,\n",
    "                         projected=None,\n",
    "                         figure_type='2d',\n",
    "                         show_figure=True,\n",
    "                         close_figure=False,\n",
    "                         text=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Soft-Decision-Tree given the self-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dataset = list(zip(test_samples.flatten(1)[clusters!=-1], clusters[clusters != -1]))\n",
    "batch_size = 512\n",
    "tree_loader = torch.utils.data.DataLoader(tree_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define how we prune the weights of a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_node(node_weights, factor=1):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    mean_ = np.mean(w)\n",
    "    std_ = np.std(w)\n",
    "    node_weights[((mean_ - std_ * factor) < node_weights) & (node_weights < (mean_ + std_ * factor))] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_node_keep(node_weights, keep=4):\n",
    "    w = node_weights.cpu().detach().numpy()\n",
    "    throw_idx = np.argsort(abs(w))[:-keep]\n",
    "    node_weights[throw_idx] = 0\n",
    "    return node_weights\n",
    "\n",
    "def prune_tree(tree_, factor):\n",
    "    new_weights = tree_.inner_nodes.weight.clone()\n",
    "    for i in range(new_weights.shape[0]):\n",
    "        res = prune_node_keep(new_weights[i, :], factor)\n",
    "        new_weights[i, :] = res\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tree_.inner_nodes.weight.copy_(new_weights)\n",
    "        \n",
    "def sparseness(x):\n",
    "    s = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_ = x[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        s.append(sp)\n",
    "    return np.mean(s)\n",
    "\n",
    "def compute_regularization_by_level(tree):\n",
    "    total_reg = 0\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_level = np.floor(np.log2(i+1))\n",
    "        node_reg = torch.norm(tree.inner_nodes.weight[i].view(-1), 2)\n",
    "        total_reg += 2**(-cur_level) * node_reg\n",
    "    return total_reg\n",
    "\n",
    "def show_sparseness(tree):\n",
    "    avg_sp = sparseness(tree.inner_nodes.weight)\n",
    "    print(f\"Average sparseness: {avg_sp}\")\n",
    "    layer = 0\n",
    "    sps = []\n",
    "    for i in range(tree.inner_nodes.weight.shape[0]):\n",
    "        cur_layer = int(np.floor(np.log2(i+1)))\n",
    "        if cur_layer != layer:\n",
    "            print(f\"layer {layer}: {np.mean(sps)}\")\n",
    "            sps = []\n",
    "            layer = cur_layer\n",
    "\n",
    "        x_ = tree.inner_nodes.weight[i, :]\n",
    "        sp = (len(x_) - torch.norm(x_, 0).item()) / len(x_)\n",
    "        sps.append(sp)\n",
    "        \n",
    "    return avg_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, loader, device, log_interval, losses, accs, epoch, iteration):\n",
    "    model = model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        iteration += 1\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output, penalty = tree.forward(data)\n",
    "\n",
    "        # Loss\n",
    "        loss_tree = criterion(output, target.view(-1))\n",
    "\n",
    "        # Penalty\n",
    "        loss_tree += penalty\n",
    "\n",
    "        # Sparse regularization\n",
    "#         fc_params = torch.cat([x.view(-1) for x in tree.inner_nodes.parameters()])\n",
    "#         regularization = sparsity_lamda * torch.norm(fc_params, 2)\n",
    "        regularization = sparsity_lamda * compute_regularization_by_level(tree)\n",
    "        loss = loss_tree\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct = pred.eq(target.view(-1).data).sum()\n",
    "        accs.append(correct.item() / data.size()[0])\n",
    "\n",
    "        # Print training status\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Epoch: {epoch:02d} | Batch: {batch_idx:03d} / {len(loader):03d} | Total loss: {loss.item():.3f} | Reg loss: {regularization.item():.3f} | Tree loss: {loss_tree.item():.3f} | Accuracy: {correct.item() / data.size()[0]:03f} | {round((time.time() - start_time) / iteration, 3)} sec/iter\")\n",
    "            \n",
    "    return iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "sparsity_lamda = 2e-3\n",
    "epochs = 400\n",
    "log_interval = 100\n",
    "use_cuda = device != 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = SDT(input_dim=test_samples.shape[2], output_dim=len(set(clusters)) - 1, depth=tree_depth, lamda=1e-3, use_cuda=use_cuda)\n",
    "optimizer = torch.optim.Adam(tree.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "tree = tree.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "sparsity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparseness: 0.0\n",
      "layer 0: 0.0\n",
      "layer 1: 0.0\n",
      "layer 2: 0.0\n",
      "layer 3: 0.0\n",
      "layer 4: 0.0\n",
      "layer 5: 0.0\n",
      "layer 6: 0.0\n",
      "Epoch: 00 | Batch: 000 / 039 | Total loss: 3.071 | Reg loss: 0.009 | Tree loss: 3.071 | Accuracy: 0.037109 | 0.245 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 01 | Batch: 000 / 039 | Total loss: 2.984 | Reg loss: 0.005 | Tree loss: 2.984 | Accuracy: 0.326172 | 0.211 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 02 | Batch: 000 / 039 | Total loss: 2.934 | Reg loss: 0.008 | Tree loss: 2.934 | Accuracy: 0.316406 | 0.209 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 03 | Batch: 000 / 039 | Total loss: 2.886 | Reg loss: 0.010 | Tree loss: 2.886 | Accuracy: 0.345703 | 0.21 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 04 | Batch: 000 / 039 | Total loss: 2.875 | Reg loss: 0.012 | Tree loss: 2.875 | Accuracy: 0.285156 | 0.208 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 05 | Batch: 000 / 039 | Total loss: 2.822 | Reg loss: 0.013 | Tree loss: 2.822 | Accuracy: 0.312500 | 0.208 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 06 | Batch: 000 / 039 | Total loss: 2.801 | Reg loss: 0.014 | Tree loss: 2.801 | Accuracy: 0.310547 | 0.208 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 07 | Batch: 000 / 039 | Total loss: 2.781 | Reg loss: 0.015 | Tree loss: 2.781 | Accuracy: 0.316406 | 0.207 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 08 | Batch: 000 / 039 | Total loss: 2.751 | Reg loss: 0.015 | Tree loss: 2.751 | Accuracy: 0.320312 | 0.207 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 09 | Batch: 000 / 039 | Total loss: 2.726 | Reg loss: 0.016 | Tree loss: 2.726 | Accuracy: 0.339844 | 0.206 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 10 | Batch: 000 / 039 | Total loss: 2.726 | Reg loss: 0.017 | Tree loss: 2.726 | Accuracy: 0.292969 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 11 | Batch: 000 / 039 | Total loss: 2.681 | Reg loss: 0.018 | Tree loss: 2.681 | Accuracy: 0.332031 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 12 | Batch: 000 / 039 | Total loss: 2.639 | Reg loss: 0.018 | Tree loss: 2.639 | Accuracy: 0.337891 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 13 | Batch: 000 / 039 | Total loss: 2.657 | Reg loss: 0.019 | Tree loss: 2.657 | Accuracy: 0.308594 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 14 | Batch: 000 / 039 | Total loss: 2.578 | Reg loss: 0.020 | Tree loss: 2.578 | Accuracy: 0.355469 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 15 | Batch: 000 / 039 | Total loss: 2.539 | Reg loss: 0.020 | Tree loss: 2.539 | Accuracy: 0.355469 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 16 | Batch: 000 / 039 | Total loss: 2.561 | Reg loss: 0.021 | Tree loss: 2.561 | Accuracy: 0.341797 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 17 | Batch: 000 / 039 | Total loss: 2.532 | Reg loss: 0.021 | Tree loss: 2.532 | Accuracy: 0.339844 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 18 | Batch: 000 / 039 | Total loss: 2.565 | Reg loss: 0.022 | Tree loss: 2.565 | Accuracy: 0.324219 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 19 | Batch: 000 / 039 | Total loss: 2.501 | Reg loss: 0.023 | Tree loss: 2.501 | Accuracy: 0.359375 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 20 | Batch: 000 / 039 | Total loss: 2.519 | Reg loss: 0.023 | Tree loss: 2.519 | Accuracy: 0.326172 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 21 | Batch: 000 / 039 | Total loss: 2.467 | Reg loss: 0.023 | Tree loss: 2.467 | Accuracy: 0.371094 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 22 | Batch: 000 / 039 | Total loss: 2.462 | Reg loss: 0.024 | Tree loss: 2.462 | Accuracy: 0.369141 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Batch: 000 / 039 | Total loss: 2.394 | Reg loss: 0.024 | Tree loss: 2.394 | Accuracy: 0.408203 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 24 | Batch: 000 / 039 | Total loss: 2.455 | Reg loss: 0.025 | Tree loss: 2.455 | Accuracy: 0.341797 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 25 | Batch: 000 / 039 | Total loss: 2.424 | Reg loss: 0.025 | Tree loss: 2.424 | Accuracy: 0.376953 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 26 | Batch: 000 / 039 | Total loss: 2.444 | Reg loss: 0.025 | Tree loss: 2.444 | Accuracy: 0.335938 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 27 | Batch: 000 / 039 | Total loss: 2.450 | Reg loss: 0.026 | Tree loss: 2.450 | Accuracy: 0.318359 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 28 | Batch: 000 / 039 | Total loss: 2.422 | Reg loss: 0.026 | Tree loss: 2.422 | Accuracy: 0.351562 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 29 | Batch: 000 / 039 | Total loss: 2.342 | Reg loss: 0.026 | Tree loss: 2.342 | Accuracy: 0.396484 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 30 | Batch: 000 / 039 | Total loss: 2.422 | Reg loss: 0.026 | Tree loss: 2.422 | Accuracy: 0.351562 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 31 | Batch: 000 / 039 | Total loss: 2.445 | Reg loss: 0.026 | Tree loss: 2.445 | Accuracy: 0.306641 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 32 | Batch: 000 / 039 | Total loss: 2.407 | Reg loss: 0.027 | Tree loss: 2.407 | Accuracy: 0.316406 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 33 | Batch: 000 / 039 | Total loss: 2.399 | Reg loss: 0.027 | Tree loss: 2.399 | Accuracy: 0.335938 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 34 | Batch: 000 / 039 | Total loss: 2.358 | Reg loss: 0.027 | Tree loss: 2.358 | Accuracy: 0.363281 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 35 | Batch: 000 / 039 | Total loss: 2.394 | Reg loss: 0.027 | Tree loss: 2.394 | Accuracy: 0.330078 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 36 | Batch: 000 / 039 | Total loss: 2.287 | Reg loss: 0.027 | Tree loss: 2.287 | Accuracy: 0.375000 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 37 | Batch: 000 / 039 | Total loss: 2.377 | Reg loss: 0.028 | Tree loss: 2.377 | Accuracy: 0.337891 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 38 | Batch: 000 / 039 | Total loss: 2.285 | Reg loss: 0.028 | Tree loss: 2.285 | Accuracy: 0.361328 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 39 | Batch: 000 / 039 | Total loss: 2.349 | Reg loss: 0.028 | Tree loss: 2.349 | Accuracy: 0.337891 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 40 | Batch: 000 / 039 | Total loss: 2.371 | Reg loss: 0.028 | Tree loss: 2.371 | Accuracy: 0.322266 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 41 | Batch: 000 / 039 | Total loss: 2.291 | Reg loss: 0.028 | Tree loss: 2.291 | Accuracy: 0.363281 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 42 | Batch: 000 / 039 | Total loss: 2.289 | Reg loss: 0.028 | Tree loss: 2.289 | Accuracy: 0.363281 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 43 | Batch: 000 / 039 | Total loss: 2.380 | Reg loss: 0.028 | Tree loss: 2.380 | Accuracy: 0.320312 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 44 | Batch: 000 / 039 | Total loss: 2.271 | Reg loss: 0.028 | Tree loss: 2.271 | Accuracy: 0.382812 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 45 | Batch: 000 / 039 | Total loss: 2.286 | Reg loss: 0.028 | Tree loss: 2.286 | Accuracy: 0.365234 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Batch: 000 / 039 | Total loss: 2.372 | Reg loss: 0.028 | Tree loss: 2.372 | Accuracy: 0.335938 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 47 | Batch: 000 / 039 | Total loss: 2.272 | Reg loss: 0.029 | Tree loss: 2.272 | Accuracy: 0.392578 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 48 | Batch: 000 / 039 | Total loss: 2.365 | Reg loss: 0.029 | Tree loss: 2.365 | Accuracy: 0.339844 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 49 | Batch: 000 / 039 | Total loss: 2.310 | Reg loss: 0.029 | Tree loss: 2.310 | Accuracy: 0.333984 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 50 | Batch: 000 / 039 | Total loss: 2.289 | Reg loss: 0.029 | Tree loss: 2.289 | Accuracy: 0.339844 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 51 | Batch: 000 / 039 | Total loss: 2.298 | Reg loss: 0.029 | Tree loss: 2.298 | Accuracy: 0.359375 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 52 | Batch: 000 / 039 | Total loss: 2.294 | Reg loss: 0.029 | Tree loss: 2.294 | Accuracy: 0.363281 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 53 | Batch: 000 / 039 | Total loss: 2.275 | Reg loss: 0.029 | Tree loss: 2.275 | Accuracy: 0.363281 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 54 | Batch: 000 / 039 | Total loss: 2.281 | Reg loss: 0.029 | Tree loss: 2.281 | Accuracy: 0.384766 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 55 | Batch: 000 / 039 | Total loss: 2.312 | Reg loss: 0.029 | Tree loss: 2.312 | Accuracy: 0.353516 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 56 | Batch: 000 / 039 | Total loss: 2.314 | Reg loss: 0.029 | Tree loss: 2.314 | Accuracy: 0.353516 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 57 | Batch: 000 / 039 | Total loss: 2.319 | Reg loss: 0.029 | Tree loss: 2.319 | Accuracy: 0.357422 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 58 | Batch: 000 / 039 | Total loss: 2.394 | Reg loss: 0.029 | Tree loss: 2.394 | Accuracy: 0.308594 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 59 | Batch: 000 / 039 | Total loss: 2.312 | Reg loss: 0.029 | Tree loss: 2.312 | Accuracy: 0.333984 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 60 | Batch: 000 / 039 | Total loss: 2.297 | Reg loss: 0.029 | Tree loss: 2.297 | Accuracy: 0.347656 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 61 | Batch: 000 / 039 | Total loss: 2.327 | Reg loss: 0.029 | Tree loss: 2.327 | Accuracy: 0.343750 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 62 | Batch: 000 / 039 | Total loss: 2.346 | Reg loss: 0.029 | Tree loss: 2.346 | Accuracy: 0.310547 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 63 | Batch: 000 / 039 | Total loss: 2.334 | Reg loss: 0.029 | Tree loss: 2.334 | Accuracy: 0.324219 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 64 | Batch: 000 / 039 | Total loss: 2.349 | Reg loss: 0.029 | Tree loss: 2.349 | Accuracy: 0.341797 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 65 | Batch: 000 / 039 | Total loss: 2.299 | Reg loss: 0.029 | Tree loss: 2.299 | Accuracy: 0.355469 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 66 | Batch: 000 / 039 | Total loss: 2.268 | Reg loss: 0.030 | Tree loss: 2.268 | Accuracy: 0.349609 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 67 | Batch: 000 / 039 | Total loss: 2.407 | Reg loss: 0.030 | Tree loss: 2.407 | Accuracy: 0.320312 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 68 | Batch: 000 / 039 | Total loss: 2.301 | Reg loss: 0.030 | Tree loss: 2.301 | Accuracy: 0.349609 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 | Batch: 000 / 039 | Total loss: 2.414 | Reg loss: 0.030 | Tree loss: 2.414 | Accuracy: 0.292969 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 70 | Batch: 000 / 039 | Total loss: 2.290 | Reg loss: 0.030 | Tree loss: 2.290 | Accuracy: 0.333984 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 71 | Batch: 000 / 039 | Total loss: 2.336 | Reg loss: 0.030 | Tree loss: 2.336 | Accuracy: 0.320312 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 72 | Batch: 000 / 039 | Total loss: 2.303 | Reg loss: 0.030 | Tree loss: 2.303 | Accuracy: 0.353516 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 73 | Batch: 000 / 039 | Total loss: 2.369 | Reg loss: 0.030 | Tree loss: 2.369 | Accuracy: 0.320312 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 74 | Batch: 000 / 039 | Total loss: 2.270 | Reg loss: 0.030 | Tree loss: 2.270 | Accuracy: 0.371094 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 75 | Batch: 000 / 039 | Total loss: 2.263 | Reg loss: 0.030 | Tree loss: 2.263 | Accuracy: 0.359375 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 76 | Batch: 000 / 039 | Total loss: 2.387 | Reg loss: 0.030 | Tree loss: 2.387 | Accuracy: 0.318359 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 77 | Batch: 000 / 039 | Total loss: 2.295 | Reg loss: 0.030 | Tree loss: 2.295 | Accuracy: 0.335938 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 78 | Batch: 000 / 039 | Total loss: 2.279 | Reg loss: 0.030 | Tree loss: 2.279 | Accuracy: 0.347656 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 79 | Batch: 000 / 039 | Total loss: 2.422 | Reg loss: 0.030 | Tree loss: 2.422 | Accuracy: 0.310547 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 80 | Batch: 000 / 039 | Total loss: 2.363 | Reg loss: 0.030 | Tree loss: 2.363 | Accuracy: 0.316406 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 81 | Batch: 000 / 039 | Total loss: 2.346 | Reg loss: 0.030 | Tree loss: 2.346 | Accuracy: 0.308594 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 82 | Batch: 000 / 039 | Total loss: 2.313 | Reg loss: 0.030 | Tree loss: 2.313 | Accuracy: 0.330078 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 83 | Batch: 000 / 039 | Total loss: 2.293 | Reg loss: 0.030 | Tree loss: 2.293 | Accuracy: 0.335938 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 84 | Batch: 000 / 039 | Total loss: 2.189 | Reg loss: 0.030 | Tree loss: 2.189 | Accuracy: 0.367188 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 85 | Batch: 000 / 039 | Total loss: 2.263 | Reg loss: 0.030 | Tree loss: 2.263 | Accuracy: 0.359375 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 86 | Batch: 000 / 039 | Total loss: 2.242 | Reg loss: 0.030 | Tree loss: 2.242 | Accuracy: 0.363281 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 87 | Batch: 000 / 039 | Total loss: 2.274 | Reg loss: 0.030 | Tree loss: 2.274 | Accuracy: 0.365234 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 88 | Batch: 000 / 039 | Total loss: 2.263 | Reg loss: 0.030 | Tree loss: 2.263 | Accuracy: 0.341797 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 89 | Batch: 000 / 039 | Total loss: 2.283 | Reg loss: 0.030 | Tree loss: 2.283 | Accuracy: 0.349609 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 90 | Batch: 000 / 039 | Total loss: 2.281 | Reg loss: 0.030 | Tree loss: 2.281 | Accuracy: 0.361328 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 91 | Batch: 000 / 039 | Total loss: 2.309 | Reg loss: 0.030 | Tree loss: 2.309 | Accuracy: 0.341797 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 | Batch: 000 / 039 | Total loss: 2.222 | Reg loss: 0.031 | Tree loss: 2.222 | Accuracy: 0.361328 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 93 | Batch: 000 / 039 | Total loss: 2.330 | Reg loss: 0.031 | Tree loss: 2.330 | Accuracy: 0.312500 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 94 | Batch: 000 / 039 | Total loss: 2.276 | Reg loss: 0.031 | Tree loss: 2.276 | Accuracy: 0.347656 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 95 | Batch: 000 / 039 | Total loss: 2.269 | Reg loss: 0.031 | Tree loss: 2.269 | Accuracy: 0.330078 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 96 | Batch: 000 / 039 | Total loss: 2.318 | Reg loss: 0.031 | Tree loss: 2.318 | Accuracy: 0.316406 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 97 | Batch: 000 / 039 | Total loss: 2.329 | Reg loss: 0.031 | Tree loss: 2.329 | Accuracy: 0.330078 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 98 | Batch: 000 / 039 | Total loss: 2.225 | Reg loss: 0.031 | Tree loss: 2.225 | Accuracy: 0.373047 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 99 | Batch: 000 / 039 | Total loss: 2.349 | Reg loss: 0.031 | Tree loss: 2.349 | Accuracy: 0.339844 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 100 | Batch: 000 / 039 | Total loss: 2.253 | Reg loss: 0.031 | Tree loss: 2.253 | Accuracy: 0.347656 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 101 | Batch: 000 / 039 | Total loss: 2.227 | Reg loss: 0.031 | Tree loss: 2.227 | Accuracy: 0.375000 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 102 | Batch: 000 / 039 | Total loss: 2.268 | Reg loss: 0.031 | Tree loss: 2.268 | Accuracy: 0.390625 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 103 | Batch: 000 / 039 | Total loss: 2.327 | Reg loss: 0.031 | Tree loss: 2.327 | Accuracy: 0.310547 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 104 | Batch: 000 / 039 | Total loss: 2.305 | Reg loss: 0.031 | Tree loss: 2.305 | Accuracy: 0.353516 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 105 | Batch: 000 / 039 | Total loss: 2.326 | Reg loss: 0.031 | Tree loss: 2.326 | Accuracy: 0.322266 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 106 | Batch: 000 / 039 | Total loss: 2.334 | Reg loss: 0.031 | Tree loss: 2.334 | Accuracy: 0.310547 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 107 | Batch: 000 / 039 | Total loss: 2.318 | Reg loss: 0.031 | Tree loss: 2.318 | Accuracy: 0.341797 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 108 | Batch: 000 / 039 | Total loss: 2.318 | Reg loss: 0.031 | Tree loss: 2.318 | Accuracy: 0.324219 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 109 | Batch: 000 / 039 | Total loss: 2.297 | Reg loss: 0.031 | Tree loss: 2.297 | Accuracy: 0.324219 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 110 | Batch: 000 / 039 | Total loss: 2.335 | Reg loss: 0.031 | Tree loss: 2.335 | Accuracy: 0.330078 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 111 | Batch: 000 / 039 | Total loss: 2.325 | Reg loss: 0.031 | Tree loss: 2.325 | Accuracy: 0.320312 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 112 | Batch: 000 / 039 | Total loss: 2.207 | Reg loss: 0.031 | Tree loss: 2.207 | Accuracy: 0.365234 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 113 | Batch: 000 / 039 | Total loss: 2.272 | Reg loss: 0.031 | Tree loss: 2.272 | Accuracy: 0.347656 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 114 | Batch: 000 / 039 | Total loss: 2.211 | Reg loss: 0.031 | Tree loss: 2.211 | Accuracy: 0.375000 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115 | Batch: 000 / 039 | Total loss: 2.301 | Reg loss: 0.031 | Tree loss: 2.301 | Accuracy: 0.349609 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 116 | Batch: 000 / 039 | Total loss: 2.399 | Reg loss: 0.031 | Tree loss: 2.399 | Accuracy: 0.310547 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 117 | Batch: 000 / 039 | Total loss: 2.249 | Reg loss: 0.031 | Tree loss: 2.249 | Accuracy: 0.369141 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 118 | Batch: 000 / 039 | Total loss: 2.317 | Reg loss: 0.031 | Tree loss: 2.317 | Accuracy: 0.328125 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 119 | Batch: 000 / 039 | Total loss: 2.291 | Reg loss: 0.031 | Tree loss: 2.291 | Accuracy: 0.351562 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 120 | Batch: 000 / 039 | Total loss: 2.261 | Reg loss: 0.031 | Tree loss: 2.261 | Accuracy: 0.328125 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 121 | Batch: 000 / 039 | Total loss: 2.294 | Reg loss: 0.031 | Tree loss: 2.294 | Accuracy: 0.326172 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 122 | Batch: 000 / 039 | Total loss: 2.333 | Reg loss: 0.031 | Tree loss: 2.333 | Accuracy: 0.324219 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 123 | Batch: 000 / 039 | Total loss: 2.333 | Reg loss: 0.031 | Tree loss: 2.333 | Accuracy: 0.320312 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 124 | Batch: 000 / 039 | Total loss: 2.263 | Reg loss: 0.031 | Tree loss: 2.263 | Accuracy: 0.322266 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 125 | Batch: 000 / 039 | Total loss: 2.281 | Reg loss: 0.031 | Tree loss: 2.281 | Accuracy: 0.361328 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 126 | Batch: 000 / 039 | Total loss: 2.305 | Reg loss: 0.031 | Tree loss: 2.305 | Accuracy: 0.332031 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 127 | Batch: 000 / 039 | Total loss: 2.253 | Reg loss: 0.031 | Tree loss: 2.253 | Accuracy: 0.347656 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 128 | Batch: 000 / 039 | Total loss: 2.268 | Reg loss: 0.031 | Tree loss: 2.268 | Accuracy: 0.347656 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 129 | Batch: 000 / 039 | Total loss: 2.331 | Reg loss: 0.031 | Tree loss: 2.331 | Accuracy: 0.328125 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 130 | Batch: 000 / 039 | Total loss: 2.285 | Reg loss: 0.031 | Tree loss: 2.285 | Accuracy: 0.333984 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 131 | Batch: 000 / 039 | Total loss: 2.310 | Reg loss: 0.031 | Tree loss: 2.310 | Accuracy: 0.332031 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 132 | Batch: 000 / 039 | Total loss: 2.313 | Reg loss: 0.031 | Tree loss: 2.313 | Accuracy: 0.353516 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 133 | Batch: 000 / 039 | Total loss: 2.256 | Reg loss: 0.031 | Tree loss: 2.256 | Accuracy: 0.357422 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 134 | Batch: 000 / 039 | Total loss: 2.340 | Reg loss: 0.031 | Tree loss: 2.340 | Accuracy: 0.335938 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 135 | Batch: 000 / 039 | Total loss: 2.253 | Reg loss: 0.031 | Tree loss: 2.253 | Accuracy: 0.337891 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 136 | Batch: 000 / 039 | Total loss: 2.409 | Reg loss: 0.031 | Tree loss: 2.409 | Accuracy: 0.304688 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 137 | Batch: 000 / 039 | Total loss: 2.300 | Reg loss: 0.031 | Tree loss: 2.300 | Accuracy: 0.361328 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138 | Batch: 000 / 039 | Total loss: 2.265 | Reg loss: 0.032 | Tree loss: 2.265 | Accuracy: 0.347656 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 139 | Batch: 000 / 039 | Total loss: 2.236 | Reg loss: 0.032 | Tree loss: 2.236 | Accuracy: 0.361328 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 140 | Batch: 000 / 039 | Total loss: 2.197 | Reg loss: 0.032 | Tree loss: 2.197 | Accuracy: 0.353516 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 141 | Batch: 000 / 039 | Total loss: 2.252 | Reg loss: 0.032 | Tree loss: 2.252 | Accuracy: 0.369141 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 142 | Batch: 000 / 039 | Total loss: 2.193 | Reg loss: 0.032 | Tree loss: 2.193 | Accuracy: 0.373047 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 143 | Batch: 000 / 039 | Total loss: 2.172 | Reg loss: 0.032 | Tree loss: 2.172 | Accuracy: 0.390625 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 144 | Batch: 000 / 039 | Total loss: 2.149 | Reg loss: 0.032 | Tree loss: 2.149 | Accuracy: 0.402344 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 145 | Batch: 000 / 039 | Total loss: 2.171 | Reg loss: 0.032 | Tree loss: 2.171 | Accuracy: 0.373047 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 146 | Batch: 000 / 039 | Total loss: 2.205 | Reg loss: 0.032 | Tree loss: 2.205 | Accuracy: 0.359375 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 147 | Batch: 000 / 039 | Total loss: 2.199 | Reg loss: 0.032 | Tree loss: 2.199 | Accuracy: 0.378906 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 148 | Batch: 000 / 039 | Total loss: 2.169 | Reg loss: 0.031 | Tree loss: 2.169 | Accuracy: 0.419922 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 149 | Batch: 000 / 039 | Total loss: 2.218 | Reg loss: 0.031 | Tree loss: 2.218 | Accuracy: 0.390625 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 150 | Batch: 000 / 039 | Total loss: 2.246 | Reg loss: 0.031 | Tree loss: 2.246 | Accuracy: 0.335938 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 151 | Batch: 000 / 039 | Total loss: 2.100 | Reg loss: 0.031 | Tree loss: 2.100 | Accuracy: 0.410156 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 152 | Batch: 000 / 039 | Total loss: 2.119 | Reg loss: 0.031 | Tree loss: 2.119 | Accuracy: 0.435547 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 153 | Batch: 000 / 039 | Total loss: 2.134 | Reg loss: 0.031 | Tree loss: 2.134 | Accuracy: 0.412109 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 154 | Batch: 000 / 039 | Total loss: 2.162 | Reg loss: 0.031 | Tree loss: 2.162 | Accuracy: 0.406250 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 155 | Batch: 000 / 039 | Total loss: 2.139 | Reg loss: 0.031 | Tree loss: 2.139 | Accuracy: 0.406250 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 156 | Batch: 000 / 039 | Total loss: 2.220 | Reg loss: 0.031 | Tree loss: 2.220 | Accuracy: 0.373047 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 157 | Batch: 000 / 039 | Total loss: 2.167 | Reg loss: 0.031 | Tree loss: 2.167 | Accuracy: 0.390625 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 158 | Batch: 000 / 039 | Total loss: 2.138 | Reg loss: 0.031 | Tree loss: 2.138 | Accuracy: 0.419922 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 159 | Batch: 000 / 039 | Total loss: 2.172 | Reg loss: 0.031 | Tree loss: 2.172 | Accuracy: 0.382812 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 160 | Batch: 000 / 039 | Total loss: 2.176 | Reg loss: 0.031 | Tree loss: 2.176 | Accuracy: 0.382812 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161 | Batch: 000 / 039 | Total loss: 2.192 | Reg loss: 0.031 | Tree loss: 2.192 | Accuracy: 0.388672 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 162 | Batch: 000 / 039 | Total loss: 2.227 | Reg loss: 0.031 | Tree loss: 2.227 | Accuracy: 0.375000 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 163 | Batch: 000 / 039 | Total loss: 2.190 | Reg loss: 0.031 | Tree loss: 2.190 | Accuracy: 0.388672 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 164 | Batch: 000 / 039 | Total loss: 2.221 | Reg loss: 0.031 | Tree loss: 2.221 | Accuracy: 0.384766 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 165 | Batch: 000 / 039 | Total loss: 2.081 | Reg loss: 0.031 | Tree loss: 2.081 | Accuracy: 0.423828 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 166 | Batch: 000 / 039 | Total loss: 2.200 | Reg loss: 0.031 | Tree loss: 2.200 | Accuracy: 0.365234 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 167 | Batch: 000 / 039 | Total loss: 2.166 | Reg loss: 0.031 | Tree loss: 2.166 | Accuracy: 0.388672 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 168 | Batch: 000 / 039 | Total loss: 2.210 | Reg loss: 0.031 | Tree loss: 2.210 | Accuracy: 0.365234 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 169 | Batch: 000 / 039 | Total loss: 2.124 | Reg loss: 0.031 | Tree loss: 2.124 | Accuracy: 0.412109 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 170 | Batch: 000 / 039 | Total loss: 2.108 | Reg loss: 0.031 | Tree loss: 2.108 | Accuracy: 0.417969 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 171 | Batch: 000 / 039 | Total loss: 2.264 | Reg loss: 0.031 | Tree loss: 2.264 | Accuracy: 0.337891 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 172 | Batch: 000 / 039 | Total loss: 2.126 | Reg loss: 0.031 | Tree loss: 2.126 | Accuracy: 0.392578 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 173 | Batch: 000 / 039 | Total loss: 2.146 | Reg loss: 0.031 | Tree loss: 2.146 | Accuracy: 0.392578 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 174 | Batch: 000 / 039 | Total loss: 2.104 | Reg loss: 0.031 | Tree loss: 2.104 | Accuracy: 0.416016 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 175 | Batch: 000 / 039 | Total loss: 2.148 | Reg loss: 0.031 | Tree loss: 2.148 | Accuracy: 0.392578 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 176 | Batch: 000 / 039 | Total loss: 2.208 | Reg loss: 0.031 | Tree loss: 2.208 | Accuracy: 0.371094 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 177 | Batch: 000 / 039 | Total loss: 2.221 | Reg loss: 0.031 | Tree loss: 2.221 | Accuracy: 0.371094 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 178 | Batch: 000 / 039 | Total loss: 2.125 | Reg loss: 0.031 | Tree loss: 2.125 | Accuracy: 0.433594 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 179 | Batch: 000 / 039 | Total loss: 2.148 | Reg loss: 0.031 | Tree loss: 2.148 | Accuracy: 0.414062 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 180 | Batch: 000 / 039 | Total loss: 2.149 | Reg loss: 0.031 | Tree loss: 2.149 | Accuracy: 0.404297 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 181 | Batch: 000 / 039 | Total loss: 2.240 | Reg loss: 0.031 | Tree loss: 2.240 | Accuracy: 0.367188 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 182 | Batch: 000 / 039 | Total loss: 2.147 | Reg loss: 0.031 | Tree loss: 2.147 | Accuracy: 0.417969 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 183 | Batch: 000 / 039 | Total loss: 2.218 | Reg loss: 0.031 | Tree loss: 2.218 | Accuracy: 0.386719 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184 | Batch: 000 / 039 | Total loss: 2.123 | Reg loss: 0.031 | Tree loss: 2.123 | Accuracy: 0.429688 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 185 | Batch: 000 / 039 | Total loss: 2.088 | Reg loss: 0.031 | Tree loss: 2.088 | Accuracy: 0.417969 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 186 | Batch: 000 / 039 | Total loss: 2.253 | Reg loss: 0.031 | Tree loss: 2.253 | Accuracy: 0.369141 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 187 | Batch: 000 / 039 | Total loss: 2.181 | Reg loss: 0.031 | Tree loss: 2.181 | Accuracy: 0.400391 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 188 | Batch: 000 / 039 | Total loss: 2.168 | Reg loss: 0.031 | Tree loss: 2.168 | Accuracy: 0.398438 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 189 | Batch: 000 / 039 | Total loss: 2.200 | Reg loss: 0.031 | Tree loss: 2.200 | Accuracy: 0.382812 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 190 | Batch: 000 / 039 | Total loss: 2.184 | Reg loss: 0.031 | Tree loss: 2.184 | Accuracy: 0.392578 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 191 | Batch: 000 / 039 | Total loss: 2.241 | Reg loss: 0.032 | Tree loss: 2.241 | Accuracy: 0.365234 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 192 | Batch: 000 / 039 | Total loss: 2.151 | Reg loss: 0.032 | Tree loss: 2.151 | Accuracy: 0.404297 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 193 | Batch: 000 / 039 | Total loss: 2.199 | Reg loss: 0.032 | Tree loss: 2.199 | Accuracy: 0.390625 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 194 | Batch: 000 / 039 | Total loss: 2.238 | Reg loss: 0.032 | Tree loss: 2.238 | Accuracy: 0.353516 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 195 | Batch: 000 / 039 | Total loss: 2.174 | Reg loss: 0.032 | Tree loss: 2.174 | Accuracy: 0.392578 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 196 | Batch: 000 / 039 | Total loss: 2.253 | Reg loss: 0.032 | Tree loss: 2.253 | Accuracy: 0.355469 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 197 | Batch: 000 / 039 | Total loss: 2.176 | Reg loss: 0.032 | Tree loss: 2.176 | Accuracy: 0.402344 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 198 | Batch: 000 / 039 | Total loss: 2.231 | Reg loss: 0.032 | Tree loss: 2.231 | Accuracy: 0.365234 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 199 | Batch: 000 / 039 | Total loss: 2.209 | Reg loss: 0.032 | Tree loss: 2.209 | Accuracy: 0.382812 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 200 | Batch: 000 / 039 | Total loss: 2.231 | Reg loss: 0.032 | Tree loss: 2.231 | Accuracy: 0.375000 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 201 | Batch: 000 / 039 | Total loss: 2.168 | Reg loss: 0.032 | Tree loss: 2.168 | Accuracy: 0.386719 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 202 | Batch: 000 / 039 | Total loss: 2.177 | Reg loss: 0.032 | Tree loss: 2.177 | Accuracy: 0.398438 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 203 | Batch: 000 / 039 | Total loss: 2.190 | Reg loss: 0.032 | Tree loss: 2.190 | Accuracy: 0.375000 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 204 | Batch: 000 / 039 | Total loss: 2.156 | Reg loss: 0.032 | Tree loss: 2.156 | Accuracy: 0.398438 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 205 | Batch: 000 / 039 | Total loss: 2.133 | Reg loss: 0.032 | Tree loss: 2.133 | Accuracy: 0.437500 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 206 | Batch: 000 / 039 | Total loss: 2.256 | Reg loss: 0.032 | Tree loss: 2.256 | Accuracy: 0.376953 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207 | Batch: 000 / 039 | Total loss: 2.099 | Reg loss: 0.032 | Tree loss: 2.099 | Accuracy: 0.400391 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 208 | Batch: 000 / 039 | Total loss: 2.324 | Reg loss: 0.032 | Tree loss: 2.324 | Accuracy: 0.343750 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 209 | Batch: 000 / 039 | Total loss: 2.209 | Reg loss: 0.032 | Tree loss: 2.209 | Accuracy: 0.396484 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 210 | Batch: 000 / 039 | Total loss: 2.308 | Reg loss: 0.032 | Tree loss: 2.308 | Accuracy: 0.335938 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 211 | Batch: 000 / 039 | Total loss: 2.185 | Reg loss: 0.032 | Tree loss: 2.185 | Accuracy: 0.388672 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 212 | Batch: 000 / 039 | Total loss: 2.106 | Reg loss: 0.032 | Tree loss: 2.106 | Accuracy: 0.423828 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 213 | Batch: 000 / 039 | Total loss: 2.222 | Reg loss: 0.032 | Tree loss: 2.222 | Accuracy: 0.363281 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 214 | Batch: 000 / 039 | Total loss: 2.079 | Reg loss: 0.032 | Tree loss: 2.079 | Accuracy: 0.445312 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 215 | Batch: 000 / 039 | Total loss: 2.143 | Reg loss: 0.032 | Tree loss: 2.143 | Accuracy: 0.380859 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 216 | Batch: 000 / 039 | Total loss: 2.187 | Reg loss: 0.032 | Tree loss: 2.187 | Accuracy: 0.375000 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 217 | Batch: 000 / 039 | Total loss: 2.220 | Reg loss: 0.032 | Tree loss: 2.220 | Accuracy: 0.388672 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 218 | Batch: 000 / 039 | Total loss: 2.182 | Reg loss: 0.032 | Tree loss: 2.182 | Accuracy: 0.388672 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 219 | Batch: 000 / 039 | Total loss: 2.162 | Reg loss: 0.032 | Tree loss: 2.162 | Accuracy: 0.396484 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 220 | Batch: 000 / 039 | Total loss: 2.247 | Reg loss: 0.032 | Tree loss: 2.247 | Accuracy: 0.371094 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 221 | Batch: 000 / 039 | Total loss: 2.226 | Reg loss: 0.032 | Tree loss: 2.226 | Accuracy: 0.406250 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 222 | Batch: 000 / 039 | Total loss: 2.226 | Reg loss: 0.033 | Tree loss: 2.226 | Accuracy: 0.380859 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 223 | Batch: 000 / 039 | Total loss: 2.193 | Reg loss: 0.032 | Tree loss: 2.193 | Accuracy: 0.380859 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 224 | Batch: 000 / 039 | Total loss: 2.183 | Reg loss: 0.032 | Tree loss: 2.183 | Accuracy: 0.402344 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 225 | Batch: 000 / 039 | Total loss: 2.206 | Reg loss: 0.033 | Tree loss: 2.206 | Accuracy: 0.408203 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 226 | Batch: 000 / 039 | Total loss: 2.294 | Reg loss: 0.033 | Tree loss: 2.294 | Accuracy: 0.365234 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 227 | Batch: 000 / 039 | Total loss: 2.237 | Reg loss: 0.033 | Tree loss: 2.237 | Accuracy: 0.376953 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 228 | Batch: 000 / 039 | Total loss: 2.276 | Reg loss: 0.033 | Tree loss: 2.276 | Accuracy: 0.376953 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 229 | Batch: 000 / 039 | Total loss: 2.170 | Reg loss: 0.033 | Tree loss: 2.170 | Accuracy: 0.390625 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 230 | Batch: 000 / 039 | Total loss: 2.181 | Reg loss: 0.033 | Tree loss: 2.181 | Accuracy: 0.406250 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 231 | Batch: 000 / 039 | Total loss: 2.302 | Reg loss: 0.033 | Tree loss: 2.302 | Accuracy: 0.361328 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 232 | Batch: 000 / 039 | Total loss: 2.287 | Reg loss: 0.033 | Tree loss: 2.287 | Accuracy: 0.363281 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 233 | Batch: 000 / 039 | Total loss: 2.143 | Reg loss: 0.033 | Tree loss: 2.143 | Accuracy: 0.408203 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 234 | Batch: 000 / 039 | Total loss: 2.222 | Reg loss: 0.033 | Tree loss: 2.222 | Accuracy: 0.388672 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 235 | Batch: 000 / 039 | Total loss: 2.022 | Reg loss: 0.033 | Tree loss: 2.022 | Accuracy: 0.437500 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 236 | Batch: 000 / 039 | Total loss: 2.302 | Reg loss: 0.033 | Tree loss: 2.302 | Accuracy: 0.353516 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 237 | Batch: 000 / 039 | Total loss: 2.215 | Reg loss: 0.033 | Tree loss: 2.215 | Accuracy: 0.390625 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 238 | Batch: 000 / 039 | Total loss: 2.145 | Reg loss: 0.033 | Tree loss: 2.145 | Accuracy: 0.388672 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 239 | Batch: 000 / 039 | Total loss: 2.228 | Reg loss: 0.033 | Tree loss: 2.228 | Accuracy: 0.367188 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 240 | Batch: 000 / 039 | Total loss: 2.244 | Reg loss: 0.033 | Tree loss: 2.244 | Accuracy: 0.394531 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 241 | Batch: 000 / 039 | Total loss: 2.211 | Reg loss: 0.033 | Tree loss: 2.211 | Accuracy: 0.386719 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 242 | Batch: 000 / 039 | Total loss: 2.161 | Reg loss: 0.033 | Tree loss: 2.161 | Accuracy: 0.410156 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 243 | Batch: 000 / 039 | Total loss: 2.108 | Reg loss: 0.033 | Tree loss: 2.108 | Accuracy: 0.416016 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 244 | Batch: 000 / 039 | Total loss: 2.211 | Reg loss: 0.033 | Tree loss: 2.211 | Accuracy: 0.396484 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 245 | Batch: 000 / 039 | Total loss: 2.101 | Reg loss: 0.033 | Tree loss: 2.101 | Accuracy: 0.416016 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 246 | Batch: 000 / 039 | Total loss: 2.236 | Reg loss: 0.033 | Tree loss: 2.236 | Accuracy: 0.378906 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 247 | Batch: 000 / 039 | Total loss: 2.183 | Reg loss: 0.033 | Tree loss: 2.183 | Accuracy: 0.402344 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 248 | Batch: 000 / 039 | Total loss: 2.114 | Reg loss: 0.033 | Tree loss: 2.114 | Accuracy: 0.414062 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 249 | Batch: 000 / 039 | Total loss: 2.187 | Reg loss: 0.033 | Tree loss: 2.187 | Accuracy: 0.406250 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 250 | Batch: 000 / 039 | Total loss: 2.254 | Reg loss: 0.033 | Tree loss: 2.254 | Accuracy: 0.367188 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 251 | Batch: 000 / 039 | Total loss: 2.177 | Reg loss: 0.033 | Tree loss: 2.177 | Accuracy: 0.369141 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 252 | Batch: 000 / 039 | Total loss: 2.193 | Reg loss: 0.033 | Tree loss: 2.193 | Accuracy: 0.396484 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 253 | Batch: 000 / 039 | Total loss: 2.229 | Reg loss: 0.033 | Tree loss: 2.229 | Accuracy: 0.369141 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 254 | Batch: 000 / 039 | Total loss: 2.177 | Reg loss: 0.033 | Tree loss: 2.177 | Accuracy: 0.404297 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 255 | Batch: 000 / 039 | Total loss: 2.211 | Reg loss: 0.033 | Tree loss: 2.211 | Accuracy: 0.376953 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 256 | Batch: 000 / 039 | Total loss: 2.223 | Reg loss: 0.033 | Tree loss: 2.223 | Accuracy: 0.386719 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 257 | Batch: 000 / 039 | Total loss: 2.168 | Reg loss: 0.033 | Tree loss: 2.168 | Accuracy: 0.396484 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 258 | Batch: 000 / 039 | Total loss: 2.204 | Reg loss: 0.033 | Tree loss: 2.204 | Accuracy: 0.380859 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 259 | Batch: 000 / 039 | Total loss: 2.178 | Reg loss: 0.033 | Tree loss: 2.178 | Accuracy: 0.369141 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 260 | Batch: 000 / 039 | Total loss: 2.090 | Reg loss: 0.033 | Tree loss: 2.090 | Accuracy: 0.423828 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 261 | Batch: 000 / 039 | Total loss: 2.272 | Reg loss: 0.033 | Tree loss: 2.272 | Accuracy: 0.355469 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 262 | Batch: 000 / 039 | Total loss: 2.142 | Reg loss: 0.033 | Tree loss: 2.142 | Accuracy: 0.416016 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 263 | Batch: 000 / 039 | Total loss: 2.074 | Reg loss: 0.033 | Tree loss: 2.074 | Accuracy: 0.406250 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 264 | Batch: 000 / 039 | Total loss: 2.169 | Reg loss: 0.033 | Tree loss: 2.169 | Accuracy: 0.375000 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 265 | Batch: 000 / 039 | Total loss: 2.228 | Reg loss: 0.033 | Tree loss: 2.228 | Accuracy: 0.375000 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 266 | Batch: 000 / 039 | Total loss: 2.135 | Reg loss: 0.033 | Tree loss: 2.135 | Accuracy: 0.416016 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 267 | Batch: 000 / 039 | Total loss: 2.166 | Reg loss: 0.033 | Tree loss: 2.166 | Accuracy: 0.404297 | 0.202 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 268 | Batch: 000 / 039 | Total loss: 2.292 | Reg loss: 0.032 | Tree loss: 2.292 | Accuracy: 0.351562 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 269 | Batch: 000 / 039 | Total loss: 2.080 | Reg loss: 0.032 | Tree loss: 2.080 | Accuracy: 0.429688 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 270 | Batch: 000 / 039 | Total loss: 2.172 | Reg loss: 0.032 | Tree loss: 2.172 | Accuracy: 0.382812 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 271 | Batch: 000 / 039 | Total loss: 2.254 | Reg loss: 0.032 | Tree loss: 2.254 | Accuracy: 0.353516 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 272 | Batch: 000 / 039 | Total loss: 2.161 | Reg loss: 0.032 | Tree loss: 2.161 | Accuracy: 0.388672 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 273 | Batch: 000 / 039 | Total loss: 2.169 | Reg loss: 0.032 | Tree loss: 2.169 | Accuracy: 0.371094 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 274 | Batch: 000 / 039 | Total loss: 2.191 | Reg loss: 0.032 | Tree loss: 2.191 | Accuracy: 0.384766 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 275 | Batch: 000 / 039 | Total loss: 2.137 | Reg loss: 0.032 | Tree loss: 2.137 | Accuracy: 0.412109 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 276 | Batch: 000 / 039 | Total loss: 2.161 | Reg loss: 0.032 | Tree loss: 2.161 | Accuracy: 0.376953 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 277 | Batch: 000 / 039 | Total loss: 2.275 | Reg loss: 0.032 | Tree loss: 2.275 | Accuracy: 0.355469 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 278 | Batch: 000 / 039 | Total loss: 2.215 | Reg loss: 0.032 | Tree loss: 2.215 | Accuracy: 0.367188 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 279 | Batch: 000 / 039 | Total loss: 2.164 | Reg loss: 0.032 | Tree loss: 2.164 | Accuracy: 0.376953 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 280 | Batch: 000 / 039 | Total loss: 2.146 | Reg loss: 0.032 | Tree loss: 2.146 | Accuracy: 0.402344 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 281 | Batch: 000 / 039 | Total loss: 2.233 | Reg loss: 0.032 | Tree loss: 2.233 | Accuracy: 0.365234 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 282 | Batch: 000 / 039 | Total loss: 2.230 | Reg loss: 0.032 | Tree loss: 2.230 | Accuracy: 0.353516 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 283 | Batch: 000 / 039 | Total loss: 2.194 | Reg loss: 0.032 | Tree loss: 2.194 | Accuracy: 0.380859 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 284 | Batch: 000 / 039 | Total loss: 2.257 | Reg loss: 0.032 | Tree loss: 2.257 | Accuracy: 0.351562 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 285 | Batch: 000 / 039 | Total loss: 2.177 | Reg loss: 0.032 | Tree loss: 2.177 | Accuracy: 0.380859 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 286 | Batch: 000 / 039 | Total loss: 2.235 | Reg loss: 0.032 | Tree loss: 2.235 | Accuracy: 0.359375 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 287 | Batch: 000 / 039 | Total loss: 2.069 | Reg loss: 0.032 | Tree loss: 2.069 | Accuracy: 0.427734 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 288 | Batch: 000 / 039 | Total loss: 2.140 | Reg loss: 0.032 | Tree loss: 2.140 | Accuracy: 0.384766 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 289 | Batch: 000 / 039 | Total loss: 2.085 | Reg loss: 0.032 | Tree loss: 2.085 | Accuracy: 0.410156 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 290 | Batch: 000 / 039 | Total loss: 2.190 | Reg loss: 0.032 | Tree loss: 2.190 | Accuracy: 0.363281 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 291 | Batch: 000 / 039 | Total loss: 2.148 | Reg loss: 0.032 | Tree loss: 2.148 | Accuracy: 0.398438 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 292 | Batch: 000 / 039 | Total loss: 2.086 | Reg loss: 0.032 | Tree loss: 2.086 | Accuracy: 0.402344 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 293 | Batch: 000 / 039 | Total loss: 2.253 | Reg loss: 0.032 | Tree loss: 2.253 | Accuracy: 0.369141 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 294 | Batch: 000 / 039 | Total loss: 2.189 | Reg loss: 0.032 | Tree loss: 2.189 | Accuracy: 0.390625 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 295 | Batch: 000 / 039 | Total loss: 2.241 | Reg loss: 0.032 | Tree loss: 2.241 | Accuracy: 0.355469 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 296 | Batch: 000 / 039 | Total loss: 2.118 | Reg loss: 0.032 | Tree loss: 2.118 | Accuracy: 0.414062 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 297 | Batch: 000 / 039 | Total loss: 2.183 | Reg loss: 0.032 | Tree loss: 2.183 | Accuracy: 0.375000 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 298 | Batch: 000 / 039 | Total loss: 2.218 | Reg loss: 0.032 | Tree loss: 2.218 | Accuracy: 0.337891 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299 | Batch: 000 / 039 | Total loss: 2.148 | Reg loss: 0.032 | Tree loss: 2.148 | Accuracy: 0.392578 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 300 | Batch: 000 / 039 | Total loss: 2.200 | Reg loss: 0.032 | Tree loss: 2.200 | Accuracy: 0.376953 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 301 | Batch: 000 / 039 | Total loss: 2.179 | Reg loss: 0.032 | Tree loss: 2.179 | Accuracy: 0.375000 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 302 | Batch: 000 / 039 | Total loss: 2.152 | Reg loss: 0.032 | Tree loss: 2.152 | Accuracy: 0.382812 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 303 | Batch: 000 / 039 | Total loss: 2.164 | Reg loss: 0.032 | Tree loss: 2.164 | Accuracy: 0.392578 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 304 | Batch: 000 / 039 | Total loss: 2.180 | Reg loss: 0.032 | Tree loss: 2.180 | Accuracy: 0.375000 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 305 | Batch: 000 / 039 | Total loss: 2.233 | Reg loss: 0.032 | Tree loss: 2.233 | Accuracy: 0.361328 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 306 | Batch: 000 / 039 | Total loss: 2.185 | Reg loss: 0.032 | Tree loss: 2.185 | Accuracy: 0.361328 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 307 | Batch: 000 / 039 | Total loss: 2.160 | Reg loss: 0.032 | Tree loss: 2.160 | Accuracy: 0.392578 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 308 | Batch: 000 / 039 | Total loss: 2.206 | Reg loss: 0.032 | Tree loss: 2.206 | Accuracy: 0.353516 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 309 | Batch: 000 / 039 | Total loss: 2.118 | Reg loss: 0.032 | Tree loss: 2.118 | Accuracy: 0.396484 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 310 | Batch: 000 / 039 | Total loss: 2.125 | Reg loss: 0.032 | Tree loss: 2.125 | Accuracy: 0.390625 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 311 | Batch: 000 / 039 | Total loss: 2.166 | Reg loss: 0.032 | Tree loss: 2.166 | Accuracy: 0.376953 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 312 | Batch: 000 / 039 | Total loss: 2.187 | Reg loss: 0.032 | Tree loss: 2.187 | Accuracy: 0.347656 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 313 | Batch: 000 / 039 | Total loss: 2.107 | Reg loss: 0.032 | Tree loss: 2.107 | Accuracy: 0.410156 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 314 | Batch: 000 / 039 | Total loss: 2.146 | Reg loss: 0.032 | Tree loss: 2.146 | Accuracy: 0.384766 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 315 | Batch: 000 / 039 | Total loss: 2.162 | Reg loss: 0.032 | Tree loss: 2.162 | Accuracy: 0.394531 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 316 | Batch: 000 / 039 | Total loss: 2.282 | Reg loss: 0.032 | Tree loss: 2.282 | Accuracy: 0.332031 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 317 | Batch: 000 / 039 | Total loss: 2.213 | Reg loss: 0.032 | Tree loss: 2.213 | Accuracy: 0.367188 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 318 | Batch: 000 / 039 | Total loss: 2.114 | Reg loss: 0.032 | Tree loss: 2.114 | Accuracy: 0.396484 | 0.203 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 319 | Batch: 000 / 039 | Total loss: 2.092 | Reg loss: 0.032 | Tree loss: 2.092 | Accuracy: 0.392578 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 320 | Batch: 000 / 039 | Total loss: 2.147 | Reg loss: 0.032 | Tree loss: 2.147 | Accuracy: 0.371094 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 321 | Batch: 000 / 039 | Total loss: 2.273 | Reg loss: 0.032 | Tree loss: 2.273 | Accuracy: 0.328125 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 322 | Batch: 000 / 039 | Total loss: 2.130 | Reg loss: 0.032 | Tree loss: 2.130 | Accuracy: 0.382812 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 323 | Batch: 000 / 039 | Total loss: 2.135 | Reg loss: 0.032 | Tree loss: 2.135 | Accuracy: 0.384766 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 324 | Batch: 000 / 039 | Total loss: 2.234 | Reg loss: 0.032 | Tree loss: 2.234 | Accuracy: 0.349609 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 325 | Batch: 000 / 039 | Total loss: 2.215 | Reg loss: 0.032 | Tree loss: 2.215 | Accuracy: 0.371094 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 326 | Batch: 000 / 039 | Total loss: 2.201 | Reg loss: 0.032 | Tree loss: 2.201 | Accuracy: 0.388672 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 327 | Batch: 000 / 039 | Total loss: 2.152 | Reg loss: 0.032 | Tree loss: 2.152 | Accuracy: 0.380859 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 328 | Batch: 000 / 039 | Total loss: 2.212 | Reg loss: 0.032 | Tree loss: 2.212 | Accuracy: 0.349609 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 329 | Batch: 000 / 039 | Total loss: 2.140 | Reg loss: 0.032 | Tree loss: 2.140 | Accuracy: 0.384766 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 330 | Batch: 000 / 039 | Total loss: 2.224 | Reg loss: 0.032 | Tree loss: 2.224 | Accuracy: 0.349609 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 331 | Batch: 000 / 039 | Total loss: 2.220 | Reg loss: 0.032 | Tree loss: 2.220 | Accuracy: 0.345703 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 332 | Batch: 000 / 039 | Total loss: 2.221 | Reg loss: 0.032 | Tree loss: 2.221 | Accuracy: 0.347656 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 333 | Batch: 000 / 039 | Total loss: 2.083 | Reg loss: 0.032 | Tree loss: 2.083 | Accuracy: 0.416016 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 334 | Batch: 000 / 039 | Total loss: 2.230 | Reg loss: 0.032 | Tree loss: 2.230 | Accuracy: 0.341797 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 335 | Batch: 000 / 039 | Total loss: 2.205 | Reg loss: 0.032 | Tree loss: 2.205 | Accuracy: 0.371094 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 336 | Batch: 000 / 039 | Total loss: 2.084 | Reg loss: 0.032 | Tree loss: 2.084 | Accuracy: 0.417969 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 337 | Batch: 000 / 039 | Total loss: 2.121 | Reg loss: 0.032 | Tree loss: 2.121 | Accuracy: 0.390625 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 338 | Batch: 000 / 039 | Total loss: 2.116 | Reg loss: 0.032 | Tree loss: 2.116 | Accuracy: 0.378906 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 339 | Batch: 000 / 039 | Total loss: 2.179 | Reg loss: 0.032 | Tree loss: 2.179 | Accuracy: 0.351562 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 340 | Batch: 000 / 039 | Total loss: 2.177 | Reg loss: 0.032 | Tree loss: 2.177 | Accuracy: 0.369141 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 341 | Batch: 000 / 039 | Total loss: 2.176 | Reg loss: 0.032 | Tree loss: 2.176 | Accuracy: 0.378906 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 342 | Batch: 000 / 039 | Total loss: 2.203 | Reg loss: 0.032 | Tree loss: 2.203 | Accuracy: 0.378906 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 343 | Batch: 000 / 039 | Total loss: 2.184 | Reg loss: 0.032 | Tree loss: 2.184 | Accuracy: 0.375000 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 344 | Batch: 000 / 039 | Total loss: 2.190 | Reg loss: 0.032 | Tree loss: 2.190 | Accuracy: 0.363281 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 345 | Batch: 000 / 039 | Total loss: 2.196 | Reg loss: 0.032 | Tree loss: 2.196 | Accuracy: 0.359375 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 346 | Batch: 000 / 039 | Total loss: 2.127 | Reg loss: 0.032 | Tree loss: 2.127 | Accuracy: 0.402344 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 347 | Batch: 000 / 039 | Total loss: 2.219 | Reg loss: 0.032 | Tree loss: 2.219 | Accuracy: 0.367188 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 348 | Batch: 000 / 039 | Total loss: 2.160 | Reg loss: 0.032 | Tree loss: 2.160 | Accuracy: 0.390625 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 349 | Batch: 000 / 039 | Total loss: 2.254 | Reg loss: 0.032 | Tree loss: 2.254 | Accuracy: 0.345703 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 350 | Batch: 000 / 039 | Total loss: 2.138 | Reg loss: 0.032 | Tree loss: 2.138 | Accuracy: 0.382812 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 351 | Batch: 000 / 039 | Total loss: 2.082 | Reg loss: 0.032 | Tree loss: 2.082 | Accuracy: 0.402344 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 352 | Batch: 000 / 039 | Total loss: 2.163 | Reg loss: 0.032 | Tree loss: 2.163 | Accuracy: 0.384766 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 353 | Batch: 000 / 039 | Total loss: 2.137 | Reg loss: 0.032 | Tree loss: 2.137 | Accuracy: 0.390625 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 354 | Batch: 000 / 039 | Total loss: 2.172 | Reg loss: 0.032 | Tree loss: 2.172 | Accuracy: 0.380859 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 355 | Batch: 000 / 039 | Total loss: 2.157 | Reg loss: 0.032 | Tree loss: 2.157 | Accuracy: 0.396484 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 356 | Batch: 000 / 039 | Total loss: 2.171 | Reg loss: 0.032 | Tree loss: 2.171 | Accuracy: 0.380859 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 357 | Batch: 000 / 039 | Total loss: 2.288 | Reg loss: 0.032 | Tree loss: 2.288 | Accuracy: 0.328125 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 358 | Batch: 000 / 039 | Total loss: 2.168 | Reg loss: 0.032 | Tree loss: 2.168 | Accuracy: 0.371094 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 359 | Batch: 000 / 039 | Total loss: 2.242 | Reg loss: 0.032 | Tree loss: 2.242 | Accuracy: 0.363281 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 360 | Batch: 000 / 039 | Total loss: 2.120 | Reg loss: 0.032 | Tree loss: 2.120 | Accuracy: 0.392578 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 361 | Batch: 000 / 039 | Total loss: 2.257 | Reg loss: 0.032 | Tree loss: 2.257 | Accuracy: 0.347656 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 362 | Batch: 000 / 039 | Total loss: 2.215 | Reg loss: 0.032 | Tree loss: 2.215 | Accuracy: 0.371094 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 363 | Batch: 000 / 039 | Total loss: 2.139 | Reg loss: 0.032 | Tree loss: 2.139 | Accuracy: 0.406250 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 364 | Batch: 000 / 039 | Total loss: 2.123 | Reg loss: 0.032 | Tree loss: 2.123 | Accuracy: 0.402344 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 365 | Batch: 000 / 039 | Total loss: 2.137 | Reg loss: 0.032 | Tree loss: 2.137 | Accuracy: 0.394531 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 366 | Batch: 000 / 039 | Total loss: 2.192 | Reg loss: 0.032 | Tree loss: 2.192 | Accuracy: 0.375000 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 367 | Batch: 000 / 039 | Total loss: 2.206 | Reg loss: 0.032 | Tree loss: 2.206 | Accuracy: 0.357422 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 368 | Batch: 000 / 039 | Total loss: 2.139 | Reg loss: 0.032 | Tree loss: 2.139 | Accuracy: 0.398438 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 369 | Batch: 000 / 039 | Total loss: 2.168 | Reg loss: 0.032 | Tree loss: 2.168 | Accuracy: 0.382812 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 370 | Batch: 000 / 039 | Total loss: 2.166 | Reg loss: 0.032 | Tree loss: 2.166 | Accuracy: 0.388672 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 371 | Batch: 000 / 039 | Total loss: 2.203 | Reg loss: 0.032 | Tree loss: 2.203 | Accuracy: 0.363281 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 372 | Batch: 000 / 039 | Total loss: 2.187 | Reg loss: 0.032 | Tree loss: 2.187 | Accuracy: 0.380859 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 373 | Batch: 000 / 039 | Total loss: 2.196 | Reg loss: 0.032 | Tree loss: 2.196 | Accuracy: 0.376953 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 374 | Batch: 000 / 039 | Total loss: 2.240 | Reg loss: 0.032 | Tree loss: 2.240 | Accuracy: 0.353516 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 375 | Batch: 000 / 039 | Total loss: 2.119 | Reg loss: 0.032 | Tree loss: 2.119 | Accuracy: 0.396484 | 0.204 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 376 | Batch: 000 / 039 | Total loss: 2.204 | Reg loss: 0.032 | Tree loss: 2.204 | Accuracy: 0.365234 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 377 | Batch: 000 / 039 | Total loss: 2.133 | Reg loss: 0.032 | Tree loss: 2.133 | Accuracy: 0.390625 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 378 | Batch: 000 / 039 | Total loss: 2.099 | Reg loss: 0.032 | Tree loss: 2.099 | Accuracy: 0.400391 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 379 | Batch: 000 / 039 | Total loss: 2.172 | Reg loss: 0.032 | Tree loss: 2.172 | Accuracy: 0.380859 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 380 | Batch: 000 / 039 | Total loss: 2.124 | Reg loss: 0.032 | Tree loss: 2.124 | Accuracy: 0.382812 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 381 | Batch: 000 / 039 | Total loss: 2.158 | Reg loss: 0.032 | Tree loss: 2.158 | Accuracy: 0.390625 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 382 | Batch: 000 / 039 | Total loss: 2.130 | Reg loss: 0.032 | Tree loss: 2.130 | Accuracy: 0.396484 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 383 | Batch: 000 / 039 | Total loss: 2.214 | Reg loss: 0.032 | Tree loss: 2.214 | Accuracy: 0.369141 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 384 | Batch: 000 / 039 | Total loss: 2.165 | Reg loss: 0.032 | Tree loss: 2.165 | Accuracy: 0.382812 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 385 | Batch: 000 / 039 | Total loss: 2.156 | Reg loss: 0.032 | Tree loss: 2.156 | Accuracy: 0.376953 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 386 | Batch: 000 / 039 | Total loss: 2.176 | Reg loss: 0.032 | Tree loss: 2.176 | Accuracy: 0.371094 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 387 | Batch: 000 / 039 | Total loss: 2.140 | Reg loss: 0.032 | Tree loss: 2.140 | Accuracy: 0.398438 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 388 | Batch: 000 / 039 | Total loss: 2.081 | Reg loss: 0.032 | Tree loss: 2.081 | Accuracy: 0.408203 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 389 | Batch: 000 / 039 | Total loss: 2.181 | Reg loss: 0.032 | Tree loss: 2.181 | Accuracy: 0.396484 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 390 | Batch: 000 / 039 | Total loss: 2.244 | Reg loss: 0.032 | Tree loss: 2.244 | Accuracy: 0.363281 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 391 | Batch: 000 / 039 | Total loss: 2.142 | Reg loss: 0.032 | Tree loss: 2.142 | Accuracy: 0.394531 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 392 | Batch: 000 / 039 | Total loss: 2.239 | Reg loss: 0.032 | Tree loss: 2.239 | Accuracy: 0.355469 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 393 | Batch: 000 / 039 | Total loss: 2.181 | Reg loss: 0.032 | Tree loss: 2.181 | Accuracy: 0.367188 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 394 | Batch: 000 / 039 | Total loss: 2.229 | Reg loss: 0.032 | Tree loss: 2.229 | Accuracy: 0.347656 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 395 | Batch: 000 / 039 | Total loss: 2.239 | Reg loss: 0.032 | Tree loss: 2.239 | Accuracy: 0.337891 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 396 | Batch: 000 / 039 | Total loss: 2.240 | Reg loss: 0.032 | Tree loss: 2.240 | Accuracy: 0.343750 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 397 | Batch: 000 / 039 | Total loss: 2.217 | Reg loss: 0.032 | Tree loss: 2.217 | Accuracy: 0.361328 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 398 | Batch: 000 / 039 | Total loss: 2.204 | Reg loss: 0.032 | Tree loss: 2.204 | Accuracy: 0.357422 | 0.205 sec/iter\n",
      "Average sparseness: 0.9840425531914894\n",
      "layer 0: 0.9840425531914894\n",
      "layer 1: 0.9840425531914894\n",
      "layer 2: 0.9840425531914894\n",
      "layer 3: 0.9840425531914894\n",
      "layer 4: 0.9840425531914894\n",
      "layer 5: 0.9840425531914894\n",
      "layer 6: 0.9840425531914895\n",
      "Epoch: 399 | Batch: 000 / 039 | Total loss: 2.216 | Reg loss: 0.032 | Tree loss: 2.216 | Accuracy: 0.355469 | 0.205 sec/iter\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    avg_sp = show_sparseness(tree)\n",
    "    sparsity.append(avg_sp)\n",
    "    iteration = do_epoch(tree, tree_loader, device, log_interval, losses, accs, epoch, iteration)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        prune_tree(tree, factor=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a67f93c9344ace9061a81f7001cfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(accs, label='Accuracy vs iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f442da4850844104bc7c85cb9ad0942c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62498c2db9f04e169260a41b0568149e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.plot(losses, label='Loss vs iteration')\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "weights = tree.inner_nodes.weight.cpu().detach().numpy().flatten()\n",
    "plt.hist(weights, bins=500)\n",
    "weights_std = np.std(weights)\n",
    "weights_mean = np.mean(weights)\n",
    "plt.axvline(weights_mean + weights_std, color='r')\n",
    "plt.axvline(weights_mean - weights_std, color='r')\n",
    "plt.title(f\"Mean: {weights_mean}   |   STD: {weights_std}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79cf7fedd134caf8818127cda23b49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average height: 6.6521739130434785\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "avg_height, root = tree.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accumulate samples in the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patterns: 46\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of patterns: {len(root.get_leaves())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'greedy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/.local/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "root.clear_leaves_samples()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(tree_loader):\n",
    "        root.accumulate_samples(data, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tighten boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Pattern 1 ==============\n",
      "2292\n",
      "============== Pattern 2 ==============\n",
      "============== Pattern 3 ==============\n",
      "============== Pattern 4 ==============\n",
      "============== Pattern 5 ==============\n",
      "============== Pattern 6 ==============\n",
      "============== Pattern 7 ==============\n",
      "============== Pattern 8 ==============\n",
      "============== Pattern 9 ==============\n",
      "============== Pattern 10 ==============\n",
      "4\n",
      "============== Pattern 11 ==============\n",
      "15706\n",
      "============== Pattern 12 ==============\n",
      "105\n",
      "============== Pattern 13 ==============\n",
      "============== Pattern 14 ==============\n",
      "============== Pattern 15 ==============\n",
      "============== Pattern 16 ==============\n",
      "============== Pattern 17 ==============\n",
      "============== Pattern 18 ==============\n",
      "============== Pattern 19 ==============\n",
      "============== Pattern 20 ==============\n",
      "============== Pattern 21 ==============\n",
      "============== Pattern 22 ==============\n",
      "============== Pattern 23 ==============\n",
      "============== Pattern 24 ==============\n",
      "============== Pattern 25 ==============\n",
      "============== Pattern 26 ==============\n",
      "============== Pattern 27 ==============\n",
      "============== Pattern 28 ==============\n",
      "============== Pattern 29 ==============\n",
      "============== Pattern 30 ==============\n",
      "============== Pattern 31 ==============\n",
      "============== Pattern 32 ==============\n",
      "============== Pattern 33 ==============\n",
      "============== Pattern 34 ==============\n",
      "224\n",
      "============== Pattern 35 ==============\n",
      "============== Pattern 36 ==============\n",
      "============== Pattern 37 ==============\n",
      "============== Pattern 38 ==============\n",
      "============== Pattern 39 ==============\n",
      "============== Pattern 40 ==============\n",
      "1593\n",
      "============== Pattern 41 ==============\n",
      "============== Pattern 42 ==============\n",
      "============== Pattern 43 ==============\n",
      "============== Pattern 44 ==============\n",
      "============== Pattern 45 ==============\n",
      "============== Pattern 46 ==============\n",
      "Average comprehensibility: 37.17391304347826\n",
      "std comprehensibility: 9.785313635697138\n",
      "var comprehensibility: 95.75236294896033\n",
      "minimum comprehensibility: 16\n",
      "maximum comprehensibility: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eitan.k/EntangledExplainableClustering/soft_decision_tree/sdt_model.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(1 / (1 - x))\n"
     ]
    }
   ],
   "source": [
    "attr_names = [f\"T_{i}\" for i in range(test_samples.shape[2])]\n",
    "leaves = root.get_leaves()\n",
    "sum_comprehensibility = 0\n",
    "comprehensibilities = []\n",
    "for pattern_counter, leaf in enumerate(leaves):\n",
    "    leaf.reset_path()\n",
    "    leaf.tighten_with_accumulated_samples()\n",
    "    conds = leaf.get_path_conditions(attr_names)\n",
    "    print(f\"============== Pattern {pattern_counter + 1} ==============\")\n",
    "    comprehensibilities.append(sum([cond.comprehensibility for cond in conds]))\n",
    "    \n",
    "print(f\"Average comprehensibility: {np.mean(comprehensibilities)}\")\n",
    "print(f\"std comprehensibility: {np.std(comprehensibilities)}\")\n",
    "print(f\"var comprehensibility: {np.var(comprehensibilities)}\")\n",
    "print(f\"minimum comprehensibility: {np.min(comprehensibilities)}\")\n",
    "print(f\"maximum comprehensibility: {np.max(comprehensibilities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
